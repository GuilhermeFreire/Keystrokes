{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Análise de Usuários através de Keystrokes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nesse trabalho, busco explorar o quanto o modo como um usuário digita diz sobre ele. É possível dicerní-lo de outros apenas por seu padrão de digitação? Conseguimos agrupar usuários que digitam de forma parecida? O que mais é possível extrair de dados de telcas?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Motivação\n",
    "\n",
    "Qual a utilidade de ser se estudar padrões de digitação de um usuário?\n",
    "\n",
    "Assumindo que cada usuário tem um padrão de digitação único, ou pelo menos razoavelmente único, é possível pensar em uma tarefa de identificação. Sites como o Coursera utilizam esses dados justamente para julgar se um aluno realmente está fazendo os deveres do curso. Logo quando um usuário se cadastra, ele deve digitar um parágrafo para que um perfil associado seja criado. Esse perfil é então comparado posteriormente aos textos (códigos ou respostas discursivas) escritos pelo aluno. Por ser utilizado por tanto tempo na plataforma, podemos suspeitar que esse tipo de dado é um bom indicativo de unicidade.\n",
    "\n",
    "Outra aplicação possível é identificação de usuários fazendo login. Se um sistema for capaz de identificar o usuário pelo modo como digita, uma camada a mais de segurança pode ser criada. Afinal, não basta saber a senha da conta, é necessário digitar como o dono original digita. Dessa forma, fraudes por senhas vazadas, bancos de dados comprometidos, ou até mesmo senhas anotadas em _post-its_ no monitor podem ser evitadas.\n",
    "\n",
    "Para o caso de uso da senha é interessante notar um detalhe que é o não envio da senha em _plain text_ ao servidor verificador. É extremamente comum - se crucial para uma base mínima de segurança - que a senha de um usuário não trafegue a rede em _plain text_. Isso porque é muito fácil um malfeitor capturar dados transientes em uma rede (principalmente pública). Dessa forma, se a senha não tiver nenhum mecanismo de proteção, a conta do usuário estará comprometida.\n",
    "\n",
    "O que normalmente ocorre é o envio de um _hash_ da senha. O _hash_ nada mais é do que uma função que leva uma entrada a uma saída de forma simples, mas garante que a inversão (sabendo uma saída, encontrar a entrada correspondente) é uma tarefa árdua. Utilizando esse método, sites que permitem fazer login não precisam guardar as senhas de seus usuários, basta guardar os hashes das senhas. Afinal, como cada senha sempre produz o mesmo hash, é possível comparar hashes para saber se a senha está correta. Aplicando essa metodologia, mesmo que ocorra um vazamento de senhas ou uma senha seja fisgada em trânsito, o segredo está seguro. Apenas o hash foi comprometido e como dito acima, hashes são difíceis de reverter.\n",
    "\n",
    "O que isso implica na utilização de dados de digitação para verificação do usuário? Imediatamente, significa que não se pode utilizar as teclas nem os tempos de digitação entre elas para tirar tais conclusões. Afinal, se isso fosse utilizado, todo o propósito de não enviar a senha em _plain text_ estará perdido. Soluções mais criativas terão que ser utilizadas, como veremos a frente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "\n",
    "Para começar a exploração desse tópico, escolhi um dataset famoso de dados de _keystrokes_. O dataset é conhecido como _CMU Keystroke Dynamics – Benchmark Data Set_.\n",
    "\n",
    "### Contrução do dataset\n",
    "\n",
    "Esse dataset foi montado com dados de 51 pessoas diferentes digitando a senha `.tie5Roanl` repetidas vezes. Ao todo foram 400 repetições por pessoa espaçadas em sessões distintas. Em cada sessão a pessoa digitava a senha 50 vezes, implicando num total de 8 sessões que foram feitas com pelo menos um dia de folga entre elas para capturar a variação de padrões de digitação ao longo de dias.\n",
    "\n",
    "### Dados coletados\n",
    "\n",
    "Resta, agora, sabermos que métricas foram efetivamente coletadas e armazenadas nesse dataset. Cada sessão de coleta captura três tipos de dados: `Hold`, `Down-Down`, `Up-Down`.\n",
    "\n",
    "![Métricas coletadas](data_explanation.jpg)\n",
    "\n",
    "- Hold: Mede o tempo que uma tecla foi pressionada (desde o momento que foi abaixada até quando é solta).\n",
    "- Down-Down: Mede o tempo entre uma tecla ser abaixada e a próxima ser abaixada.\n",
    "- Up-Down: Mede o tempo entre uma tecla ser solta e a próxima abaixada.\n",
    "\n",
    "Dessa forma, como o texto digitado foi `.tie5Roanl`, cada entrada do dataset será composta dos seguintes atributos:\n",
    "\n",
    "```\n",
    "subject,sessionIndex,rep,H.period,DD.period.t,UD.period.t,H.t,DD.t.i,UD.t.i, ... , H.n,DD.n.l,UD.n.l,H.l,DD.l.Return,UD.l.Return,H.Return\n",
    "```\n",
    "\n",
    "O primeiro parâmetro indica qual participante digitou essa entrada do dataset. O atributo `sessionIndex` indica a qual sessão essa captura faz parte e `rep` qual a repetição dentro dessa sessão. A partir desse ponto começam as medidas de tempo. O primeiro campo, `H.period`, indica o tempo que a tecla de _ponto final_ ficou pressionada (_Hold period_). Em seguida, temos `DD.period.t` que indica o tempo entre a tecla de _ponto final_ ser pressionada para baixo e a tecla `t` ser pressionada para baixo (_Down-Down period t_). Analogamente, `UD.period.t` mostra o tempo entre soltar o _ponto final_ e pressionar a tecla `t`. As mesmas três métricas se repetem para as próximas teclas da senha. É importante notar que a tecla `Enter` foi pressionada ao final da digitação e é expressa no dataset por meio do termo _Return_."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Análise inicial dos dados\n",
    "\n",
    "Sabendo como o dataset foi construído, comecemos por tentar entender seus dados. Comecemos por uma redução de dimensionalidade para ser possível desenhar um plot 2D dos pontos. Com isso teremos alguma ideia de como os dados se comportam."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import time\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comecemos por ler os dados do arquivo em que estão salvos e separá-los por linhas. Aqui também jogaremos o cabeçalho fora, visto que não será utilizado nas manipulações e já temos uma descrição dos dados acima."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lendo dados do arquivo\n",
    "with open(\"DSL-StrongPasswordData.csv\") as f:\n",
    "    data = np.array([line.split(\",\") for line in f.read().strip().split(\"\\n\")[1:]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora, separemos os identificadores de usuários dos dados propriamente ditos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['s040' '5' '44']\n",
      " ['s036' '7' '35']] \n",
      " [[ 0.1227  0.3441  0.2214  0.1071  0.1493  0.0422  0.106   0.3349  0.2289\n",
      "   0.153   0.73    0.577   0.0731  0.5698  0.4967  0.0839  0.3472  0.2633\n",
      "   0.1124  0.16    0.0476  0.1765  0.2884  0.1119  0.1097  0.3012  0.1915\n",
      "   0.0823  0.2655  0.1832  0.1084]\n",
      " [ 0.0377  0.5097  0.472   0.0475  0.2709  0.2234  0.0409  0.2883  0.2474\n",
      "   0.0457  0.4903  0.4446  0.042   0.4409  0.3989  0.0351  0.605   0.5699\n",
      "   0.0285  0.2008  0.1723  0.0525  0.3788  0.3263  0.0327  0.4781  0.4454\n",
      "   0.0393  0.4406  0.4013  0.0364]]\n"
     ]
    }
   ],
   "source": [
    "# Formatando os dados\n",
    "np.random.seed(1234)\n",
    "np.random.shuffle(data)\n",
    "recordings, keystrokes = data[:,:3], data[:,3:].astype(float)\n",
    "print(recordings[:2], \"\\n\", keystrokes[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para termos certeza de que tudo está coerente no dataset, verifiquemos a quantidade de colunas da matriz e comparemos com o tamanho do que foi digitado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de teclas na digitação da senha: 11\n",
      "Número de colunas na matriz do dataset: 31\n"
     ]
    }
   ],
   "source": [
    "password = \".tie5Roanl\\n\" # Lembrando que o enter é pressionado ao final da senha\n",
    "print(\"Número de teclas na digitação da senha: {}\".format(len(password)))\n",
    "print(\"Número de colunas na matriz do dataset: {}\".format(keystrokes.shape[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exatamente como o esperado. Afinal, temos três medições por tecla pressionada (exceto a última) e temos 11 teclas pressionadas. Como não há teclas após o `Enter`, essa tecla só terá a métrica de `Hold` medida. Isso totalizará em exatas **31 medições**, como imaginávamos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verifiquemos agora o número de usuários no dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Identificadores de usuários: ['s002', 's003', 's004', 's005', 's007', 's008', 's010', 's011', 's012', 's013', 's015', 's016', 's017', 's018', 's019', 's020', 's021', 's022', 's024', 's025', 's026', 's027', 's028', 's029', 's030', 's031', 's032', 's033', 's034', 's035', 's036', 's037', 's038', 's039', 's040', 's041', 's042', 's043', 's044', 's046', 's047', 's048', 's049', 's050', 's051', 's052', 's053', 's054', 's055', 's056', 's057']\n",
      "Quantidade de usuários únicos: 51\n"
     ]
    }
   ],
   "source": [
    "users = sorted(list(set(recordings[:,0])))\n",
    "print(\"Identificadores de usuários: {}\".format(users))\n",
    "print(\"Quantidade de usuários únicos: {}\".format(len(users)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Temos 51 usuários únicos, novamente como esperado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Redução de Dimensionalidade\n",
    "\n",
    "Para ganharmos uma intuição sobre comportamento de cada usuário, podemos tentar desenhar os pontos do dataset em um gráfico. Entretanto, como os dados são de dimensão 31, é preciso aplicar algum tipo de redução de dimensionalidade para que esse gráfico se torne possível."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVD\n",
    "\n",
    "Uma técnica que permite essa redução é o SVD (Singular Value Decomposition). Com o SVD conseguimos encontrar uma base boa para representar nossos dados. Não só isso, como também é possível verificar a importância de cada dimensão para a representação dos dados. Isso será importante para analisarmos a quantidade de informação que está sendo perdida com a simplificação dos dados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Antes de fazermos qualquer manipulação com os dados, entretanto, é interessante normalizá-los."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = np.mean(keystrokes, axis=0)\n",
    "std = np.std(keystrokes, axis=0)\n",
    "\n",
    "norm_keystrokes = (keystrokes - mean) / std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uma vez com os dados normalizados, podemos prosseguir com a redução de dimensionalidade. A técnica de SVD decompõe uma matriz em três, $U$, $\\Sigma$ e $V^T$. Juntas elas tais matrizes formam a original de acordo com a relação $U \\Sigma V^T = M$, onde $M$ é a matriz original.\n",
    "\n",
    "Para compreendermos melhor o que o SVD faz com uma matriz, primeiro precisamos entender o que a matriz original significa. No caso desse dataset, cada linha da matriz $M$ representa um usuário e cada coluna uma métrica de digitação. Dessa forma, podemos enxergar a matriz $M$ como a matriz que nos leva de usuário para digitação. É importante manter essa relação em mente, pois se nos propusermos a fazer uma decomposição dessa matriz, é importante que essa relação se mantenha."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "    \\text{Usuários} \\Bigg \\{ \n",
    "    \\overbrace{\n",
    "    \\begin{bmatrix}\n",
    "          &   &  &  \\\\\n",
    "          &   &  &  \\\\\n",
    "          &   &  &  \n",
    "    \\end{bmatrix}\n",
    "    }^\\text{Digitação}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como dito anteriormente, o SVD \"_procura uma base boa_\" para a representação dos dados. O que exatamente significa essa \"_base boa_\"?\n",
    "\n",
    "Por _base boa_, o algoritmo entende ser a base nas quais as dimensões capturam o máximo de informação possível. Em termos estatísticos, são as dimensões com maior variância dos dados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b style=\"color:red;\">[imagem mostrando pontos variando muito sobre um vetor e pouco sobre outros. Ao lado, imagem mostrando o eixo que melhor representa os dados. 2D -> 1D]</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dessa forma, se pegarmos apenas as dimensões com maior informação, seremos capazes de manter os dados quase íntegros e ao mesmo tempo reduzir sua dimensionalidade. Como no exemplo acima, vemos que os pontos variam muito na direção do vetor destacado. Significa que se projetarmos os pontos nesse vetor, poderemos representá-los - quase que fielmente - com apenas um número: a magnitude do deslocamento a partir da origem nessa direção. Dessa forma, reduzimos com sucesso dados originalmente em 2D para dados em 1D."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora, analisemos possíveis interpretações das matrizes resultantes do SVD no dataset de padrões de digitação. O algoritmo leva os pontos do dataset da base original para uma base ideal. Isso pode ser visto analisando o papel de cada matriz resultante."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "U, Sigma, Vt = np.linalg.svd(norm_keystrokes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Começando por $U$, podemos interpretar seu papel como sendo a matriz que leva os usuários a esse espaço ideal encontrado pelo SVD. Em seguida, temos $\\Sigma$. Essa é a matriz responsável por escalar os pontos no espaço ideal de acordo com a _importância_ de cada dimensão nesse espaço. Finalmente temos $V^T$ que pode ser vista como a matriz que traz os dados de volta do espaço ideal para o espaço de digitação.\n",
    "\n",
    "Vendo a decomposição dessa forma, acabamos com a mesma interpretação da matriz original - uma matriz que leva de usuários para métricas de digitação. O grande ganho é que o SVD nos permite enxergar os dados em uma dimensão ideal intermediária. Nela, podemos fazer manipulações nos dados que nos permite, por exemplo, reduzir a dimensionalidade preservando o máximo de informação possível."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A \"importância\" de cada dimensão está atrelada à magnitude dos valores singulares da matriz $\\Sigma$. Vendo a relação desses valores podemos tirar conclusões sobre a dimensão real dos dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAEICAYAAABRSj9aAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f1995b97dd8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(Sigma)\n",
    "plt.scatter(np.arange(31), Sigma)\n",
    "plt.title(\"Valores Singulares do Dataset de Keystrokes\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Olhando para esse gráfico, vemos de imediado que a partir da dimensão ideal 20 as outras dimensões praticamente não contribuem para a informação real dos dados. Em termos um pouco mais formais, praticamente não há variação dos dados ao longo das dimensões superiores à vigésima.\n",
    "\n",
    "Mais do que isso, é possível notar que as duas primeiras dimensões contribuem com a maior parte da informação dos dados. A partir da terceira, as dimensões ficam progressivamente menos relevantes de forma gradual.\n",
    "\n",
    "Isso tudo indica que nosso gráfico em 2D dos pontos conterá uma boa parte da informação do dataset original. Portanto será uma boa visualização dos dados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para fazermos esse gráfico em 2D dos pontos, basta lembrarmos da interpretação das matrizes resultantes da decompoisção. Queremos levar nossos pontos ao espaço ideal e ignorar todas as dimensões exceto as duas primeiras.\n",
    "\n",
    "O primeiro passo pode ser facilmente feito apenas com a matriz $U$ - afinal ela é a responsável por levar os pontos para o espaço ideal. Em seguida, basta zerarmos os valores singulares indesejáveis da matriz $\\Sigma$ que zeraremos as coordenadas indesejadas dos pontos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz Sigma Reduzida:\n",
      " [[ 407.97342532    0.            0.         ...,    0.            0.            0.        ]\n",
      " [   0.          326.96957765    0.         ...,    0.            0.            0.        ]\n",
      " [   0.            0.            0.         ...,    0.            0.            0.        ]\n",
      " ..., \n",
      " [   0.            0.            0.         ...,    0.            0.            0.        ]\n",
      " [   0.            0.            0.         ...,    0.            0.            0.        ]\n",
      " [   0.            0.            0.         ...,    0.            0.            0.        ]]\n",
      "\n",
      "Dimensões de Sigma Reduzida: (20400, 31)\n"
     ]
    }
   ],
   "source": [
    "reduced_sigma = np.zeros((U.shape[1], Sigma.shape[0]))\n",
    "reduced_sigma[0,0] = Sigma[0]\n",
    "reduced_sigma[1,1] = Sigma[1]\n",
    "print(\"Matriz Sigma Reduzida:\\n\",reduced_sigma, end=\"\\n\\n\")\n",
    "print(\"Dimensões de Sigma Reduzida:\",reduced_sigma.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como queremos ficar no espaço ideal, basta não incluirmos a matriz $V^T$ - cuja função é trazer os pontos de volta ao espaço original."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.79661649 -3.14352362  0.         ...,  0.          0.          0.        ]\n",
      " [ 7.33690199  2.98459802  0.         ...,  0.          0.          0.        ]\n",
      " [-0.41674256  3.11857179  0.         ...,  0.          0.          0.        ]\n",
      " ..., \n",
      " [-1.29789951 -1.33182584  0.         ...,  0.          0.          0.        ]\n",
      " [ 0.54700926 -1.83758573  0.         ...,  0.          0.          0.        ]\n",
      " [ 1.03072995 -1.17526715  0.         ...,  0.          0.          0.        ]]\n",
      "(20400, 31)\n"
     ]
    }
   ],
   "source": [
    "reduced_keystrokes = U @ reduced_sigma\n",
    "print(reduced_keystrokes)\n",
    "print(reduced_keystrokes.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como podemos ver, zeramos as coordenadas menos relevantes com sucesso. Basta então usarmos as que sobraram para desenhar o gráfico."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlUAAAJOCAYAAACeF/LqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nJ6vggh+w1CTNAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f1995b4fe48>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "colors = {\"s002\": \"#E32636\", \"s003\": \"#B0BF1A\", \"s004\": \"#7CB9E8\", \"s005\": \"#84DE02\", \"s007\": \"#EFDECD\", \"s008\": \"#00308F\", \"s010\": \"#0048BA\", \"s011\": \"#AF002A\", \"s012\": \"#C9FFE5\", \"s013\": \"#72A0C1\", \"s015\": \"#C46210\", \"s016\": \"#B284BE\", \"s017\": \"#E52B50\", \"s018\": \"#9F2B68\", \"s019\": \"#F19CBB\", \"s020\": \"#AB274F\", \"s021\": \"#D3212D\", \"s022\": \"#3B7A57\", \"s024\": \"#FFBF00\", \"s025\": \"#FF7E00\", \"s026\": \"#3B3B6D\", \"s027\": \"#391802\", \"s028\": \"#804040\", \"s029\": \"#D3AF37\", \"s030\": \"#34B334\", \"s031\": \"#FF8B00\", \"s032\": \"#FF9899\", \"s033\": \"#431C53\", \"s034\": \"#B32134\", \"s035\": \"#FF033E\", \"s036\": \"#CFCFCF\", \"s037\": \"#551B8C\", \"s038\": \"#F2B400\", \"s039\": \"#9966CC\", \"s040\": \"#A4C639\", \"s041\": \"#F2F3F4\", \"s042\": \"#CD9575\", \"s043\": \"#665D1E\", \"s044\": \"#915C83\", \"s046\": \"#841B2D\", \"s047\": \"#FAEBD7\", \"s048\": \"#008000\", \"s049\": \"#66B447\", \"s050\": \"#8DB600\", \"s051\": \"#FBCEB1\", \"s052\": \"#00FFFF\", \"s053\": \"#7FFFD4\", \"s054\": \"#D0FF14\", \"s055\": \"#C0C0C0\", \"s056\": \"#4B5320\", \"s057\": \"#3B444B\"}\n",
    "reduced_keystrokes_ = reduced_keystrokes[:,:2]\n",
    "\n",
    "vis_users = [\"s005\", \"s010\", \"s011\", \"s016\"]\n",
    "plt.figure(figsize=(10,10))\n",
    "for i, point in enumerate(reduced_keystrokes_):\n",
    "    #Para facilitar a visualização, faremos o plot de apenas quatro usuários\n",
    "    if recordings[i][0] in vis_users:\n",
    "        plt.scatter(point[0], point[1], c=colors[recordings[i][0]])\n",
    "plt.title(\"Dados de digitação dos usuários {}\".format(\", \".join(vis_users)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observando o gráfico, vemos que a redução de dimensionalidade realmente funcionou. Usando a técnica de SVD conseguimos visualizar as diferenças nos padrões de digitação das pessoas utilizadas na criação do dataset.\n",
    "\n",
    "Podemos ver que usando apenas duas dimensões não é sempre óbiva a distinção de cada par de usuários. No exemplo do gráfico acima, vemos uma clara separação entre os usuários azul, vermelho escuro e verde - com pontos concentrados em regiões diferentes do espaço. Já o usuário roxo, se mistura consideravelmente com o verde. Isso pode ser reflexo de uma possível proximidade do modo como ambos digitam, ou simplesmente uma limitação da visualização em 2D do dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos, por fim, tentar estimar a grosso modo quanta informação retemos ao simplificar os dados para 2D. Para isso, podemos usar os valores singulares obtidos em $\\Sigma$. A ideia é simplesmente verificar a proporção das dimensões retidas em relação ao total."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimativa de informação retida: 22.684216838113194%\n"
     ]
    }
   ],
   "source": [
    "retained_info = (Sigma[0] + Sigma[1]) / np.sum(Sigma)\n",
    "print(\"Estimativa de informação retida: {}%\".format(100*retained_info))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Diminuindo o espaço dos pontos do dataset da forma que fizemos, somos capazes de reter em torno de 22% da informação do dado original. Essa estimativa não pode ser levada tão literalmente, mas ajuda a entender o que estamos preservando.\n",
    "\n",
    "Mesmo com apenas um quinto da informação original, ainda somos capazes de visualmente discernir alguns usuários. Isso realmente é um indicativo motivador para a próxima tarefa: classificação."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Autoencoder\n",
    "\n",
    "Vimos uma forma de redução de dimensionalidade, o SVD. Entretanto, essa decomposição não é a única forma de se reduzir as dimensões de dados. Existe outro método muito popular conhecido como _Autoencoder_."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A técnica de _Autoencoder_ foi desenvolvida com a popularização de redes neurais no cenário acadêmico. A proposta consiste de uma ideia muito simples. Criamos uma rede neural dividida em duas partes: um _encoder_ e um _decoder_. O encoder é responsável por pegar o dado no espaço original e levá-lo para um espaço latente (_embedding space_). O decoder faz justamente o oposto, ou seja, recebe como entrada um vetor no espaço latente e o converte de volta ao espaço original.\n",
    "\n",
    "<center>\n",
    "```\n",
    "embedding = encoder(dado original)\n",
    "dado reconstruido = decoder(embedding)\n",
    "```\n",
    "</center>\n",
    "\n",
    "A ideia é treinar a rede para encontrar o melhor espaço latente possível para representar os dados. Em termos mais concretos, estamos tentando minimizar a diferença entre o dado reconstruido e o dado original controlando as funções de _encoding_ e _decoding_.\n",
    "\n",
    "$$\n",
    "    decoder, encoder = \\arg \\min_{d,e}{\\lVert X - d(e(X)) \\rVert ^2}\n",
    "$$\n",
    "\n",
    "O espaço de embedding pode ser arbitrariamente escolhido, mas como nosso objetivo é realizar uma redução de dimensionalidade, é interessante escolhermos um espaço com dimensão menor. Mais especificamente, queremos um espaço em 2D para fazermos um gráfico representativo do dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para isso, construimos uma rede neural que afunila e depois expande os dados. A camada inicial da rede é da dimensão original do dado. A partir da primeira, as camadas ficam progressivamente menores, forçando uma representação mais densa de nossos dados. Quando chegamos na dimensão desejada, começamos o processo de reconstrução do dado. A partir desse ponto, as camadas ficam progressivamente maiores até atingirem o tamanho original."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Estrutura de um Autoencoder](Autoencoder_structure.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construiremos uma rede com a mesma quantidade de camadas que a imagem acima mostra. Aproveitando que já calculamos os valores singulares previamente usando o SVD, vemos que realmente só precisamos de 20 dimensões para representar fielmente nossos dados. Dessa forma, podemos supor que é uma boa escolha fazer as camadas intermediárias entre o dado original e a representação 2D ter ser de tamanho 20.\n",
    "\n",
    "\n",
    "<center>\n",
    "```\n",
    "dado (31D) -> dado (20D) -> dado (2D) -> dado (20D) -> dado (31D)\n",
    "```\n",
    "</center>\n",
    "\n",
    "O fato de termos camadas intermediárias entre a representação 2D e a original ajuda a dar mais flexibilidade para manipulação da rede."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device(\"/device:CPU:0\"):\n",
    "    x = tf.placeholder(tf.float32, shape=[None, 31])\n",
    "\n",
    "    encoder_W1 = tf.get_variable(\"e_W1\", shape=[31, 20], initializer=tf.contrib.layers.xavier_initializer())\n",
    "    encoder_b1 = tf.Variable(tf.zeros([20]), name=\"e_b1\")\n",
    "\n",
    "    embedding_20D = tf.nn.relu(tf.matmul(x, encoder_W1) + encoder_b1)\n",
    "\n",
    "    encoder_W2 = tf.get_variable(\"e_W2\", shape=[20, 2], initializer=tf.contrib.layers.xavier_initializer())\n",
    "    encoder_b2 = tf.Variable(tf.zeros([2]), name=\"e_b2\")\n",
    "\n",
    "    embedding_2D = tf.matmul(embedding_20D, encoder_W2) + encoder_b2\n",
    "    embedding_2D_activated = tf.nn.sigmoid(embedding_2D)\n",
    "\n",
    "    decoder_W1 = tf.get_variable(\"d_W1\", shape=[2, 20], initializer=tf.contrib.layers.xavier_initializer())\n",
    "    decoder_b1 = tf.Variable(tf.zeros([20]), name=\"d_b1\")\n",
    "\n",
    "    reconstruction_20D = tf.nn.relu(tf.matmul(embedding_2D_activated, decoder_W1) + decoder_b1)\n",
    "\n",
    "    decoder_W2 = tf.get_variable(\"d_W2\", shape=[20, 31], initializer=tf.contrib.layers.xavier_initializer())\n",
    "    decoder_b2 = tf.Variable(tf.zeros([31]), name=\"d_b2\")\n",
    "\n",
    "    reconstruction_31D = tf.nn.relu(tf.matmul(reconstruction_20D, decoder_W2) + decoder_b2)\n",
    "\n",
    "    loss = tf.reduce_mean(tf.pow(x - reconstruction_31D, 2))\n",
    "\n",
    "    train_step = tf.train.AdamOptimizer(learning_rate=0.00001).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_data_idx = 20000\n",
    "train_data = norm_keystrokes[:split_data_idx]\n",
    "test_data = norm_keystrokes[split_data_idx:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def next_batch(size, i):\n",
    "    k = train_data[i*size:(i+1)*size]\n",
    "    return k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 0: Batch #0 - Loss: 0.8616877198219299\n",
      "Model saved in file: ./weights_autoencoder_low_LR/model_e0b0_1516651268.3718064.ckpt\n",
      "Ep 0: Batch #1 - Loss: 0.9478267431259155\n",
      "Ep 0: Batch #2 - Loss: 1.0629867315292358\n",
      "Ep 0: Batch #3 - Loss: 0.9341558814048767\n",
      "Ep 0: Batch #4 - Loss: 0.8574299216270447\n",
      "Model saved in file: ./weights_autoencoder_low_LR/model_e0b4_1516651268.3963735.ckpt\n",
      "Ep 0: Batch #5 - Loss: 0.7206717729568481\n",
      "Model saved in file: ./weights_autoencoder_low_LR/model_e0b5_1516651268.4175773.ckpt\n",
      "Ep 0: Batch #6 - Loss: 0.9528446197509766\n",
      "Ep 0: Batch #7 - Loss: 0.7587512731552124\n",
      "Ep 0: Batch #8 - Loss: 0.7932882308959961\n",
      "Ep 0: Batch #9 - Loss: 1.492522954940796\n",
      "Ep 0: Batch #10 - Loss: 1.0801488161087036\n",
      "Ep 0: Batch #11 - Loss: 0.7347844243049622\n",
      "Ep 0: Batch #12 - Loss: 1.6323261260986328\n",
      "Ep 0: Batch #13 - Loss: 0.6900389194488525\n",
      "Model saved in file: ./weights_autoencoder_low_LR/model_e0b13_1516651268.4417918.ckpt\n",
      "Ep 0: Batch #14 - Loss: 0.7821448445320129\n",
      "Ep 0: Batch #15 - Loss: 1.322998046875\n",
      "Ep 0: Batch #16 - Loss: 1.3710088729858398\n",
      "Ep 0: Batch #17 - Loss: 0.9457659721374512\n",
      "Ep 0: Batch #18 - Loss: 0.9924615025520325\n",
      "Ep 0: Batch #19 - Loss: 0.7205526828765869\n",
      "Ep 0: Batch #20 - Loss: 0.7133625149726868\n",
      "Ep 0: Batch #21 - Loss: 1.279697060585022\n",
      "Ep 0: Batch #22 - Loss: 0.781620442867279\n",
      "Ep 0: Batch #23 - Loss: 0.8126595616340637\n",
      "Ep 0: Batch #24 - Loss: 0.8859844207763672\n",
      "Ep 0: Batch #25 - Loss: 0.782528817653656\n",
      "Ep 0: Batch #26 - Loss: 0.793801486492157\n",
      "Ep 0: Batch #27 - Loss: 1.4300471544265747\n",
      "Ep 0: Batch #28 - Loss: 0.932361364364624\n",
      "Ep 0: Batch #29 - Loss: 0.9681746959686279\n",
      "Ep 0: Batch #30 - Loss: 1.281100869178772\n",
      "Ep 0: Batch #31 - Loss: 0.7208023071289062\n",
      "Ep 0: Batch #32 - Loss: 0.8108212351799011\n",
      "Ep 0: Batch #33 - Loss: 0.8661653399467468\n",
      "Ep 0: Batch #34 - Loss: 0.8439552187919617\n",
      "Ep 0: Batch #35 - Loss: 1.0284194946289062\n",
      "Ep 0: Batch #36 - Loss: 0.7601792216300964\n",
      "Ep 0: Batch #37 - Loss: 1.2061876058578491\n",
      "Ep 0: Batch #38 - Loss: 0.8142108917236328\n",
      "Ep 0: Batch #39 - Loss: 0.8703844547271729\n",
      "Ep 0: Batch #40 - Loss: 0.8428792953491211\n",
      "Ep 0: Batch #41 - Loss: 0.7962841987609863\n",
      "Ep 0: Batch #42 - Loss: 0.7761405110359192\n",
      "Ep 0: Batch #43 - Loss: 0.8500077128410339\n",
      "Ep 0: Batch #44 - Loss: 0.8452816009521484\n",
      "Ep 0: Batch #45 - Loss: 0.6997019648551941\n",
      "Ep 0: Batch #46 - Loss: 0.898973822593689\n",
      "Ep 0: Batch #47 - Loss: 1.0431582927703857\n",
      "Ep 0: Batch #48 - Loss: 1.4459385871887207\n",
      "Ep 0: Batch #49 - Loss: 1.0831817388534546\n",
      "Ep 0: Batch #50 - Loss: 0.756010115146637\n",
      "Ep 0: Batch #51 - Loss: 1.0718623399734497\n",
      "Ep 0: Batch #52 - Loss: 0.8469476699829102\n",
      "Ep 0: Batch #53 - Loss: 0.8865763545036316\n",
      "Ep 0: Batch #54 - Loss: 0.7615788578987122\n",
      "Ep 0: Batch #55 - Loss: 0.8183192014694214\n",
      "Ep 0: Batch #56 - Loss: 1.3527690172195435\n",
      "Ep 0: Batch #57 - Loss: 0.9299110770225525\n",
      "Ep 0: Batch #58 - Loss: 1.0824172496795654\n",
      "Ep 0: Batch #59 - Loss: 0.734566867351532\n",
      "Ep 0: Batch #60 - Loss: 1.398574948310852\n",
      "Ep 0: Batch #61 - Loss: 0.6950847506523132\n",
      "Ep 0: Batch #62 - Loss: 0.7872022986412048\n",
      "Ep 0: Batch #63 - Loss: 1.0855201482772827\n",
      "Ep 0: Batch #64 - Loss: 9.489740371704102\n",
      "Ep 0: Batch #65 - Loss: 0.6609061360359192\n",
      "Model saved in file: ./weights_autoencoder_low_LR/model_e0b65_1516651268.491854.ckpt\n",
      "Ep 0: Batch #66 - Loss: 0.8728954792022705\n",
      "Ep 0: Batch #67 - Loss: 0.9772446751594543\n",
      "Ep 0: Batch #68 - Loss: 0.9771376252174377\n",
      "Ep 0: Batch #69 - Loss: 0.8102265000343323\n",
      "Ep 0: Batch #70 - Loss: 0.8557313084602356\n",
      "Ep 0: Batch #71 - Loss: 0.7373054623603821\n",
      "Ep 0: Batch #72 - Loss: 0.9206050038337708\n",
      "Ep 0: Batch #73 - Loss: 0.9767455458641052\n",
      "Ep 0: Batch #74 - Loss: 0.8002758026123047\n",
      "Ep 0: Batch #75 - Loss: 0.8237160444259644\n",
      "Ep 0: Batch #76 - Loss: 1.1548962593078613\n",
      "Ep 0: Batch #77 - Loss: 0.7990220189094543\n",
      "Ep 0: Batch #78 - Loss: 1.2444469928741455\n",
      "Ep 0: Batch #79 - Loss: 0.6862361431121826\n",
      "Ep 0: Batch #80 - Loss: 0.9352652430534363\n",
      "Ep 0: Batch #81 - Loss: 1.7415958642959595\n",
      "Ep 0: Batch #82 - Loss: 0.942126989364624\n",
      "Ep 0: Batch #83 - Loss: 1.7943775653839111\n",
      "Ep 0: Batch #84 - Loss: 0.775431752204895\n",
      "Ep 0: Batch #85 - Loss: 1.0381481647491455\n",
      "Ep 0: Batch #86 - Loss: 0.7740809321403503\n",
      "Ep 0: Batch #87 - Loss: 0.7776841521263123\n",
      "Ep 0: Batch #88 - Loss: 0.8707790374755859\n",
      "Ep 0: Batch #89 - Loss: 0.9310190677642822\n",
      "Ep 0: Batch #90 - Loss: 1.24347984790802\n",
      "Ep 0: Batch #91 - Loss: 0.8721151351928711\n",
      "Ep 0: Batch #92 - Loss: 1.10608971118927\n",
      "Ep 0: Batch #93 - Loss: 1.1182175874710083\n",
      "Ep 0: Batch #94 - Loss: 1.125887155532837\n",
      "Ep 0: Batch #95 - Loss: 0.9931615591049194\n",
      "Ep 0: Batch #96 - Loss: 0.9682973027229309\n",
      "Ep 0: Batch #97 - Loss: 0.790657103061676\n",
      "Ep 0: Batch #98 - Loss: 0.8045549392700195\n",
      "Ep 0: Batch #99 - Loss: 1.0206962823867798\n",
      "Ep 0: Batch #100 - Loss: 0.7378241419792175\n",
      "Ep 0: Batch #101 - Loss: 1.1159381866455078\n",
      "Ep 0: Batch #102 - Loss: 0.8412967920303345\n",
      "Ep 0: Batch #103 - Loss: 0.8428925275802612\n",
      "Ep 0: Batch #104 - Loss: 0.8670773506164551\n",
      "Ep 0: Batch #105 - Loss: 1.0989142656326294\n",
      "Ep 0: Batch #106 - Loss: 0.8138896822929382\n",
      "Ep 0: Batch #107 - Loss: 0.828822910785675\n",
      "Ep 0: Batch #108 - Loss: 1.1099579334259033\n",
      "Ep 0: Batch #109 - Loss: 0.8184451460838318\n",
      "Ep 0: Batch #110 - Loss: 0.9936543703079224\n",
      "Ep 0: Batch #111 - Loss: 1.4540064334869385\n",
      "Ep 0: Batch #112 - Loss: 1.1324094533920288\n",
      "Ep 0: Batch #113 - Loss: 0.8819734454154968\n",
      "Ep 0: Batch #114 - Loss: 0.9715973138809204\n",
      "Ep 0: Batch #115 - Loss: 1.164810299873352\n",
      "Ep 0: Batch #116 - Loss: 0.67900550365448\n",
      "Ep 0: Batch #117 - Loss: 0.9354355335235596\n",
      "Ep 0: Batch #118 - Loss: 0.6020459532737732\n",
      "Model saved in file: ./weights_autoencoder_low_LR/model_e0b118_1516651268.5422149.ckpt\n",
      "Ep 0: Batch #119 - Loss: 1.0997021198272705\n",
      "Ep 0: Batch #120 - Loss: 0.8495009541511536\n",
      "Ep 0: Batch #121 - Loss: 0.7459628582000732\n",
      "Ep 0: Batch #122 - Loss: 0.8933538794517517\n",
      "Ep 0: Batch #123 - Loss: 0.8936365246772766\n",
      "Ep 0: Batch #124 - Loss: 0.7151341438293457\n",
      "Ep 0: Batch #125 - Loss: 2.7989258766174316\n",
      "Ep 0: Batch #126 - Loss: 1.3043699264526367\n",
      "Ep 0: Batch #127 - Loss: 0.8215823173522949\n",
      "Ep 0: Batch #128 - Loss: 1.191260576248169\n",
      "Ep 0: Batch #129 - Loss: 0.9058747887611389\n",
      "Ep 0: Batch #130 - Loss: 0.7891222834587097\n",
      "Ep 0: Batch #131 - Loss: 1.0850991010665894\n",
      "Ep 0: Batch #132 - Loss: 0.8930646181106567\n",
      "Ep 0: Batch #133 - Loss: 0.8838402628898621\n",
      "Ep 0: Batch #134 - Loss: 0.8293157815933228\n",
      "Ep 0: Batch #135 - Loss: 1.0408416986465454\n",
      "Ep 0: Batch #136 - Loss: 1.2599059343338013\n",
      "Ep 0: Batch #137 - Loss: 1.0383074283599854\n",
      "Ep 0: Batch #138 - Loss: 1.1384867429733276\n",
      "Ep 0: Batch #139 - Loss: 0.9720914959907532\n",
      "Ep 0: Batch #140 - Loss: 1.118378758430481\n",
      "Ep 0: Batch #141 - Loss: 1.4320958852767944\n",
      "Ep 0: Batch #142 - Loss: 0.8519368767738342\n",
      "Ep 0: Batch #143 - Loss: 1.0501304864883423\n",
      "Ep 0: Batch #144 - Loss: 0.7847695350646973\n",
      "Ep 0: Batch #145 - Loss: 0.7329068779945374\n",
      "Ep 0: Batch #146 - Loss: 0.9436154961585999\n",
      "Ep 0: Batch #147 - Loss: 0.935786783695221\n",
      "Ep 0: Batch #148 - Loss: 1.0499635934829712\n",
      "Ep 0: Batch #149 - Loss: 0.9268428683280945\n",
      "Ep 0: Batch #150 - Loss: 0.9386319518089294\n",
      "Ep 0: Batch #151 - Loss: 0.774154007434845\n",
      "Ep 0: Batch #152 - Loss: 0.7922298908233643\n",
      "Ep 0: Batch #153 - Loss: 1.1844279766082764\n",
      "Ep 0: Batch #154 - Loss: 0.8153343796730042\n",
      "Ep 0: Batch #155 - Loss: 0.9056854844093323\n",
      "Ep 0: Batch #156 - Loss: 1.0868558883666992\n",
      "Ep 0: Batch #157 - Loss: 0.8197006583213806\n",
      "Ep 0: Batch #158 - Loss: 0.8636876344680786\n",
      "Ep 0: Batch #159 - Loss: 0.8736507892608643\n",
      "Ep 0: Batch #160 - Loss: 0.9591264724731445\n",
      "Ep 0: Batch #161 - Loss: 0.879045307636261\n",
      "Ep 0: Batch #162 - Loss: 1.001037836074829\n",
      "Ep 0: Batch #163 - Loss: 0.9870007038116455\n",
      "Ep 0: Batch #164 - Loss: 0.8419591188430786\n",
      "Ep 0: Batch #165 - Loss: 1.560583472251892\n",
      "Ep 0: Batch #166 - Loss: 0.7428074479103088\n",
      "Ep 0: Batch #167 - Loss: 1.1545504331588745\n",
      "Ep 0: Batch #168 - Loss: 0.9270147085189819\n",
      "Ep 0: Batch #169 - Loss: 0.863152027130127\n",
      "Ep 0: Batch #170 - Loss: 0.8652936220169067\n",
      "Ep 0: Batch #171 - Loss: 0.8516430854797363\n",
      "Ep 0: Batch #172 - Loss: 0.6816812753677368\n",
      "Ep 0: Batch #173 - Loss: 1.2845885753631592\n",
      "Ep 0: Batch #174 - Loss: 0.6334330439567566\n",
      "Ep 0: Batch #175 - Loss: 0.8340100646018982\n",
      "Ep 0: Batch #176 - Loss: 1.2210773229599\n",
      "Ep 0: Batch #177 - Loss: 0.9105721712112427\n",
      "Ep 0: Batch #178 - Loss: 0.8289576768875122\n",
      "Ep 0: Batch #179 - Loss: 1.0144720077514648\n",
      "Ep 0: Batch #180 - Loss: 0.9333223700523376\n",
      "Ep 0: Batch #181 - Loss: 1.0745298862457275\n",
      "Ep 0: Batch #182 - Loss: 0.8225820064544678\n",
      "Ep 0: Batch #183 - Loss: 0.8266698718070984\n",
      "Ep 0: Batch #184 - Loss: 1.1289070844650269\n",
      "Ep 0: Batch #185 - Loss: 0.8137219548225403\n",
      "Ep 0: Batch #186 - Loss: 1.045549750328064\n",
      "Ep 0: Batch #187 - Loss: 1.2392245531082153\n",
      "Ep 0: Batch #188 - Loss: 1.4213088750839233\n",
      "Ep 0: Batch #189 - Loss: 0.7475340366363525\n",
      "Ep 0: Batch #190 - Loss: 0.7976387739181519\n",
      "Ep 0: Batch #191 - Loss: 1.134008765220642\n",
      "Ep 0: Batch #192 - Loss: 0.7184364199638367\n",
      "Ep 0: Batch #193 - Loss: 0.8048069477081299\n",
      "Ep 0: Batch #194 - Loss: 0.7550016045570374\n",
      "Ep 0: Batch #195 - Loss: 1.0473484992980957\n",
      "Ep 0: Batch #196 - Loss: 0.9320669770240784\n",
      "Ep 0: Batch #197 - Loss: 0.9725383520126343\n",
      "Ep 0: Batch #198 - Loss: 0.7360881567001343\n",
      "Ep 0: Batch #199 - Loss: 0.9296124577522278\n",
      "Ep 1: Batch #0 - Loss: 0.8604811429977417\n",
      "Ep 1: Batch #1 - Loss: 0.9462391138076782\n",
      "Ep 1: Batch #2 - Loss: 1.0615715980529785\n",
      "Ep 1: Batch #3 - Loss: 0.9322178959846497\n",
      "Ep 1: Batch #4 - Loss: 0.855833888053894\n",
      "Ep 1: Batch #5 - Loss: 0.7191585898399353\n",
      "Ep 1: Batch #6 - Loss: 0.9508499503135681\n",
      "Ep 1: Batch #7 - Loss: 0.7572059035301208\n",
      "Ep 1: Batch #8 - Loss: 0.7917078137397766\n",
      "Ep 1: Batch #9 - Loss: 1.4901877641677856\n",
      "Ep 1: Batch #10 - Loss: 1.0786936283111572\n",
      "Ep 1: Batch #11 - Loss: 0.7328646183013916\n",
      "Ep 1: Batch #12 - Loss: 1.630630612373352\n",
      "Ep 1: Batch #13 - Loss: 0.6887969374656677\n",
      "Ep 1: Batch #14 - Loss: 0.7805702090263367\n",
      "Ep 1: Batch #15 - Loss: 1.3215382099151611\n",
      "Ep 1: Batch #16 - Loss: 1.369071125984192\n",
      "Ep 1: Batch #17 - Loss: 0.944441020488739\n",
      "Ep 1: Batch #18 - Loss: 0.9907613396644592\n",
      "Ep 1: Batch #19 - Loss: 0.71882164478302\n",
      "Ep 1: Batch #20 - Loss: 0.7117375135421753\n",
      "Ep 1: Batch #21 - Loss: 1.2783234119415283\n",
      "Ep 1: Batch #22 - Loss: 0.7800148129463196\n",
      "Ep 1: Batch #23 - Loss: 0.8111684322357178\n",
      "Ep 1: Batch #24 - Loss: 0.884152352809906\n",
      "Ep 1: Batch #25 - Loss: 0.7810348272323608\n",
      "Ep 1: Batch #26 - Loss: 0.792628824710846\n",
      "Ep 1: Batch #27 - Loss: 1.4276421070098877\n",
      "Ep 1: Batch #28 - Loss: 0.9308677911758423\n",
      "Ep 1: Batch #29 - Loss: 0.9666197299957275\n",
      "Ep 1: Batch #30 - Loss: 1.2796955108642578\n",
      "Ep 1: Batch #31 - Loss: 0.7194899916648865\n",
      "Ep 1: Batch #32 - Loss: 0.8092884421348572\n",
      "Ep 1: Batch #33 - Loss: 0.8648139834403992\n",
      "Ep 1: Batch #34 - Loss: 0.8427006602287292\n",
      "Ep 1: Batch #35 - Loss: 1.0268652439117432\n",
      "Ep 1: Batch #36 - Loss: 0.7584779262542725\n",
      "Ep 1: Batch #37 - Loss: 1.2047680616378784\n",
      "Ep 1: Batch #38 - Loss: 0.8130723834037781\n",
      "Ep 1: Batch #39 - Loss: 0.8689516186714172\n",
      "Ep 1: Batch #40 - Loss: 0.8411830067634583\n",
      "Ep 1: Batch #41 - Loss: 0.7949657440185547\n",
      "Ep 1: Batch #42 - Loss: 0.7745959162712097\n",
      "Ep 1: Batch #43 - Loss: 0.848487138748169\n",
      "Ep 1: Batch #44 - Loss: 0.8437942862510681\n",
      "Ep 1: Batch #45 - Loss: 0.6983939409255981\n",
      "Ep 1: Batch #46 - Loss: 0.8974336981773376\n",
      "Ep 1: Batch #47 - Loss: 1.0414807796478271\n",
      "Ep 1: Batch #48 - Loss: 1.4439427852630615\n",
      "Ep 1: Batch #49 - Loss: 1.0816017389297485\n",
      "Ep 1: Batch #50 - Loss: 0.7543096542358398\n",
      "Ep 1: Batch #51 - Loss: 1.0703598260879517\n",
      "Ep 1: Batch #52 - Loss: 0.8454045653343201\n",
      "Ep 1: Batch #53 - Loss: 0.884607195854187\n",
      "Ep 1: Batch #54 - Loss: 0.7598320841789246\n",
      "Ep 1: Batch #55 - Loss: 0.8170523643493652\n",
      "Ep 1: Batch #56 - Loss: 1.3504854440689087\n",
      "Ep 1: Batch #57 - Loss: 0.9279698729515076\n",
      "Ep 1: Batch #58 - Loss: 1.0805020332336426\n",
      "Ep 1: Batch #59 - Loss: 0.733144223690033\n",
      "Ep 1: Batch #60 - Loss: 1.397043228149414\n",
      "Ep 1: Batch #61 - Loss: 0.69333416223526\n",
      "Ep 1: Batch #62 - Loss: 0.7858183979988098\n",
      "Ep 1: Batch #63 - Loss: 1.0838710069656372\n",
      "Ep 1: Batch #64 - Loss: 9.48829174041748\n",
      "Ep 1: Batch #65 - Loss: 0.6595480442047119\n",
      "Ep 1: Batch #66 - Loss: 0.8714253306388855\n",
      "Ep 1: Batch #67 - Loss: 0.9756499528884888\n",
      "Ep 1: Batch #68 - Loss: 0.9755793213844299\n",
      "Ep 1: Batch #69 - Loss: 0.8086101412773132\n",
      "Ep 1: Batch #70 - Loss: 0.854221761226654\n",
      "Ep 1: Batch #71 - Loss: 0.7357231378555298\n",
      "Ep 1: Batch #72 - Loss: 0.9191502332687378\n",
      "Ep 1: Batch #73 - Loss: 0.975604236125946\n",
      "Ep 1: Batch #74 - Loss: 0.79889315366745\n",
      "Ep 1: Batch #75 - Loss: 0.8223845362663269\n",
      "Ep 1: Batch #76 - Loss: 1.1533912420272827\n",
      "Ep 1: Batch #77 - Loss: 0.7971356511116028\n",
      "Ep 1: Batch #78 - Loss: 1.2425682544708252\n",
      "Ep 1: Batch #79 - Loss: 0.6847516894340515\n",
      "Ep 1: Batch #80 - Loss: 0.933488667011261\n",
      "Ep 1: Batch #81 - Loss: 1.74013352394104\n",
      "Ep 1: Batch #82 - Loss: 0.9404267072677612\n",
      "Ep 1: Batch #83 - Loss: 1.792921781539917\n",
      "Ep 1: Batch #84 - Loss: 0.7742865681648254\n",
      "Ep 1: Batch #85 - Loss: 1.0367388725280762\n",
      "Ep 1: Batch #86 - Loss: 0.77276211977005\n",
      "Ep 1: Batch #87 - Loss: 0.7757423520088196\n",
      "Ep 1: Batch #88 - Loss: 0.869281530380249\n",
      "Ep 1: Batch #89 - Loss: 0.9295759797096252\n",
      "Ep 1: Batch #90 - Loss: 1.242343783378601\n",
      "Ep 1: Batch #91 - Loss: 0.8705301284790039\n",
      "Ep 1: Batch #92 - Loss: 1.1046299934387207\n",
      "Ep 1: Batch #93 - Loss: 1.1164889335632324\n",
      "Ep 1: Batch #94 - Loss: 1.1239895820617676\n",
      "Ep 1: Batch #95 - Loss: 0.9916638731956482\n",
      "Ep 1: Batch #96 - Loss: 0.9670441150665283\n",
      "Ep 1: Batch #97 - Loss: 0.7893787026405334\n",
      "Ep 1: Batch #98 - Loss: 0.8029241561889648\n",
      "Ep 1: Batch #99 - Loss: 1.0191642045974731\n",
      "Ep 1: Batch #100 - Loss: 0.7365764379501343\n",
      "Ep 1: Batch #101 - Loss: 1.1145309209823608\n",
      "Ep 1: Batch #102 - Loss: 0.8397826552391052\n",
      "Ep 1: Batch #103 - Loss: 0.841740071773529\n",
      "Ep 1: Batch #104 - Loss: 0.865484356880188\n",
      "Ep 1: Batch #105 - Loss: 1.097381591796875\n",
      "Ep 1: Batch #106 - Loss: 0.812799870967865\n",
      "Ep 1: Batch #107 - Loss: 0.8271465301513672\n",
      "Ep 1: Batch #108 - Loss: 1.1085549592971802\n",
      "Ep 1: Batch #109 - Loss: 0.8168726563453674\n",
      "Ep 1: Batch #110 - Loss: 0.9921965003013611\n",
      "Ep 1: Batch #111 - Loss: 1.4525072574615479\n",
      "Ep 1: Batch #112 - Loss: 1.130932331085205\n",
      "Ep 1: Batch #113 - Loss: 0.8805264234542847\n",
      "Ep 1: Batch #114 - Loss: 0.970012903213501\n",
      "Ep 1: Batch #115 - Loss: 1.1631399393081665\n",
      "Ep 1: Batch #116 - Loss: 0.6775798797607422\n",
      "Ep 1: Batch #117 - Loss: 0.9337950348854065\n",
      "Ep 1: Batch #118 - Loss: 0.6006641983985901\n",
      "Model saved in file: ./weights_autoencoder_low_LR/model_e1b118_1516651268.6840763.ckpt\n",
      "Ep 1: Batch #119 - Loss: 1.0974665880203247\n",
      "Ep 1: Batch #120 - Loss: 0.8482134342193604\n",
      "Ep 1: Batch #121 - Loss: 0.744545578956604\n",
      "Ep 1: Batch #122 - Loss: 0.8917402625083923\n",
      "Ep 1: Batch #123 - Loss: 0.8918018341064453\n",
      "Ep 1: Batch #124 - Loss: 0.7133892178535461\n",
      "Ep 1: Batch #125 - Loss: 2.7974116802215576\n",
      "Ep 1: Batch #126 - Loss: 1.3027626276016235\n",
      "Ep 1: Batch #127 - Loss: 0.8201825022697449\n",
      "Ep 1: Batch #128 - Loss: 1.190110683441162\n",
      "Ep 1: Batch #129 - Loss: 0.9046449065208435\n",
      "Ep 1: Batch #130 - Loss: 0.7876954674720764\n",
      "Ep 1: Batch #131 - Loss: 1.0833005905151367\n",
      "Ep 1: Batch #132 - Loss: 0.8916774988174438\n",
      "Ep 1: Batch #133 - Loss: 0.8822041749954224\n",
      "Ep 1: Batch #134 - Loss: 0.8280833959579468\n",
      "Ep 1: Batch #135 - Loss: 1.03946053981781\n",
      "Ep 1: Batch #136 - Loss: 1.2587010860443115\n",
      "Ep 1: Batch #137 - Loss: 1.0366204977035522\n",
      "Ep 1: Batch #138 - Loss: 1.137025237083435\n",
      "Ep 1: Batch #139 - Loss: 0.9707869291305542\n",
      "Ep 1: Batch #140 - Loss: 1.1167765855789185\n",
      "Ep 1: Batch #141 - Loss: 1.4297256469726562\n",
      "Ep 1: Batch #142 - Loss: 0.8503934741020203\n",
      "Ep 1: Batch #143 - Loss: 1.048304557800293\n",
      "Ep 1: Batch #144 - Loss: 0.7833459973335266\n",
      "Ep 1: Batch #145 - Loss: 0.731383740901947\n",
      "Ep 1: Batch #146 - Loss: 0.9420763254165649\n",
      "Ep 1: Batch #147 - Loss: 0.9345936179161072\n",
      "Ep 1: Batch #148 - Loss: 1.0482635498046875\n",
      "Ep 1: Batch #149 - Loss: 0.9253593683242798\n",
      "Ep 1: Batch #150 - Loss: 0.9372134804725647\n",
      "Ep 1: Batch #151 - Loss: 0.7727916836738586\n",
      "Ep 1: Batch #152 - Loss: 0.7906827926635742\n",
      "Ep 1: Batch #153 - Loss: 1.1825305223464966\n",
      "Ep 1: Batch #154 - Loss: 0.8140608668327332\n",
      "Ep 1: Batch #155 - Loss: 0.9040248394012451\n",
      "Ep 1: Batch #156 - Loss: 1.0855357646942139\n",
      "Ep 1: Batch #157 - Loss: 0.8182463645935059\n",
      "Ep 1: Batch #158 - Loss: 0.8618499636650085\n",
      "Ep 1: Batch #159 - Loss: 0.8720017671585083\n",
      "Ep 1: Batch #160 - Loss: 0.9578121304512024\n",
      "Ep 1: Batch #161 - Loss: 0.8776152729988098\n",
      "Ep 1: Batch #162 - Loss: 0.9993427395820618\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 1: Batch #163 - Loss: 0.9854888916015625\n",
      "Ep 1: Batch #164 - Loss: 0.8406349420547485\n",
      "Ep 1: Batch #165 - Loss: 1.5592222213745117\n",
      "Ep 1: Batch #166 - Loss: 0.7415074706077576\n",
      "Ep 1: Batch #167 - Loss: 1.1531727313995361\n",
      "Ep 1: Batch #168 - Loss: 0.9256900548934937\n",
      "Ep 1: Batch #169 - Loss: 0.8617210984230042\n",
      "Ep 1: Batch #170 - Loss: 0.8638564944267273\n",
      "Ep 1: Batch #171 - Loss: 0.8499883413314819\n",
      "Ep 1: Batch #172 - Loss: 0.6803367733955383\n",
      "Ep 1: Batch #173 - Loss: 1.2827649116516113\n",
      "Ep 1: Batch #174 - Loss: 0.6320725679397583\n",
      "Ep 1: Batch #175 - Loss: 0.8325157761573792\n",
      "Ep 1: Batch #176 - Loss: 1.2196907997131348\n",
      "Ep 1: Batch #177 - Loss: 0.9093984961509705\n",
      "Ep 1: Batch #178 - Loss: 0.8276426196098328\n",
      "Ep 1: Batch #179 - Loss: 1.013136625289917\n",
      "Ep 1: Batch #180 - Loss: 0.9317285418510437\n",
      "Ep 1: Batch #181 - Loss: 1.0726593732833862\n",
      "Ep 1: Batch #182 - Loss: 0.8210064172744751\n",
      "Ep 1: Batch #183 - Loss: 0.8252896070480347\n",
      "Ep 1: Batch #184 - Loss: 1.127348780632019\n",
      "Ep 1: Batch #185 - Loss: 0.8123639822006226\n",
      "Ep 1: Batch #186 - Loss: 1.0438326597213745\n",
      "Ep 1: Batch #187 - Loss: 1.2376195192337036\n",
      "Ep 1: Batch #188 - Loss: 1.4196884632110596\n",
      "Ep 1: Batch #189 - Loss: 0.7461246252059937\n",
      "Ep 1: Batch #190 - Loss: 0.7960366010665894\n",
      "Ep 1: Batch #191 - Loss: 1.1314984560012817\n",
      "Ep 1: Batch #192 - Loss: 0.7169812917709351\n",
      "Ep 1: Batch #193 - Loss: 0.8034354448318481\n",
      "Ep 1: Batch #194 - Loss: 0.7536266446113586\n",
      "Ep 1: Batch #195 - Loss: 1.0460419654846191\n",
      "Ep 1: Batch #196 - Loss: 0.9299294352531433\n",
      "Ep 1: Batch #197 - Loss: 0.9701562523841858\n",
      "Ep 1: Batch #198 - Loss: 0.7348175048828125\n",
      "Ep 1: Batch #199 - Loss: 0.9279652833938599\n",
      "Ep 2: Batch #0 - Loss: 0.8593100905418396\n",
      "Ep 2: Batch #1 - Loss: 0.944645345211029\n",
      "Ep 2: Batch #2 - Loss: 1.060215711593628\n",
      "Ep 2: Batch #3 - Loss: 0.9303502440452576\n",
      "Ep 2: Batch #4 - Loss: 0.8542861938476562\n",
      "Ep 2: Batch #5 - Loss: 0.7176902890205383\n",
      "Ep 2: Batch #6 - Loss: 0.948867678642273\n",
      "Ep 2: Batch #7 - Loss: 0.7557046413421631\n",
      "Ep 2: Batch #8 - Loss: 0.7901776432991028\n",
      "Ep 2: Batch #9 - Loss: 1.4876524209976196\n",
      "Ep 2: Batch #10 - Loss: 1.0772253274917603\n",
      "Ep 2: Batch #11 - Loss: 0.7309631109237671\n",
      "Ep 2: Batch #12 - Loss: 1.6285959482192993\n",
      "Ep 2: Batch #13 - Loss: 0.6876196265220642\n",
      "Ep 2: Batch #14 - Loss: 0.779026210308075\n",
      "Ep 2: Batch #15 - Loss: 1.3200600147247314\n",
      "Ep 2: Batch #16 - Loss: 1.3670920133590698\n",
      "Ep 2: Batch #17 - Loss: 0.9431546926498413\n",
      "Ep 2: Batch #18 - Loss: 0.9891651272773743\n",
      "Ep 2: Batch #19 - Loss: 0.717146635055542\n",
      "Ep 2: Batch #20 - Loss: 0.710198163986206\n",
      "Ep 2: Batch #21 - Loss: 1.2769092321395874\n",
      "Ep 2: Batch #22 - Loss: 0.7784549593925476\n",
      "Ep 2: Batch #23 - Loss: 0.8096676468849182\n",
      "Ep 2: Batch #24 - Loss: 0.8823130130767822\n",
      "Ep 2: Batch #25 - Loss: 0.7795050740242004\n",
      "Ep 2: Batch #26 - Loss: 0.7914740443229675\n",
      "Ep 2: Batch #27 - Loss: 1.425397276878357\n",
      "Ep 2: Batch #28 - Loss: 0.9294291734695435\n",
      "Ep 2: Batch #29 - Loss: 0.9650915861129761\n",
      "Ep 2: Batch #30 - Loss: 1.2783023118972778\n",
      "Ep 2: Batch #31 - Loss: 0.7181974649429321\n",
      "Ep 2: Batch #32 - Loss: 0.8077847957611084\n",
      "Ep 2: Batch #33 - Loss: 0.8634921312332153\n",
      "Ep 2: Batch #34 - Loss: 0.8414749503135681\n",
      "Ep 2: Batch #35 - Loss: 1.0253304243087769\n",
      "Ep 2: Batch #36 - Loss: 0.7568328380584717\n",
      "Ep 2: Batch #37 - Loss: 1.2033940553665161\n",
      "Ep 2: Batch #38 - Loss: 0.8118957281112671\n",
      "Ep 2: Batch #39 - Loss: 0.8676091432571411\n",
      "Ep 2: Batch #40 - Loss: 0.8395046591758728\n",
      "Ep 2: Batch #41 - Loss: 0.7936784625053406\n",
      "Ep 2: Batch #42 - Loss: 0.7731455564498901\n",
      "Ep 2: Batch #43 - Loss: 0.846961259841919\n",
      "Ep 2: Batch #44 - Loss: 0.8423716425895691\n",
      "Ep 2: Batch #45 - Loss: 0.6970908641815186\n",
      "Ep 2: Batch #46 - Loss: 0.8959125876426697\n",
      "Ep 2: Batch #47 - Loss: 1.039794921875\n",
      "Ep 2: Batch #48 - Loss: 1.4418821334838867\n",
      "Ep 2: Batch #49 - Loss: 1.0800365209579468\n",
      "Ep 2: Batch #50 - Loss: 0.7527286410331726\n",
      "Ep 2: Batch #51 - Loss: 1.0688791275024414\n",
      "Ep 2: Batch #52 - Loss: 0.8438894152641296\n",
      "Ep 2: Batch #53 - Loss: 0.8826863169670105\n",
      "Ep 2: Batch #54 - Loss: 0.7581669092178345\n",
      "Ep 2: Batch #55 - Loss: 0.815798282623291\n",
      "Ep 2: Batch #56 - Loss: 1.3477933406829834\n",
      "Ep 2: Batch #57 - Loss: 0.9260457754135132\n",
      "Ep 2: Batch #58 - Loss: 1.0785256624221802\n",
      "Ep 2: Batch #59 - Loss: 0.7317874431610107\n",
      "Ep 2: Batch #60 - Loss: 1.3954468965530396\n",
      "Ep 2: Batch #61 - Loss: 0.6915890574455261\n",
      "Ep 2: Batch #62 - Loss: 0.7844657897949219\n",
      "Ep 2: Batch #63 - Loss: 1.0822137594223022\n",
      "Ep 2: Batch #64 - Loss: 9.486928939819336\n",
      "Ep 2: Batch #65 - Loss: 0.6582818031311035\n",
      "Ep 2: Batch #66 - Loss: 0.8699096441268921\n",
      "Ep 2: Batch #67 - Loss: 0.9740930795669556\n",
      "Ep 2: Batch #68 - Loss: 0.974047064781189\n",
      "Ep 2: Batch #69 - Loss: 0.8070197701454163\n",
      "Ep 2: Batch #70 - Loss: 0.8527005910873413\n",
      "Ep 2: Batch #71 - Loss: 0.734199583530426\n",
      "Ep 2: Batch #72 - Loss: 0.9177318811416626\n",
      "Ep 2: Batch #73 - Loss: 0.9744421243667603\n",
      "Ep 2: Batch #74 - Loss: 0.797556459903717\n",
      "Ep 2: Batch #75 - Loss: 0.8210896253585815\n",
      "Ep 2: Batch #76 - Loss: 1.1519652605056763\n",
      "Ep 2: Batch #77 - Loss: 0.7952895164489746\n",
      "Ep 2: Batch #78 - Loss: 1.2407180070877075\n",
      "Ep 2: Batch #79 - Loss: 0.6832939982414246\n",
      "Ep 2: Batch #80 - Loss: 0.9317244291305542\n",
      "Ep 2: Batch #81 - Loss: 1.7387645244598389\n",
      "Ep 2: Batch #82 - Loss: 0.9386376142501831\n",
      "Ep 2: Batch #83 - Loss: 1.7915130853652954\n",
      "Ep 2: Batch #84 - Loss: 0.7731327414512634\n",
      "Ep 2: Batch #85 - Loss: 1.0353578329086304\n",
      "Ep 2: Batch #86 - Loss: 0.7714861035346985\n",
      "Ep 2: Batch #87 - Loss: 0.7737814784049988\n",
      "Ep 2: Batch #88 - Loss: 0.8678042888641357\n",
      "Ep 2: Batch #89 - Loss: 0.9282243847846985\n",
      "Ep 2: Batch #90 - Loss: 1.2411887645721436\n",
      "Ep 2: Batch #91 - Loss: 0.8690114617347717\n",
      "Ep 2: Batch #92 - Loss: 1.1031413078308105\n",
      "Ep 2: Batch #93 - Loss: 1.1147147417068481\n",
      "Ep 2: Batch #94 - Loss: 1.1221204996109009\n",
      "Ep 2: Batch #95 - Loss: 0.9901801347732544\n",
      "Ep 2: Batch #96 - Loss: 0.9658496379852295\n",
      "Ep 2: Batch #97 - Loss: 0.7880709767341614\n",
      "Ep 2: Batch #98 - Loss: 0.8013026714324951\n",
      "Ep 2: Batch #99 - Loss: 1.017668604850769\n",
      "Ep 2: Batch #100 - Loss: 0.7353672981262207\n",
      "Ep 2: Batch #101 - Loss: 1.1131519079208374\n",
      "Ep 2: Batch #102 - Loss: 0.8383015394210815\n",
      "Ep 2: Batch #103 - Loss: 0.8406521677970886\n",
      "Ep 2: Batch #104 - Loss: 0.8639270663261414\n",
      "Ep 2: Batch #105 - Loss: 1.0958667993545532\n",
      "Ep 2: Batch #106 - Loss: 0.8117442727088928\n",
      "Ep 2: Batch #107 - Loss: 0.8255024552345276\n",
      "Ep 2: Batch #108 - Loss: 1.1071354150772095\n",
      "Ep 2: Batch #109 - Loss: 0.8153474926948547\n",
      "Ep 2: Batch #110 - Loss: 0.9907463788986206\n",
      "Ep 2: Batch #111 - Loss: 1.4510631561279297\n",
      "Ep 2: Batch #112 - Loss: 1.1293443441390991\n",
      "Ep 2: Batch #113 - Loss: 0.8791108727455139\n",
      "Ep 2: Batch #114 - Loss: 0.9684474468231201\n",
      "Ep 2: Batch #115 - Loss: 1.1614257097244263\n",
      "Ep 2: Batch #116 - Loss: 0.676215648651123\n",
      "Ep 2: Batch #117 - Loss: 0.9322043657302856\n",
      "Ep 2: Batch #118 - Loss: 0.5992895364761353\n",
      "Model saved in file: ./weights_autoencoder_low_LR/model_e2b118_1516651268.863236.ckpt\n",
      "Ep 2: Batch #119 - Loss: 1.0952796936035156\n",
      "Ep 2: Batch #120 - Loss: 0.8469782471656799\n",
      "Ep 2: Batch #121 - Loss: 0.7431503534317017\n",
      "Ep 2: Batch #122 - Loss: 0.8901462554931641\n",
      "Ep 2: Batch #123 - Loss: 0.8900426626205444\n",
      "Ep 2: Batch #124 - Loss: 0.7117268443107605\n",
      "Ep 2: Batch #125 - Loss: 2.795854330062866\n",
      "Ep 2: Batch #126 - Loss: 1.3010882139205933\n",
      "Ep 2: Batch #127 - Loss: 0.818766713142395\n",
      "Ep 2: Batch #128 - Loss: 1.188860535621643\n",
      "Ep 2: Batch #129 - Loss: 0.9034170508384705\n",
      "Ep 2: Batch #130 - Loss: 0.7862482666969299\n",
      "Ep 2: Batch #131 - Loss: 1.0813627243041992\n",
      "Ep 2: Batch #132 - Loss: 0.8903273344039917\n",
      "Ep 2: Batch #133 - Loss: 0.880541205406189\n",
      "Ep 2: Batch #134 - Loss: 0.8268871307373047\n",
      "Ep 2: Batch #135 - Loss: 1.038096308708191\n",
      "Ep 2: Batch #136 - Loss: 1.2574864625930786\n",
      "Ep 2: Batch #137 - Loss: 1.0349397659301758\n",
      "Ep 2: Batch #138 - Loss: 1.135582447052002\n",
      "Ep 2: Batch #139 - Loss: 0.9694921970367432\n",
      "Ep 2: Batch #140 - Loss: 1.1151891946792603\n",
      "Ep 2: Batch #141 - Loss: 1.427203893661499\n",
      "Ep 2: Batch #142 - Loss: 0.8489167094230652\n",
      "Ep 2: Batch #143 - Loss: 1.0464471578598022\n",
      "Ep 2: Batch #144 - Loss: 0.7819638252258301\n",
      "Ep 2: Batch #145 - Loss: 0.7298973798751831\n",
      "Ep 2: Batch #146 - Loss: 0.9403244853019714\n",
      "Ep 2: Batch #147 - Loss: 0.9333688020706177\n",
      "Ep 2: Batch #148 - Loss: 1.0465960502624512\n",
      "Ep 2: Batch #149 - Loss: 0.9238410592079163\n",
      "Ep 2: Batch #150 - Loss: 0.9358588457107544\n",
      "Ep 2: Batch #151 - Loss: 0.771458089351654\n",
      "Ep 2: Batch #152 - Loss: 0.7892191410064697\n",
      "Ep 2: Batch #153 - Loss: 1.180625557899475\n",
      "Ep 2: Batch #154 - Loss: 0.8128321766853333\n",
      "Ep 2: Batch #155 - Loss: 0.9023504257202148\n",
      "Ep 2: Batch #156 - Loss: 1.084274172782898\n",
      "Ep 2: Batch #157 - Loss: 0.8167858719825745\n",
      "Ep 2: Batch #158 - Loss: 0.8600322604179382\n",
      "Ep 2: Batch #159 - Loss: 0.8703951835632324\n",
      "Ep 2: Batch #160 - Loss: 0.9565334916114807\n",
      "Ep 2: Batch #161 - Loss: 0.8762046098709106\n",
      "Ep 2: Batch #162 - Loss: 0.9977186322212219\n",
      "Ep 2: Batch #163 - Loss: 0.9840630292892456\n",
      "Ep 2: Batch #164 - Loss: 0.8393439650535583\n",
      "Ep 2: Batch #165 - Loss: 1.5578805208206177\n",
      "Ep 2: Batch #166 - Loss: 0.7402422428131104\n",
      "Ep 2: Batch #167 - Loss: 1.1517820358276367\n",
      "Ep 2: Batch #168 - Loss: 0.9243930578231812\n",
      "Ep 2: Batch #169 - Loss: 0.8603258728981018\n",
      "Ep 2: Batch #170 - Loss: 0.8624333739280701\n",
      "Ep 2: Batch #171 - Loss: 0.8482893109321594\n",
      "Ep 2: Batch #172 - Loss: 0.6790691018104553\n",
      "Ep 2: Batch #173 - Loss: 1.280954122543335\n",
      "Ep 2: Batch #174 - Loss: 0.6307358145713806\n",
      "Ep 2: Batch #175 - Loss: 0.8309997320175171\n",
      "Ep 2: Batch #176 - Loss: 1.218349575996399\n",
      "Ep 2: Batch #177 - Loss: 0.9082306027412415\n",
      "Ep 2: Batch #178 - Loss: 0.8263112902641296\n",
      "Ep 2: Batch #179 - Loss: 1.0117666721343994\n",
      "Ep 2: Batch #180 - Loss: 0.9301382899284363\n",
      "Ep 2: Batch #181 - Loss: 1.070676326751709\n",
      "Ep 2: Batch #182 - Loss: 0.8194469213485718\n",
      "Ep 2: Batch #183 - Loss: 0.823930561542511\n",
      "Ep 2: Batch #184 - Loss: 1.1257697343826294\n",
      "Ep 2: Batch #185 - Loss: 0.8110376596450806\n",
      "Ep 2: Batch #186 - Loss: 1.0421538352966309\n",
      "Ep 2: Batch #187 - Loss: 1.235968828201294\n",
      "Ep 2: Batch #188 - Loss: 1.4181615114212036\n",
      "Ep 2: Batch #189 - Loss: 0.7447950839996338\n",
      "Ep 2: Batch #190 - Loss: 0.7944779396057129\n",
      "Ep 2: Batch #191 - Loss: 1.1289407014846802\n",
      "Ep 2: Batch #192 - Loss: 0.7155631184577942\n",
      "Ep 2: Batch #193 - Loss: 0.8020420670509338\n",
      "Ep 2: Batch #194 - Loss: 0.752278208732605\n",
      "Ep 2: Batch #195 - Loss: 1.0448092222213745\n",
      "Ep 2: Batch #196 - Loss: 0.9278172850608826\n",
      "Ep 2: Batch #197 - Loss: 0.9677035212516785\n",
      "Ep 2: Batch #198 - Loss: 0.733555793762207\n",
      "Ep 2: Batch #199 - Loss: 0.9263331890106201\n",
      "Ep 3: Batch #0 - Loss: 0.8581653237342834\n",
      "Ep 3: Batch #1 - Loss: 0.9430332779884338\n",
      "Ep 3: Batch #2 - Loss: 1.058880090713501\n",
      "Ep 3: Batch #3 - Loss: 0.9285183548927307\n",
      "Ep 3: Batch #4 - Loss: 0.8527514934539795\n",
      "Ep 3: Batch #5 - Loss: 0.7162455916404724\n",
      "Ep 3: Batch #6 - Loss: 0.9468467235565186\n",
      "Ep 3: Batch #7 - Loss: 0.7542535662651062\n",
      "Ep 3: Batch #8 - Loss: 0.7886619567871094\n",
      "Ep 3: Batch #9 - Loss: 1.4849977493286133\n",
      "Ep 3: Batch #10 - Loss: 1.0757715702056885\n",
      "Ep 3: Batch #11 - Loss: 0.7290578484535217\n",
      "Ep 3: Batch #12 - Loss: 1.625899076461792\n",
      "Ep 3: Batch #13 - Loss: 0.6864672899246216\n",
      "Ep 3: Batch #14 - Loss: 0.7774976491928101\n",
      "Ep 3: Batch #15 - Loss: 1.3185433149337769\n",
      "Ep 3: Batch #16 - Loss: 1.3650662899017334\n",
      "Ep 3: Batch #17 - Loss: 0.9418524503707886\n",
      "Ep 3: Batch #18 - Loss: 0.9876217842102051\n",
      "Ep 3: Batch #19 - Loss: 0.715528130531311\n",
      "Ep 3: Batch #20 - Loss: 0.7086990475654602\n",
      "Ep 3: Batch #21 - Loss: 1.2754440307617188\n",
      "Ep 3: Batch #22 - Loss: 0.7769469618797302\n",
      "Ep 3: Batch #23 - Loss: 0.8081316351890564\n",
      "Ep 3: Batch #24 - Loss: 0.8804044127464294\n",
      "Ep 3: Batch #25 - Loss: 0.7779403328895569\n",
      "Ep 3: Batch #26 - Loss: 0.7903172373771667\n",
      "Ep 3: Batch #27 - Loss: 1.4233907461166382\n",
      "Ep 3: Batch #28 - Loss: 0.9279900193214417\n",
      "Ep 3: Batch #29 - Loss: 0.9634294509887695\n",
      "Ep 3: Batch #30 - Loss: 1.2769097089767456\n",
      "Ep 3: Batch #31 - Loss: 0.7169216275215149\n",
      "Ep 3: Batch #32 - Loss: 0.8062641024589539\n",
      "Ep 3: Batch #33 - Loss: 0.8621762990951538\n",
      "Ep 3: Batch #34 - Loss: 0.840270459651947\n",
      "Ep 3: Batch #35 - Loss: 1.0237847566604614\n",
      "Ep 3: Batch #36 - Loss: 0.7552404403686523\n",
      "Ep 3: Batch #37 - Loss: 1.2020381689071655\n",
      "Ep 3: Batch #38 - Loss: 0.8106704950332642\n",
      "Ep 3: Batch #39 - Loss: 0.8662840127944946\n",
      "Ep 3: Batch #40 - Loss: 0.8378283977508545\n",
      "Ep 3: Batch #41 - Loss: 0.7923877239227295\n",
      "Ep 3: Batch #42 - Loss: 0.7717493176460266\n",
      "Ep 3: Batch #43 - Loss: 0.845410168170929\n",
      "Ep 3: Batch #44 - Loss: 0.8409568071365356\n",
      "Ep 3: Batch #45 - Loss: 0.6957264542579651\n",
      "Ep 3: Batch #46 - Loss: 0.8944054245948792\n",
      "Ep 3: Batch #47 - Loss: 1.038111925125122\n",
      "Ep 3: Batch #48 - Loss: 1.4398307800292969\n",
      "Ep 3: Batch #49 - Loss: 1.0784330368041992\n",
      "Ep 3: Batch #50 - Loss: 0.7512199878692627\n",
      "Ep 3: Batch #51 - Loss: 1.0673630237579346\n",
      "Ep 3: Batch #52 - Loss: 0.8424062728881836\n",
      "Ep 3: Batch #53 - Loss: 0.8808172941207886\n",
      "Ep 3: Batch #54 - Loss: 0.7565606236457825\n",
      "Ep 3: Batch #55 - Loss: 0.8145170211791992\n",
      "Ep 3: Batch #56 - Loss: 1.3445854187011719\n",
      "Ep 3: Batch #57 - Loss: 0.9240845441818237\n",
      "Ep 3: Batch #58 - Loss: 1.0764461755752563\n",
      "Ep 3: Batch #59 - Loss: 0.7304278612136841\n",
      "Ep 3: Batch #60 - Loss: 1.3937504291534424\n",
      "Ep 3: Batch #61 - Loss: 0.6898627877235413\n",
      "Ep 3: Batch #62 - Loss: 0.7831081748008728\n",
      "Ep 3: Batch #63 - Loss: 1.0804885625839233\n",
      "Ep 3: Batch #64 - Loss: 9.485621452331543\n",
      "Ep 3: Batch #65 - Loss: 0.6570276021957397\n",
      "Ep 3: Batch #66 - Loss: 0.8682965040206909\n",
      "Ep 3: Batch #67 - Loss: 0.9725396633148193\n",
      "Ep 3: Batch #68 - Loss: 0.9725363850593567\n",
      "Ep 3: Batch #69 - Loss: 0.8054132461547852\n",
      "Ep 3: Batch #70 - Loss: 0.8511483073234558\n",
      "Ep 3: Batch #71 - Loss: 0.7327151298522949\n",
      "Ep 3: Batch #72 - Loss: 0.9163147211074829\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 3: Batch #73 - Loss: 0.9732322096824646\n",
      "Ep 3: Batch #74 - Loss: 0.7962724566459656\n",
      "Ep 3: Batch #75 - Loss: 0.819796085357666\n",
      "Ep 3: Batch #76 - Loss: 1.15058434009552\n",
      "Ep 3: Batch #77 - Loss: 0.7934693098068237\n",
      "Ep 3: Batch #78 - Loss: 1.2388843297958374\n",
      "Ep 3: Batch #79 - Loss: 0.681832492351532\n",
      "Ep 3: Batch #80 - Loss: 0.9299426674842834\n",
      "Ep 3: Batch #81 - Loss: 1.7374831438064575\n",
      "Ep 3: Batch #82 - Loss: 0.9367634654045105\n",
      "Ep 3: Batch #83 - Loss: 1.79010808467865\n",
      "Ep 3: Batch #84 - Loss: 0.7719136476516724\n",
      "Ep 3: Batch #85 - Loss: 1.0339300632476807\n",
      "Ep 3: Batch #86 - Loss: 0.7702063322067261\n",
      "Ep 3: Batch #87 - Loss: 0.7717743515968323\n",
      "Ep 3: Batch #88 - Loss: 0.8662821054458618\n",
      "Ep 3: Batch #89 - Loss: 0.9269343018531799\n",
      "Ep 3: Batch #90 - Loss: 1.2398971319198608\n",
      "Ep 3: Batch #91 - Loss: 0.8675117492675781\n",
      "Ep 3: Batch #92 - Loss: 1.101591944694519\n",
      "Ep 3: Batch #93 - Loss: 1.1128926277160645\n",
      "Ep 3: Batch #94 - Loss: 1.1202465295791626\n",
      "Ep 3: Batch #95 - Loss: 0.988666296005249\n",
      "Ep 3: Batch #96 - Loss: 0.9646165370941162\n",
      "Ep 3: Batch #97 - Loss: 0.7867467999458313\n",
      "Ep 3: Batch #98 - Loss: 0.799695611000061\n",
      "Ep 3: Batch #99 - Loss: 1.0161852836608887\n",
      "Ep 3: Batch #100 - Loss: 0.7341511845588684\n",
      "Ep 3: Batch #101 - Loss: 1.1117606163024902\n",
      "Ep 3: Batch #102 - Loss: 0.8368564248085022\n",
      "Ep 3: Batch #103 - Loss: 0.8395827412605286\n",
      "Ep 3: Batch #104 - Loss: 0.8623639345169067\n",
      "Ep 3: Batch #105 - Loss: 1.094327688217163\n",
      "Ep 3: Batch #106 - Loss: 0.8106667399406433\n",
      "Ep 3: Batch #107 - Loss: 0.8238070011138916\n",
      "Ep 3: Batch #108 - Loss: 1.1056735515594482\n",
      "Ep 3: Batch #109 - Loss: 0.8138607144355774\n",
      "Ep 3: Batch #110 - Loss: 0.9892847537994385\n",
      "Ep 3: Batch #111 - Loss: 1.4496012926101685\n",
      "Ep 3: Batch #112 - Loss: 1.1276251077651978\n",
      "Ep 3: Batch #113 - Loss: 0.8776923418045044\n",
      "Ep 3: Batch #114 - Loss: 0.9668285846710205\n",
      "Ep 3: Batch #115 - Loss: 1.1596225500106812\n",
      "Ep 3: Batch #116 - Loss: 0.6748657822608948\n",
      "Ep 3: Batch #117 - Loss: 0.930615246295929\n",
      "Ep 3: Batch #118 - Loss: 0.5979012846946716\n",
      "Model saved in file: ./weights_autoencoder_low_LR/model_e3b118_1516651268.999879.ckpt\n",
      "Ep 3: Batch #119 - Loss: 1.0931062698364258\n",
      "Ep 3: Batch #120 - Loss: 0.8457648754119873\n",
      "Ep 3: Batch #121 - Loss: 0.7417463660240173\n",
      "Ep 3: Batch #122 - Loss: 0.8885069489479065\n",
      "Ep 3: Batch #123 - Loss: 0.88829505443573\n",
      "Ep 3: Batch #124 - Loss: 0.7101225256919861\n",
      "Ep 3: Batch #125 - Loss: 2.794233798980713\n",
      "Ep 3: Batch #126 - Loss: 1.2992479801177979\n",
      "Ep 3: Batch #127 - Loss: 0.8172878623008728\n",
      "Ep 3: Batch #128 - Loss: 1.1874383687973022\n",
      "Ep 3: Batch #129 - Loss: 0.9021787643432617\n",
      "Ep 3: Batch #130 - Loss: 0.7847532033920288\n",
      "Ep 3: Batch #131 - Loss: 1.0792399644851685\n",
      "Ep 3: Batch #132 - Loss: 0.8889214396476746\n",
      "Ep 3: Batch #133 - Loss: 0.8788242936134338\n",
      "Ep 3: Batch #134 - Loss: 0.8256832957267761\n",
      "Ep 3: Batch #135 - Loss: 1.0367281436920166\n",
      "Ep 3: Batch #136 - Loss: 1.2562105655670166\n",
      "Ep 3: Batch #137 - Loss: 1.0332207679748535\n",
      "Ep 3: Batch #138 - Loss: 1.1341029405593872\n",
      "Ep 3: Batch #139 - Loss: 0.9681794047355652\n",
      "Ep 3: Batch #140 - Loss: 1.1135880947113037\n",
      "Ep 3: Batch #141 - Loss: 1.4247158765792847\n",
      "Ep 3: Batch #142 - Loss: 0.8474491238594055\n",
      "Ep 3: Batch #143 - Loss: 1.0445560216903687\n",
      "Ep 3: Batch #144 - Loss: 0.7805606722831726\n",
      "Ep 3: Batch #145 - Loss: 0.7284339070320129\n",
      "Ep 3: Batch #146 - Loss: 0.9384521245956421\n",
      "Ep 3: Batch #147 - Loss: 0.9320626854896545\n",
      "Ep 3: Batch #148 - Loss: 1.0449341535568237\n",
      "Ep 3: Batch #149 - Loss: 0.9222575426101685\n",
      "Ep 3: Batch #150 - Loss: 0.934544563293457\n",
      "Ep 3: Batch #151 - Loss: 0.7701576948165894\n",
      "Ep 3: Batch #152 - Loss: 0.7878005504608154\n",
      "Ep 3: Batch #153 - Loss: 1.1786566972732544\n",
      "Ep 3: Batch #154 - Loss: 0.8116278648376465\n",
      "Ep 3: Batch #155 - Loss: 0.900641679763794\n",
      "Ep 3: Batch #156 - Loss: 1.0830152034759521\n",
      "Ep 3: Batch #157 - Loss: 0.8152983784675598\n",
      "Ep 3: Batch #158 - Loss: 0.8582080602645874\n",
      "Ep 3: Batch #159 - Loss: 0.8687900900840759\n",
      "Ep 3: Batch #160 - Loss: 0.9552852511405945\n",
      "Ep 3: Batch #161 - Loss: 0.8747948408126831\n",
      "Ep 3: Batch #162 - Loss: 0.9961508512496948\n",
      "Ep 3: Batch #163 - Loss: 0.9826359152793884\n",
      "Ep 3: Batch #164 - Loss: 0.8380675911903381\n",
      "Ep 3: Batch #165 - Loss: 1.5565248727798462\n",
      "Ep 3: Batch #166 - Loss: 0.7389660477638245\n",
      "Ep 3: Batch #167 - Loss: 1.1502330303192139\n",
      "Ep 3: Batch #168 - Loss: 0.9231133460998535\n",
      "Ep 3: Batch #169 - Loss: 0.8589249849319458\n",
      "Ep 3: Batch #170 - Loss: 0.8609849214553833\n",
      "Ep 3: Batch #171 - Loss: 0.8465057015419006\n",
      "Ep 3: Batch #172 - Loss: 0.67783123254776\n",
      "Ep 3: Batch #173 - Loss: 1.2790400981903076\n",
      "Ep 3: Batch #174 - Loss: 0.6293713450431824\n",
      "Ep 3: Batch #175 - Loss: 0.8295076489448547\n",
      "Ep 3: Batch #176 - Loss: 1.2170153856277466\n",
      "Ep 3: Batch #177 - Loss: 0.9070329070091248\n",
      "Ep 3: Batch #178 - Loss: 0.8249132633209229\n",
      "Ep 3: Batch #179 - Loss: 1.0102866888046265\n",
      "Ep 3: Batch #180 - Loss: 0.9285405278205872\n",
      "Ep 3: Batch #181 - Loss: 1.068575382232666\n",
      "Ep 3: Batch #182 - Loss: 0.8178666830062866\n",
      "Ep 3: Batch #183 - Loss: 0.8225440382957458\n",
      "Ep 3: Batch #184 - Loss: 1.1239722967147827\n",
      "Ep 3: Batch #185 - Loss: 0.8097243309020996\n",
      "Ep 3: Batch #186 - Loss: 1.0404865741729736\n",
      "Ep 3: Batch #187 - Loss: 1.2342479228973389\n",
      "Ep 3: Batch #188 - Loss: 1.416694164276123\n",
      "Ep 3: Batch #189 - Loss: 0.7435187697410583\n",
      "Ep 3: Batch #190 - Loss: 0.7929030060768127\n",
      "Ep 3: Batch #191 - Loss: 1.1264275312423706\n",
      "Ep 3: Batch #192 - Loss: 0.7141647934913635\n",
      "Ep 3: Batch #193 - Loss: 0.8005794882774353\n",
      "Ep 3: Batch #194 - Loss: 0.7508684992790222\n",
      "Ep 3: Batch #195 - Loss: 1.0436012744903564\n",
      "Ep 3: Batch #196 - Loss: 0.9257614016532898\n",
      "Ep 3: Batch #197 - Loss: 0.9652349948883057\n",
      "Ep 3: Batch #198 - Loss: 0.732250988483429\n",
      "Ep 3: Batch #199 - Loss: 0.924676775932312\n",
      "Ep 4: Batch #0 - Loss: 0.856968879699707\n",
      "Ep 4: Batch #1 - Loss: 0.9413918256759644\n",
      "Ep 4: Batch #2 - Loss: 1.0575624704360962\n",
      "Ep 4: Batch #3 - Loss: 0.9266833662986755\n",
      "Ep 4: Batch #4 - Loss: 0.8512016534805298\n",
      "Ep 4: Batch #5 - Loss: 0.7148057222366333\n",
      "Ep 4: Batch #6 - Loss: 0.9447261691093445\n",
      "Ep 4: Batch #7 - Loss: 0.7527973651885986\n",
      "Ep 4: Batch #8 - Loss: 0.7871211171150208\n",
      "Ep 4: Batch #9 - Loss: 1.482302188873291\n",
      "Ep 4: Batch #10 - Loss: 1.0742954015731812\n",
      "Ep 4: Batch #11 - Loss: 0.7270985245704651\n",
      "Ep 4: Batch #12 - Loss: 1.6222723722457886\n",
      "Ep 4: Batch #13 - Loss: 0.6853458881378174\n",
      "Ep 4: Batch #14 - Loss: 0.7759284973144531\n",
      "Ep 4: Batch #15 - Loss: 1.3169360160827637\n",
      "Ep 4: Batch #16 - Loss: 1.3629889488220215\n",
      "Ep 4: Batch #17 - Loss: 0.9404914379119873\n",
      "Ep 4: Batch #18 - Loss: 0.9861119985580444\n",
      "Ep 4: Batch #19 - Loss: 0.7139727473258972\n",
      "Ep 4: Batch #20 - Loss: 0.7072202563285828\n",
      "Ep 4: Batch #21 - Loss: 1.2738896608352661\n",
      "Ep 4: Batch #22 - Loss: 0.7754296660423279\n",
      "Ep 4: Batch #23 - Loss: 0.8065271973609924\n",
      "Ep 4: Batch #24 - Loss: 0.8783783316612244\n",
      "Ep 4: Batch #25 - Loss: 0.7763437032699585\n",
      "Ep 4: Batch #26 - Loss: 0.7891587615013123\n",
      "Ep 4: Batch #27 - Loss: 1.42153000831604\n",
      "Ep 4: Batch #28 - Loss: 0.926520049571991\n",
      "Ep 4: Batch #29 - Loss: 0.961723268032074\n",
      "Ep 4: Batch #30 - Loss: 1.2754976749420166\n",
      "Ep 4: Batch #31 - Loss: 0.7156386971473694\n",
      "Ep 4: Batch #32 - Loss: 0.8047181367874146\n",
      "Ep 4: Batch #33 - Loss: 0.8608256578445435\n",
      "Ep 4: Batch #34 - Loss: 0.8390353322029114\n",
      "Ep 4: Batch #35 - Loss: 1.0222561359405518\n",
      "Ep 4: Batch #36 - Loss: 0.7536616325378418\n",
      "Ep 4: Batch #37 - Loss: 1.2006970643997192\n",
      "Ep 4: Batch #38 - Loss: 0.8093570470809937\n",
      "Ep 4: Batch #39 - Loss: 0.8649611473083496\n",
      "Ep 4: Batch #40 - Loss: 0.8361424803733826\n",
      "Ep 4: Batch #41 - Loss: 0.7910768985748291\n",
      "Ep 4: Batch #42 - Loss: 0.7704178094863892\n",
      "Ep 4: Batch #43 - Loss: 0.8438559770584106\n",
      "Ep 4: Batch #44 - Loss: 0.8395407199859619\n",
      "Ep 4: Batch #45 - Loss: 0.6943003535270691\n",
      "Ep 4: Batch #46 - Loss: 0.8928810358047485\n",
      "Ep 4: Batch #47 - Loss: 1.036413311958313\n",
      "Ep 4: Batch #48 - Loss: 1.4377460479736328\n",
      "Ep 4: Batch #49 - Loss: 1.0768132209777832\n",
      "Ep 4: Batch #50 - Loss: 0.7497313022613525\n",
      "Ep 4: Batch #51 - Loss: 1.0657516717910767\n",
      "Ep 4: Batch #52 - Loss: 0.8409443497657776\n",
      "Ep 4: Batch #53 - Loss: 0.8790028691291809\n",
      "Ep 4: Batch #54 - Loss: 0.7549561858177185\n",
      "Ep 4: Batch #55 - Loss: 0.8131341338157654\n",
      "Ep 4: Batch #56 - Loss: 1.3409405946731567\n",
      "Ep 4: Batch #57 - Loss: 0.9220501780509949\n",
      "Ep 4: Batch #58 - Loss: 1.074267864227295\n",
      "Ep 4: Batch #59 - Loss: 0.7290574312210083\n",
      "Ep 4: Batch #60 - Loss: 1.391802430152893\n",
      "Ep 4: Batch #61 - Loss: 0.6881052255630493\n",
      "Ep 4: Batch #62 - Loss: 0.7817023396492004\n",
      "Ep 4: Batch #63 - Loss: 1.0787153244018555\n",
      "Ep 4: Batch #64 - Loss: 9.484334945678711\n",
      "Ep 4: Batch #65 - Loss: 0.6557470560073853\n",
      "Ep 4: Batch #66 - Loss: 0.8665761947631836\n",
      "Ep 4: Batch #67 - Loss: 0.9709727168083191\n",
      "Ep 4: Batch #68 - Loss: 0.9710387587547302\n",
      "Ep 4: Batch #69 - Loss: 0.8037551045417786\n",
      "Ep 4: Batch #70 - Loss: 0.849509596824646\n",
      "Ep 4: Batch #71 - Loss: 0.7312019467353821\n",
      "Ep 4: Batch #72 - Loss: 0.9148895740509033\n",
      "Ep 4: Batch #73 - Loss: 0.9719645977020264\n",
      "Ep 4: Batch #74 - Loss: 0.7949976921081543\n",
      "Ep 4: Batch #75 - Loss: 0.8184836506843567\n",
      "Ep 4: Batch #76 - Loss: 1.14920175075531\n",
      "Ep 4: Batch #77 - Loss: 0.7915899157524109\n",
      "Ep 4: Batch #78 - Loss: 1.2370084524154663\n",
      "Ep 4: Batch #79 - Loss: 0.680354654788971\n",
      "Ep 4: Batch #80 - Loss: 0.9281170964241028\n",
      "Ep 4: Batch #81 - Loss: 1.7361829280853271\n",
      "Ep 4: Batch #82 - Loss: 0.934836208820343\n",
      "Ep 4: Batch #83 - Loss: 1.7887128591537476\n",
      "Ep 4: Batch #84 - Loss: 0.7706237435340881\n",
      "Ep 4: Batch #85 - Loss: 1.0324506759643555\n",
      "Ep 4: Batch #86 - Loss: 0.768873393535614\n",
      "Ep 4: Batch #87 - Loss: 0.7696948051452637\n",
      "Ep 4: Batch #88 - Loss: 0.8646965026855469\n",
      "Ep 4: Batch #89 - Loss: 0.9256733655929565\n",
      "Ep 4: Batch #90 - Loss: 1.2384322881698608\n",
      "Ep 4: Batch #91 - Loss: 0.8659778833389282\n",
      "Ep 4: Batch #92 - Loss: 1.099951148033142\n",
      "Ep 4: Batch #93 - Loss: 1.1110163927078247\n",
      "Ep 4: Batch #94 - Loss: 1.1183308362960815\n",
      "Ep 4: Batch #95 - Loss: 0.9871490001678467\n",
      "Ep 4: Batch #96 - Loss: 0.9633411169052124\n",
      "Ep 4: Batch #97 - Loss: 0.7853608727455139\n",
      "Ep 4: Batch #98 - Loss: 0.7980548143386841\n",
      "Ep 4: Batch #99 - Loss: 1.014691948890686\n",
      "Ep 4: Batch #100 - Loss: 0.7328628301620483\n",
      "Ep 4: Batch #101 - Loss: 1.1102832555770874\n",
      "Ep 4: Batch #102 - Loss: 0.8354266285896301\n",
      "Ep 4: Batch #103 - Loss: 0.8384962677955627\n",
      "Ep 4: Batch #104 - Loss: 0.8607895374298096\n",
      "Ep 4: Batch #105 - Loss: 1.0927643775939941\n",
      "Ep 4: Batch #106 - Loss: 0.8095453977584839\n",
      "Ep 4: Batch #107 - Loss: 0.8219977021217346\n",
      "Ep 4: Batch #108 - Loss: 1.1041415929794312\n",
      "Ep 4: Batch #109 - Loss: 0.8123716115951538\n",
      "Ep 4: Batch #110 - Loss: 0.9877707362174988\n",
      "Ep 4: Batch #111 - Loss: 1.4480427503585815\n",
      "Ep 4: Batch #112 - Loss: 1.1256439685821533\n",
      "Ep 4: Batch #113 - Loss: 0.8762769103050232\n",
      "Ep 4: Batch #114 - Loss: 0.9651784300804138\n",
      "Ep 4: Batch #115 - Loss: 1.1577396392822266\n",
      "Ep 4: Batch #116 - Loss: 0.6734586358070374\n",
      "Ep 4: Batch #117 - Loss: 0.9290717840194702\n",
      "Ep 4: Batch #118 - Loss: 0.5965124368667603\n",
      "Model saved in file: ./weights_autoencoder_low_LR/model_e4b118_1516651269.1356568.ckpt\n",
      "Ep 4: Batch #119 - Loss: 1.0909018516540527\n",
      "Ep 4: Batch #120 - Loss: 0.8445624113082886\n",
      "Ep 4: Batch #121 - Loss: 0.7402686476707458\n",
      "Ep 4: Batch #122 - Loss: 0.8867817521095276\n",
      "Ep 4: Batch #123 - Loss: 0.8865723609924316\n",
      "Ep 4: Batch #124 - Loss: 0.7085419297218323\n",
      "Ep 4: Batch #125 - Loss: 2.7925448417663574\n",
      "Ep 4: Batch #126 - Loss: 1.2972421646118164\n",
      "Ep 4: Batch #127 - Loss: 0.8156872391700745\n",
      "Ep 4: Batch #128 - Loss: 1.1858423948287964\n",
      "Ep 4: Batch #129 - Loss: 0.9008700847625732\n",
      "Ep 4: Batch #130 - Loss: 0.7831893563270569\n",
      "Ep 4: Batch #131 - Loss: 1.0769885778427124\n",
      "Ep 4: Batch #132 - Loss: 0.8875011801719666\n",
      "Ep 4: Batch #133 - Loss: 0.8770632743835449\n",
      "Ep 4: Batch #134 - Loss: 0.8244800567626953\n",
      "Ep 4: Batch #135 - Loss: 1.0353055000305176\n",
      "Ep 4: Batch #136 - Loss: 1.2548909187316895\n",
      "Ep 4: Batch #137 - Loss: 1.031494140625\n",
      "Ep 4: Batch #138 - Loss: 1.1325109004974365\n",
      "Ep 4: Batch #139 - Loss: 0.9668056964874268\n",
      "Ep 4: Batch #140 - Loss: 1.1119533777236938\n",
      "Ep 4: Batch #141 - Loss: 1.4224237203598022\n",
      "Ep 4: Batch #142 - Loss: 0.8460208177566528\n",
      "Ep 4: Batch #143 - Loss: 1.042635202407837\n",
      "Ep 4: Batch #144 - Loss: 0.7790467739105225\n",
      "Ep 4: Batch #145 - Loss: 0.7269615530967712\n",
      "Ep 4: Batch #146 - Loss: 0.936610758304596\n",
      "Ep 4: Batch #147 - Loss: 0.9306557178497314\n",
      "Ep 4: Batch #148 - Loss: 1.0432926416397095\n",
      "Ep 4: Batch #149 - Loss: 0.9206192493438721\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 4: Batch #150 - Loss: 0.9332417249679565\n",
      "Ep 4: Batch #151 - Loss: 0.7688819766044617\n",
      "Ep 4: Batch #152 - Loss: 0.7863974571228027\n",
      "Ep 4: Batch #153 - Loss: 1.1766465902328491\n",
      "Ep 4: Batch #154 - Loss: 0.8104060888290405\n",
      "Ep 4: Batch #155 - Loss: 0.8988765478134155\n",
      "Ep 4: Batch #156 - Loss: 1.0817006826400757\n",
      "Ep 4: Batch #157 - Loss: 0.8137942552566528\n",
      "Ep 4: Batch #158 - Loss: 0.8563665747642517\n",
      "Ep 4: Batch #159 - Loss: 0.8671756982803345\n",
      "Ep 4: Batch #160 - Loss: 0.9540054798126221\n",
      "Ep 4: Batch #161 - Loss: 0.8733439445495605\n",
      "Ep 4: Batch #162 - Loss: 0.9945790767669678\n",
      "Ep 4: Batch #163 - Loss: 0.9811715483665466\n",
      "Ep 4: Batch #164 - Loss: 0.8367627859115601\n",
      "Ep 4: Batch #165 - Loss: 1.5551425218582153\n",
      "Ep 4: Batch #166 - Loss: 0.7376711964607239\n",
      "Ep 4: Batch #167 - Loss: 1.1486138105392456\n",
      "Ep 4: Batch #168 - Loss: 0.9218005537986755\n",
      "Ep 4: Batch #169 - Loss: 0.8574979305267334\n",
      "Ep 4: Batch #170 - Loss: 0.8594989776611328\n",
      "Ep 4: Batch #171 - Loss: 0.8446580171585083\n",
      "Ep 4: Batch #172 - Loss: 0.6766413450241089\n",
      "Ep 4: Batch #173 - Loss: 1.2770700454711914\n",
      "Ep 4: Batch #174 - Loss: 0.6279885172843933\n",
      "Ep 4: Batch #175 - Loss: 0.8279916048049927\n",
      "Ep 4: Batch #176 - Loss: 1.2156559228897095\n",
      "Ep 4: Batch #177 - Loss: 0.9057508707046509\n",
      "Ep 4: Batch #178 - Loss: 0.8234497904777527\n",
      "Ep 4: Batch #179 - Loss: 1.008696436882019\n",
      "Ep 4: Batch #180 - Loss: 0.9269419312477112\n",
      "Ep 4: Batch #181 - Loss: 1.06645667552948\n",
      "Ep 4: Batch #182 - Loss: 0.8162707090377808\n",
      "Ep 4: Batch #183 - Loss: 0.8211893439292908\n",
      "Ep 4: Batch #184 - Loss: 1.122260570526123\n",
      "Ep 4: Batch #185 - Loss: 0.8083991408348083\n",
      "Ep 4: Batch #186 - Loss: 1.0388599634170532\n",
      "Ep 4: Batch #187 - Loss: 1.2324366569519043\n",
      "Ep 4: Batch #188 - Loss: 1.4151841402053833\n",
      "Ep 4: Batch #189 - Loss: 0.7422468662261963\n",
      "Ep 4: Batch #190 - Loss: 0.7913040518760681\n",
      "Ep 4: Batch #191 - Loss: 1.1240161657333374\n",
      "Ep 4: Batch #192 - Loss: 0.7127432227134705\n",
      "Ep 4: Batch #193 - Loss: 0.7990109324455261\n",
      "Ep 4: Batch #194 - Loss: 0.7494338154792786\n",
      "Ep 4: Batch #195 - Loss: 1.0424023866653442\n",
      "Ep 4: Batch #196 - Loss: 0.9236994385719299\n",
      "Ep 4: Batch #197 - Loss: 0.962814211845398\n",
      "Ep 4: Batch #198 - Loss: 0.7308875918388367\n",
      "Ep 4: Batch #199 - Loss: 0.9229158163070679\n",
      "Ep 5: Batch #0 - Loss: 0.8556320071220398\n",
      "Ep 5: Batch #1 - Loss: 0.9396875500679016\n",
      "Ep 5: Batch #2 - Loss: 1.0562474727630615\n",
      "Ep 5: Batch #3 - Loss: 0.9248382449150085\n",
      "Ep 5: Batch #4 - Loss: 0.8496049642562866\n",
      "Ep 5: Batch #5 - Loss: 0.7133620381355286\n",
      "Ep 5: Batch #6 - Loss: 0.9425614476203918\n",
      "Ep 5: Batch #7 - Loss: 0.7513368129730225\n",
      "Ep 5: Batch #8 - Loss: 0.7854638695716858\n",
      "Ep 5: Batch #9 - Loss: 1.4796372652053833\n",
      "Ep 5: Batch #10 - Loss: 1.0727730989456177\n",
      "Ep 5: Batch #11 - Loss: 0.7251309156417847\n",
      "Ep 5: Batch #12 - Loss: 1.617979645729065\n",
      "Ep 5: Batch #13 - Loss: 0.6842121481895447\n",
      "Ep 5: Batch #14 - Loss: 0.7743337154388428\n",
      "Ep 5: Batch #15 - Loss: 1.315126895904541\n",
      "Ep 5: Batch #16 - Loss: 1.3608120679855347\n",
      "Ep 5: Batch #17 - Loss: 0.9390496611595154\n",
      "Ep 5: Batch #18 - Loss: 0.984641969203949\n",
      "Ep 5: Batch #19 - Loss: 0.7124751806259155\n",
      "Ep 5: Batch #20 - Loss: 0.7057264447212219\n",
      "Ep 5: Batch #21 - Loss: 1.272281289100647\n",
      "Ep 5: Batch #22 - Loss: 0.7738975882530212\n",
      "Ep 5: Batch #23 - Loss: 0.8048514723777771\n",
      "Ep 5: Batch #24 - Loss: 0.8762089014053345\n",
      "Ep 5: Batch #25 - Loss: 0.7746996283531189\n",
      "Ep 5: Batch #26 - Loss: 0.7879692316055298\n",
      "Ep 5: Batch #27 - Loss: 1.4197421073913574\n",
      "Ep 5: Batch #28 - Loss: 0.9249895811080933\n",
      "Ep 5: Batch #29 - Loss: 0.9599617123603821\n",
      "Ep 5: Batch #30 - Loss: 1.274024486541748\n",
      "Ep 5: Batch #31 - Loss: 0.7143279314041138\n",
      "Ep 5: Batch #32 - Loss: 0.8031396269798279\n",
      "Ep 5: Batch #33 - Loss: 0.8594325184822083\n",
      "Ep 5: Batch #34 - Loss: 0.8377541303634644\n",
      "Ep 5: Batch #35 - Loss: 1.020675539970398\n",
      "Ep 5: Batch #36 - Loss: 0.7521058917045593\n",
      "Ep 5: Batch #37 - Loss: 1.1993597745895386\n",
      "Ep 5: Batch #38 - Loss: 0.8078998923301697\n",
      "Ep 5: Batch #39 - Loss: 0.8636236786842346\n",
      "Ep 5: Batch #40 - Loss: 0.8343968987464905\n",
      "Ep 5: Batch #41 - Loss: 0.7897437810897827\n",
      "Ep 5: Batch #42 - Loss: 0.7691379189491272\n",
      "Ep 5: Batch #43 - Loss: 0.8423192501068115\n",
      "Ep 5: Batch #44 - Loss: 0.8380981683731079\n",
      "Ep 5: Batch #45 - Loss: 0.6927915215492249\n",
      "Ep 5: Batch #46 - Loss: 0.8912925124168396\n",
      "Ep 5: Batch #47 - Loss: 1.0346273183822632\n",
      "Ep 5: Batch #48 - Loss: 1.4356728792190552\n",
      "Ep 5: Batch #49 - Loss: 1.0751807689666748\n",
      "Ep 5: Batch #50 - Loss: 0.7482540607452393\n",
      "Ep 5: Batch #51 - Loss: 1.0640758275985718\n",
      "Ep 5: Batch #52 - Loss: 0.8395035266876221\n",
      "Ep 5: Batch #53 - Loss: 0.8773224949836731\n",
      "Ep 5: Batch #54 - Loss: 0.7533549666404724\n",
      "Ep 5: Batch #55 - Loss: 0.8116526007652283\n",
      "Ep 5: Batch #56 - Loss: 1.3371959924697876\n",
      "Ep 5: Batch #57 - Loss: 0.9199642539024353\n",
      "Ep 5: Batch #58 - Loss: 1.072016716003418\n",
      "Ep 5: Batch #59 - Loss: 0.7276602387428284\n",
      "Ep 5: Batch #60 - Loss: 1.3894257545471191\n",
      "Ep 5: Batch #61 - Loss: 0.6863449811935425\n",
      "Ep 5: Batch #62 - Loss: 0.7802241444587708\n",
      "Ep 5: Batch #63 - Loss: 1.0768318176269531\n",
      "Ep 5: Batch #64 - Loss: 9.483026504516602\n",
      "Ep 5: Batch #65 - Loss: 0.6544826030731201\n",
      "Ep 5: Batch #66 - Loss: 0.8648163676261902\n",
      "Ep 5: Batch #67 - Loss: 0.969379723072052\n",
      "Ep 5: Batch #68 - Loss: 0.9695615768432617\n",
      "Ep 5: Batch #69 - Loss: 0.8020532727241516\n",
      "Ep 5: Batch #70 - Loss: 0.8477776646614075\n",
      "Ep 5: Batch #71 - Loss: 0.7296333312988281\n",
      "Ep 5: Batch #72 - Loss: 0.9133546352386475\n",
      "Ep 5: Batch #73 - Loss: 0.970612108707428\n",
      "Ep 5: Batch #74 - Loss: 0.7936829924583435\n",
      "Ep 5: Batch #75 - Loss: 0.8171321153640747\n",
      "Ep 5: Batch #76 - Loss: 1.1478084325790405\n",
      "Ep 5: Batch #77 - Loss: 0.7897035479545593\n",
      "Ep 5: Batch #78 - Loss: 1.234998345375061\n",
      "Ep 5: Batch #79 - Loss: 0.6788185238838196\n",
      "Ep 5: Batch #80 - Loss: 0.9262800812721252\n",
      "Ep 5: Batch #81 - Loss: 1.7348740100860596\n",
      "Ep 5: Batch #82 - Loss: 0.9328464269638062\n",
      "Ep 5: Batch #83 - Loss: 1.7873125076293945\n",
      "Ep 5: Batch #84 - Loss: 0.7692317962646484\n",
      "Ep 5: Batch #85 - Loss: 1.0308815240859985\n",
      "Ep 5: Batch #86 - Loss: 0.7674916386604309\n",
      "Ep 5: Batch #87 - Loss: 0.7675327062606812\n",
      "Ep 5: Batch #88 - Loss: 0.8630261421203613\n",
      "Ep 5: Batch #89 - Loss: 0.9244126677513123\n",
      "Ep 5: Batch #90 - Loss: 1.236817717552185\n",
      "Ep 5: Batch #91 - Loss: 0.8643452525138855\n",
      "Ep 5: Batch #92 - Loss: 1.098172903060913\n",
      "Ep 5: Batch #93 - Loss: 1.1090266704559326\n",
      "Ep 5: Batch #94 - Loss: 1.1164250373840332\n",
      "Ep 5: Batch #95 - Loss: 0.985544741153717\n",
      "Ep 5: Batch #96 - Loss: 0.9619500041007996\n",
      "Ep 5: Batch #97 - Loss: 0.7839343547821045\n",
      "Ep 5: Batch #98 - Loss: 0.79637610912323\n",
      "Ep 5: Batch #99 - Loss: 1.0131622552871704\n",
      "Ep 5: Batch #100 - Loss: 0.7314916253089905\n",
      "Ep 5: Batch #101 - Loss: 1.1087501049041748\n",
      "Ep 5: Batch #102 - Loss: 0.833983838558197\n",
      "Ep 5: Batch #103 - Loss: 0.8373816609382629\n",
      "Ep 5: Batch #104 - Loss: 0.8591892719268799\n",
      "Ep 5: Batch #105 - Loss: 1.0911672115325928\n",
      "Ep 5: Batch #106 - Loss: 0.8083903789520264\n",
      "Ep 5: Batch #107 - Loss: 0.8201351165771484\n",
      "Ep 5: Batch #108 - Loss: 1.1025346517562866\n",
      "Ep 5: Batch #109 - Loss: 0.8108875751495361\n",
      "Ep 5: Batch #110 - Loss: 0.9861341714859009\n",
      "Ep 5: Batch #111 - Loss: 1.4463740587234497\n",
      "Ep 5: Batch #112 - Loss: 1.123469591140747\n",
      "Ep 5: Batch #113 - Loss: 0.8747431635856628\n",
      "Ep 5: Batch #114 - Loss: 0.9635303020477295\n",
      "Ep 5: Batch #115 - Loss: 1.1558035612106323\n",
      "Ep 5: Batch #116 - Loss: 0.6720377206802368\n",
      "Ep 5: Batch #117 - Loss: 0.9274880886077881\n",
      "Ep 5: Batch #118 - Loss: 0.5950942039489746\n",
      "Model saved in file: ./weights_autoencoder_low_LR/model_e5b118_1516651269.271054.ckpt\n",
      "Ep 5: Batch #119 - Loss: 1.0886863470077515\n",
      "Ep 5: Batch #120 - Loss: 0.8433694839477539\n",
      "Ep 5: Batch #121 - Loss: 0.7387619614601135\n",
      "Ep 5: Batch #122 - Loss: 0.8849295973777771\n",
      "Ep 5: Batch #123 - Loss: 0.8848470449447632\n",
      "Ep 5: Batch #124 - Loss: 0.7069650292396545\n",
      "Ep 5: Batch #125 - Loss: 2.7907943725585938\n",
      "Ep 5: Batch #126 - Loss: 1.2951359748840332\n",
      "Ep 5: Batch #127 - Loss: 0.8139629364013672\n",
      "Ep 5: Batch #128 - Loss: 1.1840745210647583\n",
      "Ep 5: Batch #129 - Loss: 0.8994849920272827\n",
      "Ep 5: Batch #130 - Loss: 0.7815238833427429\n",
      "Ep 5: Batch #131 - Loss: 1.0746846199035645\n",
      "Ep 5: Batch #132 - Loss: 0.8860456347465515\n",
      "Ep 5: Batch #133 - Loss: 0.8753229975700378\n",
      "Ep 5: Batch #134 - Loss: 0.8232757449150085\n",
      "Ep 5: Batch #135 - Loss: 1.0338011980056763\n",
      "Ep 5: Batch #136 - Loss: 1.2535256147384644\n",
      "Ep 5: Batch #137 - Loss: 1.0297635793685913\n",
      "Ep 5: Batch #138 - Loss: 1.1308139562606812\n",
      "Ep 5: Batch #139 - Loss: 0.965368390083313\n",
      "Ep 5: Batch #140 - Loss: 1.110276699066162\n",
      "Ep 5: Batch #141 - Loss: 1.4203730821609497\n",
      "Ep 5: Batch #142 - Loss: 0.8445917367935181\n",
      "Ep 5: Batch #143 - Loss: 1.0406748056411743\n",
      "Ep 5: Batch #144 - Loss: 0.7774147987365723\n",
      "Ep 5: Batch #145 - Loss: 0.7254980206489563\n",
      "Ep 5: Batch #146 - Loss: 0.934926450252533\n",
      "Ep 5: Batch #147 - Loss: 0.9290933609008789\n",
      "Ep 5: Batch #148 - Loss: 1.0416935682296753\n",
      "Ep 5: Batch #149 - Loss: 0.918920636177063\n",
      "Ep 5: Batch #150 - Loss: 0.9319356679916382\n",
      "Ep 5: Batch #151 - Loss: 0.767619252204895\n",
      "Ep 5: Batch #152 - Loss: 0.7849749326705933\n",
      "Ep 5: Batch #153 - Loss: 1.174612045288086\n",
      "Ep 5: Batch #154 - Loss: 0.8091822266578674\n",
      "Ep 5: Batch #155 - Loss: 0.8970614075660706\n",
      "Ep 5: Batch #156 - Loss: 1.080309271812439\n",
      "Ep 5: Batch #157 - Loss: 0.8122919201850891\n",
      "Ep 5: Batch #158 - Loss: 0.8545151948928833\n",
      "Ep 5: Batch #159 - Loss: 0.8655532598495483\n",
      "Ep 5: Batch #160 - Loss: 0.9526740312576294\n",
      "Ep 5: Batch #161 - Loss: 0.8718451261520386\n",
      "Ep 5: Batch #162 - Loss: 0.9929810166358948\n",
      "Ep 5: Batch #163 - Loss: 0.9796688556671143\n",
      "Ep 5: Batch #164 - Loss: 0.8354901671409607\n",
      "Ep 5: Batch #165 - Loss: 1.5537002086639404\n",
      "Ep 5: Batch #166 - Loss: 0.7362812161445618\n",
      "Ep 5: Batch #167 - Loss: 1.1469535827636719\n",
      "Ep 5: Batch #168 - Loss: 0.9203864336013794\n",
      "Ep 5: Batch #169 - Loss: 0.8560394644737244\n",
      "Ep 5: Batch #170 - Loss: 0.8580119609832764\n",
      "Ep 5: Batch #171 - Loss: 0.8427879214286804\n",
      "Ep 5: Batch #172 - Loss: 0.6754232048988342\n",
      "Ep 5: Batch #173 - Loss: 1.2751392126083374\n",
      "Ep 5: Batch #174 - Loss: 0.6265624761581421\n",
      "Ep 5: Batch #175 - Loss: 0.8264836072921753\n",
      "Ep 5: Batch #176 - Loss: 1.2143186330795288\n",
      "Ep 5: Batch #177 - Loss: 0.9043523073196411\n",
      "Ep 5: Batch #178 - Loss: 0.8219276070594788\n",
      "Ep 5: Batch #179 - Loss: 1.0070854425430298\n",
      "Ep 5: Batch #180 - Loss: 0.9253539443016052\n",
      "Ep 5: Batch #181 - Loss: 1.0643250942230225\n",
      "Ep 5: Batch #182 - Loss: 0.8146688938140869\n",
      "Ep 5: Batch #183 - Loss: 0.819840669631958\n",
      "Ep 5: Batch #184 - Loss: 1.1207151412963867\n",
      "Ep 5: Batch #185 - Loss: 0.8070154190063477\n",
      "Ep 5: Batch #186 - Loss: 1.0372207164764404\n",
      "Ep 5: Batch #187 - Loss: 1.2305262088775635\n",
      "Ep 5: Batch #188 - Loss: 1.4135253429412842\n",
      "Ep 5: Batch #189 - Loss: 0.7409020066261292\n",
      "Ep 5: Batch #190 - Loss: 0.7896576523780823\n",
      "Ep 5: Batch #191 - Loss: 1.1217979192733765\n",
      "Ep 5: Batch #192 - Loss: 0.7113056182861328\n",
      "Ep 5: Batch #193 - Loss: 0.7972757816314697\n",
      "Ep 5: Batch #194 - Loss: 0.7479497194290161\n",
      "Ep 5: Batch #195 - Loss: 1.0412276983261108\n",
      "Ep 5: Batch #196 - Loss: 0.9216483235359192\n",
      "Ep 5: Batch #197 - Loss: 0.9604494571685791\n",
      "Ep 5: Batch #198 - Loss: 0.729482114315033\n",
      "Ep 5: Batch #199 - Loss: 0.9211220741271973\n",
      "Ep 6: Batch #0 - Loss: 0.8542291522026062\n",
      "Ep 6: Batch #1 - Loss: 0.9379439949989319\n",
      "Ep 6: Batch #2 - Loss: 1.0549451112747192\n",
      "Ep 6: Batch #3 - Loss: 0.9230213761329651\n",
      "Ep 6: Batch #4 - Loss: 0.8479445576667786\n",
      "Ep 6: Batch #5 - Loss: 0.7118757963180542\n",
      "Ep 6: Batch #6 - Loss: 0.9403309226036072\n",
      "Ep 6: Batch #7 - Loss: 0.7498551607131958\n",
      "Ep 6: Batch #8 - Loss: 0.7836514115333557\n",
      "Ep 6: Batch #9 - Loss: 1.4771173000335693\n",
      "Ep 6: Batch #10 - Loss: 1.0712251663208008\n",
      "Ep 6: Batch #11 - Loss: 0.7231575846672058\n",
      "Ep 6: Batch #12 - Loss: 1.6138627529144287\n",
      "Ep 6: Batch #13 - Loss: 0.6830405592918396\n",
      "Ep 6: Batch #14 - Loss: 0.77274090051651\n",
      "Ep 6: Batch #15 - Loss: 1.3130004405975342\n",
      "Ep 6: Batch #16 - Loss: 1.3585995435714722\n",
      "Ep 6: Batch #17 - Loss: 0.9375725984573364\n",
      "Ep 6: Batch #18 - Loss: 0.9832103848457336\n",
      "Ep 6: Batch #19 - Loss: 0.7110277414321899\n",
      "Ep 6: Batch #20 - Loss: 0.7042366862297058\n",
      "Ep 6: Batch #21 - Loss: 1.2705843448638916\n",
      "Ep 6: Batch #22 - Loss: 0.7723479866981506\n",
      "Ep 6: Batch #23 - Loss: 0.8031642436981201\n",
      "Ep 6: Batch #24 - Loss: 0.8740864396095276\n",
      "Ep 6: Batch #25 - Loss: 0.7730305194854736\n",
      "Ep 6: Batch #26 - Loss: 0.7867336869239807\n",
      "Ep 6: Batch #27 - Loss: 1.4180412292480469\n",
      "Ep 6: Batch #28 - Loss: 0.9234346747398376\n",
      "Ep 6: Batch #29 - Loss: 0.958199679851532\n",
      "Ep 6: Batch #30 - Loss: 1.2723932266235352\n",
      "Ep 6: Batch #31 - Loss: 0.7130146026611328\n",
      "Ep 6: Batch #32 - Loss: 0.8015874028205872\n",
      "Ep 6: Batch #33 - Loss: 0.8579639196395874\n",
      "Ep 6: Batch #34 - Loss: 0.8364260792732239\n",
      "Ep 6: Batch #35 - Loss: 1.019006609916687\n",
      "Ep 6: Batch #36 - Loss: 0.7505794763565063\n",
      "Ep 6: Batch #37 - Loss: 1.1979329586029053\n",
      "Ep 6: Batch #38 - Loss: 0.806397557258606\n",
      "Ep 6: Batch #39 - Loss: 0.862300455570221\n",
      "Ep 6: Batch #40 - Loss: 0.8326370120048523\n",
      "Ep 6: Batch #41 - Loss: 0.7883972525596619\n",
      "Ep 6: Batch #42 - Loss: 0.7679082155227661\n",
      "Ep 6: Batch #43 - Loss: 0.8407784104347229\n",
      "Ep 6: Batch #44 - Loss: 0.8366300463676453\n",
      "Ep 6: Batch #45 - Loss: 0.6912592649459839\n",
      "Ep 6: Batch #46 - Loss: 0.8896827697753906\n",
      "Ep 6: Batch #47 - Loss: 1.0328201055526733\n",
      "Ep 6: Batch #48 - Loss: 1.4335975646972656\n",
      "Ep 6: Batch #49 - Loss: 1.0735177993774414\n",
      "Ep 6: Batch #50 - Loss: 0.7468066215515137\n",
      "Ep 6: Batch #51 - Loss: 1.062406301498413\n",
      "Ep 6: Batch #52 - Loss: 0.8380751609802246\n",
      "Ep 6: Batch #53 - Loss: 0.8757277131080627\n",
      "Ep 6: Batch #54 - Loss: 0.7517859935760498\n",
      "Ep 6: Batch #55 - Loss: 0.810122549533844\n",
      "Ep 6: Batch #56 - Loss: 1.333673119544983\n",
      "Ep 6: Batch #57 - Loss: 0.9178652167320251\n",
      "Ep 6: Batch #58 - Loss: 1.0697762966156006\n",
      "Ep 6: Batch #59 - Loss: 0.7262360453605652\n",
      "Ep 6: Batch #60 - Loss: 1.3866397142410278\n",
      "Ep 6: Batch #61 - Loss: 0.6845735311508179\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 6: Batch #62 - Loss: 0.77871173620224\n",
      "Ep 6: Batch #63 - Loss: 1.0748798847198486\n",
      "Ep 6: Batch #64 - Loss: 9.481644630432129\n",
      "Ep 6: Batch #65 - Loss: 0.6532191634178162\n",
      "Ep 6: Batch #66 - Loss: 0.8630218505859375\n",
      "Ep 6: Batch #67 - Loss: 0.9676937460899353\n",
      "Ep 6: Batch #68 - Loss: 0.9681410789489746\n",
      "Ep 6: Batch #69 - Loss: 0.8003733158111572\n",
      "Ep 6: Batch #70 - Loss: 0.8457902073860168\n",
      "Ep 6: Batch #71 - Loss: 0.7280309796333313\n",
      "Ep 6: Batch #72 - Loss: 0.9117786288261414\n",
      "Ep 6: Batch #73 - Loss: 0.96917724609375\n",
      "Ep 6: Batch #74 - Loss: 0.7923107743263245\n",
      "Ep 6: Batch #75 - Loss: 0.8157632350921631\n",
      "Ep 6: Batch #76 - Loss: 1.1464059352874756\n",
      "Ep 6: Batch #77 - Loss: 0.7878273129463196\n",
      "Ep 6: Batch #78 - Loss: 1.2329517602920532\n",
      "Ep 6: Batch #79 - Loss: 0.6772263050079346\n",
      "Ep 6: Batch #80 - Loss: 0.9244162440299988\n",
      "Ep 6: Batch #81 - Loss: 1.7335538864135742\n",
      "Ep 6: Batch #82 - Loss: 0.9309332370758057\n",
      "Ep 6: Batch #83 - Loss: 1.7858887910842896\n",
      "Ep 6: Batch #84 - Loss: 0.7677822709083557\n",
      "Ep 6: Batch #85 - Loss: 1.0292198657989502\n",
      "Ep 6: Batch #86 - Loss: 0.7660762667655945\n",
      "Ep 6: Batch #87 - Loss: 0.765404462814331\n",
      "Ep 6: Batch #88 - Loss: 0.8612639904022217\n",
      "Ep 6: Batch #89 - Loss: 0.9231153726577759\n",
      "Ep 6: Batch #90 - Loss: 1.2350974082946777\n",
      "Ep 6: Batch #91 - Loss: 0.8626434803009033\n",
      "Ep 6: Batch #92 - Loss: 1.0963233709335327\n",
      "Ep 6: Batch #93 - Loss: 1.106924295425415\n",
      "Ep 6: Batch #94 - Loss: 1.1145445108413696\n",
      "Ep 6: Batch #95 - Loss: 0.983787477016449\n",
      "Ep 6: Batch #96 - Loss: 0.9604509472846985\n",
      "Ep 6: Batch #97 - Loss: 0.7824863791465759\n",
      "Ep 6: Batch #98 - Loss: 0.7947193384170532\n",
      "Ep 6: Batch #99 - Loss: 1.0116403102874756\n",
      "Ep 6: Batch #100 - Loss: 0.7300806641578674\n",
      "Ep 6: Batch #101 - Loss: 1.1071666479110718\n",
      "Ep 6: Batch #102 - Loss: 0.8325623869895935\n",
      "Ep 6: Batch #103 - Loss: 0.8362689018249512\n",
      "Ep 6: Batch #104 - Loss: 0.8575490117073059\n",
      "Ep 6: Batch #105 - Loss: 1.0895476341247559\n",
      "Ep 6: Batch #106 - Loss: 0.8072232007980347\n",
      "Ep 6: Batch #107 - Loss: 0.8182388544082642\n",
      "Ep 6: Batch #108 - Loss: 1.1008661985397339\n",
      "Ep 6: Batch #109 - Loss: 0.8094013333320618\n",
      "Ep 6: Batch #110 - Loss: 0.9844822883605957\n",
      "Ep 6: Batch #111 - Loss: 1.4446889162063599\n",
      "Ep 6: Batch #112 - Loss: 1.1211806535720825\n",
      "Ep 6: Batch #113 - Loss: 0.8731161952018738\n",
      "Ep 6: Batch #114 - Loss: 0.9618781208992004\n",
      "Ep 6: Batch #115 - Loss: 1.1538732051849365\n",
      "Ep 6: Batch #116 - Loss: 0.6706152558326721\n",
      "Ep 6: Batch #117 - Loss: 0.9258829355239868\n",
      "Ep 6: Batch #118 - Loss: 0.593637228012085\n",
      "Model saved in file: ./weights_autoencoder_low_LR/model_e6b118_1516651269.407934.ckpt\n",
      "Ep 6: Batch #119 - Loss: 1.0865592956542969\n",
      "Ep 6: Batch #120 - Loss: 0.8421802520751953\n",
      "Ep 6: Batch #121 - Loss: 0.737257182598114\n",
      "Ep 6: Batch #122 - Loss: 0.883017897605896\n",
      "Ep 6: Batch #123 - Loss: 0.8831471800804138\n",
      "Ep 6: Batch #124 - Loss: 0.7054141163825989\n",
      "Ep 6: Batch #125 - Loss: 2.789006471633911\n",
      "Ep 6: Batch #126 - Loss: 1.2929747104644775\n",
      "Ep 6: Batch #127 - Loss: 0.8121944069862366\n",
      "Ep 6: Batch #128 - Loss: 1.1820423603057861\n",
      "Ep 6: Batch #129 - Loss: 0.898041307926178\n",
      "Ep 6: Batch #130 - Loss: 0.7798063158988953\n",
      "Ep 6: Batch #131 - Loss: 1.0724096298217773\n",
      "Ep 6: Batch #132 - Loss: 0.8845571875572205\n",
      "Ep 6: Batch #133 - Loss: 0.8736062049865723\n",
      "Ep 6: Batch #134 - Loss: 0.8220722675323486\n",
      "Ep 6: Batch #135 - Loss: 1.0321881771087646\n",
      "Ep 6: Batch #136 - Loss: 1.252097725868225\n",
      "Ep 6: Batch #137 - Loss: 1.028038740158081\n",
      "Ep 6: Batch #138 - Loss: 1.129122018814087\n",
      "Ep 6: Batch #139 - Loss: 0.963855504989624\n",
      "Ep 6: Batch #140 - Loss: 1.1086277961730957\n",
      "Ep 6: Batch #141 - Loss: 1.4185551404953003\n",
      "Ep 6: Batch #142 - Loss: 0.8431733846664429\n",
      "Ep 6: Batch #143 - Loss: 1.038658618927002\n",
      "Ep 6: Batch #144 - Loss: 0.7757714986801147\n",
      "Ep 6: Batch #145 - Loss: 0.7240659594535828\n",
      "Ep 6: Batch #146 - Loss: 0.9333066344261169\n",
      "Ep 6: Batch #147 - Loss: 0.9274571537971497\n",
      "Ep 6: Batch #148 - Loss: 1.040139079093933\n",
      "Ep 6: Batch #149 - Loss: 0.9171990156173706\n",
      "Ep 6: Batch #150 - Loss: 0.93068927526474\n",
      "Ep 6: Batch #151 - Loss: 0.7663869261741638\n",
      "Ep 6: Batch #152 - Loss: 0.7835438251495361\n",
      "Ep 6: Batch #153 - Loss: 1.1725984811782837\n",
      "Ep 6: Batch #154 - Loss: 0.8079942464828491\n",
      "Ep 6: Batch #155 - Loss: 0.8952581882476807\n",
      "Ep 6: Batch #156 - Loss: 1.0788352489471436\n",
      "Ep 6: Batch #157 - Loss: 0.8108625411987305\n",
      "Ep 6: Batch #158 - Loss: 0.852735161781311\n",
      "Ep 6: Batch #159 - Loss: 0.8639830946922302\n",
      "Ep 6: Batch #160 - Loss: 0.951322615146637\n",
      "Ep 6: Batch #161 - Loss: 0.8703465461730957\n",
      "Ep 6: Batch #162 - Loss: 0.991348922252655\n",
      "Ep 6: Batch #163 - Loss: 0.9782187342643738\n",
      "Ep 6: Batch #164 - Loss: 0.8342365622520447\n",
      "Ep 6: Batch #165 - Loss: 1.552251935005188\n",
      "Ep 6: Batch #166 - Loss: 0.7348217964172363\n",
      "Ep 6: Batch #167 - Loss: 1.1452646255493164\n",
      "Ep 6: Batch #168 - Loss: 0.9189696311950684\n",
      "Ep 6: Batch #169 - Loss: 0.8545782566070557\n",
      "Ep 6: Batch #170 - Loss: 0.8565530776977539\n",
      "Ep 6: Batch #171 - Loss: 0.8409549593925476\n",
      "Ep 6: Batch #172 - Loss: 0.6741536259651184\n",
      "Ep 6: Batch #173 - Loss: 1.2732785940170288\n",
      "Ep 6: Batch #174 - Loss: 0.6251015067100525\n",
      "Ep 6: Batch #175 - Loss: 0.8250121474266052\n",
      "Ep 6: Batch #176 - Loss: 1.2130126953125\n",
      "Ep 6: Batch #177 - Loss: 0.9028735160827637\n",
      "Ep 6: Batch #178 - Loss: 0.8203772902488708\n",
      "Ep 6: Batch #179 - Loss: 1.0054433345794678\n",
      "Ep 6: Batch #180 - Loss: 0.9237842559814453\n",
      "Ep 6: Batch #181 - Loss: 1.0622533559799194\n",
      "Ep 6: Batch #182 - Loss: 0.813084065914154\n",
      "Ep 6: Batch #183 - Loss: 0.8184807896614075\n",
      "Ep 6: Batch #184 - Loss: 1.1192240715026855\n",
      "Ep 6: Batch #185 - Loss: 0.8056349158287048\n",
      "Ep 6: Batch #186 - Loss: 1.0355892181396484\n",
      "Ep 6: Batch #187 - Loss: 1.2285552024841309\n",
      "Ep 6: Batch #188 - Loss: 1.4117697477340698\n",
      "Ep 6: Batch #189 - Loss: 0.7395651340484619\n",
      "Ep 6: Batch #190 - Loss: 0.7879966497421265\n",
      "Ep 6: Batch #191 - Loss: 1.1197762489318848\n",
      "Ep 6: Batch #192 - Loss: 0.7098705172538757\n",
      "Ep 6: Batch #193 - Loss: 0.7955307364463806\n",
      "Ep 6: Batch #194 - Loss: 0.7464617490768433\n",
      "Ep 6: Batch #195 - Loss: 1.0399727821350098\n",
      "Ep 6: Batch #196 - Loss: 0.9197078347206116\n",
      "Ep 6: Batch #197 - Loss: 0.9582465887069702\n",
      "Ep 6: Batch #198 - Loss: 0.7280739545822144\n",
      "Ep 6: Batch #199 - Loss: 0.9192811846733093\n",
      "Ep 7: Batch #0 - Loss: 0.8527669906616211\n",
      "Ep 7: Batch #1 - Loss: 0.9361788034439087\n",
      "Ep 7: Batch #2 - Loss: 1.053663969039917\n",
      "Ep 7: Batch #3 - Loss: 0.9212589859962463\n",
      "Ep 7: Batch #4 - Loss: 0.8462992310523987\n",
      "Ep 7: Batch #5 - Loss: 0.7104016542434692\n",
      "Ep 7: Batch #6 - Loss: 0.9381046891212463\n",
      "Ep 7: Batch #7 - Loss: 0.74840247631073\n",
      "Ep 7: Batch #8 - Loss: 0.7818462252616882\n",
      "Ep 7: Batch #9 - Loss: 1.4747737646102905\n",
      "Ep 7: Batch #10 - Loss: 1.069652795791626\n",
      "Ep 7: Batch #11 - Loss: 0.7211940884590149\n",
      "Ep 7: Batch #12 - Loss: 1.610580563545227\n",
      "Ep 7: Batch #13 - Loss: 0.6818992495536804\n",
      "Ep 7: Batch #14 - Loss: 0.7712137699127197\n",
      "Ep 7: Batch #15 - Loss: 1.3107852935791016\n",
      "Ep 7: Batch #16 - Loss: 1.356394648551941\n",
      "Ep 7: Batch #17 - Loss: 0.9361071586608887\n",
      "Ep 7: Batch #18 - Loss: 0.9818115830421448\n",
      "Ep 7: Batch #19 - Loss: 0.7096230983734131\n",
      "Ep 7: Batch #20 - Loss: 0.7027465105056763\n",
      "Ep 7: Batch #21 - Loss: 1.26885187625885\n",
      "Ep 7: Batch #22 - Loss: 0.770855724811554\n",
      "Ep 7: Batch #23 - Loss: 0.8015077114105225\n",
      "Ep 7: Batch #24 - Loss: 0.8720137476921082\n",
      "Ep 7: Batch #25 - Loss: 0.7713686227798462\n",
      "Ep 7: Batch #26 - Loss: 0.7854545712471008\n",
      "Ep 7: Batch #27 - Loss: 1.4163744449615479\n",
      "Ep 7: Batch #28 - Loss: 0.9219002723693848\n",
      "Ep 7: Batch #29 - Loss: 0.9564846158027649\n",
      "Ep 7: Batch #30 - Loss: 1.270699381828308\n",
      "Ep 7: Batch #31 - Loss: 0.7117429971694946\n",
      "Ep 7: Batch #32 - Loss: 0.8000362515449524\n",
      "Ep 7: Batch #33 - Loss: 0.8564642667770386\n",
      "Ep 7: Batch #34 - Loss: 0.8350766897201538\n",
      "Ep 7: Batch #35 - Loss: 1.0172107219696045\n",
      "Ep 7: Batch #36 - Loss: 0.7491004467010498\n",
      "Ep 7: Batch #37 - Loss: 1.1964404582977295\n",
      "Ep 7: Batch #38 - Loss: 0.8048433065414429\n",
      "Ep 7: Batch #39 - Loss: 0.8610028624534607\n",
      "Ep 7: Batch #40 - Loss: 0.8308971524238586\n",
      "Ep 7: Batch #41 - Loss: 0.7871183753013611\n",
      "Ep 7: Batch #42 - Loss: 0.7667021155357361\n",
      "Ep 7: Batch #43 - Loss: 0.8392883539199829\n",
      "Ep 7: Batch #44 - Loss: 0.8351808190345764\n",
      "Ep 7: Batch #45 - Loss: 0.6897444128990173\n",
      "Ep 7: Batch #46 - Loss: 0.8880941271781921\n",
      "Ep 7: Batch #47 - Loss: 1.031048059463501\n",
      "Ep 7: Batch #48 - Loss: 1.431509256362915\n",
      "Ep 7: Batch #49 - Loss: 1.071892261505127\n",
      "Ep 7: Batch #50 - Loss: 0.7453755140304565\n",
      "Ep 7: Batch #51 - Loss: 1.0606881380081177\n",
      "Ep 7: Batch #52 - Loss: 0.8366574645042419\n",
      "Ep 7: Batch #53 - Loss: 0.8742850422859192\n",
      "Ep 7: Batch #54 - Loss: 0.7502763271331787\n",
      "Ep 7: Batch #55 - Loss: 0.8085772395133972\n",
      "Ep 7: Batch #56 - Loss: 1.3304883241653442\n",
      "Ep 7: Batch #57 - Loss: 0.9157599806785583\n",
      "Ep 7: Batch #58 - Loss: 1.067604422569275\n",
      "Ep 7: Batch #59 - Loss: 0.7248045802116394\n",
      "Ep 7: Batch #60 - Loss: 1.3836687803268433\n",
      "Ep 7: Batch #61 - Loss: 0.6828371286392212\n",
      "Ep 7: Batch #62 - Loss: 0.7771952152252197\n",
      "Ep 7: Batch #63 - Loss: 1.0729416608810425\n",
      "Ep 7: Batch #64 - Loss: 9.4802827835083\n",
      "Ep 7: Batch #65 - Loss: 0.6519725322723389\n",
      "Ep 7: Batch #66 - Loss: 0.8612108826637268\n",
      "Ep 7: Batch #67 - Loss: 0.9659367799758911\n",
      "Ep 7: Batch #68 - Loss: 0.9667634963989258\n",
      "Ep 7: Batch #69 - Loss: 0.7987421154975891\n",
      "Ep 7: Batch #70 - Loss: 0.8437849879264832\n",
      "Ep 7: Batch #71 - Loss: 0.726457417011261\n",
      "Ep 7: Batch #72 - Loss: 0.9102156162261963\n",
      "Ep 7: Batch #73 - Loss: 0.9677148461341858\n",
      "Ep 7: Batch #74 - Loss: 0.7909173965454102\n",
      "Ep 7: Batch #75 - Loss: 0.8144102096557617\n",
      "Ep 7: Batch #76 - Loss: 1.1450384855270386\n",
      "Ep 7: Batch #77 - Loss: 0.7860357165336609\n",
      "Ep 7: Batch #78 - Loss: 1.230922818183899\n",
      "Ep 7: Batch #79 - Loss: 0.6756395101547241\n",
      "Ep 7: Batch #80 - Loss: 0.922636866569519\n",
      "Ep 7: Batch #81 - Loss: 1.7323189973831177\n",
      "Ep 7: Batch #82 - Loss: 0.9291002750396729\n",
      "Ep 7: Batch #83 - Loss: 1.7845432758331299\n",
      "Ep 7: Batch #84 - Loss: 0.7663432359695435\n",
      "Ep 7: Batch #85 - Loss: 1.0275201797485352\n",
      "Ep 7: Batch #86 - Loss: 0.764657735824585\n",
      "Ep 7: Batch #87 - Loss: 0.763401448726654\n",
      "Ep 7: Batch #88 - Loss: 0.8595091104507446\n",
      "Ep 7: Batch #89 - Loss: 0.9218491911888123\n",
      "Ep 7: Batch #90 - Loss: 1.2332385778427124\n",
      "Ep 7: Batch #91 - Loss: 0.8609689474105835\n",
      "Ep 7: Batch #92 - Loss: 1.0944312810897827\n",
      "Ep 7: Batch #93 - Loss: 1.1047873497009277\n",
      "Ep 7: Batch #94 - Loss: 1.1127570867538452\n",
      "Ep 7: Batch #95 - Loss: 0.9819921851158142\n",
      "Ep 7: Batch #96 - Loss: 0.9588373303413391\n",
      "Ep 7: Batch #97 - Loss: 0.7810308933258057\n",
      "Ep 7: Batch #98 - Loss: 0.7931177020072937\n",
      "Ep 7: Batch #99 - Loss: 1.0101714134216309\n",
      "Ep 7: Batch #100 - Loss: 0.7287124991416931\n",
      "Ep 7: Batch #101 - Loss: 1.105621099472046\n",
      "Ep 7: Batch #102 - Loss: 0.8311601281166077\n",
      "Ep 7: Batch #103 - Loss: 0.8351905941963196\n",
      "Ep 7: Batch #104 - Loss: 0.8559327721595764\n",
      "Ep 7: Batch #105 - Loss: 1.0879476070404053\n",
      "Ep 7: Batch #106 - Loss: 0.8060805201530457\n",
      "Ep 7: Batch #107 - Loss: 0.816362202167511\n",
      "Ep 7: Batch #108 - Loss: 1.0991681814193726\n",
      "Ep 7: Batch #109 - Loss: 0.808005154132843\n",
      "Ep 7: Batch #110 - Loss: 0.9828161001205444\n",
      "Ep 7: Batch #111 - Loss: 1.4430452585220337\n",
      "Ep 7: Batch #112 - Loss: 1.1188939809799194\n",
      "Ep 7: Batch #113 - Loss: 0.8715611100196838\n",
      "Ep 7: Batch #114 - Loss: 0.960283100605011\n",
      "Ep 7: Batch #115 - Loss: 1.152028203010559\n",
      "Ep 7: Batch #116 - Loss: 0.6692551374435425\n",
      "Ep 7: Batch #117 - Loss: 0.9242647290229797\n",
      "Ep 7: Batch #118 - Loss: 0.5922180414199829\n",
      "Model saved in file: ./weights_autoencoder_low_LR/model_e7b118_1516651269.5436008.ckpt\n",
      "Ep 7: Batch #119 - Loss: 1.084582805633545\n",
      "Ep 7: Batch #120 - Loss: 0.8409976959228516\n",
      "Ep 7: Batch #121 - Loss: 0.7358081936836243\n",
      "Ep 7: Batch #122 - Loss: 0.8811770677566528\n",
      "Ep 7: Batch #123 - Loss: 0.8815486431121826\n",
      "Ep 7: Batch #124 - Loss: 0.7039647102355957\n",
      "Ep 7: Batch #125 - Loss: 2.7872347831726074\n",
      "Ep 7: Batch #126 - Loss: 1.2908869981765747\n",
      "Ep 7: Batch #127 - Loss: 0.8104370832443237\n",
      "Ep 7: Batch #128 - Loss: 1.1799136400222778\n",
      "Ep 7: Batch #129 - Loss: 0.8966002464294434\n",
      "Ep 7: Batch #130 - Loss: 0.7781212329864502\n",
      "Ep 7: Batch #131 - Loss: 1.0702018737792969\n",
      "Ep 7: Batch #132 - Loss: 0.883091151714325\n",
      "Ep 7: Batch #133 - Loss: 0.8719673752784729\n",
      "Ep 7: Batch #134 - Loss: 0.820946455001831\n",
      "Ep 7: Batch #135 - Loss: 1.0305670499801636\n",
      "Ep 7: Batch #136 - Loss: 1.2506545782089233\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 7: Batch #137 - Loss: 1.0263817310333252\n",
      "Ep 7: Batch #138 - Loss: 1.1274702548980713\n",
      "Ep 7: Batch #139 - Loss: 0.9623450040817261\n",
      "Ep 7: Batch #140 - Loss: 1.107053279876709\n",
      "Ep 7: Batch #141 - Loss: 1.4169282913208008\n",
      "Ep 7: Batch #142 - Loss: 0.8418216109275818\n",
      "Ep 7: Batch #143 - Loss: 1.0366852283477783\n",
      "Ep 7: Batch #144 - Loss: 0.7741469144821167\n",
      "Ep 7: Batch #145 - Loss: 0.7227322459220886\n",
      "Ep 7: Batch #146 - Loss: 0.9318249225616455\n",
      "Ep 7: Batch #147 - Loss: 0.9258477091789246\n",
      "Ep 7: Batch #148 - Loss: 1.038669228553772\n",
      "Ep 7: Batch #149 - Loss: 0.9155179858207703\n",
      "Ep 7: Batch #150 - Loss: 0.9295008778572083\n",
      "Ep 7: Batch #151 - Loss: 0.7652021050453186\n",
      "Ep 7: Batch #152 - Loss: 0.7821701765060425\n",
      "Ep 7: Batch #153 - Loss: 1.1706026792526245\n",
      "Ep 7: Batch #154 - Loss: 0.8068637251853943\n",
      "Ep 7: Batch #155 - Loss: 0.8935282826423645\n",
      "Ep 7: Batch #156 - Loss: 1.0773229598999023\n",
      "Ep 7: Batch #157 - Loss: 0.8095154762268066\n",
      "Ep 7: Batch #158 - Loss: 0.8510274887084961\n",
      "Ep 7: Batch #159 - Loss: 0.8624410629272461\n",
      "Ep 7: Batch #160 - Loss: 0.950037956237793\n",
      "Ep 7: Batch #161 - Loss: 0.8688641786575317\n",
      "Ep 7: Batch #162 - Loss: 0.9897098541259766\n",
      "Ep 7: Batch #163 - Loss: 0.9768115282058716\n",
      "Ep 7: Batch #164 - Loss: 0.8329947590827942\n",
      "Ep 7: Batch #165 - Loss: 1.5507816076278687\n",
      "Ep 7: Batch #166 - Loss: 0.7333341836929321\n",
      "Ep 7: Batch #167 - Loss: 1.1436283588409424\n",
      "Ep 7: Batch #168 - Loss: 0.9175994396209717\n",
      "Ep 7: Batch #169 - Loss: 0.8531799912452698\n",
      "Ep 7: Batch #170 - Loss: 0.855147123336792\n",
      "Ep 7: Batch #171 - Loss: 0.8392037749290466\n",
      "Ep 7: Batch #172 - Loss: 0.672980010509491\n",
      "Ep 7: Batch #173 - Loss: 1.2714521884918213\n",
      "Ep 7: Batch #174 - Loss: 0.6236448287963867\n",
      "Ep 7: Batch #175 - Loss: 0.8236042857170105\n",
      "Ep 7: Batch #176 - Loss: 1.2117273807525635\n",
      "Ep 7: Batch #177 - Loss: 0.9014055132865906\n",
      "Ep 7: Batch #178 - Loss: 0.8188470005989075\n",
      "Ep 7: Batch #179 - Loss: 1.0038049221038818\n",
      "Ep 7: Batch #180 - Loss: 0.9222884774208069\n",
      "Ep 7: Batch #181 - Loss: 1.0602654218673706\n",
      "Ep 7: Batch #182 - Loss: 0.8115599751472473\n",
      "Ep 7: Batch #183 - Loss: 0.8171980381011963\n",
      "Ep 7: Batch #184 - Loss: 1.1178615093231201\n",
      "Ep 7: Batch #185 - Loss: 0.8043496608734131\n",
      "Ep 7: Batch #186 - Loss: 1.033997893333435\n",
      "Ep 7: Batch #187 - Loss: 1.2265881299972534\n",
      "Ep 7: Batch #188 - Loss: 1.410030722618103\n",
      "Ep 7: Batch #189 - Loss: 0.7383185029029846\n",
      "Ep 7: Batch #190 - Loss: 0.7863695621490479\n",
      "Ep 7: Batch #191 - Loss: 1.1179474592208862\n",
      "Ep 7: Batch #192 - Loss: 0.7085325717926025\n",
      "Ep 7: Batch #193 - Loss: 0.7938501834869385\n",
      "Ep 7: Batch #194 - Loss: 0.7450502514839172\n",
      "Ep 7: Batch #195 - Loss: 1.038643717765808\n",
      "Ep 7: Batch #196 - Loss: 0.917914867401123\n",
      "Ep 7: Batch #197 - Loss: 0.9562088847160339\n",
      "Ep 7: Batch #198 - Loss: 0.7267066240310669\n",
      "Ep 7: Batch #199 - Loss: 0.9175103902816772\n",
      "Ep 8: Batch #0 - Loss: 0.8512992858886719\n",
      "Ep 8: Batch #1 - Loss: 0.9345197677612305\n",
      "Ep 8: Batch #2 - Loss: 1.0524139404296875\n",
      "Ep 8: Batch #3 - Loss: 0.919536292552948\n",
      "Ep 8: Batch #4 - Loss: 0.8446753621101379\n",
      "Ep 8: Batch #5 - Loss: 0.7089900374412537\n",
      "Ep 8: Batch #6 - Loss: 0.9358929395675659\n",
      "Ep 8: Batch #7 - Loss: 0.746994137763977\n",
      "Ep 8: Batch #8 - Loss: 0.7801138758659363\n",
      "Ep 8: Batch #9 - Loss: 1.4725728034973145\n",
      "Ep 8: Batch #10 - Loss: 1.0680928230285645\n",
      "Ep 8: Batch #11 - Loss: 0.7193693518638611\n",
      "Ep 8: Batch #12 - Loss: 1.6081796884536743\n",
      "Ep 8: Batch #13 - Loss: 0.680838406085968\n",
      "Ep 8: Batch #14 - Loss: 0.769779622554779\n",
      "Ep 8: Batch #15 - Loss: 1.3085482120513916\n",
      "Ep 8: Batch #16 - Loss: 1.3542656898498535\n",
      "Ep 8: Batch #17 - Loss: 0.9346894025802612\n",
      "Ep 8: Batch #18 - Loss: 0.9805036187171936\n",
      "Ep 8: Batch #19 - Loss: 0.7083261609077454\n",
      "Ep 8: Batch #20 - Loss: 0.7013257741928101\n",
      "Ep 8: Batch #21 - Loss: 1.267159104347229\n",
      "Ep 8: Batch #22 - Loss: 0.769399106502533\n",
      "Ep 8: Batch #23 - Loss: 0.7999556064605713\n",
      "Ep 8: Batch #24 - Loss: 0.8700716495513916\n",
      "Ep 8: Batch #25 - Loss: 0.7697572112083435\n",
      "Ep 8: Batch #26 - Loss: 0.7841869592666626\n",
      "Ep 8: Batch #27 - Loss: 1.4148013591766357\n",
      "Ep 8: Batch #28 - Loss: 0.920377254486084\n",
      "Ep 8: Batch #29 - Loss: 0.9548285007476807\n",
      "Ep 8: Batch #30 - Loss: 1.2689889669418335\n",
      "Ep 8: Batch #31 - Loss: 0.7105076313018799\n",
      "Ep 8: Batch #32 - Loss: 0.7985354065895081\n",
      "Ep 8: Batch #33 - Loss: 0.8549996614456177\n",
      "Ep 8: Batch #34 - Loss: 0.8336846828460693\n",
      "Ep 8: Batch #35 - Loss: 1.0154402256011963\n",
      "Ep 8: Batch #36 - Loss: 0.7477200627326965\n",
      "Ep 8: Batch #37 - Loss: 1.1949654817581177\n",
      "Ep 8: Batch #38 - Loss: 0.8032724261283875\n",
      "Ep 8: Batch #39 - Loss: 0.8597650527954102\n",
      "Ep 8: Batch #40 - Loss: 0.8292326331138611\n",
      "Ep 8: Batch #41 - Loss: 0.785950243473053\n",
      "Ep 8: Batch #42 - Loss: 0.7654610872268677\n",
      "Ep 8: Batch #43 - Loss: 0.8378595113754272\n",
      "Ep 8: Batch #44 - Loss: 0.8338046669960022\n",
      "Ep 8: Batch #45 - Loss: 0.6882809996604919\n",
      "Ep 8: Batch #46 - Loss: 0.8865694403648376\n",
      "Ep 8: Batch #47 - Loss: 1.02934992313385\n",
      "Ep 8: Batch #48 - Loss: 1.4293397665023804\n",
      "Ep 8: Batch #49 - Loss: 1.070312738418579\n",
      "Ep 8: Batch #50 - Loss: 0.7440223097801208\n",
      "Ep 8: Batch #51 - Loss: 1.0589853525161743\n",
      "Ep 8: Batch #52 - Loss: 0.8353304266929626\n",
      "Ep 8: Batch #53 - Loss: 0.8729872703552246\n",
      "Ep 8: Batch #54 - Loss: 0.7487969398498535\n",
      "Ep 8: Batch #55 - Loss: 0.8070448040962219\n",
      "Ep 8: Batch #56 - Loss: 1.327707290649414\n",
      "Ep 8: Batch #57 - Loss: 0.9137334823608398\n",
      "Ep 8: Batch #58 - Loss: 1.0655332803726196\n",
      "Ep 8: Batch #59 - Loss: 0.723442554473877\n",
      "Ep 8: Batch #60 - Loss: 1.3806082010269165\n",
      "Ep 8: Batch #61 - Loss: 0.6812422275543213\n",
      "Ep 8: Batch #62 - Loss: 0.7756941318511963\n",
      "Ep 8: Batch #63 - Loss: 1.0709971189498901\n",
      "Ep 8: Batch #64 - Loss: 9.47900676727295\n",
      "Ep 8: Batch #65 - Loss: 0.6507745385169983\n",
      "Ep 8: Batch #66 - Loss: 0.8594347238540649\n",
      "Ep 8: Batch #67 - Loss: 0.9642036557197571\n",
      "Ep 8: Batch #68 - Loss: 0.9653624296188354\n",
      "Ep 8: Batch #69 - Loss: 0.7971890568733215\n",
      "Ep 8: Batch #70 - Loss: 0.8417986631393433\n",
      "Ep 8: Batch #71 - Loss: 0.7249785661697388\n",
      "Ep 8: Batch #72 - Loss: 0.9087609648704529\n",
      "Ep 8: Batch #73 - Loss: 0.966235339641571\n",
      "Ep 8: Batch #74 - Loss: 0.7896149158477783\n",
      "Ep 8: Batch #75 - Loss: 0.8131599426269531\n",
      "Ep 8: Batch #76 - Loss: 1.143705129623413\n",
      "Ep 8: Batch #77 - Loss: 0.7843545079231262\n",
      "Ep 8: Batch #78 - Loss: 1.2289236783981323\n",
      "Ep 8: Batch #79 - Loss: 0.6741021871566772\n",
      "Ep 8: Batch #80 - Loss: 0.9209321737289429\n",
      "Ep 8: Batch #81 - Loss: 1.7311309576034546\n",
      "Ep 8: Batch #82 - Loss: 0.9273949265480042\n",
      "Ep 8: Batch #83 - Loss: 1.7832448482513428\n",
      "Ep 8: Batch #84 - Loss: 0.7649538516998291\n",
      "Ep 8: Batch #85 - Loss: 1.025882363319397\n",
      "Ep 8: Batch #86 - Loss: 0.763270914554596\n",
      "Ep 8: Batch #87 - Loss: 0.7615294456481934\n",
      "Ep 8: Batch #88 - Loss: 0.8578227162361145\n",
      "Ep 8: Batch #89 - Loss: 0.9206044673919678\n",
      "Ep 8: Batch #90 - Loss: 1.2313662767410278\n",
      "Ep 8: Batch #91 - Loss: 0.8593880534172058\n",
      "Ep 8: Batch #92 - Loss: 1.09256911277771\n",
      "Ep 8: Batch #93 - Loss: 1.1026287078857422\n",
      "Ep 8: Batch #94 - Loss: 1.1110643148422241\n",
      "Ep 8: Batch #95 - Loss: 0.9801653623580933\n",
      "Ep 8: Batch #96 - Loss: 0.9572580456733704\n",
      "Ep 8: Batch #97 - Loss: 0.7796643376350403\n",
      "Ep 8: Batch #98 - Loss: 0.7916278839111328\n",
      "Ep 8: Batch #99 - Loss: 1.0087482929229736\n",
      "Ep 8: Batch #100 - Loss: 0.7273678779602051\n",
      "Ep 8: Batch #101 - Loss: 1.1041065454483032\n",
      "Ep 8: Batch #102 - Loss: 0.8298166394233704\n",
      "Ep 8: Batch #103 - Loss: 0.8341829180717468\n",
      "Ep 8: Batch #104 - Loss: 0.8543674945831299\n",
      "Ep 8: Batch #105 - Loss: 1.0863990783691406\n",
      "Ep 8: Batch #106 - Loss: 0.8049943447113037\n",
      "Ep 8: Batch #107 - Loss: 0.8145619630813599\n",
      "Ep 8: Batch #108 - Loss: 1.0974695682525635\n",
      "Ep 8: Batch #109 - Loss: 0.8066670894622803\n",
      "Ep 8: Batch #110 - Loss: 0.9811822175979614\n",
      "Ep 8: Batch #111 - Loss: 1.441465973854065\n",
      "Ep 8: Batch #112 - Loss: 1.1166760921478271\n",
      "Ep 8: Batch #113 - Loss: 0.8700541853904724\n",
      "Ep 8: Batch #114 - Loss: 0.9587964415550232\n",
      "Ep 8: Batch #115 - Loss: 1.1502851247787476\n",
      "Ep 8: Batch #116 - Loss: 0.6679623126983643\n",
      "Ep 8: Batch #117 - Loss: 0.9227091670036316\n",
      "Ep 8: Batch #118 - Loss: 0.5908411741256714\n",
      "Model saved in file: ./weights_autoencoder_low_LR/model_e8b118_1516651269.682102.ckpt\n",
      "Ep 8: Batch #119 - Loss: 1.082751750946045\n",
      "Ep 8: Batch #120 - Loss: 0.8399084806442261\n",
      "Ep 8: Batch #121 - Loss: 0.7344164848327637\n",
      "Ep 8: Batch #122 - Loss: 0.8793915510177612\n",
      "Ep 8: Batch #123 - Loss: 0.8800727725028992\n",
      "Ep 8: Batch #124 - Loss: 0.7026243805885315\n",
      "Ep 8: Batch #125 - Loss: 2.785485029220581\n",
      "Ep 8: Batch #126 - Loss: 1.2889513969421387\n",
      "Ep 8: Batch #127 - Loss: 0.8087606430053711\n",
      "Ep 8: Batch #128 - Loss: 1.1777305603027344\n",
      "Ep 8: Batch #129 - Loss: 0.8951589465141296\n",
      "Ep 8: Batch #130 - Loss: 0.7765123248100281\n",
      "Ep 8: Batch #131 - Loss: 1.068084478378296\n",
      "Ep 8: Batch #132 - Loss: 0.8817152976989746\n",
      "Ep 8: Batch #133 - Loss: 0.8703851103782654\n",
      "Ep 8: Batch #134 - Loss: 0.819892406463623\n",
      "Ep 8: Batch #135 - Loss: 1.028931975364685\n",
      "Ep 8: Batch #136 - Loss: 1.2492328882217407\n",
      "Ep 8: Batch #137 - Loss: 1.024780511856079\n",
      "Ep 8: Batch #138 - Loss: 1.1258916854858398\n",
      "Ep 8: Batch #139 - Loss: 0.9606979489326477\n",
      "Ep 8: Batch #140 - Loss: 1.1055541038513184\n",
      "Ep 8: Batch #141 - Loss: 1.415470004081726\n",
      "Ep 8: Batch #142 - Loss: 0.8405290842056274\n",
      "Ep 8: Batch #143 - Loss: 1.0347741842269897\n",
      "Ep 8: Batch #144 - Loss: 0.7726256251335144\n",
      "Ep 8: Batch #145 - Loss: 0.7214941382408142\n",
      "Ep 8: Batch #146 - Loss: 0.9304495453834534\n",
      "Ep 8: Batch #147 - Loss: 0.9243001937866211\n",
      "Ep 8: Batch #148 - Loss: 1.0372167825698853\n",
      "Ep 8: Batch #149 - Loss: 0.9139124155044556\n",
      "Ep 8: Batch #150 - Loss: 0.9283736944198608\n",
      "Ep 8: Batch #151 - Loss: 0.7640692591667175\n",
      "Ep 8: Batch #152 - Loss: 0.7808825373649597\n",
      "Ep 8: Batch #153 - Loss: 1.1686826944351196\n",
      "Ep 8: Batch #154 - Loss: 0.8057755827903748\n",
      "Ep 8: Batch #155 - Loss: 0.8918885588645935\n",
      "Ep 8: Batch #156 - Loss: 1.0758296251296997\n",
      "Ep 8: Batch #157 - Loss: 0.8082535266876221\n",
      "Ep 8: Batch #158 - Loss: 0.8494373559951782\n",
      "Ep 8: Batch #159 - Loss: 0.8609434962272644\n",
      "Ep 8: Batch #160 - Loss: 0.9488221406936646\n",
      "Ep 8: Batch #161 - Loss: 0.867416501045227\n",
      "Ep 8: Batch #162 - Loss: 0.988119900226593\n",
      "Ep 8: Batch #163 - Loss: 0.9754604697227478\n",
      "Ep 8: Batch #164 - Loss: 0.8317846059799194\n",
      "Ep 8: Batch #165 - Loss: 1.549353837966919\n",
      "Ep 8: Batch #166 - Loss: 0.7318539023399353\n",
      "Ep 8: Batch #167 - Loss: 1.1420114040374756\n",
      "Ep 8: Batch #168 - Loss: 0.9162580966949463\n",
      "Ep 8: Batch #169 - Loss: 0.8518289923667908\n",
      "Ep 8: Batch #170 - Loss: 0.8538011908531189\n",
      "Ep 8: Batch #171 - Loss: 0.837530255317688\n",
      "Ep 8: Batch #172 - Loss: 0.6718789339065552\n",
      "Ep 8: Batch #173 - Loss: 1.2696274518966675\n",
      "Ep 8: Batch #174 - Loss: 0.6222513914108276\n",
      "Ep 8: Batch #175 - Loss: 0.8222864270210266\n",
      "Ep 8: Batch #176 - Loss: 1.2104454040527344\n",
      "Ep 8: Batch #177 - Loss: 0.9000319838523865\n",
      "Ep 8: Batch #178 - Loss: 0.8173844814300537\n",
      "Ep 8: Batch #179 - Loss: 1.0021899938583374\n",
      "Ep 8: Batch #180 - Loss: 0.9208330512046814\n",
      "Ep 8: Batch #181 - Loss: 1.0583888292312622\n",
      "Ep 8: Batch #182 - Loss: 0.8100571632385254\n",
      "Ep 8: Batch #183 - Loss: 0.8158979415893555\n",
      "Ep 8: Batch #184 - Loss: 1.116613507270813\n",
      "Ep 8: Batch #185 - Loss: 0.8031116127967834\n",
      "Ep 8: Batch #186 - Loss: 1.0324605703353882\n",
      "Ep 8: Batch #187 - Loss: 1.224610686302185\n",
      "Ep 8: Batch #188 - Loss: 1.4082863330841064\n",
      "Ep 8: Batch #189 - Loss: 0.7371605634689331\n",
      "Ep 8: Batch #190 - Loss: 0.784784197807312\n",
      "Ep 8: Batch #191 - Loss: 1.1162467002868652\n",
      "Ep 8: Batch #192 - Loss: 0.7072758674621582\n",
      "Ep 8: Batch #193 - Loss: 0.7922878265380859\n",
      "Ep 8: Batch #194 - Loss: 0.7437006831169128\n",
      "Ep 8: Batch #195 - Loss: 1.0373501777648926\n",
      "Ep 8: Batch #196 - Loss: 0.9162374138832092\n",
      "Ep 8: Batch #197 - Loss: 0.9543289542198181\n",
      "Ep 8: Batch #198 - Loss: 0.7253878712654114\n",
      "Ep 8: Batch #199 - Loss: 0.9158467650413513\n",
      "Ep 9: Batch #0 - Loss: 0.849844217300415\n",
      "Ep 9: Batch #1 - Loss: 0.932918906211853\n",
      "Ep 9: Batch #2 - Loss: 1.051257848739624\n",
      "Ep 9: Batch #3 - Loss: 0.9178438186645508\n",
      "Ep 9: Batch #4 - Loss: 0.8431171774864197\n",
      "Ep 9: Batch #5 - Loss: 0.7076290249824524\n",
      "Ep 9: Batch #6 - Loss: 0.9337440133094788\n",
      "Ep 9: Batch #7 - Loss: 0.7456216812133789\n",
      "Ep 9: Batch #8 - Loss: 0.7784903645515442\n",
      "Ep 9: Batch #9 - Loss: 1.470548391342163\n",
      "Ep 9: Batch #10 - Loss: 1.0665161609649658\n",
      "Ep 9: Batch #11 - Loss: 0.7176957726478577\n",
      "Ep 9: Batch #12 - Loss: 1.606355905532837\n",
      "Ep 9: Batch #13 - Loss: 0.6798596382141113\n",
      "Ep 9: Batch #14 - Loss: 0.7684637308120728\n",
      "Ep 9: Batch #15 - Loss: 1.3063513040542603\n",
      "Ep 9: Batch #16 - Loss: 1.3522276878356934\n",
      "Ep 9: Batch #17 - Loss: 0.9333121180534363\n",
      "Ep 9: Batch #18 - Loss: 0.9793015122413635\n",
      "Ep 9: Batch #19 - Loss: 0.7071182131767273\n",
      "Ep 9: Batch #20 - Loss: 0.6999090313911438\n",
      "Ep 9: Batch #21 - Loss: 1.2655613422393799\n",
      "Ep 9: Batch #22 - Loss: 0.7679811716079712\n",
      "Ep 9: Batch #23 - Loss: 0.798471987247467\n",
      "Ep 9: Batch #24 - Loss: 0.8683162331581116\n",
      "Ep 9: Batch #25 - Loss: 0.7681975364685059\n",
      "Ep 9: Batch #26 - Loss: 0.7829452753067017\n",
      "Ep 9: Batch #27 - Loss: 1.4132746458053589\n",
      "Ep 9: Batch #28 - Loss: 0.9188473224639893\n",
      "Ep 9: Batch #29 - Loss: 0.9532417058944702\n",
      "Ep 9: Batch #30 - Loss: 1.2672938108444214\n",
      "Ep 9: Batch #31 - Loss: 0.7093442678451538\n",
      "Ep 9: Batch #32 - Loss: 0.7970690727233887\n",
      "Ep 9: Batch #33 - Loss: 0.8535091876983643\n",
      "Ep 9: Batch #34 - Loss: 0.8322609066963196\n",
      "Ep 9: Batch #35 - Loss: 1.0136618614196777\n",
      "Ep 9: Batch #36 - Loss: 0.7464079856872559\n",
      "Ep 9: Batch #37 - Loss: 1.1935163736343384\n",
      "Ep 9: Batch #38 - Loss: 0.801748514175415\n",
      "Ep 9: Batch #39 - Loss: 0.8585975170135498\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 9: Batch #40 - Loss: 0.8276094794273376\n",
      "Ep 9: Batch #41 - Loss: 0.7848094701766968\n",
      "Ep 9: Batch #42 - Loss: 0.7642462253570557\n",
      "Ep 9: Batch #43 - Loss: 0.8364421129226685\n",
      "Ep 9: Batch #44 - Loss: 0.8324617743492126\n",
      "Ep 9: Batch #45 - Loss: 0.6868783235549927\n",
      "Ep 9: Batch #46 - Loss: 0.8850847482681274\n",
      "Ep 9: Batch #47 - Loss: 1.0276703834533691\n",
      "Ep 9: Batch #48 - Loss: 1.4270679950714111\n",
      "Ep 9: Batch #49 - Loss: 1.0687546730041504\n",
      "Ep 9: Batch #50 - Loss: 0.7427230477333069\n",
      "Ep 9: Batch #51 - Loss: 1.057366967201233\n",
      "Ep 9: Batch #52 - Loss: 0.8341093063354492\n",
      "Ep 9: Batch #53 - Loss: 0.8717352747917175\n",
      "Ep 9: Batch #54 - Loss: 0.7473853230476379\n",
      "Ep 9: Batch #55 - Loss: 0.8055645227432251\n",
      "Ep 9: Batch #56 - Loss: 1.3252716064453125\n",
      "Ep 9: Batch #57 - Loss: 0.9117651581764221\n",
      "Ep 9: Batch #58 - Loss: 1.0635570287704468\n",
      "Ep 9: Batch #59 - Loss: 0.7221449613571167\n",
      "Ep 9: Batch #60 - Loss: 1.3775932788848877\n",
      "Ep 9: Batch #61 - Loss: 0.6797824501991272\n",
      "Ep 9: Batch #62 - Loss: 0.7742419242858887\n",
      "Ep 9: Batch #63 - Loss: 1.0691059827804565\n",
      "Ep 9: Batch #64 - Loss: 9.477814674377441\n",
      "Ep 9: Batch #65 - Loss: 0.6496561765670776\n",
      "Ep 9: Batch #66 - Loss: 0.8577309846878052\n",
      "Ep 9: Batch #67 - Loss: 0.9625300168991089\n",
      "Ep 9: Batch #68 - Loss: 0.9639851450920105\n",
      "Ep 9: Batch #69 - Loss: 0.7956884503364563\n",
      "Ep 9: Batch #70 - Loss: 0.8398712873458862\n",
      "Ep 9: Batch #71 - Loss: 0.7235852479934692\n",
      "Ep 9: Batch #72 - Loss: 0.9073743224143982\n",
      "Ep 9: Batch #73 - Loss: 0.9647305011749268\n",
      "Ep 9: Batch #74 - Loss: 0.7883405685424805\n",
      "Ep 9: Batch #75 - Loss: 0.812001645565033\n",
      "Ep 9: Batch #76 - Loss: 1.1424248218536377\n",
      "Ep 9: Batch #77 - Loss: 0.7827597260475159\n",
      "Ep 9: Batch #78 - Loss: 1.227001428604126\n",
      "Ep 9: Batch #79 - Loss: 0.6726433634757996\n",
      "Ep 9: Batch #80 - Loss: 0.9192649126052856\n",
      "Ep 9: Batch #81 - Loss: 1.7299386262893677\n",
      "Ep 9: Batch #82 - Loss: 0.9257773160934448\n",
      "Ep 9: Batch #83 - Loss: 1.7819716930389404\n",
      "Ep 9: Batch #84 - Loss: 0.7636256217956543\n",
      "Ep 9: Batch #85 - Loss: 1.0243244171142578\n",
      "Ep 9: Batch #86 - Loss: 0.761936604976654\n",
      "Ep 9: Batch #87 - Loss: 0.7597857713699341\n",
      "Ep 9: Batch #88 - Loss: 0.8561830520629883\n",
      "Ep 9: Batch #89 - Loss: 0.9194416403770447\n",
      "Ep 9: Batch #90 - Loss: 1.2295223474502563\n",
      "Ep 9: Batch #91 - Loss: 0.8578732013702393\n",
      "Ep 9: Batch #92 - Loss: 1.0907703638076782\n",
      "Ep 9: Batch #93 - Loss: 1.1003966331481934\n",
      "Ep 9: Batch #94 - Loss: 1.109452247619629\n",
      "Ep 9: Batch #95 - Loss: 0.9783958196640015\n",
      "Ep 9: Batch #96 - Loss: 0.9556789994239807\n",
      "Ep 9: Batch #97 - Loss: 0.7783161401748657\n",
      "Ep 9: Batch #98 - Loss: 0.7902087569236755\n",
      "Ep 9: Batch #99 - Loss: 1.0073528289794922\n",
      "Ep 9: Batch #100 - Loss: 0.7260695099830627\n",
      "Ep 9: Batch #101 - Loss: 1.102595567703247\n",
      "Ep 9: Batch #102 - Loss: 0.8285074234008789\n",
      "Ep 9: Batch #103 - Loss: 0.8332261443138123\n",
      "Ep 9: Batch #104 - Loss: 0.852851152420044\n",
      "Ep 9: Batch #105 - Loss: 1.0849167108535767\n",
      "Ep 9: Batch #106 - Loss: 0.8039402961730957\n",
      "Ep 9: Batch #107 - Loss: 0.8128431439399719\n",
      "Ep 9: Batch #108 - Loss: 1.095801591873169\n",
      "Ep 9: Batch #109 - Loss: 0.8054113984107971\n",
      "Ep 9: Batch #110 - Loss: 0.9796189069747925\n",
      "Ep 9: Batch #111 - Loss: 1.439956545829773\n",
      "Ep 9: Batch #112 - Loss: 1.1145572662353516\n",
      "Ep 9: Batch #113 - Loss: 0.8686180114746094\n",
      "Ep 9: Batch #114 - Loss: 0.9573708176612854\n",
      "Ep 9: Batch #115 - Loss: 1.1486393213272095\n",
      "Ep 9: Batch #116 - Loss: 0.6667519807815552\n",
      "Ep 9: Batch #117 - Loss: 0.9212048053741455\n",
      "Ep 9: Batch #118 - Loss: 0.5894901156425476\n",
      "Model saved in file: ./weights_autoencoder_low_LR/model_e9b118_1516651269.822512.ckpt\n",
      "Ep 9: Batch #119 - Loss: 1.0810717344284058\n",
      "Ep 9: Batch #120 - Loss: 0.8388836979866028\n",
      "Ep 9: Batch #121 - Loss: 0.7330506443977356\n",
      "Ep 9: Batch #122 - Loss: 0.8776735663414001\n",
      "Ep 9: Batch #123 - Loss: 0.8786811828613281\n",
      "Ep 9: Batch #124 - Loss: 0.7013616561889648\n",
      "Ep 9: Batch #125 - Loss: 2.7837018966674805\n",
      "Ep 9: Batch #126 - Loss: 1.2870519161224365\n",
      "Ep 9: Batch #127 - Loss: 0.8071314096450806\n",
      "Ep 9: Batch #128 - Loss: 1.1755530834197998\n",
      "Ep 9: Batch #129 - Loss: 0.8937106728553772\n",
      "Ep 9: Batch #130 - Loss: 0.7749888896942139\n",
      "Ep 9: Batch #131 - Loss: 1.066044569015503\n",
      "Ep 9: Batch #132 - Loss: 0.8803313374519348\n",
      "Ep 9: Batch #133 - Loss: 0.8688433170318604\n",
      "Ep 9: Batch #134 - Loss: 0.8188266158103943\n",
      "Ep 9: Batch #135 - Loss: 1.0273014307022095\n",
      "Ep 9: Batch #136 - Loss: 1.2478113174438477\n",
      "Ep 9: Batch #137 - Loss: 1.0232148170471191\n",
      "Ep 9: Batch #138 - Loss: 1.124375581741333\n",
      "Ep 9: Batch #139 - Loss: 0.9589964151382446\n",
      "Ep 9: Batch #140 - Loss: 1.1041145324707031\n",
      "Ep 9: Batch #141 - Loss: 1.4141082763671875\n",
      "Ep 9: Batch #142 - Loss: 0.8392913341522217\n",
      "Ep 9: Batch #143 - Loss: 1.032904028892517\n",
      "Ep 9: Batch #144 - Loss: 0.7711605429649353\n",
      "Ep 9: Batch #145 - Loss: 0.720313310623169\n",
      "Ep 9: Batch #146 - Loss: 0.9291886687278748\n",
      "Ep 9: Batch #147 - Loss: 0.9227730631828308\n",
      "Ep 9: Batch #148 - Loss: 1.035767912864685\n",
      "Ep 9: Batch #149 - Loss: 0.9123672246932983\n",
      "Ep 9: Batch #150 - Loss: 0.9272758364677429\n",
      "Ep 9: Batch #151 - Loss: 0.7629762887954712\n",
      "Ep 9: Batch #152 - Loss: 0.7796275019645691\n",
      "Ep 9: Batch #153 - Loss: 1.1667534112930298\n",
      "Ep 9: Batch #154 - Loss: 0.8047155141830444\n",
      "Ep 9: Batch #155 - Loss: 0.8902673125267029\n",
      "Ep 9: Batch #156 - Loss: 1.074378252029419\n",
      "Ep 9: Batch #157 - Loss: 0.8070316314697266\n",
      "Ep 9: Batch #158 - Loss: 0.8479506373405457\n",
      "Ep 9: Batch #159 - Loss: 0.8595253229141235\n",
      "Ep 9: Batch #160 - Loss: 0.9476722478866577\n",
      "Ep 9: Batch #161 - Loss: 0.866020917892456\n",
      "Ep 9: Batch #162 - Loss: 0.9865737557411194\n",
      "Ep 9: Batch #163 - Loss: 0.9741709232330322\n",
      "Ep 9: Batch #164 - Loss: 0.8306375741958618\n",
      "Ep 9: Batch #165 - Loss: 1.5479599237442017\n",
      "Ep 9: Batch #166 - Loss: 0.7304290533065796\n",
      "Ep 9: Batch #167 - Loss: 1.1404653787612915\n",
      "Ep 9: Batch #168 - Loss: 0.9149438738822937\n",
      "Ep 9: Batch #169 - Loss: 0.8505099415779114\n",
      "Ep 9: Batch #170 - Loss: 0.8525001406669617\n",
      "Ep 9: Batch #171 - Loss: 0.835911214351654\n",
      "Ep 9: Batch #172 - Loss: 0.6708152890205383\n",
      "Ep 9: Batch #173 - Loss: 1.2678121328353882\n",
      "Ep 9: Batch #174 - Loss: 0.6209069490432739\n",
      "Ep 9: Batch #175 - Loss: 0.821015477180481\n",
      "Ep 9: Batch #176 - Loss: 1.209152102470398\n",
      "Ep 9: Batch #177 - Loss: 0.8986964225769043\n",
      "Ep 9: Batch #178 - Loss: 0.815991222858429\n",
      "Ep 9: Batch #179 - Loss: 1.0005521774291992\n",
      "Ep 9: Batch #180 - Loss: 0.9193551540374756\n",
      "Ep 9: Batch #181 - Loss: 1.0565754175186157\n",
      "Ep 9: Batch #182 - Loss: 0.808596670627594\n",
      "Ep 9: Batch #183 - Loss: 0.814585268497467\n",
      "Ep 9: Batch #184 - Loss: 1.115422248840332\n",
      "Ep 9: Batch #185 - Loss: 0.8019359707832336\n",
      "Ep 9: Batch #186 - Loss: 1.0309550762176514\n",
      "Ep 9: Batch #187 - Loss: 1.2226403951644897\n",
      "Ep 9: Batch #188 - Loss: 1.4065276384353638\n",
      "Ep 9: Batch #189 - Loss: 0.7360624074935913\n",
      "Ep 9: Batch #190 - Loss: 0.7832445502281189\n",
      "Ep 9: Batch #191 - Loss: 1.1146631240844727\n",
      "Ep 9: Batch #192 - Loss: 0.7060964107513428\n",
      "Ep 9: Batch #193 - Loss: 0.7908047437667847\n",
      "Ep 9: Batch #194 - Loss: 0.7423925995826721\n",
      "Ep 9: Batch #195 - Loss: 1.0361039638519287\n",
      "Ep 9: Batch #196 - Loss: 0.9146689176559448\n",
      "Ep 9: Batch #197 - Loss: 0.9525983929634094\n",
      "Ep 9: Batch #198 - Loss: 0.7241286039352417\n",
      "Ep 9: Batch #199 - Loss: 0.914268970489502\n",
      "Ep 10: Batch #0 - Loss: 0.848440945148468\n",
      "Ep 10: Batch #1 - Loss: 0.9313322305679321\n",
      "Ep 10: Batch #2 - Loss: 1.050162434577942\n",
      "Ep 10: Batch #3 - Loss: 0.9161985516548157\n",
      "Ep 10: Batch #4 - Loss: 0.8416188359260559\n",
      "Ep 10: Batch #5 - Loss: 0.7063059210777283\n",
      "Ep 10: Batch #6 - Loss: 0.931726336479187\n",
      "Ep 10: Batch #7 - Loss: 0.7442606687545776\n",
      "Ep 10: Batch #8 - Loss: 0.7769795656204224\n",
      "Ep 10: Batch #9 - Loss: 1.4686440229415894\n",
      "Ep 10: Batch #10 - Loss: 1.0649224519729614\n",
      "Ep 10: Batch #11 - Loss: 0.7161026000976562\n",
      "Ep 10: Batch #12 - Loss: 1.604905605316162\n",
      "Ep 10: Batch #13 - Loss: 0.678947389125824\n",
      "Ep 10: Batch #14 - Loss: 0.767208456993103\n",
      "Ep 10: Batch #15 - Loss: 1.304208755493164\n",
      "Ep 10: Batch #16 - Loss: 1.350249171257019\n",
      "Ep 10: Batch #17 - Loss: 0.9319605231285095\n",
      "Ep 10: Batch #18 - Loss: 0.9781824946403503\n",
      "Ep 10: Batch #19 - Loss: 0.7059505581855774\n",
      "Ep 10: Batch #20 - Loss: 0.6985425353050232\n",
      "Ep 10: Batch #21 - Loss: 1.264047384262085\n",
      "Ep 10: Batch #22 - Loss: 0.7665953636169434\n",
      "Ep 10: Batch #23 - Loss: 0.7970010638237\n",
      "Ep 10: Batch #24 - Loss: 0.8666980266571045\n",
      "Ep 10: Batch #25 - Loss: 0.7666723132133484\n",
      "Ep 10: Batch #26 - Loss: 0.781731367111206\n",
      "Ep 10: Batch #27 - Loss: 1.4118343591690063\n",
      "Ep 10: Batch #28 - Loss: 0.9173204302787781\n",
      "Ep 10: Batch #29 - Loss: 0.9516729712486267\n",
      "Ep 10: Batch #30 - Loss: 1.2656376361846924\n",
      "Ep 10: Batch #31 - Loss: 0.7082141637802124\n",
      "Ep 10: Batch #32 - Loss: 0.7956202626228333\n",
      "Ep 10: Batch #33 - Loss: 0.8519951105117798\n",
      "Ep 10: Batch #34 - Loss: 0.8308446407318115\n",
      "Ep 10: Batch #35 - Loss: 1.011916160583496\n",
      "Ep 10: Batch #36 - Loss: 0.7451189756393433\n",
      "Ep 10: Batch #37 - Loss: 1.1920206546783447\n",
      "Ep 10: Batch #38 - Loss: 0.8002323508262634\n",
      "Ep 10: Batch #39 - Loss: 0.8574654459953308\n",
      "Ep 10: Batch #40 - Loss: 0.8260352611541748\n",
      "Ep 10: Batch #41 - Loss: 0.7836982607841492\n",
      "Ep 10: Batch #42 - Loss: 0.7630779147148132\n",
      "Ep 10: Batch #43 - Loss: 0.8350298404693604\n",
      "Ep 10: Batch #44 - Loss: 0.8311164975166321\n",
      "Ep 10: Batch #45 - Loss: 0.6855174899101257\n",
      "Ep 10: Batch #46 - Loss: 0.8836425542831421\n",
      "Ep 10: Batch #47 - Loss: 1.0260077714920044\n",
      "Ep 10: Batch #48 - Loss: 1.424668312072754\n",
      "Ep 10: Batch #49 - Loss: 1.0672109127044678\n",
      "Ep 10: Batch #50 - Loss: 0.7415075898170471\n",
      "Ep 10: Batch #51 - Loss: 1.0557832717895508\n",
      "Ep 10: Batch #52 - Loss: 0.832956075668335\n",
      "Ep 10: Batch #53 - Loss: 0.8704701662063599\n",
      "Ep 10: Batch #54 - Loss: 0.7460079193115234\n",
      "Ep 10: Batch #55 - Loss: 0.8041141033172607\n",
      "Ep 10: Batch #56 - Loss: 1.3230462074279785\n",
      "Ep 10: Batch #57 - Loss: 0.909818708896637\n",
      "Ep 10: Batch #58 - Loss: 1.0616565942764282\n",
      "Ep 10: Batch #59 - Loss: 0.7209104299545288\n",
      "Ep 10: Batch #60 - Loss: 1.3747035264968872\n",
      "Ep 10: Batch #61 - Loss: 0.6784290075302124\n",
      "Ep 10: Batch #62 - Loss: 0.772823691368103\n",
      "Ep 10: Batch #63 - Loss: 1.0672309398651123\n",
      "Ep 10: Batch #64 - Loss: 9.47665023803711\n",
      "Ep 10: Batch #65 - Loss: 0.6485809087753296\n",
      "Ep 10: Batch #66 - Loss: 0.8560644388198853\n",
      "Ep 10: Batch #67 - Loss: 0.9608922004699707\n",
      "Ep 10: Batch #68 - Loss: 0.962597668170929\n",
      "Ep 10: Batch #69 - Loss: 0.7942352294921875\n",
      "Ep 10: Batch #70 - Loss: 0.8379749655723572\n",
      "Ep 10: Batch #71 - Loss: 0.7222586870193481\n",
      "Ep 10: Batch #72 - Loss: 0.9060154557228088\n",
      "Ep 10: Batch #73 - Loss: 0.963200032711029\n",
      "Ep 10: Batch #74 - Loss: 0.7870985269546509\n",
      "Ep 10: Batch #75 - Loss: 0.8108861446380615\n",
      "Ep 10: Batch #76 - Loss: 1.141172170639038\n",
      "Ep 10: Batch #77 - Loss: 0.7812245488166809\n",
      "Ep 10: Batch #78 - Loss: 1.2250574827194214\n",
      "Ep 10: Batch #79 - Loss: 0.6712380051612854\n",
      "Ep 10: Batch #80 - Loss: 0.9176311492919922\n",
      "Ep 10: Batch #81 - Loss: 1.7287975549697876\n",
      "Ep 10: Batch #82 - Loss: 0.9242404103279114\n",
      "Ep 10: Batch #83 - Loss: 1.7807132005691528\n",
      "Ep 10: Batch #84 - Loss: 0.7623291015625\n",
      "Ep 10: Batch #85 - Loss: 1.0228030681610107\n",
      "Ep 10: Batch #86 - Loss: 0.7606161832809448\n",
      "Ep 10: Batch #87 - Loss: 0.7581385374069214\n",
      "Ep 10: Batch #88 - Loss: 0.8545779585838318\n",
      "Ep 10: Batch #89 - Loss: 0.9182940125465393\n",
      "Ep 10: Batch #90 - Loss: 1.2276581525802612\n",
      "Ep 10: Batch #91 - Loss: 0.8563835620880127\n",
      "Ep 10: Batch #92 - Loss: 1.089038610458374\n",
      "Ep 10: Batch #93 - Loss: 1.0982012748718262\n",
      "Ep 10: Batch #94 - Loss: 1.1078951358795166\n",
      "Ep 10: Batch #95 - Loss: 0.9766446948051453\n",
      "Ep 10: Batch #96 - Loss: 0.9541506767272949\n",
      "Ep 10: Batch #97 - Loss: 0.7769834995269775\n",
      "Ep 10: Batch #98 - Loss: 0.788828432559967\n",
      "Ep 10: Batch #99 - Loss: 1.0059940814971924\n",
      "Ep 10: Batch #100 - Loss: 0.7248103022575378\n",
      "Ep 10: Batch #101 - Loss: 1.1010684967041016\n",
      "Ep 10: Batch #102 - Loss: 0.8271792531013489\n",
      "Ep 10: Batch #103 - Loss: 0.8322391510009766\n",
      "Ep 10: Batch #104 - Loss: 0.8513607978820801\n",
      "Ep 10: Batch #105 - Loss: 1.0834275484085083\n",
      "Ep 10: Batch #106 - Loss: 0.8029115796089172\n",
      "Ep 10: Batch #107 - Loss: 0.811150312423706\n",
      "Ep 10: Batch #108 - Loss: 1.094163417816162\n",
      "Ep 10: Batch #109 - Loss: 0.8042299151420593\n",
      "Ep 10: Batch #110 - Loss: 0.9781094789505005\n",
      "Ep 10: Batch #111 - Loss: 1.4384913444519043\n",
      "Ep 10: Batch #112 - Loss: 1.1124873161315918\n",
      "Ep 10: Batch #113 - Loss: 0.867201030254364\n",
      "Ep 10: Batch #114 - Loss: 0.9559804797172546\n",
      "Ep 10: Batch #115 - Loss: 1.1470606327056885\n",
      "Ep 10: Batch #116 - Loss: 0.6655786633491516\n",
      "Ep 10: Batch #117 - Loss: 0.919739305973053\n",
      "Ep 10: Batch #118 - Loss: 0.5881292819976807\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved in file: ./weights_autoencoder_low_LR/model_e10b118_1516651269.9613125.ckpt\n",
      "Ep 10: Batch #119 - Loss: 1.0794950723648071\n",
      "Ep 10: Batch #120 - Loss: 0.8378716707229614\n",
      "Ep 10: Batch #121 - Loss: 0.7317110300064087\n",
      "Ep 10: Batch #122 - Loss: 0.8759748339653015\n",
      "Ep 10: Batch #123 - Loss: 0.8773489594459534\n",
      "Ep 10: Batch #124 - Loss: 0.7001528143882751\n",
      "Ep 10: Batch #125 - Loss: 2.7818782329559326\n",
      "Ep 10: Batch #126 - Loss: 1.2851812839508057\n",
      "Ep 10: Batch #127 - Loss: 0.8054977059364319\n",
      "Ep 10: Batch #128 - Loss: 1.1733860969543457\n",
      "Ep 10: Batch #129 - Loss: 0.8922860026359558\n",
      "Ep 10: Batch #130 - Loss: 0.7735013961791992\n",
      "Ep 10: Batch #131 - Loss: 1.0640544891357422\n",
      "Ep 10: Batch #132 - Loss: 0.878896951675415\n",
      "Ep 10: Batch #133 - Loss: 0.8673275113105774\n",
      "Ep 10: Batch #134 - Loss: 0.8177269697189331\n",
      "Ep 10: Batch #135 - Loss: 1.0256333351135254\n",
      "Ep 10: Batch #136 - Loss: 1.2463539838790894\n",
      "Ep 10: Batch #137 - Loss: 1.0216598510742188\n",
      "Ep 10: Batch #138 - Loss: 1.1229139566421509\n",
      "Ep 10: Batch #139 - Loss: 0.9572824835777283\n",
      "Ep 10: Batch #140 - Loss: 1.1027005910873413\n",
      "Ep 10: Batch #141 - Loss: 1.4127730131149292\n",
      "Ep 10: Batch #142 - Loss: 0.8380919098854065\n",
      "Ep 10: Batch #143 - Loss: 1.0310382843017578\n",
      "Ep 10: Batch #144 - Loss: 0.769709050655365\n",
      "Ep 10: Batch #145 - Loss: 0.7191562056541443\n",
      "Ep 10: Batch #146 - Loss: 0.9279718995094299\n",
      "Ep 10: Batch #147 - Loss: 0.9212276935577393\n",
      "Ep 10: Batch #148 - Loss: 1.034324288368225\n",
      "Ep 10: Batch #149 - Loss: 0.9108494520187378\n",
      "Ep 10: Batch #150 - Loss: 0.9261805415153503\n",
      "Ep 10: Batch #151 - Loss: 0.7619151473045349\n",
      "Ep 10: Batch #152 - Loss: 0.7783896327018738\n",
      "Ep 10: Batch #153 - Loss: 1.1648695468902588\n",
      "Ep 10: Batch #154 - Loss: 0.8036578297615051\n",
      "Ep 10: Batch #155 - Loss: 0.8886337280273438\n",
      "Ep 10: Batch #156 - Loss: 1.0729279518127441\n",
      "Ep 10: Batch #157 - Loss: 0.8058246970176697\n",
      "Ep 10: Batch #158 - Loss: 0.8465179204940796\n",
      "Ep 10: Batch #159 - Loss: 0.8581419587135315\n",
      "Ep 10: Batch #160 - Loss: 0.9465628266334534\n",
      "Ep 10: Batch #161 - Loss: 0.86465984582901\n",
      "Ep 10: Batch #162 - Loss: 0.9850727915763855\n",
      "Ep 10: Batch #163 - Loss: 0.9728561043739319\n",
      "Ep 10: Batch #164 - Loss: 0.8295300006866455\n",
      "Ep 10: Batch #165 - Loss: 1.5465741157531738\n",
      "Ep 10: Batch #166 - Loss: 0.7290148735046387\n",
      "Ep 10: Batch #167 - Loss: 1.1389210224151611\n",
      "Ep 10: Batch #168 - Loss: 0.9136234521865845\n",
      "Ep 10: Batch #169 - Loss: 0.8491731286048889\n",
      "Ep 10: Batch #170 - Loss: 0.8512340784072876\n",
      "Ep 10: Batch #171 - Loss: 0.8343364000320435\n",
      "Ep 10: Batch #172 - Loss: 0.6697672009468079\n",
      "Ep 10: Batch #173 - Loss: 1.2659697532653809\n",
      "Ep 10: Batch #174 - Loss: 0.6195776462554932\n",
      "Ep 10: Batch #175 - Loss: 0.8197842836380005\n",
      "Ep 10: Batch #176 - Loss: 1.2078005075454712\n",
      "Ep 10: Batch #177 - Loss: 0.8973619341850281\n",
      "Ep 10: Batch #178 - Loss: 0.8146178722381592\n",
      "Ep 10: Batch #179 - Loss: 0.9989224672317505\n",
      "Ep 10: Batch #180 - Loss: 0.9178280830383301\n",
      "Ep 10: Batch #181 - Loss: 1.0548043251037598\n",
      "Ep 10: Batch #182 - Loss: 0.807103157043457\n",
      "Ep 10: Batch #183 - Loss: 0.8132850527763367\n",
      "Ep 10: Batch #184 - Loss: 1.114208459854126\n",
      "Ep 10: Batch #185 - Loss: 0.8007827997207642\n",
      "Ep 10: Batch #186 - Loss: 1.0295019149780273\n",
      "Ep 10: Batch #187 - Loss: 1.2207108736038208\n",
      "Ep 10: Batch #188 - Loss: 1.4047203063964844\n",
      "Ep 10: Batch #189 - Loss: 0.7350155115127563\n",
      "Ep 10: Batch #190 - Loss: 0.7817500233650208\n",
      "Ep 10: Batch #191 - Loss: 1.113161563873291\n",
      "Ep 10: Batch #192 - Loss: 0.7049558758735657\n",
      "Ep 10: Batch #193 - Loss: 0.7893646955490112\n",
      "Ep 10: Batch #194 - Loss: 0.741089940071106\n",
      "Ep 10: Batch #195 - Loss: 1.034837245941162\n",
      "Ep 10: Batch #196 - Loss: 0.9131594896316528\n",
      "Ep 10: Batch #197 - Loss: 0.950991690158844\n",
      "Ep 10: Batch #198 - Loss: 0.72288978099823\n",
      "Ep 10: Batch #199 - Loss: 0.9127436876296997\n",
      "Ep 11: Batch #0 - Loss: 0.8470588326454163\n",
      "Ep 11: Batch #1 - Loss: 0.9297605752944946\n",
      "Ep 11: Batch #2 - Loss: 1.049080729484558\n",
      "Ep 11: Batch #3 - Loss: 0.9145726561546326\n",
      "Ep 11: Batch #4 - Loss: 0.8401243686676025\n",
      "Ep 11: Batch #5 - Loss: 0.7050151228904724\n",
      "Ep 11: Batch #6 - Loss: 0.929777979850769\n",
      "Ep 11: Batch #7 - Loss: 0.7429093718528748\n",
      "Ep 11: Batch #8 - Loss: 0.7755525708198547\n",
      "Ep 11: Batch #9 - Loss: 1.4667571783065796\n",
      "Ep 11: Batch #10 - Loss: 1.0632984638214111\n",
      "Ep 11: Batch #11 - Loss: 0.7145534753799438\n",
      "Ep 11: Batch #12 - Loss: 1.6036357879638672\n",
      "Ep 11: Batch #13 - Loss: 0.6780722141265869\n",
      "Ep 11: Batch #14 - Loss: 0.7659804224967957\n",
      "Ep 11: Batch #15 - Loss: 1.3020246028900146\n",
      "Ep 11: Batch #16 - Loss: 1.3482695817947388\n",
      "Ep 11: Batch #17 - Loss: 0.9306274652481079\n",
      "Ep 11: Batch #18 - Loss: 0.9770990014076233\n",
      "Ep 11: Batch #19 - Loss: 0.7047972679138184\n",
      "Ep 11: Batch #20 - Loss: 0.697203516960144\n",
      "Ep 11: Batch #21 - Loss: 1.2625657320022583\n",
      "Ep 11: Batch #22 - Loss: 0.7652189135551453\n",
      "Ep 11: Batch #23 - Loss: 0.7955218553543091\n",
      "Ep 11: Batch #24 - Loss: 0.8651874661445618\n",
      "Ep 11: Batch #25 - Loss: 0.7651752233505249\n",
      "Ep 11: Batch #26 - Loss: 0.7805155515670776\n",
      "Ep 11: Batch #27 - Loss: 1.410400390625\n",
      "Ep 11: Batch #28 - Loss: 0.9157972931861877\n",
      "Ep 11: Batch #29 - Loss: 0.9500950574874878\n",
      "Ep 11: Batch #30 - Loss: 1.2639222145080566\n",
      "Ep 11: Batch #31 - Loss: 0.7071263790130615\n",
      "Ep 11: Batch #32 - Loss: 0.794186532497406\n",
      "Ep 11: Batch #33 - Loss: 0.8504972457885742\n",
      "Ep 11: Batch #34 - Loss: 0.829439640045166\n",
      "Ep 11: Batch #35 - Loss: 1.0101685523986816\n",
      "Ep 11: Batch #36 - Loss: 0.7438319325447083\n",
      "Ep 11: Batch #37 - Loss: 1.1904751062393188\n",
      "Ep 11: Batch #38 - Loss: 0.7987163662910461\n",
      "Ep 11: Batch #39 - Loss: 0.856357753276825\n",
      "Ep 11: Batch #40 - Loss: 0.8244682550430298\n",
      "Ep 11: Batch #41 - Loss: 0.7825942635536194\n",
      "Ep 11: Batch #42 - Loss: 0.7619383335113525\n",
      "Ep 11: Batch #43 - Loss: 0.833602249622345\n",
      "Ep 11: Batch #44 - Loss: 0.8297460675239563\n",
      "Ep 11: Batch #45 - Loss: 0.6841368675231934\n",
      "Ep 11: Batch #46 - Loss: 0.882178544998169\n",
      "Ep 11: Batch #47 - Loss: 1.0243347883224487\n",
      "Ep 11: Batch #48 - Loss: 1.422164797782898\n",
      "Ep 11: Batch #49 - Loss: 1.065702199935913\n",
      "Ep 11: Batch #50 - Loss: 0.7403523325920105\n",
      "Ep 11: Batch #51 - Loss: 1.054194688796997\n",
      "Ep 11: Batch #52 - Loss: 0.8318339586257935\n",
      "Ep 11: Batch #53 - Loss: 0.8692048788070679\n",
      "Ep 11: Batch #54 - Loss: 0.7446548938751221\n",
      "Ep 11: Batch #55 - Loss: 0.8026692271232605\n",
      "Ep 11: Batch #56 - Loss: 1.3210021257400513\n",
      "Ep 11: Batch #57 - Loss: 0.9078991413116455\n",
      "Ep 11: Batch #58 - Loss: 1.0598348379135132\n",
      "Ep 11: Batch #59 - Loss: 0.7196844816207886\n",
      "Ep 11: Batch #60 - Loss: 1.371957540512085\n",
      "Ep 11: Batch #61 - Loss: 0.677130401134491\n",
      "Ep 11: Batch #62 - Loss: 0.7714090943336487\n",
      "Ep 11: Batch #63 - Loss: 1.0653142929077148\n",
      "Ep 11: Batch #64 - Loss: 9.475503921508789\n",
      "Ep 11: Batch #65 - Loss: 0.6475206613540649\n",
      "Ep 11: Batch #66 - Loss: 0.8544149994850159\n",
      "Ep 11: Batch #67 - Loss: 0.9592905044555664\n",
      "Ep 11: Batch #68 - Loss: 0.9611647129058838\n",
      "Ep 11: Batch #69 - Loss: 0.7927993535995483\n",
      "Ep 11: Batch #70 - Loss: 0.8360855579376221\n",
      "Ep 11: Batch #71 - Loss: 0.7209816575050354\n",
      "Ep 11: Batch #72 - Loss: 0.9046549201011658\n",
      "Ep 11: Batch #73 - Loss: 0.9616407752037048\n",
      "Ep 11: Batch #74 - Loss: 0.7858693599700928\n",
      "Ep 11: Batch #75 - Loss: 0.8097764849662781\n",
      "Ep 11: Batch #76 - Loss: 1.1398556232452393\n",
      "Ep 11: Batch #77 - Loss: 0.7797278165817261\n",
      "Ep 11: Batch #78 - Loss: 1.2230743169784546\n",
      "Ep 11: Batch #79 - Loss: 0.6698558926582336\n",
      "Ep 11: Batch #80 - Loss: 0.9159964323043823\n",
      "Ep 11: Batch #81 - Loss: 1.7276921272277832\n",
      "Ep 11: Batch #82 - Loss: 0.9227427244186401\n",
      "Ep 11: Batch #83 - Loss: 1.7794444561004639\n",
      "Ep 11: Batch #84 - Loss: 0.7610391974449158\n",
      "Ep 11: Batch #85 - Loss: 1.0213078260421753\n",
      "Ep 11: Batch #86 - Loss: 0.7592692971229553\n",
      "Ep 11: Batch #87 - Loss: 0.756570041179657\n",
      "Ep 11: Batch #88 - Loss: 0.8529865741729736\n",
      "Ep 11: Batch #89 - Loss: 0.9171648025512695\n",
      "Ep 11: Batch #90 - Loss: 1.2258095741271973\n",
      "Ep 11: Batch #91 - Loss: 0.8549248576164246\n",
      "Ep 11: Batch #92 - Loss: 1.0873371362686157\n",
      "Ep 11: Batch #93 - Loss: 1.0960379838943481\n",
      "Ep 11: Batch #94 - Loss: 1.1063358783721924\n",
      "Ep 11: Batch #95 - Loss: 0.9748802781105042\n",
      "Ep 11: Batch #96 - Loss: 0.9526557922363281\n",
      "Ep 11: Batch #97 - Loss: 0.7756640911102295\n",
      "Ep 11: Batch #98 - Loss: 0.7874815464019775\n",
      "Ep 11: Batch #99 - Loss: 1.0046496391296387\n",
      "Ep 11: Batch #100 - Loss: 0.7235651016235352\n",
      "Ep 11: Batch #101 - Loss: 1.0995433330535889\n",
      "Ep 11: Batch #102 - Loss: 0.8258680105209351\n",
      "Ep 11: Batch #103 - Loss: 0.8311882019042969\n",
      "Ep 11: Batch #104 - Loss: 0.8498764038085938\n",
      "Ep 11: Batch #105 - Loss: 1.081939935684204\n",
      "Ep 11: Batch #106 - Loss: 0.8018907308578491\n",
      "Ep 11: Batch #107 - Loss: 0.8094865083694458\n",
      "Ep 11: Batch #108 - Loss: 1.0925213098526\n",
      "Ep 11: Batch #109 - Loss: 0.8030883073806763\n",
      "Ep 11: Batch #110 - Loss: 0.9766191840171814\n",
      "Ep 11: Batch #111 - Loss: 1.437023401260376\n",
      "Ep 11: Batch #112 - Loss: 1.1104438304901123\n",
      "Ep 11: Batch #113 - Loss: 0.8657780885696411\n",
      "Ep 11: Batch #114 - Loss: 0.9545977115631104\n",
      "Ep 11: Batch #115 - Loss: 1.1455425024032593\n",
      "Ep 11: Batch #116 - Loss: 0.6644478440284729\n",
      "Ep 11: Batch #117 - Loss: 0.9182984828948975\n",
      "Ep 11: Batch #118 - Loss: 0.5867705941200256\n",
      "Model saved in file: ./weights_autoencoder_low_LR/model_e11b118_1516651270.0983248.ckpt\n",
      "Ep 11: Batch #119 - Loss: 1.0779680013656616\n",
      "Ep 11: Batch #120 - Loss: 0.8368578553199768\n",
      "Ep 11: Batch #121 - Loss: 0.730398952960968\n",
      "Ep 11: Batch #122 - Loss: 0.874321699142456\n",
      "Ep 11: Batch #123 - Loss: 0.8760361671447754\n",
      "Ep 11: Batch #124 - Loss: 0.698967456817627\n",
      "Ep 11: Batch #125 - Loss: 2.780000686645508\n",
      "Ep 11: Batch #126 - Loss: 1.2833342552185059\n",
      "Ep 11: Batch #127 - Loss: 0.8038631081581116\n",
      "Ep 11: Batch #128 - Loss: 1.171250820159912\n",
      "Ep 11: Batch #129 - Loss: 0.8908113241195679\n",
      "Ep 11: Batch #130 - Loss: 0.7720383405685425\n",
      "Ep 11: Batch #131 - Loss: 1.0620701313018799\n",
      "Ep 11: Batch #132 - Loss: 0.8774098753929138\n",
      "Ep 11: Batch #133 - Loss: 0.8658329248428345\n",
      "Ep 11: Batch #134 - Loss: 0.816631019115448\n",
      "Ep 11: Batch #135 - Loss: 1.0239454507827759\n",
      "Ep 11: Batch #136 - Loss: 1.2448686361312866\n",
      "Ep 11: Batch #137 - Loss: 1.0200573205947876\n",
      "Ep 11: Batch #138 - Loss: 1.1214962005615234\n",
      "Ep 11: Batch #139 - Loss: 0.9554663896560669\n",
      "Ep 11: Batch #140 - Loss: 1.101305603981018\n",
      "Ep 11: Batch #141 - Loss: 1.4114229679107666\n",
      "Ep 11: Batch #142 - Loss: 0.8369076251983643\n",
      "Ep 11: Batch #143 - Loss: 1.0291489362716675\n",
      "Ep 11: Batch #144 - Loss: 0.768243134021759\n",
      "Ep 11: Batch #145 - Loss: 0.7180045247077942\n",
      "Ep 11: Batch #146 - Loss: 0.9267528653144836\n",
      "Ep 11: Batch #147 - Loss: 0.9196779727935791\n",
      "Ep 11: Batch #148 - Loss: 1.0328848361968994\n",
      "Ep 11: Batch #149 - Loss: 0.9093384742736816\n",
      "Ep 11: Batch #150 - Loss: 0.9251061081886292\n",
      "Ep 11: Batch #151 - Loss: 0.7608847618103027\n",
      "Ep 11: Batch #152 - Loss: 0.7771515250205994\n",
      "Ep 11: Batch #153 - Loss: 1.1630022525787354\n",
      "Ep 11: Batch #154 - Loss: 0.8025990128517151\n",
      "Ep 11: Batch #155 - Loss: 0.8870102167129517\n",
      "Ep 11: Batch #156 - Loss: 1.0714235305786133\n",
      "Ep 11: Batch #157 - Loss: 0.80462646484375\n",
      "Ep 11: Batch #158 - Loss: 0.8451133966445923\n",
      "Ep 11: Batch #159 - Loss: 0.8567830920219421\n",
      "Ep 11: Batch #160 - Loss: 0.9454604983329773\n",
      "Ep 11: Batch #161 - Loss: 0.8633023500442505\n",
      "Ep 11: Batch #162 - Loss: 0.9835920333862305\n",
      "Ep 11: Batch #163 - Loss: 0.9715568423271179\n",
      "Ep 11: Batch #164 - Loss: 0.8284407258033752\n",
      "Ep 11: Batch #165 - Loss: 1.5451854467391968\n",
      "Ep 11: Batch #166 - Loss: 0.7276175022125244\n",
      "Ep 11: Batch #167 - Loss: 1.1373571157455444\n",
      "Ep 11: Batch #168 - Loss: 0.9122811555862427\n",
      "Ep 11: Batch #169 - Loss: 0.847815990447998\n",
      "Ep 11: Batch #170 - Loss: 0.8500012755393982\n",
      "Ep 11: Batch #171 - Loss: 0.8327876329421997\n",
      "Ep 11: Batch #172 - Loss: 0.6687391400337219\n",
      "Ep 11: Batch #173 - Loss: 1.264086365699768\n",
      "Ep 11: Batch #174 - Loss: 0.6182800531387329\n",
      "Ep 11: Batch #175 - Loss: 0.8185871839523315\n",
      "Ep 11: Batch #176 - Loss: 1.2064158916473389\n",
      "Ep 11: Batch #177 - Loss: 0.8960375189781189\n",
      "Ep 11: Batch #178 - Loss: 0.8132733106613159\n",
      "Ep 11: Batch #179 - Loss: 0.997308075428009\n",
      "Ep 11: Batch #180 - Loss: 0.9162343144416809\n",
      "Ep 11: Batch #181 - Loss: 1.0530720949172974\n",
      "Ep 11: Batch #182 - Loss: 0.8056245446205139\n",
      "Ep 11: Batch #183 - Loss: 0.812002956867218\n",
      "Ep 11: Batch #184 - Loss: 1.112916111946106\n",
      "Ep 11: Batch #185 - Loss: 0.7996262907981873\n",
      "Ep 11: Batch #186 - Loss: 1.0280609130859375\n",
      "Ep 11: Batch #187 - Loss: 1.2188169956207275\n",
      "Ep 11: Batch #188 - Loss: 1.402859091758728\n",
      "Ep 11: Batch #189 - Loss: 0.7340256571769714\n",
      "Ep 11: Batch #190 - Loss: 0.7802708148956299\n",
      "Ep 11: Batch #191 - Loss: 1.1117030382156372\n",
      "Ep 11: Batch #192 - Loss: 0.7038385272026062\n",
      "Ep 11: Batch #193 - Loss: 0.7879589796066284\n",
      "Ep 11: Batch #194 - Loss: 0.7397959232330322\n",
      "Ep 11: Batch #195 - Loss: 1.0335603952407837\n",
      "Ep 11: Batch #196 - Loss: 0.9117023944854736\n",
      "Ep 11: Batch #197 - Loss: 0.9494597315788269\n",
      "Ep 11: Batch #198 - Loss: 0.7216726541519165\n",
      "Ep 11: Batch #199 - Loss: 0.9112465381622314\n",
      "Ep 12: Batch #0 - Loss: 0.8456538915634155\n",
      "Ep 12: Batch #1 - Loss: 0.9281999468803406\n",
      "Ep 12: Batch #2 - Loss: 1.0480009317398071\n",
      "Ep 12: Batch #3 - Loss: 0.9129838943481445\n",
      "Ep 12: Batch #4 - Loss: 0.8386292457580566\n",
      "Ep 12: Batch #5 - Loss: 0.703754723072052\n",
      "Ep 12: Batch #6 - Loss: 0.9278420209884644\n",
      "Ep 12: Batch #7 - Loss: 0.7415602207183838\n",
      "Ep 12: Batch #8 - Loss: 0.774181604385376\n",
      "Ep 12: Batch #9 - Loss: 1.464881181716919\n",
      "Ep 12: Batch #10 - Loss: 1.0616264343261719\n",
      "Ep 12: Batch #11 - Loss: 0.7130489945411682\n",
      "Ep 12: Batch #12 - Loss: 1.6024664640426636\n",
      "Ep 12: Batch #13 - Loss: 0.6772071123123169\n",
      "Ep 12: Batch #14 - Loss: 0.7647675275802612\n",
      "Ep 12: Batch #15 - Loss: 1.2997974157333374\n",
      "Ep 12: Batch #16 - Loss: 1.3463045358657837\n",
      "Ep 12: Batch #17 - Loss: 0.9292953014373779\n",
      "Ep 12: Batch #18 - Loss: 0.9760338664054871\n",
      "Ep 12: Batch #19 - Loss: 0.7036590576171875\n",
      "Ep 12: Batch #20 - Loss: 0.6958794593811035\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 12: Batch #21 - Loss: 1.2610914707183838\n",
      "Ep 12: Batch #22 - Loss: 0.7638697624206543\n",
      "Ep 12: Batch #23 - Loss: 0.794047474861145\n",
      "Ep 12: Batch #24 - Loss: 0.863759458065033\n",
      "Ep 12: Batch #25 - Loss: 0.7637057304382324\n",
      "Ep 12: Batch #26 - Loss: 0.7792816758155823\n",
      "Ep 12: Batch #27 - Loss: 1.40898597240448\n",
      "Ep 12: Batch #28 - Loss: 0.914275586605072\n",
      "Ep 12: Batch #29 - Loss: 0.9485161900520325\n",
      "Ep 12: Batch #30 - Loss: 1.2620693445205688\n",
      "Ep 12: Batch #31 - Loss: 0.7060723304748535\n",
      "Ep 12: Batch #32 - Loss: 0.7927838563919067\n",
      "Ep 12: Batch #33 - Loss: 0.8490198254585266\n",
      "Ep 12: Batch #34 - Loss: 0.8280386924743652\n",
      "Ep 12: Batch #35 - Loss: 1.0084298849105835\n",
      "Ep 12: Batch #36 - Loss: 0.7425664663314819\n",
      "Ep 12: Batch #37 - Loss: 1.1888809204101562\n",
      "Ep 12: Batch #38 - Loss: 0.7971931099891663\n",
      "Ep 12: Batch #39 - Loss: 0.8552819490432739\n",
      "Ep 12: Batch #40 - Loss: 0.8229189515113831\n",
      "Ep 12: Batch #41 - Loss: 0.7814779281616211\n",
      "Ep 12: Batch #42 - Loss: 0.7607942223548889\n",
      "Ep 12: Batch #43 - Loss: 0.8321781158447266\n",
      "Ep 12: Batch #44 - Loss: 0.8283916711807251\n",
      "Ep 12: Batch #45 - Loss: 0.6827480792999268\n",
      "Ep 12: Batch #46 - Loss: 0.8806796669960022\n",
      "Ep 12: Batch #47 - Loss: 1.0226471424102783\n",
      "Ep 12: Batch #48 - Loss: 1.4196891784667969\n",
      "Ep 12: Batch #49 - Loss: 1.064214825630188\n",
      "Ep 12: Batch #50 - Loss: 0.7391282320022583\n",
      "Ep 12: Batch #51 - Loss: 1.052596092224121\n",
      "Ep 12: Batch #52 - Loss: 0.8307152390480042\n",
      "Ep 12: Batch #53 - Loss: 0.8679278492927551\n",
      "Ep 12: Batch #54 - Loss: 0.7433263659477234\n",
      "Ep 12: Batch #55 - Loss: 0.801224946975708\n",
      "Ep 12: Batch #56 - Loss: 1.3190860748291016\n",
      "Ep 12: Batch #57 - Loss: 0.9060060977935791\n",
      "Ep 12: Batch #58 - Loss: 1.058093547821045\n",
      "Ep 12: Batch #59 - Loss: 0.718469500541687\n",
      "Ep 12: Batch #60 - Loss: 1.3693393468856812\n",
      "Ep 12: Batch #61 - Loss: 0.675839364528656\n",
      "Ep 12: Batch #62 - Loss: 0.7699995040893555\n",
      "Ep 12: Batch #63 - Loss: 1.0633602142333984\n",
      "Ep 12: Batch #64 - Loss: 9.474370956420898\n",
      "Ep 12: Batch #65 - Loss: 0.6464735865592957\n",
      "Ep 12: Batch #66 - Loss: 0.852780282497406\n",
      "Ep 12: Batch #67 - Loss: 0.9577116966247559\n",
      "Ep 12: Batch #68 - Loss: 0.9596667289733887\n",
      "Ep 12: Batch #69 - Loss: 0.7913828492164612\n",
      "Ep 12: Batch #70 - Loss: 0.834211528301239\n",
      "Ep 12: Batch #71 - Loss: 0.7197376489639282\n",
      "Ep 12: Batch #72 - Loss: 0.9032266139984131\n",
      "Ep 12: Batch #73 - Loss: 0.9600719809532166\n",
      "Ep 12: Batch #74 - Loss: 0.7846630215644836\n",
      "Ep 12: Batch #75 - Loss: 0.8086650967597961\n",
      "Ep 12: Batch #76 - Loss: 1.1385269165039062\n",
      "Ep 12: Batch #77 - Loss: 0.7782823443412781\n",
      "Ep 12: Batch #78 - Loss: 1.221122145652771\n",
      "Ep 12: Batch #79 - Loss: 0.6684991717338562\n",
      "Ep 12: Batch #80 - Loss: 0.9143767356872559\n",
      "Ep 12: Batch #81 - Loss: 1.726604700088501\n",
      "Ep 12: Batch #82 - Loss: 0.9212751388549805\n",
      "Ep 12: Batch #83 - Loss: 1.7781304121017456\n",
      "Ep 12: Batch #84 - Loss: 0.7597535252571106\n",
      "Ep 12: Batch #85 - Loss: 1.0198054313659668\n",
      "Ep 12: Batch #86 - Loss: 0.7579298615455627\n",
      "Ep 12: Batch #87 - Loss: 0.7550679445266724\n",
      "Ep 12: Batch #88 - Loss: 0.8514204025268555\n",
      "Ep 12: Batch #89 - Loss: 0.916046679019928\n",
      "Ep 12: Batch #90 - Loss: 1.2239460945129395\n",
      "Ep 12: Batch #91 - Loss: 0.8534657955169678\n",
      "Ep 12: Batch #92 - Loss: 1.0856609344482422\n",
      "Ep 12: Batch #93 - Loss: 1.0939327478408813\n",
      "Ep 12: Batch #94 - Loss: 1.1047759056091309\n",
      "Ep 12: Batch #95 - Loss: 0.9731214642524719\n",
      "Ep 12: Batch #96 - Loss: 0.9511917233467102\n",
      "Ep 12: Batch #97 - Loss: 0.7743619084358215\n",
      "Ep 12: Batch #98 - Loss: 0.7861416339874268\n",
      "Ep 12: Batch #99 - Loss: 1.003298044204712\n",
      "Ep 12: Batch #100 - Loss: 0.7223249077796936\n",
      "Ep 12: Batch #101 - Loss: 1.0980287790298462\n",
      "Ep 12: Batch #102 - Loss: 0.8245748281478882\n",
      "Ep 12: Batch #103 - Loss: 0.8300910592079163\n",
      "Ep 12: Batch #104 - Loss: 0.8483983874320984\n",
      "Ep 12: Batch #105 - Loss: 1.0804412364959717\n",
      "Ep 12: Batch #106 - Loss: 0.8008751273155212\n",
      "Ep 12: Batch #107 - Loss: 0.8078579306602478\n",
      "Ep 12: Batch #108 - Loss: 1.0908079147338867\n",
      "Ep 12: Batch #109 - Loss: 0.8019453287124634\n",
      "Ep 12: Batch #110 - Loss: 0.9750847220420837\n",
      "Ep 12: Batch #111 - Loss: 1.4355409145355225\n",
      "Ep 12: Batch #112 - Loss: 1.1084457635879517\n",
      "Ep 12: Batch #113 - Loss: 0.8643271327018738\n",
      "Ep 12: Batch #114 - Loss: 0.9532043933868408\n",
      "Ep 12: Batch #115 - Loss: 1.1440691947937012\n",
      "Ep 12: Batch #116 - Loss: 0.6633492708206177\n",
      "Ep 12: Batch #117 - Loss: 0.9168555736541748\n",
      "Ep 12: Batch #118 - Loss: 0.5854328870773315\n",
      "Model saved in file: ./weights_autoencoder_low_LR/model_e12b118_1516651270.238246.ckpt\n",
      "Ep 12: Batch #119 - Loss: 1.076482892036438\n",
      "Ep 12: Batch #120 - Loss: 0.8358671069145203\n",
      "Ep 12: Batch #121 - Loss: 0.7290742993354797\n",
      "Ep 12: Batch #122 - Loss: 0.8727102875709534\n",
      "Ep 12: Batch #123 - Loss: 0.8747460842132568\n",
      "Ep 12: Batch #124 - Loss: 0.6978083848953247\n",
      "Ep 12: Batch #125 - Loss: 2.778104305267334\n",
      "Ep 12: Batch #126 - Loss: 1.2815091609954834\n",
      "Ep 12: Batch #127 - Loss: 0.8022352457046509\n",
      "Ep 12: Batch #128 - Loss: 1.1691919565200806\n",
      "Ep 12: Batch #129 - Loss: 0.8893178105354309\n",
      "Ep 12: Batch #130 - Loss: 0.7706051468849182\n",
      "Ep 12: Batch #131 - Loss: 1.0600643157958984\n",
      "Ep 12: Batch #132 - Loss: 0.8759264945983887\n",
      "Ep 12: Batch #133 - Loss: 0.8643577694892883\n",
      "Ep 12: Batch #134 - Loss: 0.8155396580696106\n",
      "Ep 12: Batch #135 - Loss: 1.0222687721252441\n",
      "Ep 12: Batch #136 - Loss: 1.2433573007583618\n",
      "Ep 12: Batch #137 - Loss: 1.01845383644104\n",
      "Ep 12: Batch #138 - Loss: 1.120099425315857\n",
      "Ep 12: Batch #139 - Loss: 0.9535801410675049\n",
      "Ep 12: Batch #140 - Loss: 1.099912405014038\n",
      "Ep 12: Batch #141 - Loss: 1.410060167312622\n",
      "Ep 12: Batch #142 - Loss: 0.8357295989990234\n",
      "Ep 12: Batch #143 - Loss: 1.0272619724273682\n",
      "Ep 12: Batch #144 - Loss: 0.7667974829673767\n",
      "Ep 12: Batch #145 - Loss: 0.7168672680854797\n",
      "Ep 12: Batch #146 - Loss: 0.9255574345588684\n",
      "Ep 12: Batch #147 - Loss: 0.9181239604949951\n",
      "Ep 12: Batch #148 - Loss: 1.031416654586792\n",
      "Ep 12: Batch #149 - Loss: 0.9078258872032166\n",
      "Ep 12: Batch #150 - Loss: 0.9240453243255615\n",
      "Ep 12: Batch #151 - Loss: 0.7598626613616943\n",
      "Ep 12: Batch #152 - Loss: 0.7759215235710144\n",
      "Ep 12: Batch #153 - Loss: 1.161160945892334\n",
      "Ep 12: Batch #154 - Loss: 0.801529586315155\n",
      "Ep 12: Batch #155 - Loss: 0.8853814601898193\n",
      "Ep 12: Batch #156 - Loss: 1.0698755979537964\n",
      "Ep 12: Batch #157 - Loss: 0.8034699559211731\n",
      "Ep 12: Batch #158 - Loss: 0.8437382578849792\n",
      "Ep 12: Batch #159 - Loss: 0.855442464351654\n",
      "Ep 12: Batch #160 - Loss: 0.9443666338920593\n",
      "Ep 12: Batch #161 - Loss: 0.8619488477706909\n",
      "Ep 12: Batch #162 - Loss: 0.9821062088012695\n",
      "Ep 12: Batch #163 - Loss: 0.9702509045600891\n",
      "Ep 12: Batch #164 - Loss: 0.8273123502731323\n",
      "Ep 12: Batch #165 - Loss: 1.5437928438186646\n",
      "Ep 12: Batch #166 - Loss: 0.7262267470359802\n",
      "Ep 12: Batch #167 - Loss: 1.135817050933838\n",
      "Ep 12: Batch #168 - Loss: 0.9109113812446594\n",
      "Ep 12: Batch #169 - Loss: 0.8464623093605042\n",
      "Ep 12: Batch #170 - Loss: 0.8487806916236877\n",
      "Ep 12: Batch #171 - Loss: 0.8312453627586365\n",
      "Ep 12: Batch #172 - Loss: 0.6677143573760986\n",
      "Ep 12: Batch #173 - Loss: 1.2621674537658691\n",
      "Ep 12: Batch #174 - Loss: 0.6169989109039307\n",
      "Ep 12: Batch #175 - Loss: 0.8174085021018982\n",
      "Ep 12: Batch #176 - Loss: 1.204996109008789\n",
      "Ep 12: Batch #177 - Loss: 0.894717276096344\n",
      "Ep 12: Batch #178 - Loss: 0.8119337558746338\n",
      "Ep 12: Batch #179 - Loss: 0.9956951141357422\n",
      "Ep 12: Batch #180 - Loss: 0.9145983457565308\n",
      "Ep 12: Batch #181 - Loss: 1.0514014959335327\n",
      "Ep 12: Batch #182 - Loss: 0.8041587471961975\n",
      "Ep 12: Batch #183 - Loss: 0.8107247948646545\n",
      "Ep 12: Batch #184 - Loss: 1.111572265625\n",
      "Ep 12: Batch #185 - Loss: 0.7984643578529358\n",
      "Ep 12: Batch #186 - Loss: 1.0265729427337646\n",
      "Ep 12: Batch #187 - Loss: 1.2169842720031738\n",
      "Ep 12: Batch #188 - Loss: 1.4009630680084229\n",
      "Ep 12: Batch #189 - Loss: 0.733066737651825\n",
      "Ep 12: Batch #190 - Loss: 0.7788015604019165\n",
      "Ep 12: Batch #191 - Loss: 1.110278606414795\n",
      "Ep 12: Batch #192 - Loss: 0.702730119228363\n",
      "Ep 12: Batch #193 - Loss: 0.7865843772888184\n",
      "Ep 12: Batch #194 - Loss: 0.7384817600250244\n",
      "Ep 12: Batch #195 - Loss: 1.0322345495224\n",
      "Ep 12: Batch #196 - Loss: 0.9102813005447388\n",
      "Ep 12: Batch #197 - Loss: 0.9479700922966003\n",
      "Ep 12: Batch #198 - Loss: 0.7204749584197998\n",
      "Ep 12: Batch #199 - Loss: 0.9097676873207092\n",
      "Ep 13: Batch #0 - Loss: 0.8441978096961975\n",
      "Ep 13: Batch #1 - Loss: 0.9266343116760254\n",
      "Ep 13: Batch #2 - Loss: 1.0469164848327637\n",
      "Ep 13: Batch #3 - Loss: 0.9114260673522949\n",
      "Ep 13: Batch #4 - Loss: 0.8371376991271973\n",
      "Ep 13: Batch #5 - Loss: 0.702521562576294\n",
      "Ep 13: Batch #6 - Loss: 0.9259854555130005\n",
      "Ep 13: Batch #7 - Loss: 0.7402135729789734\n",
      "Ep 13: Batch #8 - Loss: 0.772865891456604\n",
      "Ep 13: Batch #9 - Loss: 1.4630135297775269\n",
      "Ep 13: Batch #10 - Loss: 1.0599273443222046\n",
      "Ep 13: Batch #11 - Loss: 0.7115782499313354\n",
      "Ep 13: Batch #12 - Loss: 1.601359486579895\n",
      "Ep 13: Batch #13 - Loss: 0.6763555407524109\n",
      "Ep 13: Batch #14 - Loss: 0.7635672688484192\n",
      "Ep 13: Batch #15 - Loss: 1.297653079032898\n",
      "Ep 13: Batch #16 - Loss: 1.3443092107772827\n",
      "Ep 13: Batch #17 - Loss: 0.9279495477676392\n",
      "Ep 13: Batch #18 - Loss: 0.9749913215637207\n",
      "Ep 13: Batch #19 - Loss: 0.7025418281555176\n",
      "Ep 13: Batch #20 - Loss: 0.6945619583129883\n",
      "Ep 13: Batch #21 - Loss: 1.2596241235733032\n",
      "Ep 13: Batch #22 - Loss: 0.7625541090965271\n",
      "Ep 13: Batch #23 - Loss: 0.7925713658332825\n",
      "Ep 13: Batch #24 - Loss: 0.8624005913734436\n",
      "Ep 13: Batch #25 - Loss: 0.7622426152229309\n",
      "Ep 13: Batch #26 - Loss: 0.7780213356018066\n",
      "Ep 13: Batch #27 - Loss: 1.4075710773468018\n",
      "Ep 13: Batch #28 - Loss: 0.9127461910247803\n",
      "Ep 13: Batch #29 - Loss: 0.946934700012207\n",
      "Ep 13: Batch #30 - Loss: 1.259987711906433\n",
      "Ep 13: Batch #31 - Loss: 0.7050373554229736\n",
      "Ep 13: Batch #32 - Loss: 0.7914028763771057\n",
      "Ep 13: Batch #33 - Loss: 0.84755939245224\n",
      "Ep 13: Batch #34 - Loss: 0.8266486525535583\n",
      "Ep 13: Batch #35 - Loss: 1.0066994428634644\n",
      "Ep 13: Batch #36 - Loss: 0.7413026094436646\n",
      "Ep 13: Batch #37 - Loss: 1.1872671842575073\n",
      "Ep 13: Batch #38 - Loss: 0.7956803441047668\n",
      "Ep 13: Batch #39 - Loss: 0.8542258143424988\n",
      "Ep 13: Batch #40 - Loss: 0.8213763236999512\n",
      "Ep 13: Batch #41 - Loss: 0.7803352475166321\n",
      "Ep 13: Batch #42 - Loss: 0.7596448659896851\n",
      "Ep 13: Batch #43 - Loss: 0.8307451605796814\n",
      "Ep 13: Batch #44 - Loss: 0.8270635604858398\n",
      "Ep 13: Batch #45 - Loss: 0.6813263297080994\n",
      "Ep 13: Batch #46 - Loss: 0.8791664838790894\n",
      "Ep 13: Batch #47 - Loss: 1.020956039428711\n",
      "Ep 13: Batch #48 - Loss: 1.417232871055603\n",
      "Ep 13: Batch #49 - Loss: 1.0627481937408447\n",
      "Ep 13: Batch #50 - Loss: 0.7378870844841003\n",
      "Ep 13: Batch #51 - Loss: 1.0509841442108154\n",
      "Ep 13: Batch #52 - Loss: 0.8296334743499756\n",
      "Ep 13: Batch #53 - Loss: 0.8666195273399353\n",
      "Ep 13: Batch #54 - Loss: 0.7420318722724915\n",
      "Ep 13: Batch #55 - Loss: 0.7997711896896362\n",
      "Ep 13: Batch #56 - Loss: 1.3172643184661865\n",
      "Ep 13: Batch #57 - Loss: 0.9041299223899841\n",
      "Ep 13: Batch #58 - Loss: 1.0563479661941528\n",
      "Ep 13: Batch #59 - Loss: 0.7172525525093079\n",
      "Ep 13: Batch #60 - Loss: 1.3668766021728516\n",
      "Ep 13: Batch #61 - Loss: 0.6745665073394775\n",
      "Ep 13: Batch #62 - Loss: 0.7686179876327515\n",
      "Ep 13: Batch #63 - Loss: 1.0613881349563599\n",
      "Ep 13: Batch #64 - Loss: 9.473209381103516\n",
      "Ep 13: Batch #65 - Loss: 0.6454498767852783\n",
      "Ep 13: Batch #66 - Loss: 0.8511490225791931\n",
      "Ep 13: Batch #67 - Loss: 0.956151008605957\n",
      "Ep 13: Batch #68 - Loss: 0.9581397175788879\n",
      "Ep 13: Batch #69 - Loss: 0.7899880409240723\n",
      "Ep 13: Batch #70 - Loss: 0.8323619961738586\n",
      "Ep 13: Batch #71 - Loss: 0.7185077667236328\n",
      "Ep 13: Batch #72 - Loss: 0.9017853140830994\n",
      "Ep 13: Batch #73 - Loss: 0.9585062265396118\n",
      "Ep 13: Batch #74 - Loss: 0.7834600210189819\n",
      "Ep 13: Batch #75 - Loss: 0.8075487613677979\n",
      "Ep 13: Batch #76 - Loss: 1.137174129486084\n",
      "Ep 13: Batch #77 - Loss: 0.7768846750259399\n",
      "Ep 13: Batch #78 - Loss: 1.2192302942276\n",
      "Ep 13: Batch #79 - Loss: 0.6671355366706848\n",
      "Ep 13: Batch #80 - Loss: 0.912725567817688\n",
      "Ep 13: Batch #81 - Loss: 1.7255560159683228\n",
      "Ep 13: Batch #82 - Loss: 0.9198395013809204\n",
      "Ep 13: Batch #83 - Loss: 1.7767820358276367\n",
      "Ep 13: Batch #84 - Loss: 0.7584627270698547\n",
      "Ep 13: Batch #85 - Loss: 1.0182925462722778\n",
      "Ep 13: Batch #86 - Loss: 0.7565793395042419\n",
      "Ep 13: Batch #87 - Loss: 0.7536279559135437\n",
      "Ep 13: Batch #88 - Loss: 0.8498772978782654\n",
      "Ep 13: Batch #89 - Loss: 0.9149268269538879\n",
      "Ep 13: Batch #90 - Loss: 1.222055196762085\n",
      "Ep 13: Batch #91 - Loss: 0.8520029187202454\n",
      "Ep 13: Batch #92 - Loss: 1.0839788913726807\n",
      "Ep 13: Batch #93 - Loss: 1.0918402671813965\n",
      "Ep 13: Batch #94 - Loss: 1.1032228469848633\n",
      "Ep 13: Batch #95 - Loss: 0.9713749289512634\n",
      "Ep 13: Batch #96 - Loss: 0.9497826099395752\n",
      "Ep 13: Batch #97 - Loss: 0.7730651497840881\n",
      "Ep 13: Batch #98 - Loss: 0.7847991585731506\n",
      "Ep 13: Batch #99 - Loss: 1.0019406080245972\n",
      "Ep 13: Batch #100 - Loss: 0.7210688591003418\n",
      "Ep 13: Batch #101 - Loss: 1.0965081453323364\n",
      "Ep 13: Batch #102 - Loss: 0.8232828974723816\n",
      "Ep 13: Batch #103 - Loss: 0.8289810419082642\n",
      "Ep 13: Batch #104 - Loss: 0.8469151854515076\n",
      "Ep 13: Batch #105 - Loss: 1.0789446830749512\n",
      "Ep 13: Batch #106 - Loss: 0.7998470664024353\n",
      "Ep 13: Batch #107 - Loss: 0.8062570691108704\n",
      "Ep 13: Batch #108 - Loss: 1.0890507698059082\n",
      "Ep 13: Batch #109 - Loss: 0.8008179664611816\n",
      "Ep 13: Batch #110 - Loss: 0.9735348224639893\n",
      "Ep 13: Batch #111 - Loss: 1.4340733289718628\n",
      "Ep 13: Batch #112 - Loss: 1.1065151691436768\n",
      "Ep 13: Batch #113 - Loss: 0.8628765940666199\n",
      "Ep 13: Batch #114 - Loss: 0.9518075585365295\n",
      "Ep 13: Batch #115 - Loss: 1.14261794090271\n",
      "Ep 13: Batch #116 - Loss: 0.662283718585968\n",
      "Ep 13: Batch #117 - Loss: 0.9154277443885803\n",
      "Ep 13: Batch #118 - Loss: 0.5841017365455627\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved in file: ./weights_autoencoder_low_LR/model_e13b118_1516651270.3726532.ckpt\n",
      "Ep 13: Batch #119 - Loss: 1.0750221014022827\n",
      "Ep 13: Batch #120 - Loss: 0.8348826766014099\n",
      "Ep 13: Batch #121 - Loss: 0.727745532989502\n",
      "Ep 13: Batch #122 - Loss: 0.8711462020874023\n",
      "Ep 13: Batch #123 - Loss: 0.8734869360923767\n",
      "Ep 13: Batch #124 - Loss: 0.6966665983200073\n",
      "Ep 13: Batch #125 - Loss: 2.7762014865875244\n",
      "Ep 13: Batch #126 - Loss: 1.2796887159347534\n",
      "Ep 13: Batch #127 - Loss: 0.8006113171577454\n",
      "Ep 13: Batch #128 - Loss: 1.1672236919403076\n",
      "Ep 13: Batch #129 - Loss: 0.8878121972084045\n",
      "Ep 13: Batch #130 - Loss: 0.7691851854324341\n",
      "Ep 13: Batch #131 - Loss: 1.0580575466156006\n",
      "Ep 13: Batch #132 - Loss: 0.8744248747825623\n",
      "Ep 13: Batch #133 - Loss: 0.8629060387611389\n",
      "Ep 13: Batch #134 - Loss: 0.8144217729568481\n",
      "Ep 13: Batch #135 - Loss: 1.0205936431884766\n",
      "Ep 13: Batch #136 - Loss: 1.2418369054794312\n",
      "Ep 13: Batch #137 - Loss: 1.0168483257293701\n",
      "Ep 13: Batch #138 - Loss: 1.1187225580215454\n",
      "Ep 13: Batch #139 - Loss: 0.9517520070075989\n",
      "Ep 13: Batch #140 - Loss: 1.0984961986541748\n",
      "Ep 13: Batch #141 - Loss: 1.408692479133606\n",
      "Ep 13: Batch #142 - Loss: 0.8345593810081482\n",
      "Ep 13: Batch #143 - Loss: 1.0253742933273315\n",
      "Ep 13: Batch #144 - Loss: 0.7653573155403137\n",
      "Ep 13: Batch #145 - Loss: 0.7157232761383057\n",
      "Ep 13: Batch #146 - Loss: 0.9243730902671814\n",
      "Ep 13: Batch #147 - Loss: 0.9165842533111572\n",
      "Ep 13: Batch #148 - Loss: 1.0299454927444458\n",
      "Ep 13: Batch #149 - Loss: 0.9063005447387695\n",
      "Ep 13: Batch #150 - Loss: 0.9230090975761414\n",
      "Ep 13: Batch #151 - Loss: 0.7588507533073425\n",
      "Ep 13: Batch #152 - Loss: 0.7746863961219788\n",
      "Ep 13: Batch #153 - Loss: 1.1593656539916992\n",
      "Ep 13: Batch #154 - Loss: 0.8004652857780457\n",
      "Ep 13: Batch #155 - Loss: 0.8837459683418274\n",
      "Ep 13: Batch #156 - Loss: 1.068303108215332\n",
      "Ep 13: Batch #157 - Loss: 0.8023341298103333\n",
      "Ep 13: Batch #158 - Loss: 0.8423703908920288\n",
      "Ep 13: Batch #159 - Loss: 0.8540899157524109\n",
      "Ep 13: Batch #160 - Loss: 0.9432703256607056\n",
      "Ep 13: Batch #161 - Loss: 0.8606043457984924\n",
      "Ep 13: Batch #162 - Loss: 0.9805452823638916\n",
      "Ep 13: Batch #163 - Loss: 0.968940258026123\n",
      "Ep 13: Batch #164 - Loss: 0.8261686563491821\n",
      "Ep 13: Batch #165 - Loss: 1.5423985719680786\n",
      "Ep 13: Batch #166 - Loss: 0.7248289585113525\n",
      "Ep 13: Batch #167 - Loss: 1.1343064308166504\n",
      "Ep 13: Batch #168 - Loss: 0.9095250368118286\n",
      "Ep 13: Batch #169 - Loss: 0.8451025485992432\n",
      "Ep 13: Batch #170 - Loss: 0.8475551009178162\n",
      "Ep 13: Batch #171 - Loss: 0.8296951651573181\n",
      "Ep 13: Batch #172 - Loss: 0.6666960120201111\n",
      "Ep 13: Batch #173 - Loss: 1.2602566480636597\n",
      "Ep 13: Batch #174 - Loss: 0.6157192587852478\n",
      "Ep 13: Batch #175 - Loss: 0.8162523508071899\n",
      "Ep 13: Batch #176 - Loss: 1.2035846710205078\n",
      "Ep 13: Batch #177 - Loss: 0.8933892846107483\n",
      "Ep 13: Batch #178 - Loss: 0.810585618019104\n",
      "Ep 13: Batch #179 - Loss: 0.99409019947052\n",
      "Ep 13: Batch #180 - Loss: 0.9129319787025452\n",
      "Ep 13: Batch #181 - Loss: 1.049767255783081\n",
      "Ep 13: Batch #182 - Loss: 0.8027288913726807\n",
      "Ep 13: Batch #183 - Loss: 0.809454083442688\n",
      "Ep 13: Batch #184 - Loss: 1.1101984977722168\n",
      "Ep 13: Batch #185 - Loss: 0.7972831726074219\n",
      "Ep 13: Batch #186 - Loss: 1.0250704288482666\n",
      "Ep 13: Batch #187 - Loss: 1.2152155637741089\n",
      "Ep 13: Batch #188 - Loss: 1.3990763425827026\n",
      "Ep 13: Batch #189 - Loss: 0.7321049571037292\n",
      "Ep 13: Batch #190 - Loss: 0.7773287892341614\n",
      "Ep 13: Batch #191 - Loss: 1.108860731124878\n",
      "Ep 13: Batch #192 - Loss: 0.7016376256942749\n",
      "Ep 13: Batch #193 - Loss: 0.785243034362793\n",
      "Ep 13: Batch #194 - Loss: 0.7371440529823303\n",
      "Ep 13: Batch #195 - Loss: 1.0308650732040405\n",
      "Ep 13: Batch #196 - Loss: 0.908881664276123\n",
      "Ep 13: Batch #197 - Loss: 0.9465116262435913\n",
      "Ep 13: Batch #198 - Loss: 0.7192733883857727\n",
      "Ep 13: Batch #199 - Loss: 0.9083291292190552\n",
      "Ep 14: Batch #0 - Loss: 0.8427173495292664\n",
      "Ep 14: Batch #1 - Loss: 0.9250561594963074\n",
      "Ep 14: Batch #2 - Loss: 1.0458303689956665\n",
      "Ep 14: Batch #3 - Loss: 0.909857988357544\n",
      "Ep 14: Batch #4 - Loss: 0.8356338143348694\n",
      "Ep 14: Batch #5 - Loss: 0.7012929320335388\n",
      "Ep 14: Batch #6 - Loss: 0.9241846203804016\n",
      "Ep 14: Batch #7 - Loss: 0.738849401473999\n",
      "Ep 14: Batch #8 - Loss: 0.7715804576873779\n",
      "Ep 14: Batch #9 - Loss: 1.4611821174621582\n",
      "Ep 14: Batch #10 - Loss: 1.058212161064148\n",
      "Ep 14: Batch #11 - Loss: 0.7101259827613831\n",
      "Ep 14: Batch #12 - Loss: 1.6002708673477173\n",
      "Ep 14: Batch #13 - Loss: 0.6755096316337585\n",
      "Ep 14: Batch #14 - Loss: 0.7623847126960754\n",
      "Ep 14: Batch #15 - Loss: 1.295633316040039\n",
      "Ep 14: Batch #16 - Loss: 1.3423129320144653\n",
      "Ep 14: Batch #17 - Loss: 0.9266098141670227\n",
      "Ep 14: Batch #18 - Loss: 0.9739886522293091\n",
      "Ep 14: Batch #19 - Loss: 0.7014319896697998\n",
      "Ep 14: Batch #20 - Loss: 0.6932735443115234\n",
      "Ep 14: Batch #21 - Loss: 1.2581639289855957\n",
      "Ep 14: Batch #22 - Loss: 0.7612711191177368\n",
      "Ep 14: Batch #23 - Loss: 0.7910816073417664\n",
      "Ep 14: Batch #24 - Loss: 0.8610947728157043\n",
      "Ep 14: Batch #25 - Loss: 0.7607782483100891\n",
      "Ep 14: Batch #26 - Loss: 0.776749312877655\n",
      "Ep 14: Batch #27 - Loss: 1.4061464071273804\n",
      "Ep 14: Batch #28 - Loss: 0.911217212677002\n",
      "Ep 14: Batch #29 - Loss: 0.9453513026237488\n",
      "Ep 14: Batch #30 - Loss: 1.2577271461486816\n",
      "Ep 14: Batch #31 - Loss: 0.704014241695404\n",
      "Ep 14: Batch #32 - Loss: 0.7900286912918091\n",
      "Ep 14: Batch #33 - Loss: 0.8461164236068726\n",
      "Ep 14: Batch #34 - Loss: 0.8252747654914856\n",
      "Ep 14: Batch #35 - Loss: 1.0049406290054321\n",
      "Ep 14: Batch #36 - Loss: 0.7400535345077515\n",
      "Ep 14: Batch #37 - Loss: 1.1856606006622314\n",
      "Ep 14: Batch #38 - Loss: 0.7941585779190063\n",
      "Ep 14: Batch #39 - Loss: 0.853187084197998\n",
      "Ep 14: Batch #40 - Loss: 0.8198244571685791\n",
      "Ep 14: Batch #41 - Loss: 0.7791730165481567\n",
      "Ep 14: Batch #42 - Loss: 0.7584616541862488\n",
      "Ep 14: Batch #43 - Loss: 0.8293115496635437\n",
      "Ep 14: Batch #44 - Loss: 0.8257749676704407\n",
      "Ep 14: Batch #45 - Loss: 0.6798640489578247\n",
      "Ep 14: Batch #46 - Loss: 0.877650260925293\n",
      "Ep 14: Batch #47 - Loss: 1.019244909286499\n",
      "Ep 14: Batch #48 - Loss: 1.4147136211395264\n",
      "Ep 14: Batch #49 - Loss: 1.0613105297088623\n",
      "Ep 14: Batch #50 - Loss: 0.7366548180580139\n",
      "Ep 14: Batch #51 - Loss: 1.049389123916626\n",
      "Ep 14: Batch #52 - Loss: 0.8285797238349915\n",
      "Ep 14: Batch #53 - Loss: 0.8653033375740051\n",
      "Ep 14: Batch #54 - Loss: 0.7407657504081726\n",
      "Ep 14: Batch #55 - Loss: 0.7982836961746216\n",
      "Ep 14: Batch #56 - Loss: 1.3155124187469482\n",
      "Ep 14: Batch #57 - Loss: 0.9022374153137207\n",
      "Ep 14: Batch #58 - Loss: 1.0546419620513916\n",
      "Ep 14: Batch #59 - Loss: 0.7160291075706482\n",
      "Ep 14: Batch #60 - Loss: 1.364645004272461\n",
      "Ep 14: Batch #61 - Loss: 0.6733129024505615\n",
      "Ep 14: Batch #62 - Loss: 0.7672473788261414\n",
      "Ep 14: Batch #63 - Loss: 1.0594030618667603\n",
      "Ep 14: Batch #64 - Loss: 9.472064971923828\n",
      "Ep 14: Batch #65 - Loss: 0.6444249153137207\n",
      "Ep 14: Batch #66 - Loss: 0.8495133519172668\n",
      "Ep 14: Batch #67 - Loss: 0.9546300172805786\n",
      "Ep 14: Batch #68 - Loss: 0.9566044807434082\n",
      "Ep 14: Batch #69 - Loss: 0.788581907749176\n",
      "Ep 14: Batch #70 - Loss: 0.8305410742759705\n",
      "Ep 14: Batch #71 - Loss: 0.7172873616218567\n",
      "Ep 14: Batch #72 - Loss: 0.9003376364707947\n",
      "Ep 14: Batch #73 - Loss: 0.9569517970085144\n",
      "Ep 14: Batch #74 - Loss: 0.7822672128677368\n",
      "Ep 14: Batch #75 - Loss: 0.8064249753952026\n",
      "Ep 14: Batch #76 - Loss: 1.1358281373977661\n",
      "Ep 14: Batch #77 - Loss: 0.7755139470100403\n",
      "Ep 14: Batch #78 - Loss: 1.217393398284912\n",
      "Ep 14: Batch #79 - Loss: 0.6657587885856628\n",
      "Ep 14: Batch #80 - Loss: 0.9110504388809204\n",
      "Ep 14: Batch #81 - Loss: 1.7245315313339233\n",
      "Ep 14: Batch #82 - Loss: 0.918364405632019\n",
      "Ep 14: Batch #83 - Loss: 1.7753523588180542\n",
      "Ep 14: Batch #84 - Loss: 0.7571346759796143\n",
      "Ep 14: Batch #85 - Loss: 1.0167666673660278\n",
      "Ep 14: Batch #86 - Loss: 0.7551419734954834\n",
      "Ep 14: Batch #87 - Loss: 0.7522146105766296\n",
      "Ep 14: Batch #88 - Loss: 0.8483737111091614\n",
      "Ep 14: Batch #89 - Loss: 0.9138038754463196\n",
      "Ep 14: Batch #90 - Loss: 1.2201460599899292\n",
      "Ep 14: Batch #91 - Loss: 0.8505366444587708\n",
      "Ep 14: Batch #92 - Loss: 1.0822919607162476\n",
      "Ep 14: Batch #93 - Loss: 1.0897859334945679\n",
      "Ep 14: Batch #94 - Loss: 1.1016415357589722\n",
      "Ep 14: Batch #95 - Loss: 0.9696488976478577\n",
      "Ep 14: Batch #96 - Loss: 0.9483895301818848\n",
      "Ep 14: Batch #97 - Loss: 0.7717710137367249\n",
      "Ep 14: Batch #98 - Loss: 0.7834058403968811\n",
      "Ep 14: Batch #99 - Loss: 1.0005626678466797\n",
      "Ep 14: Batch #100 - Loss: 0.7198051810264587\n",
      "Ep 14: Batch #101 - Loss: 1.0949835777282715\n",
      "Ep 14: Batch #102 - Loss: 0.8220074772834778\n",
      "Ep 14: Batch #103 - Loss: 0.8278430700302124\n",
      "Ep 14: Batch #104 - Loss: 0.8454334735870361\n",
      "Ep 14: Batch #105 - Loss: 1.0774333477020264\n",
      "Ep 14: Batch #106 - Loss: 0.7988128662109375\n",
      "Ep 14: Batch #107 - Loss: 0.8046499490737915\n",
      "Ep 14: Batch #108 - Loss: 1.087307095527649\n",
      "Ep 14: Batch #109 - Loss: 0.7996928691864014\n",
      "Ep 14: Batch #110 - Loss: 0.9719714522361755\n",
      "Ep 14: Batch #111 - Loss: 1.4326140880584717\n",
      "Ep 14: Batch #112 - Loss: 1.1046159267425537\n",
      "Ep 14: Batch #113 - Loss: 0.8614298701286316\n",
      "Ep 14: Batch #114 - Loss: 0.9504071474075317\n",
      "Ep 14: Batch #115 - Loss: 1.1411741971969604\n",
      "Ep 14: Batch #116 - Loss: 0.6612412333488464\n",
      "Ep 14: Batch #117 - Loss: 0.9140201210975647\n",
      "Ep 14: Batch #118 - Loss: 0.5827539563179016\n",
      "Model saved in file: ./weights_autoencoder_low_LR/model_e14b118_1516651270.5172873.ckpt\n",
      "Ep 14: Batch #119 - Loss: 1.073581576347351\n",
      "Ep 14: Batch #120 - Loss: 0.8338953256607056\n",
      "Ep 14: Batch #121 - Loss: 0.7264185547828674\n",
      "Ep 14: Batch #122 - Loss: 0.869599461555481\n",
      "Ep 14: Batch #123 - Loss: 0.8722379803657532\n",
      "Ep 14: Batch #124 - Loss: 0.6955230832099915\n",
      "Ep 14: Batch #125 - Loss: 2.774318218231201\n",
      "Ep 14: Batch #126 - Loss: 1.2778987884521484\n",
      "Ep 14: Batch #127 - Loss: 0.7989691495895386\n",
      "Ep 14: Batch #128 - Loss: 1.1653188467025757\n",
      "Ep 14: Batch #129 - Loss: 0.8863047957420349\n",
      "Ep 14: Batch #130 - Loss: 0.7677651047706604\n",
      "Ep 14: Batch #131 - Loss: 1.0560812950134277\n",
      "Ep 14: Batch #132 - Loss: 0.8729172348976135\n",
      "Ep 14: Batch #133 - Loss: 0.8614453673362732\n",
      "Ep 14: Batch #134 - Loss: 0.8132146000862122\n",
      "Ep 14: Batch #135 - Loss: 1.0189415216445923\n",
      "Ep 14: Batch #136 - Loss: 1.2402793169021606\n",
      "Ep 14: Batch #137 - Loss: 1.0152382850646973\n",
      "Ep 14: Batch #138 - Loss: 1.1173468828201294\n",
      "Ep 14: Batch #139 - Loss: 0.9499365091323853\n",
      "Ep 14: Batch #140 - Loss: 1.0970698595046997\n",
      "Ep 14: Batch #141 - Loss: 1.4073137044906616\n",
      "Ep 14: Batch #142 - Loss: 0.8333887457847595\n",
      "Ep 14: Batch #143 - Loss: 1.023466944694519\n",
      "Ep 14: Batch #144 - Loss: 0.7639181613922119\n",
      "Ep 14: Batch #145 - Loss: 0.7145785689353943\n",
      "Ep 14: Batch #146 - Loss: 0.9232046008110046\n",
      "Ep 14: Batch #147 - Loss: 0.9150508046150208\n",
      "Ep 14: Batch #148 - Loss: 1.028488278388977\n",
      "Ep 14: Batch #149 - Loss: 0.9047313928604126\n",
      "Ep 14: Batch #150 - Loss: 0.9219731092453003\n",
      "Ep 14: Batch #151 - Loss: 0.7578474879264832\n",
      "Ep 14: Batch #152 - Loss: 0.7734654545783997\n",
      "Ep 14: Batch #153 - Loss: 1.1575723886489868\n",
      "Ep 14: Batch #154 - Loss: 0.7994036674499512\n",
      "Ep 14: Batch #155 - Loss: 0.8821153044700623\n",
      "Ep 14: Batch #156 - Loss: 1.066728949546814\n",
      "Ep 14: Batch #157 - Loss: 0.8011736273765564\n",
      "Ep 14: Batch #158 - Loss: 0.8409922122955322\n",
      "Ep 14: Batch #159 - Loss: 0.8527273535728455\n",
      "Ep 14: Batch #160 - Loss: 0.9421568512916565\n",
      "Ep 14: Batch #161 - Loss: 0.8592305779457092\n",
      "Ep 14: Batch #162 - Loss: 0.9789840579032898\n",
      "Ep 14: Batch #163 - Loss: 0.9676111340522766\n",
      "Ep 14: Batch #164 - Loss: 0.8249979615211487\n",
      "Ep 14: Batch #165 - Loss: 1.541000247001648\n",
      "Ep 14: Batch #166 - Loss: 0.7234253883361816\n",
      "Ep 14: Batch #167 - Loss: 1.1328216791152954\n",
      "Ep 14: Batch #168 - Loss: 0.9081019759178162\n",
      "Ep 14: Batch #169 - Loss: 0.8437241911888123\n",
      "Ep 14: Batch #170 - Loss: 0.8463005423545837\n",
      "Ep 14: Batch #171 - Loss: 0.8281158804893494\n",
      "Ep 14: Batch #172 - Loss: 0.6656624674797058\n",
      "Ep 14: Batch #173 - Loss: 1.2582982778549194\n",
      "Ep 14: Batch #174 - Loss: 0.6144458651542664\n",
      "Ep 14: Batch #175 - Loss: 0.8151031732559204\n",
      "Ep 14: Batch #176 - Loss: 1.2022006511688232\n",
      "Ep 14: Batch #177 - Loss: 0.8920586705207825\n",
      "Ep 14: Batch #178 - Loss: 0.8092215657234192\n",
      "Ep 14: Batch #179 - Loss: 0.9924524426460266\n",
      "Ep 14: Batch #180 - Loss: 0.9112218618392944\n",
      "Ep 14: Batch #181 - Loss: 1.0481443405151367\n",
      "Ep 14: Batch #182 - Loss: 0.8013384938240051\n",
      "Ep 14: Batch #183 - Loss: 0.8081395030021667\n",
      "Ep 14: Batch #184 - Loss: 1.108781099319458\n",
      "Ep 14: Batch #185 - Loss: 0.7960907816886902\n",
      "Ep 14: Batch #186 - Loss: 1.0235533714294434\n",
      "Ep 14: Batch #187 - Loss: 1.213493824005127\n",
      "Ep 14: Batch #188 - Loss: 1.397178053855896\n",
      "Ep 14: Batch #189 - Loss: 0.7311553955078125\n",
      "Ep 14: Batch #190 - Loss: 0.7758620381355286\n",
      "Ep 14: Batch #191 - Loss: 1.1074721813201904\n",
      "Ep 14: Batch #192 - Loss: 0.7005529403686523\n",
      "Ep 14: Batch #193 - Loss: 0.7838936448097229\n",
      "Ep 14: Batch #194 - Loss: 0.7357809543609619\n",
      "Ep 14: Batch #195 - Loss: 1.0294837951660156\n",
      "Ep 14: Batch #196 - Loss: 0.9074809551239014\n",
      "Ep 14: Batch #197 - Loss: 0.9450688362121582\n",
      "Ep 14: Batch #198 - Loss: 0.7180805802345276\n",
      "Ep 14: Batch #199 - Loss: 0.9068995714187622\n",
      "Ep 15: Batch #0 - Loss: 0.8412044048309326\n",
      "Ep 15: Batch #1 - Loss: 0.9234636425971985\n",
      "Ep 15: Batch #2 - Loss: 1.0447421073913574\n",
      "Ep 15: Batch #3 - Loss: 0.9082724452018738\n",
      "Ep 15: Batch #4 - Loss: 0.8341385126113892\n",
      "Ep 15: Batch #5 - Loss: 0.7000600099563599\n",
      "Ep 15: Batch #6 - Loss: 0.9224259853363037\n",
      "Ep 15: Batch #7 - Loss: 0.7374458909034729\n",
      "Ep 15: Batch #8 - Loss: 0.770311713218689\n",
      "Ep 15: Batch #9 - Loss: 1.4593790769577026\n",
      "Ep 15: Batch #10 - Loss: 1.05648672580719\n",
      "Ep 15: Batch #11 - Loss: 0.7086716890335083\n",
      "Ep 15: Batch #12 - Loss: 1.5992043018341064\n",
      "Ep 15: Batch #13 - Loss: 0.6746583580970764\n",
      "Ep 15: Batch #14 - Loss: 0.7612196803092957\n",
      "Ep 15: Batch #15 - Loss: 1.2936947345733643\n",
      "Ep 15: Batch #16 - Loss: 1.3402957916259766\n",
      "Ep 15: Batch #17 - Loss: 0.9252645969390869\n",
      "Ep 15: Batch #18 - Loss: 0.9729979038238525\n",
      "Ep 15: Batch #19 - Loss: 0.7003418207168579\n",
      "Ep 15: Batch #20 - Loss: 0.692026674747467\n",
      "Ep 15: Batch #21 - Loss: 1.2567023038864136\n",
      "Ep 15: Batch #22 - Loss: 0.7599925994873047\n",
      "Ep 15: Batch #23 - Loss: 0.7895473837852478\n",
      "Ep 15: Batch #24 - Loss: 0.8598132133483887\n",
      "Ep 15: Batch #25 - Loss: 0.7592967748641968\n",
      "Ep 15: Batch #26 - Loss: 0.775468111038208\n",
      "Ep 15: Batch #27 - Loss: 1.4046708345413208\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 15: Batch #28 - Loss: 0.9096885919570923\n",
      "Ep 15: Batch #29 - Loss: 0.9437596201896667\n",
      "Ep 15: Batch #30 - Loss: 1.2552613019943237\n",
      "Ep 15: Batch #31 - Loss: 0.7029908299446106\n",
      "Ep 15: Batch #32 - Loss: 0.7886406779289246\n",
      "Ep 15: Batch #33 - Loss: 0.844687819480896\n",
      "Ep 15: Batch #34 - Loss: 0.823891282081604\n",
      "Ep 15: Batch #35 - Loss: 1.0031658411026\n",
      "Ep 15: Batch #36 - Loss: 0.7388168573379517\n",
      "Ep 15: Batch #37 - Loss: 1.184049367904663\n",
      "Ep 15: Batch #38 - Loss: 0.7926115989685059\n",
      "Ep 15: Batch #39 - Loss: 0.8521652817726135\n",
      "Ep 15: Batch #40 - Loss: 0.8182495832443237\n",
      "Ep 15: Batch #41 - Loss: 0.7780019640922546\n",
      "Ep 15: Batch #42 - Loss: 0.7572762370109558\n",
      "Ep 15: Batch #43 - Loss: 0.8278626799583435\n",
      "Ep 15: Batch #44 - Loss: 0.824501097202301\n",
      "Ep 15: Batch #45 - Loss: 0.6783768534660339\n",
      "Ep 15: Batch #46 - Loss: 0.8760988712310791\n",
      "Ep 15: Batch #47 - Loss: 1.0174916982650757\n",
      "Ep 15: Batch #48 - Loss: 1.4123212099075317\n",
      "Ep 15: Batch #49 - Loss: 1.0598822832107544\n",
      "Ep 15: Batch #50 - Loss: 0.7354378700256348\n",
      "Ep 15: Batch #51 - Loss: 1.0477839708328247\n",
      "Ep 15: Batch #52 - Loss: 0.8275260925292969\n",
      "Ep 15: Batch #53 - Loss: 0.863976240158081\n",
      "Ep 15: Batch #54 - Loss: 0.7394997477531433\n",
      "Ep 15: Batch #55 - Loss: 0.7967727780342102\n",
      "Ep 15: Batch #56 - Loss: 1.313808798789978\n",
      "Ep 15: Batch #57 - Loss: 0.9003461003303528\n",
      "Ep 15: Batch #58 - Loss: 1.0529319047927856\n",
      "Ep 15: Batch #59 - Loss: 0.714788019657135\n",
      "Ep 15: Batch #60 - Loss: 1.3625104427337646\n",
      "Ep 15: Batch #61 - Loss: 0.6720500588417053\n",
      "Ep 15: Batch #62 - Loss: 0.7658695578575134\n",
      "Ep 15: Batch #63 - Loss: 1.0573961734771729\n",
      "Ep 15: Batch #64 - Loss: 9.470913887023926\n",
      "Ep 15: Batch #65 - Loss: 0.643365740776062\n",
      "Ep 15: Batch #66 - Loss: 0.84784334897995\n",
      "Ep 15: Batch #67 - Loss: 0.953098714351654\n",
      "Ep 15: Batch #68 - Loss: 0.9550459384918213\n",
      "Ep 15: Batch #69 - Loss: 0.7871199250221252\n",
      "Ep 15: Batch #70 - Loss: 0.8287175297737122\n",
      "Ep 15: Batch #71 - Loss: 0.7160646915435791\n",
      "Ep 15: Batch #72 - Loss: 0.8988419771194458\n",
      "Ep 15: Batch #73 - Loss: 0.9553825259208679\n",
      "Ep 15: Batch #74 - Loss: 0.7810701131820679\n",
      "Ep 15: Batch #75 - Loss: 0.8052860498428345\n",
      "Ep 15: Batch #76 - Loss: 1.1344808340072632\n",
      "Ep 15: Batch #77 - Loss: 0.774148166179657\n",
      "Ep 15: Batch #78 - Loss: 1.2156351804733276\n",
      "Ep 15: Batch #79 - Loss: 0.6643691062927246\n",
      "Ep 15: Batch #80 - Loss: 0.9093578457832336\n",
      "Ep 15: Batch #81 - Loss: 1.7235091924667358\n",
      "Ep 15: Batch #82 - Loss: 0.9168830513954163\n",
      "Ep 15: Batch #83 - Loss: 1.7738007307052612\n",
      "Ep 15: Batch #84 - Loss: 0.7557684779167175\n",
      "Ep 15: Batch #85 - Loss: 1.0151832103729248\n",
      "Ep 15: Batch #86 - Loss: 0.7536516189575195\n",
      "Ep 15: Batch #87 - Loss: 0.7508141398429871\n",
      "Ep 15: Batch #88 - Loss: 0.8469015955924988\n",
      "Ep 15: Batch #89 - Loss: 0.9126917123794556\n",
      "Ep 15: Batch #90 - Loss: 1.2182120084762573\n",
      "Ep 15: Batch #91 - Loss: 0.8490484952926636\n",
      "Ep 15: Batch #92 - Loss: 1.0805857181549072\n",
      "Ep 15: Batch #93 - Loss: 1.0877331495285034\n",
      "Ep 15: Batch #94 - Loss: 1.1000235080718994\n",
      "Ep 15: Batch #95 - Loss: 0.9679200053215027\n",
      "Ep 15: Batch #96 - Loss: 0.947024941444397\n",
      "Ep 15: Batch #97 - Loss: 0.7704766392707825\n",
      "Ep 15: Batch #98 - Loss: 0.7819598317146301\n",
      "Ep 15: Batch #99 - Loss: 0.9991456866264343\n",
      "Ep 15: Batch #100 - Loss: 0.7184980511665344\n",
      "Ep 15: Batch #101 - Loss: 1.0934512615203857\n",
      "Ep 15: Batch #102 - Loss: 0.8207113146781921\n",
      "Ep 15: Batch #103 - Loss: 0.8266719579696655\n",
      "Ep 15: Batch #104 - Loss: 0.8439487814903259\n",
      "Ep 15: Batch #105 - Loss: 1.0758934020996094\n",
      "Ep 15: Batch #106 - Loss: 0.7977569103240967\n",
      "Ep 15: Batch #107 - Loss: 0.8030233979225159\n",
      "Ep 15: Batch #108 - Loss: 1.0855262279510498\n",
      "Ep 15: Batch #109 - Loss: 0.7985062003135681\n",
      "Ep 15: Batch #110 - Loss: 0.9703881740570068\n",
      "Ep 15: Batch #111 - Loss: 1.4311257600784302\n",
      "Ep 15: Batch #112 - Loss: 1.1027090549468994\n",
      "Ep 15: Batch #113 - Loss: 0.8599571585655212\n",
      "Ep 15: Batch #114 - Loss: 0.9489728212356567\n",
      "Ep 15: Batch #115 - Loss: 1.1397229433059692\n",
      "Ep 15: Batch #116 - Loss: 0.6602076292037964\n",
      "Ep 15: Batch #117 - Loss: 0.9125630259513855\n",
      "Ep 15: Batch #118 - Loss: 0.5813878178596497\n",
      "Model saved in file: ./weights_autoencoder_low_LR/model_e15b118_1516651270.6540582.ckpt\n",
      "Ep 15: Batch #119 - Loss: 1.072137713432312\n",
      "Ep 15: Batch #120 - Loss: 0.8329178690910339\n",
      "Ep 15: Batch #121 - Loss: 0.7250756025314331\n",
      "Ep 15: Batch #122 - Loss: 0.8680686354637146\n",
      "Ep 15: Batch #123 - Loss: 0.8709989190101624\n",
      "Ep 15: Batch #124 - Loss: 0.6943793892860413\n",
      "Ep 15: Batch #125 - Loss: 2.772449493408203\n",
      "Ep 15: Batch #126 - Loss: 1.276096224784851\n",
      "Ep 15: Batch #127 - Loss: 0.7972909808158875\n",
      "Ep 15: Batch #128 - Loss: 1.163442850112915\n",
      "Ep 15: Batch #129 - Loss: 0.8847957253456116\n",
      "Ep 15: Batch #130 - Loss: 0.7662891149520874\n",
      "Ep 15: Batch #131 - Loss: 1.0540714263916016\n",
      "Ep 15: Batch #132 - Loss: 0.8713974356651306\n",
      "Ep 15: Batch #133 - Loss: 0.8599728345870972\n",
      "Ep 15: Batch #134 - Loss: 0.8119285702705383\n",
      "Ep 15: Batch #135 - Loss: 1.0172722339630127\n",
      "Ep 15: Batch #136 - Loss: 1.2386243343353271\n",
      "Ep 15: Batch #137 - Loss: 1.0136100053787231\n",
      "Ep 15: Batch #138 - Loss: 1.1159861087799072\n",
      "Ep 15: Batch #139 - Loss: 0.9480810761451721\n",
      "Ep 15: Batch #140 - Loss: 1.0955862998962402\n",
      "Ep 15: Batch #141 - Loss: 1.4059005975723267\n",
      "Ep 15: Batch #142 - Loss: 0.832208514213562\n",
      "Ep 15: Batch #143 - Loss: 1.021530270576477\n",
      "Ep 15: Batch #144 - Loss: 0.7624741792678833\n",
      "Ep 15: Batch #145 - Loss: 0.7133923768997192\n",
      "Ep 15: Batch #146 - Loss: 0.9220452904701233\n",
      "Ep 15: Batch #147 - Loss: 0.9135143756866455\n",
      "Ep 15: Batch #148 - Loss: 1.0270072221755981\n",
      "Ep 15: Batch #149 - Loss: 0.9031150937080383\n",
      "Ep 15: Batch #150 - Loss: 0.920934796333313\n",
      "Ep 15: Batch #151 - Loss: 0.756839394569397\n",
      "Ep 15: Batch #152 - Loss: 0.7722527980804443\n",
      "Ep 15: Batch #153 - Loss: 1.155801773071289\n",
      "Ep 15: Batch #154 - Loss: 0.7983201742172241\n",
      "Ep 15: Batch #155 - Loss: 0.8804545998573303\n",
      "Ep 15: Batch #156 - Loss: 1.0651333332061768\n",
      "Ep 15: Batch #157 - Loss: 0.7999958992004395\n",
      "Ep 15: Batch #158 - Loss: 0.8395610451698303\n",
      "Ep 15: Batch #159 - Loss: 0.851324737071991\n",
      "Ep 15: Batch #160 - Loss: 0.940998375415802\n",
      "Ep 15: Batch #161 - Loss: 0.8577883839607239\n",
      "Ep 15: Batch #162 - Loss: 0.9774040579795837\n",
      "Ep 15: Batch #163 - Loss: 0.9662549495697021\n",
      "Ep 15: Batch #164 - Loss: 0.8237646222114563\n",
      "Ep 15: Batch #165 - Loss: 1.5395357608795166\n",
      "Ep 15: Batch #166 - Loss: 0.7220145463943481\n",
      "Ep 15: Batch #167 - Loss: 1.1312628984451294\n",
      "Ep 15: Batch #168 - Loss: 0.9066212773323059\n",
      "Ep 15: Batch #169 - Loss: 0.8423025012016296\n",
      "Ep 15: Batch #170 - Loss: 0.844990074634552\n",
      "Ep 15: Batch #171 - Loss: 0.8264655470848083\n",
      "Ep 15: Batch #172 - Loss: 0.6646034121513367\n",
      "Ep 15: Batch #173 - Loss: 1.2562918663024902\n",
      "Ep 15: Batch #174 - Loss: 0.613158643245697\n",
      "Ep 15: Batch #175 - Loss: 0.8139254450798035\n",
      "Ep 15: Batch #176 - Loss: 1.2008477449417114\n",
      "Ep 15: Batch #177 - Loss: 0.8907157182693481\n",
      "Ep 15: Batch #178 - Loss: 0.8078035116195679\n",
      "Ep 15: Batch #179 - Loss: 0.9907525181770325\n",
      "Ep 15: Batch #180 - Loss: 0.9094768166542053\n",
      "Ep 15: Batch #181 - Loss: 1.0464926958084106\n",
      "Ep 15: Batch #182 - Loss: 0.7999610304832458\n",
      "Ep 15: Batch #183 - Loss: 0.806816041469574\n",
      "Ep 15: Batch #184 - Loss: 1.107255220413208\n",
      "Ep 15: Batch #185 - Loss: 0.7948743104934692\n",
      "Ep 15: Batch #186 - Loss: 1.021935224533081\n",
      "Ep 15: Batch #187 - Loss: 1.2117587327957153\n",
      "Ep 15: Batch #188 - Loss: 1.3952581882476807\n",
      "Ep 15: Batch #189 - Loss: 0.7302368879318237\n",
      "Ep 15: Batch #190 - Loss: 0.7743827700614929\n",
      "Ep 15: Batch #191 - Loss: 1.1060799360275269\n",
      "Ep 15: Batch #192 - Loss: 0.6994813084602356\n",
      "Ep 15: Batch #193 - Loss: 0.7825204730033875\n",
      "Ep 15: Batch #194 - Loss: 0.7343950271606445\n",
      "Ep 15: Batch #195 - Loss: 1.0280600786209106\n",
      "Ep 15: Batch #196 - Loss: 0.9060394167900085\n",
      "Ep 15: Batch #197 - Loss: 0.943641722202301\n",
      "Ep 15: Batch #198 - Loss: 0.7168527841567993\n",
      "Ep 15: Batch #199 - Loss: 0.9054428339004517\n",
      "Ep 16: Batch #0 - Loss: 0.8396832346916199\n",
      "Ep 16: Batch #1 - Loss: 0.9218333959579468\n",
      "Ep 16: Batch #2 - Loss: 1.043603539466858\n",
      "Ep 16: Batch #3 - Loss: 0.9066463112831116\n",
      "Ep 16: Batch #4 - Loss: 0.8325924873352051\n",
      "Ep 16: Batch #5 - Loss: 0.6988267302513123\n",
      "Ep 16: Batch #6 - Loss: 0.9206628799438477\n",
      "Ep 16: Batch #7 - Loss: 0.7360319495201111\n",
      "Ep 16: Batch #8 - Loss: 0.7690401077270508\n",
      "Ep 16: Batch #9 - Loss: 1.4575626850128174\n",
      "Ep 16: Batch #10 - Loss: 1.0547173023223877\n",
      "Ep 16: Batch #11 - Loss: 0.7072062492370605\n",
      "Ep 16: Batch #12 - Loss: 1.5981249809265137\n",
      "Ep 16: Batch #13 - Loss: 0.6737976670265198\n",
      "Ep 16: Batch #14 - Loss: 0.7600607872009277\n",
      "Ep 16: Batch #15 - Loss: 1.2917014360427856\n",
      "Ep 16: Batch #16 - Loss: 1.338213324546814\n",
      "Ep 16: Batch #17 - Loss: 0.923849880695343\n",
      "Ep 16: Batch #18 - Loss: 0.9720025658607483\n",
      "Ep 16: Batch #19 - Loss: 0.699255108833313\n",
      "Ep 16: Batch #20 - Loss: 0.6907355785369873\n",
      "Ep 16: Batch #21 - Loss: 1.2552045583724976\n",
      "Ep 16: Batch #22 - Loss: 0.7587052583694458\n",
      "Ep 16: Batch #23 - Loss: 0.7879490852355957\n",
      "Ep 16: Batch #24 - Loss: 0.8585145473480225\n",
      "Ep 16: Batch #25 - Loss: 0.7577369213104248\n",
      "Ep 16: Batch #26 - Loss: 0.7741113901138306\n",
      "Ep 16: Batch #27 - Loss: 1.4031586647033691\n",
      "Ep 16: Batch #28 - Loss: 0.9081680178642273\n",
      "Ep 16: Batch #29 - Loss: 0.942120373249054\n",
      "Ep 16: Batch #30 - Loss: 1.2526100873947144\n",
      "Ep 16: Batch #31 - Loss: 0.7019315361976624\n",
      "Ep 16: Batch #32 - Loss: 0.7872495055198669\n",
      "Ep 16: Batch #33 - Loss: 0.8432227373123169\n",
      "Ep 16: Batch #34 - Loss: 0.822490394115448\n",
      "Ep 16: Batch #35 - Loss: 1.0013238191604614\n",
      "Ep 16: Batch #36 - Loss: 0.7375754714012146\n",
      "Ep 16: Batch #37 - Loss: 1.1824164390563965\n",
      "Ep 16: Batch #38 - Loss: 0.7910061478614807\n",
      "Ep 16: Batch #39 - Loss: 0.8511461019515991\n",
      "Ep 16: Batch #40 - Loss: 0.8166489601135254\n",
      "Ep 16: Batch #41 - Loss: 0.7767990827560425\n",
      "Ep 16: Batch #42 - Loss: 0.7560741901397705\n",
      "Ep 16: Batch #43 - Loss: 0.8263927698135376\n",
      "Ep 16: Batch #44 - Loss: 0.8232142925262451\n",
      "Ep 16: Batch #45 - Loss: 0.6768144965171814\n",
      "Ep 16: Batch #46 - Loss: 0.8744904398918152\n",
      "Ep 16: Batch #47 - Loss: 1.0156883001327515\n",
      "Ep 16: Batch #48 - Loss: 1.4101004600524902\n",
      "Ep 16: Batch #49 - Loss: 1.0584068298339844\n",
      "Ep 16: Batch #50 - Loss: 0.7342678904533386\n",
      "Ep 16: Batch #51 - Loss: 1.046134114265442\n",
      "Ep 16: Batch #52 - Loss: 0.8264562487602234\n",
      "Ep 16: Batch #53 - Loss: 0.8626375794410706\n",
      "Ep 16: Batch #54 - Loss: 0.7382387518882751\n",
      "Ep 16: Batch #55 - Loss: 0.795233964920044\n",
      "Ep 16: Batch #56 - Loss: 1.3121014833450317\n",
      "Ep 16: Batch #57 - Loss: 0.8983744978904724\n",
      "Ep 16: Batch #58 - Loss: 1.0512136220932007\n",
      "Ep 16: Batch #59 - Loss: 0.7135151028633118\n",
      "Ep 16: Batch #60 - Loss: 1.3603981733322144\n",
      "Ep 16: Batch #61 - Loss: 0.6707580089569092\n",
      "Ep 16: Batch #62 - Loss: 0.7644301056861877\n",
      "Ep 16: Batch #63 - Loss: 1.0553361177444458\n",
      "Ep 16: Batch #64 - Loss: 9.469754219055176\n",
      "Ep 16: Batch #65 - Loss: 0.6422828435897827\n",
      "Ep 16: Batch #66 - Loss: 0.8460932970046997\n",
      "Ep 16: Batch #67 - Loss: 0.9515339732170105\n",
      "Ep 16: Batch #68 - Loss: 0.953443706035614\n",
      "Ep 16: Batch #69 - Loss: 0.7856004238128662\n",
      "Ep 16: Batch #70 - Loss: 0.8268557786941528\n",
      "Ep 16: Batch #71 - Loss: 0.7148119211196899\n",
      "Ep 16: Batch #72 - Loss: 0.8972863554954529\n",
      "Ep 16: Batch #73 - Loss: 0.953781008720398\n",
      "Ep 16: Batch #74 - Loss: 0.779862642288208\n",
      "Ep 16: Batch #75 - Loss: 0.8041319847106934\n",
      "Ep 16: Batch #76 - Loss: 1.133100152015686\n",
      "Ep 16: Batch #77 - Loss: 0.772758424282074\n",
      "Ep 16: Batch #78 - Loss: 1.2139190435409546\n",
      "Ep 16: Batch #79 - Loss: 0.6629641652107239\n",
      "Ep 16: Batch #80 - Loss: 0.9075571894645691\n",
      "Ep 16: Batch #81 - Loss: 1.7225297689437866\n",
      "Ep 16: Batch #82 - Loss: 0.9153645038604736\n",
      "Ep 16: Batch #83 - Loss: 1.7720829248428345\n",
      "Ep 16: Batch #84 - Loss: 0.7543569803237915\n",
      "Ep 16: Batch #85 - Loss: 1.0135728120803833\n",
      "Ep 16: Batch #86 - Loss: 0.752080500125885\n",
      "Ep 16: Batch #87 - Loss: 0.7494184970855713\n",
      "Ep 16: Batch #88 - Loss: 0.8454225063323975\n",
      "Ep 16: Batch #89 - Loss: 0.9115784168243408\n",
      "Ep 16: Batch #90 - Loss: 1.2162367105484009\n",
      "Ep 16: Batch #91 - Loss: 0.8475099205970764\n",
      "Ep 16: Batch #92 - Loss: 1.078830599784851\n",
      "Ep 16: Batch #93 - Loss: 1.0856528282165527\n",
      "Ep 16: Batch #94 - Loss: 1.0983431339263916\n",
      "Ep 16: Batch #95 - Loss: 0.9661649465560913\n",
      "Ep 16: Batch #96 - Loss: 0.9456468820571899\n",
      "Ep 16: Batch #97 - Loss: 0.7691434025764465\n",
      "Ep 16: Batch #98 - Loss: 0.7804610133171082\n",
      "Ep 16: Batch #99 - Loss: 0.9977244734764099\n",
      "Ep 16: Batch #100 - Loss: 0.7171544432640076\n",
      "Ep 16: Batch #101 - Loss: 1.0918782949447632\n",
      "Ep 16: Batch #102 - Loss: 0.8193774223327637\n",
      "Ep 16: Batch #103 - Loss: 0.825468897819519\n",
      "Ep 16: Batch #104 - Loss: 0.842423677444458\n",
      "Ep 16: Batch #105 - Loss: 1.074342966079712\n",
      "Ep 16: Batch #106 - Loss: 0.7965768575668335\n",
      "Ep 16: Batch #107 - Loss: 0.8013491630554199\n",
      "Ep 16: Batch #108 - Loss: 1.083666205406189\n",
      "Ep 16: Batch #109 - Loss: 0.7972683906555176\n",
      "Ep 16: Batch #110 - Loss: 0.9687485098838806\n",
      "Ep 16: Batch #111 - Loss: 1.4295240640640259\n",
      "Ep 16: Batch #112 - Loss: 1.100762963294983\n",
      "Ep 16: Batch #113 - Loss: 0.8584339022636414\n",
      "Ep 16: Batch #114 - Loss: 0.9474934339523315\n",
      "Ep 16: Batch #115 - Loss: 1.1382330656051636\n",
      "Ep 16: Batch #116 - Loss: 0.659170389175415\n",
      "Ep 16: Batch #117 - Loss: 0.9110687971115112\n",
      "Ep 16: Batch #118 - Loss: 0.5799525380134583\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved in file: ./weights_autoencoder_low_LR/model_e16b118_1516651270.7892377.ckpt\n",
      "Ep 16: Batch #119 - Loss: 1.070683240890503\n",
      "Ep 16: Batch #120 - Loss: 0.8319060802459717\n",
      "Ep 16: Batch #121 - Loss: 0.723723828792572\n",
      "Ep 16: Batch #122 - Loss: 0.8664965033531189\n",
      "Ep 16: Batch #123 - Loss: 0.8697496652603149\n",
      "Ep 16: Batch #124 - Loss: 0.6931878328323364\n",
      "Ep 16: Batch #125 - Loss: 2.7705280780792236\n",
      "Ep 16: Batch #126 - Loss: 1.2742488384246826\n",
      "Ep 16: Batch #127 - Loss: 0.7955653667449951\n",
      "Ep 16: Batch #128 - Loss: 1.1615793704986572\n",
      "Ep 16: Batch #129 - Loss: 0.8832615613937378\n",
      "Ep 16: Batch #130 - Loss: 0.7647251486778259\n",
      "Ep 16: Batch #131 - Loss: 1.0520100593566895\n",
      "Ep 16: Batch #132 - Loss: 0.8698186874389648\n",
      "Ep 16: Batch #133 - Loss: 0.8584665060043335\n",
      "Ep 16: Batch #134 - Loss: 0.810551106929779\n",
      "Ep 16: Batch #135 - Loss: 1.0155442953109741\n",
      "Ep 16: Batch #136 - Loss: 1.2369056940078735\n",
      "Ep 16: Batch #137 - Loss: 1.011947512626648\n",
      "Ep 16: Batch #138 - Loss: 1.114624261856079\n",
      "Ep 16: Batch #139 - Loss: 0.9462193846702576\n",
      "Ep 16: Batch #140 - Loss: 1.0939940214157104\n",
      "Ep 16: Batch #141 - Loss: 1.4044125080108643\n",
      "Ep 16: Batch #142 - Loss: 0.8310303688049316\n",
      "Ep 16: Batch #143 - Loss: 1.0195459127426147\n",
      "Ep 16: Batch #144 - Loss: 0.7609636187553406\n",
      "Ep 16: Batch #145 - Loss: 0.7121689915657043\n",
      "Ep 16: Batch #146 - Loss: 0.9208493232727051\n",
      "Ep 16: Batch #147 - Loss: 0.9119566082954407\n",
      "Ep 16: Batch #148 - Loss: 1.0254974365234375\n",
      "Ep 16: Batch #149 - Loss: 0.9014683365821838\n",
      "Ep 16: Batch #150 - Loss: 0.9198867678642273\n",
      "Ep 16: Batch #151 - Loss: 0.755772590637207\n",
      "Ep 16: Batch #152 - Loss: 0.7710326910018921\n",
      "Ep 16: Batch #153 - Loss: 1.1540194749832153\n",
      "Ep 16: Batch #154 - Loss: 0.7972564697265625\n",
      "Ep 16: Batch #155 - Loss: 0.878741979598999\n",
      "Ep 16: Batch #156 - Loss: 1.0635408163070679\n",
      "Ep 16: Batch #157 - Loss: 0.7987736463546753\n",
      "Ep 16: Batch #158 - Loss: 0.8381160497665405\n",
      "Ep 16: Batch #159 - Loss: 0.8499054908752441\n",
      "Ep 16: Batch #160 - Loss: 0.9397950768470764\n",
      "Ep 16: Batch #161 - Loss: 0.8563165664672852\n",
      "Ep 16: Batch #162 - Loss: 0.9758253693580627\n",
      "Ep 16: Batch #163 - Loss: 0.9648491144180298\n",
      "Ep 16: Batch #164 - Loss: 0.8224600553512573\n",
      "Ep 16: Batch #165 - Loss: 1.5380308628082275\n",
      "Ep 16: Batch #166 - Loss: 0.7205460667610168\n",
      "Ep 16: Batch #167 - Loss: 1.1296833753585815\n",
      "Ep 16: Batch #168 - Loss: 0.9050832390785217\n",
      "Ep 16: Batch #169 - Loss: 0.840813398361206\n",
      "Ep 16: Batch #170 - Loss: 0.8436471223831177\n",
      "Ep 16: Batch #171 - Loss: 0.824771523475647\n",
      "Ep 16: Batch #172 - Loss: 0.6635292768478394\n",
      "Ep 16: Batch #173 - Loss: 1.2542434930801392\n",
      "Ep 16: Batch #174 - Loss: 0.6118404269218445\n",
      "Ep 16: Batch #175 - Loss: 0.8127237558364868\n",
      "Ep 16: Batch #176 - Loss: 1.1994857788085938\n",
      "Ep 16: Batch #177 - Loss: 0.8893236517906189\n",
      "Ep 16: Batch #178 - Loss: 0.8063207268714905\n",
      "Ep 16: Batch #179 - Loss: 0.9890224933624268\n",
      "Ep 16: Batch #180 - Loss: 0.9076685309410095\n",
      "Ep 16: Batch #181 - Loss: 1.0447678565979004\n",
      "Ep 16: Batch #182 - Loss: 0.7985584735870361\n",
      "Ep 16: Batch #183 - Loss: 0.8054725527763367\n",
      "Ep 16: Batch #184 - Loss: 1.1056872606277466\n",
      "Ep 16: Batch #185 - Loss: 0.7935969233512878\n",
      "Ep 16: Batch #186 - Loss: 1.0201553106307983\n",
      "Ep 16: Batch #187 - Loss: 1.210024356842041\n",
      "Ep 16: Batch #188 - Loss: 1.3933050632476807\n",
      "Ep 16: Batch #189 - Loss: 0.7293106317520142\n",
      "Ep 16: Batch #190 - Loss: 0.7728833556175232\n",
      "Ep 16: Batch #191 - Loss: 1.1046795845031738\n",
      "Ep 16: Batch #192 - Loss: 0.6984091401100159\n",
      "Ep 16: Batch #193 - Loss: 0.7811224460601807\n",
      "Ep 16: Batch #194 - Loss: 0.732975423336029\n",
      "Ep 16: Batch #195 - Loss: 1.026593804359436\n",
      "Ep 16: Batch #196 - Loss: 0.9045302867889404\n",
      "Ep 16: Batch #197 - Loss: 0.9422134757041931\n",
      "Ep 16: Batch #198 - Loss: 0.7155613899230957\n",
      "Ep 16: Batch #199 - Loss: 0.903950035572052\n",
      "Ep 17: Batch #0 - Loss: 0.8381279706954956\n",
      "Ep 17: Batch #1 - Loss: 0.9201276898384094\n",
      "Ep 17: Batch #2 - Loss: 1.042441725730896\n",
      "Ep 17: Batch #3 - Loss: 0.9049897789955139\n",
      "Ep 17: Batch #4 - Loss: 0.8310198783874512\n",
      "Ep 17: Batch #5 - Loss: 0.6975612640380859\n",
      "Ep 17: Batch #6 - Loss: 0.9189147353172302\n",
      "Ep 17: Batch #7 - Loss: 0.7346096634864807\n",
      "Ep 17: Batch #8 - Loss: 0.7677608132362366\n",
      "Ep 17: Batch #9 - Loss: 1.4557582139968872\n",
      "Ep 17: Batch #10 - Loss: 1.0528936386108398\n",
      "Ep 17: Batch #11 - Loss: 0.7057664394378662\n",
      "Ep 17: Batch #12 - Loss: 1.5970135927200317\n",
      "Ep 17: Batch #13 - Loss: 0.6729117035865784\n",
      "Ep 17: Batch #14 - Loss: 0.7588555812835693\n",
      "Ep 17: Batch #15 - Loss: 1.2896826267242432\n",
      "Ep 17: Batch #16 - Loss: 1.3360812664031982\n",
      "Ep 17: Batch #17 - Loss: 0.9223780035972595\n",
      "Ep 17: Batch #18 - Loss: 0.9709941744804382\n",
      "Ep 17: Batch #19 - Loss: 0.6981592774391174\n",
      "Ep 17: Batch #20 - Loss: 0.6893986463546753\n",
      "Ep 17: Batch #21 - Loss: 1.2536704540252686\n",
      "Ep 17: Batch #22 - Loss: 0.7574325203895569\n",
      "Ep 17: Batch #23 - Loss: 0.7862911224365234\n",
      "Ep 17: Batch #24 - Loss: 0.8572081327438354\n",
      "Ep 17: Batch #25 - Loss: 0.7561145424842834\n",
      "Ep 17: Batch #26 - Loss: 0.7726544141769409\n",
      "Ep 17: Batch #27 - Loss: 1.4015942811965942\n",
      "Ep 17: Batch #28 - Loss: 0.9066323041915894\n",
      "Ep 17: Batch #29 - Loss: 0.9403928518295288\n",
      "Ep 17: Batch #30 - Loss: 1.249903917312622\n",
      "Ep 17: Batch #31 - Loss: 0.7008433938026428\n",
      "Ep 17: Batch #32 - Loss: 0.7858616709709167\n",
      "Ep 17: Batch #33 - Loss: 0.841748833656311\n",
      "Ep 17: Batch #34 - Loss: 0.8210797905921936\n",
      "Ep 17: Batch #35 - Loss: 0.9994291663169861\n",
      "Ep 17: Batch #36 - Loss: 0.736320972442627\n",
      "Ep 17: Batch #37 - Loss: 1.1807538270950317\n",
      "Ep 17: Batch #38 - Loss: 0.7893620729446411\n",
      "Ep 17: Batch #39 - Loss: 0.8500968813896179\n",
      "Ep 17: Batch #40 - Loss: 0.8150043487548828\n",
      "Ep 17: Batch #41 - Loss: 0.7755494713783264\n",
      "Ep 17: Batch #42 - Loss: 0.7548643946647644\n",
      "Ep 17: Batch #43 - Loss: 0.8249157071113586\n",
      "Ep 17: Batch #44 - Loss: 0.8219178318977356\n",
      "Ep 17: Batch #45 - Loss: 0.6752445101737976\n",
      "Ep 17: Batch #46 - Loss: 0.8728731274604797\n",
      "Ep 17: Batch #47 - Loss: 1.0138578414916992\n",
      "Ep 17: Batch #48 - Loss: 1.4079408645629883\n",
      "Ep 17: Batch #49 - Loss: 1.0569387674331665\n",
      "Ep 17: Batch #50 - Loss: 0.7331075072288513\n",
      "Ep 17: Batch #51 - Loss: 1.0444425344467163\n",
      "Ep 17: Batch #52 - Loss: 0.8253507614135742\n",
      "Ep 17: Batch #53 - Loss: 0.8612849712371826\n",
      "Ep 17: Batch #54 - Loss: 0.7369556427001953\n",
      "Ep 17: Batch #55 - Loss: 0.7936414480209351\n",
      "Ep 17: Batch #56 - Loss: 1.3103861808776855\n",
      "Ep 17: Batch #57 - Loss: 0.8963568806648254\n",
      "Ep 17: Batch #58 - Loss: 1.0494780540466309\n",
      "Ep 17: Batch #59 - Loss: 0.7122385501861572\n",
      "Ep 17: Batch #60 - Loss: 1.3583332300186157\n",
      "Ep 17: Batch #61 - Loss: 0.6694495677947998\n",
      "Ep 17: Batch #62 - Loss: 0.7629580497741699\n",
      "Ep 17: Batch #63 - Loss: 1.053267002105713\n",
      "Ep 17: Batch #64 - Loss: 9.468576431274414\n",
      "Ep 17: Batch #65 - Loss: 0.6411620378494263\n",
      "Ep 17: Batch #66 - Loss: 0.8443414568901062\n",
      "Ep 17: Batch #67 - Loss: 0.9499607682228088\n",
      "Ep 17: Batch #68 - Loss: 0.9518080353736877\n",
      "Ep 17: Batch #69 - Loss: 0.7840660214424133\n",
      "Ep 17: Batch #70 - Loss: 0.8249527215957642\n",
      "Ep 17: Batch #71 - Loss: 0.7135024070739746\n",
      "Ep 17: Batch #72 - Loss: 0.8957081437110901\n",
      "Ep 17: Batch #73 - Loss: 0.9521281123161316\n",
      "Ep 17: Batch #74 - Loss: 0.778622567653656\n",
      "Ep 17: Batch #75 - Loss: 0.8029143214225769\n",
      "Ep 17: Batch #76 - Loss: 1.1316882371902466\n",
      "Ep 17: Batch #77 - Loss: 0.771356463432312\n",
      "Ep 17: Batch #78 - Loss: 1.2122083902359009\n",
      "Ep 17: Batch #79 - Loss: 0.6615377068519592\n",
      "Ep 17: Batch #80 - Loss: 0.9056848287582397\n",
      "Ep 17: Batch #81 - Loss: 1.7215354442596436\n",
      "Ep 17: Batch #82 - Loss: 0.913817286491394\n",
      "Ep 17: Batch #83 - Loss: 1.7702646255493164\n",
      "Ep 17: Batch #84 - Loss: 0.7529342770576477\n",
      "Ep 17: Batch #85 - Loss: 1.0119502544403076\n",
      "Ep 17: Batch #86 - Loss: 0.7505069971084595\n",
      "Ep 17: Batch #87 - Loss: 0.7480288147926331\n",
      "Ep 17: Batch #88 - Loss: 0.8439230918884277\n",
      "Ep 17: Batch #89 - Loss: 0.9104741811752319\n",
      "Ep 17: Batch #90 - Loss: 1.2142033576965332\n",
      "Ep 17: Batch #91 - Loss: 0.8459256887435913\n",
      "Ep 17: Batch #92 - Loss: 1.0770695209503174\n",
      "Ep 17: Batch #93 - Loss: 1.0835506916046143\n",
      "Ep 17: Batch #94 - Loss: 1.096657633781433\n",
      "Ep 17: Batch #95 - Loss: 0.964390218257904\n",
      "Ep 17: Batch #96 - Loss: 0.9442298412322998\n",
      "Ep 17: Batch #97 - Loss: 0.7678007483482361\n",
      "Ep 17: Batch #98 - Loss: 0.7789443731307983\n",
      "Ep 17: Batch #99 - Loss: 0.9962753653526306\n",
      "Ep 17: Batch #100 - Loss: 0.7157820463180542\n",
      "Ep 17: Batch #101 - Loss: 1.0902444124221802\n",
      "Ep 17: Batch #102 - Loss: 0.8180360198020935\n",
      "Ep 17: Batch #103 - Loss: 0.824234664440155\n",
      "Ep 17: Batch #104 - Loss: 0.8408474326133728\n",
      "Ep 17: Batch #105 - Loss: 1.072750449180603\n",
      "Ep 17: Batch #106 - Loss: 0.7953444719314575\n",
      "Ep 17: Batch #107 - Loss: 0.7996277809143066\n",
      "Ep 17: Batch #108 - Loss: 1.0817644596099854\n",
      "Ep 17: Batch #109 - Loss: 0.7960151433944702\n",
      "Ep 17: Batch #110 - Loss: 0.9670495390892029\n",
      "Ep 17: Batch #111 - Loss: 1.42787766456604\n",
      "Ep 17: Batch #112 - Loss: 1.0987800359725952\n",
      "Ep 17: Batch #113 - Loss: 0.8568649888038635\n",
      "Ep 17: Batch #114 - Loss: 0.9460052251815796\n",
      "Ep 17: Batch #115 - Loss: 1.1366941928863525\n",
      "Ep 17: Batch #116 - Loss: 0.6581346988677979\n",
      "Ep 17: Batch #117 - Loss: 0.9095826148986816\n",
      "Ep 17: Batch #118 - Loss: 0.5784871578216553\n",
      "Model saved in file: ./weights_autoencoder_low_LR/model_e17b118_1516651270.9263692.ckpt\n",
      "Ep 17: Batch #119 - Loss: 1.0692187547683716\n",
      "Ep 17: Batch #120 - Loss: 0.830847978591919\n",
      "Ep 17: Batch #121 - Loss: 0.7223555445671082\n",
      "Ep 17: Batch #122 - Loss: 0.864928662776947\n",
      "Ep 17: Batch #123 - Loss: 0.8684945106506348\n",
      "Ep 17: Batch #124 - Loss: 0.6919898390769958\n",
      "Ep 17: Batch #125 - Loss: 2.7685911655426025\n",
      "Ep 17: Batch #126 - Loss: 1.2724003791809082\n",
      "Ep 17: Batch #127 - Loss: 0.7938465476036072\n",
      "Ep 17: Batch #128 - Loss: 1.1597203016281128\n",
      "Ep 17: Batch #129 - Loss: 0.8816649317741394\n",
      "Ep 17: Batch #130 - Loss: 0.7631517052650452\n",
      "Ep 17: Batch #131 - Loss: 1.0498822927474976\n",
      "Ep 17: Batch #132 - Loss: 0.8682008385658264\n",
      "Ep 17: Batch #133 - Loss: 0.8569546341896057\n",
      "Ep 17: Batch #134 - Loss: 0.809076189994812\n",
      "Ep 17: Batch #135 - Loss: 1.0137463808059692\n",
      "Ep 17: Batch #136 - Loss: 1.2351343631744385\n",
      "Ep 17: Batch #137 - Loss: 1.010238766670227\n",
      "Ep 17: Batch #138 - Loss: 1.1132625341415405\n",
      "Ep 17: Batch #139 - Loss: 0.9444002509117126\n",
      "Ep 17: Batch #140 - Loss: 1.0923444032669067\n",
      "Ep 17: Batch #141 - Loss: 1.4028884172439575\n",
      "Ep 17: Batch #142 - Loss: 0.8298161625862122\n",
      "Ep 17: Batch #143 - Loss: 1.0175522565841675\n",
      "Ep 17: Batch #144 - Loss: 0.7594208121299744\n",
      "Ep 17: Batch #145 - Loss: 0.7109315395355225\n",
      "Ep 17: Batch #146 - Loss: 0.9195831418037415\n",
      "Ep 17: Batch #147 - Loss: 0.9103577136993408\n",
      "Ep 17: Batch #148 - Loss: 1.0239278078079224\n",
      "Ep 17: Batch #149 - Loss: 0.899803102016449\n",
      "Ep 17: Batch #150 - Loss: 0.9188359379768372\n",
      "Ep 17: Batch #151 - Loss: 0.7546935081481934\n",
      "Ep 17: Batch #152 - Loss: 0.7698133587837219\n",
      "Ep 17: Batch #153 - Loss: 1.1522259712219238\n",
      "Ep 17: Batch #154 - Loss: 0.7961693406105042\n",
      "Ep 17: Batch #155 - Loss: 0.8770022392272949\n",
      "Ep 17: Batch #156 - Loss: 1.0619498491287231\n",
      "Ep 17: Batch #157 - Loss: 0.7975475788116455\n",
      "Ep 17: Batch #158 - Loss: 0.8366936445236206\n",
      "Ep 17: Batch #159 - Loss: 0.8484756350517273\n",
      "Ep 17: Batch #160 - Loss: 0.9385426640510559\n",
      "Ep 17: Batch #161 - Loss: 0.854806125164032\n",
      "Ep 17: Batch #162 - Loss: 0.9742113351821899\n",
      "Ep 17: Batch #163 - Loss: 0.9634482264518738\n",
      "Ep 17: Batch #164 - Loss: 0.8211274743080139\n",
      "Ep 17: Batch #165 - Loss: 1.5365221500396729\n",
      "Ep 17: Batch #166 - Loss: 0.7190209031105042\n",
      "Ep 17: Batch #167 - Loss: 1.1280646324157715\n",
      "Ep 17: Batch #168 - Loss: 0.9034824967384338\n",
      "Ep 17: Batch #169 - Loss: 0.8393307328224182\n",
      "Ep 17: Batch #170 - Loss: 0.8422771096229553\n",
      "Ep 17: Batch #171 - Loss: 0.8230921030044556\n",
      "Ep 17: Batch #172 - Loss: 0.6624363660812378\n",
      "Ep 17: Batch #173 - Loss: 1.2521650791168213\n",
      "Ep 17: Batch #174 - Loss: 0.6105068325996399\n",
      "Ep 17: Batch #175 - Loss: 0.8115079998970032\n",
      "Ep 17: Batch #176 - Loss: 1.1981313228607178\n",
      "Ep 17: Batch #177 - Loss: 0.88791424036026\n",
      "Ep 17: Batch #178 - Loss: 0.8048176169395447\n",
      "Ep 17: Batch #179 - Loss: 0.9872897863388062\n",
      "Ep 17: Batch #180 - Loss: 0.9057913422584534\n",
      "Ep 17: Batch #181 - Loss: 1.043006420135498\n",
      "Ep 17: Batch #182 - Loss: 0.7971840500831604\n",
      "Ep 17: Batch #183 - Loss: 0.8041240572929382\n",
      "Ep 17: Batch #184 - Loss: 1.1040937900543213\n",
      "Ep 17: Batch #185 - Loss: 0.7923130393028259\n",
      "Ep 17: Batch #186 - Loss: 1.0182842016220093\n",
      "Ep 17: Batch #187 - Loss: 1.2083117961883545\n",
      "Ep 17: Batch #188 - Loss: 1.3913480043411255\n",
      "Ep 17: Batch #189 - Loss: 0.7283825278282166\n",
      "Ep 17: Batch #190 - Loss: 0.7713863253593445\n",
      "Ep 17: Batch #191 - Loss: 1.1033005714416504\n",
      "Ep 17: Batch #192 - Loss: 0.6972838044166565\n",
      "Ep 17: Batch #193 - Loss: 0.7797040343284607\n",
      "Ep 17: Batch #194 - Loss: 0.7315600514411926\n",
      "Ep 17: Batch #195 - Loss: 1.0250850915908813\n",
      "Ep 17: Batch #196 - Loss: 0.9030076265335083\n",
      "Ep 17: Batch #197 - Loss: 0.9407453536987305\n",
      "Ep 17: Batch #198 - Loss: 0.7142407894134521\n",
      "Ep 17: Batch #199 - Loss: 0.9024221897125244\n",
      "Ep 18: Batch #0 - Loss: 0.8365315198898315\n",
      "Ep 18: Batch #1 - Loss: 0.9183859825134277\n",
      "Ep 18: Batch #2 - Loss: 1.0412583351135254\n",
      "Ep 18: Batch #3 - Loss: 0.9033433198928833\n",
      "Ep 18: Batch #4 - Loss: 0.8294373154640198\n",
      "Ep 18: Batch #5 - Loss: 0.6962575316429138\n",
      "Ep 18: Batch #6 - Loss: 0.9172086715698242\n",
      "Ep 18: Batch #7 - Loss: 0.7332072257995605\n",
      "Ep 18: Batch #8 - Loss: 0.7664324045181274\n",
      "Ep 18: Batch #9 - Loss: 1.4539270401000977\n",
      "Ep 18: Batch #10 - Loss: 1.051064133644104\n",
      "Ep 18: Batch #11 - Loss: 0.7043486833572388\n",
      "Ep 18: Batch #12 - Loss: 1.5957894325256348\n",
      "Ep 18: Batch #13 - Loss: 0.6719805598258972\n",
      "Ep 18: Batch #14 - Loss: 0.7576382756233215\n",
      "Ep 18: Batch #15 - Loss: 1.287661075592041\n",
      "Ep 18: Batch #16 - Loss: 1.333892583847046\n",
      "Ep 18: Batch #17 - Loss: 0.9208940267562866\n",
      "Ep 18: Batch #18 - Loss: 0.9699582457542419\n",
      "Ep 18: Batch #19 - Loss: 0.6970312595367432\n",
      "Ep 18: Batch #20 - Loss: 0.6880512833595276\n",
      "Ep 18: Batch #21 - Loss: 1.2520933151245117\n",
      "Ep 18: Batch #22 - Loss: 0.7561437487602234\n",
      "Ep 18: Batch #23 - Loss: 0.7846179008483887\n",
      "Ep 18: Batch #24 - Loss: 0.8558992743492126\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 18: Batch #25 - Loss: 0.7544736266136169\n",
      "Ep 18: Batch #26 - Loss: 0.7711559534072876\n",
      "Ep 18: Batch #27 - Loss: 1.3999865055084229\n",
      "Ep 18: Batch #28 - Loss: 0.9051005840301514\n",
      "Ep 18: Batch #29 - Loss: 0.9385913610458374\n",
      "Ep 18: Batch #30 - Loss: 1.2472052574157715\n",
      "Ep 18: Batch #31 - Loss: 0.6997607350349426\n",
      "Ep 18: Batch #32 - Loss: 0.7844515442848206\n",
      "Ep 18: Batch #33 - Loss: 0.8402565121650696\n",
      "Ep 18: Batch #34 - Loss: 0.8196728229522705\n",
      "Ep 18: Batch #35 - Loss: 0.997515857219696\n",
      "Ep 18: Batch #36 - Loss: 0.7350424528121948\n",
      "Ep 18: Batch #37 - Loss: 1.1790863275527954\n",
      "Ep 18: Batch #38 - Loss: 0.7876839637756348\n",
      "Ep 18: Batch #39 - Loss: 0.8490037322044373\n",
      "Ep 18: Batch #40 - Loss: 0.8133672475814819\n",
      "Ep 18: Batch #41 - Loss: 0.7742630243301392\n",
      "Ep 18: Batch #42 - Loss: 0.7536463737487793\n",
      "Ep 18: Batch #43 - Loss: 0.823437511920929\n",
      "Ep 18: Batch #44 - Loss: 0.8206262588500977\n",
      "Ep 18: Batch #45 - Loss: 0.6736879348754883\n",
      "Ep 18: Batch #46 - Loss: 0.871271550655365\n",
      "Ep 18: Batch #47 - Loss: 1.0119843482971191\n",
      "Ep 18: Batch #48 - Loss: 1.4058430194854736\n",
      "Ep 18: Batch #49 - Loss: 1.0554964542388916\n",
      "Ep 18: Batch #50 - Loss: 0.7319453954696655\n",
      "Ep 18: Batch #51 - Loss: 1.0427167415618896\n",
      "Ep 18: Batch #52 - Loss: 0.8242300748825073\n",
      "Ep 18: Batch #53 - Loss: 0.8599152565002441\n",
      "Ep 18: Batch #54 - Loss: 0.7356393337249756\n",
      "Ep 18: Batch #55 - Loss: 0.7920000553131104\n",
      "Ep 18: Batch #56 - Loss: 1.3086119890213013\n",
      "Ep 18: Batch #57 - Loss: 0.8943825364112854\n",
      "Ep 18: Batch #58 - Loss: 1.0477197170257568\n",
      "Ep 18: Batch #59 - Loss: 0.7109622359275818\n",
      "Ep 18: Batch #60 - Loss: 1.3562883138656616\n",
      "Ep 18: Batch #61 - Loss: 0.6681418418884277\n",
      "Ep 18: Batch #62 - Loss: 0.7614774703979492\n",
      "Ep 18: Batch #63 - Loss: 1.0511717796325684\n",
      "Ep 18: Batch #64 - Loss: 9.467374801635742\n",
      "Ep 18: Batch #65 - Loss: 0.6400349736213684\n",
      "Ep 18: Batch #66 - Loss: 0.8425644040107727\n",
      "Ep 18: Batch #67 - Loss: 0.9483702182769775\n",
      "Ep 18: Batch #68 - Loss: 0.9501698613166809\n",
      "Ep 18: Batch #69 - Loss: 0.782538890838623\n",
      "Ep 18: Batch #70 - Loss: 0.823045551776886\n",
      "Ep 18: Batch #71 - Loss: 0.7121936678886414\n",
      "Ep 18: Batch #72 - Loss: 0.8941231966018677\n",
      "Ep 18: Batch #73 - Loss: 0.9504616856575012\n",
      "Ep 18: Batch #74 - Loss: 0.7773623466491699\n",
      "Ep 18: Batch #75 - Loss: 0.801674485206604\n",
      "Ep 18: Batch #76 - Loss: 1.1302717924118042\n",
      "Ep 18: Batch #77 - Loss: 0.7699577212333679\n",
      "Ep 18: Batch #78 - Loss: 1.2103567123413086\n",
      "Ep 18: Batch #79 - Loss: 0.6600881814956665\n",
      "Ep 18: Batch #80 - Loss: 0.9038318395614624\n",
      "Ep 18: Batch #81 - Loss: 1.7204819917678833\n",
      "Ep 18: Batch #82 - Loss: 0.9122398495674133\n",
      "Ep 18: Batch #83 - Loss: 1.7683638334274292\n",
      "Ep 18: Batch #84 - Loss: 0.751492977142334\n",
      "Ep 18: Batch #85 - Loss: 1.010313868522644\n",
      "Ep 18: Batch #86 - Loss: 0.7489327788352966\n",
      "Ep 18: Batch #87 - Loss: 0.7466558814048767\n",
      "Ep 18: Batch #88 - Loss: 0.8423948884010315\n",
      "Ep 18: Batch #89 - Loss: 0.9093732833862305\n",
      "Ep 18: Batch #90 - Loss: 1.2120909690856934\n",
      "Ep 18: Batch #91 - Loss: 0.8443179130554199\n",
      "Ep 18: Batch #92 - Loss: 1.0752977132797241\n",
      "Ep 18: Batch #93 - Loss: 1.081424355506897\n",
      "Ep 18: Batch #94 - Loss: 1.094984769821167\n",
      "Ep 18: Batch #95 - Loss: 0.9625886082649231\n",
      "Ep 18: Batch #96 - Loss: 0.9427880644798279\n",
      "Ep 18: Batch #97 - Loss: 0.7663924694061279\n",
      "Ep 18: Batch #98 - Loss: 0.7773990631103516\n",
      "Ep 18: Batch #99 - Loss: 0.9947952628135681\n",
      "Ep 18: Batch #100 - Loss: 0.7144030332565308\n",
      "Ep 18: Batch #101 - Loss: 1.0885874032974243\n",
      "Ep 18: Batch #102 - Loss: 0.816702127456665\n",
      "Ep 18: Batch #103 - Loss: 0.8229976296424866\n",
      "Ep 18: Batch #104 - Loss: 0.8392432928085327\n",
      "Ep 18: Batch #105 - Loss: 1.0711463689804077\n",
      "Ep 18: Batch #106 - Loss: 0.7940985560417175\n",
      "Ep 18: Batch #107 - Loss: 0.7978958487510681\n",
      "Ep 18: Batch #108 - Loss: 1.0798771381378174\n",
      "Ep 18: Batch #109 - Loss: 0.7947313785552979\n",
      "Ep 18: Batch #110 - Loss: 0.9653373956680298\n",
      "Ep 18: Batch #111 - Loss: 1.4262012243270874\n",
      "Ep 18: Batch #112 - Loss: 1.0967669486999512\n",
      "Ep 18: Batch #113 - Loss: 0.8552859425544739\n",
      "Ep 18: Batch #114 - Loss: 0.9444969296455383\n",
      "Ep 18: Batch #115 - Loss: 1.13510000705719\n",
      "Ep 18: Batch #116 - Loss: 0.6570870876312256\n",
      "Ep 18: Batch #117 - Loss: 0.9081175923347473\n",
      "Ep 18: Batch #118 - Loss: 0.5770329236984253\n",
      "Model saved in file: ./weights_autoencoder_low_LR/model_e18b118_1516651271.0644891.ckpt\n",
      "Ep 18: Batch #119 - Loss: 1.0677279233932495\n",
      "Ep 18: Batch #120 - Loss: 0.8297809958457947\n",
      "Ep 18: Batch #121 - Loss: 0.7209814190864563\n",
      "Ep 18: Batch #122 - Loss: 0.8633520007133484\n",
      "Ep 18: Batch #123 - Loss: 0.867214024066925\n",
      "Ep 18: Batch #124 - Loss: 0.6908164620399475\n",
      "Ep 18: Batch #125 - Loss: 2.7666242122650146\n",
      "Ep 18: Batch #126 - Loss: 1.2705469131469727\n",
      "Ep 18: Batch #127 - Loss: 0.792140543460846\n",
      "Ep 18: Batch #128 - Loss: 1.1578452587127686\n",
      "Ep 18: Batch #129 - Loss: 0.880001425743103\n",
      "Ep 18: Batch #130 - Loss: 0.7615568041801453\n",
      "Ep 18: Batch #131 - Loss: 1.0477104187011719\n",
      "Ep 18: Batch #132 - Loss: 0.8665401935577393\n",
      "Ep 18: Batch #133 - Loss: 0.8554552793502808\n",
      "Ep 18: Batch #134 - Loss: 0.8075990676879883\n",
      "Ep 18: Batch #135 - Loss: 1.011902093887329\n",
      "Ep 18: Batch #136 - Loss: 1.23331618309021\n",
      "Ep 18: Batch #137 - Loss: 1.0085043907165527\n",
      "Ep 18: Batch #138 - Loss: 1.1118243932724\n",
      "Ep 18: Batch #139 - Loss: 0.942620575428009\n",
      "Ep 18: Batch #140 - Loss: 1.0906902551651\n",
      "Ep 18: Batch #141 - Loss: 1.4012471437454224\n",
      "Ep 18: Batch #142 - Loss: 0.8286027908325195\n",
      "Ep 18: Batch #143 - Loss: 1.0155380964279175\n",
      "Ep 18: Batch #144 - Loss: 0.7578556537628174\n",
      "Ep 18: Batch #145 - Loss: 0.7096826434135437\n",
      "Ep 18: Batch #146 - Loss: 0.9182807803153992\n",
      "Ep 18: Batch #147 - Loss: 0.9087340831756592\n",
      "Ep 18: Batch #148 - Loss: 1.022317886352539\n",
      "Ep 18: Batch #149 - Loss: 0.8981249928474426\n",
      "Ep 18: Batch #150 - Loss: 0.9177658557891846\n",
      "Ep 18: Batch #151 - Loss: 0.7536107897758484\n",
      "Ep 18: Batch #152 - Loss: 0.7685836553573608\n",
      "Ep 18: Batch #153 - Loss: 1.1504485607147217\n",
      "Ep 18: Batch #154 - Loss: 0.7950655221939087\n",
      "Ep 18: Batch #155 - Loss: 0.8752589225769043\n",
      "Ep 18: Batch #156 - Loss: 1.0603551864624023\n",
      "Ep 18: Batch #157 - Loss: 0.7962919473648071\n",
      "Ep 18: Batch #158 - Loss: 0.8352903127670288\n",
      "Ep 18: Batch #159 - Loss: 0.8470205664634705\n",
      "Ep 18: Batch #160 - Loss: 0.9372776746749878\n",
      "Ep 18: Batch #161 - Loss: 0.8532888293266296\n",
      "Ep 18: Batch #162 - Loss: 0.972567081451416\n",
      "Ep 18: Batch #163 - Loss: 0.962069034576416\n",
      "Ep 18: Batch #164 - Loss: 0.8197810649871826\n",
      "Ep 18: Batch #165 - Loss: 1.5350291728973389\n",
      "Ep 18: Batch #166 - Loss: 0.7175344824790955\n",
      "Ep 18: Batch #167 - Loss: 1.1264312267303467\n",
      "Ep 18: Batch #168 - Loss: 0.9018697738647461\n",
      "Ep 18: Batch #169 - Loss: 0.8378450870513916\n",
      "Ep 18: Batch #170 - Loss: 0.8409313559532166\n",
      "Ep 18: Batch #171 - Loss: 0.821422815322876\n",
      "Ep 18: Batch #172 - Loss: 0.661328136920929\n",
      "Ep 18: Batch #173 - Loss: 1.2500971555709839\n",
      "Ep 18: Batch #174 - Loss: 0.609157383441925\n",
      "Ep 18: Batch #175 - Loss: 0.8102555871009827\n",
      "Ep 18: Batch #176 - Loss: 1.1966828107833862\n",
      "Ep 18: Batch #177 - Loss: 0.8864985704421997\n",
      "Ep 18: Batch #178 - Loss: 0.8033194541931152\n",
      "Ep 18: Batch #179 - Loss: 0.9855445027351379\n",
      "Ep 18: Batch #180 - Loss: 0.9039241075515747\n",
      "Ep 18: Batch #181 - Loss: 1.0412123203277588\n",
      "Ep 18: Batch #182 - Loss: 0.7958264350891113\n",
      "Ep 18: Batch #183 - Loss: 0.8027586936950684\n",
      "Ep 18: Batch #184 - Loss: 1.1024622917175293\n",
      "Ep 18: Batch #185 - Loss: 0.7910211086273193\n",
      "Ep 18: Batch #186 - Loss: 1.016371726989746\n",
      "Ep 18: Batch #187 - Loss: 1.2065953016281128\n",
      "Ep 18: Batch #188 - Loss: 1.389431357383728\n",
      "Ep 18: Batch #189 - Loss: 0.7274448871612549\n",
      "Ep 18: Batch #190 - Loss: 0.7698901295661926\n",
      "Ep 18: Batch #191 - Loss: 1.1019102334976196\n",
      "Ep 18: Batch #192 - Loss: 0.6961678862571716\n",
      "Ep 18: Batch #193 - Loss: 0.7782659530639648\n",
      "Ep 18: Batch #194 - Loss: 0.7301274538040161\n",
      "Ep 18: Batch #195 - Loss: 1.023564338684082\n",
      "Ep 18: Batch #196 - Loss: 0.9015005826950073\n",
      "Ep 18: Batch #197 - Loss: 0.9392550587654114\n",
      "Ep 18: Batch #198 - Loss: 0.7129240036010742\n",
      "Ep 18: Batch #199 - Loss: 0.9008896350860596\n",
      "Ep 19: Batch #0 - Loss: 0.8348445296287537\n",
      "Ep 19: Batch #1 - Loss: 0.9166561961174011\n",
      "Ep 19: Batch #2 - Loss: 1.040056824684143\n",
      "Ep 19: Batch #3 - Loss: 0.9017125964164734\n",
      "Ep 19: Batch #4 - Loss: 0.8278647065162659\n",
      "Ep 19: Batch #5 - Loss: 0.6949544548988342\n",
      "Ep 19: Batch #6 - Loss: 0.915531575679779\n",
      "Ep 19: Batch #7 - Loss: 0.7318260073661804\n",
      "Ep 19: Batch #8 - Loss: 0.765126645565033\n",
      "Ep 19: Batch #9 - Loss: 1.4520167112350464\n",
      "Ep 19: Batch #10 - Loss: 1.049217939376831\n",
      "Ep 19: Batch #11 - Loss: 0.7029394507408142\n",
      "Ep 19: Batch #12 - Loss: 1.594505786895752\n",
      "Ep 19: Batch #13 - Loss: 0.6710532903671265\n",
      "Ep 19: Batch #14 - Loss: 0.7564297914505005\n",
      "Ep 19: Batch #15 - Loss: 1.2856734991073608\n",
      "Ep 19: Batch #16 - Loss: 1.3316611051559448\n",
      "Ep 19: Batch #17 - Loss: 0.9193975329399109\n",
      "Ep 19: Batch #18 - Loss: 0.9688805937767029\n",
      "Ep 19: Batch #19 - Loss: 0.6959197521209717\n",
      "Ep 19: Batch #20 - Loss: 0.6867116689682007\n",
      "Ep 19: Batch #21 - Loss: 1.2505381107330322\n",
      "Ep 19: Batch #22 - Loss: 0.7548661231994629\n",
      "Ep 19: Batch #23 - Loss: 0.7829314470291138\n",
      "Ep 19: Batch #24 - Loss: 0.8545975685119629\n",
      "Ep 19: Batch #25 - Loss: 0.7528455853462219\n",
      "Ep 19: Batch #26 - Loss: 0.7696484923362732\n",
      "Ep 19: Batch #27 - Loss: 1.3983570337295532\n",
      "Ep 19: Batch #28 - Loss: 0.9035414457321167\n",
      "Ep 19: Batch #29 - Loss: 0.9367846846580505\n",
      "Ep 19: Batch #30 - Loss: 1.2446295022964478\n",
      "Ep 19: Batch #31 - Loss: 0.6986549496650696\n",
      "Ep 19: Batch #32 - Loss: 0.7830427885055542\n",
      "Ep 19: Batch #33 - Loss: 0.8387573957443237\n",
      "Ep 19: Batch #34 - Loss: 0.8182500004768372\n",
      "Ep 19: Batch #35 - Loss: 0.9956133365631104\n",
      "Ep 19: Batch #36 - Loss: 0.7337684035301208\n",
      "Ep 19: Batch #37 - Loss: 1.1774553060531616\n",
      "Ep 19: Batch #38 - Loss: 0.7859970331192017\n",
      "Ep 19: Batch #39 - Loss: 0.8479018211364746\n",
      "Ep 19: Batch #40 - Loss: 0.8117530941963196\n",
      "Ep 19: Batch #41 - Loss: 0.7729870080947876\n",
      "Ep 19: Batch #42 - Loss: 0.752410352230072\n",
      "Ep 19: Batch #43 - Loss: 0.8219501376152039\n",
      "Ep 19: Batch #44 - Loss: 0.8193008899688721\n",
      "Ep 19: Batch #45 - Loss: 0.672126054763794\n",
      "Ep 19: Batch #46 - Loss: 0.869666576385498\n",
      "Ep 19: Batch #47 - Loss: 1.0100897550582886\n",
      "Ep 19: Batch #48 - Loss: 1.4037871360778809\n",
      "Ep 19: Batch #49 - Loss: 1.0540835857391357\n",
      "Ep 19: Batch #50 - Loss: 0.7307971715927124\n",
      "Ep 19: Batch #51 - Loss: 1.040994644165039\n",
      "Ep 19: Batch #52 - Loss: 0.8230885863304138\n",
      "Ep 19: Batch #53 - Loss: 0.8585168719291687\n",
      "Ep 19: Batch #54 - Loss: 0.7343379855155945\n",
      "Ep 19: Batch #55 - Loss: 0.7903673052787781\n",
      "Ep 19: Batch #56 - Loss: 1.3068301677703857\n",
      "Ep 19: Batch #57 - Loss: 0.8924381136894226\n",
      "Ep 19: Batch #58 - Loss: 1.0459128618240356\n",
      "Ep 19: Batch #59 - Loss: 0.7096979022026062\n",
      "Ep 19: Batch #60 - Loss: 1.35427987575531\n",
      "Ep 19: Batch #61 - Loss: 0.6668446063995361\n",
      "Ep 19: Batch #62 - Loss: 0.759976863861084\n",
      "Ep 19: Batch #63 - Loss: 1.0490922927856445\n",
      "Ep 19: Batch #64 - Loss: 9.466170310974121\n",
      "Ep 19: Batch #65 - Loss: 0.6389208436012268\n",
      "Ep 19: Batch #66 - Loss: 0.840796709060669\n",
      "Ep 19: Batch #67 - Loss: 0.9468091726303101\n",
      "Ep 19: Batch #68 - Loss: 0.9485527873039246\n",
      "Ep 19: Batch #69 - Loss: 0.7810113430023193\n",
      "Ep 19: Batch #70 - Loss: 0.8211520314216614\n",
      "Ep 19: Batch #71 - Loss: 0.710906445980072\n",
      "Ep 19: Batch #72 - Loss: 0.8925412893295288\n",
      "Ep 19: Batch #73 - Loss: 0.9487844705581665\n",
      "Ep 19: Batch #74 - Loss: 0.776094913482666\n",
      "Ep 19: Batch #75 - Loss: 0.8004211783409119\n",
      "Ep 19: Batch #76 - Loss: 1.1288254261016846\n",
      "Ep 19: Batch #77 - Loss: 0.7685641646385193\n",
      "Ep 19: Batch #78 - Loss: 1.2084310054779053\n",
      "Ep 19: Batch #79 - Loss: 0.6586311459541321\n",
      "Ep 19: Batch #80 - Loss: 0.9020024538040161\n",
      "Ep 19: Batch #81 - Loss: 1.7194052934646606\n",
      "Ep 19: Batch #82 - Loss: 0.9106138348579407\n",
      "Ep 19: Batch #83 - Loss: 1.7664607763290405\n",
      "Ep 19: Batch #84 - Loss: 0.7500505447387695\n",
      "Ep 19: Batch #85 - Loss: 1.0086784362792969\n",
      "Ep 19: Batch #86 - Loss: 0.747337281703949\n",
      "Ep 19: Batch #87 - Loss: 0.7452875375747681\n",
      "Ep 19: Batch #88 - Loss: 0.8408522605895996\n",
      "Ep 19: Batch #89 - Loss: 0.9082727432250977\n",
      "Ep 19: Batch #90 - Loss: 1.2099311351776123\n",
      "Ep 19: Batch #91 - Loss: 0.8426954746246338\n",
      "Ep 19: Batch #92 - Loss: 1.073468565940857\n",
      "Ep 19: Batch #93 - Loss: 1.0793492794036865\n",
      "Ep 19: Batch #94 - Loss: 1.0933247804641724\n",
      "Ep 19: Batch #95 - Loss: 0.9608228206634521\n",
      "Ep 19: Batch #96 - Loss: 0.9413434267044067\n",
      "Ep 19: Batch #97 - Loss: 0.7649737000465393\n",
      "Ep 19: Batch #98 - Loss: 0.7758485078811646\n",
      "Ep 19: Batch #99 - Loss: 0.9933010935783386\n",
      "Ep 19: Batch #100 - Loss: 0.7129906415939331\n",
      "Ep 19: Batch #101 - Loss: 1.0869179964065552\n",
      "Ep 19: Batch #102 - Loss: 0.8153709173202515\n",
      "Ep 19: Batch #103 - Loss: 0.8217619061470032\n",
      "Ep 19: Batch #104 - Loss: 0.8376442790031433\n",
      "Ep 19: Batch #105 - Loss: 1.0695515871047974\n",
      "Ep 19: Batch #106 - Loss: 0.7928622961044312\n",
      "Ep 19: Batch #107 - Loss: 0.7961385846138\n",
      "Ep 19: Batch #108 - Loss: 1.0780106782913208\n",
      "Ep 19: Batch #109 - Loss: 0.7934751510620117\n",
      "Ep 19: Batch #110 - Loss: 0.9636049270629883\n",
      "Ep 19: Batch #111 - Loss: 1.4244914054870605\n",
      "Ep 19: Batch #112 - Loss: 1.0947551727294922\n",
      "Ep 19: Batch #113 - Loss: 0.8537166118621826\n",
      "Ep 19: Batch #114 - Loss: 0.9429607391357422\n",
      "Ep 19: Batch #115 - Loss: 1.1335159540176392\n",
      "Ep 19: Batch #116 - Loss: 0.6560459733009338\n",
      "Ep 19: Batch #117 - Loss: 0.9066600203514099\n",
      "Ep 19: Batch #118 - Loss: 0.5755886435508728\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved in file: ./weights_autoencoder_low_LR/model_e19b118_1516651271.2007508.ckpt\n",
      "Ep 19: Batch #119 - Loss: 1.066198468208313\n",
      "Ep 19: Batch #120 - Loss: 0.8287128210067749\n",
      "Ep 19: Batch #121 - Loss: 0.719589352607727\n",
      "Ep 19: Batch #122 - Loss: 0.8617889881134033\n",
      "Ep 19: Batch #123 - Loss: 0.8658868074417114\n",
      "Ep 19: Batch #124 - Loss: 0.6896666884422302\n",
      "Ep 19: Batch #125 - Loss: 2.7646257877349854\n",
      "Ep 19: Batch #126 - Loss: 1.2686690092086792\n",
      "Ep 19: Batch #127 - Loss: 0.7904523611068726\n",
      "Ep 19: Batch #128 - Loss: 1.155985713005066\n",
      "Ep 19: Batch #129 - Loss: 0.8783355951309204\n",
      "Ep 19: Batch #130 - Loss: 0.7599612474441528\n",
      "Ep 19: Batch #131 - Loss: 1.0455697774887085\n",
      "Ep 19: Batch #132 - Loss: 0.864891529083252\n",
      "Ep 19: Batch #133 - Loss: 0.8539447784423828\n",
      "Ep 19: Batch #134 - Loss: 0.8061049580574036\n",
      "Ep 19: Batch #135 - Loss: 1.0100327730178833\n",
      "Ep 19: Batch #136 - Loss: 1.2314753532409668\n",
      "Ep 19: Batch #137 - Loss: 1.0067932605743408\n",
      "Ep 19: Batch #138 - Loss: 1.1103756427764893\n",
      "Ep 19: Batch #139 - Loss: 0.9409098029136658\n",
      "Ep 19: Batch #140 - Loss: 1.0890190601348877\n",
      "Ep 19: Batch #141 - Loss: 1.399607539176941\n",
      "Ep 19: Batch #142 - Loss: 0.8273879885673523\n",
      "Ep 19: Batch #143 - Loss: 1.0135207176208496\n",
      "Ep 19: Batch #144 - Loss: 0.7562849521636963\n",
      "Ep 19: Batch #145 - Loss: 0.7084335684776306\n",
      "Ep 19: Batch #146 - Loss: 0.9169906973838806\n",
      "Ep 19: Batch #147 - Loss: 0.9071156978607178\n",
      "Ep 19: Batch #148 - Loss: 1.0206748247146606\n",
      "Ep 19: Batch #149 - Loss: 0.8964470624923706\n",
      "Ep 19: Batch #150 - Loss: 0.9166858196258545\n",
      "Ep 19: Batch #151 - Loss: 0.7525199055671692\n",
      "Ep 19: Batch #152 - Loss: 0.7673497200012207\n",
      "Ep 19: Batch #153 - Loss: 1.1486846208572388\n",
      "Ep 19: Batch #154 - Loss: 0.7939538955688477\n",
      "Ep 19: Batch #155 - Loss: 0.8735190629959106\n",
      "Ep 19: Batch #156 - Loss: 1.0587635040283203\n",
      "Ep 19: Batch #157 - Loss: 0.7950053811073303\n",
      "Ep 19: Batch #158 - Loss: 0.833920419216156\n",
      "Ep 19: Batch #159 - Loss: 0.8455545902252197\n",
      "Ep 19: Batch #160 - Loss: 0.9359837174415588\n",
      "Ep 19: Batch #161 - Loss: 0.8517698049545288\n",
      "Ep 19: Batch #162 - Loss: 0.9709105491638184\n",
      "Ep 19: Batch #163 - Loss: 0.9607046246528625\n",
      "Ep 19: Batch #164 - Loss: 0.8184359073638916\n",
      "Ep 19: Batch #165 - Loss: 1.5335546731948853\n",
      "Ep 19: Batch #166 - Loss: 0.716064453125\n",
      "Ep 19: Batch #167 - Loss: 1.1248283386230469\n",
      "Ep 19: Batch #168 - Loss: 0.9002673029899597\n",
      "Ep 19: Batch #169 - Loss: 0.8363723754882812\n",
      "Ep 19: Batch #170 - Loss: 0.8395618200302124\n",
      "Ep 19: Batch #171 - Loss: 0.8198006749153137\n",
      "Ep 19: Batch #172 - Loss: 0.6602319478988647\n",
      "Ep 19: Batch #173 - Loss: 1.2480252981185913\n",
      "Ep 19: Batch #174 - Loss: 0.6078001260757446\n",
      "Ep 19: Batch #175 - Loss: 0.8089949488639832\n",
      "Ep 19: Batch #176 - Loss: 1.1952555179595947\n",
      "Ep 19: Batch #177 - Loss: 0.8850757479667664\n",
      "Ep 19: Batch #178 - Loss: 0.8018154501914978\n",
      "Ep 19: Batch #179 - Loss: 0.9838077425956726\n",
      "Ep 19: Batch #180 - Loss: 0.902051568031311\n",
      "Ep 19: Batch #181 - Loss: 1.0394155979156494\n",
      "Ep 19: Batch #182 - Loss: 0.7944859862327576\n",
      "Ep 19: Batch #183 - Loss: 0.8013727068901062\n",
      "Ep 19: Batch #184 - Loss: 1.1009122133255005\n",
      "Ep 19: Batch #185 - Loss: 0.7897272109985352\n",
      "Ep 19: Batch #186 - Loss: 1.0144338607788086\n",
      "Ep 19: Batch #187 - Loss: 1.2049182653427124\n",
      "Ep 19: Batch #188 - Loss: 1.3875614404678345\n",
      "Ep 19: Batch #189 - Loss: 0.7264560461044312\n",
      "Ep 19: Batch #190 - Loss: 0.7684242725372314\n",
      "Ep 19: Batch #191 - Loss: 1.1005141735076904\n",
      "Ep 19: Batch #192 - Loss: 0.6950615644454956\n",
      "Ep 19: Batch #193 - Loss: 0.7768397927284241\n",
      "Ep 19: Batch #194 - Loss: 0.7287018299102783\n",
      "Ep 19: Batch #195 - Loss: 1.0220431089401245\n",
      "Ep 19: Batch #196 - Loss: 0.899998664855957\n",
      "Ep 19: Batch #197 - Loss: 0.937781572341919\n",
      "Ep 19: Batch #198 - Loss: 0.7115887999534607\n",
      "Ep 19: Batch #199 - Loss: 0.8993362784385681\n",
      "Ep 20: Batch #0 - Loss: 0.8331380486488342\n",
      "Ep 20: Batch #1 - Loss: 0.9149495959281921\n",
      "Ep 20: Batch #2 - Loss: 1.0388500690460205\n",
      "Ep 20: Batch #3 - Loss: 0.9001061320304871\n",
      "Ep 20: Batch #4 - Loss: 0.8263148665428162\n",
      "Ep 20: Batch #5 - Loss: 0.6936671733856201\n",
      "Ep 20: Batch #6 - Loss: 0.9139153361320496\n",
      "Ep 20: Batch #7 - Loss: 0.7304692268371582\n",
      "Ep 20: Batch #8 - Loss: 0.7638356685638428\n",
      "Ep 20: Batch #9 - Loss: 1.4500986337661743\n",
      "Ep 20: Batch #10 - Loss: 1.0473936796188354\n",
      "Ep 20: Batch #11 - Loss: 0.7015401124954224\n",
      "Ep 20: Batch #12 - Loss: 1.5931826829910278\n",
      "Ep 20: Batch #13 - Loss: 0.6701469421386719\n",
      "Ep 20: Batch #14 - Loss: 0.7552369236946106\n",
      "Ep 20: Batch #15 - Loss: 1.2837169170379639\n",
      "Ep 20: Batch #16 - Loss: 1.329437255859375\n",
      "Ep 20: Batch #17 - Loss: 0.9178881049156189\n",
      "Ep 20: Batch #18 - Loss: 0.9677837491035461\n",
      "Ep 20: Batch #19 - Loss: 0.6947962045669556\n",
      "Ep 20: Batch #20 - Loss: 0.6853870153427124\n",
      "Ep 20: Batch #21 - Loss: 1.249009370803833\n",
      "Ep 20: Batch #22 - Loss: 0.7536189556121826\n",
      "Ep 20: Batch #23 - Loss: 0.7812554836273193\n",
      "Ep 20: Batch #24 - Loss: 0.8532942533493042\n",
      "Ep 20: Batch #25 - Loss: 0.7512348294258118\n",
      "Ep 20: Batch #26 - Loss: 0.7681379318237305\n",
      "Ep 20: Batch #27 - Loss: 1.3967442512512207\n",
      "Ep 20: Batch #28 - Loss: 0.9019942879676819\n",
      "Ep 20: Batch #29 - Loss: 0.9349828362464905\n",
      "Ep 20: Batch #30 - Loss: 1.2422226667404175\n",
      "Ep 20: Batch #31 - Loss: 0.6975587010383606\n",
      "Ep 20: Batch #32 - Loss: 0.7816318869590759\n",
      "Ep 20: Batch #33 - Loss: 0.8372854590415955\n",
      "Ep 20: Batch #34 - Loss: 0.8168307542800903\n",
      "Ep 20: Batch #35 - Loss: 0.9937217831611633\n",
      "Ep 20: Batch #36 - Loss: 0.732501745223999\n",
      "Ep 20: Batch #37 - Loss: 1.1758732795715332\n",
      "Ep 20: Batch #38 - Loss: 0.7843160033226013\n",
      "Ep 20: Batch #39 - Loss: 0.8467912673950195\n",
      "Ep 20: Batch #40 - Loss: 0.810142993927002\n",
      "Ep 20: Batch #41 - Loss: 0.7716981172561646\n",
      "Ep 20: Batch #42 - Loss: 0.7511910796165466\n",
      "Ep 20: Batch #43 - Loss: 0.8204684257507324\n",
      "Ep 20: Batch #44 - Loss: 0.8179529905319214\n",
      "Ep 20: Batch #45 - Loss: 0.6705623269081116\n",
      "Ep 20: Batch #46 - Loss: 0.8680568933486938\n",
      "Ep 20: Batch #47 - Loss: 1.0081636905670166\n",
      "Ep 20: Batch #48 - Loss: 1.40175461769104\n",
      "Ep 20: Batch #49 - Loss: 1.052696943283081\n",
      "Ep 20: Batch #50 - Loss: 0.7296823263168335\n",
      "Ep 20: Batch #51 - Loss: 1.0392756462097168\n",
      "Ep 20: Batch #52 - Loss: 0.8219258785247803\n",
      "Ep 20: Batch #53 - Loss: 0.8570799231529236\n",
      "Ep 20: Batch #54 - Loss: 0.7330465316772461\n",
      "Ep 20: Batch #55 - Loss: 0.7887480854988098\n",
      "Ep 20: Batch #56 - Loss: 1.3050450086593628\n",
      "Ep 20: Batch #57 - Loss: 0.8905300498008728\n",
      "Ep 20: Batch #58 - Loss: 1.0441135168075562\n",
      "Ep 20: Batch #59 - Loss: 0.7084540128707886\n",
      "Ep 20: Batch #60 - Loss: 1.3522886037826538\n",
      "Ep 20: Batch #61 - Loss: 0.6655532717704773\n",
      "Ep 20: Batch #62 - Loss: 0.7584843039512634\n",
      "Ep 20: Batch #63 - Loss: 1.0470370054244995\n",
      "Ep 20: Batch #64 - Loss: 9.464969635009766\n",
      "Ep 20: Batch #65 - Loss: 0.637813925743103\n",
      "Ep 20: Batch #66 - Loss: 0.8390505909919739\n",
      "Ep 20: Batch #67 - Loss: 0.9452887177467346\n",
      "Ep 20: Batch #68 - Loss: 0.9469483494758606\n",
      "Ep 20: Batch #69 - Loss: 0.7794587016105652\n",
      "Ep 20: Batch #70 - Loss: 0.8192614316940308\n",
      "Ep 20: Batch #71 - Loss: 0.7096421122550964\n",
      "Ep 20: Batch #72 - Loss: 0.8909680843353271\n",
      "Ep 20: Batch #73 - Loss: 0.9470840692520142\n",
      "Ep 20: Batch #74 - Loss: 0.7747989892959595\n",
      "Ep 20: Batch #75 - Loss: 0.7991340756416321\n",
      "Ep 20: Batch #76 - Loss: 1.1273670196533203\n",
      "Ep 20: Batch #77 - Loss: 0.7671682834625244\n",
      "Ep 20: Batch #78 - Loss: 1.2065024375915527\n",
      "Ep 20: Batch #79 - Loss: 0.6571786999702454\n",
      "Ep 20: Batch #80 - Loss: 0.9001976847648621\n",
      "Ep 20: Batch #81 - Loss: 1.718232274055481\n",
      "Ep 20: Batch #82 - Loss: 0.9090074300765991\n",
      "Ep 20: Batch #83 - Loss: 1.7646106481552124\n",
      "Ep 20: Batch #84 - Loss: 0.7486110925674438\n",
      "Ep 20: Batch #85 - Loss: 1.0070561170578003\n",
      "Ep 20: Batch #86 - Loss: 0.7457398772239685\n",
      "Ep 20: Batch #87 - Loss: 0.7439207434654236\n",
      "Ep 20: Batch #88 - Loss: 0.8392893075942993\n",
      "Ep 20: Batch #89 - Loss: 0.9071712493896484\n",
      "Ep 20: Batch #90 - Loss: 1.2077571153640747\n",
      "Ep 20: Batch #91 - Loss: 0.8410598635673523\n",
      "Ep 20: Batch #92 - Loss: 1.071630597114563\n",
      "Ep 20: Batch #93 - Loss: 1.0773124694824219\n",
      "Ep 20: Batch #94 - Loss: 1.0916587114334106\n",
      "Ep 20: Batch #95 - Loss: 0.9590469598770142\n",
      "Ep 20: Batch #96 - Loss: 0.9399146437644958\n",
      "Ep 20: Batch #97 - Loss: 0.7635583877563477\n",
      "Ep 20: Batch #98 - Loss: 0.7742888927459717\n",
      "Ep 20: Batch #99 - Loss: 0.9918327927589417\n",
      "Ep 20: Batch #100 - Loss: 0.7115346193313599\n",
      "Ep 20: Batch #101 - Loss: 1.08524489402771\n",
      "Ep 20: Batch #102 - Loss: 0.8140509724617004\n",
      "Ep 20: Batch #103 - Loss: 0.8204960227012634\n",
      "Ep 20: Batch #104 - Loss: 0.836046040058136\n",
      "Ep 20: Batch #105 - Loss: 1.0679354667663574\n",
      "Ep 20: Batch #106 - Loss: 0.7916352152824402\n",
      "Ep 20: Batch #107 - Loss: 0.7944290041923523\n",
      "Ep 20: Batch #108 - Loss: 1.0761650800704956\n",
      "Ep 20: Batch #109 - Loss: 0.7921997904777527\n",
      "Ep 20: Batch #110 - Loss: 0.9618280529975891\n",
      "Ep 20: Batch #111 - Loss: 1.4227409362792969\n",
      "Ep 20: Batch #112 - Loss: 1.0927485227584839\n",
      "Ep 20: Batch #113 - Loss: 0.8521715998649597\n",
      "Ep 20: Batch #114 - Loss: 0.9413919448852539\n",
      "Ep 20: Batch #115 - Loss: 1.1319471597671509\n",
      "Ep 20: Batch #116 - Loss: 0.6550238728523254\n",
      "Ep 20: Batch #117 - Loss: 0.9051827788352966\n",
      "Ep 20: Batch #118 - Loss: 0.5741680264472961\n",
      "Model saved in file: ./weights_autoencoder_low_LR/model_e20b118_1516651271.3371918.ckpt\n",
      "Ep 20: Batch #119 - Loss: 1.0646635293960571\n",
      "Ep 20: Batch #120 - Loss: 0.8276309967041016\n",
      "Ep 20: Batch #121 - Loss: 0.7181896567344666\n",
      "Ep 20: Batch #122 - Loss: 0.8602235317230225\n",
      "Ep 20: Batch #123 - Loss: 0.8645524978637695\n",
      "Ep 20: Batch #124 - Loss: 0.6885201930999756\n",
      "Ep 20: Batch #125 - Loss: 2.7626285552978516\n",
      "Ep 20: Batch #126 - Loss: 1.2668009996414185\n",
      "Ep 20: Batch #127 - Loss: 0.7887469530105591\n",
      "Ep 20: Batch #128 - Loss: 1.154127836227417\n",
      "Ep 20: Batch #129 - Loss: 0.8766893148422241\n",
      "Ep 20: Batch #130 - Loss: 0.7583582997322083\n",
      "Ep 20: Batch #131 - Loss: 1.0434794425964355\n",
      "Ep 20: Batch #132 - Loss: 0.8632414937019348\n",
      "Ep 20: Batch #133 - Loss: 0.8523944020271301\n",
      "Ep 20: Batch #134 - Loss: 0.8046078085899353\n",
      "Ep 20: Batch #135 - Loss: 1.0081701278686523\n",
      "Ep 20: Batch #136 - Loss: 1.2296087741851807\n",
      "Ep 20: Batch #137 - Loss: 1.0050811767578125\n",
      "Ep 20: Batch #138 - Loss: 1.1089162826538086\n",
      "Ep 20: Batch #139 - Loss: 0.9391905665397644\n",
      "Ep 20: Batch #140 - Loss: 1.0873301029205322\n",
      "Ep 20: Batch #141 - Loss: 1.3979473114013672\n",
      "Ep 20: Batch #142 - Loss: 0.8261403441429138\n",
      "Ep 20: Batch #143 - Loss: 1.0115129947662354\n",
      "Ep 20: Batch #144 - Loss: 0.754713237285614\n",
      "Ep 20: Batch #145 - Loss: 0.7071653008460999\n",
      "Ep 20: Batch #146 - Loss: 0.9157001376152039\n",
      "Ep 20: Batch #147 - Loss: 0.9054660797119141\n",
      "Ep 20: Batch #148 - Loss: 1.0189809799194336\n",
      "Ep 20: Batch #149 - Loss: 0.8947750926017761\n",
      "Ep 20: Batch #150 - Loss: 0.9155623316764832\n",
      "Ep 20: Batch #151 - Loss: 0.7514379024505615\n",
      "Ep 20: Batch #152 - Loss: 0.7660740613937378\n",
      "Ep 20: Batch #153 - Loss: 1.1468769311904907\n",
      "Ep 20: Batch #154 - Loss: 0.792797863483429\n",
      "Ep 20: Batch #155 - Loss: 0.8717813491821289\n",
      "Ep 20: Batch #156 - Loss: 1.0571757555007935\n",
      "Ep 20: Batch #157 - Loss: 0.7937175631523132\n",
      "Ep 20: Batch #158 - Loss: 0.832560658454895\n",
      "Ep 20: Batch #159 - Loss: 0.8440889716148376\n",
      "Ep 20: Batch #160 - Loss: 0.9346680641174316\n",
      "Ep 20: Batch #161 - Loss: 0.8502556681632996\n",
      "Ep 20: Batch #162 - Loss: 0.9692667126655579\n",
      "Ep 20: Batch #163 - Loss: 0.9593182802200317\n",
      "Ep 20: Batch #164 - Loss: 0.8170605301856995\n",
      "Ep 20: Batch #165 - Loss: 1.532063364982605\n",
      "Ep 20: Batch #166 - Loss: 0.7145934104919434\n",
      "Ep 20: Batch #167 - Loss: 1.1232472658157349\n",
      "Ep 20: Batch #168 - Loss: 0.8986610174179077\n",
      "Ep 20: Batch #169 - Loss: 0.8348912596702576\n",
      "Ep 20: Batch #170 - Loss: 0.8381608128547668\n",
      "Ep 20: Batch #171 - Loss: 0.8181689381599426\n",
      "Ep 20: Batch #172 - Loss: 0.659121572971344\n",
      "Ep 20: Batch #173 - Loss: 1.2459622621536255\n",
      "Ep 20: Batch #174 - Loss: 0.6064594984054565\n",
      "Ep 20: Batch #175 - Loss: 0.8077048659324646\n",
      "Ep 20: Batch #176 - Loss: 1.1938401460647583\n",
      "Ep 20: Batch #177 - Loss: 0.883630633354187\n",
      "Ep 20: Batch #178 - Loss: 0.800254225730896\n",
      "Ep 20: Batch #179 - Loss: 0.9820716381072998\n",
      "Ep 20: Batch #180 - Loss: 0.9001846313476562\n",
      "Ep 20: Batch #181 - Loss: 1.0375784635543823\n",
      "Ep 20: Batch #182 - Loss: 0.7931426167488098\n",
      "Ep 20: Batch #183 - Loss: 0.7999429702758789\n",
      "Ep 20: Batch #184 - Loss: 1.0993646383285522\n",
      "Ep 20: Batch #185 - Loss: 0.7884069681167603\n",
      "Ep 20: Batch #186 - Loss: 1.012452244758606\n",
      "Ep 20: Batch #187 - Loss: 1.2032346725463867\n",
      "Ep 20: Batch #188 - Loss: 1.385702133178711\n",
      "Ep 20: Batch #189 - Loss: 0.7254339456558228\n",
      "Ep 20: Batch #190 - Loss: 0.766986072063446\n",
      "Ep 20: Batch #191 - Loss: 1.0991235971450806\n",
      "Ep 20: Batch #192 - Loss: 0.6939582228660583\n",
      "Ep 20: Batch #193 - Loss: 0.7753981947898865\n",
      "Ep 20: Batch #194 - Loss: 0.7272542715072632\n",
      "Ep 20: Batch #195 - Loss: 1.0204931497573853\n",
      "Ep 20: Batch #196 - Loss: 0.8984748125076294\n",
      "Ep 20: Batch #197 - Loss: 0.9363116025924683\n",
      "Ep 20: Batch #198 - Loss: 0.7102273106575012\n",
      "Ep 20: Batch #199 - Loss: 0.897759735584259\n",
      "Ep 21: Batch #0 - Loss: 0.8313701748847961\n",
      "Ep 21: Batch #1 - Loss: 0.913219690322876\n",
      "Ep 21: Batch #2 - Loss: 1.0376033782958984\n",
      "Ep 21: Batch #3 - Loss: 0.8984483480453491\n",
      "Ep 21: Batch #4 - Loss: 0.8247639536857605\n",
      "Ep 21: Batch #5 - Loss: 0.6923782229423523\n",
      "Ep 21: Batch #6 - Loss: 0.9123014807701111\n",
      "Ep 21: Batch #7 - Loss: 0.7291213870048523\n",
      "Ep 21: Batch #8 - Loss: 0.762523889541626\n",
      "Ep 21: Batch #9 - Loss: 1.448166847229004\n",
      "Ep 21: Batch #10 - Loss: 1.045567512512207\n",
      "Ep 21: Batch #11 - Loss: 0.7001203298568726\n",
      "Ep 21: Batch #12 - Loss: 1.5918453931808472\n",
      "Ep 21: Batch #13 - Loss: 0.6692428588867188\n",
      "Ep 21: Batch #14 - Loss: 0.7540209293365479\n",
      "Ep 21: Batch #15 - Loss: 1.2817682027816772\n",
      "Ep 21: Batch #16 - Loss: 1.3272002935409546\n",
      "Ep 21: Batch #17 - Loss: 0.9163312911987305\n",
      "Ep 21: Batch #18 - Loss: 0.9666814208030701\n",
      "Ep 21: Batch #19 - Loss: 0.6936799883842468\n",
      "Ep 21: Batch #20 - Loss: 0.6840246915817261\n",
      "Ep 21: Batch #21 - Loss: 1.2474199533462524\n",
      "Ep 21: Batch #22 - Loss: 0.7523772716522217\n",
      "Ep 21: Batch #23 - Loss: 0.7795483469963074\n",
      "Ep 21: Batch #24 - Loss: 0.8519917726516724\n",
      "Ep 21: Batch #25 - Loss: 0.7495868802070618\n",
      "Ep 21: Batch #26 - Loss: 0.7666144967079163\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 21: Batch #27 - Loss: 1.3950529098510742\n",
      "Ep 21: Batch #28 - Loss: 0.9004590511322021\n",
      "Ep 21: Batch #29 - Loss: 0.9331538081169128\n",
      "Ep 21: Batch #30 - Loss: 1.2399702072143555\n",
      "Ep 21: Batch #31 - Loss: 0.696449875831604\n",
      "Ep 21: Batch #32 - Loss: 0.7802121639251709\n",
      "Ep 21: Batch #33 - Loss: 0.8358306884765625\n",
      "Ep 21: Batch #34 - Loss: 0.8153587579727173\n",
      "Ep 21: Batch #35 - Loss: 0.9918176531791687\n",
      "Ep 21: Batch #36 - Loss: 0.7312431335449219\n",
      "Ep 21: Batch #37 - Loss: 1.1743261814117432\n",
      "Ep 21: Batch #38 - Loss: 0.7825533747673035\n",
      "Ep 21: Batch #39 - Loss: 0.8456700444221497\n",
      "Ep 21: Batch #40 - Loss: 0.8084667921066284\n",
      "Ep 21: Batch #41 - Loss: 0.7703766226768494\n",
      "Ep 21: Batch #42 - Loss: 0.7499321103096008\n",
      "Ep 21: Batch #43 - Loss: 0.8189494013786316\n",
      "Ep 21: Batch #44 - Loss: 0.8165382146835327\n",
      "Ep 21: Batch #45 - Loss: 0.6689514517784119\n",
      "Ep 21: Batch #46 - Loss: 0.8663835525512695\n",
      "Ep 21: Batch #47 - Loss: 1.00615394115448\n",
      "Ep 21: Batch #48 - Loss: 1.3997186422348022\n",
      "Ep 21: Batch #49 - Loss: 1.0512611865997314\n",
      "Ep 21: Batch #50 - Loss: 0.7285891771316528\n",
      "Ep 21: Batch #51 - Loss: 1.0374847650527954\n",
      "Ep 21: Batch #52 - Loss: 0.820763349533081\n",
      "Ep 21: Batch #53 - Loss: 0.8555582165718079\n",
      "Ep 21: Batch #54 - Loss: 0.731728196144104\n",
      "Ep 21: Batch #55 - Loss: 0.7870953679084778\n",
      "Ep 21: Batch #56 - Loss: 1.3032293319702148\n",
      "Ep 21: Batch #57 - Loss: 0.8885870575904846\n",
      "Ep 21: Batch #58 - Loss: 1.0422942638397217\n",
      "Ep 21: Batch #59 - Loss: 0.707194447517395\n",
      "Ep 21: Batch #60 - Loss: 1.350232481956482\n",
      "Ep 21: Batch #61 - Loss: 0.6642000079154968\n",
      "Ep 21: Batch #62 - Loss: 0.7569283843040466\n",
      "Ep 21: Batch #63 - Loss: 1.0449119806289673\n",
      "Ep 21: Batch #64 - Loss: 9.463764190673828\n",
      "Ep 21: Batch #65 - Loss: 0.636687159538269\n",
      "Ep 21: Batch #66 - Loss: 0.837232768535614\n",
      "Ep 21: Batch #67 - Loss: 0.9437314867973328\n",
      "Ep 21: Batch #68 - Loss: 0.9452948570251465\n",
      "Ep 21: Batch #69 - Loss: 0.777896523475647\n",
      "Ep 21: Batch #70 - Loss: 0.8173360824584961\n",
      "Ep 21: Batch #71 - Loss: 0.7083494663238525\n",
      "Ep 21: Batch #72 - Loss: 0.8893367052078247\n",
      "Ep 21: Batch #73 - Loss: 0.945313572883606\n",
      "Ep 21: Batch #74 - Loss: 0.7734968662261963\n",
      "Ep 21: Batch #75 - Loss: 0.7977735996246338\n",
      "Ep 21: Batch #76 - Loss: 1.1259212493896484\n",
      "Ep 21: Batch #77 - Loss: 0.7657642364501953\n",
      "Ep 21: Batch #78 - Loss: 1.2044941186904907\n",
      "Ep 21: Batch #79 - Loss: 0.6556910276412964\n",
      "Ep 21: Batch #80 - Loss: 0.8983477354049683\n",
      "Ep 21: Batch #81 - Loss: 1.7168891429901123\n",
      "Ep 21: Batch #82 - Loss: 0.9073642492294312\n",
      "Ep 21: Batch #83 - Loss: 1.7627958059310913\n",
      "Ep 21: Batch #84 - Loss: 0.7471311092376709\n",
      "Ep 21: Batch #85 - Loss: 1.005392074584961\n",
      "Ep 21: Batch #86 - Loss: 0.744114339351654\n",
      "Ep 21: Batch #87 - Loss: 0.7425165176391602\n",
      "Ep 21: Batch #88 - Loss: 0.8376550078392029\n",
      "Ep 21: Batch #89 - Loss: 0.9060661792755127\n",
      "Ep 21: Batch #90 - Loss: 1.2054771184921265\n",
      "Ep 21: Batch #91 - Loss: 0.8393475413322449\n",
      "Ep 21: Batch #92 - Loss: 1.0697579383850098\n",
      "Ep 21: Batch #93 - Loss: 1.0752265453338623\n",
      "Ep 21: Batch #94 - Loss: 1.0898487567901611\n",
      "Ep 21: Batch #95 - Loss: 0.957226574420929\n",
      "Ep 21: Batch #96 - Loss: 0.9384278059005737\n",
      "Ep 21: Batch #97 - Loss: 0.7620952725410461\n",
      "Ep 21: Batch #98 - Loss: 0.772621750831604\n",
      "Ep 21: Batch #99 - Loss: 0.9903438687324524\n",
      "Ep 21: Batch #100 - Loss: 0.7100158929824829\n",
      "Ep 21: Batch #101 - Loss: 1.083472490310669\n",
      "Ep 21: Batch #102 - Loss: 0.812644898891449\n",
      "Ep 21: Batch #103 - Loss: 0.8191812634468079\n",
      "Ep 21: Batch #104 - Loss: 0.8343943953514099\n",
      "Ep 21: Batch #105 - Loss: 1.0662789344787598\n",
      "Ep 21: Batch #106 - Loss: 0.7902233600616455\n",
      "Ep 21: Batch #107 - Loss: 0.7927228808403015\n",
      "Ep 21: Batch #108 - Loss: 1.074217438697815\n",
      "Ep 21: Batch #109 - Loss: 0.7908474206924438\n",
      "Ep 21: Batch #110 - Loss: 0.9599499106407166\n",
      "Ep 21: Batch #111 - Loss: 1.4209033250808716\n",
      "Ep 21: Batch #112 - Loss: 1.090682864189148\n",
      "Ep 21: Batch #113 - Loss: 0.8505184650421143\n",
      "Ep 21: Batch #114 - Loss: 0.9398086071014404\n",
      "Ep 21: Batch #115 - Loss: 1.1303499937057495\n",
      "Ep 21: Batch #116 - Loss: 0.6539551615715027\n",
      "Ep 21: Batch #117 - Loss: 0.9036274552345276\n",
      "Ep 21: Batch #118 - Loss: 0.5726886987686157\n",
      "Model saved in file: ./weights_autoencoder_low_LR/model_e21b118_1516651271.4749544.ckpt\n",
      "Ep 21: Batch #119 - Loss: 1.0630550384521484\n",
      "Ep 21: Batch #120 - Loss: 0.8264393210411072\n",
      "Ep 21: Batch #121 - Loss: 0.7167132496833801\n",
      "Ep 21: Batch #122 - Loss: 0.858635663986206\n",
      "Ep 21: Batch #123 - Loss: 0.8631628155708313\n",
      "Ep 21: Batch #124 - Loss: 0.6873350739479065\n",
      "Ep 21: Batch #125 - Loss: 2.7605772018432617\n",
      "Ep 21: Batch #126 - Loss: 1.2648166418075562\n",
      "Ep 21: Batch #127 - Loss: 0.7869732975959778\n",
      "Ep 21: Batch #128 - Loss: 1.1522196531295776\n",
      "Ep 21: Batch #129 - Loss: 0.8749702572822571\n",
      "Ep 21: Batch #130 - Loss: 0.7566480040550232\n",
      "Ep 21: Batch #131 - Loss: 1.041285753250122\n",
      "Ep 21: Batch #132 - Loss: 0.8614131212234497\n",
      "Ep 21: Batch #133 - Loss: 0.8507688045501709\n",
      "Ep 21: Batch #134 - Loss: 0.8030457496643066\n",
      "Ep 21: Batch #135 - Loss: 1.006233811378479\n",
      "Ep 21: Batch #136 - Loss: 1.2275854349136353\n",
      "Ep 21: Batch #137 - Loss: 1.0032514333724976\n",
      "Ep 21: Batch #138 - Loss: 1.1073392629623413\n",
      "Ep 21: Batch #139 - Loss: 0.9374046921730042\n",
      "Ep 21: Batch #140 - Loss: 1.085560917854309\n",
      "Ep 21: Batch #141 - Loss: 1.396206259727478\n",
      "Ep 21: Batch #142 - Loss: 0.8248599767684937\n",
      "Ep 21: Batch #143 - Loss: 1.009501338005066\n",
      "Ep 21: Batch #144 - Loss: 0.7530103325843811\n",
      "Ep 21: Batch #145 - Loss: 0.7058291435241699\n",
      "Ep 21: Batch #146 - Loss: 0.9143617749214172\n",
      "Ep 21: Batch #147 - Loss: 0.9037289023399353\n",
      "Ep 21: Batch #148 - Loss: 1.0171830654144287\n",
      "Ep 21: Batch #149 - Loss: 0.8930060267448425\n",
      "Ep 21: Batch #150 - Loss: 0.9143296480178833\n",
      "Ep 21: Batch #151 - Loss: 0.7502890229225159\n",
      "Ep 21: Batch #152 - Loss: 0.7647764682769775\n",
      "Ep 21: Batch #153 - Loss: 1.1449801921844482\n",
      "Ep 21: Batch #154 - Loss: 0.7915543913841248\n",
      "Ep 21: Batch #155 - Loss: 0.8699657917022705\n",
      "Ep 21: Batch #156 - Loss: 1.055465579032898\n",
      "Ep 21: Batch #157 - Loss: 0.792345404624939\n",
      "Ep 21: Batch #158 - Loss: 0.8311424255371094\n",
      "Ep 21: Batch #159 - Loss: 0.8425022959709167\n",
      "Ep 21: Batch #160 - Loss: 0.9332674145698547\n",
      "Ep 21: Batch #161 - Loss: 0.8486731648445129\n",
      "Ep 21: Batch #162 - Loss: 0.967609703540802\n",
      "Ep 21: Batch #163 - Loss: 0.9578666090965271\n",
      "Ep 21: Batch #164 - Loss: 0.8156189322471619\n",
      "Ep 21: Batch #165 - Loss: 1.5304750204086304\n",
      "Ep 21: Batch #166 - Loss: 0.712967038154602\n",
      "Ep 21: Batch #167 - Loss: 1.1216431856155396\n",
      "Ep 21: Batch #168 - Loss: 0.8969451189041138\n",
      "Ep 21: Batch #169 - Loss: 0.8333578705787659\n",
      "Ep 21: Batch #170 - Loss: 0.8366534113883972\n",
      "Ep 21: Batch #171 - Loss: 0.8164448142051697\n",
      "Ep 21: Batch #172 - Loss: 0.6579501032829285\n",
      "Ep 21: Batch #173 - Loss: 1.2438081502914429\n",
      "Ep 21: Batch #174 - Loss: 0.6050869226455688\n",
      "Ep 21: Batch #175 - Loss: 0.806290864944458\n",
      "Ep 21: Batch #176 - Loss: 1.1924537420272827\n",
      "Ep 21: Batch #177 - Loss: 0.8820803165435791\n",
      "Ep 21: Batch #178 - Loss: 0.7985509037971497\n",
      "Ep 21: Batch #179 - Loss: 0.9801819920539856\n",
      "Ep 21: Batch #180 - Loss: 0.8981539011001587\n",
      "Ep 21: Batch #181 - Loss: 1.0356314182281494\n",
      "Ep 21: Batch #182 - Loss: 0.7917711138725281\n",
      "Ep 21: Batch #183 - Loss: 0.7984203100204468\n",
      "Ep 21: Batch #184 - Loss: 1.0977773666381836\n",
      "Ep 21: Batch #185 - Loss: 0.7869899868965149\n",
      "Ep 21: Batch #186 - Loss: 1.0104129314422607\n",
      "Ep 21: Batch #187 - Loss: 1.2015048265457153\n",
      "Ep 21: Batch #188 - Loss: 1.3837825059890747\n",
      "Ep 21: Batch #189 - Loss: 0.7243854999542236\n",
      "Ep 21: Batch #190 - Loss: 0.7654712796211243\n",
      "Ep 21: Batch #191 - Loss: 1.0977184772491455\n",
      "Ep 21: Batch #192 - Loss: 0.6928132772445679\n",
      "Ep 21: Batch #193 - Loss: 0.7738906741142273\n",
      "Ep 21: Batch #194 - Loss: 0.7257643938064575\n",
      "Ep 21: Batch #195 - Loss: 1.0188696384429932\n",
      "Ep 21: Batch #196 - Loss: 0.8968976736068726\n",
      "Ep 21: Batch #197 - Loss: 0.9348095655441284\n",
      "Ep 21: Batch #198 - Loss: 0.7087348699569702\n",
      "Ep 21: Batch #199 - Loss: 0.8961242437362671\n",
      "Ep 22: Batch #0 - Loss: 0.8295207023620605\n",
      "Ep 22: Batch #1 - Loss: 0.9114156365394592\n",
      "Ep 22: Batch #2 - Loss: 1.0362870693206787\n",
      "Ep 22: Batch #3 - Loss: 0.8966648578643799\n",
      "Ep 22: Batch #4 - Loss: 0.8231286406517029\n",
      "Ep 22: Batch #5 - Loss: 0.6910915374755859\n",
      "Ep 22: Batch #6 - Loss: 0.9106360077857971\n",
      "Ep 22: Batch #7 - Loss: 0.7278115749359131\n",
      "Ep 22: Batch #8 - Loss: 0.761106014251709\n",
      "Ep 22: Batch #9 - Loss: 1.4462002515792847\n",
      "Ep 22: Batch #10 - Loss: 1.043662428855896\n",
      "Ep 22: Batch #11 - Loss: 0.6985549926757812\n",
      "Ep 22: Batch #12 - Loss: 1.590429425239563\n",
      "Ep 22: Batch #13 - Loss: 0.6682828068733215\n",
      "Ep 22: Batch #14 - Loss: 0.7527455687522888\n",
      "Ep 22: Batch #15 - Loss: 1.2797728776931763\n",
      "Ep 22: Batch #16 - Loss: 1.3248934745788574\n",
      "Ep 22: Batch #17 - Loss: 0.9147243499755859\n",
      "Ep 22: Batch #18 - Loss: 0.9655675292015076\n",
      "Ep 22: Batch #19 - Loss: 0.6925548315048218\n",
      "Ep 22: Batch #20 - Loss: 0.6826167702674866\n",
      "Ep 22: Batch #21 - Loss: 1.245728611946106\n",
      "Ep 22: Batch #22 - Loss: 0.7510926723480225\n",
      "Ep 22: Batch #23 - Loss: 0.7777143120765686\n",
      "Ep 22: Batch #24 - Loss: 0.8506531715393066\n",
      "Ep 22: Batch #25 - Loss: 0.7478054761886597\n",
      "Ep 22: Batch #26 - Loss: 0.7649323344230652\n",
      "Ep 22: Batch #27 - Loss: 1.3931866884231567\n",
      "Ep 22: Batch #28 - Loss: 0.8989172577857971\n",
      "Ep 22: Batch #29 - Loss: 0.9312023520469666\n",
      "Ep 22: Batch #30 - Loss: 1.2378510236740112\n",
      "Ep 22: Batch #31 - Loss: 0.695308268070221\n",
      "Ep 22: Batch #32 - Loss: 0.7787334322929382\n",
      "Ep 22: Batch #33 - Loss: 0.8343580961227417\n",
      "Ep 22: Batch #34 - Loss: 0.8138084411621094\n",
      "Ep 22: Batch #35 - Loss: 0.9898614883422852\n",
      "Ep 22: Batch #36 - Loss: 0.729915976524353\n",
      "Ep 22: Batch #37 - Loss: 1.1727410554885864\n",
      "Ep 22: Batch #38 - Loss: 0.7807326316833496\n",
      "Ep 22: Batch #39 - Loss: 0.8444324135780334\n",
      "Ep 22: Batch #40 - Loss: 0.8067213296890259\n",
      "Ep 22: Batch #41 - Loss: 0.7689931988716125\n",
      "Ep 22: Batch #42 - Loss: 0.7486187815666199\n",
      "Ep 22: Batch #43 - Loss: 0.817392885684967\n",
      "Ep 22: Batch #44 - Loss: 0.8150712847709656\n",
      "Ep 22: Batch #45 - Loss: 0.6672244071960449\n",
      "Ep 22: Batch #46 - Loss: 0.8647163510322571\n",
      "Ep 22: Batch #47 - Loss: 1.0040680170059204\n",
      "Ep 22: Batch #48 - Loss: 1.397647738456726\n",
      "Ep 22: Batch #49 - Loss: 1.0498114824295044\n",
      "Ep 22: Batch #50 - Loss: 0.7274742722511292\n",
      "Ep 22: Batch #51 - Loss: 1.0355875492095947\n",
      "Ep 22: Batch #52 - Loss: 0.8195095658302307\n",
      "Ep 22: Batch #53 - Loss: 0.8540138006210327\n",
      "Ep 22: Batch #54 - Loss: 0.7303439974784851\n",
      "Ep 22: Batch #55 - Loss: 0.7853639125823975\n",
      "Ep 22: Batch #56 - Loss: 1.3014147281646729\n",
      "Ep 22: Batch #57 - Loss: 0.8865001201629639\n",
      "Ep 22: Batch #58 - Loss: 1.0403904914855957\n",
      "Ep 22: Batch #59 - Loss: 0.705894947052002\n",
      "Ep 22: Batch #60 - Loss: 1.3481502532958984\n",
      "Ep 22: Batch #61 - Loss: 0.6627954244613647\n",
      "Ep 22: Batch #62 - Loss: 0.75525963306427\n",
      "Ep 22: Batch #63 - Loss: 1.0427004098892212\n",
      "Ep 22: Batch #64 - Loss: 9.462536811828613\n",
      "Ep 22: Batch #65 - Loss: 0.6355034708976746\n",
      "Ep 22: Batch #66 - Loss: 0.8353362679481506\n",
      "Ep 22: Batch #67 - Loss: 0.9420815110206604\n",
      "Ep 22: Batch #68 - Loss: 0.9436375498771667\n",
      "Ep 22: Batch #69 - Loss: 0.7762731313705444\n",
      "Ep 22: Batch #70 - Loss: 0.8152987957000732\n",
      "Ep 22: Batch #71 - Loss: 0.706942081451416\n",
      "Ep 22: Batch #72 - Loss: 0.8876810669898987\n",
      "Ep 22: Batch #73 - Loss: 0.9434592127799988\n",
      "Ep 22: Batch #74 - Loss: 0.7721067070960999\n",
      "Ep 22: Batch #75 - Loss: 0.7963751554489136\n",
      "Ep 22: Batch #76 - Loss: 1.1244721412658691\n",
      "Ep 22: Batch #77 - Loss: 0.764272928237915\n",
      "Ep 22: Batch #78 - Loss: 1.2023214101791382\n",
      "Ep 22: Batch #79 - Loss: 0.6540998816490173\n",
      "Ep 22: Batch #80 - Loss: 0.896414041519165\n",
      "Ep 22: Batch #81 - Loss: 1.7154353857040405\n",
      "Ep 22: Batch #82 - Loss: 0.905645489692688\n",
      "Ep 22: Batch #83 - Loss: 1.7609779834747314\n",
      "Ep 22: Batch #84 - Loss: 0.7456094026565552\n",
      "Ep 22: Batch #85 - Loss: 1.0037312507629395\n",
      "Ep 22: Batch #86 - Loss: 0.7424059510231018\n",
      "Ep 22: Batch #87 - Loss: 0.7410767674446106\n",
      "Ep 22: Batch #88 - Loss: 0.8359929323196411\n",
      "Ep 22: Batch #89 - Loss: 0.9049495458602905\n",
      "Ep 22: Batch #90 - Loss: 1.2030575275421143\n",
      "Ep 22: Batch #91 - Loss: 0.8375664949417114\n",
      "Ep 22: Batch #92 - Loss: 1.067803144454956\n",
      "Ep 22: Batch #93 - Loss: 1.07313072681427\n",
      "Ep 22: Batch #94 - Loss: 1.088010311126709\n",
      "Ep 22: Batch #95 - Loss: 0.955348551273346\n",
      "Ep 22: Batch #96 - Loss: 0.9369223117828369\n",
      "Ep 22: Batch #97 - Loss: 0.7605199217796326\n",
      "Ep 22: Batch #98 - Loss: 0.7709543704986572\n",
      "Ep 22: Batch #99 - Loss: 0.9888226389884949\n",
      "Ep 22: Batch #100 - Loss: 0.7084192037582397\n",
      "Ep 22: Batch #101 - Loss: 1.0815889835357666\n",
      "Ep 22: Batch #102 - Loss: 0.8111881017684937\n",
      "Ep 22: Batch #103 - Loss: 0.8179118633270264\n",
      "Ep 22: Batch #104 - Loss: 0.8327304124832153\n",
      "Ep 22: Batch #105 - Loss: 1.0645630359649658\n",
      "Ep 22: Batch #106 - Loss: 0.7887569069862366\n",
      "Ep 22: Batch #107 - Loss: 0.7909570336341858\n",
      "Ep 22: Batch #108 - Loss: 1.0722423791885376\n",
      "Ep 22: Batch #109 - Loss: 0.7894943356513977\n",
      "Ep 22: Batch #110 - Loss: 0.9580718278884888\n",
      "Ep 22: Batch #111 - Loss: 1.4189993143081665\n",
      "Ep 22: Batch #112 - Loss: 1.0885344743728638\n",
      "Ep 22: Batch #113 - Loss: 0.8487915992736816\n",
      "Ep 22: Batch #114 - Loss: 0.9381864070892334\n",
      "Ep 22: Batch #115 - Loss: 1.128633975982666\n",
      "Ep 22: Batch #116 - Loss: 0.6528905034065247\n",
      "Ep 22: Batch #117 - Loss: 0.9020691514015198\n",
      "Ep 22: Batch #118 - Loss: 0.5712007284164429\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved in file: ./weights_autoencoder_low_LR/model_e22b118_1516651271.6124947.ckpt\n",
      "Ep 22: Batch #119 - Loss: 1.0613988637924194\n",
      "Ep 22: Batch #120 - Loss: 0.8252010345458984\n",
      "Ep 22: Batch #121 - Loss: 0.7152093052864075\n",
      "Ep 22: Batch #122 - Loss: 0.857030987739563\n",
      "Ep 22: Batch #123 - Loss: 0.8616955876350403\n",
      "Ep 22: Batch #124 - Loss: 0.6861365437507629\n",
      "Ep 22: Batch #125 - Loss: 2.758514881134033\n",
      "Ep 22: Batch #126 - Loss: 1.2628471851348877\n",
      "Ep 22: Batch #127 - Loss: 0.7851682901382446\n",
      "Ep 22: Batch #128 - Loss: 1.1502505540847778\n",
      "Ep 22: Batch #129 - Loss: 0.8731995224952698\n",
      "Ep 22: Batch #130 - Loss: 0.7548931837081909\n",
      "Ep 22: Batch #131 - Loss: 1.0390360355377197\n",
      "Ep 22: Batch #132 - Loss: 0.8595370650291443\n",
      "Ep 22: Batch #133 - Loss: 0.849105179309845\n",
      "Ep 22: Batch #134 - Loss: 0.8013796806335449\n",
      "Ep 22: Batch #135 - Loss: 1.0042463541030884\n",
      "Ep 22: Batch #136 - Loss: 1.2255175113677979\n",
      "Ep 22: Batch #137 - Loss: 1.0013688802719116\n",
      "Ep 22: Batch #138 - Loss: 1.1056615114212036\n",
      "Ep 22: Batch #139 - Loss: 0.9356034398078918\n",
      "Ep 22: Batch #140 - Loss: 1.0838114023208618\n",
      "Ep 22: Batch #141 - Loss: 1.3944346904754639\n",
      "Ep 22: Batch #142 - Loss: 0.8235806822776794\n",
      "Ep 22: Batch #143 - Loss: 1.007361650466919\n",
      "Ep 22: Batch #144 - Loss: 0.751287043094635\n",
      "Ep 22: Batch #145 - Loss: 0.7044814825057983\n",
      "Ep 22: Batch #146 - Loss: 0.9129652976989746\n",
      "Ep 22: Batch #147 - Loss: 0.9018599390983582\n",
      "Ep 22: Batch #148 - Loss: 1.0153638124465942\n",
      "Ep 22: Batch #149 - Loss: 0.8911581039428711\n",
      "Ep 22: Batch #150 - Loss: 0.9130027890205383\n",
      "Ep 22: Batch #151 - Loss: 0.7491406202316284\n",
      "Ep 22: Batch #152 - Loss: 0.7634645700454712\n",
      "Ep 22: Batch #153 - Loss: 1.1430952548980713\n",
      "Ep 22: Batch #154 - Loss: 0.7903030514717102\n",
      "Ep 22: Batch #155 - Loss: 0.8681178092956543\n",
      "Ep 22: Batch #156 - Loss: 1.0537630319595337\n",
      "Ep 22: Batch #157 - Loss: 0.7909056544303894\n",
      "Ep 22: Batch #158 - Loss: 0.8296866416931152\n",
      "Ep 22: Batch #159 - Loss: 0.8408727645874023\n",
      "Ep 22: Batch #160 - Loss: 0.9318376779556274\n",
      "Ep 22: Batch #161 - Loss: 0.8470963835716248\n",
      "Ep 22: Batch #162 - Loss: 0.9659299254417419\n",
      "Ep 22: Batch #163 - Loss: 0.9564621448516846\n",
      "Ep 22: Batch #164 - Loss: 0.8141546249389648\n",
      "Ep 22: Batch #165 - Loss: 1.5288835763931274\n",
      "Ep 22: Batch #166 - Loss: 0.7112878561019897\n",
      "Ep 22: Batch #167 - Loss: 1.1200356483459473\n",
      "Ep 22: Batch #168 - Loss: 0.8952063322067261\n",
      "Ep 22: Batch #169 - Loss: 0.8318222165107727\n",
      "Ep 22: Batch #170 - Loss: 0.8351601958274841\n",
      "Ep 22: Batch #171 - Loss: 0.81475430727005\n",
      "Ep 22: Batch #172 - Loss: 0.6567777991294861\n",
      "Ep 22: Batch #173 - Loss: 1.2416584491729736\n",
      "Ep 22: Batch #174 - Loss: 0.6036742925643921\n",
      "Ep 22: Batch #175 - Loss: 0.8049057126045227\n",
      "Ep 22: Batch #176 - Loss: 1.1910492181777954\n",
      "Ep 22: Batch #177 - Loss: 0.880513072013855\n",
      "Ep 22: Batch #178 - Loss: 0.7968353033065796\n",
      "Ep 22: Batch #179 - Loss: 0.9783170223236084\n",
      "Ep 22: Batch #180 - Loss: 0.896103024482727\n",
      "Ep 22: Batch #181 - Loss: 1.033644676208496\n",
      "Ep 22: Batch #182 - Loss: 0.7904287576675415\n",
      "Ep 22: Batch #183 - Loss: 0.7968670725822449\n",
      "Ep 22: Batch #184 - Loss: 1.0961990356445312\n",
      "Ep 22: Batch #185 - Loss: 0.7855928540229797\n",
      "Ep 22: Batch #186 - Loss: 1.0083832740783691\n",
      "Ep 22: Batch #187 - Loss: 1.19978666305542\n",
      "Ep 22: Batch #188 - Loss: 1.3818535804748535\n",
      "Ep 22: Batch #189 - Loss: 0.7233294248580933\n",
      "Ep 22: Batch #190 - Loss: 0.7639251351356506\n",
      "Ep 22: Batch #191 - Loss: 1.0962908267974854\n",
      "Ep 22: Batch #192 - Loss: 0.6916993856430054\n",
      "Ep 22: Batch #193 - Loss: 0.7723392844200134\n",
      "Ep 22: Batch #194 - Loss: 0.7242723107337952\n",
      "Ep 22: Batch #195 - Loss: 1.0172237157821655\n",
      "Ep 22: Batch #196 - Loss: 0.8953658938407898\n",
      "Ep 22: Batch #197 - Loss: 0.933285653591156\n",
      "Ep 22: Batch #198 - Loss: 0.70723956823349\n",
      "Ep 22: Batch #199 - Loss: 0.8944922089576721\n",
      "Ep 23: Batch #0 - Loss: 0.8276154398918152\n",
      "Ep 23: Batch #1 - Loss: 0.9096397161483765\n",
      "Ep 23: Batch #2 - Loss: 1.0349968671798706\n",
      "Ep 23: Batch #3 - Loss: 0.8948801159858704\n",
      "Ep 23: Batch #4 - Loss: 0.8214915990829468\n",
      "Ep 23: Batch #5 - Loss: 0.6898497939109802\n",
      "Ep 23: Batch #6 - Loss: 0.9090031981468201\n",
      "Ep 23: Batch #7 - Loss: 0.7265107035636902\n",
      "Ep 23: Batch #8 - Loss: 0.759697675704956\n",
      "Ep 23: Batch #9 - Loss: 1.4442481994628906\n",
      "Ep 23: Batch #10 - Loss: 1.0417563915252686\n",
      "Ep 23: Batch #11 - Loss: 0.6970189809799194\n",
      "Ep 23: Batch #12 - Loss: 1.5890191793441772\n",
      "Ep 23: Batch #13 - Loss: 0.6672881245613098\n",
      "Ep 23: Batch #14 - Loss: 0.7514623403549194\n",
      "Ep 23: Batch #15 - Loss: 1.277793288230896\n",
      "Ep 23: Batch #16 - Loss: 1.3225210905075073\n",
      "Ep 23: Batch #17 - Loss: 0.9130915403366089\n",
      "Ep 23: Batch #18 - Loss: 0.9644473791122437\n",
      "Ep 23: Batch #19 - Loss: 0.6914435029029846\n",
      "Ep 23: Batch #20 - Loss: 0.6811824440956116\n",
      "Ep 23: Batch #21 - Loss: 1.2440470457077026\n",
      "Ep 23: Batch #22 - Loss: 0.7497987747192383\n",
      "Ep 23: Batch #23 - Loss: 0.775902509689331\n",
      "Ep 23: Batch #24 - Loss: 0.8492899537086487\n",
      "Ep 23: Batch #25 - Loss: 0.74603670835495\n",
      "Ep 23: Batch #26 - Loss: 0.7632415294647217\n",
      "Ep 23: Batch #27 - Loss: 1.391324520111084\n",
      "Ep 23: Batch #28 - Loss: 0.8973708152770996\n",
      "Ep 23: Batch #29 - Loss: 0.9292663335800171\n",
      "Ep 23: Batch #30 - Loss: 1.2358438968658447\n",
      "Ep 23: Batch #31 - Loss: 0.6941648125648499\n",
      "Ep 23: Batch #32 - Loss: 0.7772176861763\n",
      "Ep 23: Batch #33 - Loss: 0.8328980207443237\n",
      "Ep 23: Batch #34 - Loss: 0.8122898936271667\n",
      "Ep 23: Batch #35 - Loss: 0.9879123568534851\n",
      "Ep 23: Batch #36 - Loss: 0.7285862565040588\n",
      "Ep 23: Batch #37 - Loss: 1.171182632446289\n",
      "Ep 23: Batch #38 - Loss: 0.7789239883422852\n",
      "Ep 23: Batch #39 - Loss: 0.8431884050369263\n",
      "Ep 23: Batch #40 - Loss: 0.8050343990325928\n",
      "Ep 23: Batch #41 - Loss: 0.7676085233688354\n",
      "Ep 23: Batch #42 - Loss: 0.7473277449607849\n",
      "Ep 23: Batch #43 - Loss: 0.8158552646636963\n",
      "Ep 23: Batch #44 - Loss: 0.8136033415794373\n",
      "Ep 23: Batch #45 - Loss: 0.6654501557350159\n",
      "Ep 23: Batch #46 - Loss: 0.8630542159080505\n",
      "Ep 23: Batch #47 - Loss: 1.0019514560699463\n",
      "Ep 23: Batch #48 - Loss: 1.395524501800537\n",
      "Ep 23: Batch #49 - Loss: 1.0483877658843994\n",
      "Ep 23: Batch #50 - Loss: 0.7263733148574829\n",
      "Ep 23: Batch #51 - Loss: 1.033722996711731\n",
      "Ep 23: Batch #52 - Loss: 0.8182373642921448\n",
      "Ep 23: Batch #53 - Loss: 0.8524714708328247\n",
      "Ep 23: Batch #54 - Loss: 0.7289854884147644\n",
      "Ep 23: Batch #55 - Loss: 0.7836354970932007\n",
      "Ep 23: Batch #56 - Loss: 1.2996315956115723\n",
      "Ep 23: Batch #57 - Loss: 0.8844447731971741\n",
      "Ep 23: Batch #58 - Loss: 1.0384761095046997\n",
      "Ep 23: Batch #59 - Loss: 0.7045841813087463\n",
      "Ep 23: Batch #60 - Loss: 1.3460575342178345\n",
      "Ep 23: Batch #61 - Loss: 0.6613932847976685\n",
      "Ep 23: Batch #62 - Loss: 0.7535605430603027\n",
      "Ep 23: Batch #63 - Loss: 1.0405365228652954\n",
      "Ep 23: Batch #64 - Loss: 9.461307525634766\n",
      "Ep 23: Batch #65 - Loss: 0.6343433260917664\n",
      "Ep 23: Batch #66 - Loss: 0.8334595561027527\n",
      "Ep 23: Batch #67 - Loss: 0.9404245615005493\n",
      "Ep 23: Batch #68 - Loss: 0.941979169845581\n",
      "Ep 23: Batch #69 - Loss: 0.7746549248695374\n",
      "Ep 23: Batch #70 - Loss: 0.8132981061935425\n",
      "Ep 23: Batch #71 - Loss: 0.7055348753929138\n",
      "Ep 23: Batch #72 - Loss: 0.8860107660293579\n",
      "Ep 23: Batch #73 - Loss: 0.941588819026947\n",
      "Ep 23: Batch #74 - Loss: 0.770691454410553\n",
      "Ep 23: Batch #75 - Loss: 0.7949833273887634\n",
      "Ep 23: Batch #76 - Loss: 1.123005747795105\n",
      "Ep 23: Batch #77 - Loss: 0.7627698183059692\n",
      "Ep 23: Batch #78 - Loss: 1.2000635862350464\n",
      "Ep 23: Batch #79 - Loss: 0.6525440812110901\n",
      "Ep 23: Batch #80 - Loss: 0.8945381045341492\n",
      "Ep 23: Batch #81 - Loss: 1.713947057723999\n",
      "Ep 23: Batch #82 - Loss: 0.9039063453674316\n",
      "Ep 23: Batch #83 - Loss: 1.7592781782150269\n",
      "Ep 23: Batch #84 - Loss: 0.7440716624259949\n",
      "Ep 23: Batch #85 - Loss: 1.0020546913146973\n",
      "Ep 23: Batch #86 - Loss: 0.7406995296478271\n",
      "Ep 23: Batch #87 - Loss: 0.7396174073219299\n",
      "Ep 23: Batch #88 - Loss: 0.8343140482902527\n",
      "Ep 23: Batch #89 - Loss: 0.9038325548171997\n",
      "Ep 23: Batch #90 - Loss: 1.2006655931472778\n",
      "Ep 23: Batch #91 - Loss: 0.8357609510421753\n",
      "Ep 23: Batch #92 - Loss: 1.0658425092697144\n",
      "Ep 23: Batch #93 - Loss: 1.0710800886154175\n",
      "Ep 23: Batch #94 - Loss: 1.086182951927185\n",
      "Ep 23: Batch #95 - Loss: 0.9534556865692139\n",
      "Ep 23: Batch #96 - Loss: 0.9354095458984375\n",
      "Ep 23: Batch #97 - Loss: 0.758939802646637\n",
      "Ep 23: Batch #98 - Loss: 0.7692760825157166\n",
      "Ep 23: Batch #99 - Loss: 0.9873164892196655\n",
      "Ep 23: Batch #100 - Loss: 0.7068268656730652\n",
      "Ep 23: Batch #101 - Loss: 1.0797232389450073\n",
      "Ep 23: Batch #102 - Loss: 0.8097396492958069\n",
      "Ep 23: Batch #103 - Loss: 0.8166592717170715\n",
      "Ep 23: Batch #104 - Loss: 0.8310742378234863\n",
      "Ep 23: Batch #105 - Loss: 1.062857747077942\n",
      "Ep 23: Batch #106 - Loss: 0.7873184084892273\n",
      "Ep 23: Batch #107 - Loss: 0.7891954183578491\n",
      "Ep 23: Batch #108 - Loss: 1.0702884197235107\n",
      "Ep 23: Batch #109 - Loss: 0.788169801235199\n",
      "Ep 23: Batch #110 - Loss: 0.9561929702758789\n",
      "Ep 23: Batch #111 - Loss: 1.417128562927246\n",
      "Ep 23: Batch #112 - Loss: 1.0863925218582153\n",
      "Ep 23: Batch #113 - Loss: 0.8470966219902039\n",
      "Ep 23: Batch #114 - Loss: 0.9365379214286804\n",
      "Ep 23: Batch #115 - Loss: 1.1269347667694092\n",
      "Ep 23: Batch #116 - Loss: 0.6518165469169617\n",
      "Ep 23: Batch #117 - Loss: 0.9005292057991028\n",
      "Ep 23: Batch #118 - Loss: 0.5697428584098816\n",
      "Model saved in file: ./weights_autoencoder_low_LR/model_e23b118_1516651271.7528107.ckpt\n",
      "Ep 23: Batch #119 - Loss: 1.0597032308578491\n",
      "Ep 23: Batch #120 - Loss: 0.8239625096321106\n",
      "Ep 23: Batch #121 - Loss: 0.713729977607727\n",
      "Ep 23: Batch #122 - Loss: 0.8554261326789856\n",
      "Ep 23: Batch #123 - Loss: 0.8602121472358704\n",
      "Ep 23: Batch #124 - Loss: 0.6849398016929626\n",
      "Ep 23: Batch #125 - Loss: 2.7564632892608643\n",
      "Ep 23: Batch #126 - Loss: 1.2608898878097534\n",
      "Ep 23: Batch #127 - Loss: 0.7833482027053833\n",
      "Ep 23: Batch #128 - Loss: 1.1482653617858887\n",
      "Ep 23: Batch #129 - Loss: 0.8714451789855957\n",
      "Ep 23: Batch #130 - Loss: 0.7531549334526062\n",
      "Ep 23: Batch #131 - Loss: 1.0368170738220215\n",
      "Ep 23: Batch #132 - Loss: 0.8576697111129761\n",
      "Ep 23: Batch #133 - Loss: 0.8474848866462708\n",
      "Ep 23: Batch #134 - Loss: 0.7997333407402039\n",
      "Ep 23: Batch #135 - Loss: 1.0023009777069092\n",
      "Ep 23: Batch #136 - Loss: 1.2234059572219849\n",
      "Ep 23: Batch #137 - Loss: 0.9995454549789429\n",
      "Ep 23: Batch #138 - Loss: 1.1039860248565674\n",
      "Ep 23: Batch #139 - Loss: 0.9338204264640808\n",
      "Ep 23: Batch #140 - Loss: 1.0820894241333008\n",
      "Ep 23: Batch #141 - Loss: 1.3926557302474976\n",
      "Ep 23: Batch #142 - Loss: 0.8222695589065552\n",
      "Ep 23: Batch #143 - Loss: 1.0052212476730347\n",
      "Ep 23: Batch #144 - Loss: 0.7496002912521362\n",
      "Ep 23: Batch #145 - Loss: 0.7031685709953308\n",
      "Ep 23: Batch #146 - Loss: 0.9115827679634094\n",
      "Ep 23: Batch #147 - Loss: 0.8999510407447815\n",
      "Ep 23: Batch #148 - Loss: 1.0135376453399658\n",
      "Ep 23: Batch #149 - Loss: 0.8893324732780457\n",
      "Ep 23: Batch #150 - Loss: 0.9116243720054626\n",
      "Ep 23: Batch #151 - Loss: 0.7479953765869141\n",
      "Ep 23: Batch #152 - Loss: 0.76215660572052\n",
      "Ep 23: Batch #153 - Loss: 1.1412314176559448\n",
      "Ep 23: Batch #154 - Loss: 0.789050281047821\n",
      "Ep 23: Batch #155 - Loss: 0.8662633299827576\n",
      "Ep 23: Batch #156 - Loss: 1.0520405769348145\n",
      "Ep 23: Batch #157 - Loss: 0.7894542217254639\n",
      "Ep 23: Batch #158 - Loss: 0.8282779455184937\n",
      "Ep 23: Batch #159 - Loss: 0.8392664790153503\n",
      "Ep 23: Batch #160 - Loss: 0.9304017424583435\n",
      "Ep 23: Batch #161 - Loss: 0.8455401062965393\n",
      "Ep 23: Batch #162 - Loss: 0.9642625451087952\n",
      "Ep 23: Batch #163 - Loss: 0.9550856351852417\n",
      "Ep 23: Batch #164 - Loss: 0.8126869797706604\n",
      "Ep 23: Batch #165 - Loss: 1.5273267030715942\n",
      "Ep 23: Batch #166 - Loss: 0.7096410989761353\n",
      "Ep 23: Batch #167 - Loss: 1.118424892425537\n",
      "Ep 23: Batch #168 - Loss: 0.8934882879257202\n",
      "Ep 23: Batch #169 - Loss: 0.8302735686302185\n",
      "Ep 23: Batch #170 - Loss: 0.8336970210075378\n",
      "Ep 23: Batch #171 - Loss: 0.8130713701248169\n",
      "Ep 23: Batch #172 - Loss: 0.6556150317192078\n",
      "Ep 23: Batch #173 - Loss: 1.2395236492156982\n",
      "Ep 23: Batch #174 - Loss: 0.6022979021072388\n",
      "Ep 23: Batch #175 - Loss: 0.8035410642623901\n",
      "Ep 23: Batch #176 - Loss: 1.1896201372146606\n",
      "Ep 23: Batch #177 - Loss: 0.8789300322532654\n",
      "Ep 23: Batch #178 - Loss: 0.7951441407203674\n",
      "Ep 23: Batch #179 - Loss: 0.976468563079834\n",
      "Ep 23: Batch #180 - Loss: 0.8940913081169128\n",
      "Ep 23: Batch #181 - Loss: 1.0316520929336548\n",
      "Ep 23: Batch #182 - Loss: 0.7890955805778503\n",
      "Ep 23: Batch #183 - Loss: 0.7953054308891296\n",
      "Ep 23: Batch #184 - Loss: 1.094663143157959\n",
      "Ep 23: Batch #185 - Loss: 0.7842006087303162\n",
      "Ep 23: Batch #186 - Loss: 1.006400227546692\n",
      "Ep 23: Batch #187 - Loss: 1.1980715990066528\n",
      "Ep 23: Batch #188 - Loss: 1.379933476448059\n",
      "Ep 23: Batch #189 - Loss: 0.722283124923706\n",
      "Ep 23: Batch #190 - Loss: 0.7623937726020813\n",
      "Ep 23: Batch #191 - Loss: 1.0948859453201294\n",
      "Ep 23: Batch #192 - Loss: 0.6905763149261475\n",
      "Ep 23: Batch #193 - Loss: 0.7707992196083069\n",
      "Ep 23: Batch #194 - Loss: 0.7227938175201416\n",
      "Ep 23: Batch #195 - Loss: 1.0155836343765259\n",
      "Ep 23: Batch #196 - Loss: 0.8938506245613098\n",
      "Ep 23: Batch #197 - Loss: 0.9317607283592224\n",
      "Ep 23: Batch #198 - Loss: 0.7057501673698425\n",
      "Ep 23: Batch #199 - Loss: 0.892845094203949\n",
      "Ep 24: Batch #0 - Loss: 0.8257560729980469\n",
      "Ep 24: Batch #1 - Loss: 0.9079225063323975\n",
      "Ep 24: Batch #2 - Loss: 1.0337404012680054\n",
      "Ep 24: Batch #3 - Loss: 0.8931654691696167\n",
      "Ep 24: Batch #4 - Loss: 0.8198398351669312\n",
      "Ep 24: Batch #5 - Loss: 0.6886413097381592\n",
      "Ep 24: Batch #6 - Loss: 0.9073984622955322\n",
      "Ep 24: Batch #7 - Loss: 0.7252610921859741\n",
      "Ep 24: Batch #8 - Loss: 0.7583039999008179\n",
      "Ep 24: Batch #9 - Loss: 1.4422920942306519\n",
      "Ep 24: Batch #10 - Loss: 1.0398674011230469\n",
      "Ep 24: Batch #11 - Loss: 0.6954929828643799\n",
      "Ep 24: Batch #12 - Loss: 1.587599277496338\n",
      "Ep 24: Batch #13 - Loss: 0.6662857532501221\n",
      "Ep 24: Batch #14 - Loss: 0.750229001045227\n",
      "Ep 24: Batch #15 - Loss: 1.2758170366287231\n",
      "Ep 24: Batch #16 - Loss: 1.3201777935028076\n",
      "Ep 24: Batch #17 - Loss: 0.9114434123039246\n",
      "Ep 24: Batch #18 - Loss: 0.9633389711380005\n",
      "Ep 24: Batch #19 - Loss: 0.6903009414672852\n",
      "Ep 24: Batch #20 - Loss: 0.6797485947608948\n",
      "Ep 24: Batch #21 - Loss: 1.2423841953277588\n",
      "Ep 24: Batch #22 - Loss: 0.7485452890396118\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 24: Batch #23 - Loss: 0.7741162180900574\n",
      "Ep 24: Batch #24 - Loss: 0.8479198217391968\n",
      "Ep 24: Batch #25 - Loss: 0.7443008422851562\n",
      "Ep 24: Batch #26 - Loss: 0.761584997177124\n",
      "Ep 24: Batch #27 - Loss: 1.3894975185394287\n",
      "Ep 24: Batch #28 - Loss: 0.8958203792572021\n",
      "Ep 24: Batch #29 - Loss: 0.9273382425308228\n",
      "Ep 24: Batch #30 - Loss: 1.2338995933532715\n",
      "Ep 24: Batch #31 - Loss: 0.6930471658706665\n",
      "Ep 24: Batch #32 - Loss: 0.7757005095481873\n",
      "Ep 24: Batch #33 - Loss: 0.8314787149429321\n",
      "Ep 24: Batch #34 - Loss: 0.8107780814170837\n",
      "Ep 24: Batch #35 - Loss: 0.9859552979469299\n",
      "Ep 24: Batch #36 - Loss: 0.7272549867630005\n",
      "Ep 24: Batch #37 - Loss: 1.1696577072143555\n",
      "Ep 24: Batch #38 - Loss: 0.777137279510498\n",
      "Ep 24: Batch #39 - Loss: 0.841958224773407\n",
      "Ep 24: Batch #40 - Loss: 0.8033667206764221\n",
      "Ep 24: Batch #41 - Loss: 0.7661956548690796\n",
      "Ep 24: Batch #42 - Loss: 0.7460134029388428\n",
      "Ep 24: Batch #43 - Loss: 0.8143543601036072\n",
      "Ep 24: Batch #44 - Loss: 0.8121195435523987\n",
      "Ep 24: Batch #45 - Loss: 0.663679301738739\n",
      "Ep 24: Batch #46 - Loss: 0.8613774180412292\n",
      "Ep 24: Batch #47 - Loss: 0.9998341202735901\n",
      "Ep 24: Batch #48 - Loss: 1.3933920860290527\n",
      "Ep 24: Batch #49 - Loss: 1.0469599962234497\n",
      "Ep 24: Batch #50 - Loss: 0.725288450717926\n",
      "Ep 24: Batch #51 - Loss: 1.0318677425384521\n",
      "Ep 24: Batch #52 - Loss: 0.8169767260551453\n",
      "Ep 24: Batch #53 - Loss: 0.8509268760681152\n",
      "Ep 24: Batch #54 - Loss: 0.7276616096496582\n",
      "Ep 24: Batch #55 - Loss: 0.7819269895553589\n",
      "Ep 24: Batch #56 - Loss: 1.297830581665039\n",
      "Ep 24: Batch #57 - Loss: 0.8824029564857483\n",
      "Ep 24: Batch #58 - Loss: 1.0365813970565796\n",
      "Ep 24: Batch #59 - Loss: 0.7032709121704102\n",
      "Ep 24: Batch #60 - Loss: 1.3439900875091553\n",
      "Ep 24: Batch #61 - Loss: 0.6600157022476196\n",
      "Ep 24: Batch #62 - Loss: 0.7518888711929321\n",
      "Ep 24: Batch #63 - Loss: 1.038399338722229\n",
      "Ep 24: Batch #64 - Loss: 9.46007251739502\n",
      "Ep 24: Batch #65 - Loss: 0.6331709623336792\n",
      "Ep 24: Batch #66 - Loss: 0.8315666913986206\n",
      "Ep 24: Batch #67 - Loss: 0.9387997984886169\n",
      "Ep 24: Batch #68 - Loss: 0.9403090476989746\n",
      "Ep 24: Batch #69 - Loss: 0.773055374622345\n",
      "Ep 24: Batch #70 - Loss: 0.811317503452301\n",
      "Ep 24: Batch #71 - Loss: 0.7041428089141846\n",
      "Ep 24: Batch #72 - Loss: 0.8843467831611633\n",
      "Ep 24: Batch #73 - Loss: 0.9397342205047607\n",
      "Ep 24: Batch #74 - Loss: 0.7692728638648987\n",
      "Ep 24: Batch #75 - Loss: 0.7936066389083862\n",
      "Ep 24: Batch #76 - Loss: 1.12156081199646\n",
      "Ep 24: Batch #77 - Loss: 0.7612999081611633\n",
      "Ep 24: Batch #78 - Loss: 1.197795033454895\n",
      "Ep 24: Batch #79 - Loss: 0.6510183215141296\n",
      "Ep 24: Batch #80 - Loss: 0.8926610350608826\n",
      "Ep 24: Batch #81 - Loss: 1.712432622909546\n",
      "Ep 24: Batch #82 - Loss: 0.9022000432014465\n",
      "Ep 24: Batch #83 - Loss: 1.7577344179153442\n",
      "Ep 24: Batch #84 - Loss: 0.7425537109375\n",
      "Ep 24: Batch #85 - Loss: 1.0004078149795532\n",
      "Ep 24: Batch #86 - Loss: 0.7389955520629883\n",
      "Ep 24: Batch #87 - Loss: 0.7381723523139954\n",
      "Ep 24: Batch #88 - Loss: 0.8326584696769714\n",
      "Ep 24: Batch #89 - Loss: 0.902739942073822\n",
      "Ep 24: Batch #90 - Loss: 1.198297142982483\n",
      "Ep 24: Batch #91 - Loss: 0.8339748978614807\n",
      "Ep 24: Batch #92 - Loss: 1.0638872385025024\n",
      "Ep 24: Batch #93 - Loss: 1.0690404176712036\n",
      "Ep 24: Batch #94 - Loss: 1.0843796730041504\n",
      "Ep 24: Batch #95 - Loss: 0.9515776038169861\n",
      "Ep 24: Batch #96 - Loss: 0.9338687658309937\n",
      "Ep 24: Batch #97 - Loss: 0.757381021976471\n",
      "Ep 24: Batch #98 - Loss: 0.7675874829292297\n",
      "Ep 24: Batch #99 - Loss: 0.985830545425415\n",
      "Ep 24: Batch #100 - Loss: 0.7052462100982666\n",
      "Ep 24: Batch #101 - Loss: 1.077939748764038\n",
      "Ep 24: Batch #102 - Loss: 0.8082703948020935\n",
      "Ep 24: Batch #103 - Loss: 0.8153958916664124\n",
      "Ep 24: Batch #104 - Loss: 0.829421877861023\n",
      "Ep 24: Batch #105 - Loss: 1.0611690282821655\n",
      "Ep 24: Batch #106 - Loss: 0.7858812808990479\n",
      "Ep 24: Batch #107 - Loss: 0.7874881625175476\n",
      "Ep 24: Batch #108 - Loss: 1.0683528184890747\n",
      "Ep 24: Batch #109 - Loss: 0.7868531346321106\n",
      "Ep 24: Batch #110 - Loss: 0.9543081521987915\n",
      "Ep 24: Batch #111 - Loss: 1.4152562618255615\n",
      "Ep 24: Batch #112 - Loss: 1.0842781066894531\n",
      "Ep 24: Batch #113 - Loss: 0.8454315662384033\n",
      "Ep 24: Batch #114 - Loss: 0.9348644018173218\n",
      "Ep 24: Batch #115 - Loss: 1.125270962715149\n",
      "Ep 24: Batch #116 - Loss: 0.6507446765899658\n",
      "Ep 24: Batch #117 - Loss: 0.8990223407745361\n",
      "Ep 24: Batch #118 - Loss: 0.5683104395866394\n",
      "Model saved in file: ./weights_autoencoder_low_LR/model_e24b118_1516651271.888861.ckpt\n",
      "Ep 24: Batch #119 - Loss: 1.0579934120178223\n",
      "Ep 24: Batch #120 - Loss: 0.822759211063385\n",
      "Ep 24: Batch #121 - Loss: 0.712263286113739\n",
      "Ep 24: Batch #122 - Loss: 0.8538588285446167\n",
      "Ep 24: Batch #123 - Loss: 0.8587540984153748\n",
      "Ep 24: Batch #124 - Loss: 0.6837486028671265\n",
      "Ep 24: Batch #125 - Loss: 2.7544384002685547\n",
      "Ep 24: Batch #126 - Loss: 1.2589536905288696\n",
      "Ep 24: Batch #127 - Loss: 0.781532883644104\n",
      "Ep 24: Batch #128 - Loss: 1.1462407112121582\n",
      "Ep 24: Batch #129 - Loss: 0.8697001934051514\n",
      "Ep 24: Batch #130 - Loss: 0.751469075679779\n",
      "Ep 24: Batch #131 - Loss: 1.0346386432647705\n",
      "Ep 24: Batch #132 - Loss: 0.8558126091957092\n",
      "Ep 24: Batch #133 - Loss: 0.8458907008171082\n",
      "Ep 24: Batch #134 - Loss: 0.7981111407279968\n",
      "Ep 24: Batch #135 - Loss: 1.0003718137741089\n",
      "Ep 24: Batch #136 - Loss: 1.221227765083313\n",
      "Ep 24: Batch #137 - Loss: 0.9977430105209351\n",
      "Ep 24: Batch #138 - Loss: 1.1022762060165405\n",
      "Ep 24: Batch #139 - Loss: 0.9320218563079834\n",
      "Ep 24: Batch #140 - Loss: 1.0803849697113037\n",
      "Ep 24: Batch #141 - Loss: 1.3908798694610596\n",
      "Ep 24: Batch #142 - Loss: 0.8209567070007324\n",
      "Ep 24: Batch #143 - Loss: 1.0031059980392456\n",
      "Ep 24: Batch #144 - Loss: 0.7479408979415894\n",
      "Ep 24: Batch #145 - Loss: 0.7018675804138184\n",
      "Ep 24: Batch #146 - Loss: 0.9102177023887634\n",
      "Ep 24: Batch #147 - Loss: 0.8980406522750854\n",
      "Ep 24: Batch #148 - Loss: 1.0117069482803345\n",
      "Ep 24: Batch #149 - Loss: 0.8875280618667603\n",
      "Ep 24: Batch #150 - Loss: 0.9102416038513184\n",
      "Ep 24: Batch #151 - Loss: 0.7468436360359192\n",
      "Ep 24: Batch #152 - Loss: 0.7608512043952942\n",
      "Ep 24: Batch #153 - Loss: 1.1393800973892212\n",
      "Ep 24: Batch #154 - Loss: 0.7877798676490784\n",
      "Ep 24: Batch #155 - Loss: 0.864421546459198\n",
      "Ep 24: Batch #156 - Loss: 1.0503194332122803\n",
      "Ep 24: Batch #157 - Loss: 0.7880259156227112\n",
      "Ep 24: Batch #158 - Loss: 0.826927900314331\n",
      "Ep 24: Batch #159 - Loss: 0.8376531004905701\n",
      "Ep 24: Batch #160 - Loss: 0.9289825558662415\n",
      "Ep 24: Batch #161 - Loss: 0.843991219997406\n",
      "Ep 24: Batch #162 - Loss: 0.9626061320304871\n",
      "Ep 24: Batch #163 - Loss: 0.9537191390991211\n",
      "Ep 24: Batch #164 - Loss: 0.8112364411354065\n",
      "Ep 24: Batch #165 - Loss: 1.5258042812347412\n",
      "Ep 24: Batch #166 - Loss: 0.7079499959945679\n",
      "Ep 24: Batch #167 - Loss: 1.1168032884597778\n",
      "Ep 24: Batch #168 - Loss: 0.8917545080184937\n",
      "Ep 24: Batch #169 - Loss: 0.8287203311920166\n",
      "Ep 24: Batch #170 - Loss: 0.8322246074676514\n",
      "Ep 24: Batch #171 - Loss: 0.8113988637924194\n",
      "Ep 24: Batch #172 - Loss: 0.6544429063796997\n",
      "Ep 24: Batch #173 - Loss: 1.2373771667480469\n",
      "Ep 24: Batch #174 - Loss: 0.6009393334388733\n",
      "Ep 24: Batch #175 - Loss: 0.8021987080574036\n",
      "Ep 24: Batch #176 - Loss: 1.188170313835144\n",
      "Ep 24: Batch #177 - Loss: 0.8773349523544312\n",
      "Ep 24: Batch #178 - Loss: 0.7934519052505493\n",
      "Ep 24: Batch #179 - Loss: 0.9746320843696594\n",
      "Ep 24: Batch #180 - Loss: 0.892061710357666\n",
      "Ep 24: Batch #181 - Loss: 1.0296416282653809\n",
      "Ep 24: Batch #182 - Loss: 0.7877686619758606\n",
      "Ep 24: Batch #183 - Loss: 0.7937185764312744\n",
      "Ep 24: Batch #184 - Loss: 1.093168020248413\n",
      "Ep 24: Batch #185 - Loss: 0.7828307747840881\n",
      "Ep 24: Batch #186 - Loss: 1.0044240951538086\n",
      "Ep 24: Batch #187 - Loss: 1.1963436603546143\n",
      "Ep 24: Batch #188 - Loss: 1.3780525922775269\n",
      "Ep 24: Batch #189 - Loss: 0.7212615609169006\n",
      "Ep 24: Batch #190 - Loss: 0.7608591318130493\n",
      "Ep 24: Batch #191 - Loss: 1.0934799909591675\n",
      "Ep 24: Batch #192 - Loss: 0.6894546747207642\n",
      "Ep 24: Batch #193 - Loss: 0.7692751288414001\n",
      "Ep 24: Batch #194 - Loss: 0.7213451266288757\n",
      "Ep 24: Batch #195 - Loss: 1.0139718055725098\n",
      "Ep 24: Batch #196 - Loss: 0.892368495464325\n",
      "Ep 24: Batch #197 - Loss: 0.9302510619163513\n",
      "Ep 24: Batch #198 - Loss: 0.7042738199234009\n",
      "Ep 24: Batch #199 - Loss: 0.8912169337272644\n",
      "Ep 25: Batch #0 - Loss: 0.8239375948905945\n",
      "Ep 25: Batch #1 - Loss: 0.9062191247940063\n",
      "Ep 25: Batch #2 - Loss: 1.0325007438659668\n",
      "Ep 25: Batch #3 - Loss: 0.8915015459060669\n",
      "Ep 25: Batch #4 - Loss: 0.8182073831558228\n",
      "Ep 25: Batch #5 - Loss: 0.6874874234199524\n",
      "Ep 25: Batch #6 - Loss: 0.9058465957641602\n",
      "Ep 25: Batch #7 - Loss: 0.7240327596664429\n",
      "Ep 25: Batch #8 - Loss: 0.7569068074226379\n",
      "Ep 25: Batch #9 - Loss: 1.4402962923049927\n",
      "Ep 25: Batch #10 - Loss: 1.0379983186721802\n",
      "Ep 25: Batch #11 - Loss: 0.6940019130706787\n",
      "Ep 25: Batch #12 - Loss: 1.586201786994934\n",
      "Ep 25: Batch #13 - Loss: 0.665287435054779\n",
      "Ep 25: Batch #14 - Loss: 0.7490209341049194\n",
      "Ep 25: Batch #15 - Loss: 1.2738595008850098\n",
      "Ep 25: Batch #16 - Loss: 1.3178520202636719\n",
      "Ep 25: Batch #17 - Loss: 0.9098087549209595\n",
      "Ep 25: Batch #18 - Loss: 0.9622663855552673\n",
      "Ep 25: Batch #19 - Loss: 0.6891251802444458\n",
      "Ep 25: Batch #20 - Loss: 0.6783599853515625\n",
      "Ep 25: Batch #21 - Loss: 1.240734338760376\n",
      "Ep 25: Batch #22 - Loss: 0.74728924036026\n",
      "Ep 25: Batch #23 - Loss: 0.7723637819290161\n",
      "Ep 25: Batch #24 - Loss: 0.8465831279754639\n",
      "Ep 25: Batch #25 - Loss: 0.7426088452339172\n",
      "Ep 25: Batch #26 - Loss: 0.7599391341209412\n",
      "Ep 25: Batch #27 - Loss: 1.3876858949661255\n",
      "Ep 25: Batch #28 - Loss: 0.8942872881889343\n",
      "Ep 25: Batch #29 - Loss: 0.9254380464553833\n",
      "Ep 25: Batch #30 - Loss: 1.2320148944854736\n",
      "Ep 25: Batch #31 - Loss: 0.6919350028038025\n",
      "Ep 25: Batch #32 - Loss: 0.7741743326187134\n",
      "Ep 25: Batch #33 - Loss: 0.8300740122795105\n",
      "Ep 25: Batch #34 - Loss: 0.8092786073684692\n",
      "Ep 25: Batch #35 - Loss: 0.9840081334114075\n",
      "Ep 25: Batch #36 - Loss: 0.7259414196014404\n",
      "Ep 25: Batch #37 - Loss: 1.168164849281311\n",
      "Ep 25: Batch #38 - Loss: 0.7753676176071167\n",
      "Ep 25: Batch #39 - Loss: 0.840744137763977\n",
      "Ep 25: Batch #40 - Loss: 0.8017272353172302\n",
      "Ep 25: Batch #41 - Loss: 0.7647778391838074\n",
      "Ep 25: Batch #42 - Loss: 0.7447112798690796\n",
      "Ep 25: Batch #43 - Loss: 0.8128808736801147\n",
      "Ep 25: Batch #44 - Loss: 0.8106516003608704\n",
      "Ep 25: Batch #45 - Loss: 0.6619431376457214\n",
      "Ep 25: Batch #46 - Loss: 0.8597306609153748\n",
      "Ep 25: Batch #47 - Loss: 0.9977332949638367\n",
      "Ep 25: Batch #48 - Loss: 1.3912506103515625\n",
      "Ep 25: Batch #49 - Loss: 1.045525312423706\n",
      "Ep 25: Batch #50 - Loss: 0.7242456674575806\n",
      "Ep 25: Batch #51 - Loss: 1.0300043821334839\n",
      "Ep 25: Batch #52 - Loss: 0.8157442212104797\n",
      "Ep 25: Batch #53 - Loss: 0.8493906855583191\n",
      "Ep 25: Batch #54 - Loss: 0.7263861894607544\n",
      "Ep 25: Batch #55 - Loss: 0.7802436947822571\n",
      "Ep 25: Batch #56 - Loss: 1.296033501625061\n",
      "Ep 25: Batch #57 - Loss: 0.8804001808166504\n",
      "Ep 25: Batch #58 - Loss: 1.034696340560913\n",
      "Ep 25: Batch #59 - Loss: 0.7019712328910828\n",
      "Ep 25: Batch #60 - Loss: 1.341963529586792\n",
      "Ep 25: Batch #61 - Loss: 0.6586307883262634\n",
      "Ep 25: Batch #62 - Loss: 0.750262439250946\n",
      "Ep 25: Batch #63 - Loss: 1.0363088846206665\n",
      "Ep 25: Batch #64 - Loss: 9.458833694458008\n",
      "Ep 25: Batch #65 - Loss: 0.6319953203201294\n",
      "Ep 25: Batch #66 - Loss: 0.8296818137168884\n",
      "Ep 25: Batch #67 - Loss: 0.9372166991233826\n",
      "Ep 25: Batch #68 - Loss: 0.9386444687843323\n",
      "Ep 25: Batch #69 - Loss: 0.7714743614196777\n",
      "Ep 25: Batch #70 - Loss: 0.8093560934066772\n",
      "Ep 25: Batch #71 - Loss: 0.7027570605278015\n",
      "Ep 25: Batch #72 - Loss: 0.8827117085456848\n",
      "Ep 25: Batch #73 - Loss: 0.937904417514801\n",
      "Ep 25: Batch #74 - Loss: 0.7678578495979309\n",
      "Ep 25: Batch #75 - Loss: 0.7922154068946838\n",
      "Ep 25: Batch #76 - Loss: 1.1201251745224\n",
      "Ep 25: Batch #77 - Loss: 0.7598603963851929\n",
      "Ep 25: Batch #78 - Loss: 1.1955937147140503\n",
      "Ep 25: Batch #79 - Loss: 0.6495245695114136\n",
      "Ep 25: Batch #80 - Loss: 0.8908091187477112\n",
      "Ep 25: Batch #81 - Loss: 1.710904598236084\n",
      "Ep 25: Batch #82 - Loss: 0.9005287885665894\n",
      "Ep 25: Batch #83 - Loss: 1.756324291229248\n",
      "Ep 25: Batch #84 - Loss: 0.7410528063774109\n",
      "Ep 25: Batch #85 - Loss: 0.998769223690033\n",
      "Ep 25: Batch #86 - Loss: 0.7373086810112\n",
      "Ep 25: Batch #87 - Loss: 0.7367591261863708\n",
      "Ep 25: Batch #88 - Loss: 0.8310324549674988\n",
      "Ep 25: Batch #89 - Loss: 0.9016510248184204\n",
      "Ep 25: Batch #90 - Loss: 1.1959636211395264\n",
      "Ep 25: Batch #91 - Loss: 0.8322269320487976\n",
      "Ep 25: Batch #92 - Loss: 1.0619608163833618\n",
      "Ep 25: Batch #93 - Loss: 1.0669846534729004\n",
      "Ep 25: Batch #94 - Loss: 1.0825673341751099\n",
      "Ep 25: Batch #95 - Loss: 0.949726939201355\n",
      "Ep 25: Batch #96 - Loss: 0.9323291182518005\n",
      "Ep 25: Batch #97 - Loss: 0.7558450698852539\n",
      "Ep 25: Batch #98 - Loss: 0.7659345269203186\n",
      "Ep 25: Batch #99 - Loss: 0.9843549728393555\n",
      "Ep 25: Batch #100 - Loss: 0.70368492603302\n",
      "Ep 25: Batch #101 - Loss: 1.0761967897415161\n",
      "Ep 25: Batch #102 - Loss: 0.8068012595176697\n",
      "Ep 25: Batch #103 - Loss: 0.8141486048698425\n",
      "Ep 25: Batch #104 - Loss: 0.827793300151825\n",
      "Ep 25: Batch #105 - Loss: 1.0595005750656128\n",
      "Ep 25: Batch #106 - Loss: 0.7844352722167969\n",
      "Ep 25: Batch #107 - Loss: 0.7858105301856995\n",
      "Ep 25: Batch #108 - Loss: 1.0664337873458862\n",
      "Ep 25: Batch #109 - Loss: 0.7855398058891296\n",
      "Ep 25: Batch #110 - Loss: 0.9524396657943726\n",
      "Ep 25: Batch #111 - Loss: 1.4133849143981934\n",
      "Ep 25: Batch #112 - Loss: 1.0821750164031982\n",
      "Ep 25: Batch #113 - Loss: 0.8437796831130981\n",
      "Ep 25: Batch #114 - Loss: 0.9331856369972229\n",
      "Ep 25: Batch #115 - Loss: 1.1236377954483032\n",
      "Ep 25: Batch #116 - Loss: 0.6497151851654053\n",
      "Ep 25: Batch #117 - Loss: 0.8975239396095276\n",
      "Ep 25: Batch #118 - Loss: 0.5668964385986328\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved in file: ./weights_autoencoder_low_LR/model_e25b118_1516651272.0246148.ckpt\n",
      "Ep 25: Batch #119 - Loss: 1.0562827587127686\n",
      "Ep 25: Batch #120 - Loss: 0.8215770721435547\n",
      "Ep 25: Batch #121 - Loss: 0.7108103632926941\n",
      "Ep 25: Batch #122 - Loss: 0.8522985577583313\n",
      "Ep 25: Batch #123 - Loss: 0.8572962880134583\n",
      "Ep 25: Batch #124 - Loss: 0.6825680732727051\n",
      "Ep 25: Batch #125 - Loss: 2.7524282932281494\n",
      "Ep 25: Batch #126 - Loss: 1.25705087184906\n",
      "Ep 25: Batch #127 - Loss: 0.7797420620918274\n",
      "Ep 25: Batch #128 - Loss: 1.144197702407837\n",
      "Ep 25: Batch #129 - Loss: 0.8679616451263428\n",
      "Ep 25: Batch #130 - Loss: 0.7498484253883362\n",
      "Ep 25: Batch #131 - Loss: 1.0324956178665161\n",
      "Ep 25: Batch #132 - Loss: 0.8539776802062988\n",
      "Ep 25: Batch #133 - Loss: 0.8443137407302856\n",
      "Ep 25: Batch #134 - Loss: 0.7964776158332825\n",
      "Ep 25: Batch #135 - Loss: 0.9984972476959229\n",
      "Ep 25: Batch #136 - Loss: 1.219031810760498\n",
      "Ep 25: Batch #137 - Loss: 0.9959405064582825\n",
      "Ep 25: Batch #138 - Loss: 1.100581407546997\n",
      "Ep 25: Batch #139 - Loss: 0.930229663848877\n",
      "Ep 25: Batch #140 - Loss: 1.0787105560302734\n",
      "Ep 25: Batch #141 - Loss: 1.3891170024871826\n",
      "Ep 25: Batch #142 - Loss: 0.8196295499801636\n",
      "Ep 25: Batch #143 - Loss: 1.0010110139846802\n",
      "Ep 25: Batch #144 - Loss: 0.7463134527206421\n",
      "Ep 25: Batch #145 - Loss: 0.7005630731582642\n",
      "Ep 25: Batch #146 - Loss: 0.9088501930236816\n",
      "Ep 25: Batch #147 - Loss: 0.8961051106452942\n",
      "Ep 25: Batch #148 - Loss: 1.0098670721054077\n",
      "Ep 25: Batch #149 - Loss: 0.885730504989624\n",
      "Ep 25: Batch #150 - Loss: 0.9088313579559326\n",
      "Ep 25: Batch #151 - Loss: 0.7456809282302856\n",
      "Ep 25: Batch #152 - Loss: 0.7595611214637756\n",
      "Ep 25: Batch #153 - Loss: 1.1375761032104492\n",
      "Ep 25: Batch #154 - Loss: 0.7865129113197327\n",
      "Ep 25: Batch #155 - Loss: 0.8626067638397217\n",
      "Ep 25: Batch #156 - Loss: 1.0485782623291016\n",
      "Ep 25: Batch #157 - Loss: 0.7866212725639343\n",
      "Ep 25: Batch #158 - Loss: 0.8256235718727112\n",
      "Ep 25: Batch #159 - Loss: 0.8360379934310913\n",
      "Ep 25: Batch #160 - Loss: 0.927579402923584\n",
      "Ep 25: Batch #161 - Loss: 0.8424685597419739\n",
      "Ep 25: Batch #162 - Loss: 0.960972785949707\n",
      "Ep 25: Batch #163 - Loss: 0.9523608684539795\n",
      "Ep 25: Batch #164 - Loss: 0.8098055720329285\n",
      "Ep 25: Batch #165 - Loss: 1.5243173837661743\n",
      "Ep 25: Batch #166 - Loss: 0.7063030004501343\n",
      "Ep 25: Batch #167 - Loss: 1.115187644958496\n",
      "Ep 25: Batch #168 - Loss: 0.8900436162948608\n",
      "Ep 25: Batch #169 - Loss: 0.8272125720977783\n",
      "Ep 25: Batch #170 - Loss: 0.8307690620422363\n",
      "Ep 25: Batch #171 - Loss: 0.8097521066665649\n",
      "Ep 25: Batch #172 - Loss: 0.6532812714576721\n",
      "Ep 25: Batch #173 - Loss: 1.235252857208252\n",
      "Ep 25: Batch #174 - Loss: 0.5996046662330627\n",
      "Ep 25: Batch #175 - Loss: 0.8008683323860168\n",
      "Ep 25: Batch #176 - Loss: 1.1867245435714722\n",
      "Ep 25: Batch #177 - Loss: 0.8757787346839905\n",
      "Ep 25: Batch #178 - Loss: 0.7917603254318237\n",
      "Ep 25: Batch #179 - Loss: 0.972807765007019\n",
      "Ep 25: Batch #180 - Loss: 0.8900443911552429\n",
      "Ep 25: Batch #181 - Loss: 1.027644395828247\n",
      "Ep 25: Batch #182 - Loss: 0.7864550948143005\n",
      "Ep 25: Batch #183 - Loss: 0.7921470403671265\n",
      "Ep 25: Batch #184 - Loss: 1.09170663356781\n",
      "Ep 25: Batch #185 - Loss: 0.7815029621124268\n",
      "Ep 25: Batch #186 - Loss: 1.0024690628051758\n",
      "Ep 25: Batch #187 - Loss: 1.1946520805358887\n",
      "Ep 25: Batch #188 - Loss: 1.3762372732162476\n",
      "Ep 25: Batch #189 - Loss: 0.7202290296554565\n",
      "Ep 25: Batch #190 - Loss: 0.7593368887901306\n",
      "Ep 25: Batch #191 - Loss: 1.092067837715149\n",
      "Ep 25: Batch #192 - Loss: 0.6883573532104492\n",
      "Ep 25: Batch #193 - Loss: 0.7677621841430664\n",
      "Ep 25: Batch #194 - Loss: 0.7199253439903259\n",
      "Ep 25: Batch #195 - Loss: 1.0123635530471802\n",
      "Ep 25: Batch #196 - Loss: 0.8908953666687012\n",
      "Ep 25: Batch #197 - Loss: 0.9287567138671875\n",
      "Ep 25: Batch #198 - Loss: 0.7028237581253052\n",
      "Ep 25: Batch #199 - Loss: 0.889619767665863\n",
      "Ep 26: Batch #0 - Loss: 0.8221482038497925\n",
      "Ep 26: Batch #1 - Loss: 0.9045197367668152\n",
      "Ep 26: Batch #2 - Loss: 1.031256079673767\n",
      "Ep 26: Batch #3 - Loss: 0.889909565448761\n",
      "Ep 26: Batch #4 - Loss: 0.8165718913078308\n",
      "Ep 26: Batch #5 - Loss: 0.6863816976547241\n",
      "Ep 26: Batch #6 - Loss: 0.9043009877204895\n",
      "Ep 26: Batch #7 - Loss: 0.722823977470398\n",
      "Ep 26: Batch #8 - Loss: 0.7555301785469055\n",
      "Ep 26: Batch #9 - Loss: 1.4382692575454712\n",
      "Ep 26: Batch #10 - Loss: 1.0361710786819458\n",
      "Ep 26: Batch #11 - Loss: 0.6925327777862549\n",
      "Ep 26: Batch #12 - Loss: 1.58482027053833\n",
      "Ep 26: Batch #13 - Loss: 0.664304256439209\n",
      "Ep 26: Batch #14 - Loss: 0.7478194236755371\n",
      "Ep 26: Batch #15 - Loss: 1.2719109058380127\n",
      "Ep 26: Batch #16 - Loss: 1.3155500888824463\n",
      "Ep 26: Batch #17 - Loss: 0.9081960320472717\n",
      "Ep 26: Batch #18 - Loss: 0.9612367153167725\n",
      "Ep 26: Batch #19 - Loss: 0.6879502534866333\n",
      "Ep 26: Batch #20 - Loss: 0.6769840121269226\n",
      "Ep 26: Batch #21 - Loss: 1.2391003370285034\n",
      "Ep 26: Batch #22 - Loss: 0.7460610866546631\n",
      "Ep 26: Batch #23 - Loss: 0.7706426382064819\n",
      "Ep 26: Batch #24 - Loss: 0.8452792763710022\n",
      "Ep 26: Batch #25 - Loss: 0.7409536242485046\n",
      "Ep 26: Batch #26 - Loss: 0.7583028078079224\n",
      "Ep 26: Batch #27 - Loss: 1.3858720064163208\n",
      "Ep 26: Batch #28 - Loss: 0.8927906155586243\n",
      "Ep 26: Batch #29 - Loss: 0.9235618710517883\n",
      "Ep 26: Batch #30 - Loss: 1.2301865816116333\n",
      "Ep 26: Batch #31 - Loss: 0.6908174753189087\n",
      "Ep 26: Batch #32 - Loss: 0.7726700901985168\n",
      "Ep 26: Batch #33 - Loss: 0.8286947011947632\n",
      "Ep 26: Batch #34 - Loss: 0.8077986240386963\n",
      "Ep 26: Batch #35 - Loss: 0.9820794463157654\n",
      "Ep 26: Batch #36 - Loss: 0.724648118019104\n",
      "Ep 26: Batch #37 - Loss: 1.166676640510559\n",
      "Ep 26: Batch #38 - Loss: 0.7736240029335022\n",
      "Ep 26: Batch #39 - Loss: 0.8395624160766602\n",
      "Ep 26: Batch #40 - Loss: 0.8001079559326172\n",
      "Ep 26: Batch #41 - Loss: 0.7633755207061768\n",
      "Ep 26: Batch #42 - Loss: 0.7434486150741577\n",
      "Ep 26: Batch #43 - Loss: 0.8114382028579712\n",
      "Ep 26: Batch #44 - Loss: 0.8092126250267029\n",
      "Ep 26: Batch #45 - Loss: 0.6602316498756409\n",
      "Ep 26: Batch #46 - Loss: 0.8580808043479919\n",
      "Ep 26: Batch #47 - Loss: 0.9956532120704651\n",
      "Ep 26: Batch #48 - Loss: 1.389093041419983\n",
      "Ep 26: Batch #49 - Loss: 1.0440869331359863\n",
      "Ep 26: Batch #50 - Loss: 0.7232237458229065\n",
      "Ep 26: Batch #51 - Loss: 1.0281329154968262\n",
      "Ep 26: Batch #52 - Loss: 0.814543604850769\n",
      "Ep 26: Batch #53 - Loss: 0.8478662371635437\n",
      "Ep 26: Batch #54 - Loss: 0.7251633405685425\n",
      "Ep 26: Batch #55 - Loss: 0.778561532497406\n",
      "Ep 26: Batch #56 - Loss: 1.294232726097107\n",
      "Ep 26: Batch #57 - Loss: 0.8784329891204834\n",
      "Ep 26: Batch #58 - Loss: 1.0328196287155151\n",
      "Ep 26: Batch #59 - Loss: 0.7006890177726746\n",
      "Ep 26: Batch #60 - Loss: 1.3399845361709595\n",
      "Ep 26: Batch #61 - Loss: 0.6572521924972534\n",
      "Ep 26: Batch #62 - Loss: 0.7486775517463684\n",
      "Ep 26: Batch #63 - Loss: 1.034254789352417\n",
      "Ep 26: Batch #64 - Loss: 9.457611083984375\n",
      "Ep 26: Batch #65 - Loss: 0.6308268308639526\n",
      "Ep 26: Batch #66 - Loss: 0.8278098106384277\n",
      "Ep 26: Batch #67 - Loss: 0.9356832504272461\n",
      "Ep 26: Batch #68 - Loss: 0.9369987845420837\n",
      "Ep 26: Batch #69 - Loss: 0.7699266076087952\n",
      "Ep 26: Batch #70 - Loss: 0.8074275255203247\n",
      "Ep 26: Batch #71 - Loss: 0.7013906836509705\n",
      "Ep 26: Batch #72 - Loss: 0.881110429763794\n",
      "Ep 26: Batch #73 - Loss: 0.9361138939857483\n",
      "Ep 26: Batch #74 - Loss: 0.766437292098999\n",
      "Ep 26: Batch #75 - Loss: 0.7908263206481934\n",
      "Ep 26: Batch #76 - Loss: 1.1186877489089966\n",
      "Ep 26: Batch #77 - Loss: 0.7584459781646729\n",
      "Ep 26: Batch #78 - Loss: 1.1934832334518433\n",
      "Ep 26: Batch #79 - Loss: 0.6480682492256165\n",
      "Ep 26: Batch #80 - Loss: 0.8889935612678528\n",
      "Ep 26: Batch #81 - Loss: 1.7093617916107178\n",
      "Ep 26: Batch #82 - Loss: 0.8988726139068604\n",
      "Ep 26: Batch #83 - Loss: 1.754989743232727\n",
      "Ep 26: Batch #84 - Loss: 0.7395521998405457\n",
      "Ep 26: Batch #85 - Loss: 0.9971778988838196\n",
      "Ep 26: Batch #86 - Loss: 0.7356412410736084\n",
      "Ep 26: Batch #87 - Loss: 0.735393226146698\n",
      "Ep 26: Batch #88 - Loss: 0.8294073939323425\n",
      "Ep 26: Batch #89 - Loss: 0.9005641937255859\n",
      "Ep 26: Batch #90 - Loss: 1.1936485767364502\n",
      "Ep 26: Batch #91 - Loss: 0.8304889798164368\n",
      "Ep 26: Batch #92 - Loss: 1.0600436925888062\n",
      "Ep 26: Batch #93 - Loss: 1.0649306774139404\n",
      "Ep 26: Batch #94 - Loss: 1.0807340145111084\n",
      "Ep 26: Batch #95 - Loss: 0.9479114413261414\n",
      "Ep 26: Batch #96 - Loss: 0.9308278560638428\n",
      "Ep 26: Batch #97 - Loss: 0.7543211579322815\n",
      "Ep 26: Batch #98 - Loss: 0.7643066644668579\n",
      "Ep 26: Batch #99 - Loss: 0.9828835129737854\n",
      "Ep 26: Batch #100 - Loss: 0.7021506428718567\n",
      "Ep 26: Batch #101 - Loss: 1.0744901895523071\n",
      "Ep 26: Batch #102 - Loss: 0.8053689002990723\n",
      "Ep 26: Batch #103 - Loss: 0.812881350517273\n",
      "Ep 26: Batch #104 - Loss: 0.826194167137146\n",
      "Ep 26: Batch #105 - Loss: 1.0578603744506836\n",
      "Ep 26: Batch #106 - Loss: 0.7829964756965637\n",
      "Ep 26: Batch #107 - Loss: 0.7841497659683228\n",
      "Ep 26: Batch #108 - Loss: 1.064538836479187\n",
      "Ep 26: Batch #109 - Loss: 0.7842479944229126\n",
      "Ep 26: Batch #110 - Loss: 0.9505928754806519\n",
      "Ep 26: Batch #111 - Loss: 1.411531686782837\n",
      "Ep 26: Batch #112 - Loss: 1.080090045928955\n",
      "Ep 26: Batch #113 - Loss: 0.8421674966812134\n",
      "Ep 26: Batch #114 - Loss: 0.9315351843833923\n",
      "Ep 26: Batch #115 - Loss: 1.122043251991272\n",
      "Ep 26: Batch #116 - Loss: 0.6487038731575012\n",
      "Ep 26: Batch #117 - Loss: 0.8960580825805664\n",
      "Ep 26: Batch #118 - Loss: 0.5654971599578857\n",
      "Model saved in file: ./weights_autoencoder_low_LR/model_e26b118_1516651272.163918.ckpt\n",
      "Ep 26: Batch #119 - Loss: 1.0545819997787476\n",
      "Ep 26: Batch #120 - Loss: 0.8204098343849182\n",
      "Ep 26: Batch #121 - Loss: 0.7093799710273743\n",
      "Ep 26: Batch #122 - Loss: 0.8507288098335266\n",
      "Ep 26: Batch #123 - Loss: 0.8558465242385864\n",
      "Ep 26: Batch #124 - Loss: 0.6814097166061401\n",
      "Ep 26: Batch #125 - Loss: 2.750438928604126\n",
      "Ep 26: Batch #126 - Loss: 1.255164623260498\n",
      "Ep 26: Batch #127 - Loss: 0.7779641151428223\n",
      "Ep 26: Batch #128 - Loss: 1.1421513557434082\n",
      "Ep 26: Batch #129 - Loss: 0.8662556409835815\n",
      "Ep 26: Batch #130 - Loss: 0.7482603192329407\n",
      "Ep 26: Batch #131 - Loss: 1.0303736925125122\n",
      "Ep 26: Batch #132 - Loss: 0.8521723747253418\n",
      "Ep 26: Batch #133 - Loss: 0.8427630662918091\n",
      "Ep 26: Batch #134 - Loss: 0.7948590517044067\n",
      "Ep 26: Batch #135 - Loss: 0.9966616630554199\n",
      "Ep 26: Batch #136 - Loss: 1.216863989830017\n",
      "Ep 26: Batch #137 - Loss: 0.9941457509994507\n",
      "Ep 26: Batch #138 - Loss: 1.098915934562683\n",
      "Ep 26: Batch #139 - Loss: 0.9284616708755493\n",
      "Ep 26: Batch #140 - Loss: 1.0770606994628906\n",
      "Ep 26: Batch #141 - Loss: 1.387359857559204\n",
      "Ep 26: Batch #142 - Loss: 0.8182992339134216\n",
      "Ep 26: Batch #143 - Loss: 0.9989410042762756\n",
      "Ep 26: Batch #144 - Loss: 0.7447119951248169\n",
      "Ep 26: Batch #145 - Loss: 0.6992841362953186\n",
      "Ep 26: Batch #146 - Loss: 0.9074774980545044\n",
      "Ep 26: Batch #147 - Loss: 0.8941726088523865\n",
      "Ep 26: Batch #148 - Loss: 1.008046269416809\n",
      "Ep 26: Batch #149 - Loss: 0.8839601278305054\n",
      "Ep 26: Batch #150 - Loss: 0.9074118137359619\n",
      "Ep 26: Batch #151 - Loss: 0.7445335388183594\n",
      "Ep 26: Batch #152 - Loss: 0.7583083510398865\n",
      "Ep 26: Batch #153 - Loss: 1.1358020305633545\n",
      "Ep 26: Batch #154 - Loss: 0.7852489948272705\n",
      "Ep 26: Batch #155 - Loss: 0.8608270883560181\n",
      "Ep 26: Batch #156 - Loss: 1.0468515157699585\n",
      "Ep 26: Batch #157 - Loss: 0.7852373123168945\n",
      "Ep 26: Batch #158 - Loss: 0.8243551254272461\n",
      "Ep 26: Batch #159 - Loss: 0.8344545960426331\n",
      "Ep 26: Batch #160 - Loss: 0.926207423210144\n",
      "Ep 26: Batch #161 - Loss: 0.8409639596939087\n",
      "Ep 26: Batch #162 - Loss: 0.9593670964241028\n",
      "Ep 26: Batch #163 - Loss: 0.951016902923584\n",
      "Ep 26: Batch #164 - Loss: 0.8083996176719666\n",
      "Ep 26: Batch #165 - Loss: 1.5228663682937622\n",
      "Ep 26: Batch #166 - Loss: 0.7046946883201599\n",
      "Ep 26: Batch #167 - Loss: 1.1135920286178589\n",
      "Ep 26: Batch #168 - Loss: 0.8883493542671204\n",
      "Ep 26: Batch #169 - Loss: 0.8257421851158142\n",
      "Ep 26: Batch #170 - Loss: 0.8293105959892273\n",
      "Ep 26: Batch #171 - Loss: 0.8081163167953491\n",
      "Ep 26: Batch #172 - Loss: 0.6521387696266174\n",
      "Ep 26: Batch #173 - Loss: 1.2331387996673584\n",
      "Ep 26: Batch #174 - Loss: 0.5983054041862488\n",
      "Ep 26: Batch #175 - Loss: 0.7995629906654358\n",
      "Ep 26: Batch #176 - Loss: 1.1852694749832153\n",
      "Ep 26: Batch #177 - Loss: 0.8742477893829346\n",
      "Ep 26: Batch #178 - Loss: 0.7900839447975159\n",
      "Ep 26: Batch #179 - Loss: 0.9709795713424683\n",
      "Ep 26: Batch #180 - Loss: 0.8880345821380615\n",
      "Ep 26: Batch #181 - Loss: 1.0256661176681519\n",
      "Ep 26: Batch #182 - Loss: 0.7851636409759521\n",
      "Ep 26: Batch #183 - Loss: 0.7906089425086975\n",
      "Ep 26: Batch #184 - Loss: 1.0902947187423706\n",
      "Ep 26: Batch #185 - Loss: 0.7801905870437622\n",
      "Ep 26: Batch #186 - Loss: 1.000551462173462\n",
      "Ep 26: Batch #187 - Loss: 1.1930044889450073\n",
      "Ep 26: Batch #188 - Loss: 1.3744611740112305\n",
      "Ep 26: Batch #189 - Loss: 0.7191961407661438\n",
      "Ep 26: Batch #190 - Loss: 0.7578594088554382\n",
      "Ep 26: Batch #191 - Loss: 1.090673565864563\n",
      "Ep 26: Batch #192 - Loss: 0.6872722506523132\n",
      "Ep 26: Batch #193 - Loss: 0.7662733197212219\n",
      "Ep 26: Batch #194 - Loss: 0.7185311913490295\n",
      "Ep 26: Batch #195 - Loss: 1.0107555389404297\n",
      "Ep 26: Batch #196 - Loss: 0.8894277811050415\n",
      "Ep 26: Batch #197 - Loss: 0.9272845387458801\n",
      "Ep 26: Batch #198 - Loss: 0.7013956904411316\n",
      "Ep 26: Batch #199 - Loss: 0.8880488276481628\n",
      "Ep 27: Batch #0 - Loss: 0.8203955292701721\n",
      "Ep 27: Batch #1 - Loss: 0.9028347134590149\n",
      "Ep 27: Batch #2 - Loss: 1.0300395488739014\n",
      "Ep 27: Batch #3 - Loss: 0.8883382678031921\n",
      "Ep 27: Batch #4 - Loss: 0.8149592280387878\n",
      "Ep 27: Batch #5 - Loss: 0.6853147149085999\n",
      "Ep 27: Batch #6 - Loss: 0.9027789235115051\n",
      "Ep 27: Batch #7 - Loss: 0.7216184735298157\n",
      "Ep 27: Batch #8 - Loss: 0.7541882991790771\n",
      "Ep 27: Batch #9 - Loss: 1.4362459182739258\n",
      "Ep 27: Batch #10 - Loss: 1.0343374013900757\n",
      "Ep 27: Batch #11 - Loss: 0.6911060214042664\n",
      "Ep 27: Batch #12 - Loss: 1.5834540128707886\n",
      "Ep 27: Batch #13 - Loss: 0.6633391380310059\n",
      "Ep 27: Batch #14 - Loss: 0.7466263175010681\n",
      "Ep 27: Batch #15 - Loss: 1.2699847221374512\n",
      "Ep 27: Batch #16 - Loss: 1.3132565021514893\n",
      "Ep 27: Batch #17 - Loss: 0.906581461429596\n",
      "Ep 27: Batch #18 - Loss: 0.9602211713790894\n",
      "Ep 27: Batch #19 - Loss: 0.6867642998695374\n",
      "Ep 27: Batch #20 - Loss: 0.675635576248169\n",
      "Ep 27: Batch #21 - Loss: 1.2374927997589111\n",
      "Ep 27: Batch #22 - Loss: 0.7448632121086121\n",
      "Ep 27: Batch #23 - Loss: 0.7689329385757446\n",
      "Ep 27: Batch #24 - Loss: 0.8439777493476868\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 27: Batch #25 - Loss: 0.7393455505371094\n",
      "Ep 27: Batch #26 - Loss: 0.7566807866096497\n",
      "Ep 27: Batch #27 - Loss: 1.384055733680725\n",
      "Ep 27: Batch #28 - Loss: 0.8913260698318481\n",
      "Ep 27: Batch #29 - Loss: 0.921704888343811\n",
      "Ep 27: Batch #30 - Loss: 1.2284034490585327\n",
      "Ep 27: Batch #31 - Loss: 0.6897211074829102\n",
      "Ep 27: Batch #32 - Loss: 0.7711777091026306\n",
      "Ep 27: Batch #33 - Loss: 0.827350378036499\n",
      "Ep 27: Batch #34 - Loss: 0.8063212633132935\n",
      "Ep 27: Batch #35 - Loss: 0.9801632761955261\n",
      "Ep 27: Batch #36 - Loss: 0.723382830619812\n",
      "Ep 27: Batch #37 - Loss: 1.1651893854141235\n",
      "Ep 27: Batch #38 - Loss: 0.7719154953956604\n",
      "Ep 27: Batch #39 - Loss: 0.8384053707122803\n",
      "Ep 27: Batch #40 - Loss: 0.7985246181488037\n",
      "Ep 27: Batch #41 - Loss: 0.7619785070419312\n",
      "Ep 27: Batch #42 - Loss: 0.742233157157898\n",
      "Ep 27: Batch #43 - Loss: 0.8100225329399109\n",
      "Ep 27: Batch #44 - Loss: 0.8077983260154724\n",
      "Ep 27: Batch #45 - Loss: 0.658551037311554\n",
      "Ep 27: Batch #46 - Loss: 0.8564481735229492\n",
      "Ep 27: Batch #47 - Loss: 0.9935904145240784\n",
      "Ep 27: Batch #48 - Loss: 1.386949062347412\n",
      "Ep 27: Batch #49 - Loss: 1.0426416397094727\n",
      "Ep 27: Batch #50 - Loss: 0.7222204208374023\n",
      "Ep 27: Batch #51 - Loss: 1.0262422561645508\n",
      "Ep 27: Batch #52 - Loss: 0.813364565372467\n",
      "Ep 27: Batch #53 - Loss: 0.8463569283485413\n",
      "Ep 27: Batch #54 - Loss: 0.7239810824394226\n",
      "Ep 27: Batch #55 - Loss: 0.7769067883491516\n",
      "Ep 27: Batch #56 - Loss: 1.292447805404663\n",
      "Ep 27: Batch #57 - Loss: 0.87651526927948\n",
      "Ep 27: Batch #58 - Loss: 1.0309208631515503\n",
      "Ep 27: Batch #59 - Loss: 0.6994256973266602\n",
      "Ep 27: Batch #60 - Loss: 1.3380686044692993\n",
      "Ep 27: Batch #61 - Loss: 0.6559202671051025\n",
      "Ep 27: Batch #62 - Loss: 0.7471224665641785\n",
      "Ep 27: Batch #63 - Loss: 1.0322530269622803\n",
      "Ep 27: Batch #64 - Loss: 9.456388473510742\n",
      "Ep 27: Batch #65 - Loss: 0.6296859383583069\n",
      "Ep 27: Batch #66 - Loss: 0.8259526491165161\n",
      "Ep 27: Batch #67 - Loss: 0.9341529607772827\n",
      "Ep 27: Batch #68 - Loss: 0.9353699684143066\n",
      "Ep 27: Batch #69 - Loss: 0.7684112191200256\n",
      "Ep 27: Batch #70 - Loss: 0.8055184483528137\n",
      "Ep 27: Batch #71 - Loss: 0.7000460028648376\n",
      "Ep 27: Batch #72 - Loss: 0.8795342445373535\n",
      "Ep 27: Batch #73 - Loss: 0.9343472719192505\n",
      "Ep 27: Batch #74 - Loss: 0.7650030851364136\n",
      "Ep 27: Batch #75 - Loss: 0.7894247174263\n",
      "Ep 27: Batch #76 - Loss: 1.1172704696655273\n",
      "Ep 27: Batch #77 - Loss: 0.7570589780807495\n",
      "Ep 27: Batch #78 - Loss: 1.1914150714874268\n",
      "Ep 27: Batch #79 - Loss: 0.6466531753540039\n",
      "Ep 27: Batch #80 - Loss: 0.8871963024139404\n",
      "Ep 27: Batch #81 - Loss: 1.7077839374542236\n",
      "Ep 27: Batch #82 - Loss: 0.8972343802452087\n",
      "Ep 27: Batch #83 - Loss: 1.7537144422531128\n",
      "Ep 27: Batch #84 - Loss: 0.7380645275115967\n",
      "Ep 27: Batch #85 - Loss: 0.9956312775611877\n",
      "Ep 27: Batch #86 - Loss: 0.734013020992279\n",
      "Ep 27: Batch #87 - Loss: 0.7340641021728516\n",
      "Ep 27: Batch #88 - Loss: 0.8277820944786072\n",
      "Ep 27: Batch #89 - Loss: 0.8994957804679871\n",
      "Ep 27: Batch #90 - Loss: 1.1912931203842163\n",
      "Ep 27: Batch #91 - Loss: 0.8287760019302368\n",
      "Ep 27: Batch #92 - Loss: 1.0581426620483398\n",
      "Ep 27: Batch #93 - Loss: 1.0628769397735596\n",
      "Ep 27: Batch #94 - Loss: 1.0788955688476562\n",
      "Ep 27: Batch #95 - Loss: 0.9461424350738525\n",
      "Ep 27: Batch #96 - Loss: 0.9293544292449951\n",
      "Ep 27: Batch #97 - Loss: 0.75281822681427\n",
      "Ep 27: Batch #98 - Loss: 0.7626913785934448\n",
      "Ep 27: Batch #99 - Loss: 0.9814096093177795\n",
      "Ep 27: Batch #100 - Loss: 0.7006453275680542\n",
      "Ep 27: Batch #101 - Loss: 1.0728062391281128\n",
      "Ep 27: Batch #102 - Loss: 0.8039607405662537\n",
      "Ep 27: Batch #103 - Loss: 0.8116195201873779\n",
      "Ep 27: Batch #104 - Loss: 0.8246189951896667\n",
      "Ep 27: Batch #105 - Loss: 1.056203842163086\n",
      "Ep 27: Batch #106 - Loss: 0.7815669178962708\n",
      "Ep 27: Batch #107 - Loss: 0.7825086116790771\n",
      "Ep 27: Batch #108 - Loss: 1.0626591444015503\n",
      "Ep 27: Batch #109 - Loss: 0.7829655408859253\n",
      "Ep 27: Batch #110 - Loss: 0.9487553834915161\n",
      "Ep 27: Batch #111 - Loss: 1.4096890687942505\n",
      "Ep 27: Batch #112 - Loss: 1.0780466794967651\n",
      "Ep 27: Batch #113 - Loss: 0.8405935764312744\n",
      "Ep 27: Batch #114 - Loss: 0.9298837780952454\n",
      "Ep 27: Batch #115 - Loss: 1.1204801797866821\n",
      "Ep 27: Batch #116 - Loss: 0.64771568775177\n",
      "Ep 27: Batch #117 - Loss: 0.8946207165718079\n",
      "Ep 27: Batch #118 - Loss: 0.5641295909881592\n",
      "Model saved in file: ./weights_autoencoder_low_LR/model_e27b118_1516651272.2991207.ckpt\n",
      "Ep 27: Batch #119 - Loss: 1.052891492843628\n",
      "Ep 27: Batch #120 - Loss: 0.8192537426948547\n",
      "Ep 27: Batch #121 - Loss: 0.7079737782478333\n",
      "Ep 27: Batch #122 - Loss: 0.8491382598876953\n",
      "Ep 27: Batch #123 - Loss: 0.8544101119041443\n",
      "Ep 27: Batch #124 - Loss: 0.6802629828453064\n",
      "Ep 27: Batch #125 - Loss: 2.748488426208496\n",
      "Ep 27: Batch #126 - Loss: 1.2533159255981445\n",
      "Ep 27: Batch #127 - Loss: 0.7762030363082886\n",
      "Ep 27: Batch #128 - Loss: 1.1400915384292603\n",
      "Ep 27: Batch #129 - Loss: 0.8645742535591125\n",
      "Ep 27: Batch #130 - Loss: 0.7467067241668701\n",
      "Ep 27: Batch #131 - Loss: 1.02826726436615\n",
      "Ep 27: Batch #132 - Loss: 0.85039222240448\n",
      "Ep 27: Batch #133 - Loss: 0.8412510752677917\n",
      "Ep 27: Batch #134 - Loss: 0.7932713031768799\n",
      "Ep 27: Batch #135 - Loss: 0.9948515295982361\n",
      "Ep 27: Batch #136 - Loss: 1.2147252559661865\n",
      "Ep 27: Batch #137 - Loss: 0.9923902750015259\n",
      "Ep 27: Batch #138 - Loss: 1.0972723960876465\n",
      "Ep 27: Batch #139 - Loss: 0.9267095923423767\n",
      "Ep 27: Batch #140 - Loss: 1.075402855873108\n",
      "Ep 27: Batch #141 - Loss: 1.385621190071106\n",
      "Ep 27: Batch #142 - Loss: 0.8169692754745483\n",
      "Ep 27: Batch #143 - Loss: 0.996903657913208\n",
      "Ep 27: Batch #144 - Loss: 0.74315345287323\n",
      "Ep 27: Batch #145 - Loss: 0.698029637336731\n",
      "Ep 27: Batch #146 - Loss: 0.9061234593391418\n",
      "Ep 27: Batch #147 - Loss: 0.8922463059425354\n",
      "Ep 27: Batch #148 - Loss: 1.0062452554702759\n",
      "Ep 27: Batch #149 - Loss: 0.8822043538093567\n",
      "Ep 27: Batch #150 - Loss: 0.9059908390045166\n",
      "Ep 27: Batch #151 - Loss: 0.7434119582176208\n",
      "Ep 27: Batch #152 - Loss: 0.7570802569389343\n",
      "Ep 27: Batch #153 - Loss: 1.1340429782867432\n",
      "Ep 27: Batch #154 - Loss: 0.7839917540550232\n",
      "Ep 27: Batch #155 - Loss: 0.8590648770332336\n",
      "Ep 27: Batch #156 - Loss: 1.0451067686080933\n",
      "Ep 27: Batch #157 - Loss: 0.7838581204414368\n",
      "Ep 27: Batch #158 - Loss: 0.8231363296508789\n",
      "Ep 27: Batch #159 - Loss: 0.832892656326294\n",
      "Ep 27: Batch #160 - Loss: 0.924847424030304\n",
      "Ep 27: Batch #161 - Loss: 0.8394805192947388\n",
      "Ep 27: Batch #162 - Loss: 0.9577619433403015\n",
      "Ep 27: Batch #163 - Loss: 0.9497036337852478\n",
      "Ep 27: Batch #164 - Loss: 0.8070204854011536\n",
      "Ep 27: Batch #165 - Loss: 1.5214383602142334\n",
      "Ep 27: Batch #166 - Loss: 0.703119695186615\n",
      "Ep 27: Batch #167 - Loss: 1.1120219230651855\n",
      "Ep 27: Batch #168 - Loss: 0.8866790533065796\n",
      "Ep 27: Batch #169 - Loss: 0.824282705783844\n",
      "Ep 27: Batch #170 - Loss: 0.8278594613075256\n",
      "Ep 27: Batch #171 - Loss: 0.8064923882484436\n",
      "Ep 27: Batch #172 - Loss: 0.651008665561676\n",
      "Ep 27: Batch #173 - Loss: 1.2310466766357422\n",
      "Ep 27: Batch #174 - Loss: 0.5970309972763062\n",
      "Ep 27: Batch #175 - Loss: 0.7982775568962097\n",
      "Ep 27: Batch #176 - Loss: 1.183808445930481\n",
      "Ep 27: Batch #177 - Loss: 0.8727105855941772\n",
      "Ep 27: Batch #178 - Loss: 0.7884313464164734\n",
      "Ep 27: Batch #179 - Loss: 0.9691534042358398\n",
      "Ep 27: Batch #180 - Loss: 0.8860474228858948\n",
      "Ep 27: Batch #181 - Loss: 1.023708462715149\n",
      "Ep 27: Batch #182 - Loss: 0.7838717699050903\n",
      "Ep 27: Batch #183 - Loss: 0.7890577912330627\n",
      "Ep 27: Batch #184 - Loss: 1.0889075994491577\n",
      "Ep 27: Batch #185 - Loss: 0.778887927532196\n",
      "Ep 27: Batch #186 - Loss: 0.9986640214920044\n",
      "Ep 27: Batch #187 - Loss: 1.1913717985153198\n",
      "Ep 27: Batch #188 - Loss: 1.3727097511291504\n",
      "Ep 27: Batch #189 - Loss: 0.7181413173675537\n",
      "Ep 27: Batch #190 - Loss: 0.756420910358429\n",
      "Ep 27: Batch #191 - Loss: 1.0892542600631714\n",
      "Ep 27: Batch #192 - Loss: 0.6862008571624756\n",
      "Ep 27: Batch #193 - Loss: 0.7648080587387085\n",
      "Ep 27: Batch #194 - Loss: 0.7171606421470642\n",
      "Ep 27: Batch #195 - Loss: 1.0091512203216553\n",
      "Ep 27: Batch #196 - Loss: 0.8879734873771667\n",
      "Ep 27: Batch #197 - Loss: 0.9258217215538025\n",
      "Ep 27: Batch #198 - Loss: 0.7000004649162292\n",
      "Ep 27: Batch #199 - Loss: 0.8864864110946655\n",
      "Ep 28: Batch #0 - Loss: 0.8186729550361633\n",
      "Ep 28: Batch #1 - Loss: 0.901159405708313\n",
      "Ep 28: Batch #2 - Loss: 1.028842806816101\n",
      "Ep 28: Batch #3 - Loss: 0.8867986798286438\n",
      "Ep 28: Batch #4 - Loss: 0.8133689761161804\n",
      "Ep 28: Batch #5 - Loss: 0.6842612624168396\n",
      "Ep 28: Batch #6 - Loss: 0.9012740850448608\n",
      "Ep 28: Batch #7 - Loss: 0.7204114198684692\n",
      "Ep 28: Batch #8 - Loss: 0.7528812289237976\n",
      "Ep 28: Batch #9 - Loss: 1.4342143535614014\n",
      "Ep 28: Batch #10 - Loss: 1.0325391292572021\n",
      "Ep 28: Batch #11 - Loss: 0.6897311806678772\n",
      "Ep 28: Batch #12 - Loss: 1.5820934772491455\n",
      "Ep 28: Batch #13 - Loss: 0.6623840928077698\n",
      "Ep 28: Batch #14 - Loss: 0.7454463839530945\n",
      "Ep 28: Batch #15 - Loss: 1.2680672407150269\n",
      "Ep 28: Batch #16 - Loss: 1.3109610080718994\n",
      "Ep 28: Batch #17 - Loss: 0.904980480670929\n",
      "Ep 28: Batch #18 - Loss: 0.9592182636260986\n",
      "Ep 28: Batch #19 - Loss: 0.6856005787849426\n",
      "Ep 28: Batch #20 - Loss: 0.6743171811103821\n",
      "Ep 28: Batch #21 - Loss: 1.235914945602417\n",
      "Ep 28: Batch #22 - Loss: 0.7436829209327698\n",
      "Ep 28: Batch #23 - Loss: 0.7672380805015564\n",
      "Ep 28: Batch #24 - Loss: 0.8426982164382935\n",
      "Ep 28: Batch #25 - Loss: 0.7377699613571167\n",
      "Ep 28: Batch #26 - Loss: 0.7550825476646423\n",
      "Ep 28: Batch #27 - Loss: 1.3821805715560913\n",
      "Ep 28: Batch #28 - Loss: 0.8898720741271973\n",
      "Ep 28: Batch #29 - Loss: 0.9198749661445618\n",
      "Ep 28: Batch #30 - Loss: 1.2266466617584229\n",
      "Ep 28: Batch #31 - Loss: 0.6886485815048218\n",
      "Ep 28: Batch #32 - Loss: 0.7697020769119263\n",
      "Ep 28: Batch #33 - Loss: 0.8260242938995361\n",
      "Ep 28: Batch #34 - Loss: 0.8048772811889648\n",
      "Ep 28: Batch #35 - Loss: 0.9782618880271912\n",
      "Ep 28: Batch #36 - Loss: 0.7221328616142273\n",
      "Ep 28: Batch #37 - Loss: 1.1637089252471924\n",
      "Ep 28: Batch #38 - Loss: 0.7702365517616272\n",
      "Ep 28: Batch #39 - Loss: 0.8372429609298706\n",
      "Ep 28: Batch #40 - Loss: 0.7969762682914734\n",
      "Ep 28: Batch #41 - Loss: 0.7605797052383423\n",
      "Ep 28: Batch #42 - Loss: 0.7410677671432495\n",
      "Ep 28: Batch #43 - Loss: 0.8086273074150085\n",
      "Ep 28: Batch #44 - Loss: 0.8063938021659851\n",
      "Ep 28: Batch #45 - Loss: 0.6569086909294128\n",
      "Ep 28: Batch #46 - Loss: 0.8548331260681152\n",
      "Ep 28: Batch #47 - Loss: 0.9915514588356018\n",
      "Ep 28: Batch #48 - Loss: 1.384807825088501\n",
      "Ep 28: Batch #49 - Loss: 1.0411787033081055\n",
      "Ep 28: Batch #50 - Loss: 0.7212225794792175\n",
      "Ep 28: Batch #51 - Loss: 1.0243639945983887\n",
      "Ep 28: Batch #52 - Loss: 0.8122095465660095\n",
      "Ep 28: Batch #53 - Loss: 0.8448675274848938\n",
      "Ep 28: Batch #54 - Loss: 0.7228273153305054\n",
      "Ep 28: Batch #55 - Loss: 0.7752986550331116\n",
      "Ep 28: Batch #56 - Loss: 1.2906792163848877\n",
      "Ep 28: Batch #57 - Loss: 0.8746356964111328\n",
      "Ep 28: Batch #58 - Loss: 1.0290342569351196\n",
      "Ep 28: Batch #59 - Loss: 0.6981832981109619\n",
      "Ep 28: Batch #60 - Loss: 1.3362056016921997\n",
      "Ep 28: Batch #61 - Loss: 0.6546126008033752\n",
      "Ep 28: Batch #62 - Loss: 0.7456002831459045\n",
      "Ep 28: Batch #63 - Loss: 1.0303066968917847\n",
      "Ep 28: Batch #64 - Loss: 9.455116271972656\n",
      "Ep 28: Batch #65 - Loss: 0.6285667419433594\n",
      "Ep 28: Batch #66 - Loss: 0.8241087198257446\n",
      "Ep 28: Batch #67 - Loss: 0.9326267838478088\n",
      "Ep 28: Batch #68 - Loss: 0.9337476491928101\n",
      "Ep 28: Batch #69 - Loss: 0.7669121623039246\n",
      "Ep 28: Batch #70 - Loss: 0.8036450147628784\n",
      "Ep 28: Batch #71 - Loss: 0.6987180113792419\n",
      "Ep 28: Batch #72 - Loss: 0.8779738545417786\n",
      "Ep 28: Batch #73 - Loss: 0.9325804710388184\n",
      "Ep 28: Batch #74 - Loss: 0.7635676264762878\n",
      "Ep 28: Batch #75 - Loss: 0.7880350351333618\n",
      "Ep 28: Batch #76 - Loss: 1.1158770322799683\n",
      "Ep 28: Batch #77 - Loss: 0.7556872367858887\n",
      "Ep 28: Batch #78 - Loss: 1.1893882751464844\n",
      "Ep 28: Batch #79 - Loss: 0.6452796459197998\n",
      "Ep 28: Batch #80 - Loss: 0.8854150176048279\n",
      "Ep 28: Batch #81 - Loss: 1.7060679197311401\n",
      "Ep 28: Batch #82 - Loss: 0.8956327438354492\n",
      "Ep 28: Batch #83 - Loss: 1.75247323513031\n",
      "Ep 28: Batch #84 - Loss: 0.7365703582763672\n",
      "Ep 28: Batch #85 - Loss: 0.9941262006759644\n",
      "Ep 28: Batch #86 - Loss: 0.7324174046516418\n",
      "Ep 28: Batch #87 - Loss: 0.7327596545219421\n",
      "Ep 28: Batch #88 - Loss: 0.8261644840240479\n",
      "Ep 28: Batch #89 - Loss: 0.8984466195106506\n",
      "Ep 28: Batch #90 - Loss: 1.188938021659851\n",
      "Ep 28: Batch #91 - Loss: 0.8271039128303528\n",
      "Ep 28: Batch #92 - Loss: 1.0562747716903687\n",
      "Ep 28: Batch #93 - Loss: 1.0608189105987549\n",
      "Ep 28: Batch #94 - Loss: 1.077082872390747\n",
      "Ep 28: Batch #95 - Loss: 0.9444046020507812\n",
      "Ep 28: Batch #96 - Loss: 0.9279056787490845\n",
      "Ep 28: Batch #97 - Loss: 0.7513400912284851\n",
      "Ep 28: Batch #98 - Loss: 0.7611036896705627\n",
      "Ep 28: Batch #99 - Loss: 0.9799508452415466\n",
      "Ep 28: Batch #100 - Loss: 0.6991638541221619\n",
      "Ep 28: Batch #101 - Loss: 1.071144938468933\n",
      "Ep 28: Batch #102 - Loss: 0.8025773167610168\n",
      "Ep 28: Batch #103 - Loss: 0.8103607892990112\n",
      "Ep 28: Batch #104 - Loss: 0.8230875730514526\n",
      "Ep 28: Batch #105 - Loss: 1.054542064666748\n",
      "Ep 28: Batch #106 - Loss: 0.7801595330238342\n",
      "Ep 28: Batch #107 - Loss: 0.7808886170387268\n",
      "Ep 28: Batch #108 - Loss: 1.0608103275299072\n",
      "Ep 28: Batch #109 - Loss: 0.7816867232322693\n",
      "Ep 28: Batch #110 - Loss: 0.9469378590583801\n",
      "Ep 28: Batch #111 - Loss: 1.4078428745269775\n",
      "Ep 28: Batch #112 - Loss: 1.0760352611541748\n",
      "Ep 28: Batch #113 - Loss: 0.8390274047851562\n",
      "Ep 28: Batch #114 - Loss: 0.9282457232475281\n",
      "Ep 28: Batch #115 - Loss: 1.1189322471618652\n",
      "Ep 28: Batch #116 - Loss: 0.6467517018318176\n",
      "Ep 28: Batch #117 - Loss: 0.893202006816864\n",
      "Ep 28: Batch #118 - Loss: 0.5627885460853577\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved in file: ./weights_autoencoder_low_LR/model_e28b118_1516651272.4340496.ckpt\n",
      "Ep 28: Batch #119 - Loss: 1.05122709274292\n",
      "Ep 28: Batch #120 - Loss: 0.8181096315383911\n",
      "Ep 28: Batch #121 - Loss: 0.7065775990486145\n",
      "Ep 28: Batch #122 - Loss: 0.8475645780563354\n",
      "Ep 28: Batch #123 - Loss: 0.8530004024505615\n",
      "Ep 28: Batch #124 - Loss: 0.6791372895240784\n",
      "Ep 28: Batch #125 - Loss: 2.7465832233428955\n",
      "Ep 28: Batch #126 - Loss: 1.251489281654358\n",
      "Ep 28: Batch #127 - Loss: 0.7744764089584351\n",
      "Ep 28: Batch #128 - Loss: 1.138031244277954\n",
      "Ep 28: Batch #129 - Loss: 0.8629253506660461\n",
      "Ep 28: Batch #130 - Loss: 0.7451730966567993\n",
      "Ep 28: Batch #131 - Loss: 1.0261924266815186\n",
      "Ep 28: Batch #132 - Loss: 0.8486455678939819\n",
      "Ep 28: Batch #133 - Loss: 0.8397694826126099\n",
      "Ep 28: Batch #134 - Loss: 0.7916990518569946\n",
      "Ep 28: Batch #135 - Loss: 0.9930785894393921\n",
      "Ep 28: Batch #136 - Loss: 1.212619423866272\n",
      "Ep 28: Batch #137 - Loss: 0.9906681776046753\n",
      "Ep 28: Batch #138 - Loss: 1.0956387519836426\n",
      "Ep 28: Batch #139 - Loss: 0.9249886870384216\n",
      "Ep 28: Batch #140 - Loss: 1.0737568140029907\n",
      "Ep 28: Batch #141 - Loss: 1.383905291557312\n",
      "Ep 28: Batch #142 - Loss: 0.8156307339668274\n",
      "Ep 28: Batch #143 - Loss: 0.9948858022689819\n",
      "Ep 28: Batch #144 - Loss: 0.7416346669197083\n",
      "Ep 28: Batch #145 - Loss: 0.6967878937721252\n",
      "Ep 28: Batch #146 - Loss: 0.9047697186470032\n",
      "Ep 28: Batch #147 - Loss: 0.8903342485427856\n",
      "Ep 28: Batch #148 - Loss: 1.00446617603302\n",
      "Ep 28: Batch #149 - Loss: 0.8804565668106079\n",
      "Ep 28: Batch #150 - Loss: 0.9045997858047485\n",
      "Ep 28: Batch #151 - Loss: 0.7423225045204163\n",
      "Ep 28: Batch #152 - Loss: 0.7558826804161072\n",
      "Ep 28: Batch #153 - Loss: 1.1322873830795288\n",
      "Ep 28: Batch #154 - Loss: 0.7827597260475159\n",
      "Ep 28: Batch #155 - Loss: 0.8573287725448608\n",
      "Ep 28: Batch #156 - Loss: 1.04338538646698\n",
      "Ep 28: Batch #157 - Loss: 0.7825050354003906\n",
      "Ep 28: Batch #158 - Loss: 0.821943461894989\n",
      "Ep 28: Batch #159 - Loss: 0.8313584327697754\n",
      "Ep 28: Batch #160 - Loss: 0.923503041267395\n",
      "Ep 28: Batch #161 - Loss: 0.8380180597305298\n",
      "Ep 28: Batch #162 - Loss: 0.9561564326286316\n",
      "Ep 28: Batch #163 - Loss: 0.9484042525291443\n",
      "Ep 28: Batch #164 - Loss: 0.8056649565696716\n",
      "Ep 28: Batch #165 - Loss: 1.5200377702713013\n",
      "Ep 28: Batch #166 - Loss: 0.7015799880027771\n",
      "Ep 28: Batch #167 - Loss: 1.1104665994644165\n",
      "Ep 28: Batch #168 - Loss: 0.8850302696228027\n",
      "Ep 28: Batch #169 - Loss: 0.8228205442428589\n",
      "Ep 28: Batch #170 - Loss: 0.8264238834381104\n",
      "Ep 28: Batch #171 - Loss: 0.8048715591430664\n",
      "Ep 28: Batch #172 - Loss: 0.6499006748199463\n",
      "Ep 28: Batch #173 - Loss: 1.2289752960205078\n",
      "Ep 28: Batch #174 - Loss: 0.5958007574081421\n",
      "Ep 28: Batch #175 - Loss: 0.7970077991485596\n",
      "Ep 28: Batch #176 - Loss: 1.1823362112045288\n",
      "Ep 28: Batch #177 - Loss: 0.8711926937103271\n",
      "Ep 28: Batch #178 - Loss: 0.7868009209632874\n",
      "Ep 28: Batch #179 - Loss: 0.9673426747322083\n",
      "Ep 28: Batch #180 - Loss: 0.8840891122817993\n",
      "Ep 28: Batch #181 - Loss: 1.021748423576355\n",
      "Ep 28: Batch #182 - Loss: 0.7826035022735596\n",
      "Ep 28: Batch #183 - Loss: 0.7875190377235413\n",
      "Ep 28: Batch #184 - Loss: 1.087542176246643\n",
      "Ep 28: Batch #185 - Loss: 0.777595043182373\n",
      "Ep 28: Batch #186 - Loss: 0.9967987537384033\n",
      "Ep 28: Batch #187 - Loss: 1.1897730827331543\n",
      "Ep 28: Batch #188 - Loss: 1.3710087537765503\n",
      "Ep 28: Batch #189 - Loss: 0.7170871496200562\n",
      "Ep 28: Batch #190 - Loss: 0.7550061345100403\n",
      "Ep 28: Batch #191 - Loss: 1.0878345966339111\n",
      "Ep 28: Batch #192 - Loss: 0.6851433515548706\n",
      "Ep 28: Batch #193 - Loss: 0.7633635997772217\n",
      "Ep 28: Batch #194 - Loss: 0.7158089876174927\n",
      "Ep 28: Batch #195 - Loss: 1.0075269937515259\n",
      "Ep 28: Batch #196 - Loss: 0.8865402936935425\n",
      "Ep 28: Batch #197 - Loss: 0.924377977848053\n",
      "Ep 28: Batch #198 - Loss: 0.6986188888549805\n",
      "Ep 28: Batch #199 - Loss: 0.8849355578422546\n",
      "Ep 29: Batch #0 - Loss: 0.8169611692428589\n",
      "Ep 29: Batch #1 - Loss: 0.8995248079299927\n",
      "Ep 29: Batch #2 - Loss: 1.027665376663208\n",
      "Ep 29: Batch #3 - Loss: 0.8852927088737488\n",
      "Ep 29: Batch #4 - Loss: 0.8117977976799011\n",
      "Ep 29: Batch #5 - Loss: 0.6832258701324463\n",
      "Ep 29: Batch #6 - Loss: 0.8997824192047119\n",
      "Ep 29: Batch #7 - Loss: 0.7192118167877197\n",
      "Ep 29: Batch #8 - Loss: 0.7516107559204102\n",
      "Ep 29: Batch #9 - Loss: 1.4321774244308472\n",
      "Ep 29: Batch #10 - Loss: 1.0307681560516357\n",
      "Ep 29: Batch #11 - Loss: 0.6883883476257324\n",
      "Ep 29: Batch #12 - Loss: 1.5807420015335083\n",
      "Ep 29: Batch #13 - Loss: 0.6614350080490112\n",
      "Ep 29: Batch #14 - Loss: 0.7442882657051086\n",
      "Ep 29: Batch #15 - Loss: 1.2661799192428589\n",
      "Ep 29: Batch #16 - Loss: 1.308681607246399\n",
      "Ep 29: Batch #17 - Loss: 0.9034024477005005\n",
      "Ep 29: Batch #18 - Loss: 0.9582440853118896\n",
      "Ep 29: Batch #19 - Loss: 0.6844555139541626\n",
      "Ep 29: Batch #20 - Loss: 0.6730186939239502\n",
      "Ep 29: Batch #21 - Loss: 1.2343626022338867\n",
      "Ep 29: Batch #22 - Loss: 0.7425261735916138\n",
      "Ep 29: Batch #23 - Loss: 0.7655718922615051\n",
      "Ep 29: Batch #24 - Loss: 0.8414321541786194\n",
      "Ep 29: Batch #25 - Loss: 0.736228883266449\n",
      "Ep 29: Batch #26 - Loss: 0.7535034418106079\n",
      "Ep 29: Batch #27 - Loss: 1.3803250789642334\n",
      "Ep 29: Batch #28 - Loss: 0.888446033000946\n",
      "Ep 29: Batch #29 - Loss: 0.9180636405944824\n",
      "Ep 29: Batch #30 - Loss: 1.224924087524414\n",
      "Ep 29: Batch #31 - Loss: 0.6875970363616943\n",
      "Ep 29: Batch #32 - Loss: 0.7682370543479919\n",
      "Ep 29: Batch #33 - Loss: 0.8247197866439819\n",
      "Ep 29: Batch #34 - Loss: 0.8034540414810181\n",
      "Ep 29: Batch #35 - Loss: 0.976375162601471\n",
      "Ep 29: Batch #36 - Loss: 0.7209048867225647\n",
      "Ep 29: Batch #37 - Loss: 1.1622371673583984\n",
      "Ep 29: Batch #38 - Loss: 0.7685896754264832\n",
      "Ep 29: Batch #39 - Loss: 0.8360931873321533\n",
      "Ep 29: Batch #40 - Loss: 0.7954590916633606\n",
      "Ep 29: Batch #41 - Loss: 0.7591805458068848\n",
      "Ep 29: Batch #42 - Loss: 0.7399191856384277\n",
      "Ep 29: Batch #43 - Loss: 0.8072524070739746\n",
      "Ep 29: Batch #44 - Loss: 0.8050025105476379\n",
      "Ep 29: Batch #45 - Loss: 0.6553021669387817\n",
      "Ep 29: Batch #46 - Loss: 0.8532454967498779\n",
      "Ep 29: Batch #47 - Loss: 0.9895445704460144\n",
      "Ep 29: Batch #48 - Loss: 1.3826913833618164\n",
      "Ep 29: Batch #49 - Loss: 1.0396822690963745\n",
      "Ep 29: Batch #50 - Loss: 0.7202351093292236\n",
      "Ep 29: Batch #51 - Loss: 1.0225120782852173\n",
      "Ep 29: Batch #52 - Loss: 0.8110755681991577\n",
      "Ep 29: Batch #53 - Loss: 0.8434060215950012\n",
      "Ep 29: Batch #54 - Loss: 0.7216927409172058\n",
      "Ep 29: Batch #55 - Loss: 0.7737065553665161\n",
      "Ep 29: Batch #56 - Loss: 1.2889398336410522\n",
      "Ep 29: Batch #57 - Loss: 0.8727811574935913\n",
      "Ep 29: Batch #58 - Loss: 1.0271737575531006\n",
      "Ep 29: Batch #59 - Loss: 0.6969665288925171\n",
      "Ep 29: Batch #60 - Loss: 1.3343889713287354\n",
      "Ep 29: Batch #61 - Loss: 0.6533283591270447\n",
      "Ep 29: Batch #62 - Loss: 0.7441052794456482\n",
      "Ep 29: Batch #63 - Loss: 1.0283914804458618\n",
      "Ep 29: Batch #64 - Loss: 9.453673362731934\n",
      "Ep 29: Batch #65 - Loss: 0.6274657249450684\n",
      "Ep 29: Batch #66 - Loss: 0.8222865462303162\n",
      "Ep 29: Batch #67 - Loss: 0.9311283826828003\n",
      "Ep 29: Batch #68 - Loss: 0.9321286082267761\n",
      "Ep 29: Batch #69 - Loss: 0.7654380202293396\n",
      "Ep 29: Batch #70 - Loss: 0.8018070459365845\n",
      "Ep 29: Batch #71 - Loss: 0.6974100470542908\n",
      "Ep 29: Batch #72 - Loss: 0.8764201998710632\n",
      "Ep 29: Batch #73 - Loss: 0.930803120136261\n",
      "Ep 29: Batch #74 - Loss: 0.7621099948883057\n",
      "Ep 29: Batch #75 - Loss: 0.7866743206977844\n",
      "Ep 29: Batch #76 - Loss: 1.1145024299621582\n",
      "Ep 29: Batch #77 - Loss: 0.7543275952339172\n",
      "Ep 29: Batch #78 - Loss: 1.1874130964279175\n",
      "Ep 29: Batch #79 - Loss: 0.6439322829246521\n",
      "Ep 29: Batch #80 - Loss: 0.8836735486984253\n",
      "Ep 29: Batch #81 - Loss: 1.704280972480774\n",
      "Ep 29: Batch #82 - Loss: 0.8940576314926147\n",
      "Ep 29: Batch #83 - Loss: 1.7512617111206055\n",
      "Ep 29: Batch #84 - Loss: 0.735095202922821\n",
      "Ep 29: Batch #85 - Loss: 0.9926625490188599\n",
      "Ep 29: Batch #86 - Loss: 0.7308524250984192\n",
      "Ep 29: Batch #87 - Loss: 0.7314671874046326\n",
      "Ep 29: Batch #88 - Loss: 0.8245537877082825\n",
      "Ep 29: Batch #89 - Loss: 0.8974200487136841\n",
      "Ep 29: Batch #90 - Loss: 1.186592698097229\n",
      "Ep 29: Batch #91 - Loss: 0.8254573941230774\n",
      "Ep 29: Batch #92 - Loss: 1.054408073425293\n",
      "Ep 29: Batch #93 - Loss: 1.05877685546875\n",
      "Ep 29: Batch #94 - Loss: 1.0752911567687988\n",
      "Ep 29: Batch #95 - Loss: 0.9427061676979065\n",
      "Ep 29: Batch #96 - Loss: 0.9264631271362305\n",
      "Ep 29: Batch #97 - Loss: 0.7498732209205627\n",
      "Ep 29: Batch #98 - Loss: 0.759544849395752\n",
      "Ep 29: Batch #99 - Loss: 0.9785048961639404\n",
      "Ep 29: Batch #100 - Loss: 0.6977201700210571\n",
      "Ep 29: Batch #101 - Loss: 1.0695184469223022\n",
      "Ep 29: Batch #102 - Loss: 0.8012263774871826\n",
      "Ep 29: Batch #103 - Loss: 0.8090947866439819\n",
      "Ep 29: Batch #104 - Loss: 0.8215779066085815\n",
      "Ep 29: Batch #105 - Loss: 1.0528935194015503\n",
      "Ep 29: Batch #106 - Loss: 0.7787688970565796\n",
      "Ep 29: Batch #107 - Loss: 0.7793022394180298\n",
      "Ep 29: Batch #108 - Loss: 1.0589927434921265\n",
      "Ep 29: Batch #109 - Loss: 0.7804171442985535\n",
      "Ep 29: Batch #110 - Loss: 0.9451348781585693\n",
      "Ep 29: Batch #111 - Loss: 1.4059922695159912\n",
      "Ep 29: Batch #112 - Loss: 1.0740392208099365\n",
      "Ep 29: Batch #113 - Loss: 0.8374808430671692\n",
      "Ep 29: Batch #114 - Loss: 0.9266245365142822\n",
      "Ep 29: Batch #115 - Loss: 1.1174018383026123\n",
      "Ep 29: Batch #116 - Loss: 0.6457954049110413\n",
      "Ep 29: Batch #117 - Loss: 0.8918099999427795\n",
      "Ep 29: Batch #118 - Loss: 0.5614742040634155\n",
      "Model saved in file: ./weights_autoencoder_low_LR/model_e29b118_1516651272.5707686.ckpt\n",
      "Ep 29: Batch #119 - Loss: 1.0495764017105103\n",
      "Ep 29: Batch #120 - Loss: 0.816963255405426\n",
      "Ep 29: Batch #121 - Loss: 0.7052046060562134\n",
      "Ep 29: Batch #122 - Loss: 0.8460225462913513\n",
      "Ep 29: Batch #123 - Loss: 0.8516115546226501\n",
      "Ep 29: Batch #124 - Loss: 0.678039014339447\n",
      "Ep 29: Batch #125 - Loss: 2.7447032928466797\n",
      "Ep 29: Batch #126 - Loss: 1.2496750354766846\n",
      "Ep 29: Batch #127 - Loss: 0.7727687358856201\n",
      "Ep 29: Batch #128 - Loss: 1.1359899044036865\n",
      "Ep 29: Batch #129 - Loss: 0.8613089919090271\n",
      "Ep 29: Batch #130 - Loss: 0.7436676025390625\n",
      "Ep 29: Batch #131 - Loss: 1.0241421461105347\n",
      "Ep 29: Batch #132 - Loss: 0.8469310998916626\n",
      "Ep 29: Batch #133 - Loss: 0.8383126854896545\n",
      "Ep 29: Batch #134 - Loss: 0.7901470065116882\n",
      "Ep 29: Batch #135 - Loss: 0.9913389682769775\n",
      "Ep 29: Batch #136 - Loss: 1.210534691810608\n",
      "Ep 29: Batch #137 - Loss: 0.9889779090881348\n",
      "Ep 29: Batch #138 - Loss: 1.0940074920654297\n",
      "Ep 29: Batch #139 - Loss: 0.9233006238937378\n",
      "Ep 29: Batch #140 - Loss: 1.0721362829208374\n",
      "Ep 29: Batch #141 - Loss: 1.3822110891342163\n",
      "Ep 29: Batch #142 - Loss: 0.8142987489700317\n",
      "Ep 29: Batch #143 - Loss: 0.9929037094116211\n",
      "Ep 29: Batch #144 - Loss: 0.7401434779167175\n",
      "Ep 29: Batch #145 - Loss: 0.6955580711364746\n",
      "Ep 29: Batch #146 - Loss: 0.9034184217453003\n",
      "Ep 29: Batch #147 - Loss: 0.888439953327179\n",
      "Ep 29: Batch #148 - Loss: 1.0027363300323486\n",
      "Ep 29: Batch #149 - Loss: 0.8787285685539246\n",
      "Ep 29: Batch #150 - Loss: 0.9032284617424011\n",
      "Ep 29: Batch #151 - Loss: 0.7412604093551636\n",
      "Ep 29: Batch #152 - Loss: 0.7546997666358948\n",
      "Ep 29: Batch #153 - Loss: 1.130542278289795\n",
      "Ep 29: Batch #154 - Loss: 0.7815350294113159\n",
      "Ep 29: Batch #155 - Loss: 0.8556327819824219\n",
      "Ep 29: Batch #156 - Loss: 1.041685700416565\n",
      "Ep 29: Batch #157 - Loss: 0.7811678051948547\n",
      "Ep 29: Batch #158 - Loss: 0.8207705616950989\n",
      "Ep 29: Batch #159 - Loss: 0.8298447132110596\n",
      "Ep 29: Batch #160 - Loss: 0.9221810698509216\n",
      "Ep 29: Batch #161 - Loss: 0.8365752696990967\n",
      "Ep 29: Batch #162 - Loss: 0.9545677900314331\n",
      "Ep 29: Batch #163 - Loss: 0.9471206665039062\n",
      "Ep 29: Batch #164 - Loss: 0.8043266534805298\n",
      "Ep 29: Batch #165 - Loss: 1.5186684131622314\n",
      "Ep 29: Batch #166 - Loss: 0.7000683546066284\n",
      "Ep 29: Batch #167 - Loss: 1.108932375907898\n",
      "Ep 29: Batch #168 - Loss: 0.88339763879776\n",
      "Ep 29: Batch #169 - Loss: 0.8213560581207275\n",
      "Ep 29: Batch #170 - Loss: 0.8250074982643127\n",
      "Ep 29: Batch #171 - Loss: 0.8032723665237427\n",
      "Ep 29: Batch #172 - Loss: 0.6488116383552551\n",
      "Ep 29: Batch #173 - Loss: 1.2269245386123657\n",
      "Ep 29: Batch #174 - Loss: 0.5945868492126465\n",
      "Ep 29: Batch #175 - Loss: 0.7957415580749512\n",
      "Ep 29: Batch #176 - Loss: 1.1808619499206543\n",
      "Ep 29: Batch #177 - Loss: 0.8696972727775574\n",
      "Ep 29: Batch #178 - Loss: 0.785191535949707\n",
      "Ep 29: Batch #179 - Loss: 0.9655472636222839\n",
      "Ep 29: Batch #180 - Loss: 0.882152795791626\n",
      "Ep 29: Batch #181 - Loss: 1.0198004245758057\n",
      "Ep 29: Batch #182 - Loss: 0.7813580632209778\n",
      "Ep 29: Batch #183 - Loss: 0.7859960198402405\n",
      "Ep 29: Batch #184 - Loss: 1.0862056016921997\n",
      "Ep 29: Batch #185 - Loss: 0.776329755783081\n",
      "Ep 29: Batch #186 - Loss: 0.9949561953544617\n",
      "Ep 29: Batch #187 - Loss: 1.1881965398788452\n",
      "Ep 29: Batch #188 - Loss: 1.369362711906433\n",
      "Ep 29: Batch #189 - Loss: 0.7160443067550659\n",
      "Ep 29: Batch #190 - Loss: 0.7536113858222961\n",
      "Ep 29: Batch #191 - Loss: 1.086418867111206\n",
      "Ep 29: Batch #192 - Loss: 0.6841084957122803\n",
      "Ep 29: Batch #193 - Loss: 0.7619329690933228\n",
      "Ep 29: Batch #194 - Loss: 0.714484453201294\n",
      "Ep 29: Batch #195 - Loss: 1.0059036016464233\n",
      "Ep 29: Batch #196 - Loss: 0.8851263523101807\n",
      "Ep 29: Batch #197 - Loss: 0.9229415059089661\n",
      "Ep 29: Batch #198 - Loss: 0.697246789932251\n",
      "Ep 29: Batch #199 - Loss: 0.8834019303321838\n",
      "Ep 30: Batch #0 - Loss: 0.8152728080749512\n",
      "Ep 30: Batch #1 - Loss: 0.8979257345199585\n",
      "Ep 30: Batch #2 - Loss: 1.0264774560928345\n",
      "Ep 30: Batch #3 - Loss: 0.8838087320327759\n",
      "Ep 30: Batch #4 - Loss: 0.8102564215660095\n",
      "Ep 30: Batch #5 - Loss: 0.6822149753570557\n",
      "Ep 30: Batch #6 - Loss: 0.8983085751533508\n",
      "Ep 30: Batch #7 - Loss: 0.7180125117301941\n",
      "Ep 30: Batch #8 - Loss: 0.7503598928451538\n",
      "Ep 30: Batch #9 - Loss: 1.4301427602767944\n",
      "Ep 30: Batch #10 - Loss: 1.02901291847229\n",
      "Ep 30: Batch #11 - Loss: 0.6870740652084351\n",
      "Ep 30: Batch #12 - Loss: 1.579407811164856\n",
      "Ep 30: Batch #13 - Loss: 0.6605057120323181\n",
      "Ep 30: Batch #14 - Loss: 0.7431503534317017\n",
      "Ep 30: Batch #15 - Loss: 1.2643104791641235\n",
      "Ep 30: Batch #16 - Loss: 1.3064228296279907\n",
      "Ep 30: Batch #17 - Loss: 0.9018391370773315\n",
      "Ep 30: Batch #18 - Loss: 0.9572862386703491\n",
      "Ep 30: Batch #19 - Loss: 0.6833149790763855\n",
      "Ep 30: Batch #20 - Loss: 0.6717456579208374\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 30: Batch #21 - Loss: 1.2328312397003174\n",
      "Ep 30: Batch #22 - Loss: 0.7413867712020874\n",
      "Ep 30: Batch #23 - Loss: 0.7639437317848206\n",
      "Ep 30: Batch #24 - Loss: 0.8401755690574646\n",
      "Ep 30: Batch #25 - Loss: 0.7347255945205688\n",
      "Ep 30: Batch #26 - Loss: 0.7519366145133972\n",
      "Ep 30: Batch #27 - Loss: 1.3784668445587158\n",
      "Ep 30: Batch #28 - Loss: 0.887016773223877\n",
      "Ep 30: Batch #29 - Loss: 0.9162816405296326\n",
      "Ep 30: Batch #30 - Loss: 1.2232258319854736\n",
      "Ep 30: Batch #31 - Loss: 0.6865612268447876\n",
      "Ep 30: Batch #32 - Loss: 0.7667883038520813\n",
      "Ep 30: Batch #33 - Loss: 0.823448896408081\n",
      "Ep 30: Batch #34 - Loss: 0.8020460605621338\n",
      "Ep 30: Batch #35 - Loss: 0.9744994044303894\n",
      "Ep 30: Batch #36 - Loss: 0.7196887731552124\n",
      "Ep 30: Batch #37 - Loss: 1.1607694625854492\n",
      "Ep 30: Batch #38 - Loss: 0.7669585347175598\n",
      "Ep 30: Batch #39 - Loss: 0.8349505662918091\n",
      "Ep 30: Batch #40 - Loss: 0.793962299823761\n",
      "Ep 30: Batch #41 - Loss: 0.757773220539093\n",
      "Ep 30: Batch #42 - Loss: 0.7387433648109436\n",
      "Ep 30: Batch #43 - Loss: 0.805902361869812\n",
      "Ep 30: Batch #44 - Loss: 0.8036351799964905\n",
      "Ep 30: Batch #45 - Loss: 0.6537339091300964\n",
      "Ep 30: Batch #46 - Loss: 0.8516730070114136\n",
      "Ep 30: Batch #47 - Loss: 0.9875690937042236\n",
      "Ep 30: Batch #48 - Loss: 1.380604863166809\n",
      "Ep 30: Batch #49 - Loss: 1.0381726026535034\n",
      "Ep 30: Batch #50 - Loss: 0.7192552089691162\n",
      "Ep 30: Batch #51 - Loss: 1.0206788778305054\n",
      "Ep 30: Batch #52 - Loss: 0.8099569082260132\n",
      "Ep 30: Batch #53 - Loss: 0.8419672846794128\n",
      "Ep 30: Batch #54 - Loss: 0.7205805778503418\n",
      "Ep 30: Batch #55 - Loss: 0.7721322178840637\n",
      "Ep 30: Batch #56 - Loss: 1.2872158288955688\n",
      "Ep 30: Batch #57 - Loss: 0.8709527850151062\n",
      "Ep 30: Batch #58 - Loss: 1.0253171920776367\n",
      "Ep 30: Batch #59 - Loss: 0.6957738399505615\n",
      "Ep 30: Batch #60 - Loss: 1.3326127529144287\n",
      "Ep 30: Batch #61 - Loss: 0.6520748734474182\n",
      "Ep 30: Batch #62 - Loss: 0.7426306009292603\n",
      "Ep 30: Batch #63 - Loss: 1.0265146493911743\n",
      "Ep 30: Batch #64 - Loss: 9.45195198059082\n",
      "Ep 30: Batch #65 - Loss: 0.6263827085494995\n",
      "Ep 30: Batch #66 - Loss: 0.8204796314239502\n",
      "Ep 30: Batch #67 - Loss: 0.9296624660491943\n",
      "Ep 30: Batch #68 - Loss: 0.9305189251899719\n",
      "Ep 30: Batch #69 - Loss: 0.7639832496643066\n",
      "Ep 30: Batch #70 - Loss: 0.7999914884567261\n",
      "Ep 30: Batch #71 - Loss: 0.6961245536804199\n",
      "Ep 30: Batch #72 - Loss: 0.8748769760131836\n",
      "Ep 30: Batch #73 - Loss: 0.9290264844894409\n",
      "Ep 30: Batch #74 - Loss: 0.7606519460678101\n",
      "Ep 30: Batch #75 - Loss: 0.7853309512138367\n",
      "Ep 30: Batch #76 - Loss: 1.1131500005722046\n",
      "Ep 30: Batch #77 - Loss: 0.7529855966567993\n",
      "Ep 30: Batch #78 - Loss: 1.1854671239852905\n",
      "Ep 30: Batch #79 - Loss: 0.6426142454147339\n",
      "Ep 30: Batch #80 - Loss: 0.881974458694458\n",
      "Ep 30: Batch #81 - Loss: 1.7023934125900269\n",
      "Ep 30: Batch #82 - Loss: 0.892522394657135\n",
      "Ep 30: Batch #83 - Loss: 1.7500802278518677\n",
      "Ep 30: Batch #84 - Loss: 0.7336429953575134\n",
      "Ep 30: Batch #85 - Loss: 0.9912360310554504\n",
      "Ep 30: Batch #86 - Loss: 0.7293078899383545\n",
      "Ep 30: Batch #87 - Loss: 0.7301940321922302\n",
      "Ep 30: Batch #88 - Loss: 0.8229583501815796\n",
      "Ep 30: Batch #89 - Loss: 0.8964093923568726\n",
      "Ep 30: Batch #90 - Loss: 1.1842644214630127\n",
      "Ep 30: Batch #91 - Loss: 0.8238268494606018\n",
      "Ep 30: Batch #92 - Loss: 1.05256187915802\n",
      "Ep 30: Batch #93 - Loss: 1.0567564964294434\n",
      "Ep 30: Batch #94 - Loss: 1.0735186338424683\n",
      "Ep 30: Batch #95 - Loss: 0.9410399794578552\n",
      "Ep 30: Batch #96 - Loss: 0.9250314831733704\n",
      "Ep 30: Batch #97 - Loss: 0.7484255433082581\n",
      "Ep 30: Batch #98 - Loss: 0.7580177187919617\n",
      "Ep 30: Batch #99 - Loss: 0.977063000202179\n",
      "Ep 30: Batch #100 - Loss: 0.6963191628456116\n",
      "Ep 30: Batch #101 - Loss: 1.0679131746292114\n",
      "Ep 30: Batch #102 - Loss: 0.7999051213264465\n",
      "Ep 30: Batch #103 - Loss: 0.8078328371047974\n",
      "Ep 30: Batch #104 - Loss: 0.8200972080230713\n",
      "Ep 30: Batch #105 - Loss: 1.0512603521347046\n",
      "Ep 30: Batch #106 - Loss: 0.7773942947387695\n",
      "Ep 30: Batch #107 - Loss: 0.777739942073822\n",
      "Ep 30: Batch #108 - Loss: 1.0572031736373901\n",
      "Ep 30: Batch #109 - Loss: 0.7791615724563599\n",
      "Ep 30: Batch #110 - Loss: 0.943337619304657\n",
      "Ep 30: Batch #111 - Loss: 1.4041472673416138\n",
      "Ep 30: Batch #112 - Loss: 1.0720641613006592\n",
      "Ep 30: Batch #113 - Loss: 0.8359599709510803\n",
      "Ep 30: Batch #114 - Loss: 0.9250078797340393\n",
      "Ep 30: Batch #115 - Loss: 1.1159001588821411\n",
      "Ep 30: Batch #116 - Loss: 0.6448525786399841\n",
      "Ep 30: Batch #117 - Loss: 0.8904423117637634\n",
      "Ep 30: Batch #118 - Loss: 0.5601916313171387\n",
      "Model saved in file: ./weights_autoencoder_low_LR/model_e30b118_1516651272.712779.ckpt\n",
      "Ep 30: Batch #119 - Loss: 1.0479347705841064\n",
      "Ep 30: Batch #120 - Loss: 0.8158223032951355\n",
      "Ep 30: Batch #121 - Loss: 0.7038365006446838\n",
      "Ep 30: Batch #122 - Loss: 0.8444874882698059\n",
      "Ep 30: Batch #123 - Loss: 0.8502427339553833\n",
      "Ep 30: Batch #124 - Loss: 0.6769590973854065\n",
      "Ep 30: Batch #125 - Loss: 2.742854118347168\n",
      "Ep 30: Batch #126 - Loss: 1.2478827238082886\n",
      "Ep 30: Batch #127 - Loss: 0.7710695862770081\n",
      "Ep 30: Batch #128 - Loss: 1.1339129209518433\n",
      "Ep 30: Batch #129 - Loss: 0.8597096800804138\n",
      "Ep 30: Batch #130 - Loss: 0.7421767711639404\n",
      "Ep 30: Batch #131 - Loss: 1.022116780281067\n",
      "Ep 30: Batch #132 - Loss: 0.8452415466308594\n",
      "Ep 30: Batch #133 - Loss: 0.8368609547615051\n",
      "Ep 30: Batch #134 - Loss: 0.7886158227920532\n",
      "Ep 30: Batch #135 - Loss: 0.9896218776702881\n",
      "Ep 30: Batch #136 - Loss: 1.2084691524505615\n",
      "Ep 30: Batch #137 - Loss: 0.9872919917106628\n",
      "Ep 30: Batch #138 - Loss: 1.0923899412155151\n",
      "Ep 30: Batch #139 - Loss: 0.9216365218162537\n",
      "Ep 30: Batch #140 - Loss: 1.0705393552780151\n",
      "Ep 30: Batch #141 - Loss: 1.3805181980133057\n",
      "Ep 30: Batch #142 - Loss: 0.8129637241363525\n",
      "Ep 30: Batch #143 - Loss: 0.9909493327140808\n",
      "Ep 30: Batch #144 - Loss: 0.7386832237243652\n",
      "Ep 30: Batch #145 - Loss: 0.6943411231040955\n",
      "Ep 30: Batch #146 - Loss: 0.9020819067955017\n",
      "Ep 30: Batch #147 - Loss: 0.8865733742713928\n",
      "Ep 30: Batch #148 - Loss: 1.0010251998901367\n",
      "Ep 30: Batch #149 - Loss: 0.8770191073417664\n",
      "Ep 30: Batch #150 - Loss: 0.9018629789352417\n",
      "Ep 30: Batch #151 - Loss: 0.7402172088623047\n",
      "Ep 30: Batch #152 - Loss: 0.7535383701324463\n",
      "Ep 30: Batch #153 - Loss: 1.1288080215454102\n",
      "Ep 30: Batch #154 - Loss: 0.7803068161010742\n",
      "Ep 30: Batch #155 - Loss: 0.8539670705795288\n",
      "Ep 30: Batch #156 - Loss: 1.039999008178711\n",
      "Ep 30: Batch #157 - Loss: 0.779845118522644\n",
      "Ep 30: Batch #158 - Loss: 0.8196213245391846\n",
      "Ep 30: Batch #159 - Loss: 0.828353226184845\n",
      "Ep 30: Batch #160 - Loss: 0.9208526015281677\n",
      "Ep 30: Batch #161 - Loss: 0.8351345658302307\n",
      "Ep 30: Batch #162 - Loss: 0.9529929161071777\n",
      "Ep 30: Batch #163 - Loss: 0.9458502531051636\n",
      "Ep 30: Batch #164 - Loss: 0.8029981851577759\n",
      "Ep 30: Batch #165 - Loss: 1.5173261165618896\n",
      "Ep 30: Batch #166 - Loss: 0.6985830664634705\n",
      "Ep 30: Batch #167 - Loss: 1.107426404953003\n",
      "Ep 30: Batch #168 - Loss: 0.881787896156311\n",
      "Ep 30: Batch #169 - Loss: 0.8199113011360168\n",
      "Ep 30: Batch #170 - Loss: 0.8236098289489746\n",
      "Ep 30: Batch #171 - Loss: 0.8016929030418396\n",
      "Ep 30: Batch #172 - Loss: 0.6477485299110413\n",
      "Ep 30: Batch #173 - Loss: 1.2248787879943848\n",
      "Ep 30: Batch #174 - Loss: 0.5934027433395386\n",
      "Ep 30: Batch #175 - Loss: 0.7944849133491516\n",
      "Ep 30: Batch #176 - Loss: 1.17938232421875\n",
      "Ep 30: Batch #177 - Loss: 0.8682193756103516\n",
      "Ep 30: Batch #178 - Loss: 0.7836062908172607\n",
      "Ep 30: Batch #179 - Loss: 0.9637686014175415\n",
      "Ep 30: Batch #180 - Loss: 0.8802316188812256\n",
      "Ep 30: Batch #181 - Loss: 1.017852544784546\n",
      "Ep 30: Batch #182 - Loss: 0.7801329493522644\n",
      "Ep 30: Batch #183 - Loss: 0.784481942653656\n",
      "Ep 30: Batch #184 - Loss: 1.0848958492279053\n",
      "Ep 30: Batch #185 - Loss: 0.7750927805900574\n",
      "Ep 30: Batch #186 - Loss: 0.9931089878082275\n",
      "Ep 30: Batch #187 - Loss: 1.1866352558135986\n",
      "Ep 30: Batch #188 - Loss: 1.3677526712417603\n",
      "Ep 30: Batch #189 - Loss: 0.7150187492370605\n",
      "Ep 30: Batch #190 - Loss: 0.7522437572479248\n",
      "Ep 30: Batch #191 - Loss: 1.0850036144256592\n",
      "Ep 30: Batch #192 - Loss: 0.6830964684486389\n",
      "Ep 30: Batch #193 - Loss: 0.7605159878730774\n",
      "Ep 30: Batch #194 - Loss: 0.7131931781768799\n",
      "Ep 30: Batch #195 - Loss: 1.0042768716812134\n",
      "Ep 30: Batch #196 - Loss: 0.8837203979492188\n",
      "Ep 30: Batch #197 - Loss: 0.921511173248291\n",
      "Ep 30: Batch #198 - Loss: 0.6958935260772705\n",
      "Ep 30: Batch #199 - Loss: 0.8818768858909607\n",
      "Ep 31: Batch #0 - Loss: 0.8136167526245117\n",
      "Ep 31: Batch #1 - Loss: 0.896352231502533\n",
      "Ep 31: Batch #2 - Loss: 1.0252619981765747\n",
      "Ep 31: Batch #3 - Loss: 0.8823464512825012\n",
      "Ep 31: Batch #4 - Loss: 0.8087429404258728\n",
      "Ep 31: Batch #5 - Loss: 0.6812248229980469\n",
      "Ep 31: Batch #6 - Loss: 0.8968631625175476\n",
      "Ep 31: Batch #7 - Loss: 0.7168241143226624\n",
      "Ep 31: Batch #8 - Loss: 0.7491376996040344\n",
      "Ep 31: Batch #9 - Loss: 1.4281067848205566\n",
      "Ep 31: Batch #10 - Loss: 1.027281403541565\n",
      "Ep 31: Batch #11 - Loss: 0.6857923269271851\n",
      "Ep 31: Batch #12 - Loss: 1.5780876874923706\n",
      "Ep 31: Batch #13 - Loss: 0.6595836281776428\n",
      "Ep 31: Batch #14 - Loss: 0.7420071363449097\n",
      "Ep 31: Batch #15 - Loss: 1.2624635696411133\n",
      "Ep 31: Batch #16 - Loss: 1.3041794300079346\n",
      "Ep 31: Batch #17 - Loss: 0.9002955555915833\n",
      "Ep 31: Batch #18 - Loss: 0.9563414454460144\n",
      "Ep 31: Batch #19 - Loss: 0.6821932196617126\n",
      "Ep 31: Batch #20 - Loss: 0.6704962849617004\n",
      "Ep 31: Batch #21 - Loss: 1.231308937072754\n",
      "Ep 31: Batch #22 - Loss: 0.7402569651603699\n",
      "Ep 31: Batch #23 - Loss: 0.7623345255851746\n",
      "Ep 31: Batch #24 - Loss: 0.8389354944229126\n",
      "Ep 31: Batch #25 - Loss: 0.7332478761672974\n",
      "Ep 31: Batch #26 - Loss: 0.7503944039344788\n",
      "Ep 31: Batch #27 - Loss: 1.376643180847168\n",
      "Ep 31: Batch #28 - Loss: 0.8855993151664734\n",
      "Ep 31: Batch #29 - Loss: 0.9145339131355286\n",
      "Ep 31: Batch #30 - Loss: 1.221551537513733\n",
      "Ep 31: Batch #31 - Loss: 0.6855437159538269\n",
      "Ep 31: Batch #32 - Loss: 0.7653600573539734\n",
      "Ep 31: Batch #33 - Loss: 0.8222079873085022\n",
      "Ep 31: Batch #34 - Loss: 0.800660252571106\n",
      "Ep 31: Batch #35 - Loss: 0.9726316928863525\n",
      "Ep 31: Batch #36 - Loss: 0.7184750437736511\n",
      "Ep 31: Batch #37 - Loss: 1.159313678741455\n",
      "Ep 31: Batch #38 - Loss: 0.7653617858886719\n",
      "Ep 31: Batch #39 - Loss: 0.8338286876678467\n",
      "Ep 31: Batch #40 - Loss: 0.7924941182136536\n",
      "Ep 31: Batch #41 - Loss: 0.7563705444335938\n",
      "Ep 31: Batch #42 - Loss: 0.737586498260498\n",
      "Ep 31: Batch #43 - Loss: 0.8045699000358582\n",
      "Ep 31: Batch #44 - Loss: 0.802285373210907\n",
      "Ep 31: Batch #45 - Loss: 0.6521936655044556\n",
      "Ep 31: Batch #46 - Loss: 0.8501209616661072\n",
      "Ep 31: Batch #47 - Loss: 0.9856259226799011\n",
      "Ep 31: Batch #48 - Loss: 1.3785514831542969\n",
      "Ep 31: Batch #49 - Loss: 1.0366405248641968\n",
      "Ep 31: Batch #50 - Loss: 0.7182875275611877\n",
      "Ep 31: Batch #51 - Loss: 1.0188616514205933\n",
      "Ep 31: Batch #52 - Loss: 0.808857262134552\n",
      "Ep 31: Batch #53 - Loss: 0.8405406475067139\n",
      "Ep 31: Batch #54 - Loss: 0.719476580619812\n",
      "Ep 31: Batch #55 - Loss: 0.7705731987953186\n",
      "Ep 31: Batch #56 - Loss: 1.2855110168457031\n",
      "Ep 31: Batch #57 - Loss: 0.8691795468330383\n",
      "Ep 31: Batch #58 - Loss: 1.0234427452087402\n",
      "Ep 31: Batch #59 - Loss: 0.6946168541908264\n",
      "Ep 31: Batch #60 - Loss: 1.3308650255203247\n",
      "Ep 31: Batch #61 - Loss: 0.6508539915084839\n",
      "Ep 31: Batch #62 - Loss: 0.7411666512489319\n",
      "Ep 31: Batch #63 - Loss: 1.0246740579605103\n",
      "Ep 31: Batch #64 - Loss: 9.44973373413086\n",
      "Ep 31: Batch #65 - Loss: 0.6253222823143005\n",
      "Ep 31: Batch #66 - Loss: 0.8186956644058228\n",
      "Ep 31: Batch #67 - Loss: 0.9282211065292358\n",
      "Ep 31: Batch #68 - Loss: 0.9289112687110901\n",
      "Ep 31: Batch #69 - Loss: 0.7625464797019958\n",
      "Ep 31: Batch #70 - Loss: 0.7982010841369629\n",
      "Ep 31: Batch #71 - Loss: 0.6948555111885071\n",
      "Ep 31: Batch #72 - Loss: 0.8733546733856201\n",
      "Ep 31: Batch #73 - Loss: 0.9272164702415466\n",
      "Ep 31: Batch #74 - Loss: 0.7592131495475769\n",
      "Ep 31: Batch #75 - Loss: 0.7840154767036438\n",
      "Ep 31: Batch #76 - Loss: 1.111825704574585\n",
      "Ep 31: Batch #77 - Loss: 0.7516500949859619\n",
      "Ep 31: Batch #78 - Loss: 1.1835581064224243\n",
      "Ep 31: Batch #79 - Loss: 0.6413267254829407\n",
      "Ep 31: Batch #80 - Loss: 0.8803021907806396\n",
      "Ep 31: Batch #81 - Loss: 1.7005258798599243\n",
      "Ep 31: Batch #82 - Loss: 0.8910239934921265\n",
      "Ep 31: Batch #83 - Loss: 1.748918056488037\n",
      "Ep 31: Batch #84 - Loss: 0.7322114706039429\n",
      "Ep 31: Batch #85 - Loss: 0.989845871925354\n",
      "Ep 31: Batch #86 - Loss: 0.7277845144271851\n",
      "Ep 31: Batch #87 - Loss: 0.7289509773254395\n",
      "Ep 31: Batch #88 - Loss: 0.8213834166526794\n",
      "Ep 31: Batch #89 - Loss: 0.8954079747200012\n",
      "Ep 31: Batch #90 - Loss: 1.1819725036621094\n",
      "Ep 31: Batch #91 - Loss: 0.822231113910675\n",
      "Ep 31: Batch #92 - Loss: 1.0507328510284424\n",
      "Ep 31: Batch #93 - Loss: 1.0547651052474976\n",
      "Ep 31: Batch #94 - Loss: 1.0717582702636719\n",
      "Ep 31: Batch #95 - Loss: 0.9394011497497559\n",
      "Ep 31: Batch #96 - Loss: 0.9236072301864624\n",
      "Ep 31: Batch #97 - Loss: 0.7470009326934814\n",
      "Ep 31: Batch #98 - Loss: 0.7565282583236694\n",
      "Ep 31: Batch #99 - Loss: 0.9756302237510681\n",
      "Ep 31: Batch #100 - Loss: 0.6949394941329956\n",
      "Ep 31: Batch #101 - Loss: 1.066320538520813\n",
      "Ep 31: Batch #102 - Loss: 0.7986099720001221\n",
      "Ep 31: Batch #103 - Loss: 0.8065751194953918\n",
      "Ep 31: Batch #104 - Loss: 0.8186415433883667\n",
      "Ep 31: Batch #105 - Loss: 1.0496455430984497\n",
      "Ep 31: Batch #106 - Loss: 0.7760395407676697\n",
      "Ep 31: Batch #107 - Loss: 0.7762058973312378\n",
      "Ep 31: Batch #108 - Loss: 1.055431842803955\n",
      "Ep 31: Batch #109 - Loss: 0.7779217958450317\n",
      "Ep 31: Batch #110 - Loss: 0.941554069519043\n",
      "Ep 31: Batch #111 - Loss: 1.4023011922836304\n",
      "Ep 31: Batch #112 - Loss: 1.0701185464859009\n",
      "Ep 31: Batch #113 - Loss: 0.8344643115997314\n",
      "Ep 31: Batch #114 - Loss: 0.9234004020690918\n",
      "Ep 31: Batch #115 - Loss: 1.11441171169281\n",
      "Ep 31: Batch #116 - Loss: 0.6439326405525208\n",
      "Ep 31: Batch #117 - Loss: 0.889102041721344\n",
      "Ep 31: Batch #118 - Loss: 0.5589428544044495\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved in file: ./weights_autoencoder_low_LR/model_e31b118_1516651272.8496318.ckpt\n",
      "Ep 31: Batch #119 - Loss: 1.0463184118270874\n",
      "Ep 31: Batch #120 - Loss: 0.8146997094154358\n",
      "Ep 31: Batch #121 - Loss: 0.7024906277656555\n",
      "Ep 31: Batch #122 - Loss: 0.8429641723632812\n",
      "Ep 31: Batch #123 - Loss: 0.8488953113555908\n",
      "Ep 31: Batch #124 - Loss: 0.6758988499641418\n",
      "Ep 31: Batch #125 - Loss: 2.741044521331787\n",
      "Ep 31: Batch #126 - Loss: 1.2461066246032715\n",
      "Ep 31: Batch #127 - Loss: 0.7693907618522644\n",
      "Ep 31: Batch #128 - Loss: 1.131798267364502\n",
      "Ep 31: Batch #129 - Loss: 0.8581300377845764\n",
      "Ep 31: Batch #130 - Loss: 0.7407194972038269\n",
      "Ep 31: Batch #131 - Loss: 1.0201188325881958\n",
      "Ep 31: Batch #132 - Loss: 0.8435891270637512\n",
      "Ep 31: Batch #133 - Loss: 0.8354312777519226\n",
      "Ep 31: Batch #134 - Loss: 0.7871181964874268\n",
      "Ep 31: Batch #135 - Loss: 0.9879328608512878\n",
      "Ep 31: Batch #136 - Loss: 1.2064300775527954\n",
      "Ep 31: Batch #137 - Loss: 0.9855878353118896\n",
      "Ep 31: Batch #138 - Loss: 1.0907998085021973\n",
      "Ep 31: Batch #139 - Loss: 0.9199971556663513\n",
      "Ep 31: Batch #140 - Loss: 1.0689703226089478\n",
      "Ep 31: Batch #141 - Loss: 1.378840684890747\n",
      "Ep 31: Batch #142 - Loss: 0.8116390705108643\n",
      "Ep 31: Batch #143 - Loss: 0.9890288710594177\n",
      "Ep 31: Batch #144 - Loss: 0.7372561693191528\n",
      "Ep 31: Batch #145 - Loss: 0.6931423544883728\n",
      "Ep 31: Batch #146 - Loss: 0.9007492661476135\n",
      "Ep 31: Batch #147 - Loss: 0.8847344517707825\n",
      "Ep 31: Batch #148 - Loss: 0.999322235584259\n",
      "Ep 31: Batch #149 - Loss: 0.8753266930580139\n",
      "Ep 31: Batch #150 - Loss: 0.9005007147789001\n",
      "Ep 31: Batch #151 - Loss: 0.7391940355300903\n",
      "Ep 31: Batch #152 - Loss: 0.7524024844169617\n",
      "Ep 31: Batch #153 - Loss: 1.1270816326141357\n",
      "Ep 31: Batch #154 - Loss: 0.7790968418121338\n",
      "Ep 31: Batch #155 - Loss: 0.8523309826850891\n",
      "Ep 31: Batch #156 - Loss: 1.0383305549621582\n",
      "Ep 31: Batch #157 - Loss: 0.7785328030586243\n",
      "Ep 31: Batch #158 - Loss: 0.818496584892273\n",
      "Ep 31: Batch #159 - Loss: 0.8268727660179138\n",
      "Ep 31: Batch #160 - Loss: 0.9195468425750732\n",
      "Ep 31: Batch #161 - Loss: 0.8337059020996094\n",
      "Ep 31: Batch #162 - Loss: 0.9514400959014893\n",
      "Ep 31: Batch #163 - Loss: 0.9446032047271729\n",
      "Ep 31: Batch #164 - Loss: 0.8016728162765503\n",
      "Ep 31: Batch #165 - Loss: 1.5160273313522339\n",
      "Ep 31: Batch #166 - Loss: 0.6971202492713928\n",
      "Ep 31: Batch #167 - Loss: 1.1059414148330688\n",
      "Ep 31: Batch #168 - Loss: 0.8802068829536438\n",
      "Ep 31: Batch #169 - Loss: 0.8184954524040222\n",
      "Ep 31: Batch #170 - Loss: 0.8222318887710571\n",
      "Ep 31: Batch #171 - Loss: 0.8001124858856201\n",
      "Ep 31: Batch #172 - Loss: 0.646708071231842\n",
      "Ep 31: Batch #173 - Loss: 1.2228279113769531\n",
      "Ep 31: Batch #174 - Loss: 0.5922526121139526\n",
      "Ep 31: Batch #175 - Loss: 0.7932462096214294\n",
      "Ep 31: Batch #176 - Loss: 1.1778969764709473\n",
      "Ep 31: Batch #177 - Loss: 0.8667652010917664\n",
      "Ep 31: Batch #178 - Loss: 0.7820632457733154\n",
      "Ep 31: Batch #179 - Loss: 0.9620158076286316\n",
      "Ep 31: Batch #180 - Loss: 0.8783387541770935\n",
      "Ep 31: Batch #181 - Loss: 1.015918493270874\n",
      "Ep 31: Batch #182 - Loss: 0.7789254784584045\n",
      "Ep 31: Batch #183 - Loss: 0.7829960584640503\n",
      "Ep 31: Batch #184 - Loss: 1.0836056470870972\n",
      "Ep 31: Batch #185 - Loss: 0.7738838195800781\n",
      "Ep 31: Batch #186 - Loss: 0.9912517070770264\n",
      "Ep 31: Batch #187 - Loss: 1.185092568397522\n",
      "Ep 31: Batch #188 - Loss: 1.3661835193634033\n",
      "Ep 31: Batch #189 - Loss: 0.7140045166015625\n",
      "Ep 31: Batch #190 - Loss: 0.7509092092514038\n",
      "Ep 31: Batch #191 - Loss: 1.0835918188095093\n",
      "Ep 31: Batch #192 - Loss: 0.6820911169052124\n",
      "Ep 31: Batch #193 - Loss: 0.7591097354888916\n",
      "Ep 31: Batch #194 - Loss: 0.7119295001029968\n",
      "Ep 31: Batch #195 - Loss: 1.0026670694351196\n",
      "Ep 31: Batch #196 - Loss: 0.8823232650756836\n",
      "Ep 31: Batch #197 - Loss: 0.9200785756111145\n",
      "Ep 31: Batch #198 - Loss: 0.6945592761039734\n",
      "Ep 31: Batch #199 - Loss: 0.880378782749176\n",
      "Ep 32: Batch #0 - Loss: 0.8119928240776062\n",
      "Ep 32: Batch #1 - Loss: 0.894804835319519\n",
      "Ep 32: Batch #2 - Loss: 1.0240576267242432\n",
      "Ep 32: Batch #3 - Loss: 0.8809155225753784\n",
      "Ep 32: Batch #4 - Loss: 0.8072612881660461\n",
      "Ep 32: Batch #5 - Loss: 0.6802507638931274\n",
      "Ep 32: Batch #6 - Loss: 0.8954330086708069\n",
      "Ep 32: Batch #7 - Loss: 0.7156590819358826\n",
      "Ep 32: Batch #8 - Loss: 0.7479370832443237\n",
      "Ep 32: Batch #9 - Loss: 1.4260656833648682\n",
      "Ep 32: Batch #10 - Loss: 1.02558171749115\n",
      "Ep 32: Batch #11 - Loss: 0.6845391392707825\n",
      "Ep 32: Batch #12 - Loss: 1.5767782926559448\n",
      "Ep 32: Batch #13 - Loss: 0.6586818695068359\n",
      "Ep 32: Batch #14 - Loss: 0.7408711910247803\n",
      "Ep 32: Batch #15 - Loss: 1.2606464624404907\n",
      "Ep 32: Batch #16 - Loss: 1.3019530773162842\n",
      "Ep 32: Batch #17 - Loss: 0.8987730145454407\n",
      "Ep 32: Batch #18 - Loss: 0.9554075002670288\n",
      "Ep 32: Batch #19 - Loss: 0.6811009049415588\n",
      "Ep 32: Batch #20 - Loss: 0.6692637801170349\n",
      "Ep 32: Batch #21 - Loss: 1.2297991514205933\n",
      "Ep 32: Batch #22 - Loss: 0.7391431331634521\n",
      "Ep 32: Batch #23 - Loss: 0.7607415318489075\n",
      "Ep 32: Batch #24 - Loss: 0.8377063274383545\n",
      "Ep 32: Batch #25 - Loss: 0.731786847114563\n",
      "Ep 32: Batch #26 - Loss: 0.7488760352134705\n",
      "Ep 32: Batch #27 - Loss: 1.3748054504394531\n",
      "Ep 32: Batch #28 - Loss: 0.8841971158981323\n",
      "Ep 32: Batch #29 - Loss: 0.9128221273422241\n",
      "Ep 32: Batch #30 - Loss: 1.219893455505371\n",
      "Ep 32: Batch #31 - Loss: 0.6845496892929077\n",
      "Ep 32: Batch #32 - Loss: 0.7639599442481995\n",
      "Ep 32: Batch #33 - Loss: 0.8209949731826782\n",
      "Ep 32: Batch #34 - Loss: 0.7993025183677673\n",
      "Ep 32: Batch #35 - Loss: 0.9707832336425781\n",
      "Ep 32: Batch #36 - Loss: 0.717275857925415\n",
      "Ep 32: Batch #37 - Loss: 1.157867431640625\n",
      "Ep 32: Batch #38 - Loss: 0.7637840509414673\n",
      "Ep 32: Batch #39 - Loss: 0.8327305316925049\n",
      "Ep 32: Batch #40 - Loss: 0.7910526990890503\n",
      "Ep 32: Batch #41 - Loss: 0.7549777626991272\n",
      "Ep 32: Batch #42 - Loss: 0.736446738243103\n",
      "Ep 32: Batch #43 - Loss: 0.8032587766647339\n",
      "Ep 32: Batch #44 - Loss: 0.8009524345397949\n",
      "Ep 32: Batch #45 - Loss: 0.6506855487823486\n",
      "Ep 32: Batch #46 - Loss: 0.8485894799232483\n",
      "Ep 32: Batch #47 - Loss: 0.983707070350647\n",
      "Ep 32: Batch #48 - Loss: 1.3765270709991455\n",
      "Ep 32: Batch #49 - Loss: 1.0351073741912842\n",
      "Ep 32: Batch #50 - Loss: 0.7173352241516113\n",
      "Ep 32: Batch #51 - Loss: 1.017041563987732\n",
      "Ep 32: Batch #52 - Loss: 0.8077768087387085\n",
      "Ep 32: Batch #53 - Loss: 0.8391135334968567\n",
      "Ep 32: Batch #54 - Loss: 0.7183751463890076\n",
      "Ep 32: Batch #55 - Loss: 0.7690459489822388\n",
      "Ep 32: Batch #56 - Loss: 1.2837958335876465\n",
      "Ep 32: Batch #57 - Loss: 0.8674362301826477\n",
      "Ep 32: Batch #58 - Loss: 1.0215818881988525\n",
      "Ep 32: Batch #59 - Loss: 0.6934826970100403\n",
      "Ep 32: Batch #60 - Loss: 1.3291434049606323\n",
      "Ep 32: Batch #61 - Loss: 0.6496616005897522\n",
      "Ep 32: Batch #62 - Loss: 0.7397212982177734\n",
      "Ep 32: Batch #63 - Loss: 1.0228599309921265\n",
      "Ep 32: Batch #64 - Loss: 9.447515487670898\n",
      "Ep 32: Batch #65 - Loss: 0.6242877244949341\n",
      "Ep 32: Batch #66 - Loss: 0.816936731338501\n",
      "Ep 32: Batch #67 - Loss: 0.9267945289611816\n",
      "Ep 32: Batch #68 - Loss: 0.9273008108139038\n",
      "Ep 32: Batch #69 - Loss: 0.7611218094825745\n",
      "Ep 32: Batch #70 - Loss: 0.7964311242103577\n",
      "Ep 32: Batch #71 - Loss: 0.6935979127883911\n",
      "Ep 32: Batch #72 - Loss: 0.8718582391738892\n",
      "Ep 32: Batch #73 - Loss: 0.9254076480865479\n",
      "Ep 32: Batch #74 - Loss: 0.7577784657478333\n",
      "Ep 32: Batch #75 - Loss: 0.7827209830284119\n",
      "Ep 32: Batch #76 - Loss: 1.1105239391326904\n",
      "Ep 32: Batch #77 - Loss: 0.7503238916397095\n",
      "Ep 32: Batch #78 - Loss: 1.1816833019256592\n",
      "Ep 32: Batch #79 - Loss: 0.6400612592697144\n",
      "Ep 32: Batch #80 - Loss: 0.8786643743515015\n",
      "Ep 32: Batch #81 - Loss: 1.6987158060073853\n",
      "Ep 32: Batch #82 - Loss: 0.889560878276825\n",
      "Ep 32: Batch #83 - Loss: 1.747772216796875\n",
      "Ep 32: Batch #84 - Loss: 0.730805516242981\n",
      "Ep 32: Batch #85 - Loss: 0.9884846210479736\n",
      "Ep 32: Batch #86 - Loss: 0.7262797951698303\n",
      "Ep 32: Batch #87 - Loss: 0.7277283072471619\n",
      "Ep 32: Batch #88 - Loss: 0.8198291659355164\n",
      "Ep 32: Batch #89 - Loss: 0.8944173455238342\n",
      "Ep 32: Batch #90 - Loss: 1.1797152757644653\n",
      "Ep 32: Batch #91 - Loss: 0.8206537961959839\n",
      "Ep 32: Batch #92 - Loss: 1.04892897605896\n",
      "Ep 32: Batch #93 - Loss: 1.052787184715271\n",
      "Ep 32: Batch #94 - Loss: 1.070007085800171\n",
      "Ep 32: Batch #95 - Loss: 0.9377837777137756\n",
      "Ep 32: Batch #96 - Loss: 0.9221899509429932\n",
      "Ep 32: Batch #97 - Loss: 0.745590329170227\n",
      "Ep 32: Batch #98 - Loss: 0.7550747394561768\n",
      "Ep 32: Batch #99 - Loss: 0.9742238521575928\n",
      "Ep 32: Batch #100 - Loss: 0.6935763359069824\n",
      "Ep 32: Batch #101 - Loss: 1.064741611480713\n",
      "Ep 32: Batch #102 - Loss: 0.7973384857177734\n",
      "Ep 32: Batch #103 - Loss: 0.8053225874900818\n",
      "Ep 32: Batch #104 - Loss: 0.817209780216217\n",
      "Ep 32: Batch #105 - Loss: 1.0480579137802124\n",
      "Ep 32: Batch #106 - Loss: 0.7746953964233398\n",
      "Ep 32: Batch #107 - Loss: 0.7746888399124146\n",
      "Ep 32: Batch #108 - Loss: 1.0536701679229736\n",
      "Ep 32: Batch #109 - Loss: 0.7766939997673035\n",
      "Ep 32: Batch #110 - Loss: 0.9397891163825989\n",
      "Ep 32: Batch #111 - Loss: 1.4004665613174438\n",
      "Ep 32: Batch #112 - Loss: 1.06820809841156\n",
      "Ep 32: Batch #113 - Loss: 0.8329920768737793\n",
      "Ep 32: Batch #114 - Loss: 0.9218046069145203\n",
      "Ep 32: Batch #115 - Loss: 1.112929344177246\n",
      "Ep 32: Batch #116 - Loss: 0.6430274248123169\n",
      "Ep 32: Batch #117 - Loss: 0.887781023979187\n",
      "Ep 32: Batch #118 - Loss: 0.5577198266983032\n",
      "Model saved in file: ./weights_autoencoder_low_LR/model_e32b118_1516651272.987514.ckpt\n",
      "Ep 32: Batch #119 - Loss: 1.0447149276733398\n",
      "Ep 32: Batch #120 - Loss: 0.8135880827903748\n",
      "Ep 32: Batch #121 - Loss: 0.7011655569076538\n",
      "Ep 32: Batch #122 - Loss: 0.8414679765701294\n",
      "Ep 32: Batch #123 - Loss: 0.8475683331489563\n",
      "Ep 32: Batch #124 - Loss: 0.674850344657898\n",
      "Ep 32: Batch #125 - Loss: 2.73926043510437\n",
      "Ep 32: Batch #126 - Loss: 1.2443530559539795\n",
      "Ep 32: Batch #127 - Loss: 0.7677409052848816\n",
      "Ep 32: Batch #128 - Loss: 1.129705786705017\n",
      "Ep 32: Batch #129 - Loss: 0.8565691709518433\n",
      "Ep 32: Batch #130 - Loss: 0.7392918467521667\n",
      "Ep 32: Batch #131 - Loss: 1.0181550979614258\n",
      "Ep 32: Batch #132 - Loss: 0.8419640064239502\n",
      "Ep 32: Batch #133 - Loss: 0.8340210914611816\n",
      "Ep 32: Batch #134 - Loss: 0.7856497168540955\n",
      "Ep 32: Batch #135 - Loss: 0.9862657785415649\n",
      "Ep 32: Batch #136 - Loss: 1.204421877861023\n",
      "Ep 32: Batch #137 - Loss: 0.9838943481445312\n",
      "Ep 32: Batch #138 - Loss: 1.0892146825790405\n",
      "Ep 32: Batch #139 - Loss: 0.9183796048164368\n",
      "Ep 32: Batch #140 - Loss: 1.0674223899841309\n",
      "Ep 32: Batch #141 - Loss: 1.377177119255066\n",
      "Ep 32: Batch #142 - Loss: 0.8103331327438354\n",
      "Ep 32: Batch #143 - Loss: 0.9871336221694946\n",
      "Ep 32: Batch #144 - Loss: 0.7358525991439819\n",
      "Ep 32: Batch #145 - Loss: 0.6919419169425964\n",
      "Ep 32: Batch #146 - Loss: 0.8994238376617432\n",
      "Ep 32: Batch #147 - Loss: 0.8829241991043091\n",
      "Ep 32: Batch #148 - Loss: 0.9976292252540588\n",
      "Ep 32: Batch #149 - Loss: 0.8736516237258911\n",
      "Ep 32: Batch #150 - Loss: 0.8991618752479553\n",
      "Ep 32: Batch #151 - Loss: 0.738185703754425\n",
      "Ep 32: Batch #152 - Loss: 0.7512916326522827\n",
      "Ep 32: Batch #153 - Loss: 1.1253700256347656\n",
      "Ep 32: Batch #154 - Loss: 0.7778961658477783\n",
      "Ep 32: Batch #155 - Loss: 0.8507188558578491\n",
      "Ep 32: Batch #156 - Loss: 1.0366675853729248\n",
      "Ep 32: Batch #157 - Loss: 0.7772315740585327\n",
      "Ep 32: Batch #158 - Loss: 0.8173922896385193\n",
      "Ep 32: Batch #159 - Loss: 0.8254080414772034\n",
      "Ep 32: Batch #160 - Loss: 0.918261706829071\n",
      "Ep 32: Batch #161 - Loss: 0.8322954177856445\n",
      "Ep 32: Batch #162 - Loss: 0.949908971786499\n",
      "Ep 32: Batch #163 - Loss: 0.9433835744857788\n",
      "Ep 32: Batch #164 - Loss: 0.800352931022644\n",
      "Ep 32: Batch #165 - Loss: 1.5147675275802612\n",
      "Ep 32: Batch #166 - Loss: 0.695675253868103\n",
      "Ep 32: Batch #167 - Loss: 1.1044702529907227\n",
      "Ep 32: Batch #168 - Loss: 0.8786459565162659\n",
      "Ep 32: Batch #169 - Loss: 0.8171048164367676\n",
      "Ep 32: Batch #170 - Loss: 0.8208566904067993\n",
      "Ep 32: Batch #171 - Loss: 0.7985419034957886\n",
      "Ep 32: Batch #172 - Loss: 0.6456803679466248\n",
      "Ep 32: Batch #173 - Loss: 1.2207826375961304\n",
      "Ep 32: Batch #174 - Loss: 0.5911237001419067\n",
      "Ep 32: Batch #175 - Loss: 0.792020857334137\n",
      "Ep 32: Batch #176 - Loss: 1.176405906677246\n",
      "Ep 32: Batch #177 - Loss: 0.8653238415718079\n",
      "Ep 32: Batch #178 - Loss: 0.7805416584014893\n",
      "Ep 32: Batch #179 - Loss: 0.9602822661399841\n",
      "Ep 32: Batch #180 - Loss: 0.8764823079109192\n",
      "Ep 32: Batch #181 - Loss: 1.0140122175216675\n",
      "Ep 32: Batch #182 - Loss: 0.7777395844459534\n",
      "Ep 32: Batch #183 - Loss: 0.7815296649932861\n",
      "Ep 32: Batch #184 - Loss: 1.0823302268981934\n",
      "Ep 32: Batch #185 - Loss: 0.7726959586143494\n",
      "Ep 32: Batch #186 - Loss: 0.9893835186958313\n",
      "Ep 32: Batch #187 - Loss: 1.1835659742355347\n",
      "Ep 32: Batch #188 - Loss: 1.3646588325500488\n",
      "Ep 32: Batch #189 - Loss: 0.7130036950111389\n",
      "Ep 32: Batch #190 - Loss: 0.7496012449264526\n",
      "Ep 32: Batch #191 - Loss: 1.0821802616119385\n",
      "Ep 32: Batch #192 - Loss: 0.6810919642448425\n",
      "Ep 32: Batch #193 - Loss: 0.7577082514762878\n",
      "Ep 32: Batch #194 - Loss: 0.710684061050415\n",
      "Ep 32: Batch #195 - Loss: 1.0010745525360107\n",
      "Ep 32: Batch #196 - Loss: 0.8809317350387573\n",
      "Ep 32: Batch #197 - Loss: 0.9186630249023438\n",
      "Ep 32: Batch #198 - Loss: 0.6932486295700073\n",
      "Ep 32: Batch #199 - Loss: 0.878897488117218\n",
      "Ep 33: Batch #0 - Loss: 0.8103852868080139\n",
      "Ep 33: Batch #1 - Loss: 0.8932865858078003\n",
      "Ep 33: Batch #2 - Loss: 1.0228623151779175\n",
      "Ep 33: Batch #3 - Loss: 0.8795099854469299\n",
      "Ep 33: Batch #4 - Loss: 0.8057947754859924\n",
      "Ep 33: Batch #5 - Loss: 0.6792839765548706\n",
      "Ep 33: Batch #6 - Loss: 0.8940311670303345\n",
      "Ep 33: Batch #7 - Loss: 0.7145126461982727\n",
      "Ep 33: Batch #8 - Loss: 0.7467511892318726\n",
      "Ep 33: Batch #9 - Loss: 1.4240193367004395\n",
      "Ep 33: Batch #10 - Loss: 1.023913025856018\n",
      "Ep 33: Batch #11 - Loss: 0.6833062767982483\n",
      "Ep 33: Batch #12 - Loss: 1.575462818145752\n",
      "Ep 33: Batch #13 - Loss: 0.6577962636947632\n",
      "Ep 33: Batch #14 - Loss: 0.7397379279136658\n",
      "Ep 33: Batch #15 - Loss: 1.2588536739349365\n",
      "Ep 33: Batch #16 - Loss: 1.2997597455978394\n",
      "Ep 33: Batch #17 - Loss: 0.8972676992416382\n",
      "Ep 33: Batch #18 - Loss: 0.9544835090637207\n",
      "Ep 33: Batch #19 - Loss: 0.6800152659416199\n",
      "Ep 33: Batch #20 - Loss: 0.6680468916893005\n",
      "Ep 33: Batch #21 - Loss: 1.2283098697662354\n",
      "Ep 33: Batch #22 - Loss: 0.7380454540252686\n",
      "Ep 33: Batch #23 - Loss: 0.7591907382011414\n",
      "Ep 33: Batch #24 - Loss: 0.8365002870559692\n",
      "Ep 33: Batch #25 - Loss: 0.7303499579429626\n",
      "Ep 33: Batch #26 - Loss: 0.7473798394203186\n",
      "Ep 33: Batch #27 - Loss: 1.3729703426361084\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 33: Batch #28 - Loss: 0.8828141689300537\n",
      "Ep 33: Batch #29 - Loss: 0.911135196685791\n",
      "Ep 33: Batch #30 - Loss: 1.218259334564209\n",
      "Ep 33: Batch #31 - Loss: 0.6835777759552002\n",
      "Ep 33: Batch #32 - Loss: 0.7625828385353088\n",
      "Ep 33: Batch #33 - Loss: 0.8198138475418091\n",
      "Ep 33: Batch #34 - Loss: 0.7979637384414673\n",
      "Ep 33: Batch #35 - Loss: 0.9689281582832336\n",
      "Ep 33: Batch #36 - Loss: 0.7160852551460266\n",
      "Ep 33: Batch #37 - Loss: 1.1564377546310425\n",
      "Ep 33: Batch #38 - Loss: 0.7622259855270386\n",
      "Ep 33: Batch #39 - Loss: 0.8316415548324585\n",
      "Ep 33: Batch #40 - Loss: 0.7896279096603394\n",
      "Ep 33: Batch #41 - Loss: 0.7535854578018188\n",
      "Ep 33: Batch #42 - Loss: 0.7353135347366333\n",
      "Ep 33: Batch #43 - Loss: 0.8019546270370483\n",
      "Ep 33: Batch #44 - Loss: 0.799618661403656\n",
      "Ep 33: Batch #45 - Loss: 0.6492089033126831\n",
      "Ep 33: Batch #46 - Loss: 0.8470842242240906\n",
      "Ep 33: Batch #47 - Loss: 0.981810450553894\n",
      "Ep 33: Batch #48 - Loss: 1.3745399713516235\n",
      "Ep 33: Batch #49 - Loss: 1.0335757732391357\n",
      "Ep 33: Batch #50 - Loss: 0.7163864970207214\n",
      "Ep 33: Batch #51 - Loss: 1.0152366161346436\n",
      "Ep 33: Batch #52 - Loss: 0.8067053556442261\n",
      "Ep 33: Batch #53 - Loss: 0.8377041220664978\n",
      "Ep 33: Batch #54 - Loss: 0.7172836065292358\n",
      "Ep 33: Batch #55 - Loss: 0.7675461769104004\n",
      "Ep 33: Batch #56 - Loss: 1.2820740938186646\n",
      "Ep 33: Batch #57 - Loss: 0.8657270073890686\n",
      "Ep 33: Batch #58 - Loss: 1.019740343093872\n",
      "Ep 33: Batch #59 - Loss: 0.6923701167106628\n",
      "Ep 33: Batch #60 - Loss: 1.3274556398391724\n",
      "Ep 33: Batch #61 - Loss: 0.6484975814819336\n",
      "Ep 33: Batch #62 - Loss: 0.7382906079292297\n",
      "Ep 33: Batch #63 - Loss: 1.0210760831832886\n",
      "Ep 33: Batch #64 - Loss: 9.445402145385742\n",
      "Ep 33: Batch #65 - Loss: 0.6232789158821106\n",
      "Ep 33: Batch #66 - Loss: 0.8152036666870117\n",
      "Ep 33: Batch #67 - Loss: 0.9253731966018677\n",
      "Ep 33: Batch #68 - Loss: 0.9257075190544128\n",
      "Ep 33: Batch #69 - Loss: 0.7597212195396423\n",
      "Ep 33: Batch #70 - Loss: 0.7946904301643372\n",
      "Ep 33: Batch #71 - Loss: 0.6923609375953674\n",
      "Ep 33: Batch #72 - Loss: 0.8703796863555908\n",
      "Ep 33: Batch #73 - Loss: 0.9235987663269043\n",
      "Ep 33: Batch #74 - Loss: 0.7563561797142029\n",
      "Ep 33: Batch #75 - Loss: 0.7814435958862305\n",
      "Ep 33: Batch #76 - Loss: 1.109239101409912\n",
      "Ep 33: Batch #77 - Loss: 0.7490073442459106\n",
      "Ep 33: Batch #78 - Loss: 1.1798261404037476\n",
      "Ep 33: Batch #79 - Loss: 0.6388210654258728\n",
      "Ep 33: Batch #80 - Loss: 0.8770452737808228\n",
      "Ep 33: Batch #81 - Loss: 1.6969842910766602\n",
      "Ep 33: Batch #82 - Loss: 0.8881201148033142\n",
      "Ep 33: Batch #83 - Loss: 1.7466418743133545\n",
      "Ep 33: Batch #84 - Loss: 0.7294130325317383\n",
      "Ep 33: Batch #85 - Loss: 0.9871463775634766\n",
      "Ep 33: Batch #86 - Loss: 0.7247893810272217\n",
      "Ep 33: Batch #87 - Loss: 0.7265125513076782\n",
      "Ep 33: Batch #88 - Loss: 0.8182990550994873\n",
      "Ep 33: Batch #89 - Loss: 0.8934469223022461\n",
      "Ep 33: Batch #90 - Loss: 1.1774914264678955\n",
      "Ep 33: Batch #91 - Loss: 0.8190931081771851\n",
      "Ep 33: Batch #92 - Loss: 1.0471476316452026\n",
      "Ep 33: Batch #93 - Loss: 1.0508296489715576\n",
      "Ep 33: Batch #94 - Loss: 1.0682655572891235\n",
      "Ep 33: Batch #95 - Loss: 0.9361861944198608\n",
      "Ep 33: Batch #96 - Loss: 0.9207866191864014\n",
      "Ep 33: Batch #97 - Loss: 0.7442092299461365\n",
      "Ep 33: Batch #98 - Loss: 0.7536495327949524\n",
      "Ep 33: Batch #99 - Loss: 0.972832977771759\n",
      "Ep 33: Batch #100 - Loss: 0.6922294497489929\n",
      "Ep 33: Batch #101 - Loss: 1.0631834268569946\n",
      "Ep 33: Batch #102 - Loss: 0.7960754036903381\n",
      "Ep 33: Batch #103 - Loss: 0.8040700554847717\n",
      "Ep 33: Batch #104 - Loss: 0.8158039450645447\n",
      "Ep 33: Batch #105 - Loss: 1.046464204788208\n",
      "Ep 33: Batch #106 - Loss: 0.7733678817749023\n",
      "Ep 33: Batch #107 - Loss: 0.7731955051422119\n",
      "Ep 33: Batch #108 - Loss: 1.0519294738769531\n",
      "Ep 33: Batch #109 - Loss: 0.7754709720611572\n",
      "Ep 33: Batch #110 - Loss: 0.938037633895874\n",
      "Ep 33: Batch #111 - Loss: 1.398639440536499\n",
      "Ep 33: Batch #112 - Loss: 1.0663303136825562\n",
      "Ep 33: Batch #113 - Loss: 0.8315431475639343\n",
      "Ep 33: Batch #114 - Loss: 0.9202233552932739\n",
      "Ep 33: Batch #115 - Loss: 1.111444354057312\n",
      "Ep 33: Batch #116 - Loss: 0.6421399116516113\n",
      "Ep 33: Batch #117 - Loss: 0.8864785432815552\n",
      "Ep 33: Batch #118 - Loss: 0.5565253496170044\n",
      "Model saved in file: ./weights_autoencoder_low_LR/model_e33b118_1516651273.1234605.ckpt\n",
      "Ep 33: Batch #119 - Loss: 1.0431315898895264\n",
      "Ep 33: Batch #120 - Loss: 0.8124813437461853\n",
      "Ep 33: Batch #121 - Loss: 0.6998575925827026\n",
      "Ep 33: Batch #122 - Loss: 0.8400091528892517\n",
      "Ep 33: Batch #123 - Loss: 0.8462597131729126\n",
      "Ep 33: Batch #124 - Loss: 0.6738161444664001\n",
      "Ep 33: Batch #125 - Loss: 2.7375118732452393\n",
      "Ep 33: Batch #126 - Loss: 1.2426308393478394\n",
      "Ep 33: Batch #127 - Loss: 0.7661161422729492\n",
      "Ep 33: Batch #128 - Loss: 1.1276110410690308\n",
      "Ep 33: Batch #129 - Loss: 0.8550357818603516\n",
      "Ep 33: Batch #130 - Loss: 0.7378857135772705\n",
      "Ep 33: Batch #131 - Loss: 1.0162090063095093\n",
      "Ep 33: Batch #132 - Loss: 0.8403719067573547\n",
      "Ep 33: Batch #133 - Loss: 0.8326239585876465\n",
      "Ep 33: Batch #134 - Loss: 0.7842028141021729\n",
      "Ep 33: Batch #135 - Loss: 0.9846158623695374\n",
      "Ep 33: Batch #136 - Loss: 1.2024364471435547\n",
      "Ep 33: Batch #137 - Loss: 0.9822160005569458\n",
      "Ep 33: Batch #138 - Loss: 1.087617039680481\n",
      "Ep 33: Batch #139 - Loss: 0.916785478591919\n",
      "Ep 33: Batch #140 - Loss: 1.0658823251724243\n",
      "Ep 33: Batch #141 - Loss: 1.3755288124084473\n",
      "Ep 33: Batch #142 - Loss: 0.8090364336967468\n",
      "Ep 33: Batch #143 - Loss: 0.985262393951416\n",
      "Ep 33: Batch #144 - Loss: 0.7344750761985779\n",
      "Ep 33: Batch #145 - Loss: 0.6907409429550171\n",
      "Ep 33: Batch #146 - Loss: 0.8981068730354309\n",
      "Ep 33: Batch #147 - Loss: 0.8811323642730713\n",
      "Ep 33: Batch #148 - Loss: 0.9959571361541748\n",
      "Ep 33: Batch #149 - Loss: 0.8719912171363831\n",
      "Ep 33: Batch #150 - Loss: 0.8978284597396851\n",
      "Ep 33: Batch #151 - Loss: 0.7371914982795715\n",
      "Ep 33: Batch #152 - Loss: 0.7502093315124512\n",
      "Ep 33: Batch #153 - Loss: 1.1236740350723267\n",
      "Ep 33: Batch #154 - Loss: 0.7767018675804138\n",
      "Ep 33: Batch #155 - Loss: 0.8491385579109192\n",
      "Ep 33: Batch #156 - Loss: 1.0350086688995361\n",
      "Ep 33: Batch #157 - Loss: 0.7759401798248291\n",
      "Ep 33: Batch #158 - Loss: 0.8163090944290161\n",
      "Ep 33: Batch #159 - Loss: 0.8239567875862122\n",
      "Ep 33: Batch #160 - Loss: 0.9169915318489075\n",
      "Ep 33: Batch #161 - Loss: 0.8308932185173035\n",
      "Ep 33: Batch #162 - Loss: 0.948397159576416\n",
      "Ep 33: Batch #163 - Loss: 0.9421923160552979\n",
      "Ep 33: Batch #164 - Loss: 0.7990384101867676\n",
      "Ep 33: Batch #165 - Loss: 1.5135252475738525\n",
      "Ep 33: Batch #166 - Loss: 0.6942563056945801\n",
      "Ep 33: Batch #167 - Loss: 1.1029976606369019\n",
      "Ep 33: Batch #168 - Loss: 0.8771041631698608\n",
      "Ep 33: Batch #169 - Loss: 0.815731942653656\n",
      "Ep 33: Batch #170 - Loss: 0.8194516897201538\n",
      "Ep 33: Batch #171 - Loss: 0.7969862222671509\n",
      "Ep 33: Batch #172 - Loss: 0.6446608901023865\n",
      "Ep 33: Batch #173 - Loss: 1.2187482118606567\n",
      "Ep 33: Batch #174 - Loss: 0.5900231003761292\n",
      "Ep 33: Batch #175 - Loss: 0.7908080220222473\n",
      "Ep 33: Batch #176 - Loss: 1.1749155521392822\n",
      "Ep 33: Batch #177 - Loss: 0.8638856410980225\n",
      "Ep 33: Batch #178 - Loss: 0.779041051864624\n",
      "Ep 33: Batch #179 - Loss: 0.9585589170455933\n",
      "Ep 33: Batch #180 - Loss: 0.8746587038040161\n",
      "Ep 33: Batch #181 - Loss: 1.0121270418167114\n",
      "Ep 33: Batch #182 - Loss: 0.7765733599662781\n",
      "Ep 33: Batch #183 - Loss: 0.780085027217865\n",
      "Ep 33: Batch #184 - Loss: 1.0810699462890625\n",
      "Ep 33: Batch #185 - Loss: 0.7715171575546265\n",
      "Ep 33: Batch #186 - Loss: 0.9875275492668152\n",
      "Ep 33: Batch #187 - Loss: 1.182058572769165\n",
      "Ep 33: Batch #188 - Loss: 1.3631796836853027\n",
      "Ep 33: Batch #189 - Loss: 0.712014377117157\n",
      "Ep 33: Batch #190 - Loss: 0.74831622838974\n",
      "Ep 33: Batch #191 - Loss: 1.0807541608810425\n",
      "Ep 33: Batch #192 - Loss: 0.6801030039787292\n",
      "Ep 33: Batch #193 - Loss: 0.7563114166259766\n",
      "Ep 33: Batch #194 - Loss: 0.7094515562057495\n",
      "Ep 33: Batch #195 - Loss: 0.999495267868042\n",
      "Ep 33: Batch #196 - Loss: 0.8795536160469055\n",
      "Ep 33: Batch #197 - Loss: 0.9172535538673401\n",
      "Ep 33: Batch #198 - Loss: 0.6919581890106201\n",
      "Ep 33: Batch #199 - Loss: 0.8774171471595764\n",
      "Ep 34: Batch #0 - Loss: 0.8087918758392334\n",
      "Ep 34: Batch #1 - Loss: 0.8917906284332275\n",
      "Ep 34: Batch #2 - Loss: 1.0216705799102783\n",
      "Ep 34: Batch #3 - Loss: 0.8781338334083557\n",
      "Ep 34: Batch #4 - Loss: 0.8043479323387146\n",
      "Ep 34: Batch #5 - Loss: 0.6783270835876465\n",
      "Ep 34: Batch #6 - Loss: 0.8926613926887512\n",
      "Ep 34: Batch #7 - Loss: 0.7133784294128418\n",
      "Ep 34: Batch #8 - Loss: 0.7455793023109436\n",
      "Ep 34: Batch #9 - Loss: 1.421980857849121\n",
      "Ep 34: Batch #10 - Loss: 1.02227783203125\n",
      "Ep 34: Batch #11 - Loss: 0.6821022033691406\n",
      "Ep 34: Batch #12 - Loss: 1.5741389989852905\n",
      "Ep 34: Batch #13 - Loss: 0.6569229364395142\n",
      "Ep 34: Batch #14 - Loss: 0.7385987043380737\n",
      "Ep 34: Batch #15 - Loss: 1.2570637464523315\n",
      "Ep 34: Batch #16 - Loss: 1.29759681224823\n",
      "Ep 34: Batch #17 - Loss: 0.895775556564331\n",
      "Ep 34: Batch #18 - Loss: 0.9535722732543945\n",
      "Ep 34: Batch #19 - Loss: 0.6789358854293823\n",
      "Ep 34: Batch #20 - Loss: 0.6668443083763123\n",
      "Ep 34: Batch #21 - Loss: 1.2268375158309937\n",
      "Ep 34: Batch #22 - Loss: 0.7369549870491028\n",
      "Ep 34: Batch #23 - Loss: 0.7576720118522644\n",
      "Ep 34: Batch #24 - Loss: 0.8353070616722107\n",
      "Ep 34: Batch #25 - Loss: 0.7289223074913025\n",
      "Ep 34: Batch #26 - Loss: 0.7458938956260681\n",
      "Ep 34: Batch #27 - Loss: 1.3711488246917725\n",
      "Ep 34: Batch #28 - Loss: 0.8814474940299988\n",
      "Ep 34: Batch #29 - Loss: 0.9094703793525696\n",
      "Ep 34: Batch #30 - Loss: 1.2166545391082764\n",
      "Ep 34: Batch #31 - Loss: 0.6826218962669373\n",
      "Ep 34: Batch #32 - Loss: 0.7612213492393494\n",
      "Ep 34: Batch #33 - Loss: 0.8186570405960083\n",
      "Ep 34: Batch #34 - Loss: 0.7966442704200745\n",
      "Ep 34: Batch #35 - Loss: 0.967086136341095\n",
      "Ep 34: Batch #36 - Loss: 0.7148990631103516\n",
      "Ep 34: Batch #37 - Loss: 1.1550229787826538\n",
      "Ep 34: Batch #38 - Loss: 0.7606867551803589\n",
      "Ep 34: Batch #39 - Loss: 0.8305608034133911\n",
      "Ep 34: Batch #40 - Loss: 0.7882242202758789\n",
      "Ep 34: Batch #41 - Loss: 0.7521994709968567\n",
      "Ep 34: Batch #42 - Loss: 0.7341788411140442\n",
      "Ep 34: Batch #43 - Loss: 0.8006579279899597\n",
      "Ep 34: Batch #44 - Loss: 0.798288106918335\n",
      "Ep 34: Batch #45 - Loss: 0.6477630138397217\n",
      "Ep 34: Batch #46 - Loss: 0.8455963134765625\n",
      "Ep 34: Batch #47 - Loss: 0.9799216985702515\n",
      "Ep 34: Batch #48 - Loss: 1.3725967407226562\n",
      "Ep 34: Batch #49 - Loss: 1.0320258140563965\n",
      "Ep 34: Batch #50 - Loss: 0.7154487371444702\n",
      "Ep 34: Batch #51 - Loss: 1.0134328603744507\n",
      "Ep 34: Batch #52 - Loss: 0.8056290745735168\n",
      "Ep 34: Batch #53 - Loss: 0.8363069891929626\n",
      "Ep 34: Batch #54 - Loss: 0.7162021398544312\n",
      "Ep 34: Batch #55 - Loss: 0.7660654187202454\n",
      "Ep 34: Batch #56 - Loss: 1.2802411317825317\n",
      "Ep 34: Batch #57 - Loss: 0.8640404343605042\n",
      "Ep 34: Batch #58 - Loss: 1.0179253816604614\n",
      "Ep 34: Batch #59 - Loss: 0.6912843585014343\n",
      "Ep 34: Batch #60 - Loss: 1.3258036375045776\n",
      "Ep 34: Batch #61 - Loss: 0.6473559737205505\n",
      "Ep 34: Batch #62 - Loss: 0.7368639707565308\n",
      "Ep 34: Batch #63 - Loss: 1.0193208456039429\n",
      "Ep 34: Batch #64 - Loss: 9.443405151367188\n",
      "Ep 34: Batch #65 - Loss: 0.6222779750823975\n",
      "Ep 34: Batch #66 - Loss: 0.8134886622428894\n",
      "Ep 34: Batch #67 - Loss: 0.9239676594734192\n",
      "Ep 34: Batch #68 - Loss: 0.9241231679916382\n",
      "Ep 34: Batch #69 - Loss: 0.7583524584770203\n",
      "Ep 34: Batch #70 - Loss: 0.792974591255188\n",
      "Ep 34: Batch #71 - Loss: 0.6911444664001465\n",
      "Ep 34: Batch #72 - Loss: 0.8689010739326477\n",
      "Ep 34: Batch #73 - Loss: 0.9217931032180786\n",
      "Ep 34: Batch #74 - Loss: 0.7549448609352112\n",
      "Ep 34: Batch #75 - Loss: 0.7801803350448608\n",
      "Ep 34: Batch #76 - Loss: 1.1079673767089844\n",
      "Ep 34: Batch #77 - Loss: 0.7477019429206848\n",
      "Ep 34: Batch #78 - Loss: 1.17799711227417\n",
      "Ep 34: Batch #79 - Loss: 0.6376010179519653\n",
      "Ep 34: Batch #80 - Loss: 0.8754265308380127\n",
      "Ep 34: Batch #81 - Loss: 1.6953386068344116\n",
      "Ep 34: Batch #82 - Loss: 0.8867030739784241\n",
      "Ep 34: Batch #83 - Loss: 1.7455241680145264\n",
      "Ep 34: Batch #84 - Loss: 0.7280327081680298\n",
      "Ep 34: Batch #85 - Loss: 0.9858289957046509\n",
      "Ep 34: Batch #86 - Loss: 0.7233219146728516\n",
      "Ep 34: Batch #87 - Loss: 0.725304126739502\n",
      "Ep 34: Batch #88 - Loss: 0.8167864680290222\n",
      "Ep 34: Batch #89 - Loss: 0.8924766778945923\n",
      "Ep 34: Batch #90 - Loss: 1.175297498703003\n",
      "Ep 34: Batch #91 - Loss: 0.8175455927848816\n",
      "Ep 34: Batch #92 - Loss: 1.0453819036483765\n",
      "Ep 34: Batch #93 - Loss: 1.0488792657852173\n",
      "Ep 34: Batch #94 - Loss: 1.0665335655212402\n",
      "Ep 34: Batch #95 - Loss: 0.9346264004707336\n",
      "Ep 34: Batch #96 - Loss: 0.9193954467773438\n",
      "Ep 34: Batch #97 - Loss: 0.7428456544876099\n",
      "Ep 34: Batch #98 - Loss: 0.7522410750389099\n",
      "Ep 34: Batch #99 - Loss: 0.971464216709137\n",
      "Ep 34: Batch #100 - Loss: 0.690902829170227\n",
      "Ep 34: Batch #101 - Loss: 1.0616416931152344\n",
      "Ep 34: Batch #102 - Loss: 0.7948166728019714\n",
      "Ep 34: Batch #103 - Loss: 0.8027699589729309\n",
      "Ep 34: Batch #104 - Loss: 0.8144205212593079\n",
      "Ep 34: Batch #105 - Loss: 1.044872760772705\n",
      "Ep 34: Batch #106 - Loss: 0.7720544934272766\n",
      "Ep 34: Batch #107 - Loss: 0.771720826625824\n",
      "Ep 34: Batch #108 - Loss: 1.050208330154419\n",
      "Ep 34: Batch #109 - Loss: 0.7742552161216736\n",
      "Ep 34: Batch #110 - Loss: 0.9362962245941162\n",
      "Ep 34: Batch #111 - Loss: 1.396824598312378\n",
      "Ep 34: Batch #112 - Loss: 1.06448495388031\n",
      "Ep 34: Batch #113 - Loss: 0.8301133513450623\n",
      "Ep 34: Batch #114 - Loss: 0.9186595678329468\n",
      "Ep 34: Batch #115 - Loss: 1.1099538803100586\n",
      "Ep 34: Batch #116 - Loss: 0.6412708759307861\n",
      "Ep 34: Batch #117 - Loss: 0.8851896524429321\n",
      "Ep 34: Batch #118 - Loss: 0.5553527474403381\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved in file: ./weights_autoencoder_low_LR/model_e34b118_1516651273.259254.ckpt\n",
      "Ep 34: Batch #119 - Loss: 1.041567087173462\n",
      "Ep 34: Batch #120 - Loss: 0.8113834261894226\n",
      "Ep 34: Batch #121 - Loss: 0.6985597014427185\n",
      "Ep 34: Batch #122 - Loss: 0.8385586142539978\n",
      "Ep 34: Batch #123 - Loss: 0.8449617028236389\n",
      "Ep 34: Batch #124 - Loss: 0.6727973818778992\n",
      "Ep 34: Batch #125 - Loss: 2.735793113708496\n",
      "Ep 34: Batch #126 - Loss: 1.2409412860870361\n",
      "Ep 34: Batch #127 - Loss: 0.7645158767700195\n",
      "Ep 34: Batch #128 - Loss: 1.1255276203155518\n",
      "Ep 34: Batch #129 - Loss: 0.853515625\n",
      "Ep 34: Batch #130 - Loss: 0.7365031242370605\n",
      "Ep 34: Batch #131 - Loss: 1.014262318611145\n",
      "Ep 34: Batch #132 - Loss: 0.8388020396232605\n",
      "Ep 34: Batch #133 - Loss: 0.8312419652938843\n",
      "Ep 34: Batch #134 - Loss: 0.7827800512313843\n",
      "Ep 34: Batch #135 - Loss: 0.9829844832420349\n",
      "Ep 34: Batch #136 - Loss: 1.2004679441452026\n",
      "Ep 34: Batch #137 - Loss: 0.9805490970611572\n",
      "Ep 34: Batch #138 - Loss: 1.0860165357589722\n",
      "Ep 34: Batch #139 - Loss: 0.9152071475982666\n",
      "Ep 34: Batch #140 - Loss: 1.0642982721328735\n",
      "Ep 34: Batch #141 - Loss: 1.3738880157470703\n",
      "Ep 34: Batch #142 - Loss: 0.8077501058578491\n",
      "Ep 34: Batch #143 - Loss: 0.9834102392196655\n",
      "Ep 34: Batch #144 - Loss: 0.7331216335296631\n",
      "Ep 34: Batch #145 - Loss: 0.6895481944084167\n",
      "Ep 34: Batch #146 - Loss: 0.8967944383621216\n",
      "Ep 34: Batch #147 - Loss: 0.8793444633483887\n",
      "Ep 34: Batch #148 - Loss: 0.9942969679832458\n",
      "Ep 34: Batch #149 - Loss: 0.8703433871269226\n",
      "Ep 34: Batch #150 - Loss: 0.8965071439743042\n",
      "Ep 34: Batch #151 - Loss: 0.736212968826294\n",
      "Ep 34: Batch #152 - Loss: 0.7491474151611328\n",
      "Ep 34: Batch #153 - Loss: 1.12198007106781\n",
      "Ep 34: Batch #154 - Loss: 0.7755087614059448\n",
      "Ep 34: Batch #155 - Loss: 0.8475849032402039\n",
      "Ep 34: Batch #156 - Loss: 1.033369779586792\n",
      "Ep 34: Batch #157 - Loss: 0.774657130241394\n",
      "Ep 34: Batch #158 - Loss: 0.8152453899383545\n",
      "Ep 34: Batch #159 - Loss: 0.822515606880188\n",
      "Ep 34: Batch #160 - Loss: 0.9157170057296753\n",
      "Ep 34: Batch #161 - Loss: 0.8295050859451294\n",
      "Ep 34: Batch #162 - Loss: 0.9469072818756104\n",
      "Ep 34: Batch #163 - Loss: 0.9410129189491272\n",
      "Ep 34: Batch #164 - Loss: 0.7977331280708313\n",
      "Ep 34: Batch #165 - Loss: 1.512305736541748\n",
      "Ep 34: Batch #166 - Loss: 0.6928620934486389\n",
      "Ep 34: Batch #167 - Loss: 1.1015241146087646\n",
      "Ep 34: Batch #168 - Loss: 0.8755760192871094\n",
      "Ep 34: Batch #169 - Loss: 0.814379096031189\n",
      "Ep 34: Batch #170 - Loss: 0.8180678486824036\n",
      "Ep 34: Batch #171 - Loss: 0.7954481244087219\n",
      "Ep 34: Batch #172 - Loss: 0.6436540484428406\n",
      "Ep 34: Batch #173 - Loss: 1.2167284488677979\n",
      "Ep 34: Batch #174 - Loss: 0.5889461636543274\n",
      "Ep 34: Batch #175 - Loss: 0.7896154522895813\n",
      "Ep 34: Batch #176 - Loss: 1.173414707183838\n",
      "Ep 34: Batch #177 - Loss: 0.8624581694602966\n",
      "Ep 34: Batch #178 - Loss: 0.7775667309761047\n",
      "Ep 34: Batch #179 - Loss: 0.9568402171134949\n",
      "Ep 34: Batch #180 - Loss: 0.8728650808334351\n",
      "Ep 34: Batch #181 - Loss: 1.0102533102035522\n",
      "Ep 34: Batch #182 - Loss: 0.7754194736480713\n",
      "Ep 34: Batch #183 - Loss: 0.7786546349525452\n",
      "Ep 34: Batch #184 - Loss: 1.0798289775848389\n",
      "Ep 34: Batch #185 - Loss: 0.7703498005867004\n",
      "Ep 34: Batch #186 - Loss: 0.9856873154640198\n",
      "Ep 34: Batch #187 - Loss: 1.1805682182312012\n",
      "Ep 34: Batch #188 - Loss: 1.361727237701416\n",
      "Ep 34: Batch #189 - Loss: 0.7110308408737183\n",
      "Ep 34: Batch #190 - Loss: 0.7470476031303406\n",
      "Ep 34: Batch #191 - Loss: 1.0793086290359497\n",
      "Ep 34: Batch #192 - Loss: 0.6791280508041382\n",
      "Ep 34: Batch #193 - Loss: 0.7549161911010742\n",
      "Ep 34: Batch #194 - Loss: 0.7082314491271973\n",
      "Ep 34: Batch #195 - Loss: 0.9979343414306641\n",
      "Ep 34: Batch #196 - Loss: 0.8781977891921997\n",
      "Ep 34: Batch #197 - Loss: 0.9158414006233215\n",
      "Ep 34: Batch #198 - Loss: 0.6906848549842834\n",
      "Ep 34: Batch #199 - Loss: 0.875954806804657\n",
      "Ep 35: Batch #0 - Loss: 0.8072114586830139\n",
      "Ep 35: Batch #1 - Loss: 0.8903273940086365\n",
      "Ep 35: Batch #2 - Loss: 1.0204898118972778\n",
      "Ep 35: Batch #3 - Loss: 0.876776933670044\n",
      "Ep 35: Batch #4 - Loss: 0.8029133081436157\n",
      "Ep 35: Batch #5 - Loss: 0.677365779876709\n",
      "Ep 35: Batch #6 - Loss: 0.8913145661354065\n",
      "Ep 35: Batch #7 - Loss: 0.7122536301612854\n",
      "Ep 35: Batch #8 - Loss: 0.7444286942481995\n",
      "Ep 35: Batch #9 - Loss: 1.4199061393737793\n",
      "Ep 35: Batch #10 - Loss: 1.020680546760559\n",
      "Ep 35: Batch #11 - Loss: 0.6809242963790894\n",
      "Ep 35: Batch #12 - Loss: 1.572839617729187\n",
      "Ep 35: Batch #13 - Loss: 0.6560595035552979\n",
      "Ep 35: Batch #14 - Loss: 0.7374645471572876\n",
      "Ep 35: Batch #15 - Loss: 1.2553040981292725\n",
      "Ep 35: Batch #16 - Loss: 1.2954527139663696\n",
      "Ep 35: Batch #17 - Loss: 0.8942903876304626\n",
      "Ep 35: Batch #18 - Loss: 0.952658474445343\n",
      "Ep 35: Batch #19 - Loss: 0.6778608560562134\n",
      "Ep 35: Batch #20 - Loss: 0.6656619906425476\n",
      "Ep 35: Batch #21 - Loss: 1.22538161277771\n",
      "Ep 35: Batch #22 - Loss: 0.735876202583313\n",
      "Ep 35: Batch #23 - Loss: 0.756183385848999\n",
      "Ep 35: Batch #24 - Loss: 0.8341166973114014\n",
      "Ep 35: Batch #25 - Loss: 0.7275195121765137\n",
      "Ep 35: Batch #26 - Loss: 0.7444263696670532\n",
      "Ep 35: Batch #27 - Loss: 1.3693240880966187\n",
      "Ep 35: Batch #28 - Loss: 0.8801046013832092\n",
      "Ep 35: Batch #29 - Loss: 0.9078271389007568\n",
      "Ep 35: Batch #30 - Loss: 1.2150822877883911\n",
      "Ep 35: Batch #31 - Loss: 0.6816840767860413\n",
      "Ep 35: Batch #32 - Loss: 0.7598825097084045\n",
      "Ep 35: Batch #33 - Loss: 0.8175244331359863\n",
      "Ep 35: Batch #34 - Loss: 0.7953435182571411\n",
      "Ep 35: Batch #35 - Loss: 0.9652656316757202\n",
      "Ep 35: Batch #36 - Loss: 0.7137211561203003\n",
      "Ep 35: Batch #37 - Loss: 1.1536216735839844\n",
      "Ep 35: Batch #38 - Loss: 0.7591540813446045\n",
      "Ep 35: Batch #39 - Loss: 0.829484760761261\n",
      "Ep 35: Batch #40 - Loss: 0.7868401408195496\n",
      "Ep 35: Batch #41 - Loss: 0.7508221864700317\n",
      "Ep 35: Batch #42 - Loss: 0.733039915561676\n",
      "Ep 35: Batch #43 - Loss: 0.7993777394294739\n",
      "Ep 35: Batch #44 - Loss: 0.796966016292572\n",
      "Ep 35: Batch #45 - Loss: 0.6463453769683838\n",
      "Ep 35: Batch #46 - Loss: 0.8441255688667297\n",
      "Ep 35: Batch #47 - Loss: 0.9780551195144653\n",
      "Ep 35: Batch #48 - Loss: 1.370682954788208\n",
      "Ep 35: Batch #49 - Loss: 1.0304714441299438\n",
      "Ep 35: Batch #50 - Loss: 0.7145184874534607\n",
      "Ep 35: Batch #51 - Loss: 1.0116348266601562\n",
      "Ep 35: Batch #52 - Loss: 0.804548442363739\n",
      "Ep 35: Batch #53 - Loss: 0.8349291086196899\n",
      "Ep 35: Batch #54 - Loss: 0.7151269316673279\n",
      "Ep 35: Batch #55 - Loss: 0.7646109461784363\n",
      "Ep 35: Batch #56 - Loss: 1.278401255607605\n",
      "Ep 35: Batch #57 - Loss: 0.8623801469802856\n",
      "Ep 35: Batch #58 - Loss: 1.0161291360855103\n",
      "Ep 35: Batch #59 - Loss: 0.6902201771736145\n",
      "Ep 35: Batch #60 - Loss: 1.324177622795105\n",
      "Ep 35: Batch #61 - Loss: 0.6462265849113464\n",
      "Ep 35: Batch #62 - Loss: 0.7354531288146973\n",
      "Ep 35: Batch #63 - Loss: 1.0175970792770386\n",
      "Ep 35: Batch #64 - Loss: 9.441567420959473\n",
      "Ep 35: Batch #65 - Loss: 0.621281623840332\n",
      "Ep 35: Batch #66 - Loss: 0.8117918372154236\n",
      "Ep 35: Batch #67 - Loss: 0.9225897192955017\n",
      "Ep 35: Batch #68 - Loss: 0.922551691532135\n",
      "Ep 35: Batch #69 - Loss: 0.75700843334198\n",
      "Ep 35: Batch #70 - Loss: 0.7912833094596863\n",
      "Ep 35: Batch #71 - Loss: 0.6899457573890686\n",
      "Ep 35: Batch #72 - Loss: 0.8674311637878418\n",
      "Ep 35: Batch #73 - Loss: 0.9199864268302917\n",
      "Ep 35: Batch #74 - Loss: 0.7535501718521118\n",
      "Ep 35: Batch #75 - Loss: 0.7789380550384521\n",
      "Ep 35: Batch #76 - Loss: 1.106706976890564\n",
      "Ep 35: Batch #77 - Loss: 0.7464122176170349\n",
      "Ep 35: Batch #78 - Loss: 1.1761884689331055\n",
      "Ep 35: Batch #79 - Loss: 0.636407732963562\n",
      "Ep 35: Batch #80 - Loss: 0.8738259077072144\n",
      "Ep 35: Batch #81 - Loss: 1.6937304735183716\n",
      "Ep 35: Batch #82 - Loss: 0.8853009939193726\n",
      "Ep 35: Batch #83 - Loss: 1.7444113492965698\n",
      "Ep 35: Batch #84 - Loss: 0.7266725897789001\n",
      "Ep 35: Batch #85 - Loss: 0.9845276474952698\n",
      "Ep 35: Batch #86 - Loss: 0.721872866153717\n",
      "Ep 35: Batch #87 - Loss: 0.7241044044494629\n",
      "Ep 35: Batch #88 - Loss: 0.8152920007705688\n",
      "Ep 35: Batch #89 - Loss: 0.8915150165557861\n",
      "Ep 35: Batch #90 - Loss: 1.1731382608413696\n",
      "Ep 35: Batch #91 - Loss: 0.8160099387168884\n",
      "Ep 35: Batch #92 - Loss: 1.0436304807662964\n",
      "Ep 35: Batch #93 - Loss: 1.0469399690628052\n",
      "Ep 35: Batch #94 - Loss: 1.0648043155670166\n",
      "Ep 35: Batch #95 - Loss: 0.9330939054489136\n",
      "Ep 35: Batch #96 - Loss: 0.918029248714447\n",
      "Ep 35: Batch #97 - Loss: 0.7414969205856323\n",
      "Ep 35: Batch #98 - Loss: 0.7508530020713806\n",
      "Ep 35: Batch #99 - Loss: 0.9701083898544312\n",
      "Ep 35: Batch #100 - Loss: 0.6896005272865295\n",
      "Ep 35: Batch #101 - Loss: 1.060120940208435\n",
      "Ep 35: Batch #102 - Loss: 0.7935650944709778\n",
      "Ep 35: Batch #103 - Loss: 0.8014845252037048\n",
      "Ep 35: Batch #104 - Loss: 0.8130569458007812\n",
      "Ep 35: Batch #105 - Loss: 1.0432705879211426\n",
      "Ep 35: Batch #106 - Loss: 0.7707505226135254\n",
      "Ep 35: Batch #107 - Loss: 0.7702680826187134\n",
      "Ep 35: Batch #108 - Loss: 1.0485100746154785\n",
      "Ep 35: Batch #109 - Loss: 0.7730504870414734\n",
      "Ep 35: Batch #110 - Loss: 0.9345691204071045\n",
      "Ep 35: Batch #111 - Loss: 1.3950289487838745\n",
      "Ep 35: Batch #112 - Loss: 1.0626699924468994\n",
      "Ep 35: Batch #113 - Loss: 0.8287095427513123\n",
      "Ep 35: Batch #114 - Loss: 0.9170992970466614\n",
      "Ep 35: Batch #115 - Loss: 1.108459234237671\n",
      "Ep 35: Batch #116 - Loss: 0.6404176950454712\n",
      "Ep 35: Batch #117 - Loss: 0.8839157819747925\n",
      "Ep 35: Batch #118 - Loss: 0.5542038083076477\n",
      "Model saved in file: ./weights_autoencoder_low_LR/model_e35b118_1516651273.3958244.ckpt\n",
      "Ep 35: Batch #119 - Loss: 1.0400217771530151\n",
      "Ep 35: Batch #120 - Loss: 0.8102762699127197\n",
      "Ep 35: Batch #121 - Loss: 0.697265625\n",
      "Ep 35: Batch #122 - Loss: 0.8371323943138123\n",
      "Ep 35: Batch #123 - Loss: 0.8436650037765503\n",
      "Ep 35: Batch #124 - Loss: 0.6717994213104248\n",
      "Ep 35: Batch #125 - Loss: 2.7340993881225586\n",
      "Ep 35: Batch #126 - Loss: 1.2392704486846924\n",
      "Ep 35: Batch #127 - Loss: 0.7629389762878418\n",
      "Ep 35: Batch #128 - Loss: 1.1234688758850098\n",
      "Ep 35: Batch #129 - Loss: 0.8520052433013916\n",
      "Ep 35: Batch #130 - Loss: 0.7351475954055786\n",
      "Ep 35: Batch #131 - Loss: 1.0123403072357178\n",
      "Ep 35: Batch #132 - Loss: 0.8372491002082825\n",
      "Ep 35: Batch #133 - Loss: 0.8298720121383667\n",
      "Ep 35: Batch #134 - Loss: 0.7813730239868164\n",
      "Ep 35: Batch #135 - Loss: 0.9813594818115234\n",
      "Ep 35: Batch #136 - Loss: 1.1985172033309937\n",
      "Ep 35: Batch #137 - Loss: 0.9788941740989685\n",
      "Ep 35: Batch #138 - Loss: 1.0844173431396484\n",
      "Ep 35: Batch #139 - Loss: 0.9136450290679932\n",
      "Ep 35: Batch #140 - Loss: 1.0627225637435913\n",
      "Ep 35: Batch #141 - Loss: 1.372253656387329\n",
      "Ep 35: Batch #142 - Loss: 0.8064680099487305\n",
      "Ep 35: Batch #143 - Loss: 0.9815781712532043\n",
      "Ep 35: Batch #144 - Loss: 0.7317906618118286\n",
      "Ep 35: Batch #145 - Loss: 0.6883729100227356\n",
      "Ep 35: Batch #146 - Loss: 0.8954952359199524\n",
      "Ep 35: Batch #147 - Loss: 0.8775765299797058\n",
      "Ep 35: Batch #148 - Loss: 0.9926517009735107\n",
      "Ep 35: Batch #149 - Loss: 0.8687214851379395\n",
      "Ep 35: Batch #150 - Loss: 0.8951865434646606\n",
      "Ep 35: Batch #151 - Loss: 0.7352507710456848\n",
      "Ep 35: Batch #152 - Loss: 0.748104453086853\n",
      "Ep 35: Batch #153 - Loss: 1.1202725172042847\n",
      "Ep 35: Batch #154 - Loss: 0.7743154764175415\n",
      "Ep 35: Batch #155 - Loss: 0.8460570573806763\n",
      "Ep 35: Batch #156 - Loss: 1.0317509174346924\n",
      "Ep 35: Batch #157 - Loss: 0.7733811140060425\n",
      "Ep 35: Batch #158 - Loss: 0.8141986131668091\n",
      "Ep 35: Batch #159 - Loss: 0.8210849165916443\n",
      "Ep 35: Batch #160 - Loss: 0.9144688844680786\n",
      "Ep 35: Batch #161 - Loss: 0.8281311988830566\n",
      "Ep 35: Batch #162 - Loss: 0.9454279541969299\n",
      "Ep 35: Batch #163 - Loss: 0.9398465752601624\n",
      "Ep 35: Batch #164 - Loss: 0.7964325547218323\n",
      "Ep 35: Batch #165 - Loss: 1.5111340284347534\n",
      "Ep 35: Batch #166 - Loss: 0.6914809346199036\n",
      "Ep 35: Batch #167 - Loss: 1.10006844997406\n",
      "Ep 35: Batch #168 - Loss: 0.8740562796592712\n",
      "Ep 35: Batch #169 - Loss: 0.8130461573600769\n",
      "Ep 35: Batch #170 - Loss: 0.8166896104812622\n",
      "Ep 35: Batch #171 - Loss: 0.7939268946647644\n",
      "Ep 35: Batch #172 - Loss: 0.6426615118980408\n",
      "Ep 35: Batch #173 - Loss: 1.2147188186645508\n",
      "Ep 35: Batch #174 - Loss: 0.5878954529762268\n",
      "Ep 35: Batch #175 - Loss: 0.7884345650672913\n",
      "Ep 35: Batch #176 - Loss: 1.17189621925354\n",
      "Ep 35: Batch #177 - Loss: 0.8610488772392273\n",
      "Ep 35: Batch #178 - Loss: 0.7761159539222717\n",
      "Ep 35: Batch #179 - Loss: 0.9551389217376709\n",
      "Ep 35: Batch #180 - Loss: 0.8710954785346985\n",
      "Ep 35: Batch #181 - Loss: 1.0083976984024048\n",
      "Ep 35: Batch #182 - Loss: 0.774281919002533\n",
      "Ep 35: Batch #183 - Loss: 0.7772358059883118\n",
      "Ep 35: Batch #184 - Loss: 1.0786092281341553\n",
      "Ep 35: Batch #185 - Loss: 0.7691812515258789\n",
      "Ep 35: Batch #186 - Loss: 0.9838517308235168\n",
      "Ep 35: Batch #187 - Loss: 1.179092526435852\n",
      "Ep 35: Batch #188 - Loss: 1.3602992296218872\n",
      "Ep 35: Batch #189 - Loss: 0.7100499272346497\n",
      "Ep 35: Batch #190 - Loss: 0.7457998991012573\n",
      "Ep 35: Batch #191 - Loss: 1.0778535604476929\n",
      "Ep 35: Batch #192 - Loss: 0.6781619191169739\n",
      "Ep 35: Batch #193 - Loss: 0.7535260319709778\n",
      "Ep 35: Batch #194 - Loss: 0.707018256187439\n",
      "Ep 35: Batch #195 - Loss: 0.9963871836662292\n",
      "Ep 35: Batch #196 - Loss: 0.8768567442893982\n",
      "Ep 35: Batch #197 - Loss: 0.9144205451011658\n",
      "Ep 35: Batch #198 - Loss: 0.6894251108169556\n",
      "Ep 35: Batch #199 - Loss: 0.8745109438896179\n",
      "Ep 36: Batch #0 - Loss: 0.8056414723396301\n",
      "Ep 36: Batch #1 - Loss: 0.8888841867446899\n",
      "Ep 36: Batch #2 - Loss: 1.0193159580230713\n",
      "Ep 36: Batch #3 - Loss: 0.8754457831382751\n",
      "Ep 36: Batch #4 - Loss: 0.8014898896217346\n",
      "Ep 36: Batch #5 - Loss: 0.6764031052589417\n",
      "Ep 36: Batch #6 - Loss: 0.8899915814399719\n",
      "Ep 36: Batch #7 - Loss: 0.7111441493034363\n",
      "Ep 36: Batch #8 - Loss: 0.7432942986488342\n",
      "Ep 36: Batch #9 - Loss: 1.417837381362915\n",
      "Ep 36: Batch #10 - Loss: 1.0191092491149902\n",
      "Ep 36: Batch #11 - Loss: 0.6797696948051453\n",
      "Ep 36: Batch #12 - Loss: 1.5715363025665283\n",
      "Ep 36: Batch #13 - Loss: 0.6552030444145203\n",
      "Ep 36: Batch #14 - Loss: 0.7363486289978027\n",
      "Ep 36: Batch #15 - Loss: 1.2535638809204102\n",
      "Ep 36: Batch #16 - Loss: 1.2933297157287598\n",
      "Ep 36: Batch #17 - Loss: 0.8928143382072449\n",
      "Ep 36: Batch #18 - Loss: 0.9517359733581543\n",
      "Ep 36: Batch #19 - Loss: 0.6767941117286682\n",
      "Ep 36: Batch #20 - Loss: 0.6644934415817261\n",
      "Ep 36: Batch #21 - Loss: 1.223937749862671\n",
      "Ep 36: Batch #22 - Loss: 0.7348108291625977\n",
      "Ep 36: Batch #23 - Loss: 0.7547207474708557\n",
      "Ep 36: Batch #24 - Loss: 0.8329426050186157\n",
      "Ep 36: Batch #25 - Loss: 0.7261337637901306\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 36: Batch #26 - Loss: 0.7429773211479187\n",
      "Ep 36: Batch #27 - Loss: 1.3675031661987305\n",
      "Ep 36: Batch #28 - Loss: 0.8787734508514404\n",
      "Ep 36: Batch #29 - Loss: 0.9062045812606812\n",
      "Ep 36: Batch #30 - Loss: 1.2135454416275024\n",
      "Ep 36: Batch #31 - Loss: 0.6807584166526794\n",
      "Ep 36: Batch #32 - Loss: 0.7585564255714417\n",
      "Ep 36: Batch #33 - Loss: 0.816409707069397\n",
      "Ep 36: Batch #34 - Loss: 0.7940598726272583\n",
      "Ep 36: Batch #35 - Loss: 0.9634675979614258\n",
      "Ep 36: Batch #36 - Loss: 0.7125471234321594\n",
      "Ep 36: Batch #37 - Loss: 1.1522294282913208\n",
      "Ep 36: Batch #38 - Loss: 0.7576450109481812\n",
      "Ep 36: Batch #39 - Loss: 0.8284127712249756\n",
      "Ep 36: Batch #40 - Loss: 0.7854660749435425\n",
      "Ep 36: Batch #41 - Loss: 0.7494470477104187\n",
      "Ep 36: Batch #42 - Loss: 0.7319093942642212\n",
      "Ep 36: Batch #43 - Loss: 0.7981113195419312\n",
      "Ep 36: Batch #44 - Loss: 0.7956503629684448\n",
      "Ep 36: Batch #45 - Loss: 0.6449501514434814\n",
      "Ep 36: Batch #46 - Loss: 0.8426751494407654\n",
      "Ep 36: Batch #47 - Loss: 0.9762089848518372\n",
      "Ep 36: Batch #48 - Loss: 1.3687949180603027\n",
      "Ep 36: Batch #49 - Loss: 1.0289082527160645\n",
      "Ep 36: Batch #50 - Loss: 0.7135891914367676\n",
      "Ep 36: Batch #51 - Loss: 1.0098556280136108\n",
      "Ep 36: Batch #52 - Loss: 0.8034736514091492\n",
      "Ep 36: Batch #53 - Loss: 0.833573579788208\n",
      "Ep 36: Batch #54 - Loss: 0.7140654921531677\n",
      "Ep 36: Batch #55 - Loss: 0.7631835341453552\n",
      "Ep 36: Batch #56 - Loss: 1.276562213897705\n",
      "Ep 36: Batch #57 - Loss: 0.8607432842254639\n",
      "Ep 36: Batch #58 - Loss: 1.014349341392517\n",
      "Ep 36: Batch #59 - Loss: 0.6891700625419617\n",
      "Ep 36: Batch #60 - Loss: 1.32257878780365\n",
      "Ep 36: Batch #61 - Loss: 0.6451163291931152\n",
      "Ep 36: Batch #62 - Loss: 0.7340598106384277\n",
      "Ep 36: Batch #63 - Loss: 1.0159001350402832\n",
      "Ep 36: Batch #64 - Loss: 9.439881324768066\n",
      "Ep 36: Batch #65 - Loss: 0.6202923655509949\n",
      "Ep 36: Batch #66 - Loss: 0.8101099133491516\n",
      "Ep 36: Batch #67 - Loss: 0.9212283492088318\n",
      "Ep 36: Batch #68 - Loss: 0.9209916591644287\n",
      "Ep 36: Batch #69 - Loss: 0.7556870579719543\n",
      "Ep 36: Batch #70 - Loss: 0.7896159291267395\n",
      "Ep 36: Batch #71 - Loss: 0.6887658834457397\n",
      "Ep 36: Batch #72 - Loss: 0.8659738898277283\n",
      "Ep 36: Batch #73 - Loss: 0.9181829690933228\n",
      "Ep 36: Batch #74 - Loss: 0.752166211605072\n",
      "Ep 36: Batch #75 - Loss: 0.777714192867279\n",
      "Ep 36: Batch #76 - Loss: 1.1054614782333374\n",
      "Ep 36: Batch #77 - Loss: 0.7451289892196655\n",
      "Ep 36: Batch #78 - Loss: 1.1743959188461304\n",
      "Ep 36: Batch #79 - Loss: 0.6352333426475525\n",
      "Ep 36: Batch #80 - Loss: 0.8722421526908875\n",
      "Ep 36: Batch #81 - Loss: 1.6921504735946655\n",
      "Ep 36: Batch #82 - Loss: 0.883918821811676\n",
      "Ep 36: Batch #83 - Loss: 1.7433218955993652\n",
      "Ep 36: Batch #84 - Loss: 0.7253295183181763\n",
      "Ep 36: Batch #85 - Loss: 0.9832428097724915\n",
      "Ep 36: Batch #86 - Loss: 0.7204381823539734\n",
      "Ep 36: Batch #87 - Loss: 0.7229118943214417\n",
      "Ep 36: Batch #88 - Loss: 0.8138172626495361\n",
      "Ep 36: Batch #89 - Loss: 0.8905683755874634\n",
      "Ep 36: Batch #90 - Loss: 1.1710220575332642\n",
      "Ep 36: Batch #91 - Loss: 0.8144873976707458\n",
      "Ep 36: Batch #92 - Loss: 1.0418950319290161\n",
      "Ep 36: Batch #93 - Loss: 1.0450141429901123\n",
      "Ep 36: Batch #94 - Loss: 1.0630849599838257\n",
      "Ep 36: Batch #95 - Loss: 0.9315769076347351\n",
      "Ep 36: Batch #96 - Loss: 0.9165549278259277\n",
      "Ep 36: Batch #97 - Loss: 0.7401540279388428\n",
      "Ep 36: Batch #98 - Loss: 0.7494840025901794\n",
      "Ep 36: Batch #99 - Loss: 0.9687711596488953\n",
      "Ep 36: Batch #100 - Loss: 0.6883018016815186\n",
      "Ep 36: Batch #101 - Loss: 1.0586096048355103\n",
      "Ep 36: Batch #102 - Loss: 0.7923216819763184\n",
      "Ep 36: Batch #103 - Loss: 0.8002028465270996\n",
      "Ep 36: Batch #104 - Loss: 0.811712920665741\n",
      "Ep 36: Batch #105 - Loss: 1.041669487953186\n",
      "Ep 36: Batch #106 - Loss: 0.7694559693336487\n",
      "Ep 36: Batch #107 - Loss: 0.7688316106796265\n",
      "Ep 36: Batch #108 - Loss: 1.046828269958496\n",
      "Ep 36: Batch #109 - Loss: 0.7718579769134521\n",
      "Ep 36: Batch #110 - Loss: 0.9328356385231018\n",
      "Ep 36: Batch #111 - Loss: 1.393241286277771\n",
      "Ep 36: Batch #112 - Loss: 1.060878038406372\n",
      "Ep 36: Batch #113 - Loss: 0.8273147940635681\n",
      "Ep 36: Batch #114 - Loss: 0.9155454635620117\n",
      "Ep 36: Batch #115 - Loss: 1.1069414615631104\n",
      "Ep 36: Batch #116 - Loss: 0.6395796537399292\n",
      "Ep 36: Batch #117 - Loss: 0.8826531171798706\n",
      "Ep 36: Batch #118 - Loss: 0.553070068359375\n",
      "Model saved in file: ./weights_autoencoder_low_LR/model_e36b118_1516651273.5352795.ckpt\n",
      "Ep 36: Batch #119 - Loss: 1.038499355316162\n",
      "Ep 36: Batch #120 - Loss: 0.8091480135917664\n",
      "Ep 36: Batch #121 - Loss: 0.6959834694862366\n",
      "Ep 36: Batch #122 - Loss: 0.8357287049293518\n",
      "Ep 36: Batch #123 - Loss: 0.8423699736595154\n",
      "Ep 36: Batch #124 - Loss: 0.6708167195320129\n",
      "Ep 36: Batch #125 - Loss: 2.7324230670928955\n",
      "Ep 36: Batch #126 - Loss: 1.237618088722229\n",
      "Ep 36: Batch #127 - Loss: 0.7613819241523743\n",
      "Ep 36: Batch #128 - Loss: 1.121435284614563\n",
      "Ep 36: Batch #129 - Loss: 0.8505052924156189\n",
      "Ep 36: Batch #130 - Loss: 0.7338102459907532\n",
      "Ep 36: Batch #131 - Loss: 1.0104418992996216\n",
      "Ep 36: Batch #132 - Loss: 0.835713267326355\n",
      "Ep 36: Batch #133 - Loss: 0.8285079598426819\n",
      "Ep 36: Batch #134 - Loss: 0.779981255531311\n",
      "Ep 36: Batch #135 - Loss: 0.9797448515892029\n",
      "Ep 36: Batch #136 - Loss: 1.1965787410736084\n",
      "Ep 36: Batch #137 - Loss: 0.9772545099258423\n",
      "Ep 36: Batch #138 - Loss: 1.0828253030776978\n",
      "Ep 36: Batch #139 - Loss: 0.9121083617210388\n",
      "Ep 36: Batch #140 - Loss: 1.0611611604690552\n",
      "Ep 36: Batch #141 - Loss: 1.3706296682357788\n",
      "Ep 36: Batch #142 - Loss: 0.8051811456680298\n",
      "Ep 36: Batch #143 - Loss: 0.9797643423080444\n",
      "Ep 36: Batch #144 - Loss: 0.7304852604866028\n",
      "Ep 36: Batch #145 - Loss: 0.687210202217102\n",
      "Ep 36: Batch #146 - Loss: 0.894203782081604\n",
      "Ep 36: Batch #147 - Loss: 0.8758355975151062\n",
      "Ep 36: Batch #148 - Loss: 0.9910153746604919\n",
      "Ep 36: Batch #149 - Loss: 0.8671090602874756\n",
      "Ep 36: Batch #150 - Loss: 0.8938674926757812\n",
      "Ep 36: Batch #151 - Loss: 0.7343007326126099\n",
      "Ep 36: Batch #152 - Loss: 0.747078001499176\n",
      "Ep 36: Batch #153 - Loss: 1.118578553199768\n",
      "Ep 36: Batch #154 - Loss: 0.7731384634971619\n",
      "Ep 36: Batch #155 - Loss: 0.844555675983429\n",
      "Ep 36: Batch #156 - Loss: 1.0301544666290283\n",
      "Ep 36: Batch #157 - Loss: 0.7721169590950012\n",
      "Ep 36: Batch #158 - Loss: 0.8131616711616516\n",
      "Ep 36: Batch #159 - Loss: 0.819669246673584\n",
      "Ep 36: Batch #160 - Loss: 0.913229763507843\n",
      "Ep 36: Batch #161 - Loss: 0.8267704844474792\n",
      "Ep 36: Batch #162 - Loss: 0.9439599514007568\n",
      "Ep 36: Batch #163 - Loss: 0.9386973977088928\n",
      "Ep 36: Batch #164 - Loss: 0.7951354384422302\n",
      "Ep 36: Batch #165 - Loss: 1.5099961757659912\n",
      "Ep 36: Batch #166 - Loss: 0.6901125311851501\n",
      "Ep 36: Batch #167 - Loss: 1.0986260175704956\n",
      "Ep 36: Batch #168 - Loss: 0.8725578188896179\n",
      "Ep 36: Batch #169 - Loss: 0.8117302656173706\n",
      "Ep 36: Batch #170 - Loss: 0.8153056502342224\n",
      "Ep 36: Batch #171 - Loss: 0.7924240827560425\n",
      "Ep 36: Batch #172 - Loss: 0.6416841149330139\n",
      "Ep 36: Batch #173 - Loss: 1.2127323150634766\n",
      "Ep 36: Batch #174 - Loss: 0.5868638753890991\n",
      "Ep 36: Batch #175 - Loss: 0.7872692346572876\n",
      "Ep 36: Batch #176 - Loss: 1.1703531742095947\n",
      "Ep 36: Batch #177 - Loss: 0.859655499458313\n",
      "Ep 36: Batch #178 - Loss: 0.7746826410293579\n",
      "Ep 36: Batch #179 - Loss: 0.9534487128257751\n",
      "Ep 36: Batch #180 - Loss: 0.8693434000015259\n",
      "Ep 36: Batch #181 - Loss: 1.0065619945526123\n",
      "Ep 36: Batch #182 - Loss: 0.7731490731239319\n",
      "Ep 36: Batch #183 - Loss: 0.7758330702781677\n",
      "Ep 36: Batch #184 - Loss: 1.0774110555648804\n",
      "Ep 36: Batch #185 - Loss: 0.7680193781852722\n",
      "Ep 36: Batch #186 - Loss: 0.9820216298103333\n",
      "Ep 36: Batch #187 - Loss: 1.1776467561721802\n",
      "Ep 36: Batch #188 - Loss: 1.3588964939117432\n",
      "Ep 36: Batch #189 - Loss: 0.7090774774551392\n",
      "Ep 36: Batch #190 - Loss: 0.7445723414421082\n",
      "Ep 36: Batch #191 - Loss: 1.0763987302780151\n",
      "Ep 36: Batch #192 - Loss: 0.6772086024284363\n",
      "Ep 36: Batch #193 - Loss: 0.7521491646766663\n",
      "Ep 36: Batch #194 - Loss: 0.705812931060791\n",
      "Ep 36: Batch #195 - Loss: 0.9948522448539734\n",
      "Ep 36: Batch #196 - Loss: 0.875526487827301\n",
      "Ep 36: Batch #197 - Loss: 0.9129972457885742\n",
      "Ep 36: Batch #198 - Loss: 0.6881694197654724\n",
      "Ep 36: Batch #199 - Loss: 0.873073399066925\n",
      "Ep 37: Batch #0 - Loss: 0.8040825128555298\n",
      "Ep 37: Batch #1 - Loss: 0.8874585628509521\n",
      "Ep 37: Batch #2 - Loss: 1.0181165933609009\n",
      "Ep 37: Batch #3 - Loss: 0.8741335868835449\n",
      "Ep 37: Batch #4 - Loss: 0.8000699877738953\n",
      "Ep 37: Batch #5 - Loss: 0.67545086145401\n",
      "Ep 37: Batch #6 - Loss: 0.8886818885803223\n",
      "Ep 37: Batch #7 - Loss: 0.7100524306297302\n",
      "Ep 37: Batch #8 - Loss: 0.7421728372573853\n",
      "Ep 37: Batch #9 - Loss: 1.415771484375\n",
      "Ep 37: Batch #10 - Loss: 1.0175573825836182\n",
      "Ep 37: Batch #11 - Loss: 0.6786324381828308\n",
      "Ep 37: Batch #12 - Loss: 1.5702265501022339\n",
      "Ep 37: Batch #13 - Loss: 0.6543486714363098\n",
      "Ep 37: Batch #14 - Loss: 0.7352460026741028\n",
      "Ep 37: Batch #15 - Loss: 1.2518471479415894\n",
      "Ep 37: Batch #16 - Loss: 1.291227102279663\n",
      "Ep 37: Batch #17 - Loss: 0.8913429379463196\n",
      "Ep 37: Batch #18 - Loss: 0.9507992267608643\n",
      "Ep 37: Batch #19 - Loss: 0.6757396459579468\n",
      "Ep 37: Batch #20 - Loss: 0.663339376449585\n",
      "Ep 37: Batch #21 - Loss: 1.2225010395050049\n",
      "Ep 37: Batch #22 - Loss: 0.7337583303451538\n",
      "Ep 37: Batch #23 - Loss: 0.753282368183136\n",
      "Ep 37: Batch #24 - Loss: 0.8317815065383911\n",
      "Ep 37: Batch #25 - Loss: 0.7247719764709473\n",
      "Ep 37: Batch #26 - Loss: 0.7415491342544556\n",
      "Ep 37: Batch #27 - Loss: 1.3656740188598633\n",
      "Ep 37: Batch #28 - Loss: 0.8774546980857849\n",
      "Ep 37: Batch #29 - Loss: 0.9045941829681396\n",
      "Ep 37: Batch #30 - Loss: 1.2120320796966553\n",
      "Ep 37: Batch #31 - Loss: 0.6798451542854309\n",
      "Ep 37: Batch #32 - Loss: 0.7572364807128906\n",
      "Ep 37: Batch #33 - Loss: 0.815315306186676\n",
      "Ep 37: Batch #34 - Loss: 0.792797863483429\n",
      "Ep 37: Batch #35 - Loss: 0.9616922736167908\n",
      "Ep 37: Batch #36 - Loss: 0.7113752365112305\n",
      "Ep 37: Batch #37 - Loss: 1.1508471965789795\n",
      "Ep 37: Batch #38 - Loss: 0.7561596035957336\n",
      "Ep 37: Batch #39 - Loss: 0.8273481726646423\n",
      "Ep 37: Batch #40 - Loss: 0.7841069102287292\n",
      "Ep 37: Batch #41 - Loss: 0.7480812072753906\n",
      "Ep 37: Batch #42 - Loss: 0.7307828068733215\n",
      "Ep 37: Batch #43 - Loss: 0.7968617677688599\n",
      "Ep 37: Batch #44 - Loss: 0.794337809085846\n",
      "Ep 37: Batch #45 - Loss: 0.6435815691947937\n",
      "Ep 37: Batch #46 - Loss: 0.8412462472915649\n",
      "Ep 37: Batch #47 - Loss: 0.9743819236755371\n",
      "Ep 37: Batch #48 - Loss: 1.3669424057006836\n",
      "Ep 37: Batch #49 - Loss: 1.0273311138153076\n",
      "Ep 37: Batch #50 - Loss: 0.7126692533493042\n",
      "Ep 37: Batch #51 - Loss: 1.008070707321167\n",
      "Ep 37: Batch #52 - Loss: 0.8024108409881592\n",
      "Ep 37: Batch #53 - Loss: 0.8322339653968811\n",
      "Ep 37: Batch #54 - Loss: 0.7130158543586731\n",
      "Ep 37: Batch #55 - Loss: 0.7617729306221008\n",
      "Ep 37: Batch #56 - Loss: 1.274705410003662\n",
      "Ep 37: Batch #57 - Loss: 0.8591257929801941\n",
      "Ep 37: Batch #58 - Loss: 1.0125796794891357\n",
      "Ep 37: Batch #59 - Loss: 0.6881368160247803\n",
      "Ep 37: Batch #60 - Loss: 1.321001648902893\n",
      "Ep 37: Batch #61 - Loss: 0.6440213322639465\n",
      "Ep 37: Batch #62 - Loss: 0.7326868772506714\n",
      "Ep 37: Batch #63 - Loss: 1.0142298936843872\n",
      "Ep 37: Batch #64 - Loss: 9.438302993774414\n",
      "Ep 37: Batch #65 - Loss: 0.6193061470985413\n",
      "Ep 37: Batch #66 - Loss: 0.8084522485733032\n",
      "Ep 37: Batch #67 - Loss: 0.919880211353302\n",
      "Ep 37: Batch #68 - Loss: 0.9194439649581909\n",
      "Ep 37: Batch #69 - Loss: 0.7543814778327942\n",
      "Ep 37: Batch #70 - Loss: 0.7879711389541626\n",
      "Ep 37: Batch #71 - Loss: 0.687605082988739\n",
      "Ep 37: Batch #72 - Loss: 0.8645336031913757\n",
      "Ep 37: Batch #73 - Loss: 0.9163843393325806\n",
      "Ep 37: Batch #74 - Loss: 0.7507873177528381\n",
      "Ep 37: Batch #75 - Loss: 0.7765105366706848\n",
      "Ep 37: Batch #76 - Loss: 1.1042263507843018\n",
      "Ep 37: Batch #77 - Loss: 0.743847668170929\n",
      "Ep 37: Batch #78 - Loss: 1.1726202964782715\n",
      "Ep 37: Batch #79 - Loss: 0.6340785026550293\n",
      "Ep 37: Batch #80 - Loss: 0.8706660866737366\n",
      "Ep 37: Batch #81 - Loss: 1.6905934810638428\n",
      "Ep 37: Batch #82 - Loss: 0.8825636506080627\n",
      "Ep 37: Batch #83 - Loss: 1.7422404289245605\n",
      "Ep 37: Batch #84 - Loss: 0.7239982485771179\n",
      "Ep 37: Batch #85 - Loss: 0.9819799661636353\n",
      "Ep 37: Batch #86 - Loss: 0.719017744064331\n",
      "Ep 37: Batch #87 - Loss: 0.721720814704895\n",
      "Ep 37: Batch #88 - Loss: 0.8123499155044556\n",
      "Ep 37: Batch #89 - Loss: 0.8896271586418152\n",
      "Ep 37: Batch #90 - Loss: 1.1689261198043823\n",
      "Ep 37: Batch #91 - Loss: 0.8129755258560181\n",
      "Ep 37: Batch #92 - Loss: 1.0401763916015625\n",
      "Ep 37: Batch #93 - Loss: 1.0431044101715088\n",
      "Ep 37: Batch #94 - Loss: 1.061371088027954\n",
      "Ep 37: Batch #95 - Loss: 0.9300640821456909\n",
      "Ep 37: Batch #96 - Loss: 0.9150537252426147\n",
      "Ep 37: Batch #97 - Loss: 0.73882657289505\n",
      "Ep 37: Batch #98 - Loss: 0.7481347918510437\n",
      "Ep 37: Batch #99 - Loss: 0.9674543142318726\n",
      "Ep 37: Batch #100 - Loss: 0.6870086193084717\n",
      "Ep 37: Batch #101 - Loss: 1.0571097135543823\n",
      "Ep 37: Batch #102 - Loss: 0.7910847663879395\n",
      "Ep 37: Batch #103 - Loss: 0.7989287972450256\n",
      "Ep 37: Batch #104 - Loss: 0.8103858232498169\n",
      "Ep 37: Batch #105 - Loss: 1.0400727987289429\n",
      "Ep 37: Batch #106 - Loss: 0.7681759595870972\n",
      "Ep 37: Batch #107 - Loss: 0.7674201130867004\n",
      "Ep 37: Batch #108 - Loss: 1.045168399810791\n",
      "Ep 37: Batch #109 - Loss: 0.7706786394119263\n",
      "Ep 37: Batch #110 - Loss: 0.9311222434043884\n",
      "Ep 37: Batch #111 - Loss: 1.3914626836776733\n",
      "Ep 37: Batch #112 - Loss: 1.0591024160385132\n",
      "Ep 37: Batch #113 - Loss: 0.825934112071991\n",
      "Ep 37: Batch #114 - Loss: 0.9139983654022217\n",
      "Ep 37: Batch #115 - Loss: 1.105431318283081\n",
      "Ep 37: Batch #116 - Loss: 0.6387470364570618\n",
      "Ep 37: Batch #117 - Loss: 0.881415069103241\n",
      "Ep 37: Batch #118 - Loss: 0.5519524812698364\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved in file: ./weights_autoencoder_low_LR/model_e37b118_1516651273.6721435.ckpt\n",
      "Ep 37: Batch #119 - Loss: 1.0369913578033447\n",
      "Ep 37: Batch #120 - Loss: 0.8080202341079712\n",
      "Ep 37: Batch #121 - Loss: 0.6947095394134521\n",
      "Ep 37: Batch #122 - Loss: 0.8343449831008911\n",
      "Ep 37: Batch #123 - Loss: 0.8410757780075073\n",
      "Ep 37: Batch #124 - Loss: 0.6698437333106995\n",
      "Ep 37: Batch #125 - Loss: 2.730766534805298\n",
      "Ep 37: Batch #126 - Loss: 1.2359941005706787\n",
      "Ep 37: Batch #127 - Loss: 0.7598456144332886\n",
      "Ep 37: Batch #128 - Loss: 1.1194185018539429\n",
      "Ep 37: Batch #129 - Loss: 0.8490250706672668\n",
      "Ep 37: Batch #130 - Loss: 0.7324891090393066\n",
      "Ep 37: Batch #131 - Loss: 1.0085605382919312\n",
      "Ep 37: Batch #132 - Loss: 0.8341937065124512\n",
      "Ep 37: Batch #133 - Loss: 0.8271462917327881\n",
      "Ep 37: Batch #134 - Loss: 0.7786065340042114\n",
      "Ep 37: Batch #135 - Loss: 0.9781277775764465\n",
      "Ep 37: Batch #136 - Loss: 1.194653034210205\n",
      "Ep 37: Batch #137 - Loss: 0.9756313562393188\n",
      "Ep 37: Batch #138 - Loss: 1.0812427997589111\n",
      "Ep 37: Batch #139 - Loss: 0.9105954766273499\n",
      "Ep 37: Batch #140 - Loss: 1.05962073802948\n",
      "Ep 37: Batch #141 - Loss: 1.3690228462219238\n",
      "Ep 37: Batch #142 - Loss: 0.8039050698280334\n",
      "Ep 37: Batch #143 - Loss: 0.9779738187789917\n",
      "Ep 37: Batch #144 - Loss: 0.7292004823684692\n",
      "Ep 37: Batch #145 - Loss: 0.6860631704330444\n",
      "Ep 37: Batch #146 - Loss: 0.8929183483123779\n",
      "Ep 37: Batch #147 - Loss: 0.874110996723175\n",
      "Ep 37: Batch #148 - Loss: 0.989387571811676\n",
      "Ep 37: Batch #149 - Loss: 0.8655160069465637\n",
      "Ep 37: Batch #150 - Loss: 0.8925426602363586\n",
      "Ep 37: Batch #151 - Loss: 0.7333595156669617\n",
      "Ep 37: Batch #152 - Loss: 0.7460657358169556\n",
      "Ep 37: Batch #153 - Loss: 1.1168946027755737\n",
      "Ep 37: Batch #154 - Loss: 0.7719701528549194\n",
      "Ep 37: Batch #155 - Loss: 0.8430805206298828\n",
      "Ep 37: Batch #156 - Loss: 1.028578281402588\n",
      "Ep 37: Batch #157 - Loss: 0.7708647847175598\n",
      "Ep 37: Batch #158 - Loss: 0.8121369481086731\n",
      "Ep 37: Batch #159 - Loss: 0.8182679414749146\n",
      "Ep 37: Batch #160 - Loss: 0.9119974374771118\n",
      "Ep 37: Batch #161 - Loss: 0.8254207968711853\n",
      "Ep 37: Batch #162 - Loss: 0.9424963593482971\n",
      "Ep 37: Batch #163 - Loss: 0.9375623464584351\n",
      "Ep 37: Batch #164 - Loss: 0.793846845626831\n",
      "Ep 37: Batch #165 - Loss: 1.5088791847229004\n",
      "Ep 37: Batch #166 - Loss: 0.6887674331665039\n",
      "Ep 37: Batch #167 - Loss: 1.0971955060958862\n",
      "Ep 37: Batch #168 - Loss: 0.871076762676239\n",
      "Ep 37: Batch #169 - Loss: 0.8104328513145447\n",
      "Ep 37: Batch #170 - Loss: 0.8139299750328064\n",
      "Ep 37: Batch #171 - Loss: 0.7909380793571472\n",
      "Ep 37: Batch #172 - Loss: 0.6407074332237244\n",
      "Ep 37: Batch #173 - Loss: 1.2107598781585693\n",
      "Ep 37: Batch #174 - Loss: 0.5858493447303772\n",
      "Ep 37: Batch #175 - Loss: 0.7861216068267822\n",
      "Ep 37: Batch #176 - Loss: 1.168785810470581\n",
      "Ep 37: Batch #177 - Loss: 0.8582751154899597\n",
      "Ep 37: Batch #178 - Loss: 0.7732715010643005\n",
      "Ep 37: Batch #179 - Loss: 0.951755702495575\n",
      "Ep 37: Batch #180 - Loss: 0.867608368396759\n",
      "Ep 37: Batch #181 - Loss: 1.0047404766082764\n",
      "Ep 37: Batch #182 - Loss: 0.7720312476158142\n",
      "Ep 37: Batch #183 - Loss: 0.7744457125663757\n",
      "Ep 37: Batch #184 - Loss: 1.076226830482483\n",
      "Ep 37: Batch #185 - Loss: 0.7668754458427429\n",
      "Ep 37: Batch #186 - Loss: 0.98019939661026\n",
      "Ep 37: Batch #187 - Loss: 1.1762351989746094\n",
      "Ep 37: Batch #188 - Loss: 1.3575252294540405\n",
      "Ep 37: Batch #189 - Loss: 0.7081202864646912\n",
      "Ep 37: Batch #190 - Loss: 0.7433627843856812\n",
      "Ep 37: Batch #191 - Loss: 1.0749439001083374\n",
      "Ep 37: Batch #192 - Loss: 0.6762676239013672\n",
      "Ep 37: Batch #193 - Loss: 0.7507807612419128\n",
      "Ep 37: Batch #194 - Loss: 0.7046165466308594\n",
      "Ep 37: Batch #195 - Loss: 0.9933297634124756\n",
      "Ep 37: Batch #196 - Loss: 0.8742078542709351\n",
      "Ep 37: Batch #197 - Loss: 0.9115791916847229\n",
      "Ep 37: Batch #198 - Loss: 0.6869174242019653\n",
      "Ep 37: Batch #199 - Loss: 0.8716535568237305\n",
      "Ep 38: Batch #0 - Loss: 0.802541196346283\n",
      "Ep 38: Batch #1 - Loss: 0.8860523104667664\n",
      "Ep 38: Batch #2 - Loss: 1.016883134841919\n",
      "Ep 38: Batch #3 - Loss: 0.8728326559066772\n",
      "Ep 38: Batch #4 - Loss: 0.7986642122268677\n",
      "Ep 38: Batch #5 - Loss: 0.6745103001594543\n",
      "Ep 38: Batch #6 - Loss: 0.8873846530914307\n",
      "Ep 38: Batch #7 - Loss: 0.708977222442627\n",
      "Ep 38: Batch #8 - Loss: 0.7410638332366943\n",
      "Ep 38: Batch #9 - Loss: 1.4137130975723267\n",
      "Ep 38: Batch #10 - Loss: 1.0160322189331055\n",
      "Ep 38: Batch #11 - Loss: 0.6775045394897461\n",
      "Ep 38: Batch #12 - Loss: 1.5689074993133545\n",
      "Ep 38: Batch #13 - Loss: 0.6535046696662903\n",
      "Ep 38: Batch #14 - Loss: 0.7341521978378296\n",
      "Ep 38: Batch #15 - Loss: 1.250154733657837\n",
      "Ep 38: Batch #16 - Loss: 1.28915274143219\n",
      "Ep 38: Batch #17 - Loss: 0.8898872137069702\n",
      "Ep 38: Batch #18 - Loss: 0.9498438835144043\n",
      "Ep 38: Batch #19 - Loss: 0.674701452255249\n",
      "Ep 38: Batch #20 - Loss: 0.6621953248977661\n",
      "Ep 38: Batch #21 - Loss: 1.221077799797058\n",
      "Ep 38: Batch #22 - Loss: 0.7327108979225159\n",
      "Ep 38: Batch #23 - Loss: 0.7518705725669861\n",
      "Ep 38: Batch #24 - Loss: 0.8306338787078857\n",
      "Ep 38: Batch #25 - Loss: 0.7234337329864502\n",
      "Ep 38: Batch #26 - Loss: 0.7401463389396667\n",
      "Ep 38: Batch #27 - Loss: 1.3638554811477661\n",
      "Ep 38: Batch #28 - Loss: 0.8761528134346008\n",
      "Ep 38: Batch #29 - Loss: 0.9029953479766846\n",
      "Ep 38: Batch #30 - Loss: 1.2105340957641602\n",
      "Ep 38: Batch #31 - Loss: 0.6789475083351135\n",
      "Ep 38: Batch #32 - Loss: 0.7559268474578857\n",
      "Ep 38: Batch #33 - Loss: 0.8142364025115967\n",
      "Ep 38: Batch #34 - Loss: 0.7915521264076233\n",
      "Ep 38: Batch #35 - Loss: 0.9599318504333496\n",
      "Ep 38: Batch #36 - Loss: 0.7102048397064209\n",
      "Ep 38: Batch #37 - Loss: 1.1494675874710083\n",
      "Ep 38: Batch #38 - Loss: 0.7546979188919067\n",
      "Ep 38: Batch #39 - Loss: 0.8262912034988403\n",
      "Ep 38: Batch #40 - Loss: 0.7827726602554321\n",
      "Ep 38: Batch #41 - Loss: 0.7467232942581177\n",
      "Ep 38: Batch #42 - Loss: 0.729658842086792\n",
      "Ep 38: Batch #43 - Loss: 0.7956264019012451\n",
      "Ep 38: Batch #44 - Loss: 0.7930341958999634\n",
      "Ep 38: Batch #45 - Loss: 0.6422411203384399\n",
      "Ep 38: Batch #46 - Loss: 0.8398289680480957\n",
      "Ep 38: Batch #47 - Loss: 0.9725743532180786\n",
      "Ep 38: Batch #48 - Loss: 1.3651162385940552\n",
      "Ep 38: Batch #49 - Loss: 1.0257396697998047\n",
      "Ep 38: Batch #50 - Loss: 0.7117611765861511\n",
      "Ep 38: Batch #51 - Loss: 1.0062881708145142\n",
      "Ep 38: Batch #52 - Loss: 0.8013578057289124\n",
      "Ep 38: Batch #53 - Loss: 0.8309020400047302\n",
      "Ep 38: Batch #54 - Loss: 0.7119737863540649\n",
      "Ep 38: Batch #55 - Loss: 0.7603731155395508\n",
      "Ep 38: Batch #56 - Loss: 1.2728593349456787\n",
      "Ep 38: Batch #57 - Loss: 0.8575340509414673\n",
      "Ep 38: Batch #58 - Loss: 1.0108274221420288\n",
      "Ep 38: Batch #59 - Loss: 0.6871227025985718\n",
      "Ep 38: Batch #60 - Loss: 1.3194544315338135\n",
      "Ep 38: Batch #61 - Loss: 0.6429402232170105\n",
      "Ep 38: Batch #62 - Loss: 0.7313284277915955\n",
      "Ep 38: Batch #63 - Loss: 1.0125802755355835\n",
      "Ep 38: Batch #64 - Loss: 9.436826705932617\n",
      "Ep 38: Batch #65 - Loss: 0.6183292269706726\n",
      "Ep 38: Batch #66 - Loss: 0.8068187832832336\n",
      "Ep 38: Batch #67 - Loss: 0.9185473918914795\n",
      "Ep 38: Batch #68 - Loss: 0.9179043173789978\n",
      "Ep 38: Batch #69 - Loss: 0.7530906796455383\n",
      "Ep 38: Batch #70 - Loss: 0.7863450646400452\n",
      "Ep 38: Batch #71 - Loss: 0.6864530444145203\n",
      "Ep 38: Batch #72 - Loss: 0.8631070256233215\n",
      "Ep 38: Batch #73 - Loss: 0.9145951867103577\n",
      "Ep 38: Batch #74 - Loss: 0.749418318271637\n",
      "Ep 38: Batch #75 - Loss: 0.7753269076347351\n",
      "Ep 38: Batch #76 - Loss: 1.1030035018920898\n",
      "Ep 38: Batch #77 - Loss: 0.7425693273544312\n",
      "Ep 38: Batch #78 - Loss: 1.1708546876907349\n",
      "Ep 38: Batch #79 - Loss: 0.6329391598701477\n",
      "Ep 38: Batch #80 - Loss: 0.8691102266311646\n",
      "Ep 38: Batch #81 - Loss: 1.6890710592269897\n",
      "Ep 38: Batch #82 - Loss: 0.8812388181686401\n",
      "Ep 38: Batch #83 - Loss: 1.7411644458770752\n",
      "Ep 38: Batch #84 - Loss: 0.7226728796958923\n",
      "Ep 38: Batch #85 - Loss: 0.9807374477386475\n",
      "Ep 38: Batch #86 - Loss: 0.7176108360290527\n",
      "Ep 38: Batch #87 - Loss: 0.7205355167388916\n",
      "Ep 38: Batch #88 - Loss: 0.8108692765235901\n",
      "Ep 38: Batch #89 - Loss: 0.8886971473693848\n",
      "Ep 38: Batch #90 - Loss: 1.166854977607727\n",
      "Ep 38: Batch #91 - Loss: 0.8114703297615051\n",
      "Ep 38: Batch #92 - Loss: 1.0384782552719116\n",
      "Ep 38: Batch #93 - Loss: 1.041216254234314\n",
      "Ep 38: Batch #94 - Loss: 1.0596672296524048\n",
      "Ep 38: Batch #95 - Loss: 0.9285624027252197\n",
      "Ep 38: Batch #96 - Loss: 0.9135675430297852\n",
      "Ep 38: Batch #97 - Loss: 0.7375090718269348\n",
      "Ep 38: Batch #98 - Loss: 0.7467966675758362\n",
      "Ep 38: Batch #99 - Loss: 0.9661577939987183\n",
      "Ep 38: Batch #100 - Loss: 0.6857427954673767\n",
      "Ep 38: Batch #101 - Loss: 1.055619716644287\n",
      "Ep 38: Batch #102 - Loss: 0.7898535132408142\n",
      "Ep 38: Batch #103 - Loss: 0.797661542892456\n",
      "Ep 38: Batch #104 - Loss: 0.8090713024139404\n",
      "Ep 38: Batch #105 - Loss: 1.038480520248413\n",
      "Ep 38: Batch #106 - Loss: 0.7669066786766052\n",
      "Ep 38: Batch #107 - Loss: 0.7660310864448547\n",
      "Ep 38: Batch #108 - Loss: 1.0435206890106201\n",
      "Ep 38: Batch #109 - Loss: 0.7695116996765137\n",
      "Ep 38: Batch #110 - Loss: 0.9294186234474182\n",
      "Ep 38: Batch #111 - Loss: 1.3896950483322144\n",
      "Ep 38: Batch #112 - Loss: 1.0573478937149048\n",
      "Ep 38: Batch #113 - Loss: 0.8245713114738464\n",
      "Ep 38: Batch #114 - Loss: 0.9124605655670166\n",
      "Ep 38: Batch #115 - Loss: 1.1039272546768188\n",
      "Ep 38: Batch #116 - Loss: 0.6379249691963196\n",
      "Ep 38: Batch #117 - Loss: 0.8801214694976807\n",
      "Ep 38: Batch #118 - Loss: 0.5508516430854797\n",
      "Model saved in file: ./weights_autoencoder_low_LR/model_e38b118_1516651273.8120232.ckpt\n",
      "Ep 38: Batch #119 - Loss: 1.035499930381775\n",
      "Ep 38: Batch #120 - Loss: 0.8068946599960327\n",
      "Ep 38: Batch #121 - Loss: 0.6934459805488586\n",
      "Ep 38: Batch #122 - Loss: 0.8329955339431763\n",
      "Ep 38: Batch #123 - Loss: 0.8397804498672485\n",
      "Ep 38: Batch #124 - Loss: 0.6688855886459351\n",
      "Ep 38: Batch #125 - Loss: 2.7291274070739746\n",
      "Ep 38: Batch #126 - Loss: 1.234391689300537\n",
      "Ep 38: Batch #127 - Loss: 0.7583256959915161\n",
      "Ep 38: Batch #128 - Loss: 1.1174253225326538\n",
      "Ep 38: Batch #129 - Loss: 0.8475573062896729\n",
      "Ep 38: Batch #130 - Loss: 0.7311931252479553\n",
      "Ep 38: Batch #131 - Loss: 1.0067017078399658\n",
      "Ep 38: Batch #132 - Loss: 0.8326994180679321\n",
      "Ep 38: Batch #133 - Loss: 0.8257968425750732\n",
      "Ep 38: Batch #134 - Loss: 0.7772405743598938\n",
      "Ep 38: Batch #135 - Loss: 0.9765095114707947\n",
      "Ep 38: Batch #136 - Loss: 1.192740559577942\n",
      "Ep 38: Batch #137 - Loss: 0.9740220308303833\n",
      "Ep 38: Batch #138 - Loss: 1.0796629190444946\n",
      "Ep 38: Batch #139 - Loss: 0.9091014266014099\n",
      "Ep 38: Batch #140 - Loss: 1.0580750703811646\n",
      "Ep 38: Batch #141 - Loss: 1.367447018623352\n",
      "Ep 38: Batch #142 - Loss: 0.8026407361030579\n",
      "Ep 38: Batch #143 - Loss: 0.9761983156204224\n",
      "Ep 38: Batch #144 - Loss: 0.7279328107833862\n",
      "Ep 38: Batch #145 - Loss: 0.6849188208580017\n",
      "Ep 38: Batch #146 - Loss: 0.8916237950325012\n",
      "Ep 38: Batch #147 - Loss: 0.8723955750465393\n",
      "Ep 38: Batch #148 - Loss: 0.9877674579620361\n",
      "Ep 38: Batch #149 - Loss: 0.8639358878135681\n",
      "Ep 38: Batch #150 - Loss: 0.8912167549133301\n",
      "Ep 38: Batch #151 - Loss: 0.7324239015579224\n",
      "Ep 38: Batch #152 - Loss: 0.7450722455978394\n",
      "Ep 38: Batch #153 - Loss: 1.1152137517929077\n",
      "Ep 38: Batch #154 - Loss: 0.7708034515380859\n",
      "Ep 38: Batch #155 - Loss: 0.8416360020637512\n",
      "Ep 38: Batch #156 - Loss: 1.0270143747329712\n",
      "Ep 38: Batch #157 - Loss: 0.7696129083633423\n",
      "Ep 38: Batch #158 - Loss: 0.8111236095428467\n",
      "Ep 38: Batch #159 - Loss: 0.8168827295303345\n",
      "Ep 38: Batch #160 - Loss: 0.9107754230499268\n",
      "Ep 38: Batch #161 - Loss: 0.8240936994552612\n",
      "Ep 38: Batch #162 - Loss: 0.9410429000854492\n",
      "Ep 38: Batch #163 - Loss: 0.9364332556724548\n",
      "Ep 38: Batch #164 - Loss: 0.7925686836242676\n",
      "Ep 38: Batch #165 - Loss: 1.5077707767486572\n",
      "Ep 38: Batch #166 - Loss: 0.687440037727356\n",
      "Ep 38: Batch #167 - Loss: 1.0957765579223633\n",
      "Ep 38: Batch #168 - Loss: 0.8696021437644958\n",
      "Ep 38: Batch #169 - Loss: 0.8091450929641724\n",
      "Ep 38: Batch #170 - Loss: 0.8125584125518799\n",
      "Ep 38: Batch #171 - Loss: 0.7894740700721741\n",
      "Ep 38: Batch #172 - Loss: 0.6397377848625183\n",
      "Ep 38: Batch #173 - Loss: 1.208777904510498\n",
      "Ep 38: Batch #174 - Loss: 0.5848525166511536\n",
      "Ep 38: Batch #175 - Loss: 0.7849929332733154\n",
      "Ep 38: Batch #176 - Loss: 1.1672033071517944\n",
      "Ep 38: Batch #177 - Loss: 0.8569076657295227\n",
      "Ep 38: Batch #178 - Loss: 0.7718724608421326\n",
      "Ep 38: Batch #179 - Loss: 0.9500195384025574\n",
      "Ep 38: Batch #180 - Loss: 0.865888774394989\n",
      "Ep 38: Batch #181 - Loss: 1.0029317140579224\n",
      "Ep 38: Batch #182 - Loss: 0.7709304690361023\n",
      "Ep 38: Batch #183 - Loss: 0.7730686664581299\n",
      "Ep 38: Batch #184 - Loss: 1.075058937072754\n",
      "Ep 38: Batch #185 - Loss: 0.7657292485237122\n",
      "Ep 38: Batch #186 - Loss: 0.9783831834793091\n",
      "Ep 38: Batch #187 - Loss: 1.174844741821289\n",
      "Ep 38: Batch #188 - Loss: 1.3561806678771973\n",
      "Ep 38: Batch #189 - Loss: 0.7071704864501953\n",
      "Ep 38: Batch #190 - Loss: 0.742169201374054\n",
      "Ep 38: Batch #191 - Loss: 1.0734999179840088\n",
      "Ep 38: Batch #192 - Loss: 0.675344705581665\n",
      "Ep 38: Batch #193 - Loss: 0.7494232058525085\n",
      "Ep 38: Batch #194 - Loss: 0.7034284472465515\n",
      "Ep 38: Batch #195 - Loss: 0.9918173551559448\n",
      "Ep 38: Batch #196 - Loss: 0.872906506061554\n",
      "Ep 38: Batch #197 - Loss: 0.9101705551147461\n",
      "Ep 38: Batch #198 - Loss: 0.6856734156608582\n",
      "Ep 38: Batch #199 - Loss: 0.8702476024627686\n",
      "Ep 39: Batch #0 - Loss: 0.8010178804397583\n",
      "Ep 39: Batch #1 - Loss: 0.8846619725227356\n",
      "Ep 39: Batch #2 - Loss: 1.0156432390213013\n",
      "Ep 39: Batch #3 - Loss: 0.8715481758117676\n",
      "Ep 39: Batch #4 - Loss: 0.7972650527954102\n",
      "Ep 39: Batch #5 - Loss: 0.6735728979110718\n",
      "Ep 39: Batch #6 - Loss: 0.8861032724380493\n",
      "Ep 39: Batch #7 - Loss: 0.7079097032546997\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 39: Batch #8 - Loss: 0.739973247051239\n",
      "Ep 39: Batch #9 - Loss: 1.41167414188385\n",
      "Ep 39: Batch #10 - Loss: 1.0145230293273926\n",
      "Ep 39: Batch #11 - Loss: 0.6763913035392761\n",
      "Ep 39: Batch #12 - Loss: 1.567577600479126\n",
      "Ep 39: Batch #13 - Loss: 0.6526625156402588\n",
      "Ep 39: Batch #14 - Loss: 0.7330706715583801\n",
      "Ep 39: Batch #15 - Loss: 1.2484850883483887\n",
      "Ep 39: Batch #16 - Loss: 1.2871031761169434\n",
      "Ep 39: Batch #17 - Loss: 0.8884424567222595\n",
      "Ep 39: Batch #18 - Loss: 0.9488744139671326\n",
      "Ep 39: Batch #19 - Loss: 0.6736775636672974\n",
      "Ep 39: Batch #20 - Loss: 0.6610608100891113\n",
      "Ep 39: Batch #21 - Loss: 1.2196791172027588\n",
      "Ep 39: Batch #22 - Loss: 0.7316669225692749\n",
      "Ep 39: Batch #23 - Loss: 0.7504867911338806\n",
      "Ep 39: Batch #24 - Loss: 0.8294922113418579\n",
      "Ep 39: Batch #25 - Loss: 0.722122073173523\n",
      "Ep 39: Batch #26 - Loss: 0.7387503385543823\n",
      "Ep 39: Batch #27 - Loss: 1.3620541095733643\n",
      "Ep 39: Batch #28 - Loss: 0.8748176693916321\n",
      "Ep 39: Batch #29 - Loss: 0.9014043807983398\n",
      "Ep 39: Batch #30 - Loss: 1.2090530395507812\n",
      "Ep 39: Batch #31 - Loss: 0.6780684590339661\n",
      "Ep 39: Batch #32 - Loss: 0.7546302676200867\n",
      "Ep 39: Batch #33 - Loss: 0.8131634593009949\n",
      "Ep 39: Batch #34 - Loss: 0.7903186678886414\n",
      "Ep 39: Batch #35 - Loss: 0.9581843614578247\n",
      "Ep 39: Batch #36 - Loss: 0.7090396881103516\n",
      "Ep 39: Batch #37 - Loss: 1.148095726966858\n",
      "Ep 39: Batch #38 - Loss: 0.7532569766044617\n",
      "Ep 39: Batch #39 - Loss: 0.8252422213554382\n",
      "Ep 39: Batch #40 - Loss: 0.7814492583274841\n",
      "Ep 39: Batch #41 - Loss: 0.7453632950782776\n",
      "Ep 39: Batch #42 - Loss: 0.7285401821136475\n",
      "Ep 39: Batch #43 - Loss: 0.7944088578224182\n",
      "Ep 39: Batch #44 - Loss: 0.7917328476905823\n",
      "Ep 39: Batch #45 - Loss: 0.6409211158752441\n",
      "Ep 39: Batch #46 - Loss: 0.8384203314781189\n",
      "Ep 39: Batch #47 - Loss: 0.9707813858985901\n",
      "Ep 39: Batch #48 - Loss: 1.3633086681365967\n",
      "Ep 39: Batch #49 - Loss: 1.0241389274597168\n",
      "Ep 39: Batch #50 - Loss: 0.7108573913574219\n",
      "Ep 39: Batch #51 - Loss: 1.0045102834701538\n",
      "Ep 39: Batch #52 - Loss: 0.8003077507019043\n",
      "Ep 39: Batch #53 - Loss: 0.8295674920082092\n",
      "Ep 39: Batch #54 - Loss: 0.7109362483024597\n",
      "Ep 39: Batch #55 - Loss: 0.758985698223114\n",
      "Ep 39: Batch #56 - Loss: 1.2710325717926025\n",
      "Ep 39: Batch #57 - Loss: 0.8559603095054626\n",
      "Ep 39: Batch #58 - Loss: 1.009095311164856\n",
      "Ep 39: Batch #59 - Loss: 0.6861226558685303\n",
      "Ep 39: Batch #60 - Loss: 1.3179394006729126\n",
      "Ep 39: Batch #61 - Loss: 0.6418700218200684\n",
      "Ep 39: Batch #62 - Loss: 0.7299784421920776\n",
      "Ep 39: Batch #63 - Loss: 1.010951042175293\n",
      "Ep 39: Batch #64 - Loss: 9.43541431427002\n",
      "Ep 39: Batch #65 - Loss: 0.6173620820045471\n",
      "Ep 39: Batch #66 - Loss: 0.8052096366882324\n",
      "Ep 39: Batch #67 - Loss: 0.9172272086143494\n",
      "Ep 39: Batch #68 - Loss: 0.9163756966590881\n",
      "Ep 39: Batch #69 - Loss: 0.7518085241317749\n",
      "Ep 39: Batch #70 - Loss: 0.7847334146499634\n",
      "Ep 39: Batch #71 - Loss: 0.6853115558624268\n",
      "Ep 39: Batch #72 - Loss: 0.861690878868103\n",
      "Ep 39: Batch #73 - Loss: 0.9128189086914062\n",
      "Ep 39: Batch #74 - Loss: 0.7480589747428894\n",
      "Ep 39: Batch #75 - Loss: 0.7741565108299255\n",
      "Ep 39: Batch #76 - Loss: 1.1017874479293823\n",
      "Ep 39: Batch #77 - Loss: 0.7413013577461243\n",
      "Ep 39: Batch #78 - Loss: 1.1690988540649414\n",
      "Ep 39: Batch #79 - Loss: 0.6318181157112122\n",
      "Ep 39: Batch #80 - Loss: 0.8675737380981445\n",
      "Ep 39: Batch #81 - Loss: 1.6875665187835693\n",
      "Ep 39: Batch #82 - Loss: 0.8799389600753784\n",
      "Ep 39: Batch #83 - Loss: 1.7401055097579956\n",
      "Ep 39: Batch #84 - Loss: 0.721355676651001\n",
      "Ep 39: Batch #85 - Loss: 0.9795148968696594\n",
      "Ep 39: Batch #86 - Loss: 0.7162217497825623\n",
      "Ep 39: Batch #87 - Loss: 0.7193448543548584\n",
      "Ep 39: Batch #88 - Loss: 0.8094014525413513\n",
      "Ep 39: Batch #89 - Loss: 0.8877793550491333\n",
      "Ep 39: Batch #90 - Loss: 1.164812684059143\n",
      "Ep 39: Batch #91 - Loss: 0.8099746704101562\n",
      "Ep 39: Batch #92 - Loss: 1.0367982387542725\n",
      "Ep 39: Batch #93 - Loss: 1.0393482446670532\n",
      "Ep 39: Batch #94 - Loss: 1.0579769611358643\n",
      "Ep 39: Batch #95 - Loss: 0.9270764589309692\n",
      "Ep 39: Batch #96 - Loss: 0.9120888710021973\n",
      "Ep 39: Batch #97 - Loss: 0.7362001538276672\n",
      "Ep 39: Batch #98 - Loss: 0.7454777359962463\n",
      "Ep 39: Batch #99 - Loss: 0.9648748636245728\n",
      "Ep 39: Batch #100 - Loss: 0.6844975352287292\n",
      "Ep 39: Batch #101 - Loss: 1.0541434288024902\n",
      "Ep 39: Batch #102 - Loss: 0.7886328101158142\n",
      "Ep 39: Batch #103 - Loss: 0.796402096748352\n",
      "Ep 39: Batch #104 - Loss: 0.8077720403671265\n",
      "Ep 39: Batch #105 - Loss: 1.0368930101394653\n",
      "Ep 39: Batch #106 - Loss: 0.7656473517417908\n",
      "Ep 39: Batch #107 - Loss: 0.7646623253822327\n",
      "Ep 39: Batch #108 - Loss: 1.0418881177902222\n",
      "Ep 39: Batch #109 - Loss: 0.7683504819869995\n",
      "Ep 39: Batch #110 - Loss: 0.9277269840240479\n",
      "Ep 39: Batch #111 - Loss: 1.3879224061965942\n",
      "Ep 39: Batch #112 - Loss: 1.0556085109710693\n",
      "Ep 39: Batch #113 - Loss: 0.8232226371765137\n",
      "Ep 39: Batch #114 - Loss: 0.9109293222427368\n",
      "Ep 39: Batch #115 - Loss: 1.1022639274597168\n",
      "Ep 39: Batch #116 - Loss: 0.6371128559112549\n",
      "Ep 39: Batch #117 - Loss: 0.8788068890571594\n",
      "Ep 39: Batch #118 - Loss: 0.5497628450393677\n",
      "Model saved in file: ./weights_autoencoder_low_LR/model_e39b118_1516651273.9577875.ckpt\n",
      "Ep 39: Batch #119 - Loss: 1.0340242385864258\n",
      "Ep 39: Batch #120 - Loss: 0.8057755827903748\n",
      "Ep 39: Batch #121 - Loss: 0.6921952366828918\n",
      "Ep 39: Batch #122 - Loss: 0.8316675424575806\n",
      "Ep 39: Batch #123 - Loss: 0.8384906053543091\n",
      "Ep 39: Batch #124 - Loss: 0.667936384677887\n",
      "Ep 39: Batch #125 - Loss: 2.7275049686431885\n",
      "Ep 39: Batch #126 - Loss: 1.2328064441680908\n",
      "Ep 39: Batch #127 - Loss: 0.7568174004554749\n",
      "Ep 39: Batch #128 - Loss: 1.1154520511627197\n",
      "Ep 39: Batch #129 - Loss: 0.8461028933525085\n",
      "Ep 39: Batch #130 - Loss: 0.7299168109893799\n",
      "Ep 39: Batch #131 - Loss: 1.0048578977584839\n",
      "Ep 39: Batch #132 - Loss: 0.8312181830406189\n",
      "Ep 39: Batch #133 - Loss: 0.8244553804397583\n",
      "Ep 39: Batch #134 - Loss: 0.7758881449699402\n",
      "Ep 39: Batch #135 - Loss: 0.974892258644104\n",
      "Ep 39: Batch #136 - Loss: 1.190843939781189\n",
      "Ep 39: Batch #137 - Loss: 0.9724361896514893\n",
      "Ep 39: Batch #138 - Loss: 1.0780954360961914\n",
      "Ep 39: Batch #139 - Loss: 0.9076217412948608\n",
      "Ep 39: Batch #140 - Loss: 1.0565388202667236\n",
      "Ep 39: Batch #141 - Loss: 1.365891456604004\n",
      "Ep 39: Batch #142 - Loss: 0.8013864159584045\n",
      "Ep 39: Batch #143 - Loss: 0.9744421243667603\n",
      "Ep 39: Batch #144 - Loss: 0.7266837954521179\n",
      "Ep 39: Batch #145 - Loss: 0.6837908029556274\n",
      "Ep 39: Batch #146 - Loss: 0.8903325796127319\n",
      "Ep 39: Batch #147 - Loss: 0.8706924319267273\n",
      "Ep 39: Batch #148 - Loss: 0.9861553907394409\n",
      "Ep 39: Batch #149 - Loss: 0.8623650670051575\n",
      "Ep 39: Batch #150 - Loss: 0.8898972868919373\n",
      "Ep 39: Batch #151 - Loss: 0.731503427028656\n",
      "Ep 39: Batch #152 - Loss: 0.744093120098114\n",
      "Ep 39: Batch #153 - Loss: 1.1135333776474\n",
      "Ep 39: Batch #154 - Loss: 0.7696471214294434\n",
      "Ep 39: Batch #155 - Loss: 0.8402143120765686\n",
      "Ep 39: Batch #156 - Loss: 1.0254647731781006\n",
      "Ep 39: Batch #157 - Loss: 0.7683636546134949\n",
      "Ep 39: Batch #158 - Loss: 0.8101214170455933\n",
      "Ep 39: Batch #159 - Loss: 0.8155065774917603\n",
      "Ep 39: Batch #160 - Loss: 0.9095677733421326\n",
      "Ep 39: Batch #161 - Loss: 0.8227880597114563\n",
      "Ep 39: Batch #162 - Loss: 0.9395947456359863\n",
      "Ep 39: Batch #163 - Loss: 0.9353139400482178\n",
      "Ep 39: Batch #164 - Loss: 0.7913058400154114\n",
      "Ep 39: Batch #165 - Loss: 1.5064642429351807\n",
      "Ep 39: Batch #166 - Loss: 0.6861175298690796\n",
      "Ep 39: Batch #167 - Loss: 1.0943493843078613\n",
      "Ep 39: Batch #168 - Loss: 0.8681397438049316\n",
      "Ep 39: Batch #169 - Loss: 0.8078722953796387\n",
      "Ep 39: Batch #170 - Loss: 0.811205267906189\n",
      "Ep 39: Batch #171 - Loss: 0.7880266308784485\n",
      "Ep 39: Batch #172 - Loss: 0.6387773156166077\n",
      "Ep 39: Batch #173 - Loss: 1.2068078517913818\n",
      "Ep 39: Batch #174 - Loss: 0.5838748812675476\n",
      "Ep 39: Batch #175 - Loss: 0.7838777303695679\n",
      "Ep 39: Batch #176 - Loss: 1.1655865907669067\n",
      "Ep 39: Batch #177 - Loss: 0.8555545806884766\n",
      "Ep 39: Batch #178 - Loss: 0.7704852819442749\n",
      "Ep 39: Batch #179 - Loss: 0.9483022093772888\n",
      "Ep 39: Batch #180 - Loss: 0.8641908168792725\n",
      "Ep 39: Batch #181 - Loss: 1.0011372566223145\n",
      "Ep 39: Batch #182 - Loss: 0.7698490023612976\n",
      "Ep 39: Batch #183 - Loss: 0.7717013955116272\n",
      "Ep 39: Batch #184 - Loss: 1.0739047527313232\n",
      "Ep 39: Batch #185 - Loss: 0.7645729780197144\n",
      "Ep 39: Batch #186 - Loss: 0.9765825867652893\n",
      "Ep 39: Batch #187 - Loss: 1.1734697818756104\n",
      "Ep 39: Batch #188 - Loss: 1.3548592329025269\n",
      "Ep 39: Batch #189 - Loss: 0.7062320709228516\n",
      "Ep 39: Batch #190 - Loss: 0.7409983277320862\n",
      "Ep 39: Batch #191 - Loss: 1.072084903717041\n",
      "Ep 39: Batch #192 - Loss: 0.674432635307312\n",
      "Ep 39: Batch #193 - Loss: 0.7480700016021729\n",
      "Ep 39: Batch #194 - Loss: 0.7022509574890137\n",
      "Ep 39: Batch #195 - Loss: 0.9903073310852051\n",
      "Ep 39: Batch #196 - Loss: 0.8716335892677307\n",
      "Ep 39: Batch #197 - Loss: 0.9087717533111572\n",
      "Ep 39: Batch #198 - Loss: 0.684439480304718\n",
      "Ep 39: Batch #199 - Loss: 0.86884605884552\n",
      "Ep 40: Batch #0 - Loss: 0.7995097637176514\n",
      "Ep 40: Batch #1 - Loss: 0.8832812309265137\n",
      "Ep 40: Batch #2 - Loss: 1.014382004737854\n",
      "Ep 40: Batch #3 - Loss: 0.8702847957611084\n",
      "Ep 40: Batch #4 - Loss: 0.7958619594573975\n",
      "Ep 40: Batch #5 - Loss: 0.6726424694061279\n",
      "Ep 40: Batch #6 - Loss: 0.8848293423652649\n",
      "Ep 40: Batch #7 - Loss: 0.7068513631820679\n",
      "Ep 40: Batch #8 - Loss: 0.7388988733291626\n",
      "Ep 40: Batch #9 - Loss: 1.4096474647521973\n",
      "Ep 40: Batch #10 - Loss: 1.0130372047424316\n",
      "Ep 40: Batch #11 - Loss: 0.6752930283546448\n",
      "Ep 40: Batch #12 - Loss: 1.5662307739257812\n",
      "Ep 40: Batch #13 - Loss: 0.6518296599388123\n",
      "Ep 40: Batch #14 - Loss: 0.731997549533844\n",
      "Ep 40: Batch #15 - Loss: 1.246793508529663\n",
      "Ep 40: Batch #16 - Loss: 1.2850641012191772\n",
      "Ep 40: Batch #17 - Loss: 0.8870159983634949\n",
      "Ep 40: Batch #18 - Loss: 0.9478890299797058\n",
      "Ep 40: Batch #19 - Loss: 0.6726693511009216\n",
      "Ep 40: Batch #20 - Loss: 0.6599397659301758\n",
      "Ep 40: Batch #21 - Loss: 1.2182940244674683\n",
      "Ep 40: Batch #22 - Loss: 0.7306283116340637\n",
      "Ep 40: Batch #23 - Loss: 0.7491229772567749\n",
      "Ep 40: Batch #24 - Loss: 0.8283575773239136\n",
      "Ep 40: Batch #25 - Loss: 0.720832109451294\n",
      "Ep 40: Batch #26 - Loss: 0.7373600006103516\n",
      "Ep 40: Batch #27 - Loss: 1.360263705253601\n",
      "Ep 40: Batch #28 - Loss: 0.8734800219535828\n",
      "Ep 40: Batch #29 - Loss: 0.8998268246650696\n",
      "Ep 40: Batch #30 - Loss: 1.2075973749160767\n",
      "Ep 40: Batch #31 - Loss: 0.6772025227546692\n",
      "Ep 40: Batch #32 - Loss: 0.7533485293388367\n",
      "Ep 40: Batch #33 - Loss: 0.8121010065078735\n",
      "Ep 40: Batch #34 - Loss: 0.7890982627868652\n",
      "Ep 40: Batch #35 - Loss: 0.9564458131790161\n",
      "Ep 40: Batch #36 - Loss: 0.7078876495361328\n",
      "Ep 40: Batch #37 - Loss: 1.1467337608337402\n",
      "Ep 40: Batch #38 - Loss: 0.7518249154090881\n",
      "Ep 40: Batch #39 - Loss: 0.8242006301879883\n",
      "Ep 40: Batch #40 - Loss: 0.7801368236541748\n",
      "Ep 40: Batch #41 - Loss: 0.7440089583396912\n",
      "Ep 40: Batch #42 - Loss: 0.727425754070282\n",
      "Ep 40: Batch #43 - Loss: 0.7932047247886658\n",
      "Ep 40: Batch #44 - Loss: 0.7904378771781921\n",
      "Ep 40: Batch #45 - Loss: 0.6396182775497437\n",
      "Ep 40: Batch #46 - Loss: 0.8370208740234375\n",
      "Ep 40: Batch #47 - Loss: 0.9690076112747192\n",
      "Ep 40: Batch #48 - Loss: 1.361539363861084\n",
      "Ep 40: Batch #49 - Loss: 1.0225250720977783\n",
      "Ep 40: Batch #50 - Loss: 0.709959864616394\n",
      "Ep 40: Batch #51 - Loss: 1.0027360916137695\n",
      "Ep 40: Batch #52 - Loss: 0.799259603023529\n",
      "Ep 40: Batch #53 - Loss: 0.8282423615455627\n",
      "Ep 40: Batch #54 - Loss: 0.709899365901947\n",
      "Ep 40: Batch #55 - Loss: 0.7576168775558472\n",
      "Ep 40: Batch #56 - Loss: 1.2692261934280396\n",
      "Ep 40: Batch #57 - Loss: 0.854402482509613\n",
      "Ep 40: Batch #58 - Loss: 1.0073678493499756\n",
      "Ep 40: Batch #59 - Loss: 0.6851350665092468\n",
      "Ep 40: Batch #60 - Loss: 1.3164446353912354\n",
      "Ep 40: Batch #61 - Loss: 0.6408095955848694\n",
      "Ep 40: Batch #62 - Loss: 0.7286425828933716\n",
      "Ep 40: Batch #63 - Loss: 1.0093443393707275\n",
      "Ep 40: Batch #64 - Loss: 9.434059143066406\n",
      "Ep 40: Batch #65 - Loss: 0.616401195526123\n",
      "Ep 40: Batch #66 - Loss: 0.8036187887191772\n",
      "Ep 40: Batch #67 - Loss: 0.9159192442893982\n",
      "Ep 40: Batch #68 - Loss: 0.9148672223091125\n",
      "Ep 40: Batch #69 - Loss: 0.7505351305007935\n",
      "Ep 40: Batch #70 - Loss: 0.7831323742866516\n",
      "Ep 40: Batch #71 - Loss: 0.6841874718666077\n",
      "Ep 40: Batch #72 - Loss: 0.8602811694145203\n",
      "Ep 40: Batch #73 - Loss: 0.9110619425773621\n",
      "Ep 40: Batch #74 - Loss: 0.7467107176780701\n",
      "Ep 40: Batch #75 - Loss: 0.7730033993721008\n",
      "Ep 40: Batch #76 - Loss: 1.1005879640579224\n",
      "Ep 40: Batch #77 - Loss: 0.7400373816490173\n",
      "Ep 40: Batch #78 - Loss: 1.167354702949524\n",
      "Ep 40: Batch #79 - Loss: 0.630710780620575\n",
      "Ep 40: Batch #80 - Loss: 0.8660518527030945\n",
      "Ep 40: Batch #81 - Loss: 1.6860707998275757\n",
      "Ep 40: Batch #82 - Loss: 0.8786603212356567\n",
      "Ep 40: Batch #83 - Loss: 1.7390557527542114\n",
      "Ep 40: Batch #84 - Loss: 0.7200509309768677\n",
      "Ep 40: Batch #85 - Loss: 0.9783097505569458\n",
      "Ep 40: Batch #86 - Loss: 0.7148508429527283\n",
      "Ep 40: Batch #87 - Loss: 0.7181533575057983\n",
      "Ep 40: Batch #88 - Loss: 0.8079498410224915\n",
      "Ep 40: Batch #89 - Loss: 0.8868693113327026\n",
      "Ep 40: Batch #90 - Loss: 1.1627955436706543\n",
      "Ep 40: Batch #91 - Loss: 0.8084923028945923\n",
      "Ep 40: Batch #92 - Loss: 1.035138726234436\n",
      "Ep 40: Batch #93 - Loss: 1.037493109703064\n",
      "Ep 40: Batch #94 - Loss: 1.0562983751296997\n",
      "Ep 40: Batch #95 - Loss: 0.9256091117858887\n",
      "Ep 40: Batch #96 - Loss: 0.9106302261352539\n",
      "Ep 40: Batch #97 - Loss: 0.7348966002464294\n",
      "Ep 40: Batch #98 - Loss: 0.7441715002059937\n",
      "Ep 40: Batch #99 - Loss: 0.9635989665985107\n",
      "Ep 40: Batch #100 - Loss: 0.6832623481750488\n",
      "Ep 40: Batch #101 - Loss: 1.052679181098938\n",
      "Ep 40: Batch #102 - Loss: 0.7874224781990051\n",
      "Ep 40: Batch #103 - Loss: 0.7951557636260986\n",
      "Ep 40: Batch #104 - Loss: 0.8064880967140198\n",
      "Ep 40: Batch #105 - Loss: 1.0353083610534668\n",
      "Ep 40: Batch #106 - Loss: 0.764394998550415\n",
      "Ep 40: Batch #107 - Loss: 0.763317883014679\n",
      "Ep 40: Batch #108 - Loss: 1.0402733087539673\n",
      "Ep 40: Batch #109 - Loss: 0.7671995759010315\n",
      "Ep 40: Batch #110 - Loss: 0.9260483980178833\n",
      "Ep 40: Batch #111 - Loss: 1.3861922025680542\n",
      "Ep 40: Batch #112 - Loss: 1.0539027452468872\n",
      "Ep 40: Batch #113 - Loss: 0.8218874335289001\n",
      "Ep 40: Batch #114 - Loss: 0.9094156622886658\n",
      "Ep 40: Batch #115 - Loss: 1.1006015539169312\n",
      "Ep 40: Batch #116 - Loss: 0.6363047957420349\n",
      "Ep 40: Batch #117 - Loss: 0.8774958848953247\n",
      "Ep 40: Batch #118 - Loss: 0.5486885905265808\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved in file: ./weights_autoencoder_low_LR/model_e40b118_1516651274.0927484.ckpt\n",
      "Ep 40: Batch #119 - Loss: 1.03256356716156\n",
      "Ep 40: Batch #120 - Loss: 0.804658055305481\n",
      "Ep 40: Batch #121 - Loss: 0.6909603476524353\n",
      "Ep 40: Batch #122 - Loss: 0.8303519487380981\n",
      "Ep 40: Batch #123 - Loss: 0.8372046947479248\n",
      "Ep 40: Batch #124 - Loss: 0.6669997572898865\n",
      "Ep 40: Batch #125 - Loss: 2.7259035110473633\n",
      "Ep 40: Batch #126 - Loss: 1.2312418222427368\n",
      "Ep 40: Batch #127 - Loss: 0.7553342580795288\n",
      "Ep 40: Batch #128 - Loss: 1.1135072708129883\n",
      "Ep 40: Batch #129 - Loss: 0.8446570038795471\n",
      "Ep 40: Batch #130 - Loss: 0.7286517024040222\n",
      "Ep 40: Batch #131 - Loss: 1.0030314922332764\n",
      "Ep 40: Batch #132 - Loss: 0.829759955406189\n",
      "Ep 40: Batch #133 - Loss: 0.8231220841407776\n",
      "Ep 40: Batch #134 - Loss: 0.774552047252655\n",
      "Ep 40: Batch #135 - Loss: 0.9732813835144043\n",
      "Ep 40: Batch #136 - Loss: 1.1889721155166626\n",
      "Ep 40: Batch #137 - Loss: 0.9708694815635681\n",
      "Ep 40: Batch #138 - Loss: 1.0765327215194702\n",
      "Ep 40: Batch #139 - Loss: 0.906157374382019\n",
      "Ep 40: Batch #140 - Loss: 1.0550204515457153\n",
      "Ep 40: Batch #141 - Loss: 1.3643500804901123\n",
      "Ep 40: Batch #142 - Loss: 0.8001407384872437\n",
      "Ep 40: Batch #143 - Loss: 0.9727022647857666\n",
      "Ep 40: Batch #144 - Loss: 0.7254536151885986\n",
      "Ep 40: Batch #145 - Loss: 0.6826685070991516\n",
      "Ep 40: Batch #146 - Loss: 0.8890495896339417\n",
      "Ep 40: Batch #147 - Loss: 0.8690109252929688\n",
      "Ep 40: Batch #148 - Loss: 0.9845460057258606\n",
      "Ep 40: Batch #149 - Loss: 0.8608102202415466\n",
      "Ep 40: Batch #150 - Loss: 0.8885824680328369\n",
      "Ep 40: Batch #151 - Loss: 0.7305989265441895\n",
      "Ep 40: Batch #152 - Loss: 0.7431269884109497\n",
      "Ep 40: Batch #153 - Loss: 1.1118592023849487\n",
      "Ep 40: Batch #154 - Loss: 0.7684990763664246\n",
      "Ep 40: Batch #155 - Loss: 0.8388216495513916\n",
      "Ep 40: Batch #156 - Loss: 1.0239344835281372\n",
      "Ep 40: Batch #157 - Loss: 0.7671219110488892\n",
      "Ep 40: Batch #158 - Loss: 0.8091309666633606\n",
      "Ep 40: Batch #159 - Loss: 0.8141352534294128\n",
      "Ep 40: Batch #160 - Loss: 0.9083703756332397\n",
      "Ep 40: Batch #161 - Loss: 0.8215013146400452\n",
      "Ep 40: Batch #162 - Loss: 0.9381541609764099\n",
      "Ep 40: Batch #163 - Loss: 0.9342038035392761\n",
      "Ep 40: Batch #164 - Loss: 0.7900564074516296\n",
      "Ep 40: Batch #165 - Loss: 1.5051524639129639\n",
      "Ep 40: Batch #166 - Loss: 0.6848163604736328\n",
      "Ep 40: Batch #167 - Loss: 1.092901587486267\n",
      "Ep 40: Batch #168 - Loss: 0.8666881918907166\n",
      "Ep 40: Batch #169 - Loss: 0.806614339351654\n",
      "Ep 40: Batch #170 - Loss: 0.809867799282074\n",
      "Ep 40: Batch #171 - Loss: 0.7865960597991943\n",
      "Ep 40: Batch #172 - Loss: 0.6378180384635925\n",
      "Ep 40: Batch #173 - Loss: 1.2048534154891968\n",
      "Ep 40: Batch #174 - Loss: 0.5829146504402161\n",
      "Ep 40: Batch #175 - Loss: 0.7827813029289246\n",
      "Ep 40: Batch #176 - Loss: 1.1639395952224731\n",
      "Ep 40: Batch #177 - Loss: 0.8542120456695557\n",
      "Ep 40: Batch #178 - Loss: 0.7691096067428589\n",
      "Ep 40: Batch #179 - Loss: 0.9465935230255127\n",
      "Ep 40: Batch #180 - Loss: 0.8625149726867676\n",
      "Ep 40: Batch #181 - Loss: 0.9993593096733093\n",
      "Ep 40: Batch #182 - Loss: 0.7687878012657166\n",
      "Ep 40: Batch #183 - Loss: 0.7703534364700317\n",
      "Ep 40: Batch #184 - Loss: 1.0727527141571045\n",
      "Ep 40: Batch #185 - Loss: 0.7633997201919556\n",
      "Ep 40: Batch #186 - Loss: 0.9747917056083679\n",
      "Ep 40: Batch #187 - Loss: 1.172098159790039\n",
      "Ep 40: Batch #188 - Loss: 1.3535641431808472\n",
      "Ep 40: Batch #189 - Loss: 0.7052958011627197\n",
      "Ep 40: Batch #190 - Loss: 0.7398431897163391\n",
      "Ep 40: Batch #191 - Loss: 1.0706753730773926\n",
      "Ep 40: Batch #192 - Loss: 0.673517644405365\n",
      "Ep 40: Batch #193 - Loss: 0.7467249035835266\n",
      "Ep 40: Batch #194 - Loss: 0.7010825872421265\n",
      "Ep 40: Batch #195 - Loss: 0.9888077974319458\n",
      "Ep 40: Batch #196 - Loss: 0.8703787326812744\n",
      "Ep 40: Batch #197 - Loss: 0.9073812365531921\n",
      "Ep 40: Batch #198 - Loss: 0.6832142472267151\n",
      "Ep 40: Batch #199 - Loss: 0.8674516677856445\n",
      "Ep 41: Batch #0 - Loss: 0.7980118989944458\n",
      "Ep 41: Batch #1 - Loss: 0.8819068670272827\n",
      "Ep 41: Batch #2 - Loss: 1.0131036043167114\n",
      "Ep 41: Batch #3 - Loss: 0.8690376281738281\n",
      "Ep 41: Batch #4 - Loss: 0.7944667339324951\n",
      "Ep 41: Batch #5 - Loss: 0.6717217564582825\n",
      "Ep 41: Batch #6 - Loss: 0.8835669159889221\n",
      "Ep 41: Batch #7 - Loss: 0.7057979702949524\n",
      "Ep 41: Batch #8 - Loss: 0.7378392815589905\n",
      "Ep 41: Batch #9 - Loss: 1.4076354503631592\n",
      "Ep 41: Batch #10 - Loss: 1.0115697383880615\n",
      "Ep 41: Batch #11 - Loss: 0.6742099523544312\n",
      "Ep 41: Batch #12 - Loss: 1.5648695230484009\n",
      "Ep 41: Batch #13 - Loss: 0.6510046124458313\n",
      "Ep 41: Batch #14 - Loss: 0.7309272885322571\n",
      "Ep 41: Batch #15 - Loss: 1.24509596824646\n",
      "Ep 41: Batch #16 - Loss: 1.283017873764038\n",
      "Ep 41: Batch #17 - Loss: 0.8856075406074524\n",
      "Ep 41: Batch #18 - Loss: 0.9468827843666077\n",
      "Ep 41: Batch #19 - Loss: 0.6716704964637756\n",
      "Ep 41: Batch #20 - Loss: 0.6588316559791565\n",
      "Ep 41: Batch #21 - Loss: 1.2169244289398193\n",
      "Ep 41: Batch #22 - Loss: 0.7295931577682495\n",
      "Ep 41: Batch #23 - Loss: 0.7477770447731018\n",
      "Ep 41: Batch #24 - Loss: 0.8272361755371094\n",
      "Ep 41: Batch #25 - Loss: 0.7195591330528259\n",
      "Ep 41: Batch #26 - Loss: 0.7359808087348938\n",
      "Ep 41: Batch #27 - Loss: 1.3584699630737305\n",
      "Ep 41: Batch #28 - Loss: 0.8721534013748169\n",
      "Ep 41: Batch #29 - Loss: 0.8982648849487305\n",
      "Ep 41: Batch #30 - Loss: 1.2061655521392822\n",
      "Ep 41: Batch #31 - Loss: 0.6763426065444946\n",
      "Ep 41: Batch #32 - Loss: 0.7520806789398193\n",
      "Ep 41: Batch #33 - Loss: 0.8110500574111938\n",
      "Ep 41: Batch #34 - Loss: 0.7878919839859009\n",
      "Ep 41: Batch #35 - Loss: 0.9547408819198608\n",
      "Ep 41: Batch #36 - Loss: 0.7067409753799438\n",
      "Ep 41: Batch #37 - Loss: 1.1453816890716553\n",
      "Ep 41: Batch #38 - Loss: 0.7504099011421204\n",
      "Ep 41: Batch #39 - Loss: 0.8231703639030457\n",
      "Ep 41: Batch #40 - Loss: 0.7788305878639221\n",
      "Ep 41: Batch #41 - Loss: 0.7426642775535583\n",
      "Ep 41: Batch #42 - Loss: 0.7263142466545105\n",
      "Ep 41: Batch #43 - Loss: 0.7920093536376953\n",
      "Ep 41: Batch #44 - Loss: 0.7891533970832825\n",
      "Ep 41: Batch #45 - Loss: 0.6383321285247803\n",
      "Ep 41: Batch #46 - Loss: 0.8356409072875977\n",
      "Ep 41: Batch #47 - Loss: 0.9672544598579407\n",
      "Ep 41: Batch #48 - Loss: 1.3597866296768188\n",
      "Ep 41: Batch #49 - Loss: 1.0208920240402222\n",
      "Ep 41: Batch #50 - Loss: 0.7090696692466736\n",
      "Ep 41: Batch #51 - Loss: 1.0009725093841553\n",
      "Ep 41: Batch #52 - Loss: 0.7982155680656433\n",
      "Ep 41: Batch #53 - Loss: 0.8269307613372803\n",
      "Ep 41: Batch #54 - Loss: 0.7088664174079895\n",
      "Ep 41: Batch #55 - Loss: 0.7562654614448547\n",
      "Ep 41: Batch #56 - Loss: 1.2674325704574585\n",
      "Ep 41: Batch #57 - Loss: 0.8528575301170349\n",
      "Ep 41: Batch #58 - Loss: 1.005646824836731\n",
      "Ep 41: Batch #59 - Loss: 0.6841601729393005\n",
      "Ep 41: Batch #60 - Loss: 1.3149791955947876\n",
      "Ep 41: Batch #61 - Loss: 0.6397619843482971\n",
      "Ep 41: Batch #62 - Loss: 0.7273139953613281\n",
      "Ep 41: Batch #63 - Loss: 1.0077580213546753\n",
      "Ep 41: Batch #64 - Loss: 9.432758331298828\n",
      "Ep 41: Batch #65 - Loss: 0.6154481768608093\n",
      "Ep 41: Batch #66 - Loss: 0.8020559549331665\n",
      "Ep 41: Batch #67 - Loss: 0.9146134853363037\n",
      "Ep 41: Batch #68 - Loss: 0.9133641719818115\n",
      "Ep 41: Batch #69 - Loss: 0.7492789030075073\n",
      "Ep 41: Batch #70 - Loss: 0.7815478444099426\n",
      "Ep 41: Batch #71 - Loss: 0.6830801367759705\n",
      "Ep 41: Batch #72 - Loss: 0.8588840365409851\n",
      "Ep 41: Batch #73 - Loss: 0.909320056438446\n",
      "Ep 41: Batch #74 - Loss: 0.7453683614730835\n",
      "Ep 41: Batch #75 - Loss: 0.7718639969825745\n",
      "Ep 41: Batch #76 - Loss: 1.0993988513946533\n",
      "Ep 41: Batch #77 - Loss: 0.738784670829773\n",
      "Ep 41: Batch #78 - Loss: 1.1656265258789062\n",
      "Ep 41: Batch #79 - Loss: 0.6296210289001465\n",
      "Ep 41: Batch #80 - Loss: 0.8645401000976562\n",
      "Ep 41: Batch #81 - Loss: 1.6845953464508057\n",
      "Ep 41: Batch #82 - Loss: 0.8774024248123169\n",
      "Ep 41: Batch #83 - Loss: 1.738016963005066\n",
      "Ep 41: Batch #84 - Loss: 0.7187663316726685\n",
      "Ep 41: Batch #85 - Loss: 0.9771037697792053\n",
      "Ep 41: Batch #86 - Loss: 0.7134946584701538\n",
      "Ep 41: Batch #87 - Loss: 0.7169702053070068\n",
      "Ep 41: Batch #88 - Loss: 0.8065202832221985\n",
      "Ep 41: Batch #89 - Loss: 0.885976254940033\n",
      "Ep 41: Batch #90 - Loss: 1.1608105897903442\n",
      "Ep 41: Batch #91 - Loss: 0.8070248961448669\n",
      "Ep 41: Batch #92 - Loss: 1.0334984064102173\n",
      "Ep 41: Batch #93 - Loss: 1.0356483459472656\n",
      "Ep 41: Batch #94 - Loss: 1.054627537727356\n",
      "Ep 41: Batch #95 - Loss: 0.9241533875465393\n",
      "Ep 41: Batch #96 - Loss: 0.9091966152191162\n",
      "Ep 41: Batch #97 - Loss: 0.7336075305938721\n",
      "Ep 41: Batch #98 - Loss: 0.7428853511810303\n",
      "Ep 41: Batch #99 - Loss: 0.9623292088508606\n",
      "Ep 41: Batch #100 - Loss: 0.6820425987243652\n",
      "Ep 41: Batch #101 - Loss: 1.0512325763702393\n",
      "Ep 41: Batch #102 - Loss: 0.7862216234207153\n",
      "Ep 41: Batch #103 - Loss: 0.7939363121986389\n",
      "Ep 41: Batch #104 - Loss: 0.8052157759666443\n",
      "Ep 41: Batch #105 - Loss: 1.033725380897522\n",
      "Ep 41: Batch #106 - Loss: 0.7631610631942749\n",
      "Ep 41: Batch #107 - Loss: 0.7619920372962952\n",
      "Ep 41: Batch #108 - Loss: 1.0386757850646973\n",
      "Ep 41: Batch #109 - Loss: 0.7660601735115051\n",
      "Ep 41: Batch #110 - Loss: 0.9243811368942261\n",
      "Ep 41: Batch #111 - Loss: 1.3844940662384033\n",
      "Ep 41: Batch #112 - Loss: 1.0522207021713257\n",
      "Ep 41: Batch #113 - Loss: 0.8205670118331909\n",
      "Ep 41: Batch #114 - Loss: 0.9079158902168274\n",
      "Ep 41: Batch #115 - Loss: 1.0989596843719482\n",
      "Ep 41: Batch #116 - Loss: 0.635516881942749\n",
      "Ep 41: Batch #117 - Loss: 0.8761976957321167\n",
      "Ep 41: Batch #118 - Loss: 0.5476263165473938\n",
      "Model saved in file: ./weights_autoencoder_low_LR/model_e41b118_1516651274.22793.ckpt\n",
      "Ep 41: Batch #119 - Loss: 1.0311204195022583\n",
      "Ep 41: Batch #120 - Loss: 0.8035393953323364\n",
      "Ep 41: Batch #121 - Loss: 0.689731776714325\n",
      "Ep 41: Batch #122 - Loss: 0.8290549516677856\n",
      "Ep 41: Batch #123 - Loss: 0.8359293341636658\n",
      "Ep 41: Batch #124 - Loss: 0.6660729646682739\n",
      "Ep 41: Batch #125 - Loss: 2.724321126937866\n",
      "Ep 41: Batch #126 - Loss: 1.2297030687332153\n",
      "Ep 41: Batch #127 - Loss: 0.7538748383522034\n",
      "Ep 41: Batch #128 - Loss: 1.1115890741348267\n",
      "Ep 41: Batch #129 - Loss: 0.8432348370552063\n",
      "Ep 41: Batch #130 - Loss: 0.7274094820022583\n",
      "Ep 41: Batch #131 - Loss: 1.0012162923812866\n",
      "Ep 41: Batch #132 - Loss: 0.8283176422119141\n",
      "Ep 41: Batch #133 - Loss: 0.8217971920967102\n",
      "Ep 41: Batch #134 - Loss: 0.7732270956039429\n",
      "Ep 41: Batch #135 - Loss: 0.9716655611991882\n",
      "Ep 41: Batch #136 - Loss: 1.1871187686920166\n",
      "Ep 41: Batch #137 - Loss: 0.9693127870559692\n",
      "Ep 41: Batch #138 - Loss: 1.0749794244766235\n",
      "Ep 41: Batch #139 - Loss: 0.9047061800956726\n",
      "Ep 41: Batch #140 - Loss: 1.0535122156143188\n",
      "Ep 41: Batch #141 - Loss: 1.362816572189331\n",
      "Ep 41: Batch #142 - Loss: 0.7989030480384827\n",
      "Ep 41: Batch #143 - Loss: 0.9709632396697998\n",
      "Ep 41: Batch #144 - Loss: 0.7242410182952881\n",
      "Ep 41: Batch #145 - Loss: 0.681564211845398\n",
      "Ep 41: Batch #146 - Loss: 0.8877723217010498\n",
      "Ep 41: Batch #147 - Loss: 0.8673510551452637\n",
      "Ep 41: Batch #148 - Loss: 0.9829489588737488\n",
      "Ep 41: Batch #149 - Loss: 0.8592608571052551\n",
      "Ep 41: Batch #150 - Loss: 0.887269139289856\n",
      "Ep 41: Batch #151 - Loss: 0.7297083139419556\n",
      "Ep 41: Batch #152 - Loss: 0.7421727180480957\n",
      "Ep 41: Batch #153 - Loss: 1.1101926565170288\n",
      "Ep 41: Batch #154 - Loss: 0.7673406600952148\n",
      "Ep 41: Batch #155 - Loss: 0.8374475240707397\n",
      "Ep 41: Batch #156 - Loss: 1.0224196910858154\n",
      "Ep 41: Batch #157 - Loss: 0.7658907175064087\n",
      "Ep 41: Batch #158 - Loss: 0.80815589427948\n",
      "Ep 41: Batch #159 - Loss: 0.8127748370170593\n",
      "Ep 41: Batch #160 - Loss: 0.9072010517120361\n",
      "Ep 41: Batch #161 - Loss: 0.8202307820320129\n",
      "Ep 41: Batch #162 - Loss: 0.9367256760597229\n",
      "Ep 41: Batch #163 - Loss: 0.9331010580062866\n",
      "Ep 41: Batch #164 - Loss: 0.7888215184211731\n",
      "Ep 41: Batch #165 - Loss: 1.5038082599639893\n",
      "Ep 41: Batch #166 - Loss: 0.6835351586341858\n",
      "Ep 41: Batch #167 - Loss: 1.091467022895813\n",
      "Ep 41: Batch #168 - Loss: 0.8652493357658386\n",
      "Ep 41: Batch #169 - Loss: 0.8053693771362305\n",
      "Ep 41: Batch #170 - Loss: 0.8085390329360962\n",
      "Ep 41: Batch #171 - Loss: 0.7851850986480713\n",
      "Ep 41: Batch #172 - Loss: 0.6368700265884399\n",
      "Ep 41: Batch #173 - Loss: 1.2029087543487549\n",
      "Ep 41: Batch #174 - Loss: 0.5819641351699829\n",
      "Ep 41: Batch #175 - Loss: 0.7817026972770691\n",
      "Ep 41: Batch #176 - Loss: 1.1622693538665771\n",
      "Ep 41: Batch #177 - Loss: 0.8528708815574646\n",
      "Ep 41: Batch #178 - Loss: 0.7677434086799622\n",
      "Ep 41: Batch #179 - Loss: 0.944898247718811\n",
      "Ep 41: Batch #180 - Loss: 0.8608609437942505\n",
      "Ep 41: Batch #181 - Loss: 0.9975860118865967\n",
      "Ep 41: Batch #182 - Loss: 0.7677508592605591\n",
      "Ep 41: Batch #183 - Loss: 0.7690223455429077\n",
      "Ep 41: Batch #184 - Loss: 1.0716029405593872\n",
      "Ep 41: Batch #185 - Loss: 0.7622255682945251\n",
      "Ep 41: Batch #186 - Loss: 0.9730113744735718\n",
      "Ep 41: Batch #187 - Loss: 1.170737624168396\n",
      "Ep 41: Batch #188 - Loss: 1.3522924184799194\n",
      "Ep 41: Batch #189 - Loss: 0.704365074634552\n",
      "Ep 41: Batch #190 - Loss: 0.7386952638626099\n",
      "Ep 41: Batch #191 - Loss: 1.0692634582519531\n",
      "Ep 41: Batch #192 - Loss: 0.6726034879684448\n",
      "Ep 41: Batch #193 - Loss: 0.7453897595405579\n",
      "Ep 41: Batch #194 - Loss: 0.6999212503433228\n",
      "Ep 41: Batch #195 - Loss: 0.9873201251029968\n",
      "Ep 41: Batch #196 - Loss: 0.8691354393959045\n",
      "Ep 41: Batch #197 - Loss: 0.9059906005859375\n",
      "Ep 41: Batch #198 - Loss: 0.6819876432418823\n",
      "Ep 41: Batch #199 - Loss: 0.8660678267478943\n",
      "Ep 42: Batch #0 - Loss: 0.7965207099914551\n",
      "Ep 42: Batch #1 - Loss: 0.8805380463600159\n",
      "Ep 42: Batch #2 - Loss: 1.0118337869644165\n",
      "Ep 42: Batch #3 - Loss: 0.8678053617477417\n",
      "Ep 42: Batch #4 - Loss: 0.793087899684906\n",
      "Ep 42: Batch #5 - Loss: 0.6708152890205383\n",
      "Ep 42: Batch #6 - Loss: 0.8823150992393494\n",
      "Ep 42: Batch #7 - Loss: 0.7047523260116577\n",
      "Ep 42: Batch #8 - Loss: 0.7367919683456421\n",
      "Ep 42: Batch #9 - Loss: 1.4056260585784912\n",
      "Ep 42: Batch #10 - Loss: 1.0101226568222046\n",
      "Ep 42: Batch #11 - Loss: 0.6731407642364502\n",
      "Ep 42: Batch #12 - Loss: 1.5635226964950562\n",
      "Ep 42: Batch #13 - Loss: 0.6501893997192383\n",
      "Ep 42: Batch #14 - Loss: 0.729870080947876\n",
      "Ep 42: Batch #15 - Loss: 1.2434005737304688\n",
      "Ep 42: Batch #16 - Loss: 1.2810009717941284\n",
      "Ep 42: Batch #17 - Loss: 0.8842118382453918\n",
      "Ep 42: Batch #18 - Loss: 0.9458848237991333\n",
      "Ep 42: Batch #19 - Loss: 0.6706831455230713\n",
      "Ep 42: Batch #20 - Loss: 0.6577344536781311\n",
      "Ep 42: Batch #21 - Loss: 1.2155725955963135\n",
      "Ep 42: Batch #22 - Loss: 0.7285653948783875\n",
      "Ep 42: Batch #23 - Loss: 0.7464526295661926\n",
      "Ep 42: Batch #24 - Loss: 0.826125979423523\n",
      "Ep 42: Batch #25 - Loss: 0.718306303024292\n",
      "Ep 42: Batch #26 - Loss: 0.734615683555603\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 42: Batch #27 - Loss: 1.3566772937774658\n",
      "Ep 42: Batch #28 - Loss: 0.8708385229110718\n",
      "Ep 42: Batch #29 - Loss: 0.8967234492301941\n",
      "Ep 42: Batch #30 - Loss: 1.2047784328460693\n",
      "Ep 42: Batch #31 - Loss: 0.6754934191703796\n",
      "Ep 42: Batch #32 - Loss: 0.7508202195167542\n",
      "Ep 42: Batch #33 - Loss: 0.8100127577781677\n",
      "Ep 42: Batch #34 - Loss: 0.7867005467414856\n",
      "Ep 42: Batch #35 - Loss: 0.953063428401947\n",
      "Ep 42: Batch #36 - Loss: 0.7056010365486145\n",
      "Ep 42: Batch #37 - Loss: 1.1440460681915283\n",
      "Ep 42: Batch #38 - Loss: 0.7490109801292419\n",
      "Ep 42: Batch #39 - Loss: 0.8221499919891357\n",
      "Ep 42: Batch #40 - Loss: 0.7775351405143738\n",
      "Ep 42: Batch #41 - Loss: 0.7413248419761658\n",
      "Ep 42: Batch #42 - Loss: 0.725212037563324\n",
      "Ep 42: Batch #43 - Loss: 0.790823221206665\n",
      "Ep 42: Batch #44 - Loss: 0.787872850894928\n",
      "Ep 42: Batch #45 - Loss: 0.6370567083358765\n",
      "Ep 42: Batch #46 - Loss: 0.8342593908309937\n",
      "Ep 42: Batch #47 - Loss: 0.9655156135559082\n",
      "Ep 42: Batch #48 - Loss: 1.3580620288848877\n",
      "Ep 42: Batch #49 - Loss: 1.0192370414733887\n",
      "Ep 42: Batch #50 - Loss: 0.7081891298294067\n",
      "Ep 42: Batch #51 - Loss: 0.9992192387580872\n",
      "Ep 42: Batch #52 - Loss: 0.7971740961074829\n",
      "Ep 42: Batch #53 - Loss: 0.8256316781044006\n",
      "Ep 42: Batch #54 - Loss: 0.707831859588623\n",
      "Ep 42: Batch #55 - Loss: 0.7549323439598083\n",
      "Ep 42: Batch #56 - Loss: 1.2656556367874146\n",
      "Ep 42: Batch #57 - Loss: 0.851327657699585\n",
      "Ep 42: Batch #58 - Loss: 1.0039278268814087\n",
      "Ep 42: Batch #59 - Loss: 0.6831961870193481\n",
      "Ep 42: Batch #60 - Loss: 1.3135300874710083\n",
      "Ep 42: Batch #61 - Loss: 0.6387302875518799\n",
      "Ep 42: Batch #62 - Loss: 0.7259876728057861\n",
      "Ep 42: Batch #63 - Loss: 1.0061887502670288\n",
      "Ep 42: Batch #64 - Loss: 9.431496620178223\n",
      "Ep 42: Batch #65 - Loss: 0.6145015954971313\n",
      "Ep 42: Batch #66 - Loss: 0.8005208969116211\n",
      "Ep 42: Batch #67 - Loss: 0.9133216738700867\n",
      "Ep 42: Batch #68 - Loss: 0.9118585586547852\n",
      "Ep 42: Batch #69 - Loss: 0.7480327486991882\n",
      "Ep 42: Batch #70 - Loss: 0.7799814939498901\n",
      "Ep 42: Batch #71 - Loss: 0.6819879412651062\n",
      "Ep 42: Batch #72 - Loss: 0.8574995398521423\n",
      "Ep 42: Batch #73 - Loss: 0.9075978398323059\n",
      "Ep 42: Batch #74 - Loss: 0.7440342903137207\n",
      "Ep 42: Batch #75 - Loss: 0.7707335352897644\n",
      "Ep 42: Batch #76 - Loss: 1.0982184410095215\n",
      "Ep 42: Batch #77 - Loss: 0.7375429272651672\n",
      "Ep 42: Batch #78 - Loss: 1.163904070854187\n",
      "Ep 42: Batch #79 - Loss: 0.6285474300384521\n",
      "Ep 42: Batch #80 - Loss: 0.8630430698394775\n",
      "Ep 42: Batch #81 - Loss: 1.6831426620483398\n",
      "Ep 42: Batch #82 - Loss: 0.8761489391326904\n",
      "Ep 42: Batch #83 - Loss: 1.7369850873947144\n",
      "Ep 42: Batch #84 - Loss: 0.7174991369247437\n",
      "Ep 42: Batch #85 - Loss: 0.9759203195571899\n",
      "Ep 42: Batch #86 - Loss: 0.7121467590332031\n",
      "Ep 42: Batch #87 - Loss: 0.7158018946647644\n",
      "Ep 42: Batch #88 - Loss: 0.805111825466156\n",
      "Ep 42: Batch #89 - Loss: 0.8851042985916138\n",
      "Ep 42: Batch #90 - Loss: 1.1588438749313354\n",
      "Ep 42: Batch #91 - Loss: 0.8055627942085266\n",
      "Ep 42: Batch #92 - Loss: 1.031878113746643\n",
      "Ep 42: Batch #93 - Loss: 1.0338202714920044\n",
      "Ep 42: Batch #94 - Loss: 1.0529611110687256\n",
      "Ep 42: Batch #95 - Loss: 0.9227080941200256\n",
      "Ep 42: Batch #96 - Loss: 0.9077933430671692\n",
      "Ep 42: Batch #97 - Loss: 0.7323319315910339\n",
      "Ep 42: Batch #98 - Loss: 0.7416163682937622\n",
      "Ep 42: Batch #99 - Loss: 0.9610644578933716\n",
      "Ep 42: Batch #100 - Loss: 0.6808395385742188\n",
      "Ep 42: Batch #101 - Loss: 1.0497967004776\n",
      "Ep 42: Batch #102 - Loss: 0.7850214242935181\n",
      "Ep 42: Batch #103 - Loss: 0.7927353382110596\n",
      "Ep 42: Batch #104 - Loss: 0.8039466738700867\n",
      "Ep 42: Batch #105 - Loss: 1.032169222831726\n",
      "Ep 42: Batch #106 - Loss: 0.7619309425354004\n",
      "Ep 42: Batch #107 - Loss: 0.7606716156005859\n",
      "Ep 42: Batch #108 - Loss: 1.0370930433273315\n",
      "Ep 42: Batch #109 - Loss: 0.7649307250976562\n",
      "Ep 42: Batch #110 - Loss: 0.922723650932312\n",
      "Ep 42: Batch #111 - Loss: 1.3827910423278809\n",
      "Ep 42: Batch #112 - Loss: 1.050558090209961\n",
      "Ep 42: Batch #113 - Loss: 0.8192538619041443\n",
      "Ep 42: Batch #114 - Loss: 0.9064270257949829\n",
      "Ep 42: Batch #115 - Loss: 1.0973443984985352\n",
      "Ep 42: Batch #116 - Loss: 0.634737491607666\n",
      "Ep 42: Batch #117 - Loss: 0.8749129176139832\n",
      "Ep 42: Batch #118 - Loss: 0.546577513217926\n",
      "Model saved in file: ./weights_autoencoder_low_LR/model_e42b118_1516651274.3679175.ckpt\n",
      "Ep 42: Batch #119 - Loss: 1.029700756072998\n",
      "Ep 42: Batch #120 - Loss: 0.802423894405365\n",
      "Ep 42: Batch #121 - Loss: 0.6885147094726562\n",
      "Ep 42: Batch #122 - Loss: 0.8277795910835266\n",
      "Ep 42: Batch #123 - Loss: 0.8346572518348694\n",
      "Ep 42: Batch #124 - Loss: 0.6651526093482971\n",
      "Ep 42: Batch #125 - Loss: 2.7227632999420166\n",
      "Ep 42: Batch #126 - Loss: 1.2281829118728638\n",
      "Ep 42: Batch #127 - Loss: 0.7524347901344299\n",
      "Ep 42: Batch #128 - Loss: 1.109702229499817\n",
      "Ep 42: Batch #129 - Loss: 0.8418112993240356\n",
      "Ep 42: Batch #130 - Loss: 0.726174533367157\n",
      "Ep 42: Batch #131 - Loss: 0.9994173645973206\n",
      "Ep 42: Batch #132 - Loss: 0.8268947005271912\n",
      "Ep 42: Batch #133 - Loss: 0.820482611656189\n",
      "Ep 42: Batch #134 - Loss: 0.7719048261642456\n",
      "Ep 42: Batch #135 - Loss: 0.9700465202331543\n",
      "Ep 42: Batch #136 - Loss: 1.1852837800979614\n",
      "Ep 42: Batch #137 - Loss: 0.9677788019180298\n",
      "Ep 42: Batch #138 - Loss: 1.0734386444091797\n",
      "Ep 42: Batch #139 - Loss: 0.9032623767852783\n",
      "Ep 42: Batch #140 - Loss: 1.0520141124725342\n",
      "Ep 42: Batch #141 - Loss: 1.3612792491912842\n",
      "Ep 42: Batch #142 - Loss: 0.7976593375205994\n",
      "Ep 42: Batch #143 - Loss: 0.9692304134368896\n",
      "Ep 42: Batch #144 - Loss: 0.7230482697486877\n",
      "Ep 42: Batch #145 - Loss: 0.6804659366607666\n",
      "Ep 42: Batch #146 - Loss: 0.8865025043487549\n",
      "Ep 42: Batch #147 - Loss: 0.865703284740448\n",
      "Ep 42: Batch #148 - Loss: 0.9813553690910339\n",
      "Ep 42: Batch #149 - Loss: 0.8577246069908142\n",
      "Ep 42: Batch #150 - Loss: 0.8859606385231018\n",
      "Ep 42: Batch #151 - Loss: 0.7288227081298828\n",
      "Ep 42: Batch #152 - Loss: 0.7412199378013611\n",
      "Ep 42: Batch #153 - Loss: 1.1085419654846191\n",
      "Ep 42: Batch #154 - Loss: 0.7661879658699036\n",
      "Ep 42: Batch #155 - Loss: 0.8361016511917114\n",
      "Ep 42: Batch #156 - Loss: 1.0209145545959473\n",
      "Ep 42: Batch #157 - Loss: 0.764667272567749\n",
      "Ep 42: Batch #158 - Loss: 0.8071917295455933\n",
      "Ep 42: Batch #159 - Loss: 0.8114248514175415\n",
      "Ep 42: Batch #160 - Loss: 0.9060436487197876\n",
      "Ep 42: Batch #161 - Loss: 0.8189738392829895\n",
      "Ep 42: Batch #162 - Loss: 0.9353032112121582\n",
      "Ep 42: Batch #163 - Loss: 0.9320017099380493\n",
      "Ep 42: Batch #164 - Loss: 0.787590742111206\n",
      "Ep 42: Batch #165 - Loss: 1.502416968345642\n",
      "Ep 42: Batch #166 - Loss: 0.6822735071182251\n",
      "Ep 42: Batch #167 - Loss: 1.0900436639785767\n",
      "Ep 42: Batch #168 - Loss: 0.8638254404067993\n",
      "Ep 42: Batch #169 - Loss: 0.8041371703147888\n",
      "Ep 42: Batch #170 - Loss: 0.8072212338447571\n",
      "Ep 42: Batch #171 - Loss: 0.7837875485420227\n",
      "Ep 42: Batch #172 - Loss: 0.6359325051307678\n",
      "Ep 42: Batch #173 - Loss: 1.2009514570236206\n",
      "Ep 42: Batch #174 - Loss: 0.5810277462005615\n",
      "Ep 42: Batch #175 - Loss: 0.780642569065094\n",
      "Ep 42: Batch #176 - Loss: 1.160562515258789\n",
      "Ep 42: Batch #177 - Loss: 0.851540207862854\n",
      "Ep 42: Batch #178 - Loss: 0.7663801908493042\n",
      "Ep 42: Batch #179 - Loss: 0.9432169795036316\n",
      "Ep 42: Batch #180 - Loss: 0.8592196106910706\n",
      "Ep 42: Batch #181 - Loss: 0.9958232045173645\n",
      "Ep 42: Batch #182 - Loss: 0.7667302489280701\n",
      "Ep 42: Batch #183 - Loss: 0.7677070498466492\n",
      "Ep 42: Batch #184 - Loss: 1.0704572200775146\n",
      "Ep 42: Batch #185 - Loss: 0.7610584497451782\n",
      "Ep 42: Batch #186 - Loss: 0.9712449312210083\n",
      "Ep 42: Batch #187 - Loss: 1.1693854331970215\n",
      "Ep 42: Batch #188 - Loss: 1.351041555404663\n",
      "Ep 42: Batch #189 - Loss: 0.7034382820129395\n",
      "Ep 42: Batch #190 - Loss: 0.7375535368919373\n",
      "Ep 42: Batch #191 - Loss: 1.0678269863128662\n",
      "Ep 42: Batch #192 - Loss: 0.6716908812522888\n",
      "Ep 42: Batch #193 - Loss: 0.744060754776001\n",
      "Ep 42: Batch #194 - Loss: 0.6987684369087219\n",
      "Ep 42: Batch #195 - Loss: 0.9858396649360657\n",
      "Ep 42: Batch #196 - Loss: 0.8679000735282898\n",
      "Ep 42: Batch #197 - Loss: 0.9045988321304321\n",
      "Ep 42: Batch #198 - Loss: 0.6807618737220764\n",
      "Ep 42: Batch #199 - Loss: 0.8646949529647827\n",
      "Ep 43: Batch #0 - Loss: 0.7950363159179688\n",
      "Ep 43: Batch #1 - Loss: 0.8791773319244385\n",
      "Ep 43: Batch #2 - Loss: 1.0105699300765991\n",
      "Ep 43: Batch #3 - Loss: 0.8665899038314819\n",
      "Ep 43: Batch #4 - Loss: 0.7917206287384033\n",
      "Ep 43: Batch #5 - Loss: 0.6699100732803345\n",
      "Ep 43: Batch #6 - Loss: 0.8810586333274841\n",
      "Ep 43: Batch #7 - Loss: 0.7037122249603271\n",
      "Ep 43: Batch #8 - Loss: 0.7357560396194458\n",
      "Ep 43: Batch #9 - Loss: 1.403612494468689\n",
      "Ep 43: Batch #10 - Loss: 1.0086979866027832\n",
      "Ep 43: Batch #11 - Loss: 0.6720805764198303\n",
      "Ep 43: Batch #12 - Loss: 1.5621459484100342\n",
      "Ep 43: Batch #13 - Loss: 0.6493797898292542\n",
      "Ep 43: Batch #14 - Loss: 0.7288284301757812\n",
      "Ep 43: Batch #15 - Loss: 1.2417216300964355\n",
      "Ep 43: Batch #16 - Loss: 1.2790096998214722\n",
      "Ep 43: Batch #17 - Loss: 0.8828135132789612\n",
      "Ep 43: Batch #18 - Loss: 0.9447605013847351\n",
      "Ep 43: Batch #19 - Loss: 0.6697081327438354\n",
      "Ep 43: Batch #20 - Loss: 0.6566466689109802\n",
      "Ep 43: Batch #21 - Loss: 1.2142289876937866\n",
      "Ep 43: Batch #22 - Loss: 0.7275485992431641\n",
      "Ep 43: Batch #23 - Loss: 0.7451505661010742\n",
      "Ep 43: Batch #24 - Loss: 0.825030505657196\n",
      "Ep 43: Batch #25 - Loss: 0.7170554995536804\n",
      "Ep 43: Batch #26 - Loss: 0.7332577705383301\n",
      "Ep 43: Batch #27 - Loss: 1.3548845052719116\n",
      "Ep 43: Batch #28 - Loss: 0.8695386648178101\n",
      "Ep 43: Batch #29 - Loss: 0.8952009081840515\n",
      "Ep 43: Batch #30 - Loss: 1.203425407409668\n",
      "Ep 43: Batch #31 - Loss: 0.6746553778648376\n",
      "Ep 43: Batch #32 - Loss: 0.7495637536048889\n",
      "Ep 43: Batch #33 - Loss: 0.808981716632843\n",
      "Ep 43: Batch #34 - Loss: 0.7855241894721985\n",
      "Ep 43: Batch #35 - Loss: 0.9513953924179077\n",
      "Ep 43: Batch #36 - Loss: 0.7044710516929626\n",
      "Ep 43: Batch #37 - Loss: 1.142716407775879\n",
      "Ep 43: Batch #38 - Loss: 0.7476255893707275\n",
      "Ep 43: Batch #39 - Loss: 0.8211355805397034\n",
      "Ep 43: Batch #40 - Loss: 0.7762510776519775\n",
      "Ep 43: Batch #41 - Loss: 0.7399904131889343\n",
      "Ep 43: Batch #42 - Loss: 0.7241191267967224\n",
      "Ep 43: Batch #43 - Loss: 0.7896504998207092\n",
      "Ep 43: Batch #44 - Loss: 0.7865983843803406\n",
      "Ep 43: Batch #45 - Loss: 0.6357904672622681\n",
      "Ep 43: Batch #46 - Loss: 0.832879900932312\n",
      "Ep 43: Batch #47 - Loss: 0.9637874960899353\n",
      "Ep 43: Batch #48 - Loss: 1.356369972229004\n",
      "Ep 43: Batch #49 - Loss: 1.0175681114196777\n",
      "Ep 43: Batch #50 - Loss: 0.7073068022727966\n",
      "Ep 43: Batch #51 - Loss: 0.9974703192710876\n",
      "Ep 43: Batch #52 - Loss: 0.7961310148239136\n",
      "Ep 43: Batch #53 - Loss: 0.8243361711502075\n",
      "Ep 43: Batch #54 - Loss: 0.7067908644676208\n",
      "Ep 43: Batch #55 - Loss: 0.7536113858222961\n",
      "Ep 43: Batch #56 - Loss: 1.2638943195343018\n",
      "Ep 43: Batch #57 - Loss: 0.8498180508613586\n",
      "Ep 43: Batch #58 - Loss: 1.0022064447402954\n",
      "Ep 43: Batch #59 - Loss: 0.6822528839111328\n",
      "Ep 43: Batch #60 - Loss: 1.312106966972351\n",
      "Ep 43: Batch #61 - Loss: 0.637710690498352\n",
      "Ep 43: Batch #62 - Loss: 0.7246593236923218\n",
      "Ep 43: Batch #63 - Loss: 1.004618763923645\n",
      "Ep 43: Batch #64 - Loss: 9.430269241333008\n",
      "Ep 43: Batch #65 - Loss: 0.6135606169700623\n",
      "Ep 43: Batch #66 - Loss: 0.7990071177482605\n",
      "Ep 43: Batch #67 - Loss: 0.9120442271232605\n",
      "Ep 43: Batch #68 - Loss: 0.9103462100028992\n",
      "Ep 43: Batch #69 - Loss: 0.7467948198318481\n",
      "Ep 43: Batch #70 - Loss: 0.7784375548362732\n",
      "Ep 43: Batch #71 - Loss: 0.6809091567993164\n",
      "Ep 43: Batch #72 - Loss: 0.8561275601387024\n",
      "Ep 43: Batch #73 - Loss: 0.9058851003646851\n",
      "Ep 43: Batch #74 - Loss: 0.7427077293395996\n",
      "Ep 43: Batch #75 - Loss: 0.7696054577827454\n",
      "Ep 43: Batch #76 - Loss: 1.0970478057861328\n",
      "Ep 43: Batch #77 - Loss: 0.7363010048866272\n",
      "Ep 43: Batch #78 - Loss: 1.162175178527832\n",
      "Ep 43: Batch #79 - Loss: 0.627484142780304\n",
      "Ep 43: Batch #80 - Loss: 0.8615565299987793\n",
      "Ep 43: Batch #81 - Loss: 1.681706190109253\n",
      "Ep 43: Batch #82 - Loss: 0.8749173283576965\n",
      "Ep 43: Batch #83 - Loss: 1.7359604835510254\n",
      "Ep 43: Batch #84 - Loss: 0.7162302136421204\n",
      "Ep 43: Batch #85 - Loss: 0.9747503399848938\n",
      "Ep 43: Batch #86 - Loss: 0.7108055353164673\n",
      "Ep 43: Batch #87 - Loss: 0.7146375179290771\n",
      "Ep 43: Batch #88 - Loss: 0.803704023361206\n",
      "Ep 43: Batch #89 - Loss: 0.8842374682426453\n",
      "Ep 43: Batch #90 - Loss: 1.1569055318832397\n",
      "Ep 43: Batch #91 - Loss: 0.8041067719459534\n",
      "Ep 43: Batch #92 - Loss: 1.0302770137786865\n",
      "Ep 43: Batch #93 - Loss: 1.031994104385376\n",
      "Ep 43: Batch #94 - Loss: 1.0512980222702026\n",
      "Ep 43: Batch #95 - Loss: 0.9212750196456909\n",
      "Ep 43: Batch #96 - Loss: 0.9064196944236755\n",
      "Ep 43: Batch #97 - Loss: 0.7310696244239807\n",
      "Ep 43: Batch #98 - Loss: 0.7403597235679626\n",
      "Ep 43: Batch #99 - Loss: 0.9597903490066528\n",
      "Ep 43: Batch #100 - Loss: 0.6796453595161438\n",
      "Ep 43: Batch #101 - Loss: 1.0483711957931519\n",
      "Ep 43: Batch #102 - Loss: 0.783829391002655\n",
      "Ep 43: Batch #103 - Loss: 0.7915509939193726\n",
      "Ep 43: Batch #104 - Loss: 0.8026872277259827\n",
      "Ep 43: Batch #105 - Loss: 1.0305466651916504\n",
      "Ep 43: Batch #106 - Loss: 0.7607080340385437\n",
      "Ep 43: Batch #107 - Loss: 0.7593604922294617\n",
      "Ep 43: Batch #108 - Loss: 1.0355216264724731\n",
      "Ep 43: Batch #109 - Loss: 0.763813316822052\n",
      "Ep 43: Batch #110 - Loss: 0.9210780262947083\n",
      "Ep 43: Batch #111 - Loss: 1.3810871839523315\n",
      "Ep 43: Batch #112 - Loss: 1.0489040613174438\n",
      "Ep 43: Batch #113 - Loss: 0.8179463744163513\n",
      "Ep 43: Batch #114 - Loss: 0.9049456715583801\n",
      "Ep 43: Batch #115 - Loss: 1.0957591533660889\n",
      "Ep 43: Batch #116 - Loss: 0.6339635252952576\n",
      "Ep 43: Batch #117 - Loss: 0.8736463785171509\n",
      "Ep 43: Batch #118 - Loss: 0.5455459952354431\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved in file: ./weights_autoencoder_low_LR/model_e43b118_1516651274.504101.ckpt\n",
      "Ep 43: Batch #119 - Loss: 1.0282962322235107\n",
      "Ep 43: Batch #120 - Loss: 0.8013077974319458\n",
      "Ep 43: Batch #121 - Loss: 0.6873032450675964\n",
      "Ep 43: Batch #122 - Loss: 0.8265290260314941\n",
      "Ep 43: Batch #123 - Loss: 0.8333861231803894\n",
      "Ep 43: Batch #124 - Loss: 0.6642420887947083\n",
      "Ep 43: Batch #125 - Loss: 2.7212324142456055\n",
      "Ep 43: Batch #126 - Loss: 1.2266664505004883\n",
      "Ep 43: Batch #127 - Loss: 0.7510015964508057\n",
      "Ep 43: Batch #128 - Loss: 1.1078404188156128\n",
      "Ep 43: Batch #129 - Loss: 0.8403847813606262\n",
      "Ep 43: Batch #130 - Loss: 0.7249543070793152\n",
      "Ep 43: Batch #131 - Loss: 0.9976275563240051\n",
      "Ep 43: Batch #132 - Loss: 0.8254861831665039\n",
      "Ep 43: Batch #133 - Loss: 0.8191815614700317\n",
      "Ep 43: Batch #134 - Loss: 0.7705916166305542\n",
      "Ep 43: Batch #135 - Loss: 0.9684207439422607\n",
      "Ep 43: Batch #136 - Loss: 1.183467149734497\n",
      "Ep 43: Batch #137 - Loss: 0.966259241104126\n",
      "Ep 43: Batch #138 - Loss: 1.071908712387085\n",
      "Ep 43: Batch #139 - Loss: 0.9018146991729736\n",
      "Ep 43: Batch #140 - Loss: 1.050511121749878\n",
      "Ep 43: Batch #141 - Loss: 1.359758973121643\n",
      "Ep 43: Batch #142 - Loss: 0.7964144349098206\n",
      "Ep 43: Batch #143 - Loss: 0.9674979448318481\n",
      "Ep 43: Batch #144 - Loss: 0.7218735814094543\n",
      "Ep 43: Batch #145 - Loss: 0.6793702840805054\n",
      "Ep 43: Batch #146 - Loss: 0.8852430582046509\n",
      "Ep 43: Batch #147 - Loss: 0.8640639781951904\n",
      "Ep 43: Batch #148 - Loss: 0.979773759841919\n",
      "Ep 43: Batch #149 - Loss: 0.8562018275260925\n",
      "Ep 43: Batch #150 - Loss: 0.8846473097801208\n",
      "Ep 43: Batch #151 - Loss: 0.727940559387207\n",
      "Ep 43: Batch #152 - Loss: 0.740268886089325\n",
      "Ep 43: Batch #153 - Loss: 1.1068956851959229\n",
      "Ep 43: Batch #154 - Loss: 0.7650291919708252\n",
      "Ep 43: Batch #155 - Loss: 0.8347784876823425\n",
      "Ep 43: Batch #156 - Loss: 1.019424557685852\n",
      "Ep 43: Batch #157 - Loss: 0.7634573578834534\n",
      "Ep 43: Batch #158 - Loss: 0.8062381148338318\n",
      "Ep 43: Batch #159 - Loss: 0.8100661039352417\n",
      "Ep 43: Batch #160 - Loss: 0.9048924446105957\n",
      "Ep 43: Batch #161 - Loss: 0.8177314400672913\n",
      "Ep 43: Batch #162 - Loss: 0.9338900446891785\n",
      "Ep 43: Batch #163 - Loss: 0.9309008121490479\n",
      "Ep 43: Batch #164 - Loss: 0.7863548994064331\n",
      "Ep 43: Batch #165 - Loss: 1.5010231733322144\n",
      "Ep 43: Batch #166 - Loss: 0.6810269951820374\n",
      "Ep 43: Batch #167 - Loss: 1.0886192321777344\n",
      "Ep 43: Batch #168 - Loss: 0.8624138236045837\n",
      "Ep 43: Batch #169 - Loss: 0.8029221296310425\n",
      "Ep 43: Batch #170 - Loss: 0.8059052228927612\n",
      "Ep 43: Batch #171 - Loss: 0.7824018001556396\n",
      "Ep 43: Batch #172 - Loss: 0.6350120306015015\n",
      "Ep 43: Batch #173 - Loss: 1.1989902257919312\n",
      "Ep 43: Batch #174 - Loss: 0.5801025629043579\n",
      "Ep 43: Batch #175 - Loss: 0.7796038389205933\n",
      "Ep 43: Batch #176 - Loss: 1.1587997674942017\n",
      "Ep 43: Batch #177 - Loss: 0.8502269983291626\n",
      "Ep 43: Batch #178 - Loss: 0.7650293111801147\n",
      "Ep 43: Batch #179 - Loss: 0.9415501952171326\n",
      "Ep 43: Batch #180 - Loss: 0.8575809001922607\n",
      "Ep 43: Batch #181 - Loss: 0.9940778017044067\n",
      "Ep 43: Batch #182 - Loss: 0.7657193541526794\n",
      "Ep 43: Batch #183 - Loss: 0.7664061784744263\n",
      "Ep 43: Batch #184 - Loss: 1.0693219900131226\n",
      "Ep 43: Batch #185 - Loss: 0.7598934173583984\n",
      "Ep 43: Batch #186 - Loss: 0.9694864153862\n",
      "Ep 43: Batch #187 - Loss: 1.1680678129196167\n",
      "Ep 43: Batch #188 - Loss: 1.3498049974441528\n",
      "Ep 43: Batch #189 - Loss: 0.7025028467178345\n",
      "Ep 43: Batch #190 - Loss: 0.7364178895950317\n",
      "Ep 43: Batch #191 - Loss: 1.0663689374923706\n",
      "Ep 43: Batch #192 - Loss: 0.6707862615585327\n",
      "Ep 43: Batch #193 - Loss: 0.7427429556846619\n",
      "Ep 43: Batch #194 - Loss: 0.6976219415664673\n",
      "Ep 43: Batch #195 - Loss: 0.9843630790710449\n",
      "Ep 43: Batch #196 - Loss: 0.8666712641716003\n",
      "Ep 43: Batch #197 - Loss: 0.9032100439071655\n",
      "Ep 43: Batch #198 - Loss: 0.679539144039154\n",
      "Ep 43: Batch #199 - Loss: 0.8633214831352234\n",
      "Ep 44: Batch #0 - Loss: 0.7935581803321838\n",
      "Ep 44: Batch #1 - Loss: 0.8778272867202759\n",
      "Ep 44: Batch #2 - Loss: 1.0093164443969727\n",
      "Ep 44: Batch #3 - Loss: 0.8653932809829712\n",
      "Ep 44: Batch #4 - Loss: 0.7903596758842468\n",
      "Ep 44: Batch #5 - Loss: 0.6690056324005127\n",
      "Ep 44: Batch #6 - Loss: 0.8798019886016846\n",
      "Ep 44: Batch #7 - Loss: 0.7026787996292114\n",
      "Ep 44: Batch #8 - Loss: 0.7347245812416077\n",
      "Ep 44: Batch #9 - Loss: 1.401612639427185\n",
      "Ep 44: Batch #10 - Loss: 1.0072964429855347\n",
      "Ep 44: Batch #11 - Loss: 0.6710329651832581\n",
      "Ep 44: Batch #12 - Loss: 1.560745358467102\n",
      "Ep 44: Batch #13 - Loss: 0.6485763788223267\n",
      "Ep 44: Batch #14 - Loss: 0.727801501750946\n",
      "Ep 44: Batch #15 - Loss: 1.2400496006011963\n",
      "Ep 44: Batch #16 - Loss: 1.2770198583602905\n",
      "Ep 44: Batch #17 - Loss: 0.8814027905464172\n",
      "Ep 44: Batch #18 - Loss: 0.9435844421386719\n",
      "Ep 44: Batch #19 - Loss: 0.6687441468238831\n",
      "Ep 44: Batch #20 - Loss: 0.6555678844451904\n",
      "Ep 44: Batch #21 - Loss: 1.2128833532333374\n",
      "Ep 44: Batch #22 - Loss: 0.7265421748161316\n",
      "Ep 44: Batch #23 - Loss: 0.743872880935669\n",
      "Ep 44: Batch #24 - Loss: 0.8239423036575317\n",
      "Ep 44: Batch #25 - Loss: 0.7158203125\n",
      "Ep 44: Batch #26 - Loss: 0.7319127917289734\n",
      "Ep 44: Batch #27 - Loss: 1.3531023263931274\n",
      "Ep 44: Batch #28 - Loss: 0.868259847164154\n",
      "Ep 44: Batch #29 - Loss: 0.8936710953712463\n",
      "Ep 44: Batch #30 - Loss: 1.2020982503890991\n",
      "Ep 44: Batch #31 - Loss: 0.6738232374191284\n",
      "Ep 44: Batch #32 - Loss: 0.7483159303665161\n",
      "Ep 44: Batch #33 - Loss: 0.8079586625099182\n",
      "Ep 44: Batch #34 - Loss: 0.7843565940856934\n",
      "Ep 44: Batch #35 - Loss: 0.9497411847114563\n",
      "Ep 44: Batch #36 - Loss: 0.7033450603485107\n",
      "Ep 44: Batch #37 - Loss: 1.141379952430725\n",
      "Ep 44: Batch #38 - Loss: 0.7462621331214905\n",
      "Ep 44: Batch #39 - Loss: 0.8201271295547485\n",
      "Ep 44: Batch #40 - Loss: 0.7749814391136169\n",
      "Ep 44: Batch #41 - Loss: 0.7386631965637207\n",
      "Ep 44: Batch #42 - Loss: 0.7230266332626343\n",
      "Ep 44: Batch #43 - Loss: 0.7884880900382996\n",
      "Ep 44: Batch #44 - Loss: 0.7853255867958069\n",
      "Ep 44: Batch #45 - Loss: 0.6345427632331848\n",
      "Ep 44: Batch #46 - Loss: 0.8315132260322571\n",
      "Ep 44: Batch #47 - Loss: 0.9620586633682251\n",
      "Ep 44: Batch #48 - Loss: 1.3546981811523438\n",
      "Ep 44: Batch #49 - Loss: 1.0158638954162598\n",
      "Ep 44: Batch #50 - Loss: 0.7064223289489746\n",
      "Ep 44: Batch #51 - Loss: 0.995730459690094\n",
      "Ep 44: Batch #52 - Loss: 0.7950944304466248\n",
      "Ep 44: Batch #53 - Loss: 0.8230511546134949\n",
      "Ep 44: Batch #54 - Loss: 0.7057475447654724\n",
      "Ep 44: Batch #55 - Loss: 0.7522994875907898\n",
      "Ep 44: Batch #56 - Loss: 1.2621541023254395\n",
      "Ep 44: Batch #57 - Loss: 0.8483285903930664\n",
      "Ep 44: Batch #58 - Loss: 1.0004820823669434\n",
      "Ep 44: Batch #59 - Loss: 0.6813262104988098\n",
      "Ep 44: Batch #60 - Loss: 1.3106927871704102\n",
      "Ep 44: Batch #61 - Loss: 0.636713981628418\n",
      "Ep 44: Batch #62 - Loss: 0.72333824634552\n",
      "Ep 44: Batch #63 - Loss: 1.0030746459960938\n",
      "Ep 44: Batch #64 - Loss: 9.429060935974121\n",
      "Ep 44: Batch #65 - Loss: 0.6126312017440796\n",
      "Ep 44: Batch #66 - Loss: 0.7975060343742371\n",
      "Ep 44: Batch #67 - Loss: 0.9107810854911804\n",
      "Ep 44: Batch #68 - Loss: 0.9088465571403503\n",
      "Ep 44: Batch #69 - Loss: 0.7455720901489258\n",
      "Ep 44: Batch #70 - Loss: 0.776907205581665\n",
      "Ep 44: Batch #71 - Loss: 0.6798411011695862\n",
      "Ep 44: Batch #72 - Loss: 0.8547640442848206\n",
      "Ep 44: Batch #73 - Loss: 0.9041811227798462\n",
      "Ep 44: Batch #74 - Loss: 0.7413848042488098\n",
      "Ep 44: Batch #75 - Loss: 0.7684865593910217\n",
      "Ep 44: Batch #76 - Loss: 1.095892310142517\n",
      "Ep 44: Batch #77 - Loss: 0.7350609302520752\n",
      "Ep 44: Batch #78 - Loss: 1.1604549884796143\n",
      "Ep 44: Batch #79 - Loss: 0.6264368295669556\n",
      "Ep 44: Batch #80 - Loss: 0.8600814938545227\n",
      "Ep 44: Batch #81 - Loss: 1.6802845001220703\n",
      "Ep 44: Batch #82 - Loss: 0.8736836314201355\n",
      "Ep 44: Batch #83 - Loss: 1.7349305152893066\n",
      "Ep 44: Batch #84 - Loss: 0.7149741649627686\n",
      "Ep 44: Batch #85 - Loss: 0.9735931754112244\n",
      "Ep 44: Batch #86 - Loss: 0.7094783186912537\n",
      "Ep 44: Batch #87 - Loss: 0.7134791016578674\n",
      "Ep 44: Batch #88 - Loss: 0.8023137450218201\n",
      "Ep 44: Batch #89 - Loss: 0.8833727836608887\n",
      "Ep 44: Batch #90 - Loss: 1.154990553855896\n",
      "Ep 44: Batch #91 - Loss: 0.8026593923568726\n",
      "Ep 44: Batch #92 - Loss: 1.0287009477615356\n",
      "Ep 44: Batch #93 - Loss: 1.0301785469055176\n",
      "Ep 44: Batch #94 - Loss: 1.0496463775634766\n",
      "Ep 44: Batch #95 - Loss: 0.9198591709136963\n",
      "Ep 44: Batch #96 - Loss: 0.9050677418708801\n",
      "Ep 44: Batch #97 - Loss: 0.7298212051391602\n",
      "Ep 44: Batch #98 - Loss: 0.7391183972358704\n",
      "Ep 44: Batch #99 - Loss: 0.9585343599319458\n",
      "Ep 44: Batch #100 - Loss: 0.678463339805603\n",
      "Ep 44: Batch #101 - Loss: 1.0469672679901123\n",
      "Ep 44: Batch #102 - Loss: 0.7826461791992188\n",
      "Ep 44: Batch #103 - Loss: 0.790372908115387\n",
      "Ep 44: Batch #104 - Loss: 0.8014402985572815\n",
      "Ep 44: Batch #105 - Loss: 1.0289156436920166\n",
      "Ep 44: Batch #106 - Loss: 0.7594969272613525\n",
      "Ep 44: Batch #107 - Loss: 0.7580626010894775\n",
      "Ep 44: Batch #108 - Loss: 1.0339542627334595\n",
      "Ep 44: Batch #109 - Loss: 0.7627006769180298\n",
      "Ep 44: Batch #110 - Loss: 0.919413685798645\n",
      "Ep 44: Batch #111 - Loss: 1.3793890476226807\n",
      "Ep 44: Batch #112 - Loss: 1.0472828149795532\n",
      "Ep 44: Batch #113 - Loss: 0.816650390625\n",
      "Ep 44: Batch #114 - Loss: 0.90346759557724\n",
      "Ep 44: Batch #115 - Loss: 1.094191074371338\n",
      "Ep 44: Batch #116 - Loss: 0.6332026720046997\n",
      "Ep 44: Batch #117 - Loss: 0.8724002838134766\n",
      "Ep 44: Batch #118 - Loss: 0.5445322394371033\n",
      "Model saved in file: ./weights_autoencoder_low_LR/model_e44b118_1516651274.6412907.ckpt\n",
      "Ep 44: Batch #119 - Loss: 1.026911973953247\n",
      "Ep 44: Batch #120 - Loss: 0.8001949787139893\n",
      "Ep 44: Batch #121 - Loss: 0.6861065030097961\n",
      "Ep 44: Batch #122 - Loss: 0.8252828121185303\n",
      "Ep 44: Batch #123 - Loss: 0.8321214318275452\n",
      "Ep 44: Batch #124 - Loss: 0.6633384823799133\n",
      "Ep 44: Batch #125 - Loss: 2.719724416732788\n",
      "Ep 44: Batch #126 - Loss: 1.225164771080017\n",
      "Ep 44: Batch #127 - Loss: 0.7495896816253662\n",
      "Ep 44: Batch #128 - Loss: 1.1059849262237549\n",
      "Ep 44: Batch #129 - Loss: 0.838970422744751\n",
      "Ep 44: Batch #130 - Loss: 0.7237412333488464\n",
      "Ep 44: Batch #131 - Loss: 0.9958356618881226\n",
      "Ep 44: Batch #132 - Loss: 0.8240787386894226\n",
      "Ep 44: Batch #133 - Loss: 0.817889392375946\n",
      "Ep 44: Batch #134 - Loss: 0.7692883610725403\n",
      "Ep 44: Batch #135 - Loss: 0.9667721390724182\n",
      "Ep 44: Batch #136 - Loss: 1.1816632747650146\n",
      "Ep 44: Batch #137 - Loss: 0.9647522568702698\n",
      "Ep 44: Batch #138 - Loss: 1.0703953504562378\n",
      "Ep 44: Batch #139 - Loss: 0.9003790616989136\n",
      "Ep 44: Batch #140 - Loss: 1.0490059852600098\n",
      "Ep 44: Batch #141 - Loss: 1.3582569360733032\n",
      "Ep 44: Batch #142 - Loss: 0.7951793074607849\n",
      "Ep 44: Batch #143 - Loss: 0.9657845497131348\n",
      "Ep 44: Batch #144 - Loss: 0.7207167744636536\n",
      "Ep 44: Batch #145 - Loss: 0.6782861351966858\n",
      "Ep 44: Batch #146 - Loss: 0.8839928507804871\n",
      "Ep 44: Batch #147 - Loss: 0.8624349236488342\n",
      "Ep 44: Batch #148 - Loss: 0.9781736731529236\n",
      "Ep 44: Batch #149 - Loss: 0.8546870946884155\n",
      "Ep 44: Batch #150 - Loss: 0.883342981338501\n",
      "Ep 44: Batch #151 - Loss: 0.7270724177360535\n",
      "Ep 44: Batch #152 - Loss: 0.7393317818641663\n",
      "Ep 44: Batch #153 - Loss: 1.1052495241165161\n",
      "Ep 44: Batch #154 - Loss: 0.7638724446296692\n",
      "Ep 44: Batch #155 - Loss: 0.8334732055664062\n",
      "Ep 44: Batch #156 - Loss: 1.0179541110992432\n",
      "Ep 44: Batch #157 - Loss: 0.7622635960578918\n",
      "Ep 44: Batch #158 - Loss: 0.8052968382835388\n",
      "Ep 44: Batch #159 - Loss: 0.8087190985679626\n",
      "Ep 44: Batch #160 - Loss: 0.9037296772003174\n",
      "Ep 44: Batch #161 - Loss: 0.8165010809898376\n",
      "Ep 44: Batch #162 - Loss: 0.9324875473976135\n",
      "Ep 44: Batch #163 - Loss: 0.9298065900802612\n",
      "Ep 44: Batch #164 - Loss: 0.7851275205612183\n",
      "Ep 44: Batch #165 - Loss: 1.4996386766433716\n",
      "Ep 44: Batch #166 - Loss: 0.6797984838485718\n",
      "Ep 44: Batch #167 - Loss: 1.0871977806091309\n",
      "Ep 44: Batch #168 - Loss: 0.8609991669654846\n",
      "Ep 44: Batch #169 - Loss: 0.8017179369926453\n",
      "Ep 44: Batch #170 - Loss: 0.8046024441719055\n",
      "Ep 44: Batch #171 - Loss: 0.7810333967208862\n",
      "Ep 44: Batch #172 - Loss: 0.6341042518615723\n",
      "Ep 44: Batch #173 - Loss: 1.1970360279083252\n",
      "Ep 44: Batch #174 - Loss: 0.579192042350769\n",
      "Ep 44: Batch #175 - Loss: 0.7785812020301819\n",
      "Ep 44: Batch #176 - Loss: 1.1570078134536743\n",
      "Ep 44: Batch #177 - Loss: 0.8489102125167847\n",
      "Ep 44: Batch #178 - Loss: 0.76369708776474\n",
      "Ep 44: Batch #179 - Loss: 0.9399152398109436\n",
      "Ep 44: Batch #180 - Loss: 0.855951189994812\n",
      "Ep 44: Batch #181 - Loss: 0.9923453330993652\n",
      "Ep 44: Batch #182 - Loss: 0.7647324800491333\n",
      "Ep 44: Batch #183 - Loss: 0.7651180624961853\n",
      "Ep 44: Batch #184 - Loss: 1.0681947469711304\n",
      "Ep 44: Batch #185 - Loss: 0.7587317228317261\n",
      "Ep 44: Batch #186 - Loss: 0.9677388668060303\n",
      "Ep 44: Batch #187 - Loss: 1.1667757034301758\n",
      "Ep 44: Batch #188 - Loss: 1.3485772609710693\n",
      "Ep 44: Batch #189 - Loss: 0.701573371887207\n",
      "Ep 44: Batch #190 - Loss: 0.7352986335754395\n",
      "Ep 44: Batch #191 - Loss: 1.0649123191833496\n",
      "Ep 44: Batch #192 - Loss: 0.6698896884918213\n",
      "Ep 44: Batch #193 - Loss: 0.7414366602897644\n",
      "Ep 44: Batch #194 - Loss: 0.6964924931526184\n",
      "Ep 44: Batch #195 - Loss: 0.9828954339027405\n",
      "Ep 44: Batch #196 - Loss: 0.8654552102088928\n",
      "Ep 44: Batch #197 - Loss: 0.9018301367759705\n",
      "Ep 44: Batch #198 - Loss: 0.6783215999603271\n",
      "Ep 44: Batch #199 - Loss: 0.861957311630249\n",
      "Ep 45: Batch #0 - Loss: 0.792091429233551\n",
      "Ep 45: Batch #1 - Loss: 0.8764862418174744\n",
      "Ep 45: Batch #2 - Loss: 1.008016586303711\n",
      "Ep 45: Batch #3 - Loss: 0.8642174601554871\n",
      "Ep 45: Batch #4 - Loss: 0.7890098094940186\n",
      "Ep 45: Batch #5 - Loss: 0.6681054830551147\n",
      "Ep 45: Batch #6 - Loss: 0.8785517811775208\n",
      "Ep 45: Batch #7 - Loss: 0.7016496062278748\n",
      "Ep 45: Batch #8 - Loss: 0.7336879372596741\n",
      "Ep 45: Batch #9 - Loss: 1.3996357917785645\n",
      "Ep 45: Batch #10 - Loss: 1.0059157609939575\n",
      "Ep 45: Batch #11 - Loss: 0.6699944734573364\n",
      "Ep 45: Batch #12 - Loss: 1.559231162071228\n",
      "Ep 45: Batch #13 - Loss: 0.6477797627449036\n",
      "Ep 45: Batch #14 - Loss: 0.7267823815345764\n",
      "Ep 45: Batch #15 - Loss: 1.2383911609649658\n",
      "Ep 45: Batch #16 - Loss: 1.275081753730774\n",
      "Ep 45: Batch #17 - Loss: 0.8800030946731567\n",
      "Ep 45: Batch #18 - Loss: 0.9424229860305786\n",
      "Ep 45: Batch #19 - Loss: 0.6677885055541992\n",
      "Ep 45: Batch #20 - Loss: 0.6544995903968811\n",
      "Ep 45: Batch #21 - Loss: 1.2115521430969238\n",
      "Ep 45: Batch #22 - Loss: 0.7255430221557617\n",
      "Ep 45: Batch #23 - Loss: 0.7426174283027649\n",
      "Ep 45: Batch #24 - Loss: 0.8228598237037659\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 45: Batch #25 - Loss: 0.7145954370498657\n",
      "Ep 45: Batch #26 - Loss: 0.7305805683135986\n",
      "Ep 45: Batch #27 - Loss: 1.3513199090957642\n",
      "Ep 45: Batch #28 - Loss: 0.8669880628585815\n",
      "Ep 45: Batch #29 - Loss: 0.8921530246734619\n",
      "Ep 45: Batch #30 - Loss: 1.2007774114608765\n",
      "Ep 45: Batch #31 - Loss: 0.6729986667633057\n",
      "Ep 45: Batch #32 - Loss: 0.7470800876617432\n",
      "Ep 45: Batch #33 - Loss: 0.8069528341293335\n",
      "Ep 45: Batch #34 - Loss: 0.7832014560699463\n",
      "Ep 45: Batch #35 - Loss: 0.9481090903282166\n",
      "Ep 45: Batch #36 - Loss: 0.7022171020507812\n",
      "Ep 45: Batch #37 - Loss: 1.1400470733642578\n",
      "Ep 45: Batch #38 - Loss: 0.7449191808700562\n",
      "Ep 45: Batch #39 - Loss: 0.8191279172897339\n",
      "Ep 45: Batch #40 - Loss: 0.7737264633178711\n",
      "Ep 45: Batch #41 - Loss: 0.7373412251472473\n",
      "Ep 45: Batch #42 - Loss: 0.7219263315200806\n",
      "Ep 45: Batch #43 - Loss: 0.7873354554176331\n",
      "Ep 45: Batch #44 - Loss: 0.7840574383735657\n",
      "Ep 45: Batch #45 - Loss: 0.6333125233650208\n",
      "Ep 45: Batch #46 - Loss: 0.8301485180854797\n",
      "Ep 45: Batch #47 - Loss: 0.9603342413902283\n",
      "Ep 45: Batch #48 - Loss: 1.3530528545379639\n",
      "Ep 45: Batch #49 - Loss: 1.0141386985778809\n",
      "Ep 45: Batch #50 - Loss: 0.7055465579032898\n",
      "Ep 45: Batch #51 - Loss: 0.9939857721328735\n",
      "Ep 45: Batch #52 - Loss: 0.7940618991851807\n",
      "Ep 45: Batch #53 - Loss: 0.821747899055481\n",
      "Ep 45: Batch #54 - Loss: 0.7047248482704163\n",
      "Ep 45: Batch #55 - Loss: 0.7510062456130981\n",
      "Ep 45: Batch #56 - Loss: 1.2604302167892456\n",
      "Ep 45: Batch #57 - Loss: 0.8468508720397949\n",
      "Ep 45: Batch #58 - Loss: 0.9987745881080627\n",
      "Ep 45: Batch #59 - Loss: 0.6804106831550598\n",
      "Ep 45: Batch #60 - Loss: 1.3093011379241943\n",
      "Ep 45: Batch #61 - Loss: 0.6357342004776001\n",
      "Ep 45: Batch #62 - Loss: 0.7220292687416077\n",
      "Ep 45: Batch #63 - Loss: 1.001551628112793\n",
      "Ep 45: Batch #64 - Loss: 9.427874565124512\n",
      "Ep 45: Batch #65 - Loss: 0.6117082834243774\n",
      "Ep 45: Batch #66 - Loss: 0.7960244417190552\n",
      "Ep 45: Batch #67 - Loss: 0.9095355272293091\n",
      "Ep 45: Batch #68 - Loss: 0.9073522686958313\n",
      "Ep 45: Batch #69 - Loss: 0.7443641424179077\n",
      "Ep 45: Batch #70 - Loss: 0.7754011750221252\n",
      "Ep 45: Batch #71 - Loss: 0.678791880607605\n",
      "Ep 45: Batch #72 - Loss: 0.8534091711044312\n",
      "Ep 45: Batch #73 - Loss: 0.9024834632873535\n",
      "Ep 45: Batch #74 - Loss: 0.7400642037391663\n",
      "Ep 45: Batch #75 - Loss: 0.7673823237419128\n",
      "Ep 45: Batch #76 - Loss: 1.0947304964065552\n",
      "Ep 45: Batch #77 - Loss: 0.7338293790817261\n",
      "Ep 45: Batch #78 - Loss: 1.1587095260620117\n",
      "Ep 45: Batch #79 - Loss: 0.6254066228866577\n",
      "Ep 45: Batch #80 - Loss: 0.85861736536026\n",
      "Ep 45: Batch #81 - Loss: 1.6788700819015503\n",
      "Ep 45: Batch #82 - Loss: 0.8724546432495117\n",
      "Ep 45: Batch #83 - Loss: 1.7339102029800415\n",
      "Ep 45: Batch #84 - Loss: 0.7137250900268555\n",
      "Ep 45: Batch #85 - Loss: 0.9724476337432861\n",
      "Ep 45: Batch #86 - Loss: 0.7081642150878906\n",
      "Ep 45: Batch #87 - Loss: 0.7123221158981323\n",
      "Ep 45: Batch #88 - Loss: 0.8009368181228638\n",
      "Ep 45: Batch #89 - Loss: 0.8825196027755737\n",
      "Ep 45: Batch #90 - Loss: 1.1530770063400269\n",
      "Ep 45: Batch #91 - Loss: 0.8012205362319946\n",
      "Ep 45: Batch #92 - Loss: 1.0271482467651367\n",
      "Ep 45: Batch #93 - Loss: 1.0283758640289307\n",
      "Ep 45: Batch #94 - Loss: 1.0480159521102905\n",
      "Ep 45: Batch #95 - Loss: 0.9184560775756836\n",
      "Ep 45: Batch #96 - Loss: 0.9037292003631592\n",
      "Ep 45: Batch #97 - Loss: 0.728583037853241\n",
      "Ep 45: Batch #98 - Loss: 0.7378876209259033\n",
      "Ep 45: Batch #99 - Loss: 0.9572812914848328\n",
      "Ep 45: Batch #100 - Loss: 0.6772960424423218\n",
      "Ep 45: Batch #101 - Loss: 1.045581340789795\n",
      "Ep 45: Batch #102 - Loss: 0.7814636826515198\n",
      "Ep 45: Batch #103 - Loss: 0.7892031073570251\n",
      "Ep 45: Batch #104 - Loss: 0.8002135753631592\n",
      "Ep 45: Batch #105 - Loss: 1.0272867679595947\n",
      "Ep 45: Batch #106 - Loss: 0.7583020925521851\n",
      "Ep 45: Batch #107 - Loss: 0.75677889585495\n",
      "Ep 45: Batch #108 - Loss: 1.0323988199234009\n",
      "Ep 45: Batch #109 - Loss: 0.761595606803894\n",
      "Ep 45: Batch #110 - Loss: 0.9177551865577698\n",
      "Ep 45: Batch #111 - Loss: 1.377694010734558\n",
      "Ep 45: Batch #112 - Loss: 1.0456914901733398\n",
      "Ep 45: Batch #113 - Loss: 0.8153638243675232\n",
      "Ep 45: Batch #114 - Loss: 0.9019939303398132\n",
      "Ep 45: Batch #115 - Loss: 1.0926443338394165\n",
      "Ep 45: Batch #116 - Loss: 0.6324526071548462\n",
      "Ep 45: Batch #117 - Loss: 0.8711737394332886\n",
      "Ep 45: Batch #118 - Loss: 0.543533980846405\n",
      "Model saved in file: ./weights_autoencoder_low_LR/model_e45b118_1516651274.7808077.ckpt\n",
      "Ep 45: Batch #119 - Loss: 1.0255489349365234\n",
      "Ep 45: Batch #120 - Loss: 0.7990757822990417\n",
      "Ep 45: Batch #121 - Loss: 0.6849235892295837\n",
      "Ep 45: Batch #122 - Loss: 0.8240473866462708\n",
      "Ep 45: Batch #123 - Loss: 0.8308604955673218\n",
      "Ep 45: Batch #124 - Loss: 0.6624593734741211\n",
      "Ep 45: Batch #125 - Loss: 2.71824312210083\n",
      "Ep 45: Batch #126 - Loss: 1.2236741781234741\n",
      "Ep 45: Batch #127 - Loss: 0.7481968998908997\n",
      "Ep 45: Batch #128 - Loss: 1.1041574478149414\n",
      "Ep 45: Batch #129 - Loss: 0.8375697135925293\n",
      "Ep 45: Batch #130 - Loss: 0.7225388288497925\n",
      "Ep 45: Batch #131 - Loss: 0.9940534234046936\n",
      "Ep 45: Batch #132 - Loss: 0.8226924538612366\n",
      "Ep 45: Batch #133 - Loss: 0.8165906667709351\n",
      "Ep 45: Batch #134 - Loss: 0.7679938077926636\n",
      "Ep 45: Batch #135 - Loss: 0.9651123285293579\n",
      "Ep 45: Batch #136 - Loss: 1.1798804998397827\n",
      "Ep 45: Batch #137 - Loss: 0.9632401466369629\n",
      "Ep 45: Batch #138 - Loss: 1.0688960552215576\n",
      "Ep 45: Batch #139 - Loss: 0.8989565968513489\n",
      "Ep 45: Batch #140 - Loss: 1.0475088357925415\n",
      "Ep 45: Batch #141 - Loss: 1.3567698001861572\n",
      "Ep 45: Batch #142 - Loss: 0.7939409613609314\n",
      "Ep 45: Batch #143 - Loss: 0.9640865325927734\n",
      "Ep 45: Batch #144 - Loss: 0.7195772528648376\n",
      "Ep 45: Batch #145 - Loss: 0.6772198677062988\n",
      "Ep 45: Batch #146 - Loss: 0.8827526569366455\n",
      "Ep 45: Batch #147 - Loss: 0.8608165383338928\n",
      "Ep 45: Batch #148 - Loss: 0.9765740036964417\n",
      "Ep 45: Batch #149 - Loss: 0.8531836867332458\n",
      "Ep 45: Batch #150 - Loss: 0.8820434808731079\n",
      "Ep 45: Batch #151 - Loss: 0.7262101769447327\n",
      "Ep 45: Batch #152 - Loss: 0.7384080290794373\n",
      "Ep 45: Batch #153 - Loss: 1.1036189794540405\n",
      "Ep 45: Batch #154 - Loss: 0.7627244591712952\n",
      "Ep 45: Batch #155 - Loss: 0.8321850299835205\n",
      "Ep 45: Batch #156 - Loss: 1.016496181488037\n",
      "Ep 45: Batch #157 - Loss: 0.7610745429992676\n",
      "Ep 45: Batch #158 - Loss: 0.804369330406189\n",
      "Ep 45: Batch #159 - Loss: 0.8073864579200745\n",
      "Ep 45: Batch #160 - Loss: 0.9025663137435913\n",
      "Ep 45: Batch #161 - Loss: 0.8152796030044556\n",
      "Ep 45: Batch #162 - Loss: 0.9310991168022156\n",
      "Ep 45: Batch #163 - Loss: 0.9287192225456238\n",
      "Ep 45: Batch #164 - Loss: 0.783913791179657\n",
      "Ep 45: Batch #165 - Loss: 1.4982753992080688\n",
      "Ep 45: Batch #166 - Loss: 0.6785845160484314\n",
      "Ep 45: Batch #167 - Loss: 1.0857726335525513\n",
      "Ep 45: Batch #168 - Loss: 0.8595929741859436\n",
      "Ep 45: Batch #169 - Loss: 0.8005050420761108\n",
      "Ep 45: Batch #170 - Loss: 0.8033074140548706\n",
      "Ep 45: Batch #171 - Loss: 0.7796699404716492\n",
      "Ep 45: Batch #172 - Loss: 0.6331999897956848\n",
      "Ep 45: Batch #173 - Loss: 1.195091962814331\n",
      "Ep 45: Batch #174 - Loss: 0.5782938599586487\n",
      "Ep 45: Batch #175 - Loss: 0.7775810956954956\n",
      "Ep 45: Batch #176 - Loss: 1.1551408767700195\n",
      "Ep 45: Batch #177 - Loss: 0.8476053476333618\n",
      "Ep 45: Batch #178 - Loss: 0.7623768448829651\n",
      "Ep 45: Batch #179 - Loss: 0.9383094310760498\n",
      "Ep 45: Batch #180 - Loss: 0.8543289303779602\n",
      "Ep 45: Batch #181 - Loss: 0.9906270503997803\n",
      "Ep 45: Batch #182 - Loss: 0.7637541890144348\n",
      "Ep 45: Batch #183 - Loss: 0.7638413310050964\n",
      "Ep 45: Batch #184 - Loss: 1.0670770406723022\n",
      "Ep 45: Batch #185 - Loss: 0.7575696706771851\n",
      "Ep 45: Batch #186 - Loss: 0.9660055637359619\n",
      "Ep 45: Batch #187 - Loss: 1.1655021905899048\n",
      "Ep 45: Batch #188 - Loss: 1.3473601341247559\n",
      "Ep 45: Batch #189 - Loss: 0.7006503343582153\n",
      "Ep 45: Batch #190 - Loss: 0.7341904044151306\n",
      "Ep 45: Batch #191 - Loss: 1.0634456872940063\n",
      "Ep 45: Batch #192 - Loss: 0.6689990162849426\n",
      "Ep 45: Batch #193 - Loss: 0.7401478886604309\n",
      "Ep 45: Batch #194 - Loss: 0.6953691244125366\n",
      "Ep 45: Batch #195 - Loss: 0.9814391732215881\n",
      "Ep 45: Batch #196 - Loss: 0.8642516732215881\n",
      "Ep 45: Batch #197 - Loss: 0.9004561305046082\n",
      "Ep 45: Batch #198 - Loss: 0.6771134734153748\n",
      "Ep 45: Batch #199 - Loss: 0.8606040477752686\n",
      "Ep 46: Batch #0 - Loss: 0.7906352281570435\n",
      "Ep 46: Batch #1 - Loss: 0.8751538991928101\n",
      "Ep 46: Batch #2 - Loss: 1.0067428350448608\n",
      "Ep 46: Batch #3 - Loss: 0.8630616664886475\n",
      "Ep 46: Batch #4 - Loss: 0.7876637578010559\n",
      "Ep 46: Batch #5 - Loss: 0.6672101616859436\n",
      "Ep 46: Batch #6 - Loss: 0.8773013949394226\n",
      "Ep 46: Batch #7 - Loss: 0.7006281614303589\n",
      "Ep 46: Batch #8 - Loss: 0.7326586246490479\n",
      "Ep 46: Batch #9 - Loss: 1.397681474685669\n",
      "Ep 46: Batch #10 - Loss: 1.0045524835586548\n",
      "Ep 46: Batch #11 - Loss: 0.6689585447311401\n",
      "Ep 46: Batch #12 - Loss: 1.5576852560043335\n",
      "Ep 46: Batch #13 - Loss: 0.6469841003417969\n",
      "Ep 46: Batch #14 - Loss: 0.7257688045501709\n",
      "Ep 46: Batch #15 - Loss: 1.2367652654647827\n",
      "Ep 46: Batch #16 - Loss: 1.273177981376648\n",
      "Ep 46: Batch #17 - Loss: 0.8786213994026184\n",
      "Ep 46: Batch #18 - Loss: 0.9412795901298523\n",
      "Ep 46: Batch #19 - Loss: 0.6668429374694824\n",
      "Ep 46: Batch #20 - Loss: 0.6534460783004761\n",
      "Ep 46: Batch #21 - Loss: 1.2102364301681519\n",
      "Ep 46: Batch #22 - Loss: 0.7245540022850037\n",
      "Ep 46: Batch #23 - Loss: 0.7413823008537292\n",
      "Ep 46: Batch #24 - Loss: 0.8217834830284119\n",
      "Ep 46: Batch #25 - Loss: 0.7133869528770447\n",
      "Ep 46: Batch #26 - Loss: 0.7292591333389282\n",
      "Ep 46: Batch #27 - Loss: 1.3495477437973022\n",
      "Ep 46: Batch #28 - Loss: 0.8657408356666565\n",
      "Ep 46: Batch #29 - Loss: 0.8906569480895996\n",
      "Ep 46: Batch #30 - Loss: 1.1995327472686768\n",
      "Ep 46: Batch #31 - Loss: 0.6721796989440918\n",
      "Ep 46: Batch #32 - Loss: 0.7458533644676208\n",
      "Ep 46: Batch #33 - Loss: 0.8059577941894531\n",
      "Ep 46: Batch #34 - Loss: 0.7820602059364319\n",
      "Ep 46: Batch #35 - Loss: 0.9464969635009766\n",
      "Ep 46: Batch #36 - Loss: 0.7010992765426636\n",
      "Ep 46: Batch #37 - Loss: 1.1387252807617188\n",
      "Ep 46: Batch #38 - Loss: 0.7435888648033142\n",
      "Ep 46: Batch #39 - Loss: 0.8181443214416504\n",
      "Ep 46: Batch #40 - Loss: 0.7724844813346863\n",
      "Ep 46: Batch #41 - Loss: 0.7360190749168396\n",
      "Ep 46: Batch #42 - Loss: 0.720842182636261\n",
      "Ep 46: Batch #43 - Loss: 0.7861979603767395\n",
      "Ep 46: Batch #44 - Loss: 0.7828032970428467\n",
      "Ep 46: Batch #45 - Loss: 0.6320960521697998\n",
      "Ep 46: Batch #46 - Loss: 0.8287212252616882\n",
      "Ep 46: Batch #47 - Loss: 0.9586257934570312\n",
      "Ep 46: Batch #48 - Loss: 1.3514182567596436\n",
      "Ep 46: Batch #49 - Loss: 1.0124152898788452\n",
      "Ep 46: Batch #50 - Loss: 0.7046773433685303\n",
      "Ep 46: Batch #51 - Loss: 0.9922555685043335\n",
      "Ep 46: Batch #52 - Loss: 0.7930359840393066\n",
      "Ep 46: Batch #53 - Loss: 0.8204487562179565\n",
      "Ep 46: Batch #54 - Loss: 0.7037125825881958\n",
      "Ep 46: Batch #55 - Loss: 0.7497276663780212\n",
      "Ep 46: Batch #56 - Loss: 1.2587206363677979\n",
      "Ep 46: Batch #57 - Loss: 0.8453976511955261\n",
      "Ep 46: Batch #58 - Loss: 0.9970867037773132\n",
      "Ep 46: Batch #59 - Loss: 0.6795054078102112\n",
      "Ep 46: Batch #60 - Loss: 1.3079273700714111\n",
      "Ep 46: Batch #61 - Loss: 0.6347684264183044\n",
      "Ep 46: Batch #62 - Loss: 0.7207404375076294\n",
      "Ep 46: Batch #63 - Loss: 1.0000505447387695\n",
      "Ep 46: Batch #64 - Loss: 9.4266996383667\n",
      "Ep 46: Batch #65 - Loss: 0.6107918620109558\n",
      "Ep 46: Batch #66 - Loss: 0.7945684790611267\n",
      "Ep 46: Batch #67 - Loss: 0.9083014130592346\n",
      "Ep 46: Batch #68 - Loss: 0.9058666229248047\n",
      "Ep 46: Batch #69 - Loss: 0.7431659698486328\n",
      "Ep 46: Batch #70 - Loss: 0.7739039063453674\n",
      "Ep 46: Batch #71 - Loss: 0.67775958776474\n",
      "Ep 46: Batch #72 - Loss: 0.8520747423171997\n",
      "Ep 46: Batch #73 - Loss: 0.9007917046546936\n",
      "Ep 46: Batch #74 - Loss: 0.7387520670890808\n",
      "Ep 46: Batch #75 - Loss: 0.7662941217422485\n",
      "Ep 46: Batch #76 - Loss: 1.0935460329055786\n",
      "Ep 46: Batch #77 - Loss: 0.7326046824455261\n",
      "Ep 46: Batch #78 - Loss: 1.1569486856460571\n",
      "Ep 46: Batch #79 - Loss: 0.624393105506897\n",
      "Ep 46: Batch #80 - Loss: 0.8571701049804688\n",
      "Ep 46: Batch #81 - Loss: 1.6774694919586182\n",
      "Ep 46: Batch #82 - Loss: 0.8712465167045593\n",
      "Ep 46: Batch #83 - Loss: 1.732896327972412\n",
      "Ep 46: Batch #84 - Loss: 0.7124887108802795\n",
      "Ep 46: Batch #85 - Loss: 0.9713151454925537\n",
      "Ep 46: Batch #86 - Loss: 0.706864058971405\n",
      "Ep 46: Batch #87 - Loss: 0.7111815810203552\n",
      "Ep 46: Batch #88 - Loss: 0.7995883226394653\n",
      "Ep 46: Batch #89 - Loss: 0.8816781044006348\n",
      "Ep 46: Batch #90 - Loss: 1.1511918306350708\n",
      "Ep 46: Batch #91 - Loss: 0.7997973561286926\n",
      "Ep 46: Batch #92 - Loss: 1.0256294012069702\n",
      "Ep 46: Batch #93 - Loss: 1.0265624523162842\n",
      "Ep 46: Batch #94 - Loss: 1.046399474143982\n",
      "Ep 46: Batch #95 - Loss: 0.9170693159103394\n",
      "Ep 46: Batch #96 - Loss: 0.9023910164833069\n",
      "Ep 46: Batch #97 - Loss: 0.727362334728241\n",
      "Ep 46: Batch #98 - Loss: 0.7366734743118286\n",
      "Ep 46: Batch #99 - Loss: 0.9560377597808838\n",
      "Ep 46: Batch #100 - Loss: 0.6761502027511597\n",
      "Ep 46: Batch #101 - Loss: 1.0442193746566772\n",
      "Ep 46: Batch #102 - Loss: 0.7802934646606445\n",
      "Ep 46: Batch #103 - Loss: 0.7880418300628662\n",
      "Ep 46: Batch #104 - Loss: 0.7989966869354248\n",
      "Ep 46: Batch #105 - Loss: 1.0256738662719727\n",
      "Ep 46: Batch #106 - Loss: 0.7571235299110413\n",
      "Ep 46: Batch #107 - Loss: 0.7555100321769714\n",
      "Ep 46: Batch #108 - Loss: 1.030854344367981\n",
      "Ep 46: Batch #109 - Loss: 0.7605024576187134\n",
      "Ep 46: Batch #110 - Loss: 0.9161143898963928\n",
      "Ep 46: Batch #111 - Loss: 1.376002550125122\n",
      "Ep 46: Batch #112 - Loss: 1.0441133975982666\n",
      "Ep 46: Batch #113 - Loss: 0.8140873908996582\n",
      "Ep 46: Batch #114 - Loss: 0.9005388617515564\n",
      "Ep 46: Batch #115 - Loss: 1.091107726097107\n",
      "Ep 46: Batch #116 - Loss: 0.6317156553268433\n",
      "Ep 46: Batch #117 - Loss: 0.8699661493301392\n",
      "Ep 46: Batch #118 - Loss: 0.542553186416626\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved in file: ./weights_autoencoder_low_LR/model_e46b118_1516651274.9192972.ckpt\n",
      "Ep 46: Batch #119 - Loss: 1.0242232084274292\n",
      "Ep 46: Batch #120 - Loss: 0.7979496121406555\n",
      "Ep 46: Batch #121 - Loss: 0.6837550401687622\n",
      "Ep 46: Batch #122 - Loss: 0.8228244781494141\n",
      "Ep 46: Batch #123 - Loss: 0.8296102285385132\n",
      "Ep 46: Batch #124 - Loss: 0.6615929007530212\n",
      "Ep 46: Batch #125 - Loss: 2.7167720794677734\n",
      "Ep 46: Batch #126 - Loss: 1.2222040891647339\n",
      "Ep 46: Batch #127 - Loss: 0.7468270659446716\n",
      "Ep 46: Batch #128 - Loss: 1.102353811264038\n",
      "Ep 46: Batch #129 - Loss: 0.8361839056015015\n",
      "Ep 46: Batch #130 - Loss: 0.7213557958602905\n",
      "Ep 46: Batch #131 - Loss: 0.9922955632209778\n",
      "Ep 46: Batch #132 - Loss: 0.8213246464729309\n",
      "Ep 46: Batch #133 - Loss: 0.8152987957000732\n",
      "Ep 46: Batch #134 - Loss: 0.7667130827903748\n",
      "Ep 46: Batch #135 - Loss: 0.9634950757026672\n",
      "Ep 46: Batch #136 - Loss: 1.1781185865402222\n",
      "Ep 46: Batch #137 - Loss: 0.9617521166801453\n",
      "Ep 46: Batch #138 - Loss: 1.0674165487289429\n",
      "Ep 46: Batch #139 - Loss: 0.8975405693054199\n",
      "Ep 46: Batch #140 - Loss: 1.046022653579712\n",
      "Ep 46: Batch #141 - Loss: 1.3552942276000977\n",
      "Ep 46: Batch #142 - Loss: 0.7927113771438599\n",
      "Ep 46: Batch #143 - Loss: 0.9624029994010925\n",
      "Ep 46: Batch #144 - Loss: 0.7184516787528992\n",
      "Ep 46: Batch #145 - Loss: 0.6761831641197205\n",
      "Ep 46: Batch #146 - Loss: 0.8815255761146545\n",
      "Ep 46: Batch #147 - Loss: 0.8592131733894348\n",
      "Ep 46: Batch #148 - Loss: 0.974983274936676\n",
      "Ep 46: Batch #149 - Loss: 0.8516963720321655\n",
      "Ep 46: Batch #150 - Loss: 0.8807525634765625\n",
      "Ep 46: Batch #151 - Loss: 0.7253594994544983\n",
      "Ep 46: Batch #152 - Loss: 0.7375045418739319\n",
      "Ep 46: Batch #153 - Loss: 1.1019972562789917\n",
      "Ep 46: Batch #154 - Loss: 0.7615882754325867\n",
      "Ep 46: Batch #155 - Loss: 0.8309216499328613\n",
      "Ep 46: Batch #156 - Loss: 1.015051245689392\n",
      "Ep 46: Batch #157 - Loss: 0.759881854057312\n",
      "Ep 46: Batch #158 - Loss: 0.8034569025039673\n",
      "Ep 46: Batch #159 - Loss: 0.8060641288757324\n",
      "Ep 46: Batch #160 - Loss: 0.9014204144477844\n",
      "Ep 46: Batch #161 - Loss: 0.8140757083892822\n",
      "Ep 46: Batch #162 - Loss: 0.9297207593917847\n",
      "Ep 46: Batch #163 - Loss: 0.9276389479637146\n",
      "Ep 46: Batch #164 - Loss: 0.7827143669128418\n",
      "Ep 46: Batch #165 - Loss: 1.4968522787094116\n",
      "Ep 46: Batch #166 - Loss: 0.6773872375488281\n",
      "Ep 46: Batch #167 - Loss: 1.0843455791473389\n",
      "Ep 46: Batch #168 - Loss: 0.8582054376602173\n",
      "Ep 46: Batch #169 - Loss: 0.7992926239967346\n",
      "Ep 46: Batch #170 - Loss: 0.8020220398902893\n",
      "Ep 46: Batch #171 - Loss: 0.7783259153366089\n",
      "Ep 46: Batch #172 - Loss: 0.6323057413101196\n",
      "Ep 46: Batch #173 - Loss: 1.1931666135787964\n",
      "Ep 46: Batch #174 - Loss: 0.5774086713790894\n",
      "Ep 46: Batch #175 - Loss: 0.7766023278236389\n",
      "Ep 46: Batch #176 - Loss: 1.153295874595642\n",
      "Ep 46: Batch #177 - Loss: 0.8463119268417358\n",
      "Ep 46: Batch #178 - Loss: 0.7610765695571899\n",
      "Ep 46: Batch #179 - Loss: 0.9367266893386841\n",
      "Ep 46: Batch #180 - Loss: 0.8527239561080933\n",
      "Ep 46: Batch #181 - Loss: 0.9889252185821533\n",
      "Ep 46: Batch #182 - Loss: 0.7627786993980408\n",
      "Ep 46: Batch #183 - Loss: 0.762579083442688\n",
      "Ep 46: Batch #184 - Loss: 1.0659630298614502\n",
      "Ep 46: Batch #185 - Loss: 0.756417453289032\n",
      "Ep 46: Batch #186 - Loss: 0.9642879962921143\n",
      "Ep 46: Batch #187 - Loss: 1.1642462015151978\n",
      "Ep 46: Batch #188 - Loss: 1.346169352531433\n",
      "Ep 46: Batch #189 - Loss: 0.6997442841529846\n",
      "Ep 46: Batch #190 - Loss: 0.733090341091156\n",
      "Ep 46: Batch #191 - Loss: 1.0619808435440063\n",
      "Ep 46: Batch #192 - Loss: 0.6681143641471863\n",
      "Ep 46: Batch #193 - Loss: 0.7388781309127808\n",
      "Ep 46: Batch #194 - Loss: 0.6942570209503174\n",
      "Ep 46: Batch #195 - Loss: 0.9800050258636475\n",
      "Ep 46: Batch #196 - Loss: 0.8630586862564087\n",
      "Ep 46: Batch #197 - Loss: 0.899093747138977\n",
      "Ep 46: Batch #198 - Loss: 0.675918459892273\n",
      "Ep 46: Batch #199 - Loss: 0.8592628240585327\n",
      "Ep 47: Batch #0 - Loss: 0.7891985177993774\n",
      "Ep 47: Batch #1 - Loss: 0.8738359808921814\n",
      "Ep 47: Batch #2 - Loss: 1.0054874420166016\n",
      "Ep 47: Batch #3 - Loss: 0.8619217872619629\n",
      "Ep 47: Batch #4 - Loss: 0.7863385081291199\n",
      "Ep 47: Batch #5 - Loss: 0.6663234829902649\n",
      "Ep 47: Batch #6 - Loss: 0.87604159116745\n",
      "Ep 47: Batch #7 - Loss: 0.6996124982833862\n",
      "Ep 47: Batch #8 - Loss: 0.7316381335258484\n",
      "Ep 47: Batch #9 - Loss: 1.3957479000091553\n",
      "Ep 47: Batch #10 - Loss: 1.003199577331543\n",
      "Ep 47: Batch #11 - Loss: 0.66794353723526\n",
      "Ep 47: Batch #12 - Loss: 1.5562087297439575\n",
      "Ep 47: Batch #13 - Loss: 0.6461995244026184\n",
      "Ep 47: Batch #14 - Loss: 0.7247673869132996\n",
      "Ep 47: Batch #15 - Loss: 1.2351657152175903\n",
      "Ep 47: Batch #16 - Loss: 1.2712979316711426\n",
      "Ep 47: Batch #17 - Loss: 0.877251923084259\n",
      "Ep 47: Batch #18 - Loss: 0.9401809573173523\n",
      "Ep 47: Batch #19 - Loss: 0.6659138798713684\n",
      "Ep 47: Batch #20 - Loss: 0.6524102091789246\n",
      "Ep 47: Batch #21 - Loss: 1.208937406539917\n",
      "Ep 47: Batch #22 - Loss: 0.7235840559005737\n",
      "Ep 47: Batch #23 - Loss: 0.7401660084724426\n",
      "Ep 47: Batch #24 - Loss: 0.820716381072998\n",
      "Ep 47: Batch #25 - Loss: 0.7121937870979309\n",
      "Ep 47: Batch #26 - Loss: 0.7279456257820129\n",
      "Ep 47: Batch #27 - Loss: 1.3477885723114014\n",
      "Ep 47: Batch #28 - Loss: 0.8645164966583252\n",
      "Ep 47: Batch #29 - Loss: 0.8891870975494385\n",
      "Ep 47: Batch #30 - Loss: 1.1983040571212769\n",
      "Ep 47: Batch #31 - Loss: 0.6713659167289734\n",
      "Ep 47: Batch #32 - Loss: 0.7446383833885193\n",
      "Ep 47: Batch #33 - Loss: 0.8048697113990784\n",
      "Ep 47: Batch #34 - Loss: 0.780932605266571\n",
      "Ep 47: Batch #35 - Loss: 0.9449011087417603\n",
      "Ep 47: Batch #36 - Loss: 0.7000004649162292\n",
      "Ep 47: Batch #37 - Loss: 1.1374180316925049\n",
      "Ep 47: Batch #38 - Loss: 0.7422723174095154\n",
      "Ep 47: Batch #39 - Loss: 0.8171722888946533\n",
      "Ep 47: Batch #40 - Loss: 0.7712582945823669\n",
      "Ep 47: Batch #41 - Loss: 0.7347061634063721\n",
      "Ep 47: Batch #42 - Loss: 0.7197717428207397\n",
      "Ep 47: Batch #43 - Loss: 0.7850741147994995\n",
      "Ep 47: Batch #44 - Loss: 0.7815495729446411\n",
      "Ep 47: Batch #45 - Loss: 0.6308972835540771\n",
      "Ep 47: Batch #46 - Loss: 0.8272886276245117\n",
      "Ep 47: Batch #47 - Loss: 0.9569233655929565\n",
      "Ep 47: Batch #48 - Loss: 1.3498051166534424\n",
      "Ep 47: Batch #49 - Loss: 1.0106903314590454\n",
      "Ep 47: Batch #50 - Loss: 0.7038170695304871\n",
      "Ep 47: Batch #51 - Loss: 0.990539014339447\n",
      "Ep 47: Batch #52 - Loss: 0.7920154929161072\n",
      "Ep 47: Batch #53 - Loss: 0.8191660046577454\n",
      "Ep 47: Batch #54 - Loss: 0.7027053833007812\n",
      "Ep 47: Batch #55 - Loss: 0.74846351146698\n",
      "Ep 47: Batch #56 - Loss: 1.2570430040359497\n",
      "Ep 47: Batch #57 - Loss: 0.843966007232666\n",
      "Ep 47: Batch #58 - Loss: 0.9954127669334412\n",
      "Ep 47: Batch #59 - Loss: 0.6786127090454102\n",
      "Ep 47: Batch #60 - Loss: 1.3065613508224487\n",
      "Ep 47: Batch #61 - Loss: 0.6338216066360474\n",
      "Ep 47: Batch #62 - Loss: 0.7194715738296509\n",
      "Ep 47: Batch #63 - Loss: 0.9985665082931519\n",
      "Ep 47: Batch #64 - Loss: 9.425555229187012\n",
      "Ep 47: Batch #65 - Loss: 0.6098877787590027\n",
      "Ep 47: Batch #66 - Loss: 0.7931383848190308\n",
      "Ep 47: Batch #67 - Loss: 0.9070762395858765\n",
      "Ep 47: Batch #68 - Loss: 0.9043964743614197\n",
      "Ep 47: Batch #69 - Loss: 0.7419837117195129\n",
      "Ep 47: Batch #70 - Loss: 0.7724184989929199\n",
      "Ep 47: Batch #71 - Loss: 0.6767458915710449\n",
      "Ep 47: Batch #72 - Loss: 0.8507513999938965\n",
      "Ep 47: Batch #73 - Loss: 0.8991221785545349\n",
      "Ep 47: Batch #74 - Loss: 0.737445056438446\n",
      "Ep 47: Batch #75 - Loss: 0.7652167081832886\n",
      "Ep 47: Batch #76 - Loss: 1.092376947402954\n",
      "Ep 47: Batch #77 - Loss: 0.731391429901123\n",
      "Ep 47: Batch #78 - Loss: 1.1551882028579712\n",
      "Ep 47: Batch #79 - Loss: 0.6233915686607361\n",
      "Ep 47: Batch #80 - Loss: 0.8557383418083191\n",
      "Ep 47: Batch #81 - Loss: 1.6760954856872559\n",
      "Ep 47: Batch #82 - Loss: 0.8700537085533142\n",
      "Ep 47: Batch #83 - Loss: 1.7318888902664185\n",
      "Ep 47: Batch #84 - Loss: 0.7112714052200317\n",
      "Ep 47: Batch #85 - Loss: 0.9702057242393494\n",
      "Ep 47: Batch #86 - Loss: 0.7055787444114685\n",
      "Ep 47: Batch #87 - Loss: 0.7100479602813721\n",
      "Ep 47: Batch #88 - Loss: 0.7982711791992188\n",
      "Ep 47: Batch #89 - Loss: 0.8808450698852539\n",
      "Ep 47: Batch #90 - Loss: 1.1493333578109741\n",
      "Ep 47: Batch #91 - Loss: 0.7983854413032532\n",
      "Ep 47: Batch #92 - Loss: 1.0241308212280273\n",
      "Ep 47: Batch #93 - Loss: 1.0247704982757568\n",
      "Ep 47: Batch #94 - Loss: 1.0447943210601807\n",
      "Ep 47: Batch #95 - Loss: 0.9156906008720398\n",
      "Ep 47: Batch #96 - Loss: 0.9010651111602783\n",
      "Ep 47: Batch #97 - Loss: 0.7261683940887451\n",
      "Ep 47: Batch #98 - Loss: 0.7354755997657776\n",
      "Ep 47: Batch #99 - Loss: 0.9548072814941406\n",
      "Ep 47: Batch #100 - Loss: 0.6750216484069824\n",
      "Ep 47: Batch #101 - Loss: 1.0428673028945923\n",
      "Ep 47: Batch #102 - Loss: 0.7791370153427124\n",
      "Ep 47: Batch #103 - Loss: 0.7869032621383667\n",
      "Ep 47: Batch #104 - Loss: 0.797791063785553\n",
      "Ep 47: Batch #105 - Loss: 1.0240771770477295\n",
      "Ep 47: Batch #106 - Loss: 0.7559666633605957\n",
      "Ep 47: Batch #107 - Loss: 0.7542572617530823\n",
      "Ep 47: Batch #108 - Loss: 1.0293225049972534\n",
      "Ep 47: Batch #109 - Loss: 0.7594192028045654\n",
      "Ep 47: Batch #110 - Loss: 0.9144805073738098\n",
      "Ep 47: Batch #111 - Loss: 1.3743176460266113\n",
      "Ep 47: Batch #112 - Loss: 1.0425512790679932\n",
      "Ep 47: Batch #113 - Loss: 0.8128277659416199\n",
      "Ep 47: Batch #114 - Loss: 0.8991015553474426\n",
      "Ep 47: Batch #115 - Loss: 1.0895906686782837\n",
      "Ep 47: Batch #116 - Loss: 0.6309863924980164\n",
      "Ep 47: Batch #117 - Loss: 0.8687874674797058\n",
      "Ep 47: Batch #118 - Loss: 0.5415900349617004\n",
      "Model saved in file: ./weights_autoencoder_low_LR/model_e47b118_1516651275.0575.ckpt\n",
      "Ep 47: Batch #119 - Loss: 1.0229121446609497\n",
      "Ep 47: Batch #120 - Loss: 0.7968289852142334\n",
      "Ep 47: Batch #121 - Loss: 0.6826024055480957\n",
      "Ep 47: Batch #122 - Loss: 0.821617603302002\n",
      "Ep 47: Batch #123 - Loss: 0.8283669948577881\n",
      "Ep 47: Batch #124 - Loss: 0.6607352495193481\n",
      "Ep 47: Batch #125 - Loss: 2.7152891159057617\n",
      "Ep 47: Batch #126 - Loss: 1.22074294090271\n",
      "Ep 47: Batch #127 - Loss: 0.7454755902290344\n",
      "Ep 47: Batch #128 - Loss: 1.1005851030349731\n",
      "Ep 47: Batch #129 - Loss: 0.8348185420036316\n",
      "Ep 47: Batch #130 - Loss: 0.7201831936836243\n",
      "Ep 47: Batch #131 - Loss: 0.9905730485916138\n",
      "Ep 47: Batch #132 - Loss: 0.8199796676635742\n",
      "Ep 47: Batch #133 - Loss: 0.8140187859535217\n",
      "Ep 47: Batch #134 - Loss: 0.7654421925544739\n",
      "Ep 47: Batch #135 - Loss: 0.9618895649909973\n",
      "Ep 47: Batch #136 - Loss: 1.176379680633545\n",
      "Ep 47: Batch #137 - Loss: 0.9602794051170349\n",
      "Ep 47: Batch #138 - Loss: 1.0659457445144653\n",
      "Ep 47: Batch #139 - Loss: 0.8961304426193237\n",
      "Ep 47: Batch #140 - Loss: 1.0445332527160645\n",
      "Ep 47: Batch #141 - Loss: 1.3538199663162231\n",
      "Ep 47: Batch #142 - Loss: 0.7915012836456299\n",
      "Ep 47: Batch #143 - Loss: 0.9607335925102234\n",
      "Ep 47: Batch #144 - Loss: 0.717346727848053\n",
      "Ep 47: Batch #145 - Loss: 0.6751527786254883\n",
      "Ep 47: Batch #146 - Loss: 0.8803069591522217\n",
      "Ep 47: Batch #147 - Loss: 0.8576260209083557\n",
      "Ep 47: Batch #148 - Loss: 0.9733965396881104\n",
      "Ep 47: Batch #149 - Loss: 0.8502206206321716\n",
      "Ep 47: Batch #150 - Loss: 0.8794648051261902\n",
      "Ep 47: Batch #151 - Loss: 0.7245206236839294\n",
      "Ep 47: Batch #152 - Loss: 0.7366066575050354\n",
      "Ep 47: Batch #153 - Loss: 1.1003614664077759\n",
      "Ep 47: Batch #154 - Loss: 0.7604597806930542\n",
      "Ep 47: Batch #155 - Loss: 0.8296786546707153\n",
      "Ep 47: Batch #156 - Loss: 1.0136257410049438\n",
      "Ep 47: Batch #157 - Loss: 0.7587025761604309\n",
      "Ep 47: Batch #158 - Loss: 0.8025538921356201\n",
      "Ep 47: Batch #159 - Loss: 0.8047534823417664\n",
      "Ep 47: Batch #160 - Loss: 0.9002899527549744\n",
      "Ep 47: Batch #161 - Loss: 0.8128838539123535\n",
      "Ep 47: Batch #162 - Loss: 0.9283557534217834\n",
      "Ep 47: Batch #163 - Loss: 0.9265631437301636\n",
      "Ep 47: Batch #164 - Loss: 0.7815319299697876\n",
      "Ep 47: Batch #165 - Loss: 1.4953887462615967\n",
      "Ep 47: Batch #166 - Loss: 0.6762083172798157\n",
      "Ep 47: Batch #167 - Loss: 1.0829236507415771\n",
      "Ep 47: Batch #168 - Loss: 0.8568323254585266\n",
      "Ep 47: Batch #169 - Loss: 0.7981079816818237\n",
      "Ep 47: Batch #170 - Loss: 0.8007404804229736\n",
      "Ep 47: Batch #171 - Loss: 0.7769931554794312\n",
      "Ep 47: Batch #172 - Loss: 0.6314185261726379\n",
      "Ep 47: Batch #173 - Loss: 1.1912516355514526\n",
      "Ep 47: Batch #174 - Loss: 0.5765301585197449\n",
      "Ep 47: Batch #175 - Loss: 0.7756396532058716\n",
      "Ep 47: Batch #176 - Loss: 1.1514602899551392\n",
      "Ep 47: Batch #177 - Loss: 0.8450295925140381\n",
      "Ep 47: Batch #178 - Loss: 0.7597886323928833\n",
      "Ep 47: Batch #179 - Loss: 0.9351727962493896\n",
      "Ep 47: Batch #180 - Loss: 0.8511337041854858\n",
      "Ep 47: Batch #181 - Loss: 0.9872443675994873\n",
      "Ep 47: Batch #182 - Loss: 0.7618137001991272\n",
      "Ep 47: Batch #183 - Loss: 0.7613410353660583\n",
      "Ep 47: Batch #184 - Loss: 1.0648541450500488\n",
      "Ep 47: Batch #185 - Loss: 0.7552754282951355\n",
      "Ep 47: Batch #186 - Loss: 0.9625841379165649\n",
      "Ep 47: Batch #187 - Loss: 1.1630109548568726\n",
      "Ep 47: Batch #188 - Loss: 1.3449947834014893\n",
      "Ep 47: Batch #189 - Loss: 0.6988434195518494\n",
      "Ep 47: Batch #190 - Loss: 0.7320029735565186\n",
      "Ep 47: Batch #191 - Loss: 1.0605111122131348\n",
      "Ep 47: Batch #192 - Loss: 0.6672402620315552\n",
      "Ep 47: Batch #193 - Loss: 0.7376288175582886\n",
      "Ep 47: Batch #194 - Loss: 0.6931502819061279\n",
      "Ep 47: Batch #195 - Loss: 0.9785943031311035\n",
      "Ep 47: Batch #196 - Loss: 0.86187344789505\n",
      "Ep 47: Batch #197 - Loss: 0.8977327942848206\n",
      "Ep 47: Batch #198 - Loss: 0.6747304797172546\n",
      "Ep 47: Batch #199 - Loss: 0.8579309582710266\n",
      "Ep 48: Batch #0 - Loss: 0.787777841091156\n",
      "Ep 48: Batch #1 - Loss: 0.8725124597549438\n",
      "Ep 48: Batch #2 - Loss: 1.0042500495910645\n",
      "Ep 48: Batch #3 - Loss: 0.8607943058013916\n",
      "Ep 48: Batch #4 - Loss: 0.7850345969200134\n",
      "Ep 48: Batch #5 - Loss: 0.6654479503631592\n",
      "Ep 48: Batch #6 - Loss: 0.874796986579895\n",
      "Ep 48: Batch #7 - Loss: 0.6985959410667419\n",
      "Ep 48: Batch #8 - Loss: 0.7306197285652161\n",
      "Ep 48: Batch #9 - Loss: 1.3938270807266235\n",
      "Ep 48: Batch #10 - Loss: 1.001854658126831\n",
      "Ep 48: Batch #11 - Loss: 0.6669448614120483\n",
      "Ep 48: Batch #12 - Loss: 1.55470609664917\n",
      "Ep 48: Batch #13 - Loss: 0.6454282402992249\n",
      "Ep 48: Batch #14 - Loss: 0.7237750291824341\n",
      "Ep 48: Batch #15 - Loss: 1.2335851192474365\n",
      "Ep 48: Batch #16 - Loss: 1.2694333791732788\n",
      "Ep 48: Batch #17 - Loss: 0.8758937120437622\n",
      "Ep 48: Batch #18 - Loss: 0.9391293525695801\n",
      "Ep 48: Batch #19 - Loss: 0.6649969220161438\n",
      "Ep 48: Batch #20 - Loss: 0.651390016078949\n",
      "Ep 48: Batch #21 - Loss: 1.2076544761657715\n",
      "Ep 48: Batch #22 - Loss: 0.722627580165863\n",
      "Ep 48: Batch #23 - Loss: 0.7389653325080872\n",
      "Ep 48: Batch #24 - Loss: 0.8196625113487244\n",
      "Ep 48: Batch #25 - Loss: 0.7110165953636169\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 48: Batch #26 - Loss: 0.7266397476196289\n",
      "Ep 48: Batch #27 - Loss: 1.346048355102539\n",
      "Ep 48: Batch #28 - Loss: 0.8633193969726562\n",
      "Ep 48: Batch #29 - Loss: 0.8877385258674622\n",
      "Ep 48: Batch #30 - Loss: 1.1970258951187134\n",
      "Ep 48: Batch #31 - Loss: 0.6705371141433716\n",
      "Ep 48: Batch #32 - Loss: 0.7434270977973938\n",
      "Ep 48: Batch #33 - Loss: 0.8037824630737305\n",
      "Ep 48: Batch #34 - Loss: 0.7798190712928772\n",
      "Ep 48: Batch #35 - Loss: 0.9433203935623169\n",
      "Ep 48: Batch #36 - Loss: 0.6989152431488037\n",
      "Ep 48: Batch #37 - Loss: 1.1361217498779297\n",
      "Ep 48: Batch #38 - Loss: 0.7409729361534119\n",
      "Ep 48: Batch #39 - Loss: 0.8162035346031189\n",
      "Ep 48: Batch #40 - Loss: 0.7700472474098206\n",
      "Ep 48: Batch #41 - Loss: 0.7334021925926208\n",
      "Ep 48: Batch #42 - Loss: 0.7187106013298035\n",
      "Ep 48: Batch #43 - Loss: 0.7839626669883728\n",
      "Ep 48: Batch #44 - Loss: 0.780295729637146\n",
      "Ep 48: Batch #45 - Loss: 0.6297124028205872\n",
      "Ep 48: Batch #46 - Loss: 0.8258616328239441\n",
      "Ep 48: Batch #47 - Loss: 0.955231249332428\n",
      "Ep 48: Batch #48 - Loss: 1.348215103149414\n",
      "Ep 48: Batch #49 - Loss: 1.0089610815048218\n",
      "Ep 48: Batch #50 - Loss: 0.7029666304588318\n",
      "Ep 48: Batch #51 - Loss: 0.9888290762901306\n",
      "Ep 48: Batch #52 - Loss: 0.7910061478614807\n",
      "Ep 48: Batch #53 - Loss: 0.817924976348877\n",
      "Ep 48: Batch #54 - Loss: 0.7016997933387756\n",
      "Ep 48: Batch #55 - Loss: 0.7472137808799744\n",
      "Ep 48: Batch #56 - Loss: 1.2554081678390503\n",
      "Ep 48: Batch #57 - Loss: 0.842521607875824\n",
      "Ep 48: Batch #58 - Loss: 0.9937474727630615\n",
      "Ep 48: Batch #59 - Loss: 0.677730143070221\n",
      "Ep 48: Batch #60 - Loss: 1.3052129745483398\n",
      "Ep 48: Batch #61 - Loss: 0.6328871846199036\n",
      "Ep 48: Batch #62 - Loss: 0.7182176113128662\n",
      "Ep 48: Batch #63 - Loss: 0.9971040487289429\n",
      "Ep 48: Batch #64 - Loss: 9.424416542053223\n",
      "Ep 48: Batch #65 - Loss: 0.6089918613433838\n",
      "Ep 48: Batch #66 - Loss: 0.7917266488075256\n",
      "Ep 48: Batch #67 - Loss: 0.905852735042572\n",
      "Ep 48: Batch #68 - Loss: 0.9029391407966614\n",
      "Ep 48: Batch #69 - Loss: 0.7408161163330078\n",
      "Ep 48: Batch #70 - Loss: 0.7709483504295349\n",
      "Ep 48: Batch #71 - Loss: 0.6757479906082153\n",
      "Ep 48: Batch #72 - Loss: 0.849442183971405\n",
      "Ep 48: Batch #73 - Loss: 0.8974687457084656\n",
      "Ep 48: Batch #74 - Loss: 0.7361504435539246\n",
      "Ep 48: Batch #75 - Loss: 0.7641474008560181\n",
      "Ep 48: Batch #76 - Loss: 1.0912058353424072\n",
      "Ep 48: Batch #77 - Loss: 0.7301892638206482\n",
      "Ep 48: Batch #78 - Loss: 1.1534227132797241\n",
      "Ep 48: Batch #79 - Loss: 0.6223840713500977\n",
      "Ep 48: Batch #80 - Loss: 0.8543206453323364\n",
      "Ep 48: Batch #81 - Loss: 1.674739122390747\n",
      "Ep 48: Batch #82 - Loss: 0.868873655796051\n",
      "Ep 48: Batch #83 - Loss: 1.7308895587921143\n",
      "Ep 48: Batch #84 - Loss: 0.7100679874420166\n",
      "Ep 48: Batch #85 - Loss: 0.9691174030303955\n",
      "Ep 48: Batch #86 - Loss: 0.704298198223114\n",
      "Ep 48: Batch #87 - Loss: 0.7089160680770874\n",
      "Ep 48: Batch #88 - Loss: 0.7969728112220764\n",
      "Ep 48: Batch #89 - Loss: 0.8800225257873535\n",
      "Ep 48: Batch #90 - Loss: 1.1474915742874146\n",
      "Ep 48: Batch #91 - Loss: 0.79698646068573\n",
      "Ep 48: Batch #92 - Loss: 1.0226465463638306\n",
      "Ep 48: Batch #93 - Loss: 1.0229878425598145\n",
      "Ep 48: Batch #94 - Loss: 1.0432062149047852\n",
      "Ep 48: Batch #95 - Loss: 0.9143227338790894\n",
      "Ep 48: Batch #96 - Loss: 0.8997538089752197\n",
      "Ep 48: Batch #97 - Loss: 0.724998414516449\n",
      "Ep 48: Batch #98 - Loss: 0.7342934012413025\n",
      "Ep 48: Batch #99 - Loss: 0.9535802006721497\n",
      "Ep 48: Batch #100 - Loss: 0.6739035844802856\n",
      "Ep 48: Batch #101 - Loss: 1.0415072441101074\n",
      "Ep 48: Batch #102 - Loss: 0.7779898643493652\n",
      "Ep 48: Batch #103 - Loss: 0.7857823371887207\n",
      "Ep 48: Batch #104 - Loss: 0.7965977191925049\n",
      "Ep 48: Batch #105 - Loss: 1.0224919319152832\n",
      "Ep 48: Batch #106 - Loss: 0.7548239231109619\n",
      "Ep 48: Batch #107 - Loss: 0.7530196309089661\n",
      "Ep 48: Batch #108 - Loss: 1.0278027057647705\n",
      "Ep 48: Batch #109 - Loss: 0.7583466172218323\n",
      "Ep 48: Batch #110 - Loss: 0.9128614068031311\n",
      "Ep 48: Batch #111 - Loss: 1.3726285696029663\n",
      "Ep 48: Batch #112 - Loss: 1.0410081148147583\n",
      "Ep 48: Batch #113 - Loss: 0.8115840554237366\n",
      "Ep 48: Batch #114 - Loss: 0.897674024105072\n",
      "Ep 48: Batch #115 - Loss: 1.0880836248397827\n",
      "Ep 48: Batch #116 - Loss: 0.6302627921104431\n",
      "Ep 48: Batch #117 - Loss: 0.8675988912582397\n",
      "Ep 48: Batch #118 - Loss: 0.5406412482261658\n",
      "Model saved in file: ./weights_autoencoder_low_LR/model_e48b118_1516651275.1950858.ckpt\n",
      "Ep 48: Batch #119 - Loss: 1.0216072797775269\n",
      "Ep 48: Batch #120 - Loss: 0.7957125902175903\n",
      "Ep 48: Batch #121 - Loss: 0.6814687848091125\n",
      "Ep 48: Batch #122 - Loss: 0.8204255700111389\n",
      "Ep 48: Batch #123 - Loss: 0.8271308541297913\n",
      "Ep 48: Batch #124 - Loss: 0.6598837375640869\n",
      "Ep 48: Batch #125 - Loss: 2.7137508392333984\n",
      "Ep 48: Batch #126 - Loss: 1.2192965745925903\n",
      "Ep 48: Batch #127 - Loss: 0.7441343069076538\n",
      "Ep 48: Batch #128 - Loss: 1.0988366603851318\n",
      "Ep 48: Batch #129 - Loss: 0.8334700465202332\n",
      "Ep 48: Batch #130 - Loss: 0.7190260887145996\n",
      "Ep 48: Batch #131 - Loss: 0.9888638854026794\n",
      "Ep 48: Batch #132 - Loss: 0.8186381459236145\n",
      "Ep 48: Batch #133 - Loss: 0.8127508163452148\n",
      "Ep 48: Batch #134 - Loss: 0.7641780972480774\n",
      "Ep 48: Batch #135 - Loss: 0.9602832198143005\n",
      "Ep 48: Batch #136 - Loss: 1.1746556758880615\n",
      "Ep 48: Batch #137 - Loss: 0.9588226079940796\n",
      "Ep 48: Batch #138 - Loss: 1.0644813776016235\n",
      "Ep 48: Batch #139 - Loss: 0.8947320580482483\n",
      "Ep 48: Batch #140 - Loss: 1.0430601835250854\n",
      "Ep 48: Batch #141 - Loss: 1.3523592948913574\n",
      "Ep 48: Batch #142 - Loss: 0.7903203964233398\n",
      "Ep 48: Batch #143 - Loss: 0.9590703248977661\n",
      "Ep 48: Batch #144 - Loss: 0.7162638902664185\n",
      "Ep 48: Batch #145 - Loss: 0.6741393804550171\n",
      "Ep 48: Batch #146 - Loss: 0.879101574420929\n",
      "Ep 48: Batch #147 - Loss: 0.8560560941696167\n",
      "Ep 48: Batch #148 - Loss: 0.9718173742294312\n",
      "Ep 48: Batch #149 - Loss: 0.8487608432769775\n",
      "Ep 48: Batch #150 - Loss: 0.8781769275665283\n",
      "Ep 48: Batch #151 - Loss: 0.723693311214447\n",
      "Ep 48: Batch #152 - Loss: 0.7357180714607239\n",
      "Ep 48: Batch #153 - Loss: 1.098739504814148\n",
      "Ep 48: Batch #154 - Loss: 0.7593425512313843\n",
      "Ep 48: Batch #155 - Loss: 0.8284571766853333\n",
      "Ep 48: Batch #156 - Loss: 1.0122140645980835\n",
      "Ep 48: Batch #157 - Loss: 0.7575235366821289\n",
      "Ep 48: Batch #158 - Loss: 0.8016590476036072\n",
      "Ep 48: Batch #159 - Loss: 0.8034491539001465\n",
      "Ep 48: Batch #160 - Loss: 0.8991804718971252\n",
      "Ep 48: Batch #161 - Loss: 0.8116945624351501\n",
      "Ep 48: Batch #162 - Loss: 0.9270017743110657\n",
      "Ep 48: Batch #163 - Loss: 0.9254910349845886\n",
      "Ep 48: Batch #164 - Loss: 0.7803568243980408\n",
      "Ep 48: Batch #165 - Loss: 1.493862271308899\n",
      "Ep 48: Batch #166 - Loss: 0.6750481724739075\n",
      "Ep 48: Batch #167 - Loss: 1.0815128087997437\n",
      "Ep 48: Batch #168 - Loss: 0.8554791212081909\n",
      "Ep 48: Batch #169 - Loss: 0.7969309091567993\n",
      "Ep 48: Batch #170 - Loss: 0.7994678020477295\n",
      "Ep 48: Batch #171 - Loss: 0.7756766676902771\n",
      "Ep 48: Batch #172 - Loss: 0.630537211894989\n",
      "Ep 48: Batch #173 - Loss: 1.1893492937088013\n",
      "Ep 48: Batch #174 - Loss: 0.5756657123565674\n",
      "Ep 48: Batch #175 - Loss: 0.7746964693069458\n",
      "Ep 48: Batch #176 - Loss: 1.1495553255081177\n",
      "Ep 48: Batch #177 - Loss: 0.8437588214874268\n",
      "Ep 48: Batch #178 - Loss: 0.7585203647613525\n",
      "Ep 48: Batch #179 - Loss: 0.9336466789245605\n",
      "Ep 48: Batch #180 - Loss: 0.8495525121688843\n",
      "Ep 48: Batch #181 - Loss: 0.9855820536613464\n",
      "Ep 48: Batch #182 - Loss: 0.7608662843704224\n",
      "Ep 48: Batch #183 - Loss: 0.7601310610771179\n",
      "Ep 48: Batch #184 - Loss: 1.0637590885162354\n",
      "Ep 48: Batch #185 - Loss: 0.7541305422782898\n",
      "Ep 48: Batch #186 - Loss: 0.9608992338180542\n",
      "Ep 48: Batch #187 - Loss: 1.1618362665176392\n",
      "Ep 48: Batch #188 - Loss: 1.343839168548584\n",
      "Ep 48: Batch #189 - Loss: 0.6979491114616394\n",
      "Ep 48: Batch #190 - Loss: 0.7309228777885437\n",
      "Ep 48: Batch #191 - Loss: 1.0590343475341797\n",
      "Ep 48: Batch #192 - Loss: 0.6663712859153748\n",
      "Ep 48: Batch #193 - Loss: 0.7363952398300171\n",
      "Ep 48: Batch #194 - Loss: 0.6920506954193115\n",
      "Ep 48: Batch #195 - Loss: 0.9771995544433594\n",
      "Ep 48: Batch #196 - Loss: 0.8606968522071838\n",
      "Ep 48: Batch #197 - Loss: 0.8963785171508789\n",
      "Ep 48: Batch #198 - Loss: 0.6735506057739258\n",
      "Ep 48: Batch #199 - Loss: 0.8566097021102905\n",
      "Ep 49: Batch #0 - Loss: 0.7863771319389343\n",
      "Ep 49: Batch #1 - Loss: 0.8711860775947571\n",
      "Ep 49: Batch #2 - Loss: 1.0030303001403809\n",
      "Ep 49: Batch #3 - Loss: 0.8596823215484619\n",
      "Ep 49: Batch #4 - Loss: 0.7837445139884949\n",
      "Ep 49: Batch #5 - Loss: 0.6645823121070862\n",
      "Ep 49: Batch #6 - Loss: 0.8735886216163635\n",
      "Ep 49: Batch #7 - Loss: 0.6975886821746826\n",
      "Ep 49: Batch #8 - Loss: 0.7296043634414673\n",
      "Ep 49: Batch #9 - Loss: 1.3919206857681274\n",
      "Ep 49: Batch #10 - Loss: 1.0005199909210205\n",
      "Ep 49: Batch #11 - Loss: 0.665953516960144\n",
      "Ep 49: Batch #12 - Loss: 1.5531789064407349\n",
      "Ep 49: Batch #13 - Loss: 0.6446776390075684\n",
      "Ep 49: Batch #14 - Loss: 0.7227948307991028\n",
      "Ep 49: Batch #15 - Loss: 1.232019305229187\n",
      "Ep 49: Batch #16 - Loss: 1.2675824165344238\n",
      "Ep 49: Batch #17 - Loss: 0.8745371699333191\n",
      "Ep 49: Batch #18 - Loss: 0.9381268620491028\n",
      "Ep 49: Batch #19 - Loss: 0.664091944694519\n",
      "Ep 49: Batch #20 - Loss: 0.650384783744812\n",
      "Ep 49: Batch #21 - Loss: 1.2063864469528198\n",
      "Ep 49: Batch #22 - Loss: 0.7216833233833313\n",
      "Ep 49: Batch #23 - Loss: 0.7377795577049255\n",
      "Ep 49: Batch #24 - Loss: 0.8186260461807251\n",
      "Ep 49: Batch #25 - Loss: 0.7098579406738281\n",
      "Ep 49: Batch #26 - Loss: 0.7253430485725403\n",
      "Ep 49: Batch #27 - Loss: 1.3443214893341064\n",
      "Ep 49: Batch #28 - Loss: 0.8621298670768738\n",
      "Ep 49: Batch #29 - Loss: 0.8863090872764587\n",
      "Ep 49: Batch #30 - Loss: 1.1957805156707764\n",
      "Ep 49: Batch #31 - Loss: 0.6696966290473938\n",
      "Ep 49: Batch #32 - Loss: 0.7422260046005249\n",
      "Ep 49: Batch #33 - Loss: 0.8026704788208008\n",
      "Ep 49: Batch #34 - Loss: 0.7787232995033264\n",
      "Ep 49: Batch #35 - Loss: 0.9417516589164734\n",
      "Ep 49: Batch #36 - Loss: 0.6978404521942139\n",
      "Ep 49: Batch #37 - Loss: 1.1348249912261963\n",
      "Ep 49: Batch #38 - Loss: 0.73968106508255\n",
      "Ep 49: Batch #39 - Loss: 0.8152439594268799\n",
      "Ep 49: Batch #40 - Loss: 0.7688488960266113\n",
      "Ep 49: Batch #41 - Loss: 0.7321019768714905\n",
      "Ep 49: Batch #42 - Loss: 0.7176616787910461\n",
      "Ep 49: Batch #43 - Loss: 0.7828624248504639\n",
      "Ep 49: Batch #44 - Loss: 0.7790557146072388\n",
      "Ep 49: Batch #45 - Loss: 0.6285457015037537\n",
      "Ep 49: Batch #46 - Loss: 0.8244385719299316\n",
      "Ep 49: Batch #47 - Loss: 0.9535490870475769\n",
      "Ep 49: Batch #48 - Loss: 1.346644401550293\n",
      "Ep 49: Batch #49 - Loss: 1.0072325468063354\n",
      "Ep 49: Batch #50 - Loss: 0.702129602432251\n",
      "Ep 49: Batch #51 - Loss: 0.9871340394020081\n",
      "Ep 49: Batch #52 - Loss: 0.7899948954582214\n",
      "Ep 49: Batch #53 - Loss: 0.8166970014572144\n",
      "Ep 49: Batch #54 - Loss: 0.7007022500038147\n",
      "Ep 49: Batch #55 - Loss: 0.7459800243377686\n",
      "Ep 49: Batch #56 - Loss: 1.2537708282470703\n",
      "Ep 49: Batch #57 - Loss: 0.8410943746566772\n",
      "Ep 49: Batch #58 - Loss: 0.9920863509178162\n",
      "Ep 49: Batch #59 - Loss: 0.6768617630004883\n",
      "Ep 49: Batch #60 - Loss: 1.303882122039795\n",
      "Ep 49: Batch #61 - Loss: 0.6319624185562134\n",
      "Ep 49: Batch #62 - Loss: 0.7169780731201172\n",
      "Ep 49: Batch #63 - Loss: 0.9956669211387634\n",
      "Ep 49: Batch #64 - Loss: 9.423294067382812\n",
      "Ep 49: Batch #65 - Loss: 0.608100175857544\n",
      "Ep 49: Batch #66 - Loss: 0.7903420925140381\n",
      "Ep 49: Batch #67 - Loss: 0.9046303033828735\n",
      "Ep 49: Batch #68 - Loss: 0.9014958739280701\n",
      "Ep 49: Batch #69 - Loss: 0.7396624684333801\n",
      "Ep 49: Batch #70 - Loss: 0.7694985866546631\n",
      "Ep 49: Batch #71 - Loss: 0.6747676730155945\n",
      "Ep 49: Batch #72 - Loss: 0.8481357097625732\n",
      "Ep 49: Batch #73 - Loss: 0.8958331346511841\n",
      "Ep 49: Batch #74 - Loss: 0.7348728179931641\n",
      "Ep 49: Batch #75 - Loss: 0.7630911469459534\n",
      "Ep 49: Batch #76 - Loss: 1.0900394916534424\n",
      "Ep 49: Batch #77 - Loss: 0.7289984226226807\n",
      "Ep 49: Batch #78 - Loss: 1.151688814163208\n",
      "Ep 49: Batch #79 - Loss: 0.6213968992233276\n",
      "Ep 49: Batch #80 - Loss: 0.8529145121574402\n",
      "Ep 49: Batch #81 - Loss: 1.673402190208435\n",
      "Ep 49: Batch #82 - Loss: 0.8676934838294983\n",
      "Ep 49: Batch #83 - Loss: 1.7299028635025024\n",
      "Ep 49: Batch #84 - Loss: 0.7088904976844788\n",
      "Ep 49: Batch #85 - Loss: 0.9680437445640564\n",
      "Ep 49: Batch #86 - Loss: 0.7030242681503296\n",
      "Ep 49: Batch #87 - Loss: 0.707789957523346\n",
      "Ep 49: Batch #88 - Loss: 0.7956823110580444\n",
      "Ep 49: Batch #89 - Loss: 0.8792070746421814\n",
      "Ep 49: Batch #90 - Loss: 1.1456513404846191\n",
      "Ep 49: Batch #91 - Loss: 0.7956011891365051\n",
      "Ep 49: Batch #92 - Loss: 1.0211600065231323\n",
      "Ep 49: Batch #93 - Loss: 1.0212079286575317\n",
      "Ep 49: Batch #94 - Loss: 1.0416244268417358\n",
      "Ep 49: Batch #95 - Loss: 0.9129660725593567\n",
      "Ep 49: Batch #96 - Loss: 0.89846271276474\n",
      "Ep 49: Batch #97 - Loss: 0.7238323092460632\n",
      "Ep 49: Batch #98 - Loss: 0.7331212162971497\n",
      "Ep 49: Batch #99 - Loss: 0.9523659348487854\n",
      "Ep 49: Batch #100 - Loss: 0.6727966070175171\n",
      "Ep 49: Batch #101 - Loss: 1.0401605367660522\n",
      "Ep 49: Batch #102 - Loss: 0.7768397927284241\n",
      "Ep 49: Batch #103 - Loss: 0.7846719026565552\n",
      "Ep 49: Batch #104 - Loss: 0.79541015625\n",
      "Ep 49: Batch #105 - Loss: 1.0209201574325562\n",
      "Ep 49: Batch #106 - Loss: 0.7536932826042175\n",
      "Ep 49: Batch #107 - Loss: 0.751800000667572\n",
      "Ep 49: Batch #108 - Loss: 1.026295781135559\n",
      "Ep 49: Batch #109 - Loss: 0.757282018661499\n",
      "Ep 49: Batch #110 - Loss: 0.911259114742279\n",
      "Ep 49: Batch #111 - Loss: 1.370934247970581\n",
      "Ep 49: Batch #112 - Loss: 1.0394810438156128\n",
      "Ep 49: Batch #113 - Loss: 0.8103457093238831\n",
      "Ep 49: Batch #114 - Loss: 0.8962615132331848\n",
      "Ep 49: Batch #115 - Loss: 1.0865834951400757\n",
      "Ep 49: Batch #116 - Loss: 0.6295527219772339\n",
      "Ep 49: Batch #117 - Loss: 0.8664289116859436\n",
      "Ep 49: Batch #118 - Loss: 0.5397067070007324\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved in file: ./weights_autoencoder_low_LR/model_e49b118_1516651275.3314586.ckpt\n",
      "Ep 49: Batch #119 - Loss: 1.020317792892456\n",
      "Ep 49: Batch #120 - Loss: 0.7945887446403503\n",
      "Ep 49: Batch #121 - Loss: 0.6803500056266785\n",
      "Ep 49: Batch #122 - Loss: 0.8192542791366577\n",
      "Ep 49: Batch #123 - Loss: 0.8259003162384033\n",
      "Ep 49: Batch #124 - Loss: 0.6590277552604675\n",
      "Ep 49: Batch #125 - Loss: 2.7121951580047607\n",
      "Ep 49: Batch #126 - Loss: 1.2178739309310913\n",
      "Ep 49: Batch #127 - Loss: 0.7428073883056641\n",
      "Ep 49: Batch #128 - Loss: 1.097109317779541\n",
      "Ep 49: Batch #129 - Loss: 0.8321294784545898\n",
      "Ep 49: Batch #130 - Loss: 0.7178873419761658\n",
      "Ep 49: Batch #131 - Loss: 0.9871737360954285\n",
      "Ep 49: Batch #132 - Loss: 0.817291796207428\n",
      "Ep 49: Batch #133 - Loss: 0.8114952445030212\n",
      "Ep 49: Batch #134 - Loss: 0.7629230618476868\n",
      "Ep 49: Batch #135 - Loss: 0.9586791396141052\n",
      "Ep 49: Batch #136 - Loss: 1.1729531288146973\n",
      "Ep 49: Batch #137 - Loss: 0.9573789238929749\n",
      "Ep 49: Batch #138 - Loss: 1.063022255897522\n",
      "Ep 49: Batch #139 - Loss: 0.893345057964325\n",
      "Ep 49: Batch #140 - Loss: 1.0416021347045898\n",
      "Ep 49: Batch #141 - Loss: 1.3509105443954468\n",
      "Ep 49: Batch #142 - Loss: 0.7891502380371094\n",
      "Ep 49: Batch #143 - Loss: 0.9574295878410339\n",
      "Ep 49: Batch #144 - Loss: 0.715177059173584\n",
      "Ep 49: Batch #145 - Loss: 0.6731398105621338\n",
      "Ep 49: Batch #146 - Loss: 0.8779119849205017\n",
      "Ep 49: Batch #147 - Loss: 0.8545064926147461\n",
      "Ep 49: Batch #148 - Loss: 0.9702469706535339\n",
      "Ep 49: Batch #149 - Loss: 0.8473174571990967\n",
      "Ep 49: Batch #150 - Loss: 0.8768972158432007\n",
      "Ep 49: Batch #151 - Loss: 0.7228718996047974\n",
      "Ep 49: Batch #152 - Loss: 0.7348392605781555\n",
      "Ep 49: Batch #153 - Loss: 1.0971368551254272\n",
      "Ep 49: Batch #154 - Loss: 0.7582284808158875\n",
      "Ep 49: Batch #155 - Loss: 0.8272573351860046\n",
      "Ep 49: Batch #156 - Loss: 1.010823130607605\n",
      "Ep 49: Batch #157 - Loss: 0.7563505172729492\n",
      "Ep 49: Batch #158 - Loss: 0.8007766604423523\n",
      "Ep 49: Batch #159 - Loss: 0.8021520376205444\n",
      "Ep 49: Batch #160 - Loss: 0.8980876803398132\n",
      "Ep 49: Batch #161 - Loss: 0.8105152249336243\n",
      "Ep 49: Batch #162 - Loss: 0.9256629347801208\n",
      "Ep 49: Batch #163 - Loss: 0.9244263768196106\n",
      "Ep 49: Batch #164 - Loss: 0.7791818976402283\n",
      "Ep 49: Batch #165 - Loss: 1.4924272298812866\n",
      "Ep 49: Batch #166 - Loss: 0.6739038228988647\n",
      "Ep 49: Batch #167 - Loss: 1.0801055431365967\n",
      "Ep 49: Batch #168 - Loss: 0.8541498184204102\n",
      "Ep 49: Batch #169 - Loss: 0.7957713007926941\n",
      "Ep 49: Batch #170 - Loss: 0.7982089519500732\n",
      "Ep 49: Batch #171 - Loss: 0.7743710875511169\n",
      "Ep 49: Batch #172 - Loss: 0.6296671032905579\n",
      "Ep 49: Batch #173 - Loss: 1.1874613761901855\n",
      "Ep 49: Batch #174 - Loss: 0.5748139023780823\n",
      "Ep 49: Batch #175 - Loss: 0.7737686634063721\n",
      "Ep 49: Batch #176 - Loss: 1.1476300954818726\n",
      "Ep 49: Batch #177 - Loss: 0.8424902558326721\n",
      "Ep 49: Batch #178 - Loss: 0.7572661638259888\n",
      "Ep 49: Batch #179 - Loss: 0.9321498274803162\n",
      "Ep 49: Batch #180 - Loss: 0.8479819297790527\n",
      "Ep 49: Batch #181 - Loss: 0.9839300513267517\n",
      "Ep 49: Batch #182 - Loss: 0.7599313259124756\n",
      "Ep 49: Batch #183 - Loss: 0.7589395046234131\n",
      "Ep 49: Batch #184 - Loss: 1.0626716613769531\n",
      "Ep 49: Batch #185 - Loss: 0.7529928684234619\n",
      "Ep 49: Batch #186 - Loss: 0.9592351317405701\n",
      "Ep 49: Batch #187 - Loss: 1.1604853868484497\n",
      "Ep 49: Batch #188 - Loss: 1.342700481414795\n",
      "Ep 49: Batch #189 - Loss: 0.6970641016960144\n",
      "Ep 49: Batch #190 - Loss: 0.7298552393913269\n",
      "Ep 49: Batch #191 - Loss: 1.0575510263442993\n",
      "Ep 49: Batch #192 - Loss: 0.6655142903327942\n",
      "Ep 49: Batch #193 - Loss: 0.7351744174957275\n",
      "Ep 49: Batch #194 - Loss: 0.6909561157226562\n",
      "Ep 49: Batch #195 - Loss: 0.9758142232894897\n",
      "Ep 49: Batch #196 - Loss: 0.8595419526100159\n",
      "Ep 49: Batch #197 - Loss: 0.895029604434967\n",
      "Ep 49: Batch #198 - Loss: 0.6723794341087341\n",
      "Ep 49: Batch #199 - Loss: 0.8553005456924438\n",
      "Ep 50: Batch #0 - Loss: 0.7849869132041931\n",
      "Ep 50: Batch #1 - Loss: 0.8698514699935913\n",
      "Ep 50: Batch #2 - Loss: 1.0018292665481567\n",
      "Ep 50: Batch #3 - Loss: 0.8585803508758545\n",
      "Ep 50: Batch #4 - Loss: 0.7824598550796509\n",
      "Ep 50: Batch #5 - Loss: 0.6637170910835266\n",
      "Ep 50: Batch #6 - Loss: 0.8723847270011902\n",
      "Ep 50: Batch #7 - Loss: 0.6965906023979187\n",
      "Ep 50: Batch #8 - Loss: 0.7285980582237244\n",
      "Ep 50: Batch #9 - Loss: 1.390028715133667\n",
      "Ep 50: Batch #10 - Loss: 0.9991990327835083\n",
      "Ep 50: Batch #11 - Loss: 0.6649748086929321\n",
      "Ep 50: Batch #12 - Loss: 1.5516797304153442\n",
      "Ep 50: Batch #13 - Loss: 0.6439356207847595\n",
      "Ep 50: Batch #14 - Loss: 0.7218258380889893\n",
      "Ep 50: Batch #15 - Loss: 1.2304435968399048\n",
      "Ep 50: Batch #16 - Loss: 1.2657538652420044\n",
      "Ep 50: Batch #17 - Loss: 0.8731898665428162\n",
      "Ep 50: Batch #18 - Loss: 0.9371508955955505\n",
      "Ep 50: Batch #19 - Loss: 0.6631927490234375\n",
      "Ep 50: Batch #20 - Loss: 0.6493883728981018\n",
      "Ep 50: Batch #21 - Loss: 1.2051279544830322\n",
      "Ep 50: Batch #22 - Loss: 0.7207470536231995\n",
      "Ep 50: Batch #23 - Loss: 0.7366132736206055\n",
      "Ep 50: Batch #24 - Loss: 0.8175954222679138\n",
      "Ep 50: Batch #25 - Loss: 0.7087054252624512\n",
      "Ep 50: Batch #26 - Loss: 0.7240565419197083\n",
      "Ep 50: Batch #27 - Loss: 1.3426066637039185\n",
      "Ep 50: Batch #28 - Loss: 0.8609562516212463\n",
      "Ep 50: Batch #29 - Loss: 0.8848938345909119\n",
      "Ep 50: Batch #30 - Loss: 1.1945571899414062\n",
      "Ep 50: Batch #31 - Loss: 0.6688560843467712\n",
      "Ep 50: Batch #32 - Loss: 0.7410323023796082\n",
      "Ep 50: Batch #33 - Loss: 0.8015631437301636\n",
      "Ep 50: Batch #34 - Loss: 0.7776432037353516\n",
      "Ep 50: Batch #35 - Loss: 0.9401898980140686\n",
      "Ep 50: Batch #36 - Loss: 0.6967660784721375\n",
      "Ep 50: Batch #37 - Loss: 1.1335314512252808\n",
      "Ep 50: Batch #38 - Loss: 0.7384001612663269\n",
      "Ep 50: Batch #39 - Loss: 0.8142889738082886\n",
      "Ep 50: Batch #40 - Loss: 0.7676646709442139\n",
      "Ep 50: Batch #41 - Loss: 0.7307863831520081\n",
      "Ep 50: Batch #42 - Loss: 0.7166188955307007\n",
      "Ep 50: Batch #43 - Loss: 0.7817732691764832\n",
      "Ep 50: Batch #44 - Loss: 0.7778142094612122\n",
      "Ep 50: Batch #45 - Loss: 0.6273996829986572\n",
      "Ep 50: Batch #46 - Loss: 0.8230117559432983\n",
      "Ep 50: Batch #47 - Loss: 0.9518812894821167\n",
      "Ep 50: Batch #48 - Loss: 1.3450995683670044\n",
      "Ep 50: Batch #49 - Loss: 1.0055040121078491\n",
      "Ep 50: Batch #50 - Loss: 0.7012946009635925\n",
      "Ep 50: Batch #51 - Loss: 0.985454261302948\n",
      "Ep 50: Batch #52 - Loss: 0.7889578938484192\n",
      "Ep 50: Batch #53 - Loss: 0.8154760003089905\n",
      "Ep 50: Batch #54 - Loss: 0.6996940970420837\n",
      "Ep 50: Batch #55 - Loss: 0.7447634935379028\n",
      "Ep 50: Batch #56 - Loss: 1.2521164417266846\n",
      "Ep 50: Batch #57 - Loss: 0.839683473110199\n",
      "Ep 50: Batch #58 - Loss: 0.990432858467102\n",
      "Ep 50: Batch #59 - Loss: 0.6760047674179077\n",
      "Ep 50: Batch #60 - Loss: 1.3025339841842651\n",
      "Ep 50: Batch #61 - Loss: 0.6310538649559021\n",
      "Ep 50: Batch #62 - Loss: 0.7157473564147949\n",
      "Ep 50: Batch #63 - Loss: 0.9942492842674255\n",
      "Ep 50: Batch #64 - Loss: 9.42216968536377\n",
      "Ep 50: Batch #65 - Loss: 0.607208788394928\n",
      "Ep 50: Batch #66 - Loss: 0.7889859676361084\n",
      "Ep 50: Batch #67 - Loss: 0.9034000039100647\n",
      "Ep 50: Batch #68 - Loss: 0.9000601172447205\n",
      "Ep 50: Batch #69 - Loss: 0.738525390625\n",
      "Ep 50: Batch #70 - Loss: 0.7680668234825134\n",
      "Ep 50: Batch #71 - Loss: 0.673809289932251\n",
      "Ep 50: Batch #72 - Loss: 0.8468422293663025\n",
      "Ep 50: Batch #73 - Loss: 0.894209086894989\n",
      "Ep 50: Batch #74 - Loss: 0.7336068153381348\n",
      "Ep 50: Batch #75 - Loss: 0.762042224407196\n",
      "Ep 50: Batch #76 - Loss: 1.0888793468475342\n",
      "Ep 50: Batch #77 - Loss: 0.7278127074241638\n",
      "Ep 50: Batch #78 - Loss: 1.14995539188385\n",
      "Ep 50: Batch #79 - Loss: 0.6204221844673157\n",
      "Ep 50: Batch #80 - Loss: 0.8515090346336365\n",
      "Ep 50: Batch #81 - Loss: 1.6720834970474243\n",
      "Ep 50: Batch #82 - Loss: 0.8665258884429932\n",
      "Ep 50: Batch #83 - Loss: 1.7289267778396606\n",
      "Ep 50: Batch #84 - Loss: 0.707728385925293\n",
      "Ep 50: Batch #85 - Loss: 0.9669880867004395\n",
      "Ep 50: Batch #86 - Loss: 0.7017625570297241\n",
      "Ep 50: Batch #87 - Loss: 0.7066671848297119\n",
      "Ep 50: Batch #88 - Loss: 0.7944027185440063\n",
      "Ep 50: Batch #89 - Loss: 0.8783985376358032\n",
      "Ep 50: Batch #90 - Loss: 1.1438257694244385\n",
      "Ep 50: Batch #91 - Loss: 0.7942217588424683\n",
      "Ep 50: Batch #92 - Loss: 1.0196822881698608\n",
      "Ep 50: Batch #93 - Loss: 1.0194333791732788\n",
      "Ep 50: Batch #94 - Loss: 1.0400456190109253\n",
      "Ep 50: Batch #95 - Loss: 0.9116162061691284\n",
      "Ep 50: Batch #96 - Loss: 0.8971956968307495\n",
      "Ep 50: Batch #97 - Loss: 0.7226661443710327\n",
      "Ep 50: Batch #98 - Loss: 0.7319521903991699\n",
      "Ep 50: Batch #99 - Loss: 0.9511444568634033\n",
      "Ep 50: Batch #100 - Loss: 0.67169588804245\n",
      "Ep 50: Batch #101 - Loss: 1.0388197898864746\n",
      "Ep 50: Batch #102 - Loss: 0.7756749391555786\n",
      "Ep 50: Batch #103 - Loss: 0.783573567867279\n",
      "Ep 50: Batch #104 - Loss: 0.7942299246788025\n",
      "Ep 50: Batch #105 - Loss: 1.0193175077438354\n",
      "Ep 50: Batch #106 - Loss: 0.752580463886261\n",
      "Ep 50: Batch #107 - Loss: 0.7505866289138794\n",
      "Ep 50: Batch #108 - Loss: 1.0247961282730103\n",
      "Ep 50: Batch #109 - Loss: 0.7562205195426941\n",
      "Ep 50: Batch #110 - Loss: 0.9096672534942627\n",
      "Ep 50: Batch #111 - Loss: 1.369226336479187\n",
      "Ep 50: Batch #112 - Loss: 1.0379739999771118\n",
      "Ep 50: Batch #113 - Loss: 0.8091195225715637\n",
      "Ep 50: Batch #114 - Loss: 0.8948420882225037\n",
      "Ep 50: Batch #115 - Loss: 1.0851006507873535\n",
      "Ep 50: Batch #116 - Loss: 0.6288461089134216\n",
      "Ep 50: Batch #117 - Loss: 0.8652756214141846\n",
      "Ep 50: Batch #118 - Loss: 0.5387892127037048\n",
      "Model saved in file: ./weights_autoencoder_low_LR/model_e50b118_1516651275.4672515.ckpt\n",
      "Ep 50: Batch #119 - Loss: 1.0190441608428955\n",
      "Ep 50: Batch #120 - Loss: 0.7934526205062866\n",
      "Ep 50: Batch #121 - Loss: 0.6792452335357666\n",
      "Ep 50: Batch #122 - Loss: 0.8181009292602539\n",
      "Ep 50: Batch #123 - Loss: 0.824669361114502\n",
      "Ep 50: Batch #124 - Loss: 0.6581799983978271\n",
      "Ep 50: Batch #125 - Loss: 2.7104053497314453\n",
      "Ep 50: Batch #126 - Loss: 1.2164722681045532\n",
      "Ep 50: Batch #127 - Loss: 0.7414997220039368\n",
      "Ep 50: Batch #128 - Loss: 1.0953994989395142\n",
      "Ep 50: Batch #129 - Loss: 0.8307790160179138\n",
      "Ep 50: Batch #130 - Loss: 0.7167615294456482\n",
      "Ep 50: Batch #131 - Loss: 0.9854949712753296\n",
      "Ep 50: Batch #132 - Loss: 0.8159502744674683\n",
      "Ep 50: Batch #133 - Loss: 0.8102558255195618\n",
      "Ep 50: Batch #134 - Loss: 0.7616817951202393\n",
      "Ep 50: Batch #135 - Loss: 0.9570747017860413\n",
      "Ep 50: Batch #136 - Loss: 1.1712735891342163\n",
      "Ep 50: Batch #137 - Loss: 0.9559268951416016\n",
      "Ep 50: Batch #138 - Loss: 1.0615568161010742\n",
      "Ep 50: Batch #139 - Loss: 0.8919609785079956\n",
      "Ep 50: Batch #140 - Loss: 1.0401532649993896\n",
      "Ep 50: Batch #141 - Loss: 1.3494406938552856\n",
      "Ep 50: Batch #142 - Loss: 0.7879773378372192\n",
      "Ep 50: Batch #143 - Loss: 0.9557815790176392\n",
      "Ep 50: Batch #144 - Loss: 0.7140929102897644\n",
      "Ep 50: Batch #145 - Loss: 0.6721451878547668\n",
      "Ep 50: Batch #146 - Loss: 0.8767320513725281\n",
      "Ep 50: Batch #147 - Loss: 0.8529704213142395\n",
      "Ep 50: Batch #148 - Loss: 0.9686676263809204\n",
      "Ep 50: Batch #149 - Loss: 0.8458820581436157\n",
      "Ep 50: Batch #150 - Loss: 0.8756132125854492\n",
      "Ep 50: Batch #151 - Loss: 0.722055971622467\n",
      "Ep 50: Batch #152 - Loss: 0.7339550256729126\n",
      "Ep 50: Batch #153 - Loss: 1.0955458879470825\n",
      "Ep 50: Batch #154 - Loss: 0.7570972442626953\n",
      "Ep 50: Batch #155 - Loss: 0.8260787725448608\n",
      "Ep 50: Batch #156 - Loss: 1.0094324350357056\n",
      "Ep 50: Batch #157 - Loss: 0.75518399477005\n",
      "Ep 50: Batch #158 - Loss: 0.7999034523963928\n",
      "Ep 50: Batch #159 - Loss: 0.8008633852005005\n",
      "Ep 50: Batch #160 - Loss: 0.897005558013916\n",
      "Ep 50: Batch #161 - Loss: 0.8093312382698059\n",
      "Ep 50: Batch #162 - Loss: 0.9243324995040894\n",
      "Ep 50: Batch #163 - Loss: 0.9233685731887817\n",
      "Ep 50: Batch #164 - Loss: 0.777991771697998\n",
      "Ep 50: Batch #165 - Loss: 1.4910496473312378\n",
      "Ep 50: Batch #166 - Loss: 0.6727759838104248\n",
      "Ep 50: Batch #167 - Loss: 1.0786700248718262\n",
      "Ep 50: Batch #168 - Loss: 0.8528305888175964\n",
      "Ep 50: Batch #169 - Loss: 0.7946282625198364\n",
      "Ep 50: Batch #170 - Loss: 0.7969560623168945\n",
      "Ep 50: Batch #171 - Loss: 0.773074746131897\n",
      "Ep 50: Batch #172 - Loss: 0.6287975907325745\n",
      "Ep 50: Batch #173 - Loss: 1.1855659484863281\n",
      "Ep 50: Batch #174 - Loss: 0.5739701986312866\n",
      "Ep 50: Batch #175 - Loss: 0.772858202457428\n",
      "Ep 50: Batch #176 - Loss: 1.1456762552261353\n",
      "Ep 50: Batch #177 - Loss: 0.8412213325500488\n",
      "Ep 50: Batch #178 - Loss: 0.756027340888977\n",
      "Ep 50: Batch #179 - Loss: 0.930675745010376\n",
      "Ep 50: Batch #180 - Loss: 0.8464205265045166\n",
      "Ep 50: Batch #181 - Loss: 0.9822897911071777\n",
      "Ep 50: Batch #182 - Loss: 0.7590023279190063\n",
      "Ep 50: Batch #183 - Loss: 0.757766604423523\n",
      "Ep 50: Batch #184 - Loss: 1.0615878105163574\n",
      "Ep 50: Batch #185 - Loss: 0.7518594264984131\n",
      "Ep 50: Batch #186 - Loss: 0.957583487033844\n",
      "Ep 50: Batch #187 - Loss: 1.1590887308120728\n",
      "Ep 50: Batch #188 - Loss: 1.3415621519088745\n",
      "Ep 50: Batch #189 - Loss: 0.6961951851844788\n",
      "Ep 50: Batch #190 - Loss: 0.7287972569465637\n",
      "Ep 50: Batch #191 - Loss: 1.0560399293899536\n",
      "Ep 50: Batch #192 - Loss: 0.6646600961685181\n",
      "Ep 50: Batch #193 - Loss: 0.7339619994163513\n",
      "Ep 50: Batch #194 - Loss: 0.68986976146698\n",
      "Ep 50: Batch #195 - Loss: 0.9744225740432739\n",
      "Ep 50: Batch #196 - Loss: 0.8583812713623047\n",
      "Ep 50: Batch #197 - Loss: 0.8936854004859924\n",
      "Ep 50: Batch #198 - Loss: 0.6712182760238647\n",
      "Ep 50: Batch #199 - Loss: 0.8539850115776062\n",
      "Ep 51: Batch #0 - Loss: 0.7836084961891174\n",
      "Ep 51: Batch #1 - Loss: 0.8685147762298584\n",
      "Ep 51: Batch #2 - Loss: 1.0006496906280518\n",
      "Ep 51: Batch #3 - Loss: 0.8574874997138977\n",
      "Ep 51: Batch #4 - Loss: 0.781176745891571\n",
      "Ep 51: Batch #5 - Loss: 0.662844181060791\n",
      "Ep 51: Batch #6 - Loss: 0.8711804747581482\n",
      "Ep 51: Batch #7 - Loss: 0.6955980062484741\n",
      "Ep 51: Batch #8 - Loss: 0.7275903820991516\n",
      "Ep 51: Batch #9 - Loss: 1.3881374597549438\n",
      "Ep 51: Batch #10 - Loss: 0.9978935122489929\n",
      "Ep 51: Batch #11 - Loss: 0.6640066504478455\n",
      "Ep 51: Batch #12 - Loss: 1.5501707792282104\n",
      "Ep 51: Batch #13 - Loss: 0.6431998014450073\n",
      "Ep 51: Batch #14 - Loss: 0.7208656668663025\n",
      "Ep 51: Batch #15 - Loss: 1.2288883924484253\n",
      "Ep 51: Batch #16 - Loss: 1.2639414072036743\n",
      "Ep 51: Batch #17 - Loss: 0.871849775314331\n",
      "Ep 51: Batch #18 - Loss: 0.93621426820755\n",
      "Ep 51: Batch #19 - Loss: 0.6622978448867798\n",
      "Ep 51: Batch #20 - Loss: 0.6483975052833557\n",
      "Ep 51: Batch #21 - Loss: 1.203859567642212\n",
      "Ep 51: Batch #22 - Loss: 0.7198214530944824\n",
      "Ep 51: Batch #23 - Loss: 0.7354522347450256\n",
      "Ep 51: Batch #24 - Loss: 0.8165704011917114\n",
      "Ep 51: Batch #25 - Loss: 0.7075666189193726\n",
      "Ep 51: Batch #26 - Loss: 0.7227795720100403\n",
      "Ep 51: Batch #27 - Loss: 1.340897798538208\n",
      "Ep 51: Batch #28 - Loss: 0.859808623790741\n",
      "Ep 51: Batch #29 - Loss: 0.8834875226020813\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 51: Batch #30 - Loss: 1.1933531761169434\n",
      "Ep 51: Batch #31 - Loss: 0.6679885387420654\n",
      "Ep 51: Batch #32 - Loss: 0.7398421764373779\n",
      "Ep 51: Batch #33 - Loss: 0.8004657626152039\n",
      "Ep 51: Batch #34 - Loss: 0.7765762209892273\n",
      "Ep 51: Batch #35 - Loss: 0.938642680644989\n",
      "Ep 51: Batch #36 - Loss: 0.6956887245178223\n",
      "Ep 51: Batch #37 - Loss: 1.1322306394577026\n",
      "Ep 51: Batch #38 - Loss: 0.7371335029602051\n",
      "Ep 51: Batch #39 - Loss: 0.8133309483528137\n",
      "Ep 51: Batch #40 - Loss: 0.7665005922317505\n",
      "Ep 51: Batch #41 - Loss: 0.7294792532920837\n",
      "Ep 51: Batch #42 - Loss: 0.7155580520629883\n",
      "Ep 51: Batch #43 - Loss: 0.7807000279426575\n",
      "Ep 51: Batch #44 - Loss: 0.7765804529190063\n",
      "Ep 51: Batch #45 - Loss: 0.6262623071670532\n",
      "Ep 51: Batch #46 - Loss: 0.8215966820716858\n",
      "Ep 51: Batch #47 - Loss: 0.9502197504043579\n",
      "Ep 51: Batch #48 - Loss: 1.3435676097869873\n",
      "Ep 51: Batch #49 - Loss: 1.0037648677825928\n",
      "Ep 51: Batch #50 - Loss: 0.7004616856575012\n",
      "Ep 51: Batch #51 - Loss: 0.9837879538536072\n",
      "Ep 51: Batch #52 - Loss: 0.7879239320755005\n",
      "Ep 51: Batch #53 - Loss: 0.8142547607421875\n",
      "Ep 51: Batch #54 - Loss: 0.6986939311027527\n",
      "Ep 51: Batch #55 - Loss: 0.7435593605041504\n",
      "Ep 51: Batch #56 - Loss: 1.2504552602767944\n",
      "Ep 51: Batch #57 - Loss: 0.8382883667945862\n",
      "Ep 51: Batch #58 - Loss: 0.9887816309928894\n",
      "Ep 51: Batch #59 - Loss: 0.6751565933227539\n",
      "Ep 51: Batch #60 - Loss: 1.3011842966079712\n",
      "Ep 51: Batch #61 - Loss: 0.6301584839820862\n",
      "Ep 51: Batch #62 - Loss: 0.7145286798477173\n",
      "Ep 51: Batch #63 - Loss: 0.9928420186042786\n",
      "Ep 51: Batch #64 - Loss: 9.421059608459473\n",
      "Ep 51: Batch #65 - Loss: 0.6063171625137329\n",
      "Ep 51: Batch #66 - Loss: 0.7876545190811157\n",
      "Ep 51: Batch #67 - Loss: 0.9021309614181519\n",
      "Ep 51: Batch #68 - Loss: 0.8986348509788513\n",
      "Ep 51: Batch #69 - Loss: 0.7374053597450256\n",
      "Ep 51: Batch #70 - Loss: 0.7666530609130859\n",
      "Ep 51: Batch #71 - Loss: 0.6728687286376953\n",
      "Ep 51: Batch #72 - Loss: 0.8455598950386047\n",
      "Ep 51: Batch #73 - Loss: 0.8925927877426147\n",
      "Ep 51: Batch #74 - Loss: 0.7323446869850159\n",
      "Ep 51: Batch #75 - Loss: 0.7610044479370117\n",
      "Ep 51: Batch #76 - Loss: 1.0877294540405273\n",
      "Ep 51: Batch #77 - Loss: 0.7266374826431274\n",
      "Ep 51: Batch #78 - Loss: 1.148215889930725\n",
      "Ep 51: Batch #79 - Loss: 0.6194556355476379\n",
      "Ep 51: Batch #80 - Loss: 0.8501105904579163\n",
      "Ep 51: Batch #81 - Loss: 1.6707683801651\n",
      "Ep 51: Batch #82 - Loss: 0.8653728365898132\n",
      "Ep 51: Batch #83 - Loss: 1.727960228919983\n",
      "Ep 51: Batch #84 - Loss: 0.706574022769928\n",
      "Ep 51: Batch #85 - Loss: 0.965926468372345\n",
      "Ep 51: Batch #86 - Loss: 0.7005146145820618\n",
      "Ep 51: Batch #87 - Loss: 0.7055549025535583\n",
      "Ep 51: Batch #88 - Loss: 0.7931347489356995\n",
      "Ep 51: Batch #89 - Loss: 0.8775978684425354\n",
      "Ep 51: Batch #90 - Loss: 1.14200758934021\n",
      "Ep 51: Batch #91 - Loss: 0.7928518652915955\n",
      "Ep 51: Batch #92 - Loss: 1.0182101726531982\n",
      "Ep 51: Batch #93 - Loss: 1.0176703929901123\n",
      "Ep 51: Batch #94 - Loss: 1.0384726524353027\n",
      "Ep 51: Batch #95 - Loss: 0.9102785587310791\n",
      "Ep 51: Batch #96 - Loss: 0.8959431648254395\n",
      "Ep 51: Batch #97 - Loss: 0.721501886844635\n",
      "Ep 51: Batch #98 - Loss: 0.7307748198509216\n",
      "Ep 51: Batch #99 - Loss: 0.9499070644378662\n",
      "Ep 51: Batch #100 - Loss: 0.6706016659736633\n",
      "Ep 51: Batch #101 - Loss: 1.0374977588653564\n",
      "Ep 51: Batch #102 - Loss: 0.7745087146759033\n",
      "Ep 51: Batch #103 - Loss: 0.7824673056602478\n",
      "Ep 51: Batch #104 - Loss: 0.7930577397346497\n",
      "Ep 51: Batch #105 - Loss: 1.0177085399627686\n",
      "Ep 51: Batch #106 - Loss: 0.7514878511428833\n",
      "Ep 51: Batch #107 - Loss: 0.749387264251709\n",
      "Ep 51: Batch #108 - Loss: 1.0233020782470703\n",
      "Ep 51: Batch #109 - Loss: 0.7551705241203308\n",
      "Ep 51: Batch #110 - Loss: 0.9080793857574463\n",
      "Ep 51: Batch #111 - Loss: 1.367516279220581\n",
      "Ep 51: Batch #112 - Loss: 1.0364930629730225\n",
      "Ep 51: Batch #113 - Loss: 0.807887852191925\n",
      "Ep 51: Batch #114 - Loss: 0.8934296369552612\n",
      "Ep 51: Batch #115 - Loss: 1.0836291313171387\n",
      "Ep 51: Batch #116 - Loss: 0.6281439065933228\n",
      "Ep 51: Batch #117 - Loss: 0.8641400933265686\n",
      "Ep 51: Batch #118 - Loss: 0.5378910303115845\n",
      "Model saved in file: ./weights_autoencoder_low_LR/model_e51b118_1516651275.6035378.ckpt\n",
      "Ep 51: Batch #119 - Loss: 1.0177836418151855\n",
      "Ep 51: Batch #120 - Loss: 0.7923223972320557\n",
      "Ep 51: Batch #121 - Loss: 0.6781549453735352\n",
      "Ep 51: Batch #122 - Loss: 0.8169681429862976\n",
      "Ep 51: Batch #123 - Loss: 0.8234458565711975\n",
      "Ep 51: Batch #124 - Loss: 0.6573358774185181\n",
      "Ep 51: Batch #125 - Loss: 2.7085585594177246\n",
      "Ep 51: Batch #126 - Loss: 1.2150861024856567\n",
      "Ep 51: Batch #127 - Loss: 0.7402036786079407\n",
      "Ep 51: Batch #128 - Loss: 1.0936895608901978\n",
      "Ep 51: Batch #129 - Loss: 0.8294298648834229\n",
      "Ep 51: Batch #130 - Loss: 0.7156513333320618\n",
      "Ep 51: Batch #131 - Loss: 0.9838230609893799\n",
      "Ep 51: Batch #132 - Loss: 0.814629077911377\n",
      "Ep 51: Batch #133 - Loss: 0.8090193271636963\n",
      "Ep 51: Batch #134 - Loss: 0.7604517936706543\n",
      "Ep 51: Batch #135 - Loss: 0.9554816484451294\n",
      "Ep 51: Batch #136 - Loss: 1.1696125268936157\n",
      "Ep 51: Batch #137 - Loss: 0.9544410109519958\n",
      "Ep 51: Batch #138 - Loss: 1.060084581375122\n",
      "Ep 51: Batch #139 - Loss: 0.8905867338180542\n",
      "Ep 51: Batch #140 - Loss: 1.038716435432434\n",
      "Ep 51: Batch #141 - Loss: 1.3479748964309692\n",
      "Ep 51: Batch #142 - Loss: 0.7868034839630127\n",
      "Ep 51: Batch #143 - Loss: 0.9541324377059937\n",
      "Ep 51: Batch #144 - Loss: 0.7130166292190552\n",
      "Ep 51: Batch #145 - Loss: 0.6711621284484863\n",
      "Ep 51: Batch #146 - Loss: 0.8755594491958618\n",
      "Ep 51: Batch #147 - Loss: 0.8514539003372192\n",
      "Ep 51: Batch #148 - Loss: 0.9670906066894531\n",
      "Ep 51: Batch #149 - Loss: 0.8444559574127197\n",
      "Ep 51: Batch #150 - Loss: 0.8743352890014648\n",
      "Ep 51: Batch #151 - Loss: 0.721246063709259\n",
      "Ep 51: Batch #152 - Loss: 0.7330732345581055\n",
      "Ep 51: Batch #153 - Loss: 1.0939558744430542\n",
      "Ep 51: Batch #154 - Loss: 0.7559539675712585\n",
      "Ep 51: Batch #155 - Loss: 0.8249132633209229\n",
      "Ep 51: Batch #156 - Loss: 1.0080500841140747\n",
      "Ep 51: Batch #157 - Loss: 0.7540267705917358\n",
      "Ep 51: Batch #158 - Loss: 0.799027681350708\n",
      "Ep 51: Batch #159 - Loss: 0.7995875477790833\n",
      "Ep 51: Batch #160 - Loss: 0.8959351181983948\n",
      "Ep 51: Batch #161 - Loss: 0.808144748210907\n",
      "Ep 51: Batch #162 - Loss: 0.923012375831604\n",
      "Ep 51: Batch #163 - Loss: 0.9223139882087708\n",
      "Ep 51: Batch #164 - Loss: 0.7768111824989319\n",
      "Ep 51: Batch #165 - Loss: 1.4897048473358154\n",
      "Ep 51: Batch #166 - Loss: 0.6716673970222473\n",
      "Ep 51: Batch #167 - Loss: 1.0772535800933838\n",
      "Ep 51: Batch #168 - Loss: 0.8515228629112244\n",
      "Ep 51: Batch #169 - Loss: 0.7934800386428833\n",
      "Ep 51: Batch #170 - Loss: 0.7957135438919067\n",
      "Ep 51: Batch #171 - Loss: 0.7717760801315308\n",
      "Ep 51: Batch #172 - Loss: 0.6279396414756775\n",
      "Ep 51: Batch #173 - Loss: 1.1836715936660767\n",
      "Ep 51: Batch #174 - Loss: 0.5731333494186401\n",
      "Ep 51: Batch #175 - Loss: 0.7719611525535583\n",
      "Ep 51: Batch #176 - Loss: 1.1437041759490967\n",
      "Ep 51: Batch #177 - Loss: 0.8399535417556763\n",
      "Ep 51: Batch #178 - Loss: 0.7548081278800964\n",
      "Ep 51: Batch #179 - Loss: 0.9292279481887817\n",
      "Ep 51: Batch #180 - Loss: 0.8448766469955444\n",
      "Ep 51: Batch #181 - Loss: 0.9806682467460632\n",
      "Ep 51: Batch #182 - Loss: 0.7580761909484863\n",
      "Ep 51: Batch #183 - Loss: 0.7566131949424744\n",
      "Ep 51: Batch #184 - Loss: 1.0605101585388184\n",
      "Ep 51: Batch #185 - Loss: 0.7507305145263672\n",
      "Ep 51: Batch #186 - Loss: 0.955947995185852\n",
      "Ep 51: Batch #187 - Loss: 1.1576836109161377\n",
      "Ep 51: Batch #188 - Loss: 1.3404290676116943\n",
      "Ep 51: Batch #189 - Loss: 0.6953416466712952\n",
      "Ep 51: Batch #190 - Loss: 0.7277526259422302\n",
      "Ep 51: Batch #191 - Loss: 1.0545258522033691\n",
      "Ep 51: Batch #192 - Loss: 0.6638193130493164\n",
      "Ep 51: Batch #193 - Loss: 0.7327647805213928\n",
      "Ep 51: Batch #194 - Loss: 0.6887862086296082\n",
      "Ep 51: Batch #195 - Loss: 0.9730464220046997\n",
      "Ep 51: Batch #196 - Loss: 0.8572055101394653\n",
      "Ep 51: Batch #197 - Loss: 0.8923421502113342\n",
      "Ep 51: Batch #198 - Loss: 0.6700708866119385\n",
      "Ep 51: Batch #199 - Loss: 0.8526816368103027\n",
      "Ep 52: Batch #0 - Loss: 0.7822532057762146\n",
      "Ep 52: Batch #1 - Loss: 0.8671673536300659\n",
      "Ep 52: Batch #2 - Loss: 0.9995012283325195\n",
      "Ep 52: Batch #3 - Loss: 0.856407642364502\n",
      "Ep 52: Batch #4 - Loss: 0.7798982262611389\n",
      "Ep 52: Batch #5 - Loss: 0.6619676351547241\n",
      "Ep 52: Batch #6 - Loss: 0.8699806928634644\n",
      "Ep 52: Batch #7 - Loss: 0.6946094036102295\n",
      "Ep 52: Batch #8 - Loss: 0.7265852093696594\n",
      "Ep 52: Batch #9 - Loss: 1.3862613439559937\n",
      "Ep 52: Batch #10 - Loss: 0.9966091513633728\n",
      "Ep 52: Batch #11 - Loss: 0.6630546450614929\n",
      "Ep 52: Batch #12 - Loss: 1.5486526489257812\n",
      "Ep 52: Batch #13 - Loss: 0.6424729228019714\n",
      "Ep 52: Batch #14 - Loss: 0.7199128866195679\n",
      "Ep 52: Batch #15 - Loss: 1.2273566722869873\n",
      "Ep 52: Batch #16 - Loss: 1.2621558904647827\n",
      "Ep 52: Batch #17 - Loss: 0.8705233335494995\n",
      "Ep 52: Batch #18 - Loss: 0.9352989792823792\n",
      "Ep 52: Batch #19 - Loss: 0.6614158749580383\n",
      "Ep 52: Batch #20 - Loss: 0.6474157571792603\n",
      "Ep 52: Batch #21 - Loss: 1.2025866508483887\n",
      "Ep 52: Batch #22 - Loss: 0.718903660774231\n",
      "Ep 52: Batch #23 - Loss: 0.7343060970306396\n",
      "Ep 52: Batch #24 - Loss: 0.8155596256256104\n",
      "Ep 52: Batch #25 - Loss: 0.7064456343650818\n",
      "Ep 52: Batch #26 - Loss: 0.7215182185173035\n",
      "Ep 52: Batch #27 - Loss: 1.339192271232605\n",
      "Ep 52: Batch #28 - Loss: 0.8586837649345398\n",
      "Ep 52: Batch #29 - Loss: 0.8820962905883789\n",
      "Ep 52: Batch #30 - Loss: 1.192172884941101\n",
      "Ep 52: Batch #31 - Loss: 0.667106568813324\n",
      "Ep 52: Batch #32 - Loss: 0.7386562824249268\n",
      "Ep 52: Batch #33 - Loss: 0.7993872761726379\n",
      "Ep 52: Batch #34 - Loss: 0.7755202054977417\n",
      "Ep 52: Batch #35 - Loss: 0.9371147155761719\n",
      "Ep 52: Batch #36 - Loss: 0.694617748260498\n",
      "Ep 52: Batch #37 - Loss: 1.130944848060608\n",
      "Ep 52: Batch #38 - Loss: 0.7358801960945129\n",
      "Ep 52: Batch #39 - Loss: 0.8123828172683716\n",
      "Ep 52: Batch #40 - Loss: 0.7653554081916809\n",
      "Ep 52: Batch #41 - Loss: 0.728193998336792\n",
      "Ep 52: Batch #42 - Loss: 0.7144956588745117\n",
      "Ep 52: Batch #43 - Loss: 0.7796444892883301\n",
      "Ep 52: Batch #44 - Loss: 0.7753548622131348\n",
      "Ep 52: Batch #45 - Loss: 0.6251448392868042\n",
      "Ep 52: Batch #46 - Loss: 0.8201963901519775\n",
      "Ep 52: Batch #47 - Loss: 0.9485718011856079\n",
      "Ep 52: Batch #48 - Loss: 1.3420383930206299\n",
      "Ep 52: Batch #49 - Loss: 1.0019959211349487\n",
      "Ep 52: Batch #50 - Loss: 0.6996403336524963\n",
      "Ep 52: Batch #51 - Loss: 0.982130229473114\n",
      "Ep 52: Batch #52 - Loss: 0.7868908047676086\n",
      "Ep 52: Batch #53 - Loss: 0.8130449652671814\n",
      "Ep 52: Batch #54 - Loss: 0.6977095007896423\n",
      "Ep 52: Batch #55 - Loss: 0.7423719167709351\n",
      "Ep 52: Batch #56 - Loss: 1.24880051612854\n",
      "Ep 52: Batch #57 - Loss: 0.8369160890579224\n",
      "Ep 52: Batch #58 - Loss: 0.9871302247047424\n",
      "Ep 52: Batch #59 - Loss: 0.674324095249176\n",
      "Ep 52: Batch #60 - Loss: 1.2998679876327515\n",
      "Ep 52: Batch #61 - Loss: 0.6292648911476135\n",
      "Ep 52: Batch #62 - Loss: 0.7133303880691528\n",
      "Ep 52: Batch #63 - Loss: 0.9914552569389343\n",
      "Ep 52: Batch #64 - Loss: 9.419954299926758\n",
      "Ep 52: Batch #65 - Loss: 0.6054349541664124\n",
      "Ep 52: Batch #66 - Loss: 0.7863531708717346\n",
      "Ep 52: Batch #67 - Loss: 0.9008110165596008\n",
      "Ep 52: Batch #68 - Loss: 0.8972216844558716\n",
      "Ep 52: Batch #69 - Loss: 0.7362977862358093\n",
      "Ep 52: Batch #70 - Loss: 0.7652642726898193\n",
      "Ep 52: Batch #71 - Loss: 0.6719502806663513\n",
      "Ep 52: Batch #72 - Loss: 0.8442919850349426\n",
      "Ep 52: Batch #73 - Loss: 0.8909862637519836\n",
      "Ep 52: Batch #74 - Loss: 0.7310925126075745\n",
      "Ep 52: Batch #75 - Loss: 0.7599825859069824\n",
      "Ep 52: Batch #76 - Loss: 1.0865801572799683\n",
      "Ep 52: Batch #77 - Loss: 0.725470781326294\n",
      "Ep 52: Batch #78 - Loss: 1.146478533744812\n",
      "Ep 52: Batch #79 - Loss: 0.6185019016265869\n",
      "Ep 52: Batch #80 - Loss: 0.8487276434898376\n",
      "Ep 52: Batch #81 - Loss: 1.6694592237472534\n",
      "Ep 52: Batch #82 - Loss: 0.8642300963401794\n",
      "Ep 52: Batch #83 - Loss: 1.727014422416687\n",
      "Ep 52: Batch #84 - Loss: 0.7054281234741211\n",
      "Ep 52: Batch #85 - Loss: 0.9648601412773132\n",
      "Ep 52: Batch #86 - Loss: 0.6992833018302917\n",
      "Ep 52: Batch #87 - Loss: 0.7044470906257629\n",
      "Ep 52: Batch #88 - Loss: 0.7918710112571716\n",
      "Ep 52: Batch #89 - Loss: 0.8768013715744019\n",
      "Ep 52: Batch #90 - Loss: 1.1402312517166138\n",
      "Ep 52: Batch #91 - Loss: 0.7914968132972717\n",
      "Ep 52: Batch #92 - Loss: 1.016750693321228\n",
      "Ep 52: Batch #93 - Loss: 1.015918254852295\n",
      "Ep 52: Batch #94 - Loss: 1.036908507347107\n",
      "Ep 52: Batch #95 - Loss: 0.9089612364768982\n",
      "Ep 52: Batch #96 - Loss: 0.8947029113769531\n",
      "Ep 52: Batch #97 - Loss: 0.7203362584114075\n",
      "Ep 52: Batch #98 - Loss: 0.7296150326728821\n",
      "Ep 52: Batch #99 - Loss: 0.9486537575721741\n",
      "Ep 52: Batch #100 - Loss: 0.6695151329040527\n",
      "Ep 52: Batch #101 - Loss: 1.0361961126327515\n",
      "Ep 52: Batch #102 - Loss: 0.7733555436134338\n",
      "Ep 52: Batch #103 - Loss: 0.781337559223175\n",
      "Ep 52: Batch #104 - Loss: 0.7918981313705444\n",
      "Ep 52: Batch #105 - Loss: 1.0161242485046387\n",
      "Ep 52: Batch #106 - Loss: 0.75041663646698\n",
      "Ep 52: Batch #107 - Loss: 0.7482055425643921\n",
      "Ep 52: Batch #108 - Loss: 1.0218271017074585\n",
      "Ep 52: Batch #109 - Loss: 0.7541283965110779\n",
      "Ep 52: Batch #110 - Loss: 0.9065081477165222\n",
      "Ep 52: Batch #111 - Loss: 1.3658143281936646\n",
      "Ep 52: Batch #112 - Loss: 1.0350375175476074\n",
      "Ep 52: Batch #113 - Loss: 0.806670069694519\n",
      "Ep 52: Batch #114 - Loss: 0.8920333981513977\n",
      "Ep 52: Batch #115 - Loss: 1.082177996635437\n",
      "Ep 52: Batch #116 - Loss: 0.6274423599243164\n",
      "Ep 52: Batch #117 - Loss: 0.8630073666572571\n",
      "Ep 52: Batch #118 - Loss: 0.5370038747787476\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved in file: ./weights_autoencoder_low_LR/model_e52b118_1516651275.7403514.ckpt\n",
      "Ep 52: Batch #119 - Loss: 1.0165313482284546\n",
      "Ep 52: Batch #120 - Loss: 0.7912091016769409\n",
      "Ep 52: Batch #121 - Loss: 0.6770715117454529\n",
      "Ep 52: Batch #122 - Loss: 0.815854012966156\n",
      "Ep 52: Batch #123 - Loss: 0.8222370147705078\n",
      "Ep 52: Batch #124 - Loss: 0.6564992666244507\n",
      "Ep 52: Batch #125 - Loss: 2.706617832183838\n",
      "Ep 52: Batch #126 - Loss: 1.2137192487716675\n",
      "Ep 52: Batch #127 - Loss: 0.7389314770698547\n",
      "Ep 52: Batch #128 - Loss: 1.0919466018676758\n",
      "Ep 52: Batch #129 - Loss: 0.8280981183052063\n",
      "Ep 52: Batch #130 - Loss: 0.7145576477050781\n",
      "Ep 52: Batch #131 - Loss: 0.9821585416793823\n",
      "Ep 52: Batch #132 - Loss: 0.8133239150047302\n",
      "Ep 52: Batch #133 - Loss: 0.8077934384346008\n",
      "Ep 52: Batch #134 - Loss: 0.759236216545105\n",
      "Ep 52: Batch #135 - Loss: 0.9539031982421875\n",
      "Ep 52: Batch #136 - Loss: 1.1679617166519165\n",
      "Ep 52: Batch #137 - Loss: 0.9529605507850647\n",
      "Ep 52: Batch #138 - Loss: 1.0586254596710205\n",
      "Ep 52: Batch #139 - Loss: 0.8892033100128174\n",
      "Ep 52: Batch #140 - Loss: 1.037290334701538\n",
      "Ep 52: Batch #141 - Loss: 1.3465226888656616\n",
      "Ep 52: Batch #142 - Loss: 0.7856298685073853\n",
      "Ep 52: Batch #143 - Loss: 0.9524971842765808\n",
      "Ep 52: Batch #144 - Loss: 0.7119653820991516\n",
      "Ep 52: Batch #145 - Loss: 0.6701990962028503\n",
      "Ep 52: Batch #146 - Loss: 0.874399721622467\n",
      "Ep 52: Batch #147 - Loss: 0.8499592542648315\n",
      "Ep 52: Batch #148 - Loss: 0.9655141830444336\n",
      "Ep 52: Batch #149 - Loss: 0.8430448174476624\n",
      "Ep 52: Batch #150 - Loss: 0.8730719685554504\n",
      "Ep 52: Batch #151 - Loss: 0.720441997051239\n",
      "Ep 52: Batch #152 - Loss: 0.7322034239768982\n",
      "Ep 52: Batch #153 - Loss: 1.0923651456832886\n",
      "Ep 52: Batch #154 - Loss: 0.7548173069953918\n",
      "Ep 52: Batch #155 - Loss: 0.8237611055374146\n",
      "Ep 52: Batch #156 - Loss: 1.006680965423584\n",
      "Ep 52: Batch #157 - Loss: 0.7528712749481201\n",
      "Ep 52: Batch #158 - Loss: 0.7981635332107544\n",
      "Ep 52: Batch #159 - Loss: 0.798326313495636\n",
      "Ep 52: Batch #160 - Loss: 0.8948761820793152\n",
      "Ep 52: Batch #161 - Loss: 0.806958019733429\n",
      "Ep 52: Batch #162 - Loss: 0.9217034578323364\n",
      "Ep 52: Batch #163 - Loss: 0.9212676286697388\n",
      "Ep 52: Batch #164 - Loss: 0.7756466865539551\n",
      "Ep 52: Batch #165 - Loss: 1.4884068965911865\n",
      "Ep 52: Batch #166 - Loss: 0.6705798506736755\n",
      "Ep 52: Batch #167 - Loss: 1.0758520364761353\n",
      "Ep 52: Batch #168 - Loss: 0.8502315282821655\n",
      "Ep 52: Batch #169 - Loss: 0.792343020439148\n",
      "Ep 52: Batch #170 - Loss: 0.794484555721283\n",
      "Ep 52: Batch #171 - Loss: 0.7704859375953674\n",
      "Ep 52: Batch #172 - Loss: 0.627100944519043\n",
      "Ep 52: Batch #173 - Loss: 1.1817866563796997\n",
      "Ep 52: Batch #174 - Loss: 0.572303295135498\n",
      "Ep 52: Batch #175 - Loss: 0.7710831165313721\n",
      "Ep 52: Batch #176 - Loss: 1.1417406797409058\n",
      "Ep 52: Batch #177 - Loss: 0.8387036919593811\n",
      "Ep 52: Batch #178 - Loss: 0.7536094784736633\n",
      "Ep 52: Batch #179 - Loss: 0.9277936220169067\n",
      "Ep 52: Batch #180 - Loss: 0.8433541059494019\n",
      "Ep 52: Batch #181 - Loss: 0.9790640473365784\n",
      "Ep 52: Batch #182 - Loss: 0.7571577429771423\n",
      "Ep 52: Batch #183 - Loss: 0.7554880976676941\n",
      "Ep 52: Batch #184 - Loss: 1.0594425201416016\n",
      "Ep 52: Batch #185 - Loss: 0.749607503414154\n",
      "Ep 52: Batch #186 - Loss: 0.9543293714523315\n",
      "Ep 52: Batch #187 - Loss: 1.1562711000442505\n",
      "Ep 52: Batch #188 - Loss: 1.339302659034729\n",
      "Ep 52: Batch #189 - Loss: 0.6944969296455383\n",
      "Ep 52: Batch #190 - Loss: 0.7267220616340637\n",
      "Ep 52: Batch #191 - Loss: 1.0530093908309937\n",
      "Ep 52: Batch #192 - Loss: 0.662979781627655\n",
      "Ep 52: Batch #193 - Loss: 0.7315842509269714\n",
      "Ep 52: Batch #194 - Loss: 0.6877127885818481\n",
      "Ep 52: Batch #195 - Loss: 0.971686601638794\n",
      "Ep 52: Batch #196 - Loss: 0.8560090065002441\n",
      "Ep 52: Batch #197 - Loss: 0.8909929990768433\n",
      "Ep 52: Batch #198 - Loss: 0.6689432859420776\n",
      "Ep 52: Batch #199 - Loss: 0.8513952493667603\n",
      "Ep 53: Batch #0 - Loss: 0.7809132933616638\n",
      "Ep 53: Batch #1 - Loss: 0.8658270835876465\n",
      "Ep 53: Batch #2 - Loss: 0.9983735680580139\n",
      "Ep 53: Batch #3 - Loss: 0.8553427457809448\n",
      "Ep 53: Batch #4 - Loss: 0.7786338925361633\n",
      "Ep 53: Batch #5 - Loss: 0.6610895991325378\n",
      "Ep 53: Batch #6 - Loss: 0.8687832355499268\n",
      "Ep 53: Batch #7 - Loss: 0.6936147212982178\n",
      "Ep 53: Batch #8 - Loss: 0.7255911231040955\n",
      "Ep 53: Batch #9 - Loss: 1.3843740224838257\n",
      "Ep 53: Batch #10 - Loss: 0.9953458309173584\n",
      "Ep 53: Batch #11 - Loss: 0.6621095538139343\n",
      "Ep 53: Batch #12 - Loss: 1.5471079349517822\n",
      "Ep 53: Batch #13 - Loss: 0.6417558193206787\n",
      "Ep 53: Batch #14 - Loss: 0.718977689743042\n",
      "Ep 53: Batch #15 - Loss: 1.2258508205413818\n",
      "Ep 53: Batch #16 - Loss: 1.2604060173034668\n",
      "Ep 53: Batch #17 - Loss: 0.8692168593406677\n",
      "Ep 53: Batch #18 - Loss: 0.9344143271446228\n",
      "Ep 53: Batch #19 - Loss: 0.6605505347251892\n",
      "Ep 53: Batch #20 - Loss: 0.6464518308639526\n",
      "Ep 53: Batch #21 - Loss: 1.201332449913025\n",
      "Ep 53: Batch #22 - Loss: 0.7180032730102539\n",
      "Ep 53: Batch #23 - Loss: 0.7331802845001221\n",
      "Ep 53: Batch #24 - Loss: 0.8145561218261719\n",
      "Ep 53: Batch #25 - Loss: 0.7053409814834595\n",
      "Ep 53: Batch #26 - Loss: 0.7202677726745605\n",
      "Ep 53: Batch #27 - Loss: 1.3374862670898438\n",
      "Ep 53: Batch #28 - Loss: 0.8575801849365234\n",
      "Ep 53: Batch #29 - Loss: 0.8807278275489807\n",
      "Ep 53: Batch #30 - Loss: 1.1910003423690796\n",
      "Ep 53: Batch #31 - Loss: 0.6662244200706482\n",
      "Ep 53: Batch #32 - Loss: 0.7374860048294067\n",
      "Ep 53: Batch #33 - Loss: 0.7983200550079346\n",
      "Ep 53: Batch #34 - Loss: 0.7744719982147217\n",
      "Ep 53: Batch #35 - Loss: 0.9356057643890381\n",
      "Ep 53: Batch #36 - Loss: 0.6935559511184692\n",
      "Ep 53: Batch #37 - Loss: 1.1296736001968384\n",
      "Ep 53: Batch #38 - Loss: 0.734635055065155\n",
      "Ep 53: Batch #39 - Loss: 0.8114482760429382\n",
      "Ep 53: Batch #40 - Loss: 0.7642219662666321\n",
      "Ep 53: Batch #41 - Loss: 0.7269073724746704\n",
      "Ep 53: Batch #42 - Loss: 0.7134447693824768\n",
      "Ep 53: Batch #43 - Loss: 0.7786043882369995\n",
      "Ep 53: Batch #44 - Loss: 0.7741402387619019\n",
      "Ep 53: Batch #45 - Loss: 0.6240448355674744\n",
      "Ep 53: Batch #46 - Loss: 0.8188008069992065\n",
      "Ep 53: Batch #47 - Loss: 0.9469428062438965\n",
      "Ep 53: Batch #48 - Loss: 1.34052574634552\n",
      "Ep 53: Batch #49 - Loss: 1.0002319812774658\n",
      "Ep 53: Batch #50 - Loss: 0.6988294124603271\n",
      "Ep 53: Batch #51 - Loss: 0.9804898500442505\n",
      "Ep 53: Batch #52 - Loss: 0.7858695983886719\n",
      "Ep 53: Batch #53 - Loss: 0.8118467330932617\n",
      "Ep 53: Batch #54 - Loss: 0.6967268586158752\n",
      "Ep 53: Batch #55 - Loss: 0.7411972284317017\n",
      "Ep 53: Batch #56 - Loss: 1.2471373081207275\n",
      "Ep 53: Batch #57 - Loss: 0.835564374923706\n",
      "Ep 53: Batch #58 - Loss: 0.9854832291603088\n",
      "Ep 53: Batch #59 - Loss: 0.6735062003135681\n",
      "Ep 53: Batch #60 - Loss: 1.2985820770263672\n",
      "Ep 53: Batch #61 - Loss: 0.6283730268478394\n",
      "Ep 53: Batch #62 - Loss: 0.7121501564979553\n",
      "Ep 53: Batch #63 - Loss: 0.9900683760643005\n",
      "Ep 53: Batch #64 - Loss: 9.418846130371094\n",
      "Ep 53: Batch #65 - Loss: 0.6045581698417664\n",
      "Ep 53: Batch #66 - Loss: 0.7850757837295532\n",
      "Ep 53: Batch #67 - Loss: 0.8994939923286438\n",
      "Ep 53: Batch #68 - Loss: 0.8958200216293335\n",
      "Ep 53: Batch #69 - Loss: 0.7352026104927063\n",
      "Ep 53: Batch #70 - Loss: 0.7638968229293823\n",
      "Ep 53: Batch #71 - Loss: 0.671049952507019\n",
      "Ep 53: Batch #72 - Loss: 0.8430382013320923\n",
      "Ep 53: Batch #73 - Loss: 0.8894086480140686\n",
      "Ep 53: Batch #74 - Loss: 0.7298538088798523\n",
      "Ep 53: Batch #75 - Loss: 0.758967936038971\n",
      "Ep 53: Batch #76 - Loss: 1.0854302644729614\n",
      "Ep 53: Batch #77 - Loss: 0.7243105173110962\n",
      "Ep 53: Batch #78 - Loss: 1.1447418928146362\n",
      "Ep 53: Batch #79 - Loss: 0.6175615787506104\n",
      "Ep 53: Batch #80 - Loss: 0.8473529815673828\n",
      "Ep 53: Batch #81 - Loss: 1.6681674718856812\n",
      "Ep 53: Batch #82 - Loss: 0.8630883693695068\n",
      "Ep 53: Batch #83 - Loss: 1.7260732650756836\n",
      "Ep 53: Batch #84 - Loss: 0.704298198223114\n",
      "Ep 53: Batch #85 - Loss: 0.9638120532035828\n",
      "Ep 53: Batch #86 - Loss: 0.6980615258216858\n",
      "Ep 53: Batch #87 - Loss: 0.7033507227897644\n",
      "Ep 53: Batch #88 - Loss: 0.7906067967414856\n",
      "Ep 53: Batch #89 - Loss: 0.876011848449707\n",
      "Ep 53: Batch #90 - Loss: 1.1384884119033813\n",
      "Ep 53: Batch #91 - Loss: 0.7901508808135986\n",
      "Ep 53: Batch #92 - Loss: 1.0153026580810547\n",
      "Ep 53: Batch #93 - Loss: 1.0141805410385132\n",
      "Ep 53: Batch #94 - Loss: 1.03536057472229\n",
      "Ep 53: Batch #95 - Loss: 0.9076555967330933\n",
      "Ep 53: Batch #96 - Loss: 0.8934784531593323\n",
      "Ep 53: Batch #97 - Loss: 0.7191853523254395\n",
      "Ep 53: Batch #98 - Loss: 0.7284680604934692\n",
      "Ep 53: Batch #99 - Loss: 0.9473912119865417\n",
      "Ep 53: Batch #100 - Loss: 0.6684425473213196\n",
      "Ep 53: Batch #101 - Loss: 1.0349082946777344\n",
      "Ep 53: Batch #102 - Loss: 0.7722153663635254\n",
      "Ep 53: Batch #103 - Loss: 0.7802019119262695\n",
      "Ep 53: Batch #104 - Loss: 0.7907388806343079\n",
      "Ep 53: Batch #105 - Loss: 1.0145704746246338\n",
      "Ep 53: Batch #106 - Loss: 0.7493678331375122\n",
      "Ep 53: Batch #107 - Loss: 0.7470345497131348\n",
      "Ep 53: Batch #108 - Loss: 1.0203728675842285\n",
      "Ep 53: Batch #109 - Loss: 0.7530948519706726\n",
      "Ep 53: Batch #110 - Loss: 0.9049537181854248\n",
      "Ep 53: Batch #111 - Loss: 1.36412513256073\n",
      "Ep 53: Batch #112 - Loss: 1.0336015224456787\n",
      "Ep 53: Batch #113 - Loss: 0.8054682612419128\n",
      "Ep 53: Batch #114 - Loss: 0.8906466364860535\n",
      "Ep 53: Batch #115 - Loss: 1.080741286277771\n",
      "Ep 53: Batch #116 - Loss: 0.6267456412315369\n",
      "Ep 53: Batch #117 - Loss: 0.8618891835212708\n",
      "Ep 53: Batch #118 - Loss: 0.5361225605010986\n",
      "Model saved in file: ./weights_autoencoder_low_LR/model_e53b118_1516651275.8786552.ckpt\n",
      "Ep 53: Batch #119 - Loss: 1.0152839422225952\n",
      "Ep 53: Batch #120 - Loss: 0.7901083827018738\n",
      "Ep 53: Batch #121 - Loss: 0.6759973764419556\n",
      "Ep 53: Batch #122 - Loss: 0.8147550821304321\n",
      "Ep 53: Batch #123 - Loss: 0.8210510015487671\n",
      "Ep 53: Batch #124 - Loss: 0.6556688547134399\n",
      "Ep 53: Batch #125 - Loss: 2.704707145690918\n",
      "Ep 53: Batch #126 - Loss: 1.2123615741729736\n",
      "Ep 53: Batch #127 - Loss: 0.7376738786697388\n",
      "Ep 53: Batch #128 - Loss: 1.0902094841003418\n",
      "Ep 53: Batch #129 - Loss: 0.8267866373062134\n",
      "Ep 53: Batch #130 - Loss: 0.7134732007980347\n",
      "Ep 53: Batch #131 - Loss: 0.9805062413215637\n",
      "Ep 53: Batch #132 - Loss: 0.8120357990264893\n",
      "Ep 53: Batch #133 - Loss: 0.8065723180770874\n",
      "Ep 53: Batch #134 - Loss: 0.7580297589302063\n",
      "Ep 53: Batch #135 - Loss: 0.9523401260375977\n",
      "Ep 53: Batch #136 - Loss: 1.1663283109664917\n",
      "Ep 53: Batch #137 - Loss: 0.9514909386634827\n",
      "Ep 53: Batch #138 - Loss: 1.0571837425231934\n",
      "Ep 53: Batch #139 - Loss: 0.8877869248390198\n",
      "Ep 53: Batch #140 - Loss: 1.0358785390853882\n",
      "Ep 53: Batch #141 - Loss: 1.3450722694396973\n",
      "Ep 53: Batch #142 - Loss: 0.7844659090042114\n",
      "Ep 53: Batch #143 - Loss: 0.9508731365203857\n",
      "Ep 53: Batch #144 - Loss: 0.710936963558197\n",
      "Ep 53: Batch #145 - Loss: 0.669259786605835\n",
      "Ep 53: Batch #146 - Loss: 0.8732549548149109\n",
      "Ep 53: Batch #147 - Loss: 0.8484828472137451\n",
      "Ep 53: Batch #148 - Loss: 0.9639484882354736\n",
      "Ep 53: Batch #149 - Loss: 0.8416560888290405\n",
      "Ep 53: Batch #150 - Loss: 0.8718150854110718\n",
      "Ep 53: Batch #151 - Loss: 0.7196444869041443\n",
      "Ep 53: Batch #152 - Loss: 0.7313445806503296\n",
      "Ep 53: Batch #153 - Loss: 1.0907645225524902\n",
      "Ep 53: Batch #154 - Loss: 0.7536881566047668\n",
      "Ep 53: Batch #155 - Loss: 0.822623074054718\n",
      "Ep 53: Batch #156 - Loss: 1.005323052406311\n",
      "Ep 53: Batch #157 - Loss: 0.7517203092575073\n",
      "Ep 53: Batch #158 - Loss: 0.7973071932792664\n",
      "Ep 53: Batch #159 - Loss: 0.7970415949821472\n",
      "Ep 53: Batch #160 - Loss: 0.8938295245170593\n",
      "Ep 53: Batch #161 - Loss: 0.8057730793952942\n",
      "Ep 53: Batch #162 - Loss: 0.9204086065292358\n",
      "Ep 53: Batch #163 - Loss: 0.9202277660369873\n",
      "Ep 53: Batch #164 - Loss: 0.7744976878166199\n",
      "Ep 53: Batch #165 - Loss: 1.4871448278427124\n",
      "Ep 53: Batch #166 - Loss: 0.6695087552070618\n",
      "Ep 53: Batch #167 - Loss: 1.074461579322815\n",
      "Ep 53: Batch #168 - Loss: 0.8489475250244141\n",
      "Ep 53: Batch #169 - Loss: 0.7912214994430542\n",
      "Ep 53: Batch #170 - Loss: 0.793279230594635\n",
      "Ep 53: Batch #171 - Loss: 0.769196093082428\n",
      "Ep 53: Batch #172 - Loss: 0.6262755393981934\n",
      "Ep 53: Batch #173 - Loss: 1.1799067258834839\n",
      "Ep 53: Batch #174 - Loss: 0.5714828968048096\n",
      "Ep 53: Batch #175 - Loss: 0.7702175974845886\n",
      "Ep 53: Batch #176 - Loss: 1.1397836208343506\n",
      "Ep 53: Batch #177 - Loss: 0.8374621272087097\n",
      "Ep 53: Batch #178 - Loss: 0.7524322867393494\n",
      "Ep 53: Batch #179 - Loss: 0.9263781905174255\n",
      "Ep 53: Batch #180 - Loss: 0.8418486714363098\n",
      "Ep 53: Batch #181 - Loss: 0.9774813055992126\n",
      "Ep 53: Batch #182 - Loss: 0.7562509179115295\n",
      "Ep 53: Batch #183 - Loss: 0.7543849945068359\n",
      "Ep 53: Batch #184 - Loss: 1.0583668947219849\n",
      "Ep 53: Batch #185 - Loss: 0.7484930157661438\n",
      "Ep 53: Batch #186 - Loss: 0.95273357629776\n",
      "Ep 53: Batch #187 - Loss: 1.1548103094100952\n",
      "Ep 53: Batch #188 - Loss: 1.3381577730178833\n",
      "Ep 53: Batch #189 - Loss: 0.693673312664032\n",
      "Ep 53: Batch #190 - Loss: 0.7257057428359985\n",
      "Ep 53: Batch #191 - Loss: 1.0514757633209229\n",
      "Ep 53: Batch #192 - Loss: 0.6621466875076294\n",
      "Ep 53: Batch #193 - Loss: 0.7304081320762634\n",
      "Ep 53: Batch #194 - Loss: 0.6866453289985657\n",
      "Ep 53: Batch #195 - Loss: 0.970339298248291\n",
      "Ep 53: Batch #196 - Loss: 0.8547986745834351\n",
      "Ep 53: Batch #197 - Loss: 0.8896356225013733\n",
      "Ep 53: Batch #198 - Loss: 0.6678295135498047\n",
      "Ep 53: Batch #199 - Loss: 0.8501206636428833\n",
      "Ep 54: Batch #0 - Loss: 0.7795904874801636\n",
      "Ep 54: Batch #1 - Loss: 0.8645009994506836\n",
      "Ep 54: Batch #2 - Loss: 0.9972604513168335\n",
      "Ep 54: Batch #3 - Loss: 0.8542863130569458\n",
      "Ep 54: Batch #4 - Loss: 0.7773875594139099\n",
      "Ep 54: Batch #5 - Loss: 0.6601881980895996\n",
      "Ep 54: Batch #6 - Loss: 0.8675883412361145\n",
      "Ep 54: Batch #7 - Loss: 0.6926164627075195\n",
      "Ep 54: Batch #8 - Loss: 0.7246019840240479\n",
      "Ep 54: Batch #9 - Loss: 1.3825021982192993\n",
      "Ep 54: Batch #10 - Loss: 0.9940959215164185\n",
      "Ep 54: Batch #11 - Loss: 0.6611710786819458\n",
      "Ep 54: Batch #12 - Loss: 1.5455777645111084\n",
      "Ep 54: Batch #13 - Loss: 0.6410458087921143\n",
      "Ep 54: Batch #14 - Loss: 0.718052089214325\n",
      "Ep 54: Batch #15 - Loss: 1.2243125438690186\n",
      "Ep 54: Batch #16 - Loss: 1.2586766481399536\n",
      "Ep 54: Batch #17 - Loss: 0.8679205775260925\n",
      "Ep 54: Batch #18 - Loss: 0.9335571527481079\n",
      "Ep 54: Batch #19 - Loss: 0.659697413444519\n",
      "Ep 54: Batch #20 - Loss: 0.6454941630363464\n",
      "Ep 54: Batch #21 - Loss: 1.200085997581482\n",
      "Ep 54: Batch #22 - Loss: 0.7171168327331543\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 54: Batch #23 - Loss: 0.7320701479911804\n",
      "Ep 54: Batch #24 - Loss: 0.8135631680488586\n",
      "Ep 54: Batch #25 - Loss: 0.7042425274848938\n",
      "Ep 54: Batch #26 - Loss: 0.719027042388916\n",
      "Ep 54: Batch #27 - Loss: 1.3357959985733032\n",
      "Ep 54: Batch #28 - Loss: 0.8564958572387695\n",
      "Ep 54: Batch #29 - Loss: 0.8793697953224182\n",
      "Ep 54: Batch #30 - Loss: 1.1898369789123535\n",
      "Ep 54: Batch #31 - Loss: 0.6653427481651306\n",
      "Ep 54: Batch #32 - Loss: 0.7363251447677612\n",
      "Ep 54: Batch #33 - Loss: 0.7972502112388611\n",
      "Ep 54: Batch #34 - Loss: 0.7734372019767761\n",
      "Ep 54: Batch #35 - Loss: 0.9340952634811401\n",
      "Ep 54: Batch #36 - Loss: 0.692503809928894\n",
      "Ep 54: Batch #37 - Loss: 1.1284140348434448\n",
      "Ep 54: Batch #38 - Loss: 0.7333787679672241\n",
      "Ep 54: Batch #39 - Loss: 0.8105202317237854\n",
      "Ep 54: Batch #40 - Loss: 0.7630999684333801\n",
      "Ep 54: Batch #41 - Loss: 0.7256116271018982\n",
      "Ep 54: Batch #42 - Loss: 0.7124121189117432\n",
      "Ep 54: Batch #43 - Loss: 0.7775748372077942\n",
      "Ep 54: Batch #44 - Loss: 0.7729331254959106\n",
      "Ep 54: Batch #45 - Loss: 0.6229545474052429\n",
      "Ep 54: Batch #46 - Loss: 0.8174209594726562\n",
      "Ep 54: Batch #47 - Loss: 0.9453205466270447\n",
      "Ep 54: Batch #48 - Loss: 1.3390285968780518\n",
      "Ep 54: Batch #49 - Loss: 0.9984868168830872\n",
      "Ep 54: Batch #50 - Loss: 0.6980205774307251\n",
      "Ep 54: Batch #51 - Loss: 0.978866696357727\n",
      "Ep 54: Batch #52 - Loss: 0.7848496437072754\n",
      "Ep 54: Batch #53 - Loss: 0.8106560111045837\n",
      "Ep 54: Batch #54 - Loss: 0.6957488059997559\n",
      "Ep 54: Batch #55 - Loss: 0.7400323748588562\n",
      "Ep 54: Batch #56 - Loss: 1.2454556226730347\n",
      "Ep 54: Batch #57 - Loss: 0.8342080116271973\n",
      "Ep 54: Batch #58 - Loss: 0.9838384985923767\n",
      "Ep 54: Batch #59 - Loss: 0.6727005839347839\n",
      "Ep 54: Batch #60 - Loss: 1.2973204851150513\n",
      "Ep 54: Batch #61 - Loss: 0.6274909973144531\n",
      "Ep 54: Batch #62 - Loss: 0.7109735608100891\n",
      "Ep 54: Batch #63 - Loss: 0.9886813759803772\n",
      "Ep 54: Batch #64 - Loss: 9.417753219604492\n",
      "Ep 54: Batch #65 - Loss: 0.6036846041679382\n",
      "Ep 54: Batch #66 - Loss: 0.783806562423706\n",
      "Ep 54: Batch #67 - Loss: 0.8981755375862122\n",
      "Ep 54: Batch #68 - Loss: 0.8944236636161804\n",
      "Ep 54: Batch #69 - Loss: 0.7341195344924927\n",
      "Ep 54: Batch #70 - Loss: 0.7625458240509033\n",
      "Ep 54: Batch #71 - Loss: 0.6701628565788269\n",
      "Ep 54: Batch #72 - Loss: 0.8417921662330627\n",
      "Ep 54: Batch #73 - Loss: 0.8878538608551025\n",
      "Ep 54: Batch #74 - Loss: 0.7286275625228882\n",
      "Ep 54: Batch #75 - Loss: 0.7579600214958191\n",
      "Ep 54: Batch #76 - Loss: 1.084281086921692\n",
      "Ep 54: Batch #77 - Loss: 0.7231629490852356\n",
      "Ep 54: Batch #78 - Loss: 1.143000602722168\n",
      "Ep 54: Batch #79 - Loss: 0.6166057586669922\n",
      "Ep 54: Batch #80 - Loss: 0.8459463119506836\n",
      "Ep 54: Batch #81 - Loss: 1.66688871383667\n",
      "Ep 54: Batch #82 - Loss: 0.8619400262832642\n",
      "Ep 54: Batch #83 - Loss: 1.7251355648040771\n",
      "Ep 54: Batch #84 - Loss: 0.7031828761100769\n",
      "Ep 54: Batch #85 - Loss: 0.9627688527107239\n",
      "Ep 54: Batch #86 - Loss: 0.6968511939048767\n",
      "Ep 54: Batch #87 - Loss: 0.7022650837898254\n",
      "Ep 54: Batch #88 - Loss: 0.7893565893173218\n",
      "Ep 54: Batch #89 - Loss: 0.875228762626648\n",
      "Ep 54: Batch #90 - Loss: 1.1367676258087158\n",
      "Ep 54: Batch #91 - Loss: 0.7888092994689941\n",
      "Ep 54: Batch #92 - Loss: 1.0138661861419678\n",
      "Ep 54: Batch #93 - Loss: 1.012447714805603\n",
      "Ep 54: Batch #94 - Loss: 1.033825397491455\n",
      "Ep 54: Batch #95 - Loss: 0.9063649773597717\n",
      "Ep 54: Batch #96 - Loss: 0.8922631144523621\n",
      "Ep 54: Batch #97 - Loss: 0.718041181564331\n",
      "Ep 54: Batch #98 - Loss: 0.7273350954055786\n",
      "Ep 54: Batch #99 - Loss: 0.9461154937744141\n",
      "Ep 54: Batch #100 - Loss: 0.6673774719238281\n",
      "Ep 54: Batch #101 - Loss: 1.0336359739303589\n",
      "Ep 54: Batch #102 - Loss: 0.7710857391357422\n",
      "Ep 54: Batch #103 - Loss: 0.7790746092796326\n",
      "Ep 54: Batch #104 - Loss: 0.7895958423614502\n",
      "Ep 54: Batch #105 - Loss: 1.0130199193954468\n",
      "Ep 54: Batch #106 - Loss: 0.7483300566673279\n",
      "Ep 54: Batch #107 - Loss: 0.7458739280700684\n",
      "Ep 54: Batch #108 - Loss: 1.0189321041107178\n",
      "Ep 54: Batch #109 - Loss: 0.7520827651023865\n",
      "Ep 54: Batch #110 - Loss: 0.9034093022346497\n",
      "Ep 54: Batch #111 - Loss: 1.362444519996643\n",
      "Ep 54: Batch #112 - Loss: 1.032177448272705\n",
      "Ep 54: Batch #113 - Loss: 0.8042781352996826\n",
      "Ep 54: Batch #114 - Loss: 0.8892685174942017\n",
      "Ep 54: Batch #115 - Loss: 1.0793061256408691\n",
      "Ep 54: Batch #116 - Loss: 0.6260530352592468\n",
      "Ep 54: Batch #117 - Loss: 0.8607823252677917\n",
      "Ep 54: Batch #118 - Loss: 0.5352462530136108\n",
      "Model saved in file: ./weights_autoencoder_low_LR/model_e54b118_1516651276.0166152.ckpt\n",
      "Ep 54: Batch #119 - Loss: 1.014041543006897\n",
      "Ep 54: Batch #120 - Loss: 0.7890176177024841\n",
      "Ep 54: Batch #121 - Loss: 0.6749311685562134\n",
      "Ep 54: Batch #122 - Loss: 0.8136715888977051\n",
      "Ep 54: Batch #123 - Loss: 0.8198751211166382\n",
      "Ep 54: Batch #124 - Loss: 0.654845118522644\n",
      "Ep 54: Batch #125 - Loss: 2.7028579711914062\n",
      "Ep 54: Batch #126 - Loss: 1.2110151052474976\n",
      "Ep 54: Batch #127 - Loss: 0.7364268898963928\n",
      "Ep 54: Batch #128 - Loss: 1.0884754657745361\n",
      "Ep 54: Batch #129 - Loss: 0.8254876732826233\n",
      "Ep 54: Batch #130 - Loss: 0.7123982310295105\n",
      "Ep 54: Batch #131 - Loss: 0.9788646101951599\n",
      "Ep 54: Batch #132 - Loss: 0.8107588887214661\n",
      "Ep 54: Batch #133 - Loss: 0.8053581714630127\n",
      "Ep 54: Batch #134 - Loss: 0.7568318247795105\n",
      "Ep 54: Batch #135 - Loss: 0.9507726430892944\n",
      "Ep 54: Batch #136 - Loss: 1.1646857261657715\n",
      "Ep 54: Batch #137 - Loss: 0.950035810470581\n",
      "Ep 54: Batch #138 - Loss: 1.0557529926300049\n",
      "Ep 54: Batch #139 - Loss: 0.886381983757019\n",
      "Ep 54: Batch #140 - Loss: 1.0344847440719604\n",
      "Ep 54: Batch #141 - Loss: 1.3436040878295898\n",
      "Ep 54: Batch #142 - Loss: 0.7833144068717957\n",
      "Ep 54: Batch #143 - Loss: 0.949260413646698\n",
      "Ep 54: Batch #144 - Loss: 0.7099259495735168\n",
      "Ep 54: Batch #145 - Loss: 0.668331503868103\n",
      "Ep 54: Batch #146 - Loss: 0.8721190094947815\n",
      "Ep 54: Batch #147 - Loss: 0.8470263481140137\n",
      "Ep 54: Batch #148 - Loss: 0.9623874425888062\n",
      "Ep 54: Batch #149 - Loss: 0.8402823209762573\n",
      "Ep 54: Batch #150 - Loss: 0.8705500960350037\n",
      "Ep 54: Batch #151 - Loss: 0.7188489437103271\n",
      "Ep 54: Batch #152 - Loss: 0.7304885983467102\n",
      "Ep 54: Batch #153 - Loss: 1.0891730785369873\n",
      "Ep 54: Batch #154 - Loss: 0.7525649666786194\n",
      "Ep 54: Batch #155 - Loss: 0.8214991688728333\n",
      "Ep 54: Batch #156 - Loss: 1.0039806365966797\n",
      "Ep 54: Batch #157 - Loss: 0.7505671977996826\n",
      "Ep 54: Batch #158 - Loss: 0.796457052230835\n",
      "Ep 54: Batch #159 - Loss: 0.7957481741905212\n",
      "Ep 54: Batch #160 - Loss: 0.8927923440933228\n",
      "Ep 54: Batch #161 - Loss: 0.8045786023139954\n",
      "Ep 54: Batch #162 - Loss: 0.9191272258758545\n",
      "Ep 54: Batch #163 - Loss: 0.9191951155662537\n",
      "Ep 54: Batch #164 - Loss: 0.7733553647994995\n",
      "Ep 54: Batch #165 - Loss: 1.4859169721603394\n",
      "Ep 54: Batch #166 - Loss: 0.6684388518333435\n",
      "Ep 54: Batch #167 - Loss: 1.0730739831924438\n",
      "Ep 54: Batch #168 - Loss: 0.847679853439331\n",
      "Ep 54: Batch #169 - Loss: 0.7901110649108887\n",
      "Ep 54: Batch #170 - Loss: 0.7920909523963928\n",
      "Ep 54: Batch #171 - Loss: 0.7679011225700378\n",
      "Ep 54: Batch #172 - Loss: 0.6254605650901794\n",
      "Ep 54: Batch #173 - Loss: 1.178026556968689\n",
      "Ep 54: Batch #174 - Loss: 0.5706685781478882\n",
      "Ep 54: Batch #175 - Loss: 0.769339382648468\n",
      "Ep 54: Batch #176 - Loss: 1.137851595878601\n",
      "Ep 54: Batch #177 - Loss: 0.836222767829895\n",
      "Ep 54: Batch #178 - Loss: 0.7512751817703247\n",
      "Ep 54: Batch #179 - Loss: 0.9249833226203918\n",
      "Ep 54: Batch #180 - Loss: 0.8403604626655579\n",
      "Ep 54: Batch #181 - Loss: 0.9759138226509094\n",
      "Ep 54: Batch #182 - Loss: 0.755355179309845\n",
      "Ep 54: Batch #183 - Loss: 0.7533007860183716\n",
      "Ep 54: Batch #184 - Loss: 1.0572969913482666\n",
      "Ep 54: Batch #185 - Loss: 0.7473793625831604\n",
      "Ep 54: Batch #186 - Loss: 0.9511562585830688\n",
      "Ep 54: Batch #187 - Loss: 1.1532398462295532\n",
      "Ep 54: Batch #188 - Loss: 1.3370167016983032\n",
      "Ep 54: Batch #189 - Loss: 0.6928609609603882\n",
      "Ep 54: Batch #190 - Loss: 0.7247030735015869\n",
      "Ep 54: Batch #191 - Loss: 1.0499383211135864\n",
      "Ep 54: Batch #192 - Loss: 0.6613229513168335\n",
      "Ep 54: Batch #193 - Loss: 0.7292463183403015\n",
      "Ep 54: Batch #194 - Loss: 0.6855860948562622\n",
      "Ep 54: Batch #195 - Loss: 0.9690049290657043\n",
      "Ep 54: Batch #196 - Loss: 0.853563666343689\n",
      "Ep 54: Batch #197 - Loss: 0.8882912397384644\n",
      "Ep 54: Batch #198 - Loss: 0.6667281985282898\n",
      "Ep 54: Batch #199 - Loss: 0.8488625288009644\n",
      "Ep 55: Batch #0 - Loss: 0.7782720923423767\n",
      "Ep 55: Batch #1 - Loss: 0.8631913661956787\n",
      "Ep 55: Batch #2 - Loss: 0.9961655735969543\n",
      "Ep 55: Batch #3 - Loss: 0.8532395362854004\n",
      "Ep 55: Batch #4 - Loss: 0.7761529684066772\n",
      "Ep 55: Batch #5 - Loss: 0.6592773199081421\n",
      "Ep 55: Batch #6 - Loss: 0.8663914203643799\n",
      "Ep 55: Batch #7 - Loss: 0.6916207671165466\n",
      "Ep 55: Batch #8 - Loss: 0.7236238121986389\n",
      "Ep 55: Batch #9 - Loss: 1.3806445598602295\n",
      "Ep 55: Batch #10 - Loss: 0.9928617477416992\n",
      "Ep 55: Batch #11 - Loss: 0.6602380871772766\n",
      "Ep 55: Batch #12 - Loss: 1.5440665483474731\n",
      "Ep 55: Batch #13 - Loss: 0.6403447389602661\n",
      "Ep 55: Batch #14 - Loss: 0.7171329259872437\n",
      "Ep 55: Batch #15 - Loss: 1.2227009534835815\n",
      "Ep 55: Batch #16 - Loss: 1.2569557428359985\n",
      "Ep 55: Batch #17 - Loss: 0.8666319847106934\n",
      "Ep 55: Batch #18 - Loss: 0.9327211380004883\n",
      "Ep 55: Batch #19 - Loss: 0.658856213092804\n",
      "Ep 55: Batch #20 - Loss: 0.6445395946502686\n",
      "Ep 55: Batch #21 - Loss: 1.1988551616668701\n",
      "Ep 55: Batch #22 - Loss: 0.7162355184555054\n",
      "Ep 55: Batch #23 - Loss: 0.7309689521789551\n",
      "Ep 55: Batch #24 - Loss: 0.8125801086425781\n",
      "Ep 55: Batch #25 - Loss: 0.7031627893447876\n",
      "Ep 55: Batch #26 - Loss: 0.7178018689155579\n",
      "Ep 55: Batch #27 - Loss: 1.3341072797775269\n",
      "Ep 55: Batch #28 - Loss: 0.8554385304450989\n",
      "Ep 55: Batch #29 - Loss: 0.8780199289321899\n",
      "Ep 55: Batch #30 - Loss: 1.1883771419525146\n",
      "Ep 55: Batch #31 - Loss: 0.6644559502601624\n",
      "Ep 55: Batch #32 - Loss: 0.7351779341697693\n",
      "Ep 55: Batch #33 - Loss: 0.7961851954460144\n",
      "Ep 55: Batch #34 - Loss: 0.7724170088768005\n",
      "Ep 55: Batch #35 - Loss: 0.9325827956199646\n",
      "Ep 55: Batch #36 - Loss: 0.6914520263671875\n",
      "Ep 55: Batch #37 - Loss: 1.1271611452102661\n",
      "Ep 55: Batch #38 - Loss: 0.7321256995201111\n",
      "Ep 55: Batch #39 - Loss: 0.8096238374710083\n",
      "Ep 55: Batch #40 - Loss: 0.7619827389717102\n",
      "Ep 55: Batch #41 - Loss: 0.7243214249610901\n",
      "Ep 55: Batch #42 - Loss: 0.7113887667655945\n",
      "Ep 55: Batch #43 - Loss: 0.7765563726425171\n",
      "Ep 55: Batch #44 - Loss: 0.7717193961143494\n",
      "Ep 55: Batch #45 - Loss: 0.6218695044517517\n",
      "Ep 55: Batch #46 - Loss: 0.816058337688446\n",
      "Ep 55: Batch #47 - Loss: 0.943699300289154\n",
      "Ep 55: Batch #48 - Loss: 1.3375433683395386\n",
      "Ep 55: Batch #49 - Loss: 0.9967555999755859\n",
      "Ep 55: Batch #50 - Loss: 0.6972114443778992\n",
      "Ep 55: Batch #51 - Loss: 0.9772559404373169\n",
      "Ep 55: Batch #52 - Loss: 0.7838329076766968\n",
      "Ep 55: Batch #53 - Loss: 0.809471845626831\n",
      "Ep 55: Batch #54 - Loss: 0.6947746872901917\n",
      "Ep 55: Batch #55 - Loss: 0.738884687423706\n",
      "Ep 55: Batch #56 - Loss: 1.2436801195144653\n",
      "Ep 55: Batch #57 - Loss: 0.8328619599342346\n",
      "Ep 55: Batch #58 - Loss: 0.9821728467941284\n",
      "Ep 55: Batch #59 - Loss: 0.6719069480895996\n",
      "Ep 55: Batch #60 - Loss: 1.295871376991272\n",
      "Ep 55: Batch #61 - Loss: 0.6266123056411743\n",
      "Ep 55: Batch #62 - Loss: 0.7098147869110107\n",
      "Ep 55: Batch #63 - Loss: 0.987311601638794\n",
      "Ep 55: Batch #64 - Loss: 9.416671752929688\n",
      "Ep 55: Batch #65 - Loss: 0.6028202176094055\n",
      "Ep 55: Batch #66 - Loss: 0.7825464606285095\n",
      "Ep 55: Batch #67 - Loss: 0.8968572616577148\n",
      "Ep 55: Batch #68 - Loss: 0.8930221199989319\n",
      "Ep 55: Batch #69 - Loss: 0.7330554723739624\n",
      "Ep 55: Batch #70 - Loss: 0.7612102031707764\n",
      "Ep 55: Batch #71 - Loss: 0.6692811250686646\n",
      "Ep 55: Batch #72 - Loss: 0.8405595421791077\n",
      "Ep 55: Batch #73 - Loss: 0.8863190412521362\n",
      "Ep 55: Batch #74 - Loss: 0.7273890972137451\n",
      "Ep 55: Batch #75 - Loss: 0.7569611668586731\n",
      "Ep 55: Batch #76 - Loss: 1.0831347703933716\n",
      "Ep 55: Batch #77 - Loss: 0.7220213413238525\n",
      "Ep 55: Batch #78 - Loss: 1.1412537097930908\n",
      "Ep 55: Batch #79 - Loss: 0.6156451106071472\n",
      "Ep 55: Batch #80 - Loss: 0.8445496559143066\n",
      "Ep 55: Batch #81 - Loss: 1.6656224727630615\n",
      "Ep 55: Batch #82 - Loss: 0.8607898950576782\n",
      "Ep 55: Batch #83 - Loss: 1.7242094278335571\n",
      "Ep 55: Batch #84 - Loss: 0.7020817995071411\n",
      "Ep 55: Batch #85 - Loss: 0.9617429971694946\n",
      "Ep 55: Batch #86 - Loss: 0.6956461668014526\n",
      "Ep 55: Batch #87 - Loss: 0.7011831402778625\n",
      "Ep 55: Batch #88 - Loss: 0.7881203293800354\n",
      "Ep 55: Batch #89 - Loss: 0.8744524717330933\n",
      "Ep 55: Batch #90 - Loss: 1.1350539922714233\n",
      "Ep 55: Batch #91 - Loss: 0.7874723672866821\n",
      "Ep 55: Batch #92 - Loss: 1.0124365091323853\n",
      "Ep 55: Batch #93 - Loss: 1.01072359085083\n",
      "Ep 55: Batch #94 - Loss: 1.0323009490966797\n",
      "Ep 55: Batch #95 - Loss: 0.905095636844635\n",
      "Ep 55: Batch #96 - Loss: 0.8910605311393738\n",
      "Ep 55: Batch #97 - Loss: 0.7168979048728943\n",
      "Ep 55: Batch #98 - Loss: 0.7262148857116699\n",
      "Ep 55: Batch #99 - Loss: 0.9447962641716003\n",
      "Ep 55: Batch #100 - Loss: 0.6663205027580261\n",
      "Ep 55: Batch #101 - Loss: 1.0323787927627563\n",
      "Ep 55: Batch #102 - Loss: 0.7699650526046753\n",
      "Ep 55: Batch #103 - Loss: 0.7779523730278015\n",
      "Ep 55: Batch #104 - Loss: 0.788465142250061\n",
      "Ep 55: Batch #105 - Loss: 1.011497974395752\n",
      "Ep 55: Batch #106 - Loss: 0.7473027110099792\n",
      "Ep 55: Batch #107 - Loss: 0.7447234392166138\n",
      "Ep 55: Batch #108 - Loss: 1.0174928903579712\n",
      "Ep 55: Batch #109 - Loss: 0.7510852217674255\n",
      "Ep 55: Batch #110 - Loss: 0.901870846748352\n",
      "Ep 55: Batch #111 - Loss: 1.3607486486434937\n",
      "Ep 55: Batch #112 - Loss: 1.0307626724243164\n",
      "Ep 55: Batch #113 - Loss: 0.8030979037284851\n",
      "Ep 55: Batch #114 - Loss: 0.8878870606422424\n",
      "Ep 55: Batch #115 - Loss: 1.0778721570968628\n",
      "Ep 55: Batch #116 - Loss: 0.6253610849380493\n",
      "Ep 55: Batch #117 - Loss: 0.8596788644790649\n",
      "Ep 55: Batch #118 - Loss: 0.5343852043151855\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved in file: ./weights_autoencoder_low_LR/model_e55b118_1516651276.1510217.ckpt\n",
      "Ep 55: Batch #119 - Loss: 1.0127979516983032\n",
      "Ep 55: Batch #120 - Loss: 0.7879356741905212\n",
      "Ep 55: Batch #121 - Loss: 0.6738743782043457\n",
      "Ep 55: Batch #122 - Loss: 0.8126041293144226\n",
      "Ep 55: Batch #123 - Loss: 0.8187114000320435\n",
      "Ep 55: Batch #124 - Loss: 0.6540273427963257\n",
      "Ep 55: Batch #125 - Loss: 2.7010421752929688\n",
      "Ep 55: Batch #126 - Loss: 1.2096835374832153\n",
      "Ep 55: Batch #127 - Loss: 0.7351905107498169\n",
      "Ep 55: Batch #128 - Loss: 1.086744785308838\n",
      "Ep 55: Batch #129 - Loss: 0.8242005705833435\n",
      "Ep 55: Batch #130 - Loss: 0.7113287448883057\n",
      "Ep 55: Batch #131 - Loss: 0.9772323966026306\n",
      "Ep 55: Batch #132 - Loss: 0.8094900846481323\n",
      "Ep 55: Batch #133 - Loss: 0.8041507601737976\n",
      "Ep 55: Batch #134 - Loss: 0.7556430101394653\n",
      "Ep 55: Batch #135 - Loss: 0.9492160081863403\n",
      "Ep 55: Batch #136 - Loss: 1.1630558967590332\n",
      "Ep 55: Batch #137 - Loss: 0.948592483997345\n",
      "Ep 55: Batch #138 - Loss: 1.0543208122253418\n",
      "Ep 55: Batch #139 - Loss: 0.884986400604248\n",
      "Ep 55: Batch #140 - Loss: 1.0331122875213623\n",
      "Ep 55: Batch #141 - Loss: 1.3420063257217407\n",
      "Ep 55: Batch #142 - Loss: 0.7821712493896484\n",
      "Ep 55: Batch #143 - Loss: 0.9476523399353027\n",
      "Ep 55: Batch #144 - Loss: 0.7089279890060425\n",
      "Ep 55: Batch #145 - Loss: 0.6674143075942993\n",
      "Ep 55: Batch #146 - Loss: 0.8709927797317505\n",
      "Ep 55: Batch #147 - Loss: 0.8455783724784851\n",
      "Ep 55: Batch #148 - Loss: 0.9608402252197266\n",
      "Ep 55: Batch #149 - Loss: 0.83892422914505\n",
      "Ep 55: Batch #150 - Loss: 0.8692996501922607\n",
      "Ep 55: Batch #151 - Loss: 0.7180508375167847\n",
      "Ep 55: Batch #152 - Loss: 0.7296392321586609\n",
      "Ep 55: Batch #153 - Loss: 1.087585687637329\n",
      "Ep 55: Batch #154 - Loss: 0.7514513731002808\n",
      "Ep 55: Batch #155 - Loss: 0.8203850388526917\n",
      "Ep 55: Batch #156 - Loss: 1.002651572227478\n",
      "Ep 55: Batch #157 - Loss: 0.7494184970855713\n",
      "Ep 55: Batch #158 - Loss: 0.7956134080886841\n",
      "Ep 55: Batch #159 - Loss: 0.7944323420524597\n",
      "Ep 55: Batch #160 - Loss: 0.8917590975761414\n",
      "Ep 55: Batch #161 - Loss: 0.8033844232559204\n",
      "Ep 55: Batch #162 - Loss: 0.9178667068481445\n",
      "Ep 55: Batch #163 - Loss: 0.9181552529335022\n",
      "Ep 55: Batch #164 - Loss: 0.7722188234329224\n",
      "Ep 55: Batch #165 - Loss: 1.4847211837768555\n",
      "Ep 55: Batch #166 - Loss: 0.6673738360404968\n",
      "Ep 55: Batch #167 - Loss: 1.0716930627822876\n",
      "Ep 55: Batch #168 - Loss: 0.8464252352714539\n",
      "Ep 55: Batch #169 - Loss: 0.7890105843544006\n",
      "Ep 55: Batch #170 - Loss: 0.7909141778945923\n",
      "Ep 55: Batch #171 - Loss: 0.7666091322898865\n",
      "Ep 55: Batch #172 - Loss: 0.6246532797813416\n",
      "Ep 55: Batch #173 - Loss: 1.1761534214019775\n",
      "Ep 55: Batch #174 - Loss: 0.5698608160018921\n",
      "Ep 55: Batch #175 - Loss: 0.7684680819511414\n",
      "Ep 55: Batch #176 - Loss: 1.1359539031982422\n",
      "Ep 55: Batch #177 - Loss: 0.8349875807762146\n",
      "Ep 55: Batch #178 - Loss: 0.7501385807991028\n",
      "Ep 55: Batch #179 - Loss: 0.9236096739768982\n",
      "Ep 55: Batch #180 - Loss: 0.8388947248458862\n",
      "Ep 55: Batch #181 - Loss: 0.9743587970733643\n",
      "Ep 55: Batch #182 - Loss: 0.7544696927070618\n",
      "Ep 55: Batch #183 - Loss: 0.7522395849227905\n",
      "Ep 55: Batch #184 - Loss: 1.056208848953247\n",
      "Ep 55: Batch #185 - Loss: 0.7462665438652039\n",
      "Ep 55: Batch #186 - Loss: 0.9495938420295715\n",
      "Ep 55: Batch #187 - Loss: 1.151597499847412\n",
      "Ep 55: Batch #188 - Loss: 1.3358826637268066\n",
      "Ep 55: Batch #189 - Loss: 0.6920569539070129\n",
      "Ep 55: Batch #190 - Loss: 0.7237136363983154\n",
      "Ep 55: Batch #191 - Loss: 1.0484036207199097\n",
      "Ep 55: Batch #192 - Loss: 0.6605145335197449\n",
      "Ep 55: Batch #193 - Loss: 0.7281001806259155\n",
      "Ep 55: Batch #194 - Loss: 0.6845353245735168\n",
      "Ep 55: Batch #195 - Loss: 0.9676884412765503\n",
      "Ep 55: Batch #196 - Loss: 0.8523248434066772\n",
      "Ep 55: Batch #197 - Loss: 0.886953592300415\n",
      "Ep 55: Batch #198 - Loss: 0.6656415462493896\n",
      "Ep 55: Batch #199 - Loss: 0.847623348236084\n",
      "Ep 56: Batch #0 - Loss: 0.7769632339477539\n",
      "Ep 56: Batch #1 - Loss: 0.8618869185447693\n",
      "Ep 56: Batch #2 - Loss: 0.9950867295265198\n",
      "Ep 56: Batch #3 - Loss: 0.8521831631660461\n",
      "Ep 56: Batch #4 - Loss: 0.7749310731887817\n",
      "Ep 56: Batch #5 - Loss: 0.6583541631698608\n",
      "Ep 56: Batch #6 - Loss: 0.8651966452598572\n",
      "Ep 56: Batch #7 - Loss: 0.6906255483627319\n",
      "Ep 56: Batch #8 - Loss: 0.7226547002792358\n",
      "Ep 56: Batch #9 - Loss: 1.378806233406067\n",
      "Ep 56: Batch #10 - Loss: 0.9916295409202576\n",
      "Ep 56: Batch #11 - Loss: 0.6593101620674133\n",
      "Ep 56: Batch #12 - Loss: 1.5425583124160767\n",
      "Ep 56: Batch #13 - Loss: 0.6396454572677612\n",
      "Ep 56: Batch #14 - Loss: 0.7162235379219055\n",
      "Ep 56: Batch #15 - Loss: 1.2211029529571533\n",
      "Ep 56: Batch #16 - Loss: 1.255236029624939\n",
      "Ep 56: Batch #17 - Loss: 0.8653513789176941\n",
      "Ep 56: Batch #18 - Loss: 0.9319027066230774\n",
      "Ep 56: Batch #19 - Loss: 0.6580212712287903\n",
      "Ep 56: Batch #20 - Loss: 0.6435881853103638\n",
      "Ep 56: Batch #21 - Loss: 1.1976417303085327\n",
      "Ep 56: Batch #22 - Loss: 0.7153621912002563\n",
      "Ep 56: Batch #23 - Loss: 0.7298641204833984\n",
      "Ep 56: Batch #24 - Loss: 0.8116111755371094\n",
      "Ep 56: Batch #25 - Loss: 0.702093780040741\n",
      "Ep 56: Batch #26 - Loss: 0.7165859937667847\n",
      "Ep 56: Batch #27 - Loss: 1.3324193954467773\n",
      "Ep 56: Batch #28 - Loss: 0.8544022440910339\n",
      "Ep 56: Batch #29 - Loss: 0.8766801357269287\n",
      "Ep 56: Batch #30 - Loss: 1.1868447065353394\n",
      "Ep 56: Batch #31 - Loss: 0.6635607481002808\n",
      "Ep 56: Batch #32 - Loss: 0.7340440154075623\n",
      "Ep 56: Batch #33 - Loss: 0.7951317429542542\n",
      "Ep 56: Batch #34 - Loss: 0.7714127898216248\n",
      "Ep 56: Batch #35 - Loss: 0.9310835003852844\n",
      "Ep 56: Batch #36 - Loss: 0.6904129981994629\n",
      "Ep 56: Batch #37 - Loss: 1.12591552734375\n",
      "Ep 56: Batch #38 - Loss: 0.7308797836303711\n",
      "Ep 56: Batch #39 - Loss: 0.808751106262207\n",
      "Ep 56: Batch #40 - Loss: 0.7608770132064819\n",
      "Ep 56: Batch #41 - Loss: 0.7230444550514221\n",
      "Ep 56: Batch #42 - Loss: 0.7103706002235413\n",
      "Ep 56: Batch #43 - Loss: 0.7755177617073059\n",
      "Ep 56: Batch #44 - Loss: 0.7705227136611938\n",
      "Ep 56: Batch #45 - Loss: 0.6207948923110962\n",
      "Ep 56: Batch #46 - Loss: 0.8147119283676147\n",
      "Ep 56: Batch #47 - Loss: 0.9420899748802185\n",
      "Ep 56: Batch #48 - Loss: 1.3360803127288818\n",
      "Ep 56: Batch #49 - Loss: 0.9950225353240967\n",
      "Ep 56: Batch #50 - Loss: 0.6964027881622314\n",
      "Ep 56: Batch #51 - Loss: 0.9756653308868408\n",
      "Ep 56: Batch #52 - Loss: 0.7828217148780823\n",
      "Ep 56: Batch #53 - Loss: 0.8083003759384155\n",
      "Ep 56: Batch #54 - Loss: 0.6938104033470154\n",
      "Ep 56: Batch #55 - Loss: 0.7377526164054871\n",
      "Ep 56: Batch #56 - Loss: 1.2419079542160034\n",
      "Ep 56: Batch #57 - Loss: 0.831520140171051\n",
      "Ep 56: Batch #58 - Loss: 0.9805015325546265\n",
      "Ep 56: Batch #59 - Loss: 0.6711244583129883\n",
      "Ep 56: Batch #60 - Loss: 1.2942886352539062\n",
      "Ep 56: Batch #61 - Loss: 0.6257356405258179\n",
      "Ep 56: Batch #62 - Loss: 0.7086706757545471\n",
      "Ep 56: Batch #63 - Loss: 0.9859364628791809\n",
      "Ep 56: Batch #64 - Loss: 9.41557502746582\n",
      "Ep 56: Batch #65 - Loss: 0.6019682884216309\n",
      "Ep 56: Batch #66 - Loss: 0.7812882661819458\n",
      "Ep 56: Batch #67 - Loss: 0.8955455422401428\n",
      "Ep 56: Batch #68 - Loss: 0.8916395306587219\n",
      "Ep 56: Batch #69 - Loss: 0.7320095300674438\n",
      "Ep 56: Batch #70 - Loss: 0.759890615940094\n",
      "Ep 56: Batch #71 - Loss: 0.668408215045929\n",
      "Ep 56: Batch #72 - Loss: 0.8393412828445435\n",
      "Ep 56: Batch #73 - Loss: 0.884803295135498\n",
      "Ep 56: Batch #74 - Loss: 0.7261567711830139\n",
      "Ep 56: Batch #75 - Loss: 0.7559732794761658\n",
      "Ep 56: Batch #76 - Loss: 1.082000970840454\n",
      "Ep 56: Batch #77 - Loss: 0.7208899259567261\n",
      "Ep 56: Batch #78 - Loss: 1.139515995979309\n",
      "Ep 56: Batch #79 - Loss: 0.6146983504295349\n",
      "Ep 56: Batch #80 - Loss: 0.8431589603424072\n",
      "Ep 56: Batch #81 - Loss: 1.664367437362671\n",
      "Ep 56: Batch #82 - Loss: 0.8596426844596863\n",
      "Ep 56: Batch #83 - Loss: 1.7232929468154907\n",
      "Ep 56: Batch #84 - Loss: 0.7009958624839783\n",
      "Ep 56: Batch #85 - Loss: 0.9607316851615906\n",
      "Ep 56: Batch #86 - Loss: 0.6944500803947449\n",
      "Ep 56: Batch #87 - Loss: 0.7001129388809204\n",
      "Ep 56: Batch #88 - Loss: 0.7869020104408264\n",
      "Ep 56: Batch #89 - Loss: 0.873685896396637\n",
      "Ep 56: Batch #90 - Loss: 1.1333509683609009\n",
      "Ep 56: Batch #91 - Loss: 0.7861502766609192\n",
      "Ep 56: Batch #92 - Loss: 1.0110163688659668\n",
      "Ep 56: Batch #93 - Loss: 1.009009599685669\n",
      "Ep 56: Batch #94 - Loss: 1.0307929515838623\n",
      "Ep 56: Batch #95 - Loss: 0.9038350582122803\n",
      "Ep 56: Batch #96 - Loss: 0.8898749351501465\n",
      "Ep 56: Batch #97 - Loss: 0.7157691121101379\n",
      "Ep 56: Batch #98 - Loss: 0.7251047492027283\n",
      "Ep 56: Batch #99 - Loss: 0.9434760212898254\n",
      "Ep 56: Batch #100 - Loss: 0.665276288986206\n",
      "Ep 56: Batch #101 - Loss: 1.0311344861984253\n",
      "Ep 56: Batch #102 - Loss: 0.7688539624214172\n",
      "Ep 56: Batch #103 - Loss: 0.7768435478210449\n",
      "Ep 56: Batch #104 - Loss: 0.7873445153236389\n",
      "Ep 56: Batch #105 - Loss: 1.0100091695785522\n",
      "Ep 56: Batch #106 - Loss: 0.7462865710258484\n",
      "Ep 56: Batch #107 - Loss: 0.7435861825942993\n",
      "Ep 56: Batch #108 - Loss: 1.016068935394287\n",
      "Ep 56: Batch #109 - Loss: 0.7500864863395691\n",
      "Ep 56: Batch #110 - Loss: 0.9003499746322632\n",
      "Ep 56: Batch #111 - Loss: 1.3590508699417114\n",
      "Ep 56: Batch #112 - Loss: 1.029355525970459\n",
      "Ep 56: Batch #113 - Loss: 0.8019316792488098\n",
      "Ep 56: Batch #114 - Loss: 0.8864960074424744\n",
      "Ep 56: Batch #115 - Loss: 1.0764541625976562\n",
      "Ep 56: Batch #116 - Loss: 0.6246780157089233\n",
      "Ep 56: Batch #117 - Loss: 0.8585877418518066\n",
      "Ep 56: Batch #118 - Loss: 0.5335323810577393\n",
      "Model saved in file: ./weights_autoencoder_low_LR/model_e56b118_1516651276.290101.ckpt\n",
      "Ep 56: Batch #119 - Loss: 1.011552095413208\n",
      "Ep 56: Batch #120 - Loss: 0.7868677377700806\n",
      "Ep 56: Batch #121 - Loss: 0.6728284955024719\n",
      "Ep 56: Batch #122 - Loss: 0.8115347027778625\n",
      "Ep 56: Batch #123 - Loss: 0.8175620436668396\n",
      "Ep 56: Batch #124 - Loss: 0.6532213091850281\n",
      "Ep 56: Batch #125 - Loss: 2.69925594329834\n",
      "Ep 56: Batch #126 - Loss: 1.208361268043518\n",
      "Ep 56: Batch #127 - Loss: 0.733970046043396\n",
      "Ep 56: Batch #128 - Loss: 1.0850250720977783\n",
      "Ep 56: Batch #129 - Loss: 0.8229120969772339\n",
      "Ep 56: Batch #130 - Loss: 0.710269033908844\n",
      "Ep 56: Batch #131 - Loss: 0.9755955338478088\n",
      "Ep 56: Batch #132 - Loss: 0.8082293272018433\n",
      "Ep 56: Batch #133 - Loss: 0.8029506206512451\n",
      "Ep 56: Batch #134 - Loss: 0.7544658780097961\n",
      "Ep 56: Batch #135 - Loss: 0.9476855993270874\n",
      "Ep 56: Batch #136 - Loss: 1.1614662408828735\n",
      "Ep 56: Batch #137 - Loss: 0.9471664428710938\n",
      "Ep 56: Batch #138 - Loss: 1.0528850555419922\n",
      "Ep 56: Batch #139 - Loss: 0.8836079835891724\n",
      "Ep 56: Batch #140 - Loss: 1.031764268875122\n",
      "Ep 56: Batch #141 - Loss: 1.3402938842773438\n",
      "Ep 56: Batch #142 - Loss: 0.7810412049293518\n",
      "Ep 56: Batch #143 - Loss: 0.9460474252700806\n",
      "Ep 56: Batch #144 - Loss: 0.7079490423202515\n",
      "Ep 56: Batch #145 - Loss: 0.6665117740631104\n",
      "Ep 56: Batch #146 - Loss: 0.8698818683624268\n",
      "Ep 56: Batch #147 - Loss: 0.8441426753997803\n",
      "Ep 56: Batch #148 - Loss: 0.9593082070350647\n",
      "Ep 56: Batch #149 - Loss: 0.8375734090805054\n",
      "Ep 56: Batch #150 - Loss: 0.8680676817893982\n",
      "Ep 56: Batch #151 - Loss: 0.717261552810669\n",
      "Ep 56: Batch #152 - Loss: 0.7288035750389099\n",
      "Ep 56: Batch #153 - Loss: 1.0860093832015991\n",
      "Ep 56: Batch #154 - Loss: 0.7503481507301331\n",
      "Ep 56: Batch #155 - Loss: 0.8192697763442993\n",
      "Ep 56: Batch #156 - Loss: 1.0013291835784912\n",
      "Ep 56: Batch #157 - Loss: 0.7482777833938599\n",
      "Ep 56: Batch #158 - Loss: 0.794773519039154\n",
      "Ep 56: Batch #159 - Loss: 0.7931281328201294\n",
      "Ep 56: Batch #160 - Loss: 0.8907366991043091\n",
      "Ep 56: Batch #161 - Loss: 0.802203357219696\n",
      "Ep 56: Batch #162 - Loss: 0.9166266322135925\n",
      "Ep 56: Batch #163 - Loss: 0.9171181321144104\n",
      "Ep 56: Batch #164 - Loss: 0.7710924744606018\n",
      "Ep 56: Batch #165 - Loss: 1.48356032371521\n",
      "Ep 56: Batch #166 - Loss: 0.6663181781768799\n",
      "Ep 56: Batch #167 - Loss: 1.0703232288360596\n",
      "Ep 56: Batch #168 - Loss: 0.8451841473579407\n",
      "Ep 56: Batch #169 - Loss: 0.7879233956336975\n",
      "Ep 56: Batch #170 - Loss: 0.7897537350654602\n",
      "Ep 56: Batch #171 - Loss: 0.7653264403343201\n",
      "Ep 56: Batch #172 - Loss: 0.6238575577735901\n",
      "Ep 56: Batch #173 - Loss: 1.1742937564849854\n",
      "Ep 56: Batch #174 - Loss: 0.5690629482269287\n",
      "Ep 56: Batch #175 - Loss: 0.7676056623458862\n",
      "Ep 56: Batch #176 - Loss: 1.1340926885604858\n",
      "Ep 56: Batch #177 - Loss: 0.8337532877922058\n",
      "Ep 56: Batch #178 - Loss: 0.7490171194076538\n",
      "Ep 56: Batch #179 - Loss: 0.9222579598426819\n",
      "Ep 56: Batch #180 - Loss: 0.8374584913253784\n",
      "Ep 56: Batch #181 - Loss: 0.9728202223777771\n",
      "Ep 56: Batch #182 - Loss: 0.7535917162895203\n",
      "Ep 56: Batch #183 - Loss: 0.7511824369430542\n",
      "Ep 56: Batch #184 - Loss: 1.055062174797058\n",
      "Ep 56: Batch #185 - Loss: 0.7451632022857666\n",
      "Ep 56: Batch #186 - Loss: 0.9480440616607666\n",
      "Ep 56: Batch #187 - Loss: 1.149949550628662\n",
      "Ep 56: Batch #188 - Loss: 1.3347619771957397\n",
      "Ep 56: Batch #189 - Loss: 0.6912588477134705\n",
      "Ep 56: Batch #190 - Loss: 0.7227442860603333\n",
      "Ep 56: Batch #191 - Loss: 1.0468711853027344\n",
      "Ep 56: Batch #192 - Loss: 0.6597151756286621\n",
      "Ep 56: Batch #193 - Loss: 0.7269787788391113\n",
      "Ep 56: Batch #194 - Loss: 0.6834992170333862\n",
      "Ep 56: Batch #195 - Loss: 0.9663887619972229\n",
      "Ep 56: Batch #196 - Loss: 0.851087749004364\n",
      "Ep 56: Batch #197 - Loss: 0.8856211304664612\n",
      "Ep 56: Batch #198 - Loss: 0.664567232131958\n",
      "Ep 56: Batch #199 - Loss: 0.8463886380195618\n",
      "Ep 57: Batch #0 - Loss: 0.775661051273346\n",
      "Ep 57: Batch #1 - Loss: 0.8605898022651672\n",
      "Ep 57: Batch #2 - Loss: 0.994022786617279\n",
      "Ep 57: Batch #3 - Loss: 0.8511373996734619\n",
      "Ep 57: Batch #4 - Loss: 0.7737311720848083\n",
      "Ep 57: Batch #5 - Loss: 0.6574316620826721\n",
      "Ep 57: Batch #6 - Loss: 0.8640046119689941\n",
      "Ep 57: Batch #7 - Loss: 0.6896443367004395\n",
      "Ep 57: Batch #8 - Loss: 0.7216900587081909\n",
      "Ep 57: Batch #9 - Loss: 1.3769892454147339\n",
      "Ep 57: Batch #10 - Loss: 0.9903985261917114\n",
      "Ep 57: Batch #11 - Loss: 0.6583919525146484\n",
      "Ep 57: Batch #12 - Loss: 1.5410716533660889\n",
      "Ep 57: Batch #13 - Loss: 0.6389549374580383\n",
      "Ep 57: Batch #14 - Loss: 0.715313732624054\n",
      "Ep 57: Batch #15 - Loss: 1.2195268869400024\n",
      "Ep 57: Batch #16 - Loss: 1.2535202503204346\n",
      "Ep 57: Batch #17 - Loss: 0.8640825748443604\n",
      "Ep 57: Batch #18 - Loss: 0.9311041235923767\n",
      "Ep 57: Batch #19 - Loss: 0.6571989059448242\n",
      "Ep 57: Batch #20 - Loss: 0.6426477432250977\n",
      "Ep 57: Batch #21 - Loss: 1.196447730064392\n",
      "Ep 57: Batch #22 - Loss: 0.7144896388053894\n",
      "Ep 57: Batch #23 - Loss: 0.7287663817405701\n",
      "Ep 57: Batch #24 - Loss: 0.8106541633605957\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 57: Batch #25 - Loss: 0.7010326385498047\n",
      "Ep 57: Batch #26 - Loss: 0.7153845429420471\n",
      "Ep 57: Batch #27 - Loss: 1.33074152469635\n",
      "Ep 57: Batch #28 - Loss: 0.8533880710601807\n",
      "Ep 57: Batch #29 - Loss: 0.8753516674041748\n",
      "Ep 57: Batch #30 - Loss: 1.1853288412094116\n",
      "Ep 57: Batch #31 - Loss: 0.6626709699630737\n",
      "Ep 57: Batch #32 - Loss: 0.73292076587677\n",
      "Ep 57: Batch #33 - Loss: 0.7941048741340637\n",
      "Ep 57: Batch #34 - Loss: 0.7704450488090515\n",
      "Ep 57: Batch #35 - Loss: 0.9296026229858398\n",
      "Ep 57: Batch #36 - Loss: 0.68938148021698\n",
      "Ep 57: Batch #37 - Loss: 1.1246792078018188\n",
      "Ep 57: Batch #38 - Loss: 0.7296443581581116\n",
      "Ep 57: Batch #39 - Loss: 0.8078874945640564\n",
      "Ep 57: Batch #40 - Loss: 0.7597776055335999\n",
      "Ep 57: Batch #41 - Loss: 0.721783459186554\n",
      "Ep 57: Batch #42 - Loss: 0.7093496322631836\n",
      "Ep 57: Batch #43 - Loss: 0.7744520902633667\n",
      "Ep 57: Batch #44 - Loss: 0.7693333625793457\n",
      "Ep 57: Batch #45 - Loss: 0.6197314262390137\n",
      "Ep 57: Batch #46 - Loss: 0.813378095626831\n",
      "Ep 57: Batch #47 - Loss: 0.9404863119125366\n",
      "Ep 57: Batch #48 - Loss: 1.3346396684646606\n",
      "Ep 57: Batch #49 - Loss: 0.9933022856712341\n",
      "Ep 57: Batch #50 - Loss: 0.6956015229225159\n",
      "Ep 57: Batch #51 - Loss: 0.9740892648696899\n",
      "Ep 57: Batch #52 - Loss: 0.7818198800086975\n",
      "Ep 57: Batch #53 - Loss: 0.8071388006210327\n",
      "Ep 57: Batch #54 - Loss: 0.6928523778915405\n",
      "Ep 57: Batch #55 - Loss: 0.7366343140602112\n",
      "Ep 57: Batch #56 - Loss: 1.2401413917541504\n",
      "Ep 57: Batch #57 - Loss: 0.8301937580108643\n",
      "Ep 57: Batch #58 - Loss: 0.9788463711738586\n",
      "Ep 57: Batch #59 - Loss: 0.6703586578369141\n",
      "Ep 57: Batch #60 - Loss: 1.292681336402893\n",
      "Ep 57: Batch #61 - Loss: 0.6248615980148315\n",
      "Ep 57: Batch #62 - Loss: 0.7075373530387878\n",
      "Ep 57: Batch #63 - Loss: 0.9845720529556274\n",
      "Ep 57: Batch #64 - Loss: 9.414454460144043\n",
      "Ep 57: Batch #65 - Loss: 0.6011285781860352\n",
      "Ep 57: Batch #66 - Loss: 0.7800466418266296\n",
      "Ep 57: Batch #67 - Loss: 0.8942155838012695\n",
      "Ep 57: Batch #68 - Loss: 0.8902661800384521\n",
      "Ep 57: Batch #69 - Loss: 0.7309746146202087\n",
      "Ep 57: Batch #70 - Loss: 0.758586049079895\n",
      "Ep 57: Batch #71 - Loss: 0.6675469875335693\n",
      "Ep 57: Batch #72 - Loss: 0.8381327390670776\n",
      "Ep 57: Batch #73 - Loss: 0.8833020925521851\n",
      "Ep 57: Batch #74 - Loss: 0.7249326109886169\n",
      "Ep 57: Batch #75 - Loss: 0.754997968673706\n",
      "Ep 57: Batch #76 - Loss: 1.0808959007263184\n",
      "Ep 57: Batch #77 - Loss: 0.7197747826576233\n",
      "Ep 57: Batch #78 - Loss: 1.137790322303772\n",
      "Ep 57: Batch #79 - Loss: 0.6137562394142151\n",
      "Ep 57: Batch #80 - Loss: 0.841777503490448\n",
      "Ep 57: Batch #81 - Loss: 1.6631227731704712\n",
      "Ep 57: Batch #82 - Loss: 0.8585007190704346\n",
      "Ep 57: Batch #83 - Loss: 1.7223860025405884\n",
      "Ep 57: Batch #84 - Loss: 0.6999237537384033\n",
      "Ep 57: Batch #85 - Loss: 0.9597356915473938\n",
      "Ep 57: Batch #86 - Loss: 0.6932529211044312\n",
      "Ep 57: Batch #87 - Loss: 0.6990669369697571\n",
      "Ep 57: Batch #88 - Loss: 0.7857043147087097\n",
      "Ep 57: Batch #89 - Loss: 0.872931182384491\n",
      "Ep 57: Batch #90 - Loss: 1.131664752960205\n",
      "Ep 57: Batch #91 - Loss: 0.7848365306854248\n",
      "Ep 57: Batch #92 - Loss: 1.0096100568771362\n",
      "Ep 57: Batch #93 - Loss: 1.0072951316833496\n",
      "Ep 57: Batch #94 - Loss: 1.0293104648590088\n",
      "Ep 57: Batch #95 - Loss: 0.902596652507782\n",
      "Ep 57: Batch #96 - Loss: 0.8887010216712952\n",
      "Ep 57: Batch #97 - Loss: 0.7146511077880859\n",
      "Ep 57: Batch #98 - Loss: 0.7240017056465149\n",
      "Ep 57: Batch #99 - Loss: 0.9421600699424744\n",
      "Ep 57: Batch #100 - Loss: 0.6642444133758545\n",
      "Ep 57: Batch #101 - Loss: 1.029902458190918\n",
      "Ep 57: Batch #102 - Loss: 0.7677484154701233\n",
      "Ep 57: Batch #103 - Loss: 0.7757495045661926\n",
      "Ep 57: Batch #104 - Loss: 0.7862276434898376\n",
      "Ep 57: Batch #105 - Loss: 1.0085512399673462\n",
      "Ep 57: Batch #106 - Loss: 0.7452758550643921\n",
      "Ep 57: Batch #107 - Loss: 0.7424585223197937\n",
      "Ep 57: Batch #108 - Loss: 1.0146777629852295\n",
      "Ep 57: Batch #109 - Loss: 0.749081015586853\n",
      "Ep 57: Batch #110 - Loss: 0.8988478183746338\n",
      "Ep 57: Batch #111 - Loss: 1.35736882686615\n",
      "Ep 57: Batch #112 - Loss: 1.0279539823532104\n",
      "Ep 57: Batch #113 - Loss: 0.8007810711860657\n",
      "Ep 57: Batch #114 - Loss: 0.8851239681243896\n",
      "Ep 57: Batch #115 - Loss: 1.0750535726547241\n",
      "Ep 57: Batch #116 - Loss: 0.624000608921051\n",
      "Ep 57: Batch #117 - Loss: 0.8575100302696228\n",
      "Ep 57: Batch #118 - Loss: 0.5326920747756958\n",
      "Model saved in file: ./weights_autoencoder_low_LR/model_e57b118_1516651276.4257958.ckpt\n",
      "Ep 57: Batch #119 - Loss: 1.010308861732483\n",
      "Ep 57: Batch #120 - Loss: 0.7858114838600159\n",
      "Ep 57: Batch #121 - Loss: 0.6717935800552368\n",
      "Ep 57: Batch #122 - Loss: 0.8104654550552368\n",
      "Ep 57: Batch #123 - Loss: 0.8164071440696716\n",
      "Ep 57: Batch #124 - Loss: 0.6524279117584229\n",
      "Ep 57: Batch #125 - Loss: 2.697510004043579\n",
      "Ep 57: Batch #126 - Loss: 1.207047700881958\n",
      "Ep 57: Batch #127 - Loss: 0.7327675819396973\n",
      "Ep 57: Batch #128 - Loss: 1.0832754373550415\n",
      "Ep 57: Batch #129 - Loss: 0.8216352462768555\n",
      "Ep 57: Batch #130 - Loss: 0.7092204689979553\n",
      "Ep 57: Batch #131 - Loss: 0.973966658115387\n",
      "Ep 57: Batch #132 - Loss: 0.8069819211959839\n",
      "Ep 57: Batch #133 - Loss: 0.8017585873603821\n",
      "Ep 57: Batch #134 - Loss: 0.7533022165298462\n",
      "Ep 57: Batch #135 - Loss: 0.9461789727210999\n",
      "Ep 57: Batch #136 - Loss: 1.1598882675170898\n",
      "Ep 57: Batch #137 - Loss: 0.9457583427429199\n",
      "Ep 57: Batch #138 - Loss: 1.051464319229126\n",
      "Ep 57: Batch #139 - Loss: 0.8822413086891174\n",
      "Ep 57: Batch #140 - Loss: 1.0304410457611084\n",
      "Ep 57: Batch #141 - Loss: 1.3386006355285645\n",
      "Ep 57: Batch #142 - Loss: 0.7799229621887207\n",
      "Ep 57: Batch #143 - Loss: 0.9444575905799866\n",
      "Ep 57: Batch #144 - Loss: 0.7069816589355469\n",
      "Ep 57: Batch #145 - Loss: 0.665620744228363\n",
      "Ep 57: Batch #146 - Loss: 0.8687790036201477\n",
      "Ep 57: Batch #147 - Loss: 0.8427190780639648\n",
      "Ep 57: Batch #148 - Loss: 0.9577615261077881\n",
      "Ep 57: Batch #149 - Loss: 0.8362298607826233\n",
      "Ep 57: Batch #150 - Loss: 0.8668625354766846\n",
      "Ep 57: Batch #151 - Loss: 0.7164785265922546\n",
      "Ep 57: Batch #152 - Loss: 0.7279793620109558\n",
      "Ep 57: Batch #153 - Loss: 1.0844519138336182\n",
      "Ep 57: Batch #154 - Loss: 0.7492349743843079\n",
      "Ep 57: Batch #155 - Loss: 0.8181524276733398\n",
      "Ep 57: Batch #156 - Loss: 1.0000187158584595\n",
      "Ep 57: Batch #157 - Loss: 0.7471458911895752\n",
      "Ep 57: Batch #158 - Loss: 0.7939428091049194\n",
      "Ep 57: Batch #159 - Loss: 0.7918181419372559\n",
      "Ep 57: Batch #160 - Loss: 0.8897292613983154\n",
      "Ep 57: Batch #161 - Loss: 0.801032304763794\n",
      "Ep 57: Batch #162 - Loss: 0.9153991341590881\n",
      "Ep 57: Batch #163 - Loss: 0.916085422039032\n",
      "Ep 57: Batch #164 - Loss: 0.7699717879295349\n",
      "Ep 57: Batch #165 - Loss: 1.482423186302185\n",
      "Ep 57: Batch #166 - Loss: 0.6652758121490479\n",
      "Ep 57: Batch #167 - Loss: 1.0688570737838745\n",
      "Ep 57: Batch #168 - Loss: 0.8439581394195557\n",
      "Ep 57: Batch #169 - Loss: 0.7868490219116211\n",
      "Ep 57: Batch #170 - Loss: 0.7886225581169128\n",
      "Ep 57: Batch #171 - Loss: 0.7640572786331177\n",
      "Ep 57: Batch #172 - Loss: 0.6230698823928833\n",
      "Ep 57: Batch #173 - Loss: 1.172437310218811\n",
      "Ep 57: Batch #174 - Loss: 0.5682776570320129\n",
      "Ep 57: Batch #175 - Loss: 0.7667571902275085\n",
      "Ep 57: Batch #176 - Loss: 1.1322556734085083\n",
      "Ep 57: Batch #177 - Loss: 0.8325019478797913\n",
      "Ep 57: Batch #178 - Loss: 0.7479072213172913\n",
      "Ep 57: Batch #179 - Loss: 0.9209268093109131\n",
      "Ep 57: Batch #180 - Loss: 0.8360394239425659\n",
      "Ep 57: Batch #181 - Loss: 0.9712976217269897\n",
      "Ep 57: Batch #182 - Loss: 0.7527287006378174\n",
      "Ep 57: Batch #183 - Loss: 0.7501387596130371\n",
      "Ep 57: Batch #184 - Loss: 1.0539268255233765\n",
      "Ep 57: Batch #185 - Loss: 0.7440614104270935\n",
      "Ep 57: Batch #186 - Loss: 0.9465091824531555\n",
      "Ep 57: Batch #187 - Loss: 1.1482493877410889\n",
      "Ep 57: Batch #188 - Loss: 1.3336529731750488\n",
      "Ep 57: Batch #189 - Loss: 0.6904599070549011\n",
      "Ep 57: Batch #190 - Loss: 0.7217943668365479\n",
      "Ep 57: Batch #191 - Loss: 1.0453451871871948\n",
      "Ep 57: Batch #192 - Loss: 0.6589237451553345\n",
      "Ep 57: Batch #193 - Loss: 0.7258766889572144\n",
      "Ep 57: Batch #194 - Loss: 0.6824716329574585\n",
      "Ep 57: Batch #195 - Loss: 0.9650868773460388\n",
      "Ep 57: Batch #196 - Loss: 0.8498563766479492\n",
      "Ep 57: Batch #197 - Loss: 0.8842858672142029\n",
      "Ep 57: Batch #198 - Loss: 0.6635061502456665\n",
      "Ep 57: Batch #199 - Loss: 0.8451646566390991\n",
      "Ep 58: Batch #0 - Loss: 0.7743687033653259\n",
      "Ep 58: Batch #1 - Loss: 0.859288215637207\n",
      "Ep 58: Batch #2 - Loss: 0.9929696917533875\n",
      "Ep 58: Batch #3 - Loss: 0.8501039743423462\n",
      "Ep 58: Batch #4 - Loss: 0.7725492715835571\n",
      "Ep 58: Batch #5 - Loss: 0.6565138101577759\n",
      "Ep 58: Batch #6 - Loss: 0.8628206849098206\n",
      "Ep 58: Batch #7 - Loss: 0.6886728405952454\n",
      "Ep 58: Batch #8 - Loss: 0.720739483833313\n",
      "Ep 58: Batch #9 - Loss: 1.375191330909729\n",
      "Ep 58: Batch #10 - Loss: 0.9891823530197144\n",
      "Ep 58: Batch #11 - Loss: 0.6574829816818237\n",
      "Ep 58: Batch #12 - Loss: 1.5396229028701782\n",
      "Ep 58: Batch #13 - Loss: 0.638271689414978\n",
      "Ep 58: Batch #14 - Loss: 0.7144107818603516\n",
      "Ep 58: Batch #15 - Loss: 1.217976689338684\n",
      "Ep 58: Batch #16 - Loss: 1.2517129182815552\n",
      "Ep 58: Batch #17 - Loss: 0.8628235459327698\n",
      "Ep 58: Batch #18 - Loss: 0.9303191304206848\n",
      "Ep 58: Batch #19 - Loss: 0.6563889384269714\n",
      "Ep 58: Batch #20 - Loss: 0.6417177319526672\n",
      "Ep 58: Batch #21 - Loss: 1.195264458656311\n",
      "Ep 58: Batch #22 - Loss: 0.7136255502700806\n",
      "Ep 58: Batch #23 - Loss: 0.7276780605316162\n",
      "Ep 58: Batch #24 - Loss: 0.8097129464149475\n",
      "Ep 58: Batch #25 - Loss: 0.6999884247779846\n",
      "Ep 58: Batch #26 - Loss: 0.7142010927200317\n",
      "Ep 58: Batch #27 - Loss: 1.3290735483169556\n",
      "Ep 58: Batch #28 - Loss: 0.8523900508880615\n",
      "Ep 58: Batch #29 - Loss: 0.8740065693855286\n",
      "Ep 58: Batch #30 - Loss: 1.183825969696045\n",
      "Ep 58: Batch #31 - Loss: 0.6617918610572815\n",
      "Ep 58: Batch #32 - Loss: 0.731805682182312\n",
      "Ep 58: Batch #33 - Loss: 0.7930863499641418\n",
      "Ep 58: Batch #34 - Loss: 0.7694873213768005\n",
      "Ep 58: Batch #35 - Loss: 0.9281184077262878\n",
      "Ep 58: Batch #36 - Loss: 0.6883540153503418\n",
      "Ep 58: Batch #37 - Loss: 1.1234524250030518\n",
      "Ep 58: Batch #38 - Loss: 0.7284207940101624\n",
      "Ep 58: Batch #39 - Loss: 0.8070061802864075\n",
      "Ep 58: Batch #40 - Loss: 0.7586816549301147\n",
      "Ep 58: Batch #41 - Loss: 0.720533549785614\n",
      "Ep 58: Batch #42 - Loss: 0.7083354592323303\n",
      "Ep 58: Batch #43 - Loss: 0.7733973264694214\n",
      "Ep 58: Batch #44 - Loss: 0.7681397199630737\n",
      "Ep 58: Batch #45 - Loss: 0.6186808347702026\n",
      "Ep 58: Batch #46 - Loss: 0.8120290637016296\n",
      "Ep 58: Batch #47 - Loss: 0.9388948082923889\n",
      "Ep 58: Batch #48 - Loss: 1.3332043886184692\n",
      "Ep 58: Batch #49 - Loss: 0.9916111826896667\n",
      "Ep 58: Batch #50 - Loss: 0.6948050260543823\n",
      "Ep 58: Batch #51 - Loss: 0.9725228548049927\n",
      "Ep 58: Batch #52 - Loss: 0.7808244228363037\n",
      "Ep 58: Batch #53 - Loss: 0.8059853911399841\n",
      "Ep 58: Batch #54 - Loss: 0.6918737292289734\n",
      "Ep 58: Batch #55 - Loss: 0.735528290271759\n",
      "Ep 58: Batch #56 - Loss: 1.238340973854065\n",
      "Ep 58: Batch #57 - Loss: 0.8288796544075012\n",
      "Ep 58: Batch #58 - Loss: 0.977223813533783\n",
      "Ep 58: Batch #59 - Loss: 0.6696024537086487\n",
      "Ep 58: Batch #60 - Loss: 1.291021704673767\n",
      "Ep 58: Batch #61 - Loss: 0.62398761510849\n",
      "Ep 58: Batch #62 - Loss: 0.7064135074615479\n",
      "Ep 58: Batch #63 - Loss: 0.983218252658844\n",
      "Ep 58: Batch #64 - Loss: 9.413339614868164\n",
      "Ep 58: Batch #65 - Loss: 0.6002976298332214\n",
      "Ep 58: Batch #66 - Loss: 0.7788228392601013\n",
      "Ep 58: Batch #67 - Loss: 0.8929061889648438\n",
      "Ep 58: Batch #68 - Loss: 0.8888900279998779\n",
      "Ep 58: Batch #69 - Loss: 0.7299509644508362\n",
      "Ep 58: Batch #70 - Loss: 0.7572928071022034\n",
      "Ep 58: Batch #71 - Loss: 0.6666934490203857\n",
      "Ep 58: Batch #72 - Loss: 0.8369324803352356\n",
      "Ep 58: Batch #73 - Loss: 0.8818175196647644\n",
      "Ep 58: Batch #74 - Loss: 0.7236997485160828\n",
      "Ep 58: Batch #75 - Loss: 0.7540412545204163\n",
      "Ep 58: Batch #76 - Loss: 1.0798026323318481\n",
      "Ep 58: Batch #77 - Loss: 0.718665599822998\n",
      "Ep 58: Batch #78 - Loss: 1.1360784769058228\n",
      "Ep 58: Batch #79 - Loss: 0.6128213405609131\n",
      "Ep 58: Batch #80 - Loss: 0.8403982520103455\n",
      "Ep 58: Batch #81 - Loss: 1.6618866920471191\n",
      "Ep 58: Batch #82 - Loss: 0.8573642373085022\n",
      "Ep 58: Batch #83 - Loss: 1.7214884757995605\n",
      "Ep 58: Batch #84 - Loss: 0.6988652944564819\n",
      "Ep 58: Batch #85 - Loss: 0.9587531685829163\n",
      "Ep 58: Batch #86 - Loss: 0.6920583248138428\n",
      "Ep 58: Batch #87 - Loss: 0.6980320811271667\n",
      "Ep 58: Batch #88 - Loss: 0.7845208644866943\n",
      "Ep 58: Batch #89 - Loss: 0.8721864223480225\n",
      "Ep 58: Batch #90 - Loss: 1.1299940347671509\n",
      "Ep 58: Batch #91 - Loss: 0.7835335731506348\n",
      "Ep 58: Batch #92 - Loss: 1.0081934928894043\n",
      "Ep 58: Batch #93 - Loss: 1.0055896043777466\n",
      "Ep 58: Batch #94 - Loss: 1.0278382301330566\n",
      "Ep 58: Batch #95 - Loss: 0.9013723731040955\n",
      "Ep 58: Batch #96 - Loss: 0.8875401616096497\n",
      "Ep 58: Batch #97 - Loss: 0.7135398983955383\n",
      "Ep 58: Batch #98 - Loss: 0.7229068279266357\n",
      "Ep 58: Batch #99 - Loss: 0.9408454895019531\n",
      "Ep 58: Batch #100 - Loss: 0.6632235050201416\n",
      "Ep 58: Batch #101 - Loss: 1.0286785364151\n",
      "Ep 58: Batch #102 - Loss: 0.7666419148445129\n",
      "Ep 58: Batch #103 - Loss: 0.7746613621711731\n",
      "Ep 58: Batch #104 - Loss: 0.7851130962371826\n",
      "Ep 58: Batch #105 - Loss: 1.0071133375167847\n",
      "Ep 58: Batch #106 - Loss: 0.7442671656608582\n",
      "Ep 58: Batch #107 - Loss: 0.741338312625885\n",
      "Ep 58: Batch #108 - Loss: 1.0133092403411865\n",
      "Ep 58: Batch #109 - Loss: 0.7480831146240234\n",
      "Ep 58: Batch #110 - Loss: 0.8973562121391296\n",
      "Ep 58: Batch #111 - Loss: 1.3556965589523315\n",
      "Ep 58: Batch #112 - Loss: 1.0265560150146484\n",
      "Ep 58: Batch #113 - Loss: 0.7996401190757751\n",
      "Ep 58: Batch #114 - Loss: 0.8837620615959167\n",
      "Ep 58: Batch #115 - Loss: 1.0736643075942993\n",
      "Ep 58: Batch #116 - Loss: 0.6233219504356384\n",
      "Ep 58: Batch #117 - Loss: 0.8564376831054688\n",
      "Ep 58: Batch #118 - Loss: 0.5318607687950134\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved in file: ./weights_autoencoder_low_LR/model_e58b118_1516651276.5611362.ckpt\n",
      "Ep 58: Batch #119 - Loss: 1.0090687274932861\n",
      "Ep 58: Batch #120 - Loss: 0.7847679853439331\n",
      "Ep 58: Batch #121 - Loss: 0.6707667708396912\n",
      "Ep 58: Batch #122 - Loss: 0.8093881011009216\n",
      "Ep 58: Batch #123 - Loss: 0.8152496814727783\n",
      "Ep 58: Batch #124 - Loss: 0.651641309261322\n",
      "Ep 58: Batch #125 - Loss: 2.695701837539673\n",
      "Ep 58: Batch #126 - Loss: 1.2057305574417114\n",
      "Ep 58: Batch #127 - Loss: 0.7315793633460999\n",
      "Ep 58: Batch #128 - Loss: 1.0815229415893555\n",
      "Ep 58: Batch #129 - Loss: 0.8203720450401306\n",
      "Ep 58: Batch #130 - Loss: 0.7081892490386963\n",
      "Ep 58: Batch #131 - Loss: 0.9723295569419861\n",
      "Ep 58: Batch #132 - Loss: 0.8057459592819214\n",
      "Ep 58: Batch #133 - Loss: 0.8005746006965637\n",
      "Ep 58: Batch #134 - Loss: 0.7521476745605469\n",
      "Ep 58: Batch #135 - Loss: 0.944706380367279\n",
      "Ep 58: Batch #136 - Loss: 1.1583234071731567\n",
      "Ep 58: Batch #137 - Loss: 0.9443597197532654\n",
      "Ep 58: Batch #138 - Loss: 1.050049901008606\n",
      "Ep 58: Batch #139 - Loss: 0.880881667137146\n",
      "Ep 58: Batch #140 - Loss: 1.0291357040405273\n",
      "Ep 58: Batch #141 - Loss: 1.336972713470459\n",
      "Ep 58: Batch #142 - Loss: 0.7788150310516357\n",
      "Ep 58: Batch #143 - Loss: 0.9428818821907043\n",
      "Ep 58: Batch #144 - Loss: 0.7060238122940063\n",
      "Ep 58: Batch #145 - Loss: 0.6647363901138306\n",
      "Ep 58: Batch #146 - Loss: 0.8676819205284119\n",
      "Ep 58: Batch #147 - Loss: 0.8412975668907166\n",
      "Ep 58: Batch #148 - Loss: 0.9562024474143982\n",
      "Ep 58: Batch #149 - Loss: 0.8348930478096008\n",
      "Ep 58: Batch #150 - Loss: 0.8656678199768066\n",
      "Ep 58: Batch #151 - Loss: 0.7157015204429626\n",
      "Ep 58: Batch #152 - Loss: 0.7271600365638733\n",
      "Ep 58: Batch #153 - Loss: 1.0829139947891235\n",
      "Ep 58: Batch #154 - Loss: 0.748114287853241\n",
      "Ep 58: Batch #155 - Loss: 0.8170408010482788\n",
      "Ep 58: Batch #156 - Loss: 0.9987180233001709\n",
      "Ep 58: Batch #157 - Loss: 0.7460179924964905\n",
      "Ep 58: Batch #158 - Loss: 0.7931156158447266\n",
      "Ep 58: Batch #159 - Loss: 0.7905042171478271\n",
      "Ep 58: Batch #160 - Loss: 0.8887317180633545\n",
      "Ep 58: Batch #161 - Loss: 0.7998656630516052\n",
      "Ep 58: Batch #162 - Loss: 0.9141853451728821\n",
      "Ep 58: Batch #163 - Loss: 0.9150471091270447\n",
      "Ep 58: Batch #164 - Loss: 0.7688571214675903\n",
      "Ep 58: Batch #165 - Loss: 1.4813066720962524\n",
      "Ep 58: Batch #166 - Loss: 0.664242684841156\n",
      "Ep 58: Batch #167 - Loss: 1.0673822164535522\n",
      "Ep 58: Batch #168 - Loss: 0.8427441120147705\n",
      "Ep 58: Batch #169 - Loss: 0.7857866287231445\n",
      "Ep 58: Batch #170 - Loss: 0.7874957323074341\n",
      "Ep 58: Batch #171 - Loss: 0.7627894282341003\n",
      "Ep 58: Batch #172 - Loss: 0.6222845911979675\n",
      "Ep 58: Batch #173 - Loss: 1.1705862283706665\n",
      "Ep 58: Batch #174 - Loss: 0.5674957633018494\n",
      "Ep 58: Batch #175 - Loss: 0.7659116387367249\n",
      "Ep 58: Batch #176 - Loss: 1.1304339170455933\n",
      "Ep 58: Batch #177 - Loss: 0.8312647938728333\n",
      "Ep 58: Batch #178 - Loss: 0.7468081116676331\n",
      "Ep 58: Batch #179 - Loss: 0.9196149110794067\n",
      "Ep 58: Batch #180 - Loss: 0.8346361517906189\n",
      "Ep 58: Batch #181 - Loss: 0.9697843790054321\n",
      "Ep 58: Batch #182 - Loss: 0.7518660426139832\n",
      "Ep 58: Batch #183 - Loss: 0.7491106986999512\n",
      "Ep 58: Batch #184 - Loss: 1.0527856349945068\n",
      "Ep 58: Batch #185 - Loss: 0.7429622411727905\n",
      "Ep 58: Batch #186 - Loss: 0.9449837803840637\n",
      "Ep 58: Batch #187 - Loss: 1.1465673446655273\n",
      "Ep 58: Batch #188 - Loss: 1.3325530290603638\n",
      "Ep 58: Batch #189 - Loss: 0.6896593570709229\n",
      "Ep 58: Batch #190 - Loss: 0.7208550572395325\n",
      "Ep 58: Batch #191 - Loss: 1.0438194274902344\n",
      "Ep 58: Batch #192 - Loss: 0.6581469178199768\n",
      "Ep 58: Batch #193 - Loss: 0.7247917652130127\n",
      "Ep 58: Batch #194 - Loss: 0.6814481616020203\n",
      "Ep 58: Batch #195 - Loss: 0.963787317276001\n",
      "Ep 58: Batch #196 - Loss: 0.8486161231994629\n",
      "Ep 58: Batch #197 - Loss: 0.8829468488693237\n",
      "Ep 58: Batch #198 - Loss: 0.6624547839164734\n",
      "Ep 58: Batch #199 - Loss: 0.8439527153968811\n",
      "Ep 59: Batch #0 - Loss: 0.7730886340141296\n",
      "Ep 59: Batch #1 - Loss: 0.8579881191253662\n",
      "Ep 59: Batch #2 - Loss: 0.9919300675392151\n",
      "Ep 59: Batch #3 - Loss: 0.8490797281265259\n",
      "Ep 59: Batch #4 - Loss: 0.7713804244995117\n",
      "Ep 59: Batch #5 - Loss: 0.6555951237678528\n",
      "Ep 59: Batch #6 - Loss: 0.8616452217102051\n",
      "Ep 59: Batch #7 - Loss: 0.6877022385597229\n",
      "Ep 59: Batch #8 - Loss: 0.7197958827018738\n",
      "Ep 59: Batch #9 - Loss: 1.3734104633331299\n",
      "Ep 59: Batch #10 - Loss: 0.9879859685897827\n",
      "Ep 59: Batch #11 - Loss: 0.6565697193145752\n",
      "Ep 59: Batch #12 - Loss: 1.538203239440918\n",
      "Ep 59: Batch #13 - Loss: 0.6375961303710938\n",
      "Ep 59: Batch #14 - Loss: 0.7135120034217834\n",
      "Ep 59: Batch #15 - Loss: 1.216245174407959\n",
      "Ep 59: Batch #16 - Loss: 1.2499067783355713\n",
      "Ep 59: Batch #17 - Loss: 0.8615763783454895\n",
      "Ep 59: Batch #18 - Loss: 0.9295482039451599\n",
      "Ep 59: Batch #19 - Loss: 0.6555920243263245\n",
      "Ep 59: Batch #20 - Loss: 0.6407971382141113\n",
      "Ep 59: Batch #21 - Loss: 1.194092869758606\n",
      "Ep 59: Batch #22 - Loss: 0.712772011756897\n",
      "Ep 59: Batch #23 - Loss: 0.7265914678573608\n",
      "Ep 59: Batch #24 - Loss: 0.8087818026542664\n",
      "Ep 59: Batch #25 - Loss: 0.6989510655403137\n",
      "Ep 59: Batch #26 - Loss: 0.7130246758460999\n",
      "Ep 59: Batch #27 - Loss: 1.3274073600769043\n",
      "Ep 59: Batch #28 - Loss: 0.8513979911804199\n",
      "Ep 59: Batch #29 - Loss: 0.8726620078086853\n",
      "Ep 59: Batch #30 - Loss: 1.1823292970657349\n",
      "Ep 59: Batch #31 - Loss: 0.6609132289886475\n",
      "Ep 59: Batch #32 - Loss: 0.7307009696960449\n",
      "Ep 59: Batch #33 - Loss: 0.7920608520507812\n",
      "Ep 59: Batch #34 - Loss: 0.7685375213623047\n",
      "Ep 59: Batch #35 - Loss: 0.9266300797462463\n",
      "Ep 59: Batch #36 - Loss: 0.6873206496238708\n",
      "Ep 59: Batch #37 - Loss: 1.122226595878601\n",
      "Ep 59: Batch #38 - Loss: 0.7272035479545593\n",
      "Ep 59: Batch #39 - Loss: 0.8061332702636719\n",
      "Ep 59: Batch #40 - Loss: 0.7575842142105103\n",
      "Ep 59: Batch #41 - Loss: 0.719284176826477\n",
      "Ep 59: Batch #42 - Loss: 0.7073163390159607\n",
      "Ep 59: Batch #43 - Loss: 0.7723479270935059\n",
      "Ep 59: Batch #44 - Loss: 0.7669551968574524\n",
      "Ep 59: Batch #45 - Loss: 0.617639422416687\n",
      "Ep 59: Batch #46 - Loss: 0.8106978535652161\n",
      "Ep 59: Batch #47 - Loss: 0.9373106956481934\n",
      "Ep 59: Batch #48 - Loss: 1.3317806720733643\n",
      "Ep 59: Batch #49 - Loss: 0.98993319272995\n",
      "Ep 59: Batch #50 - Loss: 0.6940118670463562\n",
      "Ep 59: Batch #51 - Loss: 0.9709627032279968\n",
      "Ep 59: Batch #52 - Loss: 0.7798309326171875\n",
      "Ep 59: Batch #53 - Loss: 0.8048384785652161\n",
      "Ep 59: Batch #54 - Loss: 0.6909042596817017\n",
      "Ep 59: Batch #55 - Loss: 0.7344338297843933\n",
      "Ep 59: Batch #56 - Loss: 1.2365273237228394\n",
      "Ep 59: Batch #57 - Loss: 0.82757967710495\n",
      "Ep 59: Batch #58 - Loss: 0.9756003618240356\n",
      "Ep 59: Batch #59 - Loss: 0.6688602566719055\n",
      "Ep 59: Batch #60 - Loss: 1.2893229722976685\n",
      "Ep 59: Batch #61 - Loss: 0.6231127977371216\n",
      "Ep 59: Batch #62 - Loss: 0.7053002119064331\n",
      "Ep 59: Batch #63 - Loss: 0.981863260269165\n",
      "Ep 59: Batch #64 - Loss: 9.4122314453125\n",
      "Ep 59: Batch #65 - Loss: 0.5994730591773987\n",
      "Ep 59: Batch #66 - Loss: 0.7775992155075073\n",
      "Ep 59: Batch #67 - Loss: 0.8916226625442505\n",
      "Ep 59: Batch #68 - Loss: 0.8875133991241455\n",
      "Ep 59: Batch #69 - Loss: 0.728936493396759\n",
      "Ep 59: Batch #70 - Loss: 0.7560119032859802\n",
      "Ep 59: Batch #71 - Loss: 0.6658438444137573\n",
      "Ep 59: Batch #72 - Loss: 0.8357494473457336\n",
      "Ep 59: Batch #73 - Loss: 0.8803417682647705\n",
      "Ep 59: Batch #74 - Loss: 0.7224711775779724\n",
      "Ep 59: Batch #75 - Loss: 0.7530806064605713\n",
      "Ep 59: Batch #76 - Loss: 1.078728199005127\n",
      "Ep 59: Batch #77 - Loss: 0.7175487279891968\n",
      "Ep 59: Batch #78 - Loss: 1.1343706846237183\n",
      "Ep 59: Batch #79 - Loss: 0.6118995547294617\n",
      "Ep 59: Batch #80 - Loss: 0.8390242457389832\n",
      "Ep 59: Batch #81 - Loss: 1.6606571674346924\n",
      "Ep 59: Batch #82 - Loss: 0.856236457824707\n",
      "Ep 59: Batch #83 - Loss: 1.7206029891967773\n",
      "Ep 59: Batch #84 - Loss: 0.6978166699409485\n",
      "Ep 59: Batch #85 - Loss: 0.9577851891517639\n",
      "Ep 59: Batch #86 - Loss: 0.6908710598945618\n",
      "Ep 59: Batch #87 - Loss: 0.6970050930976868\n",
      "Ep 59: Batch #88 - Loss: 0.7833548188209534\n",
      "Ep 59: Batch #89 - Loss: 0.8714447021484375\n",
      "Ep 59: Batch #90 - Loss: 1.1283422708511353\n",
      "Ep 59: Batch #91 - Loss: 0.7822403311729431\n",
      "Ep 59: Batch #92 - Loss: 1.00676429271698\n",
      "Ep 59: Batch #93 - Loss: 1.0038933753967285\n",
      "Ep 59: Batch #94 - Loss: 1.0263737440109253\n",
      "Ep 59: Batch #95 - Loss: 0.9001519680023193\n",
      "Ep 59: Batch #96 - Loss: 0.8863763213157654\n",
      "Ep 59: Batch #97 - Loss: 0.7124354243278503\n",
      "Ep 59: Batch #98 - Loss: 0.7218144536018372\n",
      "Ep 59: Batch #99 - Loss: 0.9395315051078796\n",
      "Ep 59: Batch #100 - Loss: 0.6622139811515808\n",
      "Ep 59: Batch #101 - Loss: 1.027461290359497\n",
      "Ep 59: Batch #102 - Loss: 0.7655146718025208\n",
      "Ep 59: Batch #103 - Loss: 0.7735750675201416\n",
      "Ep 59: Batch #104 - Loss: 0.7840038537979126\n",
      "Ep 59: Batch #105 - Loss: 1.0056840181350708\n",
      "Ep 59: Batch #106 - Loss: 0.7432653307914734\n",
      "Ep 59: Batch #107 - Loss: 0.7402260303497314\n",
      "Ep 59: Batch #108 - Loss: 1.0119489431381226\n",
      "Ep 59: Batch #109 - Loss: 0.7470926642417908\n",
      "Ep 59: Batch #110 - Loss: 0.8958612084388733\n",
      "Ep 59: Batch #111 - Loss: 1.3540369272232056\n",
      "Ep 59: Batch #112 - Loss: 1.025162696838379\n",
      "Ep 59: Batch #113 - Loss: 0.7985177636146545\n",
      "Ep 59: Batch #114 - Loss: 0.882388710975647\n",
      "Ep 59: Batch #115 - Loss: 1.0722838640213013\n",
      "Ep 59: Batch #116 - Loss: 0.6226471662521362\n",
      "Ep 59: Batch #117 - Loss: 0.8553733229637146\n",
      "Ep 59: Batch #118 - Loss: 0.5310353636741638\n",
      "Model saved in file: ./weights_autoencoder_low_LR/model_e59b118_1516651276.6968877.ckpt\n",
      "Ep 59: Batch #119 - Loss: 1.0078226327896118\n",
      "Ep 59: Batch #120 - Loss: 0.7837352752685547\n",
      "Ep 59: Batch #121 - Loss: 0.669750988483429\n",
      "Ep 59: Batch #122 - Loss: 0.8083108067512512\n",
      "Ep 59: Batch #123 - Loss: 0.814102292060852\n",
      "Ep 59: Batch #124 - Loss: 0.6508156657218933\n",
      "Ep 59: Batch #125 - Loss: 2.693822145462036\n",
      "Ep 59: Batch #126 - Loss: 1.2044082880020142\n",
      "Ep 59: Batch #127 - Loss: 0.7304019927978516\n",
      "Ep 59: Batch #128 - Loss: 1.0797817707061768\n",
      "Ep 59: Batch #129 - Loss: 0.8191152811050415\n",
      "Ep 59: Batch #130 - Loss: 0.707160234451294\n",
      "Ep 59: Batch #131 - Loss: 0.9706823229789734\n",
      "Ep 59: Batch #132 - Loss: 0.8045200109481812\n",
      "Ep 59: Batch #133 - Loss: 0.7993919849395752\n",
      "Ep 59: Batch #134 - Loss: 0.7510035037994385\n",
      "Ep 59: Batch #135 - Loss: 0.9432781934738159\n",
      "Ep 59: Batch #136 - Loss: 1.15678071975708\n",
      "Ep 59: Batch #137 - Loss: 0.9429149031639099\n",
      "Ep 59: Batch #138 - Loss: 1.048636794090271\n",
      "Ep 59: Batch #139 - Loss: 0.8795322179794312\n",
      "Ep 59: Batch #140 - Loss: 1.027840256690979\n",
      "Ep 59: Batch #141 - Loss: 1.3353121280670166\n",
      "Ep 59: Batch #142 - Loss: 0.777719259262085\n",
      "Ep 59: Batch #143 - Loss: 0.9413096904754639\n",
      "Ep 59: Batch #144 - Loss: 0.7050779461860657\n",
      "Ep 59: Batch #145 - Loss: 0.6638568043708801\n",
      "Ep 59: Batch #146 - Loss: 0.8665923476219177\n",
      "Ep 59: Batch #147 - Loss: 0.8398849368095398\n",
      "Ep 59: Batch #148 - Loss: 0.9546496868133545\n",
      "Ep 59: Batch #149 - Loss: 0.8335661888122559\n",
      "Ep 59: Batch #150 - Loss: 0.8644627928733826\n",
      "Ep 59: Batch #151 - Loss: 0.7149300575256348\n",
      "Ep 59: Batch #152 - Loss: 0.7263399362564087\n",
      "Ep 59: Batch #153 - Loss: 1.0813713073730469\n",
      "Ep 59: Batch #154 - Loss: 0.7469989061355591\n",
      "Ep 59: Batch #155 - Loss: 0.8159405589103699\n",
      "Ep 59: Batch #156 - Loss: 0.997420608997345\n",
      "Ep 59: Batch #157 - Loss: 0.7448952794075012\n",
      "Ep 59: Batch #158 - Loss: 0.7922922372817993\n",
      "Ep 59: Batch #159 - Loss: 0.7891960144042969\n",
      "Ep 59: Batch #160 - Loss: 0.8877466320991516\n",
      "Ep 59: Batch #161 - Loss: 0.798709511756897\n",
      "Ep 59: Batch #162 - Loss: 0.9129810929298401\n",
      "Ep 59: Batch #163 - Loss: 0.9140075445175171\n",
      "Ep 59: Batch #164 - Loss: 0.7677519917488098\n",
      "Ep 59: Batch #165 - Loss: 1.4802093505859375\n",
      "Ep 59: Batch #166 - Loss: 0.6632187366485596\n",
      "Ep 59: Batch #167 - Loss: 1.0659191608428955\n",
      "Ep 59: Batch #168 - Loss: 0.8415149450302124\n",
      "Ep 59: Batch #169 - Loss: 0.7847256064414978\n",
      "Ep 59: Batch #170 - Loss: 0.7863808274269104\n",
      "Ep 59: Batch #171 - Loss: 0.7615196704864502\n",
      "Ep 59: Batch #172 - Loss: 0.6215112805366516\n",
      "Ep 59: Batch #173 - Loss: 1.1687458753585815\n",
      "Ep 59: Batch #174 - Loss: 0.5667158961296082\n",
      "Ep 59: Batch #175 - Loss: 0.7650853991508484\n",
      "Ep 59: Batch #176 - Loss: 1.128637433052063\n",
      "Ep 59: Batch #177 - Loss: 0.8300423622131348\n",
      "Ep 59: Batch #178 - Loss: 0.7457209229469299\n",
      "Ep 59: Batch #179 - Loss: 0.9183206558227539\n",
      "Ep 59: Batch #180 - Loss: 0.8332352638244629\n",
      "Ep 59: Batch #181 - Loss: 0.9682759642601013\n",
      "Ep 59: Batch #182 - Loss: 0.7510042786598206\n",
      "Ep 59: Batch #183 - Loss: 0.7480996251106262\n",
      "Ep 59: Batch #184 - Loss: 1.0516464710235596\n",
      "Ep 59: Batch #185 - Loss: 0.7418704032897949\n",
      "Ep 59: Batch #186 - Loss: 0.9434590935707092\n",
      "Ep 59: Batch #187 - Loss: 1.1448514461517334\n",
      "Ep 59: Batch #188 - Loss: 1.3314552307128906\n",
      "Ep 59: Batch #189 - Loss: 0.6888707876205444\n",
      "Ep 59: Batch #190 - Loss: 0.7199209332466125\n",
      "Ep 59: Batch #191 - Loss: 1.0422955751419067\n",
      "Ep 59: Batch #192 - Loss: 0.6573794484138489\n",
      "Ep 59: Batch #193 - Loss: 0.723698079586029\n",
      "Ep 59: Batch #194 - Loss: 0.6804388165473938\n",
      "Ep 59: Batch #195 - Loss: 0.9624938368797302\n",
      "Ep 59: Batch #196 - Loss: 0.8473760485649109\n",
      "Ep 59: Batch #197 - Loss: 0.8816070556640625\n",
      "Ep 59: Batch #198 - Loss: 0.6614053845405579\n",
      "Ep 59: Batch #199 - Loss: 0.8427553176879883\n",
      "Ep 60: Batch #0 - Loss: 0.7718166708946228\n",
      "Ep 60: Batch #1 - Loss: 0.856692910194397\n",
      "Ep 60: Batch #2 - Loss: 0.9909139275550842\n",
      "Ep 60: Batch #3 - Loss: 0.8480589985847473\n",
      "Ep 60: Batch #4 - Loss: 0.7702139019966125\n",
      "Ep 60: Batch #5 - Loss: 0.65467768907547\n",
      "Ep 60: Batch #6 - Loss: 0.8604779839515686\n",
      "Ep 60: Batch #7 - Loss: 0.6867358684539795\n",
      "Ep 60: Batch #8 - Loss: 0.7188571095466614\n",
      "Ep 60: Batch #9 - Loss: 1.3716410398483276\n",
      "Ep 60: Batch #10 - Loss: 0.9868025183677673\n",
      "Ep 60: Batch #11 - Loss: 0.6556651592254639\n",
      "Ep 60: Batch #12 - Loss: 1.5368024110794067\n",
      "Ep 60: Batch #13 - Loss: 0.6369244456291199\n",
      "Ep 60: Batch #14 - Loss: 0.7126192450523376\n",
      "Ep 60: Batch #15 - Loss: 1.2144436836242676\n",
      "Ep 60: Batch #16 - Loss: 1.248107671737671\n",
      "Ep 60: Batch #17 - Loss: 0.8603363037109375\n",
      "Ep 60: Batch #18 - Loss: 0.9287863969802856\n",
      "Ep 60: Batch #19 - Loss: 0.654806911945343\n",
      "Ep 60: Batch #20 - Loss: 0.6398862600326538\n",
      "Ep 60: Batch #21 - Loss: 1.1929361820220947\n",
      "Ep 60: Batch #22 - Loss: 0.7119260430335999\n",
      "Ep 60: Batch #23 - Loss: 0.7255165576934814\n",
      "Ep 60: Batch #24 - Loss: 0.8078676462173462\n",
      "Ep 60: Batch #25 - Loss: 0.6979290843009949\n",
      "Ep 60: Batch #26 - Loss: 0.7118579745292664\n",
      "Ep 60: Batch #27 - Loss: 1.3257473707199097\n",
      "Ep 60: Batch #28 - Loss: 0.8504107594490051\n",
      "Ep 60: Batch #29 - Loss: 0.8713292479515076\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 60: Batch #30 - Loss: 1.1808491945266724\n",
      "Ep 60: Batch #31 - Loss: 0.6600435376167297\n",
      "Ep 60: Batch #32 - Loss: 0.7296164035797119\n",
      "Ep 60: Batch #33 - Loss: 0.7910474538803101\n",
      "Ep 60: Batch #34 - Loss: 0.7675660848617554\n",
      "Ep 60: Batch #35 - Loss: 0.9251323342323303\n",
      "Ep 60: Batch #36 - Loss: 0.6863003969192505\n",
      "Ep 60: Batch #37 - Loss: 1.1209982633590698\n",
      "Ep 60: Batch #38 - Loss: 0.7259970903396606\n",
      "Ep 60: Batch #39 - Loss: 0.8052619099617004\n",
      "Ep 60: Batch #40 - Loss: 0.7564941644668579\n",
      "Ep 60: Batch #41 - Loss: 0.7180522084236145\n",
      "Ep 60: Batch #42 - Loss: 0.7062892913818359\n",
      "Ep 60: Batch #43 - Loss: 0.771307647228241\n",
      "Ep 60: Batch #44 - Loss: 0.7657865881919861\n",
      "Ep 60: Batch #45 - Loss: 0.6166092753410339\n",
      "Ep 60: Batch #46 - Loss: 0.8093818426132202\n",
      "Ep 60: Batch #47 - Loss: 0.9357343316078186\n",
      "Ep 60: Batch #48 - Loss: 1.3303773403167725\n",
      "Ep 60: Batch #49 - Loss: 0.9882793426513672\n",
      "Ep 60: Batch #50 - Loss: 0.693223774433136\n",
      "Ep 60: Batch #51 - Loss: 0.9694135189056396\n",
      "Ep 60: Batch #52 - Loss: 0.7788472771644592\n",
      "Ep 60: Batch #53 - Loss: 0.8037015795707703\n",
      "Ep 60: Batch #54 - Loss: 0.6899433135986328\n",
      "Ep 60: Batch #55 - Loss: 0.7333520650863647\n",
      "Ep 60: Batch #56 - Loss: 1.2347283363342285\n",
      "Ep 60: Batch #57 - Loss: 0.8262934684753418\n",
      "Ep 60: Batch #58 - Loss: 0.9739720821380615\n",
      "Ep 60: Batch #59 - Loss: 0.6681323051452637\n",
      "Ep 60: Batch #60 - Loss: 1.2876360416412354\n",
      "Ep 60: Batch #61 - Loss: 0.6222469806671143\n",
      "Ep 60: Batch #62 - Loss: 0.7042001485824585\n",
      "Ep 60: Batch #63 - Loss: 0.9805114269256592\n",
      "Ep 60: Batch #64 - Loss: 9.41112232208252\n",
      "Ep 60: Batch #65 - Loss: 0.5986554026603699\n",
      "Ep 60: Batch #66 - Loss: 0.7763903141021729\n",
      "Ep 60: Batch #67 - Loss: 0.8903730511665344\n",
      "Ep 60: Batch #68 - Loss: 0.886142909526825\n",
      "Ep 60: Batch #69 - Loss: 0.7279371023178101\n",
      "Ep 60: Batch #70 - Loss: 0.7547439932823181\n",
      "Ep 60: Batch #71 - Loss: 0.6649990677833557\n",
      "Ep 60: Batch #72 - Loss: 0.834571123123169\n",
      "Ep 60: Batch #73 - Loss: 0.8788807392120361\n",
      "Ep 60: Batch #74 - Loss: 0.7212480902671814\n",
      "Ep 60: Batch #75 - Loss: 0.7521257400512695\n",
      "Ep 60: Batch #76 - Loss: 1.0776641368865967\n",
      "Ep 60: Batch #77 - Loss: 0.7164338231086731\n",
      "Ep 60: Batch #78 - Loss: 1.1326745748519897\n",
      "Ep 60: Batch #79 - Loss: 0.6109902858734131\n",
      "Ep 60: Batch #80 - Loss: 0.8376582860946655\n",
      "Ep 60: Batch #81 - Loss: 1.6594288349151611\n",
      "Ep 60: Batch #82 - Loss: 0.855116069316864\n",
      "Ep 60: Batch #83 - Loss: 1.7197256088256836\n",
      "Ep 60: Batch #84 - Loss: 0.6967774033546448\n",
      "Ep 60: Batch #85 - Loss: 0.9568305015563965\n",
      "Ep 60: Batch #86 - Loss: 0.6896919012069702\n",
      "Ep 60: Batch #87 - Loss: 0.695991575717926\n",
      "Ep 60: Batch #88 - Loss: 0.7821990847587585\n",
      "Ep 60: Batch #89 - Loss: 0.8707059621810913\n",
      "Ep 60: Batch #90 - Loss: 1.1267091035842896\n",
      "Ep 60: Batch #91 - Loss: 0.780959963798523\n",
      "Ep 60: Batch #92 - Loss: 1.005347728729248\n",
      "Ep 60: Batch #93 - Loss: 1.0022042989730835\n",
      "Ep 60: Batch #94 - Loss: 1.0249183177947998\n",
      "Ep 60: Batch #95 - Loss: 0.8989519476890564\n",
      "Ep 60: Batch #96 - Loss: 0.8852118253707886\n",
      "Ep 60: Batch #97 - Loss: 0.7113420367240906\n",
      "Ep 60: Batch #98 - Loss: 0.7207320928573608\n",
      "Ep 60: Batch #99 - Loss: 0.9382178783416748\n",
      "Ep 60: Batch #100 - Loss: 0.6612059473991394\n",
      "Ep 60: Batch #101 - Loss: 1.0262583494186401\n",
      "Ep 60: Batch #102 - Loss: 0.764396607875824\n",
      "Ep 60: Batch #103 - Loss: 0.77249675989151\n",
      "Ep 60: Batch #104 - Loss: 0.7829046249389648\n",
      "Ep 60: Batch #105 - Loss: 1.0042659044265747\n",
      "Ep 60: Batch #106 - Loss: 0.7422760725021362\n",
      "Ep 60: Batch #107 - Loss: 0.7391192317008972\n",
      "Ep 60: Batch #108 - Loss: 1.0105873346328735\n",
      "Ep 60: Batch #109 - Loss: 0.7461052536964417\n",
      "Ep 60: Batch #110 - Loss: 0.8943787813186646\n",
      "Ep 60: Batch #111 - Loss: 1.3523871898651123\n",
      "Ep 60: Batch #112 - Loss: 1.0237925052642822\n",
      "Ep 60: Batch #113 - Loss: 0.7974086999893188\n",
      "Ep 60: Batch #114 - Loss: 0.8810133934020996\n",
      "Ep 60: Batch #115 - Loss: 1.0709165334701538\n",
      "Ep 60: Batch #116 - Loss: 0.6219825148582458\n",
      "Ep 60: Batch #117 - Loss: 0.8543093204498291\n",
      "Ep 60: Batch #118 - Loss: 0.5302119255065918\n",
      "Model saved in file: ./weights_autoencoder_low_LR/model_e60b118_1516651276.8336003.ckpt\n",
      "Ep 60: Batch #119 - Loss: 1.0065504312515259\n",
      "Ep 60: Batch #120 - Loss: 0.7827066779136658\n",
      "Ep 60: Batch #121 - Loss: 0.6687438488006592\n",
      "Ep 60: Batch #122 - Loss: 0.8072380423545837\n",
      "Ep 60: Batch #123 - Loss: 0.8129730224609375\n",
      "Ep 60: Batch #124 - Loss: 0.6499791741371155\n",
      "Ep 60: Batch #125 - Loss: 2.6920180320739746\n",
      "Ep 60: Batch #126 - Loss: 1.2030400037765503\n",
      "Ep 60: Batch #127 - Loss: 0.7292314171791077\n",
      "Ep 60: Batch #128 - Loss: 1.0780539512634277\n",
      "Ep 60: Batch #129 - Loss: 0.8178693056106567\n",
      "Ep 60: Batch #130 - Loss: 0.7061309814453125\n",
      "Ep 60: Batch #131 - Loss: 0.9690479040145874\n",
      "Ep 60: Batch #132 - Loss: 0.8033059239387512\n",
      "Ep 60: Batch #133 - Loss: 0.7982088923454285\n",
      "Ep 60: Batch #134 - Loss: 0.749862015247345\n",
      "Ep 60: Batch #135 - Loss: 0.941856861114502\n",
      "Ep 60: Batch #136 - Loss: 1.1552551984786987\n",
      "Ep 60: Batch #137 - Loss: 0.9414728879928589\n",
      "Ep 60: Batch #138 - Loss: 1.0472201108932495\n",
      "Ep 60: Batch #139 - Loss: 0.8781705498695374\n",
      "Ep 60: Batch #140 - Loss: 1.0265603065490723\n",
      "Ep 60: Batch #141 - Loss: 1.333635926246643\n",
      "Ep 60: Batch #142 - Loss: 0.7766387462615967\n",
      "Ep 60: Batch #143 - Loss: 0.9397456049919128\n",
      "Ep 60: Batch #144 - Loss: 0.704146146774292\n",
      "Ep 60: Batch #145 - Loss: 0.6629717350006104\n",
      "Ep 60: Batch #146 - Loss: 0.8655131459236145\n",
      "Ep 60: Batch #147 - Loss: 0.8384842276573181\n",
      "Ep 60: Batch #148 - Loss: 0.9531095623970032\n",
      "Ep 60: Batch #149 - Loss: 0.8322535753250122\n",
      "Ep 60: Batch #150 - Loss: 0.8632681965827942\n",
      "Ep 60: Batch #151 - Loss: 0.7141648530960083\n",
      "Ep 60: Batch #152 - Loss: 0.7255290150642395\n",
      "Ep 60: Batch #153 - Loss: 1.079832673072815\n",
      "Ep 60: Batch #154 - Loss: 0.7458903789520264\n",
      "Ep 60: Batch #155 - Loss: 0.8148455023765564\n",
      "Ep 60: Batch #156 - Loss: 0.9961361289024353\n",
      "Ep 60: Batch #157 - Loss: 0.7437812089920044\n",
      "Ep 60: Batch #158 - Loss: 0.7914727330207825\n",
      "Ep 60: Batch #159 - Loss: 0.7878934741020203\n",
      "Ep 60: Batch #160 - Loss: 0.8867712616920471\n",
      "Ep 60: Batch #161 - Loss: 0.7975568771362305\n",
      "Ep 60: Batch #162 - Loss: 0.9117944836616516\n",
      "Ep 60: Batch #163 - Loss: 0.912976861000061\n",
      "Ep 60: Batch #164 - Loss: 0.7666543126106262\n",
      "Ep 60: Batch #165 - Loss: 1.4791288375854492\n",
      "Ep 60: Batch #166 - Loss: 0.6622035503387451\n",
      "Ep 60: Batch #167 - Loss: 1.064475655555725\n",
      "Ep 60: Batch #168 - Loss: 0.8402709364891052\n",
      "Ep 60: Batch #169 - Loss: 0.7836772203445435\n",
      "Ep 60: Batch #170 - Loss: 0.7852795720100403\n",
      "Ep 60: Batch #171 - Loss: 0.7602702379226685\n",
      "Ep 60: Batch #172 - Loss: 0.6207482814788818\n",
      "Ep 60: Batch #173 - Loss: 1.1669197082519531\n",
      "Ep 60: Batch #174 - Loss: 0.5659381151199341\n",
      "Ep 60: Batch #175 - Loss: 0.7642647624015808\n",
      "Ep 60: Batch #176 - Loss: 1.126878023147583\n",
      "Ep 60: Batch #177 - Loss: 0.828866720199585\n",
      "Ep 60: Batch #178 - Loss: 0.7446464896202087\n",
      "Ep 60: Batch #179 - Loss: 0.9170475006103516\n",
      "Ep 60: Batch #180 - Loss: 0.8318390846252441\n",
      "Ep 60: Batch #181 - Loss: 0.9667701721191406\n",
      "Ep 60: Batch #182 - Loss: 0.7501511573791504\n",
      "Ep 60: Batch #183 - Loss: 0.747105598449707\n",
      "Ep 60: Batch #184 - Loss: 1.0505176782608032\n",
      "Ep 60: Batch #185 - Loss: 0.740788996219635\n",
      "Ep 60: Batch #186 - Loss: 0.9419443011283875\n",
      "Ep 60: Batch #187 - Loss: 1.143154501914978\n",
      "Ep 60: Batch #188 - Loss: 1.3303390741348267\n",
      "Ep 60: Batch #189 - Loss: 0.6880967020988464\n",
      "Ep 60: Batch #190 - Loss: 0.7189934849739075\n",
      "Ep 60: Batch #191 - Loss: 1.0407817363739014\n",
      "Ep 60: Batch #192 - Loss: 0.6566121578216553\n",
      "Ep 60: Batch #193 - Loss: 0.7226160764694214\n",
      "Ep 60: Batch #194 - Loss: 0.6794360876083374\n",
      "Ep 60: Batch #195 - Loss: 0.9612123370170593\n",
      "Ep 60: Batch #196 - Loss: 0.8461294770240784\n",
      "Ep 60: Batch #197 - Loss: 0.8802603483200073\n",
      "Ep 60: Batch #198 - Loss: 0.6603530049324036\n",
      "Ep 60: Batch #199 - Loss: 0.8415754437446594\n",
      "Ep 61: Batch #0 - Loss: 0.7705507278442383\n",
      "Ep 61: Batch #1 - Loss: 0.8553959131240845\n",
      "Ep 61: Batch #2 - Loss: 0.989913821220398\n",
      "Ep 61: Batch #3 - Loss: 0.847032904624939\n",
      "Ep 61: Batch #4 - Loss: 0.7690474390983582\n",
      "Ep 61: Batch #5 - Loss: 0.653766393661499\n",
      "Ep 61: Batch #6 - Loss: 0.8593156337738037\n",
      "Ep 61: Batch #7 - Loss: 0.6857810020446777\n",
      "Ep 61: Batch #8 - Loss: 0.7178791165351868\n",
      "Ep 61: Batch #9 - Loss: 1.369857907295227\n",
      "Ep 61: Batch #10 - Loss: 0.9856324195861816\n",
      "Ep 61: Batch #11 - Loss: 0.6547680497169495\n",
      "Ep 61: Batch #12 - Loss: 1.5354303121566772\n",
      "Ep 61: Batch #13 - Loss: 0.6362600922584534\n",
      "Ep 61: Batch #14 - Loss: 0.711731493473053\n",
      "Ep 61: Batch #15 - Loss: 1.2126554250717163\n",
      "Ep 61: Batch #16 - Loss: 1.2463159561157227\n",
      "Ep 61: Batch #17 - Loss: 0.8591020107269287\n",
      "Ep 61: Batch #18 - Loss: 0.9280331134796143\n",
      "Ep 61: Batch #19 - Loss: 0.6540297269821167\n",
      "Ep 61: Batch #20 - Loss: 0.6389754414558411\n",
      "Ep 61: Batch #21 - Loss: 1.1917916536331177\n",
      "Ep 61: Batch #22 - Loss: 0.7111140489578247\n",
      "Ep 61: Batch #23 - Loss: 0.7244551777839661\n",
      "Ep 61: Batch #24 - Loss: 0.8069605231285095\n",
      "Ep 61: Batch #25 - Loss: 0.6969305872917175\n",
      "Ep 61: Batch #26 - Loss: 0.7106971144676208\n",
      "Ep 61: Batch #27 - Loss: 1.3240879774093628\n",
      "Ep 61: Batch #28 - Loss: 0.84943687915802\n",
      "Ep 61: Batch #29 - Loss: 0.8700125217437744\n",
      "Ep 61: Batch #30 - Loss: 1.1793737411499023\n",
      "Ep 61: Batch #31 - Loss: 0.6591768860816956\n",
      "Ep 61: Batch #32 - Loss: 0.7285458445549011\n",
      "Ep 61: Batch #33 - Loss: 0.7900458574295044\n",
      "Ep 61: Batch #34 - Loss: 0.7665945291519165\n",
      "Ep 61: Batch #35 - Loss: 0.9236534237861633\n",
      "Ep 61: Batch #36 - Loss: 0.6852875351905823\n",
      "Ep 61: Batch #37 - Loss: 1.1197763681411743\n",
      "Ep 61: Batch #38 - Loss: 0.7247991561889648\n",
      "Ep 61: Batch #39 - Loss: 0.8043912053108215\n",
      "Ep 61: Batch #40 - Loss: 0.7554174065589905\n",
      "Ep 61: Batch #41 - Loss: 0.7168393135070801\n",
      "Ep 61: Batch #42 - Loss: 0.7052666544914246\n",
      "Ep 61: Batch #43 - Loss: 0.7702778577804565\n",
      "Ep 61: Batch #44 - Loss: 0.7646292448043823\n",
      "Ep 61: Batch #45 - Loss: 0.6155962347984314\n",
      "Ep 61: Batch #46 - Loss: 0.8080832362174988\n",
      "Ep 61: Batch #47 - Loss: 0.9341703057289124\n",
      "Ep 61: Batch #48 - Loss: 1.3289953470230103\n",
      "Ep 61: Batch #49 - Loss: 0.9866479635238647\n",
      "Ep 61: Batch #50 - Loss: 0.6924363374710083\n",
      "Ep 61: Batch #51 - Loss: 0.9678773880004883\n",
      "Ep 61: Batch #52 - Loss: 0.7778703570365906\n",
      "Ep 61: Batch #53 - Loss: 0.8025729060173035\n",
      "Ep 61: Batch #54 - Loss: 0.6889888048171997\n",
      "Ep 61: Batch #55 - Loss: 0.7322808504104614\n",
      "Ep 61: Batch #56 - Loss: 1.232934594154358\n",
      "Ep 61: Batch #57 - Loss: 0.8250254392623901\n",
      "Ep 61: Batch #58 - Loss: 0.9723327159881592\n",
      "Ep 61: Batch #59 - Loss: 0.6674053072929382\n",
      "Ep 61: Batch #60 - Loss: 1.2858964204788208\n",
      "Ep 61: Batch #61 - Loss: 0.6213893294334412\n",
      "Ep 61: Batch #62 - Loss: 0.703115701675415\n",
      "Ep 61: Batch #63 - Loss: 0.9791663289070129\n",
      "Ep 61: Batch #64 - Loss: 9.410028457641602\n",
      "Ep 61: Batch #65 - Loss: 0.597847044467926\n",
      "Ep 61: Batch #66 - Loss: 0.775198757648468\n",
      "Ep 61: Batch #67 - Loss: 0.8891422152519226\n",
      "Ep 61: Batch #68 - Loss: 0.8847879767417908\n",
      "Ep 61: Batch #69 - Loss: 0.7269421219825745\n",
      "Ep 61: Batch #70 - Loss: 0.7534758448600769\n",
      "Ep 61: Batch #71 - Loss: 0.6641584038734436\n",
      "Ep 61: Batch #72 - Loss: 0.8333936929702759\n",
      "Ep 61: Batch #73 - Loss: 0.8774353265762329\n",
      "Ep 61: Batch #74 - Loss: 0.7200323939323425\n",
      "Ep 61: Batch #75 - Loss: 0.7511515021324158\n",
      "Ep 61: Batch #76 - Loss: 1.07660973072052\n",
      "Ep 61: Batch #77 - Loss: 0.7153316140174866\n",
      "Ep 61: Batch #78 - Loss: 1.1309870481491089\n",
      "Ep 61: Batch #79 - Loss: 0.6100903749465942\n",
      "Ep 61: Batch #80 - Loss: 0.8362945914268494\n",
      "Ep 61: Batch #81 - Loss: 1.6582062244415283\n",
      "Ep 61: Batch #82 - Loss: 0.8540058732032776\n",
      "Ep 61: Batch #83 - Loss: 1.7188568115234375\n",
      "Ep 61: Batch #84 - Loss: 0.6957446932792664\n",
      "Ep 61: Batch #85 - Loss: 0.9559294581413269\n",
      "Ep 61: Batch #86 - Loss: 0.6885247826576233\n",
      "Ep 61: Batch #87 - Loss: 0.6949650049209595\n",
      "Ep 61: Batch #88 - Loss: 0.7810347080230713\n",
      "Ep 61: Batch #89 - Loss: 0.8699852228164673\n",
      "Ep 61: Batch #90 - Loss: 1.1250855922698975\n",
      "Ep 61: Batch #91 - Loss: 0.7796915173530579\n",
      "Ep 61: Batch #92 - Loss: 1.0039397478103638\n",
      "Ep 61: Batch #93 - Loss: 1.0005139112472534\n",
      "Ep 61: Batch #94 - Loss: 1.0234729051589966\n",
      "Ep 61: Batch #95 - Loss: 0.8977660536766052\n",
      "Ep 61: Batch #96 - Loss: 0.884050190448761\n",
      "Ep 61: Batch #97 - Loss: 0.7102510929107666\n",
      "Ep 61: Batch #98 - Loss: 0.7196601033210754\n",
      "Ep 61: Batch #99 - Loss: 0.9369123578071594\n",
      "Ep 61: Batch #100 - Loss: 0.660192608833313\n",
      "Ep 61: Batch #101 - Loss: 1.0250699520111084\n",
      "Ep 61: Batch #102 - Loss: 0.7632870078086853\n",
      "Ep 61: Batch #103 - Loss: 0.7714306712150574\n",
      "Ep 61: Batch #104 - Loss: 0.7818160653114319\n",
      "Ep 61: Batch #105 - Loss: 1.0028746128082275\n",
      "Ep 61: Batch #106 - Loss: 0.7412962913513184\n",
      "Ep 61: Batch #107 - Loss: 0.7380221486091614\n",
      "Ep 61: Batch #108 - Loss: 1.0092358589172363\n",
      "Ep 61: Batch #109 - Loss: 0.7451127171516418\n",
      "Ep 61: Batch #110 - Loss: 0.8929066061973572\n",
      "Ep 61: Batch #111 - Loss: 1.3507498502731323\n",
      "Ep 61: Batch #112 - Loss: 1.0224947929382324\n",
      "Ep 61: Batch #113 - Loss: 0.7963030934333801\n",
      "Ep 61: Batch #114 - Loss: 0.8796481490135193\n",
      "Ep 61: Batch #115 - Loss: 1.069553017616272\n",
      "Ep 61: Batch #116 - Loss: 0.6213201284408569\n",
      "Ep 61: Batch #117 - Loss: 0.8532440662384033\n",
      "Ep 61: Batch #118 - Loss: 0.5294008851051331\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved in file: ./weights_autoencoder_low_LR/model_e61b118_1516651276.970165.ckpt\n",
      "Ep 61: Batch #119 - Loss: 1.005281686782837\n",
      "Ep 61: Batch #120 - Loss: 0.7816892862319946\n",
      "Ep 61: Batch #121 - Loss: 0.6677493453025818\n",
      "Ep 61: Batch #122 - Loss: 0.8061732649803162\n",
      "Ep 61: Batch #123 - Loss: 0.8118570446968079\n",
      "Ep 61: Batch #124 - Loss: 0.6491458415985107\n",
      "Ep 61: Batch #125 - Loss: 2.690274715423584\n",
      "Ep 61: Batch #126 - Loss: 1.2014418840408325\n",
      "Ep 61: Batch #127 - Loss: 0.7280558347702026\n",
      "Ep 61: Batch #128 - Loss: 1.0763146877288818\n",
      "Ep 61: Batch #129 - Loss: 0.8166332244873047\n",
      "Ep 61: Batch #130 - Loss: 0.7051085233688354\n",
      "Ep 61: Batch #131 - Loss: 0.9674233794212341\n",
      "Ep 61: Batch #132 - Loss: 0.8021021485328674\n",
      "Ep 61: Batch #133 - Loss: 0.7970200777053833\n",
      "Ep 61: Batch #134 - Loss: 0.7487236857414246\n",
      "Ep 61: Batch #135 - Loss: 0.9404573440551758\n",
      "Ep 61: Batch #136 - Loss: 1.1537415981292725\n",
      "Ep 61: Batch #137 - Loss: 0.9400447607040405\n",
      "Ep 61: Batch #138 - Loss: 1.0458154678344727\n",
      "Ep 61: Batch #139 - Loss: 0.8768005967140198\n",
      "Ep 61: Batch #140 - Loss: 1.0252965688705444\n",
      "Ep 61: Batch #141 - Loss: 1.331932544708252\n",
      "Ep 61: Batch #142 - Loss: 0.7755610346794128\n",
      "Ep 61: Batch #143 - Loss: 0.938194990158081\n",
      "Ep 61: Batch #144 - Loss: 0.7032228112220764\n",
      "Ep 61: Batch #145 - Loss: 0.6620943546295166\n",
      "Ep 61: Batch #146 - Loss: 0.8644436597824097\n",
      "Ep 61: Batch #147 - Loss: 0.8370968699455261\n",
      "Ep 61: Batch #148 - Loss: 0.9515798091888428\n",
      "Ep 61: Batch #149 - Loss: 0.830948531627655\n",
      "Ep 61: Batch #150 - Loss: 0.8620898723602295\n",
      "Ep 61: Batch #151 - Loss: 0.7133970260620117\n",
      "Ep 61: Batch #152 - Loss: 0.7247274518013\n",
      "Ep 61: Batch #153 - Loss: 1.0782753229141235\n",
      "Ep 61: Batch #154 - Loss: 0.7447919249534607\n",
      "Ep 61: Batch #155 - Loss: 0.8137564659118652\n",
      "Ep 61: Batch #156 - Loss: 0.9948635697364807\n",
      "Ep 61: Batch #157 - Loss: 0.7426795363426208\n",
      "Ep 61: Batch #158 - Loss: 0.7906492352485657\n",
      "Ep 61: Batch #159 - Loss: 0.7866012454032898\n",
      "Ep 61: Batch #160 - Loss: 0.8857941627502441\n",
      "Ep 61: Batch #161 - Loss: 0.7964090704917908\n",
      "Ep 61: Batch #162 - Loss: 0.9106188416481018\n",
      "Ep 61: Batch #163 - Loss: 0.9119553565979004\n",
      "Ep 61: Batch #164 - Loss: 0.7655625343322754\n",
      "Ep 61: Batch #165 - Loss: 1.4780666828155518\n",
      "Ep 61: Batch #166 - Loss: 0.6611970663070679\n",
      "Ep 61: Batch #167 - Loss: 1.0630544424057007\n",
      "Ep 61: Batch #168 - Loss: 0.839000940322876\n",
      "Ep 61: Batch #169 - Loss: 0.7826348543167114\n",
      "Ep 61: Batch #170 - Loss: 0.7841825485229492\n",
      "Ep 61: Batch #171 - Loss: 0.7590333819389343\n",
      "Ep 61: Batch #172 - Loss: 0.6199948787689209\n",
      "Ep 61: Batch #173 - Loss: 1.1651057004928589\n",
      "Ep 61: Batch #174 - Loss: 0.5651634931564331\n",
      "Ep 61: Batch #175 - Loss: 0.7634451389312744\n",
      "Ep 61: Batch #176 - Loss: 1.1251472234725952\n",
      "Ep 61: Batch #177 - Loss: 0.827723503112793\n",
      "Ep 61: Batch #178 - Loss: 0.74358069896698\n",
      "Ep 61: Batch #179 - Loss: 0.9157928824424744\n",
      "Ep 61: Batch #180 - Loss: 0.8304473161697388\n",
      "Ep 61: Batch #181 - Loss: 0.9652753472328186\n",
      "Ep 61: Batch #182 - Loss: 0.7492952346801758\n",
      "Ep 61: Batch #183 - Loss: 0.7461341023445129\n",
      "Ep 61: Batch #184 - Loss: 1.049391746520996\n",
      "Ep 61: Batch #185 - Loss: 0.7397186160087585\n",
      "Ep 61: Batch #186 - Loss: 0.9404363036155701\n",
      "Ep 61: Batch #187 - Loss: 1.1414744853973389\n",
      "Ep 61: Batch #188 - Loss: 1.3291646242141724\n",
      "Ep 61: Batch #189 - Loss: 0.6873365044593811\n",
      "Ep 61: Batch #190 - Loss: 0.7180659174919128\n",
      "Ep 61: Batch #191 - Loss: 1.0392754077911377\n",
      "Ep 61: Batch #192 - Loss: 0.6558709740638733\n",
      "Ep 61: Batch #193 - Loss: 0.7215494513511658\n",
      "Ep 61: Batch #194 - Loss: 0.6784301996231079\n",
      "Ep 61: Batch #195 - Loss: 0.9599317908287048\n",
      "Ep 61: Batch #196 - Loss: 0.8448601365089417\n",
      "Ep 61: Batch #197 - Loss: 0.8789116144180298\n",
      "Ep 61: Batch #198 - Loss: 0.6593188643455505\n",
      "Ep 61: Batch #199 - Loss: 0.8404099941253662\n",
      "Ep 62: Batch #0 - Loss: 0.7692875862121582\n",
      "Ep 62: Batch #1 - Loss: 0.8540887832641602\n",
      "Ep 62: Batch #2 - Loss: 0.9889229536056519\n",
      "Ep 62: Batch #3 - Loss: 0.8459609746932983\n",
      "Ep 62: Batch #4 - Loss: 0.7678871750831604\n",
      "Ep 62: Batch #5 - Loss: 0.6528589725494385\n",
      "Ep 62: Batch #6 - Loss: 0.858161985874176\n",
      "Ep 62: Batch #7 - Loss: 0.6848357319831848\n",
      "Ep 62: Batch #8 - Loss: 0.7168518304824829\n",
      "Ep 62: Batch #9 - Loss: 1.3680806159973145\n",
      "Ep 62: Batch #10 - Loss: 0.9844649434089661\n",
      "Ep 62: Batch #11 - Loss: 0.6538878083229065\n",
      "Ep 62: Batch #12 - Loss: 1.5340746641159058\n",
      "Ep 62: Batch #13 - Loss: 0.6356024742126465\n",
      "Ep 62: Batch #14 - Loss: 0.7108527421951294\n",
      "Ep 62: Batch #15 - Loss: 1.2108874320983887\n",
      "Ep 62: Batch #16 - Loss: 1.244537353515625\n",
      "Ep 62: Batch #17 - Loss: 0.857877254486084\n",
      "Ep 62: Batch #18 - Loss: 0.9272845387458801\n",
      "Ep 62: Batch #19 - Loss: 0.6532601714134216\n",
      "Ep 62: Batch #20 - Loss: 0.638064444065094\n",
      "Ep 62: Batch #21 - Loss: 1.1906507015228271\n",
      "Ep 62: Batch #22 - Loss: 0.7102998495101929\n",
      "Ep 62: Batch #23 - Loss: 0.723385214805603\n",
      "Ep 62: Batch #24 - Loss: 0.8060613870620728\n",
      "Ep 62: Batch #25 - Loss: 0.6959433555603027\n",
      "Ep 62: Batch #26 - Loss: 0.7095388174057007\n",
      "Ep 62: Batch #27 - Loss: 1.322434425354004\n",
      "Ep 62: Batch #28 - Loss: 0.8485094308853149\n",
      "Ep 62: Batch #29 - Loss: 0.8687095046043396\n",
      "Ep 62: Batch #30 - Loss: 1.1779141426086426\n",
      "Ep 62: Batch #31 - Loss: 0.6583075523376465\n",
      "Ep 62: Batch #32 - Loss: 0.7274904847145081\n",
      "Ep 62: Batch #33 - Loss: 0.7890510559082031\n",
      "Ep 62: Batch #34 - Loss: 0.7656053304672241\n",
      "Ep 62: Batch #35 - Loss: 0.9221963286399841\n",
      "Ep 62: Batch #36 - Loss: 0.6842719912528992\n",
      "Ep 62: Batch #37 - Loss: 1.1185659170150757\n",
      "Ep 62: Batch #38 - Loss: 0.7236080765724182\n",
      "Ep 62: Batch #39 - Loss: 0.803503155708313\n",
      "Ep 62: Batch #40 - Loss: 0.7543472051620483\n",
      "Ep 62: Batch #41 - Loss: 0.7156201004981995\n",
      "Ep 62: Batch #42 - Loss: 0.7042391300201416\n",
      "Ep 62: Batch #43 - Loss: 0.7692596912384033\n",
      "Ep 62: Batch #44 - Loss: 0.7634701728820801\n",
      "Ep 62: Batch #45 - Loss: 0.6145815253257751\n",
      "Ep 62: Batch #46 - Loss: 0.8068033456802368\n",
      "Ep 62: Batch #47 - Loss: 0.9326134324073792\n",
      "Ep 62: Batch #48 - Loss: 1.327629804611206\n",
      "Ep 62: Batch #49 - Loss: 0.9850316047668457\n",
      "Ep 62: Batch #50 - Loss: 0.6916458010673523\n",
      "Ep 62: Batch #51 - Loss: 0.9663230776786804\n",
      "Ep 62: Batch #52 - Loss: 0.7769004106521606\n",
      "Ep 62: Batch #53 - Loss: 0.801453173160553\n",
      "Ep 62: Batch #54 - Loss: 0.6880417466163635\n",
      "Ep 62: Batch #55 - Loss: 0.7312120199203491\n",
      "Ep 62: Batch #56 - Loss: 1.23114013671875\n",
      "Ep 62: Batch #57 - Loss: 0.8237627744674683\n",
      "Ep 62: Batch #58 - Loss: 0.9707035422325134\n",
      "Ep 62: Batch #59 - Loss: 0.6666644215583801\n",
      "Ep 62: Batch #60 - Loss: 1.284132957458496\n",
      "Ep 62: Batch #61 - Loss: 0.6205347180366516\n",
      "Ep 62: Batch #62 - Loss: 0.7020282745361328\n",
      "Ep 62: Batch #63 - Loss: 0.9778285622596741\n",
      "Ep 62: Batch #64 - Loss: 9.408920288085938\n",
      "Ep 62: Batch #65 - Loss: 0.5970488786697388\n",
      "Ep 62: Batch #66 - Loss: 0.7740302681922913\n",
      "Ep 62: Batch #67 - Loss: 0.8878950476646423\n",
      "Ep 62: Batch #68 - Loss: 0.883421778678894\n",
      "Ep 62: Batch #69 - Loss: 0.725951075553894\n",
      "Ep 62: Batch #70 - Loss: 0.752200722694397\n",
      "Ep 62: Batch #71 - Loss: 0.663329541683197\n",
      "Ep 62: Batch #72 - Loss: 0.832219660282135\n",
      "Ep 62: Batch #73 - Loss: 0.875986635684967\n",
      "Ep 62: Batch #74 - Loss: 0.718810498714447\n",
      "Ep 62: Batch #75 - Loss: 0.7501764297485352\n",
      "Ep 62: Batch #76 - Loss: 1.0754975080490112\n",
      "Ep 62: Batch #77 - Loss: 0.7142336964607239\n",
      "Ep 62: Batch #78 - Loss: 1.1292990446090698\n",
      "Ep 62: Batch #79 - Loss: 0.6091880798339844\n",
      "Ep 62: Batch #80 - Loss: 0.8349275588989258\n",
      "Ep 62: Batch #81 - Loss: 1.6569952964782715\n",
      "Ep 62: Batch #82 - Loss: 0.8528895974159241\n",
      "Ep 62: Batch #83 - Loss: 1.7179782390594482\n",
      "Ep 62: Batch #84 - Loss: 0.694709837436676\n",
      "Ep 62: Batch #85 - Loss: 0.9550260901451111\n",
      "Ep 62: Batch #86 - Loss: 0.6873552203178406\n",
      "Ep 62: Batch #87 - Loss: 0.693931519985199\n",
      "Ep 62: Batch #88 - Loss: 0.7798277735710144\n",
      "Ep 62: Batch #89 - Loss: 0.8692511320114136\n",
      "Ep 62: Batch #90 - Loss: 1.1234667301177979\n",
      "Ep 62: Batch #91 - Loss: 0.778439998626709\n",
      "Ep 62: Batch #92 - Loss: 1.0025371313095093\n",
      "Ep 62: Batch #93 - Loss: 0.9988126754760742\n",
      "Ep 62: Batch #94 - Loss: 1.0220426321029663\n",
      "Ep 62: Batch #95 - Loss: 0.8965938687324524\n",
      "Ep 62: Batch #96 - Loss: 0.8828717470169067\n",
      "Ep 62: Batch #97 - Loss: 0.7091349363327026\n",
      "Ep 62: Batch #98 - Loss: 0.7185808420181274\n",
      "Ep 62: Batch #99 - Loss: 0.9356086254119873\n",
      "Ep 62: Batch #100 - Loss: 0.6591802835464478\n",
      "Ep 62: Batch #101 - Loss: 1.023883581161499\n",
      "Ep 62: Batch #102 - Loss: 0.7621938586235046\n",
      "Ep 62: Batch #103 - Loss: 0.7703573107719421\n",
      "Ep 62: Batch #104 - Loss: 0.7807303667068481\n",
      "Ep 62: Batch #105 - Loss: 1.0014804601669312\n",
      "Ep 62: Batch #106 - Loss: 0.7403073310852051\n",
      "Ep 62: Batch #107 - Loss: 0.7369239330291748\n",
      "Ep 62: Batch #108 - Loss: 1.0078790187835693\n",
      "Ep 62: Batch #109 - Loss: 0.7440969944000244\n",
      "Ep 62: Batch #110 - Loss: 0.8914285898208618\n",
      "Ep 62: Batch #111 - Loss: 1.3491305112838745\n",
      "Ep 62: Batch #112 - Loss: 1.0211893320083618\n",
      "Ep 62: Batch #113 - Loss: 0.7952045798301697\n",
      "Ep 62: Batch #114 - Loss: 0.8782601356506348\n",
      "Ep 62: Batch #115 - Loss: 1.0681990385055542\n",
      "Ep 62: Batch #116 - Loss: 0.6206294298171997\n",
      "Ep 62: Batch #117 - Loss: 0.8521708250045776\n",
      "Ep 62: Batch #118 - Loss: 0.5285950303077698\n",
      "Model saved in file: ./weights_autoencoder_low_LR/model_e62b118_1516651277.1059544.ckpt\n",
      "Ep 62: Batch #119 - Loss: 1.0040029287338257\n",
      "Ep 62: Batch #120 - Loss: 0.7806878685951233\n",
      "Ep 62: Batch #121 - Loss: 0.6667559742927551\n",
      "Ep 62: Batch #122 - Loss: 0.805115282535553\n",
      "Ep 62: Batch #123 - Loss: 0.8107057213783264\n",
      "Ep 62: Batch #124 - Loss: 0.6483081579208374\n",
      "Ep 62: Batch #125 - Loss: 2.688568592071533\n",
      "Ep 62: Batch #126 - Loss: 1.1997909545898438\n",
      "Ep 62: Batch #127 - Loss: 0.726883590221405\n",
      "Ep 62: Batch #128 - Loss: 1.0745465755462646\n",
      "Ep 62: Batch #129 - Loss: 0.8153941035270691\n",
      "Ep 62: Batch #130 - Loss: 0.7040954232215881\n",
      "Ep 62: Batch #131 - Loss: 0.9657582640647888\n",
      "Ep 62: Batch #132 - Loss: 0.8008981347084045\n",
      "Ep 62: Batch #133 - Loss: 0.7958092093467712\n",
      "Ep 62: Batch #134 - Loss: 0.7475709319114685\n",
      "Ep 62: Batch #135 - Loss: 0.9390037655830383\n",
      "Ep 62: Batch #136 - Loss: 1.1522386074066162\n",
      "Ep 62: Batch #137 - Loss: 0.9386149644851685\n",
      "Ep 62: Batch #138 - Loss: 1.0443925857543945\n",
      "Ep 62: Batch #139 - Loss: 0.8754448890686035\n",
      "Ep 62: Batch #140 - Loss: 1.024040937423706\n",
      "Ep 62: Batch #141 - Loss: 1.3302290439605713\n",
      "Ep 62: Batch #142 - Loss: 0.7744848132133484\n",
      "Ep 62: Batch #143 - Loss: 0.9366122484207153\n",
      "Ep 62: Batch #144 - Loss: 0.7022911310195923\n",
      "Ep 62: Batch #145 - Loss: 0.6612271666526794\n",
      "Ep 62: Batch #146 - Loss: 0.8633871078491211\n",
      "Ep 62: Batch #147 - Loss: 0.8356916308403015\n",
      "Ep 62: Batch #148 - Loss: 0.9500433206558228\n",
      "Ep 62: Batch #149 - Loss: 0.8296292424201965\n",
      "Ep 62: Batch #150 - Loss: 0.8609347939491272\n",
      "Ep 62: Batch #151 - Loss: 0.7126302719116211\n",
      "Ep 62: Batch #152 - Loss: 0.7239319086074829\n",
      "Ep 62: Batch #153 - Loss: 1.0766911506652832\n",
      "Ep 62: Batch #154 - Loss: 0.7436962723731995\n",
      "Ep 62: Batch #155 - Loss: 0.8126822113990784\n",
      "Ep 62: Batch #156 - Loss: 0.993582546710968\n",
      "Ep 62: Batch #157 - Loss: 0.741538941860199\n",
      "Ep 62: Batch #158 - Loss: 0.7898232936859131\n",
      "Ep 62: Batch #159 - Loss: 0.7852570414543152\n",
      "Ep 62: Batch #160 - Loss: 0.8848434090614319\n",
      "Ep 62: Batch #161 - Loss: 0.795221745967865\n",
      "Ep 62: Batch #162 - Loss: 0.9094134569168091\n",
      "Ep 62: Batch #163 - Loss: 0.9109464287757874\n",
      "Ep 62: Batch #164 - Loss: 0.7643797397613525\n",
      "Ep 62: Batch #165 - Loss: 1.4769967794418335\n",
      "Ep 62: Batch #166 - Loss: 0.6601592302322388\n",
      "Ep 62: Batch #167 - Loss: 1.0616228580474854\n",
      "Ep 62: Batch #168 - Loss: 0.8377304077148438\n",
      "Ep 62: Batch #169 - Loss: 0.7815596461296082\n",
      "Ep 62: Batch #170 - Loss: 0.7830570340156555\n",
      "Ep 62: Batch #171 - Loss: 0.7577792406082153\n",
      "Ep 62: Batch #172 - Loss: 0.6192499399185181\n",
      "Ep 62: Batch #173 - Loss: 1.1633424758911133\n",
      "Ep 62: Batch #174 - Loss: 0.564373791217804\n",
      "Ep 62: Batch #175 - Loss: 0.7626543641090393\n",
      "Ep 62: Batch #176 - Loss: 1.123428463935852\n",
      "Ep 62: Batch #177 - Loss: 0.8265605568885803\n",
      "Ep 62: Batch #178 - Loss: 0.7424549460411072\n",
      "Ep 62: Batch #179 - Loss: 0.9145280122756958\n",
      "Ep 62: Batch #180 - Loss: 0.8290224671363831\n",
      "Ep 62: Batch #181 - Loss: 0.96379554271698\n",
      "Ep 62: Batch #182 - Loss: 0.7483643889427185\n",
      "Ep 62: Batch #183 - Loss: 0.745185911655426\n",
      "Ep 62: Batch #184 - Loss: 1.0482927560806274\n",
      "Ep 62: Batch #185 - Loss: 0.7385805249214172\n",
      "Ep 62: Batch #186 - Loss: 0.9389082193374634\n",
      "Ep 62: Batch #187 - Loss: 1.1397954225540161\n",
      "Ep 62: Batch #188 - Loss: 1.3279564380645752\n",
      "Ep 62: Batch #189 - Loss: 0.6865467429161072\n",
      "Ep 62: Batch #190 - Loss: 0.7171019911766052\n",
      "Ep 62: Batch #191 - Loss: 1.0377627611160278\n",
      "Ep 62: Batch #192 - Loss: 0.6551291346549988\n",
      "Ep 62: Batch #193 - Loss: 0.7204239964485168\n",
      "Ep 62: Batch #194 - Loss: 0.6773996949195862\n",
      "Ep 62: Batch #195 - Loss: 0.9586502313613892\n",
      "Ep 62: Batch #196 - Loss: 0.8435518741607666\n",
      "Ep 62: Batch #197 - Loss: 0.8775308728218079\n",
      "Ep 62: Batch #198 - Loss: 0.6582772135734558\n",
      "Ep 62: Batch #199 - Loss: 0.8392369151115417\n",
      "Ep 63: Batch #0 - Loss: 0.7680196762084961\n",
      "Ep 63: Batch #1 - Loss: 0.8527472615242004\n",
      "Ep 63: Batch #2 - Loss: 0.9879271388053894\n",
      "Ep 63: Batch #3 - Loss: 0.8448842167854309\n",
      "Ep 63: Batch #4 - Loss: 0.7667096853256226\n",
      "Ep 63: Batch #5 - Loss: 0.6519143581390381\n",
      "Ep 63: Batch #6 - Loss: 0.8569926619529724\n",
      "Ep 63: Batch #7 - Loss: 0.6839101910591125\n",
      "Ep 63: Batch #8 - Loss: 0.7157553434371948\n",
      "Ep 63: Batch #9 - Loss: 1.3663206100463867\n",
      "Ep 63: Batch #10 - Loss: 0.983259379863739\n",
      "Ep 63: Batch #11 - Loss: 0.6530039310455322\n",
      "Ep 63: Batch #12 - Loss: 1.5327223539352417\n",
      "Ep 63: Batch #13 - Loss: 0.6348683834075928\n",
      "Ep 63: Batch #14 - Loss: 0.7099400758743286\n",
      "Ep 63: Batch #15 - Loss: 1.2091177701950073\n",
      "Ep 63: Batch #16 - Loss: 1.2427666187286377\n",
      "Ep 63: Batch #17 - Loss: 0.8566651344299316\n",
      "Ep 63: Batch #18 - Loss: 0.9264955520629883\n",
      "Ep 63: Batch #19 - Loss: 0.6524810791015625\n",
      "Ep 63: Batch #20 - Loss: 0.6371716260910034\n",
      "Ep 63: Batch #21 - Loss: 1.1894769668579102\n",
      "Ep 63: Batch #22 - Loss: 0.7094662189483643\n",
      "Ep 63: Batch #23 - Loss: 0.7223387360572815\n",
      "Ep 63: Batch #24 - Loss: 0.8051419258117676\n",
      "Ep 63: Batch #25 - Loss: 0.6949408054351807\n",
      "Ep 63: Batch #26 - Loss: 0.7083888053894043\n",
      "Ep 63: Batch #27 - Loss: 1.3207809925079346\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 63: Batch #28 - Loss: 0.847603976726532\n",
      "Ep 63: Batch #29 - Loss: 0.8673943281173706\n",
      "Ep 63: Batch #30 - Loss: 1.1764894723892212\n",
      "Ep 63: Batch #31 - Loss: 0.6574010252952576\n",
      "Ep 63: Batch #32 - Loss: 0.726437509059906\n",
      "Ep 63: Batch #33 - Loss: 0.7880520820617676\n",
      "Ep 63: Batch #34 - Loss: 0.7645630836486816\n",
      "Ep 63: Batch #35 - Loss: 0.9207364916801453\n",
      "Ep 63: Batch #36 - Loss: 0.6832312941551208\n",
      "Ep 63: Batch #37 - Loss: 1.117375135421753\n",
      "Ep 63: Batch #38 - Loss: 0.7224223613739014\n",
      "Ep 63: Batch #39 - Loss: 0.8025970458984375\n",
      "Ep 63: Batch #40 - Loss: 0.7532783150672913\n",
      "Ep 63: Batch #41 - Loss: 0.7143694758415222\n",
      "Ep 63: Batch #42 - Loss: 0.7031873464584351\n",
      "Ep 63: Batch #43 - Loss: 0.7682439088821411\n",
      "Ep 63: Batch #44 - Loss: 0.7622821927070618\n",
      "Ep 63: Batch #45 - Loss: 0.6135576963424683\n",
      "Ep 63: Batch #46 - Loss: 0.8055522441864014\n",
      "Ep 63: Batch #47 - Loss: 0.9310467839241028\n",
      "Ep 63: Batch #48 - Loss: 1.3263095617294312\n",
      "Ep 63: Batch #49 - Loss: 0.9834325909614563\n",
      "Ep 63: Batch #50 - Loss: 0.6908530592918396\n",
      "Ep 63: Batch #51 - Loss: 0.9647277593612671\n",
      "Ep 63: Batch #52 - Loss: 0.7759425640106201\n",
      "Ep 63: Batch #53 - Loss: 0.8003525137901306\n",
      "Ep 63: Batch #54 - Loss: 0.6870953440666199\n",
      "Ep 63: Batch #55 - Loss: 0.730159342288971\n",
      "Ep 63: Batch #56 - Loss: 1.229344129562378\n",
      "Ep 63: Batch #57 - Loss: 0.822457492351532\n",
      "Ep 63: Batch #58 - Loss: 0.9690792560577393\n",
      "Ep 63: Batch #59 - Loss: 0.6659334897994995\n",
      "Ep 63: Batch #60 - Loss: 1.282418131828308\n",
      "Ep 63: Batch #61 - Loss: 0.6196853518486023\n",
      "Ep 63: Batch #62 - Loss: 0.7009534239768982\n",
      "Ep 63: Batch #63 - Loss: 0.9764876961708069\n",
      "Ep 63: Batch #64 - Loss: 9.407814025878906\n",
      "Ep 63: Batch #65 - Loss: 0.596248209476471\n",
      "Ep 63: Batch #66 - Loss: 0.772893488407135\n",
      "Ep 63: Batch #67 - Loss: 0.8866637945175171\n",
      "Ep 63: Batch #68 - Loss: 0.8820192217826843\n",
      "Ep 63: Batch #69 - Loss: 0.7249694466590881\n",
      "Ep 63: Batch #70 - Loss: 0.750901997089386\n",
      "Ep 63: Batch #71 - Loss: 0.6625152230262756\n",
      "Ep 63: Batch #72 - Loss: 0.8310576677322388\n",
      "Ep 63: Batch #73 - Loss: 0.874502420425415\n",
      "Ep 63: Batch #74 - Loss: 0.7175810933113098\n",
      "Ep 63: Batch #75 - Loss: 0.7491949796676636\n",
      "Ep 63: Batch #76 - Loss: 1.0743306875228882\n",
      "Ep 63: Batch #77 - Loss: 0.7131147384643555\n",
      "Ep 63: Batch #78 - Loss: 1.1276062726974487\n",
      "Ep 63: Batch #79 - Loss: 0.6082958579063416\n",
      "Ep 63: Batch #80 - Loss: 0.833568811416626\n",
      "Ep 63: Batch #81 - Loss: 1.6557961702346802\n",
      "Ep 63: Batch #82 - Loss: 0.8517693281173706\n",
      "Ep 63: Batch #83 - Loss: 1.7171063423156738\n",
      "Ep 63: Batch #84 - Loss: 0.6936883926391602\n",
      "Ep 63: Batch #85 - Loss: 0.954089879989624\n",
      "Ep 63: Batch #86 - Loss: 0.6861720085144043\n",
      "Ep 63: Batch #87 - Loss: 0.6929046511650085\n",
      "Ep 63: Batch #88 - Loss: 0.778628408908844\n",
      "Ep 63: Batch #89 - Loss: 0.8684968948364258\n",
      "Ep 63: Batch #90 - Loss: 1.1218687295913696\n",
      "Ep 63: Batch #91 - Loss: 0.7771917581558228\n",
      "Ep 63: Batch #92 - Loss: 1.0011396408081055\n",
      "Ep 63: Batch #93 - Loss: 0.9971176981925964\n",
      "Ep 63: Batch #94 - Loss: 1.0206316709518433\n",
      "Ep 63: Batch #95 - Loss: 0.8954386711120605\n",
      "Ep 63: Batch #96 - Loss: 0.8816960453987122\n",
      "Ep 63: Batch #97 - Loss: 0.708008885383606\n",
      "Ep 63: Batch #98 - Loss: 0.7175211906433105\n",
      "Ep 63: Batch #99 - Loss: 0.9342930316925049\n",
      "Ep 63: Batch #100 - Loss: 0.6581669449806213\n",
      "Ep 63: Batch #101 - Loss: 1.0227149724960327\n",
      "Ep 63: Batch #102 - Loss: 0.7610971927642822\n",
      "Ep 63: Batch #103 - Loss: 0.7692921757698059\n",
      "Ep 63: Batch #104 - Loss: 0.7796621918678284\n",
      "Ep 63: Batch #105 - Loss: 1.0001024007797241\n",
      "Ep 63: Batch #106 - Loss: 0.7393266558647156\n",
      "Ep 63: Batch #107 - Loss: 0.7358445525169373\n",
      "Ep 63: Batch #108 - Loss: 1.0064976215362549\n",
      "Ep 63: Batch #109 - Loss: 0.7430533170700073\n",
      "Ep 63: Batch #110 - Loss: 0.8899571299552917\n",
      "Ep 63: Batch #111 - Loss: 1.347510814666748\n",
      "Ep 63: Batch #112 - Loss: 1.019885540008545\n",
      "Ep 63: Batch #113 - Loss: 0.79410320520401\n",
      "Ep 63: Batch #114 - Loss: 0.8768766522407532\n",
      "Ep 63: Batch #115 - Loss: 1.066835880279541\n",
      "Ep 63: Batch #116 - Loss: 0.6199337244033813\n",
      "Ep 63: Batch #117 - Loss: 0.851100504398346\n",
      "Ep 63: Batch #118 - Loss: 0.5277860164642334\n",
      "Model saved in file: ./weights_autoencoder_low_LR/model_e63b118_1516651277.2441595.ckpt\n",
      "Ep 63: Batch #119 - Loss: 1.0027239322662354\n",
      "Ep 63: Batch #120 - Loss: 0.7796974182128906\n",
      "Ep 63: Batch #121 - Loss: 0.6657774448394775\n",
      "Ep 63: Batch #122 - Loss: 0.8040590286254883\n",
      "Ep 63: Batch #123 - Loss: 0.8095781803131104\n",
      "Ep 63: Batch #124 - Loss: 0.6474766731262207\n",
      "Ep 63: Batch #125 - Loss: 2.68686842918396\n",
      "Ep 63: Batch #126 - Loss: 1.1980994939804077\n",
      "Ep 63: Batch #127 - Loss: 0.7257246971130371\n",
      "Ep 63: Batch #128 - Loss: 1.0727925300598145\n",
      "Ep 63: Batch #129 - Loss: 0.8141663074493408\n",
      "Ep 63: Batch #130 - Loss: 0.7030904293060303\n",
      "Ep 63: Batch #131 - Loss: 0.9641128778457642\n",
      "Ep 63: Batch #132 - Loss: 0.799717366695404\n",
      "Ep 63: Batch #133 - Loss: 0.7946036458015442\n",
      "Ep 63: Batch #134 - Loss: 0.7464264035224915\n",
      "Ep 63: Batch #135 - Loss: 0.9375919699668884\n",
      "Ep 63: Batch #136 - Loss: 1.1507437229156494\n",
      "Ep 63: Batch #137 - Loss: 0.9371808171272278\n",
      "Ep 63: Batch #138 - Loss: 1.042961835861206\n",
      "Ep 63: Batch #139 - Loss: 0.8740929961204529\n",
      "Ep 63: Batch #140 - Loss: 1.022797703742981\n",
      "Ep 63: Batch #141 - Loss: 1.3285216093063354\n",
      "Ep 63: Batch #142 - Loss: 0.7734234929084778\n",
      "Ep 63: Batch #143 - Loss: 0.9350318908691406\n",
      "Ep 63: Batch #144 - Loss: 0.7013780474662781\n",
      "Ep 63: Batch #145 - Loss: 0.6603730916976929\n",
      "Ep 63: Batch #146 - Loss: 0.8623363375663757\n",
      "Ep 63: Batch #147 - Loss: 0.8342942595481873\n",
      "Ep 63: Batch #148 - Loss: 0.9484971165657043\n",
      "Ep 63: Batch #149 - Loss: 0.8283277153968811\n",
      "Ep 63: Batch #150 - Loss: 0.8597897291183472\n",
      "Ep 63: Batch #151 - Loss: 0.7118748426437378\n",
      "Ep 63: Batch #152 - Loss: 0.7231325507164001\n",
      "Ep 63: Batch #153 - Loss: 1.0751292705535889\n",
      "Ep 63: Batch #154 - Loss: 0.7426005601882935\n",
      "Ep 63: Batch #155 - Loss: 0.8116174936294556\n",
      "Ep 63: Batch #156 - Loss: 0.9923155307769775\n",
      "Ep 63: Batch #157 - Loss: 0.7404137849807739\n",
      "Ep 63: Batch #158 - Loss: 0.7890010476112366\n",
      "Ep 63: Batch #159 - Loss: 0.7839431166648865\n",
      "Ep 63: Batch #160 - Loss: 0.883901059627533\n",
      "Ep 63: Batch #161 - Loss: 0.7940365672111511\n",
      "Ep 63: Batch #162 - Loss: 0.908234715461731\n",
      "Ep 63: Batch #163 - Loss: 0.9099282622337341\n",
      "Ep 63: Batch #164 - Loss: 0.7632225155830383\n",
      "Ep 63: Batch #165 - Loss: 1.4759340286254883\n",
      "Ep 63: Batch #166 - Loss: 0.6591361165046692\n",
      "Ep 63: Batch #167 - Loss: 1.0601966381072998\n",
      "Ep 63: Batch #168 - Loss: 0.8364651799201965\n",
      "Ep 63: Batch #169 - Loss: 0.7805099487304688\n",
      "Ep 63: Batch #170 - Loss: 0.781947135925293\n",
      "Ep 63: Batch #171 - Loss: 0.7565354704856873\n",
      "Ep 63: Batch #172 - Loss: 0.618511438369751\n",
      "Ep 63: Batch #173 - Loss: 1.1616015434265137\n",
      "Ep 63: Batch #174 - Loss: 0.563588559627533\n",
      "Ep 63: Batch #175 - Loss: 0.7618571519851685\n",
      "Ep 63: Batch #176 - Loss: 1.1217302083969116\n",
      "Ep 63: Batch #177 - Loss: 0.825413167476654\n",
      "Ep 63: Batch #178 - Loss: 0.7413625121116638\n",
      "Ep 63: Batch #179 - Loss: 0.9133005738258362\n",
      "Ep 63: Batch #180 - Loss: 0.8276309967041016\n",
      "Ep 63: Batch #181 - Loss: 0.9623178243637085\n",
      "Ep 63: Batch #182 - Loss: 0.7474607825279236\n",
      "Ep 63: Batch #183 - Loss: 0.7442371249198914\n",
      "Ep 63: Batch #184 - Loss: 1.04719877243042\n",
      "Ep 63: Batch #185 - Loss: 0.7374914884567261\n",
      "Ep 63: Batch #186 - Loss: 0.9373704195022583\n",
      "Ep 63: Batch #187 - Loss: 1.138109564781189\n",
      "Ep 63: Batch #188 - Loss: 1.326805591583252\n",
      "Ep 63: Batch #189 - Loss: 0.6857799887657166\n",
      "Ep 63: Batch #190 - Loss: 0.7161630392074585\n",
      "Ep 63: Batch #191 - Loss: 1.036243200302124\n",
      "Ep 63: Batch #192 - Loss: 0.654403805732727\n",
      "Ep 63: Batch #193 - Loss: 0.7193236351013184\n",
      "Ep 63: Batch #194 - Loss: 0.6763768196105957\n",
      "Ep 63: Batch #195 - Loss: 0.957383930683136\n",
      "Ep 63: Batch #196 - Loss: 0.8422538638114929\n",
      "Ep 63: Batch #197 - Loss: 0.8761605620384216\n",
      "Ep 63: Batch #198 - Loss: 0.6572434306144714\n",
      "Ep 63: Batch #199 - Loss: 0.838077962398529\n",
      "Ep 64: Batch #0 - Loss: 0.7667655348777771\n",
      "Ep 64: Batch #1 - Loss: 0.851423442363739\n",
      "Ep 64: Batch #2 - Loss: 0.9869381785392761\n",
      "Ep 64: Batch #3 - Loss: 0.8438136577606201\n",
      "Ep 64: Batch #4 - Loss: 0.7655521631240845\n",
      "Ep 64: Batch #5 - Loss: 0.6509684324264526\n",
      "Ep 64: Batch #6 - Loss: 0.8557971715927124\n",
      "Ep 64: Batch #7 - Loss: 0.6829863786697388\n",
      "Ep 64: Batch #8 - Loss: 0.7147016525268555\n",
      "Ep 64: Batch #9 - Loss: 1.3645274639129639\n",
      "Ep 64: Batch #10 - Loss: 0.982086718082428\n",
      "Ep 64: Batch #11 - Loss: 0.6521322727203369\n",
      "Ep 64: Batch #12 - Loss: 1.5313764810562134\n",
      "Ep 64: Batch #13 - Loss: 0.6341986656188965\n",
      "Ep 64: Batch #14 - Loss: 0.7090458273887634\n",
      "Ep 64: Batch #15 - Loss: 1.2073792219161987\n",
      "Ep 64: Batch #16 - Loss: 1.2409822940826416\n",
      "Ep 64: Batch #17 - Loss: 0.8554638624191284\n",
      "Ep 64: Batch #18 - Loss: 0.9257345199584961\n",
      "Ep 64: Batch #19 - Loss: 0.651716947555542\n",
      "Ep 64: Batch #20 - Loss: 0.6362758278846741\n",
      "Ep 64: Batch #21 - Loss: 1.18833589553833\n",
      "Ep 64: Batch #22 - Loss: 0.7086427211761475\n",
      "Ep 64: Batch #23 - Loss: 0.7212904691696167\n",
      "Ep 64: Batch #24 - Loss: 0.8042299151420593\n",
      "Ep 64: Batch #25 - Loss: 0.6939577460289001\n",
      "Ep 64: Batch #26 - Loss: 0.7072620987892151\n",
      "Ep 64: Batch #27 - Loss: 1.3191217184066772\n",
      "Ep 64: Batch #28 - Loss: 0.8467049598693848\n",
      "Ep 64: Batch #29 - Loss: 0.8660910129547119\n",
      "Ep 64: Batch #30 - Loss: 1.1750630140304565\n",
      "Ep 64: Batch #31 - Loss: 0.6565301418304443\n",
      "Ep 64: Batch #32 - Loss: 0.7253937721252441\n",
      "Ep 64: Batch #33 - Loss: 0.7870626449584961\n",
      "Ep 64: Batch #34 - Loss: 0.7635497450828552\n",
      "Ep 64: Batch #35 - Loss: 0.9192882180213928\n",
      "Ep 64: Batch #36 - Loss: 0.6821809411048889\n",
      "Ep 64: Batch #37 - Loss: 1.1161762475967407\n",
      "Ep 64: Batch #38 - Loss: 0.7212420701980591\n",
      "Ep 64: Batch #39 - Loss: 0.8016267418861389\n",
      "Ep 64: Batch #40 - Loss: 0.7522281408309937\n",
      "Ep 64: Batch #41 - Loss: 0.7131548523902893\n",
      "Ep 64: Batch #42 - Loss: 0.7021414041519165\n",
      "Ep 64: Batch #43 - Loss: 0.7672385573387146\n",
      "Ep 64: Batch #44 - Loss: 0.7611218094825745\n",
      "Ep 64: Batch #45 - Loss: 0.6125600934028625\n",
      "Ep 64: Batch #46 - Loss: 0.8043084740638733\n",
      "Ep 64: Batch #47 - Loss: 0.929487943649292\n",
      "Ep 64: Batch #48 - Loss: 1.3249943256378174\n",
      "Ep 64: Batch #49 - Loss: 0.9818593263626099\n",
      "Ep 64: Batch #50 - Loss: 0.69005286693573\n",
      "Ep 64: Batch #51 - Loss: 0.9631509780883789\n",
      "Ep 64: Batch #52 - Loss: 0.7749757170677185\n",
      "Ep 64: Batch #53 - Loss: 0.799246609210968\n",
      "Ep 64: Batch #54 - Loss: 0.6861567497253418\n",
      "Ep 64: Batch #55 - Loss: 0.7291223406791687\n",
      "Ep 64: Batch #56 - Loss: 1.2275540828704834\n",
      "Ep 64: Batch #57 - Loss: 0.8211711645126343\n",
      "Ep 64: Batch #58 - Loss: 0.9674504399299622\n",
      "Ep 64: Batch #59 - Loss: 0.6652064323425293\n",
      "Ep 64: Batch #60 - Loss: 1.2807351350784302\n",
      "Ep 64: Batch #61 - Loss: 0.6188264489173889\n",
      "Ep 64: Batch #62 - Loss: 0.6998982429504395\n",
      "Ep 64: Batch #63 - Loss: 0.9751525521278381\n",
      "Ep 64: Batch #64 - Loss: 9.406715393066406\n",
      "Ep 64: Batch #65 - Loss: 0.595435380935669\n",
      "Ep 64: Batch #66 - Loss: 0.7717578411102295\n",
      "Ep 64: Batch #67 - Loss: 0.885465145111084\n",
      "Ep 64: Batch #68 - Loss: 0.8806180953979492\n",
      "Ep 64: Batch #69 - Loss: 0.7240020036697388\n",
      "Ep 64: Batch #70 - Loss: 0.7496109008789062\n",
      "Ep 64: Batch #71 - Loss: 0.661697506904602\n",
      "Ep 64: Batch #72 - Loss: 0.8299042582511902\n",
      "Ep 64: Batch #73 - Loss: 0.8730116486549377\n",
      "Ep 64: Batch #74 - Loss: 0.7163553237915039\n",
      "Ep 64: Batch #75 - Loss: 0.7482039332389832\n",
      "Ep 64: Batch #76 - Loss: 1.0731810331344604\n",
      "Ep 64: Batch #77 - Loss: 0.7119795680046082\n",
      "Ep 64: Batch #78 - Loss: 1.1259336471557617\n",
      "Ep 64: Batch #79 - Loss: 0.6074198484420776\n",
      "Ep 64: Batch #80 - Loss: 0.8322293758392334\n",
      "Ep 64: Batch #81 - Loss: 1.6546027660369873\n",
      "Ep 64: Batch #82 - Loss: 0.8506580591201782\n",
      "Ep 64: Batch #83 - Loss: 1.716233730316162\n",
      "Ep 64: Batch #84 - Loss: 0.6926652193069458\n",
      "Ep 64: Batch #85 - Loss: 0.9531208276748657\n",
      "Ep 64: Batch #86 - Loss: 0.6850006580352783\n",
      "Ep 64: Batch #87 - Loss: 0.6918857097625732\n",
      "Ep 64: Batch #88 - Loss: 0.7774639129638672\n",
      "Ep 64: Batch #89 - Loss: 0.8677569627761841\n",
      "Ep 64: Batch #90 - Loss: 1.1202741861343384\n",
      "Ep 64: Batch #91 - Loss: 0.7759450674057007\n",
      "Ep 64: Batch #92 - Loss: 0.9997477531433105\n",
      "Ep 64: Batch #93 - Loss: 0.9954233169555664\n",
      "Ep 64: Batch #94 - Loss: 1.0192288160324097\n",
      "Ep 64: Batch #95 - Loss: 0.8942972421646118\n",
      "Ep 64: Batch #96 - Loss: 0.8805232644081116\n",
      "Ep 64: Batch #97 - Loss: 0.7068936824798584\n",
      "Ep 64: Batch #98 - Loss: 0.7164733409881592\n",
      "Ep 64: Batch #99 - Loss: 0.9329824447631836\n",
      "Ep 64: Batch #100 - Loss: 0.6571745872497559\n",
      "Ep 64: Batch #101 - Loss: 1.0215650796890259\n",
      "Ep 64: Batch #102 - Loss: 0.759994387626648\n",
      "Ep 64: Batch #103 - Loss: 0.7682371735572815\n",
      "Ep 64: Batch #104 - Loss: 0.7786068320274353\n",
      "Ep 64: Batch #105 - Loss: 0.998753011226654\n",
      "Ep 64: Batch #106 - Loss: 0.7383625507354736\n",
      "Ep 64: Batch #107 - Loss: 0.7347747683525085\n",
      "Ep 64: Batch #108 - Loss: 1.0051645040512085\n",
      "Ep 64: Batch #109 - Loss: 0.7420005202293396\n",
      "Ep 64: Batch #110 - Loss: 0.888488233089447\n",
      "Ep 64: Batch #111 - Loss: 1.345893383026123\n",
      "Ep 64: Batch #112 - Loss: 1.0186011791229248\n",
      "Ep 64: Batch #113 - Loss: 0.793003261089325\n",
      "Ep 64: Batch #114 - Loss: 0.8755089044570923\n",
      "Ep 64: Batch #115 - Loss: 1.0654655694961548\n",
      "Ep 64: Batch #116 - Loss: 0.6192068457603455\n",
      "Ep 64: Batch #117 - Loss: 0.8500463962554932\n",
      "Ep 64: Batch #118 - Loss: 0.5269594192504883\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved in file: ./weights_autoencoder_low_LR/model_e64b118_1516651277.38204.ckpt\n",
      "Ep 64: Batch #119 - Loss: 1.0014526844024658\n",
      "Ep 64: Batch #120 - Loss: 0.7787325978279114\n",
      "Ep 64: Batch #121 - Loss: 0.664804220199585\n",
      "Ep 64: Batch #122 - Loss: 0.8030201196670532\n",
      "Ep 64: Batch #123 - Loss: 0.8084732294082642\n",
      "Ep 64: Batch #124 - Loss: 0.6466430425643921\n",
      "Ep 64: Batch #125 - Loss: 2.6851656436920166\n",
      "Ep 64: Batch #126 - Loss: 1.1963980197906494\n",
      "Ep 64: Batch #127 - Loss: 0.7245834469795227\n",
      "Ep 64: Batch #128 - Loss: 1.0710517168045044\n",
      "Ep 64: Batch #129 - Loss: 0.8129419684410095\n",
      "Ep 64: Batch #130 - Loss: 0.7020979523658752\n",
      "Ep 64: Batch #131 - Loss: 0.962476372718811\n",
      "Ep 64: Batch #132 - Loss: 0.798547625541687\n",
      "Ep 64: Batch #133 - Loss: 0.7934132218360901\n",
      "Ep 64: Batch #134 - Loss: 0.7453031539916992\n",
      "Ep 64: Batch #135 - Loss: 0.9362072944641113\n",
      "Ep 64: Batch #136 - Loss: 1.1492528915405273\n",
      "Ep 64: Batch #137 - Loss: 0.9357113242149353\n",
      "Ep 64: Batch #138 - Loss: 1.0415356159210205\n",
      "Ep 64: Batch #139 - Loss: 0.8727453947067261\n",
      "Ep 64: Batch #140 - Loss: 1.0215615034103394\n",
      "Ep 64: Batch #141 - Loss: 1.326830267906189\n",
      "Ep 64: Batch #142 - Loss: 0.7723593711853027\n",
      "Ep 64: Batch #143 - Loss: 0.9334661960601807\n",
      "Ep 64: Batch #144 - Loss: 0.7004635334014893\n",
      "Ep 64: Batch #145 - Loss: 0.6595048904418945\n",
      "Ep 64: Batch #146 - Loss: 0.861299455165863\n",
      "Ep 64: Batch #147 - Loss: 0.8328939080238342\n",
      "Ep 64: Batch #148 - Loss: 0.9469677805900574\n",
      "Ep 64: Batch #149 - Loss: 0.8270212411880493\n",
      "Ep 64: Batch #150 - Loss: 0.8586671352386475\n",
      "Ep 64: Batch #151 - Loss: 0.7111140489578247\n",
      "Ep 64: Batch #152 - Loss: 0.7223412394523621\n",
      "Ep 64: Batch #153 - Loss: 1.0735845565795898\n",
      "Ep 64: Batch #154 - Loss: 0.7415035963058472\n",
      "Ep 64: Batch #155 - Loss: 0.8105646967887878\n",
      "Ep 64: Batch #156 - Loss: 0.9910504221916199\n",
      "Ep 64: Batch #157 - Loss: 0.739294171333313\n",
      "Ep 64: Batch #158 - Loss: 0.7881757020950317\n",
      "Ep 64: Batch #159 - Loss: 0.7826176881790161\n",
      "Ep 64: Batch #160 - Loss: 0.8829683661460876\n",
      "Ep 64: Batch #161 - Loss: 0.7928668260574341\n",
      "Ep 64: Batch #162 - Loss: 0.9070716500282288\n",
      "Ep 64: Batch #163 - Loss: 0.90889972448349\n",
      "Ep 64: Batch #164 - Loss: 0.7620426416397095\n",
      "Ep 64: Batch #165 - Loss: 1.4748830795288086\n",
      "Ep 64: Batch #166 - Loss: 0.6580988764762878\n",
      "Ep 64: Batch #167 - Loss: 1.0587767362594604\n",
      "Ep 64: Batch #168 - Loss: 0.8351748585700989\n",
      "Ep 64: Batch #169 - Loss: 0.7794789671897888\n",
      "Ep 64: Batch #170 - Loss: 0.7808368802070618\n",
      "Ep 64: Batch #171 - Loss: 0.7552894949913025\n",
      "Ep 64: Batch #172 - Loss: 0.6177803874015808\n",
      "Ep 64: Batch #173 - Loss: 1.1598678827285767\n",
      "Ep 64: Batch #174 - Loss: 0.5627912282943726\n",
      "Ep 64: Batch #175 - Loss: 0.7610712051391602\n",
      "Ep 64: Batch #176 - Loss: 1.1200439929962158\n",
      "Ep 64: Batch #177 - Loss: 0.8242570161819458\n",
      "Ep 64: Batch #178 - Loss: 0.740247905254364\n",
      "Ep 64: Batch #179 - Loss: 0.9120861291885376\n",
      "Ep 64: Batch #180 - Loss: 0.8262510895729065\n",
      "Ep 64: Batch #181 - Loss: 0.960806131362915\n",
      "Ep 64: Batch #182 - Loss: 0.7465499043464661\n",
      "Ep 64: Batch #183 - Loss: 0.7432942390441895\n",
      "Ep 64: Batch #184 - Loss: 1.0460729598999023\n",
      "Ep 64: Batch #185 - Loss: 0.7363958358764648\n",
      "Ep 64: Batch #186 - Loss: 0.935810387134552\n",
      "Ep 64: Batch #187 - Loss: 1.136406421661377\n",
      "Ep 64: Batch #188 - Loss: 1.3257017135620117\n",
      "Ep 64: Batch #189 - Loss: 0.6850086450576782\n",
      "Ep 64: Batch #190 - Loss: 0.7151952981948853\n",
      "Ep 64: Batch #191 - Loss: 1.0346685647964478\n",
      "Ep 64: Batch #192 - Loss: 0.653669536113739\n",
      "Ep 64: Batch #193 - Loss: 0.7182092666625977\n",
      "Ep 64: Batch #194 - Loss: 0.6753409504890442\n",
      "Ep 64: Batch #195 - Loss: 0.95611172914505\n",
      "Ep 64: Batch #196 - Loss: 0.8409207463264465\n",
      "Ep 64: Batch #197 - Loss: 0.874751627445221\n",
      "Ep 64: Batch #198 - Loss: 0.6562018394470215\n",
      "Ep 64: Batch #199 - Loss: 0.8368959426879883\n",
      "Ep 65: Batch #0 - Loss: 0.7654775977134705\n",
      "Ep 65: Batch #1 - Loss: 0.8500765562057495\n",
      "Ep 65: Batch #2 - Loss: 0.9859538674354553\n",
      "Ep 65: Batch #3 - Loss: 0.8427324891090393\n",
      "Ep 65: Batch #4 - Loss: 0.7643939256668091\n",
      "Ep 65: Batch #5 - Loss: 0.6500288844108582\n",
      "Ep 65: Batch #6 - Loss: 0.8545876145362854\n",
      "Ep 65: Batch #7 - Loss: 0.6820604801177979\n",
      "Ep 65: Batch #8 - Loss: 0.7136361002922058\n",
      "Ep 65: Batch #9 - Loss: 1.362676739692688\n",
      "Ep 65: Batch #10 - Loss: 0.980894923210144\n",
      "Ep 65: Batch #11 - Loss: 0.6512787938117981\n",
      "Ep 65: Batch #12 - Loss: 1.5299298763275146\n",
      "Ep 65: Batch #13 - Loss: 0.6334726810455322\n",
      "Ep 65: Batch #14 - Loss: 0.708139955997467\n",
      "Ep 65: Batch #15 - Loss: 1.205665111541748\n",
      "Ep 65: Batch #16 - Loss: 1.2391117811203003\n",
      "Ep 65: Batch #17 - Loss: 0.8541997671127319\n",
      "Ep 65: Batch #18 - Loss: 0.9249395132064819\n",
      "Ep 65: Batch #19 - Loss: 0.6509242653846741\n",
      "Ep 65: Batch #20 - Loss: 0.6353564858436584\n",
      "Ep 65: Batch #21 - Loss: 1.1871298551559448\n",
      "Ep 65: Batch #22 - Loss: 0.7077805399894714\n",
      "Ep 65: Batch #23 - Loss: 0.7202449440956116\n",
      "Ep 65: Batch #24 - Loss: 0.8033148646354675\n",
      "Ep 65: Batch #25 - Loss: 0.6929692029953003\n",
      "Ep 65: Batch #26 - Loss: 0.7061614990234375\n",
      "Ep 65: Batch #27 - Loss: 1.317350149154663\n",
      "Ep 65: Batch #28 - Loss: 0.8458070158958435\n",
      "Ep 65: Batch #29 - Loss: 0.864742636680603\n",
      "Ep 65: Batch #30 - Loss: 1.1736167669296265\n",
      "Ep 65: Batch #31 - Loss: 0.6555872559547424\n",
      "Ep 65: Batch #32 - Loss: 0.7242782711982727\n",
      "Ep 65: Batch #33 - Loss: 0.7860539555549622\n",
      "Ep 65: Batch #34 - Loss: 0.7624933123588562\n",
      "Ep 65: Batch #35 - Loss: 0.9178197383880615\n",
      "Ep 65: Batch #36 - Loss: 0.6810675263404846\n",
      "Ep 65: Batch #37 - Loss: 1.114980697631836\n",
      "Ep 65: Batch #38 - Loss: 0.7200184464454651\n",
      "Ep 65: Batch #39 - Loss: 0.8005974292755127\n",
      "Ep 65: Batch #40 - Loss: 0.7511998414993286\n",
      "Ep 65: Batch #41 - Loss: 0.71187824010849\n",
      "Ep 65: Batch #42 - Loss: 0.7010718584060669\n",
      "Ep 65: Batch #43 - Loss: 0.766226053237915\n",
      "Ep 65: Batch #44 - Loss: 0.7598620057106018\n",
      "Ep 65: Batch #45 - Loss: 0.6115793585777283\n",
      "Ep 65: Batch #46 - Loss: 0.8030279874801636\n",
      "Ep 65: Batch #47 - Loss: 0.9277883768081665\n",
      "Ep 65: Batch #48 - Loss: 1.3236479759216309\n",
      "Ep 65: Batch #49 - Loss: 0.980269193649292\n",
      "Ep 65: Batch #50 - Loss: 0.6892096400260925\n",
      "Ep 65: Batch #51 - Loss: 0.9614287614822388\n",
      "Ep 65: Batch #52 - Loss: 0.7738593220710754\n",
      "Ep 65: Batch #53 - Loss: 0.7980669736862183\n",
      "Ep 65: Batch #54 - Loss: 0.6851590871810913\n",
      "Ep 65: Batch #55 - Loss: 0.7280635833740234\n",
      "Ep 65: Batch #56 - Loss: 1.2256675958633423\n",
      "Ep 65: Batch #57 - Loss: 0.819831371307373\n",
      "Ep 65: Batch #58 - Loss: 0.9657652378082275\n",
      "Ep 65: Batch #59 - Loss: 0.6645029187202454\n",
      "Ep 65: Batch #60 - Loss: 1.278968334197998\n",
      "Ep 65: Batch #61 - Loss: 0.6179587244987488\n",
      "Ep 65: Batch #62 - Loss: 0.6988343596458435\n",
      "Ep 65: Batch #63 - Loss: 0.9737773537635803\n",
      "Ep 65: Batch #64 - Loss: 9.40554141998291\n",
      "Ep 65: Batch #65 - Loss: 0.5945233106613159\n",
      "Ep 65: Batch #66 - Loss: 0.7705712914466858\n",
      "Ep 65: Batch #67 - Loss: 0.8842608332633972\n",
      "Ep 65: Batch #68 - Loss: 0.8790867328643799\n",
      "Ep 65: Batch #69 - Loss: 0.7230545878410339\n",
      "Ep 65: Batch #70 - Loss: 0.7482722997665405\n",
      "Ep 65: Batch #71 - Loss: 0.6608979105949402\n",
      "Ep 65: Batch #72 - Loss: 0.8287100195884705\n",
      "Ep 65: Batch #73 - Loss: 0.8713401556015015\n",
      "Ep 65: Batch #74 - Loss: 0.7150599956512451\n",
      "Ep 65: Batch #75 - Loss: 0.7471592426300049\n",
      "Ep 65: Batch #76 - Loss: 1.071948766708374\n",
      "Ep 65: Batch #77 - Loss: 0.7107744812965393\n",
      "Ep 65: Batch #78 - Loss: 1.1240826845169067\n",
      "Ep 65: Batch #79 - Loss: 0.606532871723175\n",
      "Ep 65: Batch #80 - Loss: 0.8308306932449341\n",
      "Ep 65: Batch #81 - Loss: 1.6533877849578857\n",
      "Ep 65: Batch #82 - Loss: 0.8494732975959778\n",
      "Ep 65: Batch #83 - Loss: 1.7152787446975708\n",
      "Ep 65: Batch #84 - Loss: 0.6915825009346008\n",
      "Ep 65: Batch #85 - Loss: 0.952068030834198\n",
      "Ep 65: Batch #86 - Loss: 0.683751106262207\n",
      "Ep 65: Batch #87 - Loss: 0.6908539533615112\n",
      "Ep 65: Batch #88 - Loss: 0.7762152552604675\n",
      "Ep 65: Batch #89 - Loss: 0.8669941425323486\n",
      "Ep 65: Batch #90 - Loss: 1.1186362504959106\n",
      "Ep 65: Batch #91 - Loss: 0.7745693922042847\n",
      "Ep 65: Batch #92 - Loss: 0.9983522891998291\n",
      "Ep 65: Batch #93 - Loss: 0.9935462474822998\n",
      "Ep 65: Batch #94 - Loss: 1.0176825523376465\n",
      "Ep 65: Batch #95 - Loss: 0.8931820392608643\n",
      "Ep 65: Batch #96 - Loss: 0.8792511820793152\n",
      "Ep 65: Batch #97 - Loss: 0.70576012134552\n",
      "Ep 65: Batch #98 - Loss: 0.7154239416122437\n",
      "Ep 65: Batch #99 - Loss: 0.9316036105155945\n",
      "Ep 65: Batch #100 - Loss: 0.6561533212661743\n",
      "Ep 65: Batch #101 - Loss: 1.020438551902771\n",
      "Ep 65: Batch #102 - Loss: 0.7587904930114746\n",
      "Ep 65: Batch #103 - Loss: 0.7671267986297607\n",
      "Ep 65: Batch #104 - Loss: 0.7775310277938843\n",
      "Ep 65: Batch #105 - Loss: 0.9974193572998047\n",
      "Ep 65: Batch #106 - Loss: 0.7374144196510315\n",
      "Ep 65: Batch #107 - Loss: 0.733675479888916\n",
      "Ep 65: Batch #108 - Loss: 1.003795862197876\n",
      "Ep 65: Batch #109 - Loss: 0.7408173084259033\n",
      "Ep 65: Batch #110 - Loss: 0.8869649171829224\n",
      "Ep 65: Batch #111 - Loss: 1.344156265258789\n",
      "Ep 65: Batch #112 - Loss: 1.0171889066696167\n",
      "Ep 65: Batch #113 - Loss: 0.7918635606765747\n",
      "Ep 65: Batch #114 - Loss: 0.8740217089653015\n",
      "Ep 65: Batch #115 - Loss: 1.0639642477035522\n",
      "Ep 65: Batch #116 - Loss: 0.6184724569320679\n",
      "Ep 65: Batch #117 - Loss: 0.8489590883255005\n",
      "Ep 65: Batch #118 - Loss: 0.5261201858520508\n",
      "Model saved in file: ./weights_autoencoder_low_LR/model_e65b118_1516651277.520814.ckpt\n",
      "Ep 65: Batch #119 - Loss: 1.0000121593475342\n",
      "Ep 65: Batch #120 - Loss: 0.7776444554328918\n",
      "Ep 65: Batch #121 - Loss: 0.6638340353965759\n",
      "Ep 65: Batch #122 - Loss: 0.8019106984138489\n",
      "Ep 65: Batch #123 - Loss: 0.807248592376709\n",
      "Ep 65: Batch #124 - Loss: 0.6457523703575134\n",
      "Ep 65: Batch #125 - Loss: 2.683413505554199\n",
      "Ep 65: Batch #126 - Loss: 1.1947133541107178\n",
      "Ep 65: Batch #127 - Loss: 0.7233982086181641\n",
      "Ep 65: Batch #128 - Loss: 1.0691962242126465\n",
      "Ep 65: Batch #129 - Loss: 0.8116457462310791\n",
      "Ep 65: Batch #130 - Loss: 0.7011423707008362\n",
      "Ep 65: Batch #131 - Loss: 0.960770845413208\n",
      "Ep 65: Batch #132 - Loss: 0.7973554134368896\n",
      "Ep 65: Batch #133 - Loss: 0.7920336127281189\n",
      "Ep 65: Batch #134 - Loss: 0.7441027164459229\n",
      "Ep 65: Batch #135 - Loss: 0.9347670674324036\n",
      "Ep 65: Batch #136 - Loss: 1.147649884223938\n",
      "Ep 65: Batch #137 - Loss: 0.9340800046920776\n",
      "Ep 65: Batch #138 - Loss: 1.0399603843688965\n",
      "Ep 65: Batch #139 - Loss: 0.8713585138320923\n",
      "Ep 65: Batch #140 - Loss: 1.0202171802520752\n",
      "Ep 65: Batch #141 - Loss: 1.3250573873519897\n",
      "Ep 65: Batch #142 - Loss: 0.7711591124534607\n",
      "Ep 65: Batch #143 - Loss: 0.9317482709884644\n",
      "Ep 65: Batch #144 - Loss: 0.6994016766548157\n",
      "Ep 65: Batch #145 - Loss: 0.6585893630981445\n",
      "Ep 65: Batch #146 - Loss: 0.8601920008659363\n",
      "Ep 65: Batch #147 - Loss: 0.8314343094825745\n",
      "Ep 65: Batch #148 - Loss: 0.9453867673873901\n",
      "Ep 65: Batch #149 - Loss: 0.8256198167800903\n",
      "Ep 65: Batch #150 - Loss: 0.8575596809387207\n",
      "Ep 65: Batch #151 - Loss: 0.7102391719818115\n",
      "Ep 65: Batch #152 - Loss: 0.721534013748169\n",
      "Ep 65: Batch #153 - Loss: 1.0718971490859985\n",
      "Ep 65: Batch #154 - Loss: 0.7402642965316772\n",
      "Ep 65: Batch #155 - Loss: 0.8094603419303894\n",
      "Ep 65: Batch #156 - Loss: 0.9896652102470398\n",
      "Ep 65: Batch #157 - Loss: 0.7380754351615906\n",
      "Ep 65: Batch #158 - Loss: 0.7872966527938843\n",
      "Ep 65: Batch #159 - Loss: 0.781230092048645\n",
      "Ep 65: Batch #160 - Loss: 0.8820111751556396\n",
      "Ep 65: Batch #161 - Loss: 0.7916722893714905\n",
      "Ep 65: Batch #162 - Loss: 0.9059350490570068\n",
      "Ep 65: Batch #163 - Loss: 0.9076762795448303\n",
      "Ep 65: Batch #164 - Loss: 0.7606948018074036\n",
      "Ep 65: Batch #165 - Loss: 1.4737818241119385\n",
      "Ep 65: Batch #166 - Loss: 0.6570124626159668\n",
      "Ep 65: Batch #167 - Loss: 1.0573126077651978\n",
      "Ep 65: Batch #168 - Loss: 0.8336494565010071\n",
      "Ep 65: Batch #169 - Loss: 0.7784399390220642\n",
      "Ep 65: Batch #170 - Loss: 0.7797021269798279\n",
      "Ep 65: Batch #171 - Loss: 0.7539070248603821\n",
      "Ep 65: Batch #172 - Loss: 0.6170253753662109\n",
      "Ep 65: Batch #173 - Loss: 1.158008098602295\n",
      "Ep 65: Batch #174 - Loss: 0.5619837045669556\n",
      "Ep 65: Batch #175 - Loss: 0.7602492570877075\n",
      "Ep 65: Batch #176 - Loss: 1.11823308467865\n",
      "Ep 65: Batch #177 - Loss: 0.8229973912239075\n",
      "Ep 65: Batch #178 - Loss: 0.7390496134757996\n",
      "Ep 65: Batch #179 - Loss: 0.910904586315155\n",
      "Ep 65: Batch #180 - Loss: 0.8248319625854492\n",
      "Ep 65: Batch #181 - Loss: 0.9590804576873779\n",
      "Ep 65: Batch #182 - Loss: 0.745574414730072\n",
      "Ep 65: Batch #183 - Loss: 0.7423076629638672\n",
      "Ep 65: Batch #184 - Loss: 1.0447193384170532\n",
      "Ep 65: Batch #185 - Loss: 0.735243022441864\n",
      "Ep 65: Batch #186 - Loss: 0.9340946078300476\n",
      "Ep 65: Batch #187 - Loss: 1.1345700025558472\n",
      "Ep 65: Batch #188 - Loss: 1.3245145082473755\n",
      "Ep 65: Batch #189 - Loss: 0.6842036247253418\n",
      "Ep 65: Batch #190 - Loss: 0.7141668796539307\n",
      "Ep 65: Batch #191 - Loss: 1.0329314470291138\n",
      "Ep 65: Batch #192 - Loss: 0.6529271006584167\n",
      "Ep 65: Batch #193 - Loss: 0.7170270085334778\n",
      "Ep 65: Batch #194 - Loss: 0.6742373108863831\n",
      "Ep 65: Batch #195 - Loss: 0.9547455310821533\n",
      "Ep 65: Batch #196 - Loss: 0.839495837688446\n",
      "Ep 65: Batch #197 - Loss: 0.8732145428657532\n",
      "Ep 65: Batch #198 - Loss: 0.6551688313484192\n",
      "Ep 65: Batch #199 - Loss: 0.8356713056564331\n",
      "Ep 66: Batch #0 - Loss: 0.7641478776931763\n",
      "Ep 66: Batch #1 - Loss: 0.8486619591712952\n",
      "Ep 66: Batch #2 - Loss: 0.9849650263786316\n",
      "Ep 66: Batch #3 - Loss: 0.8415807485580444\n",
      "Ep 66: Batch #4 - Loss: 0.7631851434707642\n",
      "Ep 66: Batch #5 - Loss: 0.6490750908851624\n",
      "Ep 66: Batch #6 - Loss: 0.8533702492713928\n",
      "Ep 66: Batch #7 - Loss: 0.6811268329620361\n",
      "Ep 66: Batch #8 - Loss: 0.7125281691551208\n",
      "Ep 66: Batch #9 - Loss: 1.3607012033462524\n",
      "Ep 66: Batch #10 - Loss: 0.9796263575553894\n",
      "Ep 66: Batch #11 - Loss: 0.6504020690917969\n",
      "Ep 66: Batch #12 - Loss: 1.5282928943634033\n",
      "Ep 66: Batch #13 - Loss: 0.6325989961624146\n",
      "Ep 66: Batch #14 - Loss: 0.7071954011917114\n",
      "Ep 66: Batch #15 - Loss: 1.2038755416870117\n",
      "Ep 66: Batch #16 - Loss: 1.2371333837509155\n",
      "Ep 66: Batch #17 - Loss: 0.8528729677200317\n",
      "Ep 66: Batch #18 - Loss: 0.9240989089012146\n",
      "Ep 66: Batch #19 - Loss: 0.6501145362854004\n",
      "Ep 66: Batch #20 - Loss: 0.6344325542449951\n",
      "Ep 66: Batch #21 - Loss: 1.1858423948287964\n",
      "Ep 66: Batch #22 - Loss: 0.7068799734115601\n",
      "Ep 66: Batch #23 - Loss: 0.7191908955574036\n",
      "Ep 66: Batch #24 - Loss: 0.8024086952209473\n",
      "Ep 66: Batch #25 - Loss: 0.6919200420379639\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 66: Batch #26 - Loss: 0.7050741910934448\n",
      "Ep 66: Batch #27 - Loss: 1.3154516220092773\n",
      "Ep 66: Batch #28 - Loss: 0.8449393510818481\n",
      "Ep 66: Batch #29 - Loss: 0.8633010387420654\n",
      "Ep 66: Batch #30 - Loss: 1.172104835510254\n",
      "Ep 66: Batch #31 - Loss: 0.654573380947113\n",
      "Ep 66: Batch #32 - Loss: 0.7231230139732361\n",
      "Ep 66: Batch #33 - Loss: 0.7849669456481934\n",
      "Ep 66: Batch #34 - Loss: 0.7613252401351929\n",
      "Ep 66: Batch #35 - Loss: 0.916326105594635\n",
      "Ep 66: Batch #36 - Loss: 0.6798804402351379\n",
      "Ep 66: Batch #37 - Loss: 1.1137912273406982\n",
      "Ep 66: Batch #38 - Loss: 0.7187372446060181\n",
      "Ep 66: Batch #39 - Loss: 0.7995356321334839\n",
      "Ep 66: Batch #40 - Loss: 0.7501885890960693\n",
      "Ep 66: Batch #41 - Loss: 0.7105515003204346\n",
      "Ep 66: Batch #42 - Loss: 0.6999784708023071\n",
      "Ep 66: Batch #43 - Loss: 0.7651507258415222\n",
      "Ep 66: Batch #44 - Loss: 0.7585543990135193\n",
      "Ep 66: Batch #45 - Loss: 0.6106058359146118\n",
      "Ep 66: Batch #46 - Loss: 0.8016692996025085\n",
      "Ep 66: Batch #47 - Loss: 0.925935685634613\n",
      "Ep 66: Batch #48 - Loss: 1.3222941160202026\n",
      "Ep 66: Batch #49 - Loss: 0.9786126613616943\n",
      "Ep 66: Batch #50 - Loss: 0.6883382797241211\n",
      "Ep 66: Batch #51 - Loss: 0.9596386551856995\n",
      "Ep 66: Batch #52 - Loss: 0.7726633548736572\n",
      "Ep 66: Batch #53 - Loss: 0.7968353033065796\n",
      "Ep 66: Batch #54 - Loss: 0.6841200590133667\n",
      "Ep 66: Batch #55 - Loss: 0.7269861102104187\n",
      "Ep 66: Batch #56 - Loss: 1.2237141132354736\n",
      "Ep 66: Batch #57 - Loss: 0.8184819221496582\n",
      "Ep 66: Batch #58 - Loss: 0.9640371203422546\n",
      "Ep 66: Batch #59 - Loss: 0.6637951135635376\n",
      "Ep 66: Batch #60 - Loss: 1.2770949602127075\n",
      "Ep 66: Batch #61 - Loss: 0.6171166300773621\n",
      "Ep 66: Batch #62 - Loss: 0.6977749466896057\n",
      "Ep 66: Batch #63 - Loss: 0.9723420739173889\n",
      "Ep 66: Batch #64 - Loss: 9.404315948486328\n",
      "Ep 66: Batch #65 - Loss: 0.5935980081558228\n",
      "Ep 66: Batch #66 - Loss: 0.7693930268287659\n",
      "Ep 66: Batch #67 - Loss: 0.8830760717391968\n",
      "Ep 66: Batch #68 - Loss: 0.8775150179862976\n",
      "Ep 66: Batch #69 - Loss: 0.7221088409423828\n",
      "Ep 66: Batch #70 - Loss: 0.7469421029090881\n",
      "Ep 66: Batch #71 - Loss: 0.6601095199584961\n",
      "Ep 66: Batch #72 - Loss: 0.8275066018104553\n",
      "Ep 66: Batch #73 - Loss: 0.8696591258049011\n",
      "Ep 66: Batch #74 - Loss: 0.713746190071106\n",
      "Ep 66: Batch #75 - Loss: 0.7461157441139221\n",
      "Ep 66: Batch #76 - Loss: 1.0706886053085327\n",
      "Ep 66: Batch #77 - Loss: 0.7094628810882568\n",
      "Ep 66: Batch #78 - Loss: 1.1221588850021362\n",
      "Ep 66: Batch #79 - Loss: 0.60565185546875\n",
      "Ep 66: Batch #80 - Loss: 0.8293866515159607\n",
      "Ep 66: Batch #81 - Loss: 1.6521644592285156\n",
      "Ep 66: Batch #82 - Loss: 0.8482297658920288\n",
      "Ep 66: Batch #83 - Loss: 1.7143099308013916\n",
      "Ep 66: Batch #84 - Loss: 0.6905030012130737\n",
      "Ep 66: Batch #85 - Loss: 0.950915515422821\n",
      "Ep 66: Batch #86 - Loss: 0.6825088262557983\n",
      "Ep 66: Batch #87 - Loss: 0.689800500869751\n",
      "Ep 66: Batch #88 - Loss: 0.7749514579772949\n",
      "Ep 66: Batch #89 - Loss: 0.8662458062171936\n",
      "Ep 66: Batch #90 - Loss: 1.1169880628585815\n",
      "Ep 66: Batch #91 - Loss: 0.7731630206108093\n",
      "Ep 66: Batch #92 - Loss: 0.9969619512557983\n",
      "Ep 66: Batch #93 - Loss: 0.991605281829834\n",
      "Ep 66: Batch #94 - Loss: 1.0160982608795166\n",
      "Ep 66: Batch #95 - Loss: 0.8920904994010925\n",
      "Ep 66: Batch #96 - Loss: 0.8779838681221008\n",
      "Ep 66: Batch #97 - Loss: 0.7046400904655457\n",
      "Ep 66: Batch #98 - Loss: 0.7143603563308716\n",
      "Ep 66: Batch #99 - Loss: 0.9302194118499756\n",
      "Ep 66: Batch #100 - Loss: 0.6550700068473816\n",
      "Ep 66: Batch #101 - Loss: 1.019302487373352\n",
      "Ep 66: Batch #102 - Loss: 0.7575778961181641\n",
      "Ep 66: Batch #103 - Loss: 0.7659192085266113\n",
      "Ep 66: Batch #104 - Loss: 0.7764549851417542\n",
      "Ep 66: Batch #105 - Loss: 0.9960874319076538\n",
      "Ep 66: Batch #106 - Loss: 0.736492395401001\n",
      "Ep 66: Batch #107 - Loss: 0.7325780987739563\n",
      "Ep 66: Batch #108 - Loss: 1.0024503469467163\n",
      "Ep 66: Batch #109 - Loss: 0.7396463751792908\n",
      "Ep 66: Batch #110 - Loss: 0.8854588270187378\n",
      "Ep 66: Batch #111 - Loss: 1.3424396514892578\n",
      "Ep 66: Batch #112 - Loss: 1.0154980421066284\n",
      "Ep 66: Batch #113 - Loss: 0.7907393574714661\n",
      "Ep 66: Batch #114 - Loss: 0.872499942779541\n",
      "Ep 66: Batch #115 - Loss: 1.062462329864502\n",
      "Ep 66: Batch #116 - Loss: 0.6177383661270142\n",
      "Ep 66: Batch #117 - Loss: 0.8478102684020996\n",
      "Ep 66: Batch #118 - Loss: 0.5252781510353088\n",
      "Model saved in file: ./weights_autoencoder_low_LR/model_e66b118_1516651277.6576033.ckpt\n",
      "Ep 66: Batch #119 - Loss: 0.998561441898346\n",
      "Ep 66: Batch #120 - Loss: 0.7765653133392334\n",
      "Ep 66: Batch #121 - Loss: 0.6628692746162415\n",
      "Ep 66: Batch #122 - Loss: 0.8007098436355591\n",
      "Ep 66: Batch #123 - Loss: 0.8060118556022644\n",
      "Ep 66: Batch #124 - Loss: 0.644862949848175\n",
      "Ep 66: Batch #125 - Loss: 2.6816728115081787\n",
      "Ep 66: Batch #126 - Loss: 1.1930171251296997\n",
      "Ep 66: Batch #127 - Loss: 0.7222265601158142\n",
      "Ep 66: Batch #128 - Loss: 1.067246675491333\n",
      "Ep 66: Batch #129 - Loss: 0.8103498816490173\n",
      "Ep 66: Batch #130 - Loss: 0.7001896500587463\n",
      "Ep 66: Batch #131 - Loss: 0.9590596556663513\n",
      "Ep 66: Batch #132 - Loss: 0.7961658239364624\n",
      "Ep 66: Batch #133 - Loss: 0.7906725406646729\n",
      "Ep 66: Batch #134 - Loss: 0.742897629737854\n",
      "Ep 66: Batch #135 - Loss: 0.9333541989326477\n",
      "Ep 66: Batch #136 - Loss: 1.1460604667663574\n",
      "Ep 66: Batch #137 - Loss: 0.9324721097946167\n",
      "Ep 66: Batch #138 - Loss: 1.0383696556091309\n",
      "Ep 66: Batch #139 - Loss: 0.8698715567588806\n",
      "Ep 66: Batch #140 - Loss: 1.0188968181610107\n",
      "Ep 66: Batch #141 - Loss: 1.3232892751693726\n",
      "Ep 66: Batch #142 - Loss: 0.769931972026825\n",
      "Ep 66: Batch #143 - Loss: 0.9300218820571899\n",
      "Ep 66: Batch #144 - Loss: 0.6983957886695862\n",
      "Ep 66: Batch #145 - Loss: 0.6576758027076721\n",
      "Ep 66: Batch #146 - Loss: 0.859102189540863\n",
      "Ep 66: Batch #147 - Loss: 0.8299595713615417\n",
      "Ep 66: Batch #148 - Loss: 0.9437843561172485\n",
      "Ep 66: Batch #149 - Loss: 0.8242499232292175\n",
      "Ep 66: Batch #150 - Loss: 0.8564244508743286\n",
      "Ep 66: Batch #151 - Loss: 0.7093939185142517\n",
      "Ep 66: Batch #152 - Loss: 0.7207157015800476\n",
      "Ep 66: Batch #153 - Loss: 1.0702046155929565\n",
      "Ep 66: Batch #154 - Loss: 0.7390626668930054\n",
      "Ep 66: Batch #155 - Loss: 0.8083667755126953\n",
      "Ep 66: Batch #156 - Loss: 0.9882876873016357\n",
      "Ep 66: Batch #157 - Loss: 0.7368664145469666\n",
      "Ep 66: Batch #158 - Loss: 0.7864347696304321\n",
      "Ep 66: Batch #159 - Loss: 0.7798412442207336\n",
      "Ep 66: Batch #160 - Loss: 0.8810237646102905\n",
      "Ep 66: Batch #161 - Loss: 0.7904863953590393\n",
      "Ep 66: Batch #162 - Loss: 0.9048286080360413\n",
      "Ep 66: Batch #163 - Loss: 0.906361997127533\n",
      "Ep 66: Batch #164 - Loss: 0.7594143748283386\n",
      "Ep 66: Batch #165 - Loss: 1.4726232290267944\n",
      "Ep 66: Batch #166 - Loss: 0.655947208404541\n",
      "Ep 66: Batch #167 - Loss: 1.055850863456726\n",
      "Ep 66: Batch #168 - Loss: 0.8321930170059204\n",
      "Ep 66: Batch #169 - Loss: 0.7774040102958679\n",
      "Ep 66: Batch #170 - Loss: 0.7785881757736206\n",
      "Ep 66: Batch #171 - Loss: 0.7525162100791931\n",
      "Ep 66: Batch #172 - Loss: 0.616246223449707\n",
      "Ep 66: Batch #173 - Loss: 1.1561750173568726\n",
      "Ep 66: Batch #174 - Loss: 0.5611446499824524\n",
      "Ep 66: Batch #175 - Loss: 0.7594404220581055\n",
      "Ep 66: Batch #176 - Loss: 1.116449236869812\n",
      "Ep 66: Batch #177 - Loss: 0.8217648863792419\n",
      "Ep 66: Batch #178 - Loss: 0.737902820110321\n",
      "Ep 66: Batch #179 - Loss: 0.9097506403923035\n",
      "Ep 66: Batch #180 - Loss: 0.8234345316886902\n",
      "Ep 66: Batch #181 - Loss: 0.9574006199836731\n",
      "Ep 66: Batch #182 - Loss: 0.7446097135543823\n",
      "Ep 66: Batch #183 - Loss: 0.7413416504859924\n",
      "Ep 66: Batch #184 - Loss: 1.0433709621429443\n",
      "Ep 66: Batch #185 - Loss: 0.7341218590736389\n",
      "Ep 66: Batch #186 - Loss: 0.9324357509613037\n",
      "Ep 66: Batch #187 - Loss: 1.132774829864502\n",
      "Ep 66: Batch #188 - Loss: 1.3233290910720825\n",
      "Ep 66: Batch #189 - Loss: 0.6833978891372681\n",
      "Ep 66: Batch #190 - Loss: 0.7131764888763428\n",
      "Ep 66: Batch #191 - Loss: 1.0311580896377563\n",
      "Ep 66: Batch #192 - Loss: 0.6522161364555359\n",
      "Ep 66: Batch #193 - Loss: 0.7158847451210022\n",
      "Ep 66: Batch #194 - Loss: 0.6731140613555908\n",
      "Ep 66: Batch #195 - Loss: 0.9534035325050354\n",
      "Ep 66: Batch #196 - Loss: 0.8380651473999023\n",
      "Ep 66: Batch #197 - Loss: 0.8716797828674316\n",
      "Ep 66: Batch #198 - Loss: 0.654155433177948\n",
      "Ep 66: Batch #199 - Loss: 0.8344807028770447\n",
      "Ep 67: Batch #0 - Loss: 0.7628489136695862\n",
      "Ep 67: Batch #1 - Loss: 0.8472468852996826\n",
      "Ep 67: Batch #2 - Loss: 0.9839790463447571\n",
      "Ep 67: Batch #3 - Loss: 0.8404439687728882\n",
      "Ep 67: Batch #4 - Loss: 0.7619712948799133\n",
      "Ep 67: Batch #5 - Loss: 0.6480439901351929\n",
      "Ep 67: Batch #6 - Loss: 0.8521575927734375\n",
      "Ep 67: Batch #7 - Loss: 0.6801934838294983\n",
      "Ep 67: Batch #8 - Loss: 0.7114207148551941\n",
      "Ep 67: Batch #9 - Loss: 1.3587843179702759\n",
      "Ep 67: Batch #10 - Loss: 0.978383481502533\n",
      "Ep 67: Batch #11 - Loss: 0.6495203971862793\n",
      "Ep 67: Batch #12 - Loss: 1.526735782623291\n",
      "Ep 67: Batch #13 - Loss: 0.6317499876022339\n",
      "Ep 67: Batch #14 - Loss: 0.706265926361084\n",
      "Ep 67: Batch #15 - Loss: 1.202093482017517\n",
      "Ep 67: Batch #16 - Loss: 1.235161542892456\n",
      "Ep 67: Batch #17 - Loss: 0.8515952825546265\n",
      "Ep 67: Batch #18 - Loss: 0.9232656359672546\n",
      "Ep 67: Batch #19 - Loss: 0.649333119392395\n",
      "Ep 67: Batch #20 - Loss: 0.6334969401359558\n",
      "Ep 67: Batch #21 - Loss: 1.1846022605895996\n",
      "Ep 67: Batch #22 - Loss: 0.7059817314147949\n",
      "Ep 67: Batch #23 - Loss: 0.7181134819984436\n",
      "Ep 67: Batch #24 - Loss: 0.8015357255935669\n",
      "Ep 67: Batch #25 - Loss: 0.6908644437789917\n",
      "Ep 67: Batch #26 - Loss: 0.7039543986320496\n",
      "Ep 67: Batch #27 - Loss: 1.313571572303772\n",
      "Ep 67: Batch #28 - Loss: 0.8440806269645691\n",
      "Ep 67: Batch #29 - Loss: 0.8618713617324829\n",
      "Ep 67: Batch #30 - Loss: 1.1706279516220093\n",
      "Ep 67: Batch #31 - Loss: 0.6535813808441162\n",
      "Ep 67: Batch #32 - Loss: 0.7219860553741455\n",
      "Ep 67: Batch #33 - Loss: 0.7838955521583557\n",
      "Ep 67: Batch #34 - Loss: 0.7601157426834106\n",
      "Ep 67: Batch #35 - Loss: 0.9148640036582947\n",
      "Ep 67: Batch #36 - Loss: 0.6787214279174805\n",
      "Ep 67: Batch #37 - Loss: 1.1126151084899902\n",
      "Ep 67: Batch #38 - Loss: 0.7174752950668335\n",
      "Ep 67: Batch #39 - Loss: 0.7985007166862488\n",
      "Ep 67: Batch #40 - Loss: 0.7491595149040222\n",
      "Ep 67: Batch #41 - Loss: 0.7092474102973938\n",
      "Ep 67: Batch #42 - Loss: 0.6989210844039917\n",
      "Ep 67: Batch #43 - Loss: 0.7640575170516968\n",
      "Ep 67: Batch #44 - Loss: 0.7572482824325562\n",
      "Ep 67: Batch #45 - Loss: 0.6096542477607727\n",
      "Ep 67: Batch #46 - Loss: 0.8003308773040771\n",
      "Ep 67: Batch #47 - Loss: 0.9241464734077454\n",
      "Ep 67: Batch #48 - Loss: 1.320994257926941\n",
      "Ep 67: Batch #49 - Loss: 0.9769706130027771\n",
      "Ep 67: Batch #50 - Loss: 0.6874703764915466\n",
      "Ep 67: Batch #51 - Loss: 0.9578465819358826\n",
      "Ep 67: Batch #52 - Loss: 0.7715170383453369\n",
      "Ep 67: Batch #53 - Loss: 0.7955418229103088\n",
      "Ep 67: Batch #54 - Loss: 0.6831042170524597\n",
      "Ep 67: Batch #55 - Loss: 0.7259384393692017\n",
      "Ep 67: Batch #56 - Loss: 1.2217915058135986\n",
      "Ep 67: Batch #57 - Loss: 0.8170893788337708\n",
      "Ep 67: Batch #58 - Loss: 0.9623382091522217\n",
      "Ep 67: Batch #59 - Loss: 0.6630582213401794\n",
      "Ep 67: Batch #60 - Loss: 1.2752625942230225\n",
      "Ep 67: Batch #61 - Loss: 0.6163025498390198\n",
      "Ep 67: Batch #62 - Loss: 0.6967214345932007\n",
      "Ep 67: Batch #63 - Loss: 0.9709053635597229\n",
      "Ep 67: Batch #64 - Loss: 9.403101921081543\n",
      "Ep 67: Batch #65 - Loss: 0.5926912426948547\n",
      "Ep 67: Batch #66 - Loss: 0.7682007551193237\n",
      "Ep 67: Batch #67 - Loss: 0.8819180130958557\n",
      "Ep 67: Batch #68 - Loss: 0.8759427070617676\n",
      "Ep 67: Batch #69 - Loss: 0.7211664915084839\n",
      "Ep 67: Batch #70 - Loss: 0.7456387877464294\n",
      "Ep 67: Batch #71 - Loss: 0.6593142151832581\n",
      "Ep 67: Batch #72 - Loss: 0.8263357877731323\n",
      "Ep 67: Batch #73 - Loss: 0.868035614490509\n",
      "Ep 67: Batch #74 - Loss: 0.7124577760696411\n",
      "Ep 67: Batch #75 - Loss: 0.745101273059845\n",
      "Ep 67: Batch #76 - Loss: 1.0693951845169067\n",
      "Ep 67: Batch #77 - Loss: 0.708169162273407\n",
      "Ep 67: Batch #78 - Loss: 1.1202675104141235\n",
      "Ep 67: Batch #79 - Loss: 0.6047758460044861\n",
      "Ep 67: Batch #80 - Loss: 0.8279398679733276\n",
      "Ep 67: Batch #81 - Loss: 1.650948166847229\n",
      "Ep 67: Batch #82 - Loss: 0.8470093011856079\n",
      "Ep 67: Batch #83 - Loss: 1.7133736610412598\n",
      "Ep 67: Batch #84 - Loss: 0.6894382238388062\n",
      "Ep 67: Batch #85 - Loss: 0.9495761394500732\n",
      "Ep 67: Batch #86 - Loss: 0.681310772895813\n",
      "Ep 67: Batch #87 - Loss: 0.6887734532356262\n",
      "Ep 67: Batch #88 - Loss: 0.7737306952476501\n",
      "Ep 67: Batch #89 - Loss: 0.8655074834823608\n",
      "Ep 67: Batch #90 - Loss: 1.1153450012207031\n",
      "Ep 67: Batch #91 - Loss: 0.7717836499214172\n",
      "Ep 67: Batch #92 - Loss: 0.99554842710495\n",
      "Ep 67: Batch #93 - Loss: 0.9896889328956604\n",
      "Ep 67: Batch #94 - Loss: 1.0145342350006104\n",
      "Ep 67: Batch #95 - Loss: 0.8909909129142761\n",
      "Ep 67: Batch #96 - Loss: 0.8766999840736389\n",
      "Ep 67: Batch #97 - Loss: 0.7035367488861084\n",
      "Ep 67: Batch #98 - Loss: 0.7133068442344666\n",
      "Ep 67: Batch #99 - Loss: 0.9288584589958191\n",
      "Ep 67: Batch #100 - Loss: 0.6539999842643738\n",
      "Ep 67: Batch #101 - Loss: 1.0181806087493896\n",
      "Ep 67: Batch #102 - Loss: 0.7563759088516235\n",
      "Ep 67: Batch #103 - Loss: 0.7647190093994141\n",
      "Ep 67: Batch #104 - Loss: 0.7753783464431763\n",
      "Ep 67: Batch #105 - Loss: 0.9947409629821777\n",
      "Ep 67: Batch #106 - Loss: 0.7355747818946838\n",
      "Ep 67: Batch #107 - Loss: 0.7315024137496948\n",
      "Ep 67: Batch #108 - Loss: 1.0011286735534668\n",
      "Ep 67: Batch #109 - Loss: 0.7385125756263733\n",
      "Ep 67: Batch #110 - Loss: 0.8839738368988037\n",
      "Ep 67: Batch #111 - Loss: 1.3407340049743652\n",
      "Ep 67: Batch #112 - Loss: 1.0138072967529297\n",
      "Ep 67: Batch #113 - Loss: 0.7896316647529602\n",
      "Ep 67: Batch #114 - Loss: 0.8709735870361328\n",
      "Ep 67: Batch #115 - Loss: 1.0610017776489258\n",
      "Ep 67: Batch #116 - Loss: 0.6169968843460083\n",
      "Ep 67: Batch #117 - Loss: 0.8466928601264954\n",
      "Ep 67: Batch #118 - Loss: 0.5244362950325012\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved in file: ./weights_autoencoder_low_LR/model_e67b118_1516651277.7971745.ckpt\n",
      "Ep 67: Batch #119 - Loss: 0.9971418380737305\n",
      "Ep 67: Batch #120 - Loss: 0.7755067348480225\n",
      "Ep 67: Batch #121 - Loss: 0.6619037985801697\n",
      "Ep 67: Batch #122 - Loss: 0.7995375394821167\n",
      "Ep 67: Batch #123 - Loss: 0.8048083782196045\n",
      "Ep 67: Batch #124 - Loss: 0.64399653673172\n",
      "Ep 67: Batch #125 - Loss: 2.679948329925537\n",
      "Ep 67: Batch #126 - Loss: 1.191288709640503\n",
      "Ep 67: Batch #127 - Loss: 0.7210545539855957\n",
      "Ep 67: Batch #128 - Loss: 1.065335988998413\n",
      "Ep 67: Batch #129 - Loss: 0.8090876936912537\n",
      "Ep 67: Batch #130 - Loss: 0.699230432510376\n",
      "Ep 67: Batch #131 - Loss: 0.9573690295219421\n",
      "Ep 67: Batch #132 - Loss: 0.7950035929679871\n",
      "Ep 67: Batch #133 - Loss: 0.7893556356430054\n",
      "Ep 67: Batch #134 - Loss: 0.7417055368423462\n",
      "Ep 67: Batch #135 - Loss: 0.931977391242981\n",
      "Ep 67: Batch #136 - Loss: 1.1444751024246216\n",
      "Ep 67: Batch #137 - Loss: 0.9309102296829224\n",
      "Ep 67: Batch #138 - Loss: 1.0368080139160156\n",
      "Ep 67: Batch #139 - Loss: 0.8684127926826477\n",
      "Ep 67: Batch #140 - Loss: 1.0176318883895874\n",
      "Ep 67: Batch #141 - Loss: 1.3214552402496338\n",
      "Ep 67: Batch #142 - Loss: 0.7687279582023621\n",
      "Ep 67: Batch #143 - Loss: 0.9283449053764343\n",
      "Ep 67: Batch #144 - Loss: 0.6974220275878906\n",
      "Ep 67: Batch #145 - Loss: 0.65675288438797\n",
      "Ep 67: Batch #146 - Loss: 0.8580370545387268\n",
      "Ep 67: Batch #147 - Loss: 0.8284995555877686\n",
      "Ep 67: Batch #148 - Loss: 0.9421687722206116\n",
      "Ep 67: Batch #149 - Loss: 0.8229168653488159\n",
      "Ep 67: Batch #150 - Loss: 0.8552934527397156\n",
      "Ep 67: Batch #151 - Loss: 0.7085569500923157\n",
      "Ep 67: Batch #152 - Loss: 0.7199131846427917\n",
      "Ep 67: Batch #153 - Loss: 1.0685240030288696\n",
      "Ep 67: Batch #154 - Loss: 0.7378838658332825\n",
      "Ep 67: Batch #155 - Loss: 0.8072837591171265\n",
      "Ep 67: Batch #156 - Loss: 0.9869219660758972\n",
      "Ep 67: Batch #157 - Loss: 0.7356418371200562\n",
      "Ep 67: Batch #158 - Loss: 0.7855910062789917\n",
      "Ep 67: Batch #159 - Loss: 0.7784764170646667\n",
      "Ep 67: Batch #160 - Loss: 0.8800419569015503\n",
      "Ep 67: Batch #161 - Loss: 0.789294958114624\n",
      "Ep 67: Batch #162 - Loss: 0.9036750197410583\n",
      "Ep 67: Batch #163 - Loss: 0.905089795589447\n",
      "Ep 67: Batch #164 - Loss: 0.7581713199615479\n",
      "Ep 67: Batch #165 - Loss: 1.471501111984253\n",
      "Ep 67: Batch #166 - Loss: 0.6548853516578674\n",
      "Ep 67: Batch #167 - Loss: 1.0544052124023438\n",
      "Ep 67: Batch #168 - Loss: 0.8307913541793823\n",
      "Ep 67: Batch #169 - Loss: 0.7763699293136597\n",
      "Ep 67: Batch #170 - Loss: 0.7774667143821716\n",
      "Ep 67: Batch #171 - Loss: 0.751153290271759\n",
      "Ep 67: Batch #172 - Loss: 0.6154877543449402\n",
      "Ep 67: Batch #173 - Loss: 1.154341697692871\n",
      "Ep 67: Batch #174 - Loss: 0.5602881908416748\n",
      "Ep 67: Batch #175 - Loss: 0.7586381435394287\n",
      "Ep 67: Batch #176 - Loss: 1.1146742105484009\n",
      "Ep 67: Batch #177 - Loss: 0.8205210566520691\n",
      "Ep 67: Batch #178 - Loss: 0.7367828488349915\n",
      "Ep 67: Batch #179 - Loss: 0.908608615398407\n",
      "Ep 67: Batch #180 - Loss: 0.8220576047897339\n",
      "Ep 67: Batch #181 - Loss: 0.955775260925293\n",
      "Ep 67: Batch #182 - Loss: 0.7436679601669312\n",
      "Ep 67: Batch #183 - Loss: 0.7403491735458374\n",
      "Ep 67: Batch #184 - Loss: 1.0420395135879517\n",
      "Ep 67: Batch #185 - Loss: 0.7330182194709778\n",
      "Ep 67: Batch #186 - Loss: 0.9307993650436401\n",
      "Ep 67: Batch #187 - Loss: 1.1310255527496338\n",
      "Ep 67: Batch #188 - Loss: 1.322147011756897\n",
      "Ep 67: Batch #189 - Loss: 0.6826056241989136\n",
      "Ep 67: Batch #190 - Loss: 0.7122057676315308\n",
      "Ep 67: Batch #191 - Loss: 1.0294233560562134\n",
      "Ep 67: Batch #192 - Loss: 0.6515315175056458\n",
      "Ep 67: Batch #193 - Loss: 0.714779257774353\n",
      "Ep 67: Batch #194 - Loss: 0.6720235347747803\n",
      "Ep 67: Batch #195 - Loss: 0.9520763754844666\n",
      "Ep 67: Batch #196 - Loss: 0.8366074562072754\n",
      "Ep 67: Batch #197 - Loss: 0.8701677322387695\n",
      "Ep 67: Batch #198 - Loss: 0.653120756149292\n",
      "Ep 67: Batch #199 - Loss: 0.8333105444908142\n",
      "Ep 68: Batch #0 - Loss: 0.761572003364563\n",
      "Ep 68: Batch #1 - Loss: 0.8458460569381714\n",
      "Ep 68: Batch #2 - Loss: 0.9830127954483032\n",
      "Ep 68: Batch #3 - Loss: 0.8393116593360901\n",
      "Ep 68: Batch #4 - Loss: 0.7607607245445251\n",
      "Ep 68: Batch #5 - Loss: 0.6470128893852234\n",
      "Ep 68: Batch #6 - Loss: 0.8509825468063354\n",
      "Ep 68: Batch #7 - Loss: 0.679241418838501\n",
      "Ep 68: Batch #8 - Loss: 0.7103146314620972\n",
      "Ep 68: Batch #9 - Loss: 1.3568962812423706\n",
      "Ep 68: Batch #10 - Loss: 0.9771488904953003\n",
      "Ep 68: Batch #11 - Loss: 0.6486426591873169\n",
      "Ep 68: Batch #12 - Loss: 1.5252346992492676\n",
      "Ep 68: Batch #13 - Loss: 0.6309318542480469\n",
      "Ep 68: Batch #14 - Loss: 0.7053457498550415\n",
      "Ep 68: Batch #15 - Loss: 1.2003302574157715\n",
      "Ep 68: Batch #16 - Loss: 1.2332096099853516\n",
      "Ep 68: Batch #17 - Loss: 0.8503376841545105\n",
      "Ep 68: Batch #18 - Loss: 0.9224432110786438\n",
      "Ep 68: Batch #19 - Loss: 0.6485738158226013\n",
      "Ep 68: Batch #20 - Loss: 0.6325657367706299\n",
      "Ep 68: Batch #21 - Loss: 1.1833820343017578\n",
      "Ep 68: Batch #22 - Loss: 0.7050879001617432\n",
      "Ep 68: Batch #23 - Loss: 0.7170174717903137\n",
      "Ep 68: Batch #24 - Loss: 0.8006846308708191\n",
      "Ep 68: Batch #25 - Loss: 0.6898368000984192\n",
      "Ep 68: Batch #26 - Loss: 0.7028453350067139\n",
      "Ep 68: Batch #27 - Loss: 1.3117116689682007\n",
      "Ep 68: Batch #28 - Loss: 0.8431963324546814\n",
      "Ep 68: Batch #29 - Loss: 0.8604694604873657\n",
      "Ep 68: Batch #30 - Loss: 1.1691713333129883\n",
      "Ep 68: Batch #31 - Loss: 0.6526217460632324\n",
      "Ep 68: Batch #32 - Loss: 0.7208105325698853\n",
      "Ep 68: Batch #33 - Loss: 0.7828425765037537\n",
      "Ep 68: Batch #34 - Loss: 0.7589271068572998\n",
      "Ep 68: Batch #35 - Loss: 0.9134097695350647\n",
      "Ep 68: Batch #36 - Loss: 0.6775894165039062\n",
      "Ep 68: Batch #37 - Loss: 1.1114555597305298\n",
      "Ep 68: Batch #38 - Loss: 0.7162272334098816\n",
      "Ep 68: Batch #39 - Loss: 0.7974802851676941\n",
      "Ep 68: Batch #40 - Loss: 0.7481309771537781\n",
      "Ep 68: Batch #41 - Loss: 0.707972526550293\n",
      "Ep 68: Batch #42 - Loss: 0.6978869438171387\n",
      "Ep 68: Batch #43 - Loss: 0.7629759907722473\n",
      "Ep 68: Batch #44 - Loss: 0.7559618353843689\n",
      "Ep 68: Batch #45 - Loss: 0.6087185740470886\n",
      "Ep 68: Batch #46 - Loss: 0.7990097999572754\n",
      "Ep 68: Batch #47 - Loss: 0.9223989844322205\n",
      "Ep 68: Batch #48 - Loss: 1.3197451829910278\n",
      "Ep 68: Batch #49 - Loss: 0.9753469824790955\n",
      "Ep 68: Batch #50 - Loss: 0.6866035461425781\n",
      "Ep 68: Batch #51 - Loss: 0.956084668636322\n",
      "Ep 68: Batch #52 - Loss: 0.7704076170921326\n",
      "Ep 68: Batch #53 - Loss: 0.7942752242088318\n",
      "Ep 68: Batch #54 - Loss: 0.6820909380912781\n",
      "Ep 68: Batch #55 - Loss: 0.7249177694320679\n",
      "Ep 68: Batch #56 - Loss: 1.2198892831802368\n",
      "Ep 68: Batch #57 - Loss: 0.8156899213790894\n",
      "Ep 68: Batch #58 - Loss: 0.9606536626815796\n",
      "Ep 68: Batch #59 - Loss: 0.6622927784919739\n",
      "Ep 68: Batch #60 - Loss: 1.273482322692871\n",
      "Ep 68: Batch #61 - Loss: 0.6154974102973938\n",
      "Ep 68: Batch #62 - Loss: 0.6956787705421448\n",
      "Ep 68: Batch #63 - Loss: 0.9694822430610657\n",
      "Ep 68: Batch #64 - Loss: 9.4019193649292\n",
      "Ep 68: Batch #65 - Loss: 0.5918039083480835\n",
      "Ep 68: Batch #66 - Loss: 0.7669955492019653\n",
      "Ep 68: Batch #67 - Loss: 0.8807814121246338\n",
      "Ep 68: Batch #68 - Loss: 0.874393880367279\n",
      "Ep 68: Batch #69 - Loss: 0.7202138304710388\n",
      "Ep 68: Batch #70 - Loss: 0.7443531155586243\n",
      "Ep 68: Batch #71 - Loss: 0.6584922075271606\n",
      "Ep 68: Batch #72 - Loss: 0.8251826167106628\n",
      "Ep 68: Batch #73 - Loss: 0.8664326071739197\n",
      "Ep 68: Batch #74 - Loss: 0.7111898064613342\n",
      "Ep 68: Batch #75 - Loss: 0.7441014647483826\n",
      "Ep 68: Batch #76 - Loss: 1.0681129693984985\n",
      "Ep 68: Batch #77 - Loss: 0.7069104313850403\n",
      "Ep 68: Batch #78 - Loss: 1.1184093952178955\n",
      "Ep 68: Batch #79 - Loss: 0.603890061378479\n",
      "Ep 68: Batch #80 - Loss: 0.826493501663208\n",
      "Ep 68: Batch #81 - Loss: 1.6497316360473633\n",
      "Ep 68: Batch #82 - Loss: 0.8458179235458374\n",
      "Ep 68: Batch #83 - Loss: 1.7124533653259277\n",
      "Ep 68: Batch #84 - Loss: 0.6883841156959534\n",
      "Ep 68: Batch #85 - Loss: 0.9482552409172058\n",
      "Ep 68: Batch #86 - Loss: 0.6801184415817261\n",
      "Ep 68: Batch #87 - Loss: 0.6877556443214417\n",
      "Ep 68: Batch #88 - Loss: 0.7725351452827454\n",
      "Ep 68: Batch #89 - Loss: 0.8648282289505005\n",
      "Ep 68: Batch #90 - Loss: 1.1136953830718994\n",
      "Ep 68: Batch #91 - Loss: 0.7704366445541382\n",
      "Ep 68: Batch #92 - Loss: 0.9941307306289673\n",
      "Ep 68: Batch #93 - Loss: 0.987808108329773\n",
      "Ep 68: Batch #94 - Loss: 1.0129767656326294\n",
      "Ep 68: Batch #95 - Loss: 0.8898845314979553\n",
      "Ep 68: Batch #96 - Loss: 0.8754372596740723\n",
      "Ep 68: Batch #97 - Loss: 0.7024310231208801\n",
      "Ep 68: Batch #98 - Loss: 0.7122672200202942\n",
      "Ep 68: Batch #99 - Loss: 0.9274899363517761\n",
      "Ep 68: Batch #100 - Loss: 0.6529414057731628\n",
      "Ep 68: Batch #101 - Loss: 1.0170649290084839\n",
      "Ep 68: Batch #102 - Loss: 0.7551876902580261\n",
      "Ep 68: Batch #103 - Loss: 0.7635505199432373\n",
      "Ep 68: Batch #104 - Loss: 0.7742807269096375\n",
      "Ep 68: Batch #105 - Loss: 0.9934220910072327\n",
      "Ep 68: Batch #106 - Loss: 0.7346740961074829\n",
      "Ep 68: Batch #107 - Loss: 0.7304373979568481\n",
      "Ep 68: Batch #108 - Loss: 0.9998170733451843\n",
      "Ep 68: Batch #109 - Loss: 0.7373846173286438\n",
      "Ep 68: Batch #110 - Loss: 0.8824787139892578\n",
      "Ep 68: Batch #111 - Loss: 1.3390480279922485\n",
      "Ep 68: Batch #112 - Loss: 1.0121140480041504\n",
      "Ep 68: Batch #113 - Loss: 0.7885403633117676\n",
      "Ep 68: Batch #114 - Loss: 0.8694682717323303\n",
      "Ep 68: Batch #115 - Loss: 1.0595710277557373\n",
      "Ep 68: Batch #116 - Loss: 0.6162728071212769\n",
      "Ep 68: Batch #117 - Loss: 0.8455797433853149\n",
      "Ep 68: Batch #118 - Loss: 0.5236053466796875\n",
      "Model saved in file: ./weights_autoencoder_low_LR/model_e68b118_1516651277.9344435.ckpt\n",
      "Ep 68: Batch #119 - Loss: 0.995742678642273\n",
      "Ep 68: Batch #120 - Loss: 0.774478554725647\n",
      "Ep 68: Batch #121 - Loss: 0.6609482765197754\n",
      "Ep 68: Batch #122 - Loss: 0.7983729243278503\n",
      "Ep 68: Batch #123 - Loss: 0.8036180138587952\n",
      "Ep 68: Batch #124 - Loss: 0.6431527733802795\n",
      "Ep 68: Batch #125 - Loss: 2.678262948989868\n",
      "Ep 68: Batch #126 - Loss: 1.18961501121521\n",
      "Ep 68: Batch #127 - Loss: 0.7198690176010132\n",
      "Ep 68: Batch #128 - Loss: 1.0634740591049194\n",
      "Ep 68: Batch #129 - Loss: 0.8078466653823853\n",
      "Ep 68: Batch #130 - Loss: 0.6982735991477966\n",
      "Ep 68: Batch #131 - Loss: 0.9556995034217834\n",
      "Ep 68: Batch #132 - Loss: 0.7938616871833801\n",
      "Ep 68: Batch #133 - Loss: 0.7880673408508301\n",
      "Ep 68: Batch #134 - Loss: 0.7405309677124023\n",
      "Ep 68: Batch #135 - Loss: 0.9306257963180542\n",
      "Ep 68: Batch #136 - Loss: 1.1429142951965332\n",
      "Ep 68: Batch #137 - Loss: 0.9293803572654724\n",
      "Ep 68: Batch #138 - Loss: 1.035265564918518\n",
      "Ep 68: Batch #139 - Loss: 0.8669739961624146\n",
      "Ep 68: Batch #140 - Loss: 1.0163984298706055\n",
      "Ep 68: Batch #141 - Loss: 1.319632887840271\n",
      "Ep 68: Batch #142 - Loss: 0.7675364017486572\n",
      "Ep 68: Batch #143 - Loss: 0.9267048239707947\n",
      "Ep 68: Batch #144 - Loss: 0.6964760422706604\n",
      "Ep 68: Batch #145 - Loss: 0.6558447480201721\n",
      "Ep 68: Batch #146 - Loss: 0.8569943904876709\n",
      "Ep 68: Batch #147 - Loss: 0.8270770311355591\n",
      "Ep 68: Batch #148 - Loss: 0.9405533075332642\n",
      "Ep 68: Batch #149 - Loss: 0.8216069340705872\n",
      "Ep 68: Batch #150 - Loss: 0.8541702628135681\n",
      "Ep 68: Batch #151 - Loss: 0.707732617855072\n",
      "Ep 68: Batch #152 - Loss: 0.7191212773323059\n",
      "Ep 68: Batch #153 - Loss: 1.0668634176254272\n",
      "Ep 68: Batch #154 - Loss: 0.7367340922355652\n",
      "Ep 68: Batch #155 - Loss: 0.806164026260376\n",
      "Ep 68: Batch #156 - Loss: 0.9855654835700989\n",
      "Ep 68: Batch #157 - Loss: 0.7344260215759277\n",
      "Ep 68: Batch #158 - Loss: 0.7847564816474915\n",
      "Ep 68: Batch #159 - Loss: 0.7771123051643372\n",
      "Ep 68: Batch #160 - Loss: 0.8790802955627441\n",
      "Ep 68: Batch #161 - Loss: 0.7881200313568115\n",
      "Ep 68: Batch #162 - Loss: 0.9025158882141113\n",
      "Ep 68: Batch #163 - Loss: 0.9038485884666443\n",
      "Ep 68: Batch #164 - Loss: 0.7569172382354736\n",
      "Ep 68: Batch #165 - Loss: 1.4704138040542603\n",
      "Ep 68: Batch #166 - Loss: 0.6538373827934265\n",
      "Ep 68: Batch #167 - Loss: 1.052966594696045\n",
      "Ep 68: Batch #168 - Loss: 0.8294126391410828\n",
      "Ep 68: Batch #169 - Loss: 0.7753492593765259\n",
      "Ep 68: Batch #170 - Loss: 0.7763552069664001\n",
      "Ep 68: Batch #171 - Loss: 0.7497990727424622\n",
      "Ep 68: Batch #172 - Loss: 0.6147394180297852\n",
      "Ep 68: Batch #173 - Loss: 1.152457356452942\n",
      "Ep 68: Batch #174 - Loss: 0.5594472289085388\n",
      "Ep 68: Batch #175 - Loss: 0.7578443288803101\n",
      "Ep 68: Batch #176 - Loss: 1.1129204034805298\n",
      "Ep 68: Batch #177 - Loss: 0.8192033171653748\n",
      "Ep 68: Batch #178 - Loss: 0.73566734790802\n",
      "Ep 68: Batch #179 - Loss: 0.9074732065200806\n",
      "Ep 68: Batch #180 - Loss: 0.8206140398979187\n",
      "Ep 68: Batch #181 - Loss: 0.9541775584220886\n",
      "Ep 68: Batch #182 - Loss: 0.7427442073822021\n",
      "Ep 68: Batch #183 - Loss: 0.7393649220466614\n",
      "Ep 68: Batch #184 - Loss: 1.0407339334487915\n",
      "Ep 68: Batch #185 - Loss: 0.7319279313087463\n",
      "Ep 68: Batch #186 - Loss: 0.9291894435882568\n",
      "Ep 68: Batch #187 - Loss: 1.1293184757232666\n",
      "Ep 68: Batch #188 - Loss: 1.3206535577774048\n",
      "Ep 68: Batch #189 - Loss: 0.6818257570266724\n",
      "Ep 68: Batch #190 - Loss: 0.7112597823143005\n",
      "Ep 68: Batch #191 - Loss: 1.027703046798706\n",
      "Ep 68: Batch #192 - Loss: 0.6508522629737854\n",
      "Ep 68: Batch #193 - Loss: 0.7137033939361572\n",
      "Ep 68: Batch #194 - Loss: 0.6709598898887634\n",
      "Ep 68: Batch #195 - Loss: 0.9507673382759094\n",
      "Ep 68: Batch #196 - Loss: 0.8351661562919617\n",
      "Ep 68: Batch #197 - Loss: 0.8686673045158386\n",
      "Ep 68: Batch #198 - Loss: 0.6520606279373169\n",
      "Ep 68: Batch #199 - Loss: 0.832147479057312\n",
      "Ep 69: Batch #0 - Loss: 0.7603232264518738\n",
      "Ep 69: Batch #1 - Loss: 0.8444751501083374\n",
      "Ep 69: Batch #2 - Loss: 0.9820588231086731\n",
      "Ep 69: Batch #3 - Loss: 0.8381913900375366\n",
      "Ep 69: Batch #4 - Loss: 0.7595741748809814\n",
      "Ep 69: Batch #5 - Loss: 0.6459948420524597\n",
      "Ep 69: Batch #6 - Loss: 0.849798858165741\n",
      "Ep 69: Batch #7 - Loss: 0.6783006191253662\n",
      "Ep 69: Batch #8 - Loss: 0.7092081904411316\n",
      "Ep 69: Batch #9 - Loss: 1.3550004959106445\n",
      "Ep 69: Batch #10 - Loss: 0.975939154624939\n",
      "Ep 69: Batch #11 - Loss: 0.6477523446083069\n",
      "Ep 69: Batch #12 - Loss: 1.5237698554992676\n",
      "Ep 69: Batch #13 - Loss: 0.6301291584968567\n",
      "Ep 69: Batch #14 - Loss: 0.7044334411621094\n",
      "Ep 69: Batch #15 - Loss: 1.1985894441604614\n",
      "Ep 69: Batch #16 - Loss: 1.2312849760055542\n",
      "Ep 69: Batch #17 - Loss: 0.8491080403327942\n",
      "Ep 69: Batch #18 - Loss: 0.9216343760490417\n",
      "Ep 69: Batch #19 - Loss: 0.6478344202041626\n",
      "Ep 69: Batch #20 - Loss: 0.6316474676132202\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 69: Batch #21 - Loss: 1.182192325592041\n",
      "Ep 69: Batch #22 - Loss: 0.7041758298873901\n",
      "Ep 69: Batch #23 - Loss: 0.7159141898155212\n",
      "Ep 69: Batch #24 - Loss: 0.7998711466789246\n",
      "Ep 69: Batch #25 - Loss: 0.6888231039047241\n",
      "Ep 69: Batch #26 - Loss: 0.7017379403114319\n",
      "Ep 69: Batch #27 - Loss: 1.3098751306533813\n",
      "Ep 69: Batch #28 - Loss: 0.8423029780387878\n",
      "Ep 69: Batch #29 - Loss: 0.8590921759605408\n",
      "Ep 69: Batch #30 - Loss: 1.1677314043045044\n",
      "Ep 69: Batch #31 - Loss: 0.6516841053962708\n",
      "Ep 69: Batch #32 - Loss: 0.7196328639984131\n",
      "Ep 69: Batch #33 - Loss: 0.781792938709259\n",
      "Ep 69: Batch #34 - Loss: 0.7577581405639648\n",
      "Ep 69: Batch #35 - Loss: 0.9119601845741272\n",
      "Ep 69: Batch #36 - Loss: 0.6764817237854004\n",
      "Ep 69: Batch #37 - Loss: 1.1103105545043945\n",
      "Ep 69: Batch #38 - Loss: 0.7149873971939087\n",
      "Ep 69: Batch #39 - Loss: 0.7964608073234558\n",
      "Ep 69: Batch #40 - Loss: 0.7471053004264832\n",
      "Ep 69: Batch #41 - Loss: 0.7067132592201233\n",
      "Ep 69: Batch #42 - Loss: 0.6968573331832886\n",
      "Ep 69: Batch #43 - Loss: 0.7619143724441528\n",
      "Ep 69: Batch #44 - Loss: 0.7546821236610413\n",
      "Ep 69: Batch #45 - Loss: 0.6077979803085327\n",
      "Ep 69: Batch #46 - Loss: 0.7976789474487305\n",
      "Ep 69: Batch #47 - Loss: 0.9206784963607788\n",
      "Ep 69: Batch #48 - Loss: 1.318549394607544\n",
      "Ep 69: Batch #49 - Loss: 0.9737516045570374\n",
      "Ep 69: Batch #50 - Loss: 0.6857544183731079\n",
      "Ep 69: Batch #51 - Loss: 0.9543483853340149\n",
      "Ep 69: Batch #52 - Loss: 0.7693228721618652\n",
      "Ep 69: Batch #53 - Loss: 0.7930390238761902\n",
      "Ep 69: Batch #54 - Loss: 0.6810778975486755\n",
      "Ep 69: Batch #55 - Loss: 0.7239109873771667\n",
      "Ep 69: Batch #56 - Loss: 1.218005895614624\n",
      "Ep 69: Batch #57 - Loss: 0.8142973184585571\n",
      "Ep 69: Batch #58 - Loss: 0.9589799046516418\n",
      "Ep 69: Batch #59 - Loss: 0.6614171266555786\n",
      "Ep 69: Batch #60 - Loss: 1.271734356880188\n",
      "Ep 69: Batch #61 - Loss: 0.614711344242096\n",
      "Ep 69: Batch #62 - Loss: 0.6946508288383484\n",
      "Ep 69: Batch #63 - Loss: 0.9680399298667908\n",
      "Ep 69: Batch #64 - Loss: 9.400751113891602\n",
      "Ep 69: Batch #65 - Loss: 0.590926468372345\n",
      "Ep 69: Batch #66 - Loss: 0.7657856345176697\n",
      "Ep 69: Batch #67 - Loss: 0.8796645998954773\n",
      "Ep 69: Batch #68 - Loss: 0.8728669881820679\n",
      "Ep 69: Batch #69 - Loss: 0.71926349401474\n",
      "Ep 69: Batch #70 - Loss: 0.7430823445320129\n",
      "Ep 69: Batch #71 - Loss: 0.6576442718505859\n",
      "Ep 69: Batch #72 - Loss: 0.823951780796051\n",
      "Ep 69: Batch #73 - Loss: 0.8648673892021179\n",
      "Ep 69: Batch #74 - Loss: 0.7099393606185913\n",
      "Ep 69: Batch #75 - Loss: 0.7431125640869141\n",
      "Ep 69: Batch #76 - Loss: 1.0668551921844482\n",
      "Ep 69: Batch #77 - Loss: 0.7056867480278015\n",
      "Ep 69: Batch #78 - Loss: 1.1165814399719238\n",
      "Ep 69: Batch #79 - Loss: 0.6030181050300598\n",
      "Ep 69: Batch #80 - Loss: 0.8250604271888733\n",
      "Ep 69: Batch #81 - Loss: 1.6485099792480469\n",
      "Ep 69: Batch #82 - Loss: 0.8446517586708069\n",
      "Ep 69: Batch #83 - Loss: 1.7115504741668701\n",
      "Ep 69: Batch #84 - Loss: 0.6873446702957153\n",
      "Ep 69: Batch #85 - Loss: 0.9469621777534485\n",
      "Ep 69: Batch #86 - Loss: 0.6789435744285583\n",
      "Ep 69: Batch #87 - Loss: 0.6867516040802002\n",
      "Ep 69: Batch #88 - Loss: 0.7713389992713928\n",
      "Ep 69: Batch #89 - Loss: 0.8641659021377563\n",
      "Ep 69: Batch #90 - Loss: 1.112047553062439\n",
      "Ep 69: Batch #91 - Loss: 0.7691137194633484\n",
      "Ep 69: Batch #92 - Loss: 0.9927295446395874\n",
      "Ep 69: Batch #93 - Loss: 0.9859189391136169\n",
      "Ep 69: Batch #94 - Loss: 1.0114336013793945\n",
      "Ep 69: Batch #95 - Loss: 0.8887457251548767\n",
      "Ep 69: Batch #96 - Loss: 0.8742079734802246\n",
      "Ep 69: Batch #97 - Loss: 0.7013291716575623\n",
      "Ep 69: Batch #98 - Loss: 0.711242139339447\n",
      "Ep 69: Batch #99 - Loss: 0.9261318445205688\n",
      "Ep 69: Batch #100 - Loss: 0.651904821395874\n",
      "Ep 69: Batch #101 - Loss: 1.0159504413604736\n",
      "Ep 69: Batch #102 - Loss: 0.7540109157562256\n",
      "Ep 69: Batch #103 - Loss: 0.7624036073684692\n",
      "Ep 69: Batch #104 - Loss: 0.7731678485870361\n",
      "Ep 69: Batch #105 - Loss: 0.9921245574951172\n",
      "Ep 69: Batch #106 - Loss: 0.7337892055511475\n",
      "Ep 69: Batch #107 - Loss: 0.7293809652328491\n",
      "Ep 69: Batch #108 - Loss: 0.9985184669494629\n",
      "Ep 69: Batch #109 - Loss: 0.736272931098938\n",
      "Ep 69: Batch #110 - Loss: 0.8809862732887268\n",
      "Ep 69: Batch #111 - Loss: 1.3373781442642212\n",
      "Ep 69: Batch #112 - Loss: 1.010430932044983\n",
      "Ep 69: Batch #113 - Loss: 0.7874590754508972\n",
      "Ep 69: Batch #114 - Loss: 0.8679888844490051\n",
      "Ep 69: Batch #115 - Loss: 1.0581594705581665\n",
      "Ep 69: Batch #116 - Loss: 0.6155382990837097\n",
      "Ep 69: Batch #117 - Loss: 0.8444674015045166\n",
      "Ep 69: Batch #118 - Loss: 0.5227900743484497\n",
      "Model saved in file: ./weights_autoencoder_low_LR/model_e69b118_1516651278.074065.ckpt\n",
      "Ep 69: Batch #119 - Loss: 0.9943531155586243\n",
      "Ep 69: Batch #120 - Loss: 0.7734612226486206\n",
      "Ep 69: Batch #121 - Loss: 0.6600040793418884\n",
      "Ep 69: Batch #122 - Loss: 0.7972280383110046\n",
      "Ep 69: Batch #123 - Loss: 0.8024389147758484\n",
      "Ep 69: Batch #124 - Loss: 0.6423249840736389\n",
      "Ep 69: Batch #125 - Loss: 2.676603078842163\n",
      "Ep 69: Batch #126 - Loss: 1.1879955530166626\n",
      "Ep 69: Batch #127 - Loss: 0.7186524868011475\n",
      "Ep 69: Batch #128 - Loss: 1.061646819114685\n",
      "Ep 69: Batch #129 - Loss: 0.8065922856330872\n",
      "Ep 69: Batch #130 - Loss: 0.6973207592964172\n",
      "Ep 69: Batch #131 - Loss: 0.9540415406227112\n",
      "Ep 69: Batch #132 - Loss: 0.792733907699585\n",
      "Ep 69: Batch #133 - Loss: 0.7867937088012695\n",
      "Ep 69: Batch #134 - Loss: 0.7393789291381836\n",
      "Ep 69: Batch #135 - Loss: 0.9292969703674316\n",
      "Ep 69: Batch #136 - Loss: 1.1413682699203491\n",
      "Ep 69: Batch #137 - Loss: 0.9278711676597595\n",
      "Ep 69: Batch #138 - Loss: 1.0337356328964233\n",
      "Ep 69: Batch #139 - Loss: 0.8655522465705872\n",
      "Ep 69: Batch #140 - Loss: 1.0151758193969727\n",
      "Ep 69: Batch #141 - Loss: 1.3178565502166748\n",
      "Ep 69: Batch #142 - Loss: 0.7663552761077881\n",
      "Ep 69: Batch #143 - Loss: 0.9250897169113159\n",
      "Ep 69: Batch #144 - Loss: 0.6955470442771912\n",
      "Ep 69: Batch #145 - Loss: 0.6549413800239563\n",
      "Ep 69: Batch #146 - Loss: 0.8559667468070984\n",
      "Ep 69: Batch #147 - Loss: 0.8256750702857971\n",
      "Ep 69: Batch #148 - Loss: 0.9389494061470032\n",
      "Ep 69: Batch #149 - Loss: 0.820311427116394\n",
      "Ep 69: Batch #150 - Loss: 0.8530537486076355\n",
      "Ep 69: Batch #151 - Loss: 0.7069177627563477\n",
      "Ep 69: Batch #152 - Loss: 0.718336284160614\n",
      "Ep 69: Batch #153 - Loss: 1.065219759941101\n",
      "Ep 69: Batch #154 - Loss: 0.7356103658676147\n",
      "Ep 69: Batch #155 - Loss: 0.8049171566963196\n",
      "Ep 69: Batch #156 - Loss: 0.9842327833175659\n",
      "Ep 69: Batch #157 - Loss: 0.7331998348236084\n",
      "Ep 69: Batch #158 - Loss: 0.7839365005493164\n",
      "Ep 69: Batch #159 - Loss: 0.7757644057273865\n",
      "Ep 69: Batch #160 - Loss: 0.8781306743621826\n",
      "Ep 69: Batch #161 - Loss: 0.786950945854187\n",
      "Ep 69: Batch #162 - Loss: 0.9012125134468079\n",
      "Ep 69: Batch #163 - Loss: 0.9026356339454651\n",
      "Ep 69: Batch #164 - Loss: 0.7556689381599426\n",
      "Ep 69: Batch #165 - Loss: 1.4693447351455688\n",
      "Ep 69: Batch #166 - Loss: 0.6528014540672302\n",
      "Ep 69: Batch #167 - Loss: 1.0515332221984863\n",
      "Ep 69: Batch #168 - Loss: 0.8280565738677979\n",
      "Ep 69: Batch #169 - Loss: 0.7743285298347473\n",
      "Ep 69: Batch #170 - Loss: 0.7752564549446106\n",
      "Ep 69: Batch #171 - Loss: 0.7484709024429321\n",
      "Ep 69: Batch #172 - Loss: 0.6140025854110718\n",
      "Ep 69: Batch #173 - Loss: 1.1505320072174072\n",
      "Ep 69: Batch #174 - Loss: 0.558622419834137\n",
      "Ep 69: Batch #175 - Loss: 0.7570553421974182\n",
      "Ep 69: Batch #176 - Loss: 1.1111916303634644\n",
      "Ep 69: Batch #177 - Loss: 0.8179054260253906\n",
      "Ep 69: Batch #178 - Loss: 0.7345629334449768\n",
      "Ep 69: Batch #179 - Loss: 0.906353235244751\n",
      "Ep 69: Batch #180 - Loss: 0.8191711902618408\n",
      "Ep 69: Batch #181 - Loss: 0.9525981545448303\n",
      "Ep 69: Batch #182 - Loss: 0.7418422102928162\n",
      "Ep 69: Batch #183 - Loss: 0.7383967638015747\n",
      "Ep 69: Batch #184 - Loss: 1.0394538640975952\n",
      "Ep 69: Batch #185 - Loss: 0.7308582067489624\n",
      "Ep 69: Batch #186 - Loss: 0.9275606274604797\n",
      "Ep 69: Batch #187 - Loss: 1.1276483535766602\n",
      "Ep 69: Batch #188 - Loss: 1.3191590309143066\n",
      "Ep 69: Batch #189 - Loss: 0.6810640096664429\n",
      "Ep 69: Batch #190 - Loss: 0.7103273868560791\n",
      "Ep 69: Batch #191 - Loss: 1.0260013341903687\n",
      "Ep 69: Batch #192 - Loss: 0.6501718163490295\n",
      "Ep 69: Batch #193 - Loss: 0.7126482725143433\n",
      "Ep 69: Batch #194 - Loss: 0.669912576675415\n",
      "Ep 69: Batch #195 - Loss: 0.9494661092758179\n",
      "Ep 69: Batch #196 - Loss: 0.8337497115135193\n",
      "Ep 69: Batch #197 - Loss: 0.8671607375144958\n",
      "Ep 69: Batch #198 - Loss: 0.6510107517242432\n",
      "Ep 69: Batch #199 - Loss: 0.8309926390647888\n",
      "Ep 70: Batch #0 - Loss: 0.7590935230255127\n",
      "Ep 70: Batch #1 - Loss: 0.8431156873703003\n",
      "Ep 70: Batch #2 - Loss: 0.9811194539070129\n",
      "Ep 70: Batch #3 - Loss: 0.8370630741119385\n",
      "Ep 70: Batch #4 - Loss: 0.758405864238739\n",
      "Ep 70: Batch #5 - Loss: 0.6450023651123047\n",
      "Ep 70: Batch #6 - Loss: 0.8486335277557373\n",
      "Ep 70: Batch #7 - Loss: 0.6773771643638611\n",
      "Ep 70: Batch #8 - Loss: 0.7081246972084045\n",
      "Ep 70: Batch #9 - Loss: 1.3531205654144287\n",
      "Ep 70: Batch #10 - Loss: 0.9747505187988281\n",
      "Ep 70: Batch #11 - Loss: 0.6468715071678162\n",
      "Ep 70: Batch #12 - Loss: 1.5223392248153687\n",
      "Ep 70: Batch #13 - Loss: 0.629336953163147\n",
      "Ep 70: Batch #14 - Loss: 0.7035355567932129\n",
      "Ep 70: Batch #15 - Loss: 1.1968696117401123\n",
      "Ep 70: Batch #16 - Loss: 1.2293810844421387\n",
      "Ep 70: Batch #17 - Loss: 0.847900390625\n",
      "Ep 70: Batch #18 - Loss: 0.9208384156227112\n",
      "Ep 70: Batch #19 - Loss: 0.6471068859100342\n",
      "Ep 70: Batch #20 - Loss: 0.6307321786880493\n",
      "Ep 70: Batch #21 - Loss: 1.1810252666473389\n",
      "Ep 70: Batch #22 - Loss: 0.7032420039176941\n",
      "Ep 70: Batch #23 - Loss: 0.7148160338401794\n",
      "Ep 70: Batch #24 - Loss: 0.7991085648536682\n",
      "Ep 70: Batch #25 - Loss: 0.6878203749656677\n",
      "Ep 70: Batch #26 - Loss: 0.7006326913833618\n",
      "Ep 70: Batch #27 - Loss: 1.3080594539642334\n",
      "Ep 70: Batch #28 - Loss: 0.8413922190666199\n",
      "Ep 70: Batch #29 - Loss: 0.857740581035614\n",
      "Ep 70: Batch #30 - Loss: 1.1662739515304565\n",
      "Ep 70: Batch #31 - Loss: 0.6507687568664551\n",
      "Ep 70: Batch #32 - Loss: 0.7184779047966003\n",
      "Ep 70: Batch #33 - Loss: 0.7807646989822388\n",
      "Ep 70: Batch #34 - Loss: 0.7566092014312744\n",
      "Ep 70: Batch #35 - Loss: 0.9105337858200073\n",
      "Ep 70: Batch #36 - Loss: 0.675386369228363\n",
      "Ep 70: Batch #37 - Loss: 1.1091760396957397\n",
      "Ep 70: Batch #38 - Loss: 0.7137579321861267\n",
      "Ep 70: Batch #39 - Loss: 0.7954432964324951\n",
      "Ep 70: Batch #40 - Loss: 0.7460998892784119\n",
      "Ep 70: Batch #41 - Loss: 0.7054412364959717\n",
      "Ep 70: Batch #42 - Loss: 0.6958341598510742\n",
      "Ep 70: Batch #43 - Loss: 0.760871410369873\n",
      "Ep 70: Batch #44 - Loss: 0.7534182667732239\n",
      "Ep 70: Batch #45 - Loss: 0.6068965196609497\n",
      "Ep 70: Batch #46 - Loss: 0.7963364720344543\n",
      "Ep 70: Batch #47 - Loss: 0.9189776182174683\n",
      "Ep 70: Batch #48 - Loss: 1.3174495697021484\n",
      "Ep 70: Batch #49 - Loss: 0.9721774458885193\n",
      "Ep 70: Batch #50 - Loss: 0.6849173307418823\n",
      "Ep 70: Batch #51 - Loss: 0.952629029750824\n",
      "Ep 70: Batch #52 - Loss: 0.7682573199272156\n",
      "Ep 70: Batch #53 - Loss: 0.791822075843811\n",
      "Ep 70: Batch #54 - Loss: 0.6800745129585266\n",
      "Ep 70: Batch #55 - Loss: 0.7229126691818237\n",
      "Ep 70: Batch #56 - Loss: 1.2161496877670288\n",
      "Ep 70: Batch #57 - Loss: 0.8128878474235535\n",
      "Ep 70: Batch #58 - Loss: 0.9573124051094055\n",
      "Ep 70: Batch #59 - Loss: 0.6605573296546936\n",
      "Ep 70: Batch #60 - Loss: 1.2700068950653076\n",
      "Ep 70: Batch #61 - Loss: 0.6139358878135681\n",
      "Ep 70: Batch #62 - Loss: 0.6936396360397339\n",
      "Ep 70: Batch #63 - Loss: 0.9665988683700562\n",
      "Ep 70: Batch #64 - Loss: 9.399590492248535\n",
      "Ep 70: Batch #65 - Loss: 0.5900658965110779\n",
      "Ep 70: Batch #66 - Loss: 0.7645827531814575\n",
      "Ep 70: Batch #67 - Loss: 0.8785702586174011\n",
      "Ep 70: Batch #68 - Loss: 0.871357262134552\n",
      "Ep 70: Batch #69 - Loss: 0.7183224558830261\n",
      "Ep 70: Batch #70 - Loss: 0.7418266534805298\n",
      "Ep 70: Batch #71 - Loss: 0.6567975282669067\n",
      "Ep 70: Batch #72 - Loss: 0.8226683139801025\n",
      "Ep 70: Batch #73 - Loss: 0.8633185625076294\n",
      "Ep 70: Batch #74 - Loss: 0.7087010145187378\n",
      "Ep 70: Batch #75 - Loss: 0.7421392798423767\n",
      "Ep 70: Batch #76 - Loss: 1.0656005144119263\n",
      "Ep 70: Batch #77 - Loss: 0.7044790387153625\n",
      "Ep 70: Batch #78 - Loss: 1.1147798299789429\n",
      "Ep 70: Batch #79 - Loss: 0.6021718382835388\n",
      "Ep 70: Batch #80 - Loss: 0.8236277103424072\n",
      "Ep 70: Batch #81 - Loss: 1.647295594215393\n",
      "Ep 70: Batch #82 - Loss: 0.8435071110725403\n",
      "Ep 70: Batch #83 - Loss: 1.7106634378433228\n",
      "Ep 70: Batch #84 - Loss: 0.686321496963501\n",
      "Ep 70: Batch #85 - Loss: 0.9457003474235535\n",
      "Ep 70: Batch #86 - Loss: 0.6777825951576233\n",
      "Ep 70: Batch #87 - Loss: 0.6857552528381348\n",
      "Ep 70: Batch #88 - Loss: 0.7701379656791687\n",
      "Ep 70: Batch #89 - Loss: 0.8635030388832092\n",
      "Ep 70: Batch #90 - Loss: 1.1104176044464111\n",
      "Ep 70: Batch #91 - Loss: 0.767815351486206\n",
      "Ep 70: Batch #92 - Loss: 0.9913322329521179\n",
      "Ep 70: Batch #93 - Loss: 0.9840413928031921\n",
      "Ep 70: Batch #94 - Loss: 1.0099000930786133\n",
      "Ep 70: Batch #95 - Loss: 0.8875536918640137\n",
      "Ep 70: Batch #96 - Loss: 0.8730015158653259\n",
      "Ep 70: Batch #97 - Loss: 0.7002316117286682\n",
      "Ep 70: Batch #98 - Loss: 0.7102187871932983\n",
      "Ep 70: Batch #99 - Loss: 0.9248008131980896\n",
      "Ep 70: Batch #100 - Loss: 0.6508732438087463\n",
      "Ep 70: Batch #101 - Loss: 1.014845848083496\n",
      "Ep 70: Batch #102 - Loss: 0.7528532147407532\n",
      "Ep 70: Batch #103 - Loss: 0.7612523436546326\n",
      "Ep 70: Batch #104 - Loss: 0.7720618844032288\n",
      "Ep 70: Batch #105 - Loss: 0.9908410310745239\n",
      "Ep 70: Batch #106 - Loss: 0.7329161167144775\n",
      "Ep 70: Batch #107 - Loss: 0.7283344268798828\n",
      "Ep 70: Batch #108 - Loss: 0.9972364902496338\n",
      "Ep 70: Batch #109 - Loss: 0.7351788282394409\n",
      "Ep 70: Batch #110 - Loss: 0.8795158863067627\n",
      "Ep 70: Batch #111 - Loss: 1.3357248306274414\n",
      "Ep 70: Batch #112 - Loss: 1.0087724924087524\n",
      "Ep 70: Batch #113 - Loss: 0.786392867565155\n",
      "Ep 70: Batch #114 - Loss: 0.866538405418396\n",
      "Ep 70: Batch #115 - Loss: 1.0567680597305298\n",
      "Ep 70: Batch #116 - Loss: 0.6148078441619873\n",
      "Ep 70: Batch #117 - Loss: 0.8433629274368286\n",
      "Ep 70: Batch #118 - Loss: 0.5219852924346924\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved in file: ./weights_autoencoder_low_LR/model_e70b118_1516651278.2117393.ckpt\n",
      "Ep 70: Batch #119 - Loss: 0.9929347038269043\n",
      "Ep 70: Batch #120 - Loss: 0.7724565267562866\n",
      "Ep 70: Batch #121 - Loss: 0.6590521335601807\n",
      "Ep 70: Batch #122 - Loss: 0.7960641384124756\n",
      "Ep 70: Batch #123 - Loss: 0.8012813329696655\n",
      "Ep 70: Batch #124 - Loss: 0.6415086984634399\n",
      "Ep 70: Batch #125 - Loss: 2.6749677658081055\n",
      "Ep 70: Batch #126 - Loss: 1.1864335536956787\n",
      "Ep 70: Batch #127 - Loss: 0.7174084186553955\n",
      "Ep 70: Batch #128 - Loss: 1.059845209121704\n",
      "Ep 70: Batch #129 - Loss: 0.8053502440452576\n",
      "Ep 70: Batch #130 - Loss: 0.6963755488395691\n",
      "Ep 70: Batch #131 - Loss: 0.9524151682853699\n",
      "Ep 70: Batch #132 - Loss: 0.7916174530982971\n",
      "Ep 70: Batch #133 - Loss: 0.7855307459831238\n",
      "Ep 70: Batch #134 - Loss: 0.7382473945617676\n",
      "Ep 70: Batch #135 - Loss: 0.9279753565788269\n",
      "Ep 70: Batch #136 - Loss: 1.1398481130599976\n",
      "Ep 70: Batch #137 - Loss: 0.9263889193534851\n",
      "Ep 70: Batch #138 - Loss: 1.0322155952453613\n",
      "Ep 70: Batch #139 - Loss: 0.8641354441642761\n",
      "Ep 70: Batch #140 - Loss: 1.0139646530151367\n",
      "Ep 70: Batch #141 - Loss: 1.3161274194717407\n",
      "Ep 70: Batch #142 - Loss: 0.765191376209259\n",
      "Ep 70: Batch #143 - Loss: 0.9235036373138428\n",
      "Ep 70: Batch #144 - Loss: 0.6946306228637695\n",
      "Ep 70: Batch #145 - Loss: 0.6540501117706299\n",
      "Ep 70: Batch #146 - Loss: 0.8549569845199585\n",
      "Ep 70: Batch #147 - Loss: 0.8242824673652649\n",
      "Ep 70: Batch #148 - Loss: 0.9373683333396912\n",
      "Ep 70: Batch #149 - Loss: 0.8190391659736633\n",
      "Ep 70: Batch #150 - Loss: 0.8519628643989563\n",
      "Ep 70: Batch #151 - Loss: 0.7061078548431396\n",
      "Ep 70: Batch #152 - Loss: 0.7175595164299011\n",
      "Ep 70: Batch #153 - Loss: 1.0636026859283447\n",
      "Ep 70: Batch #154 - Loss: 0.7344961166381836\n",
      "Ep 70: Batch #155 - Loss: 0.803695023059845\n",
      "Ep 70: Batch #156 - Loss: 0.9829246997833252\n",
      "Ep 70: Batch #157 - Loss: 0.7319936752319336\n",
      "Ep 70: Batch #158 - Loss: 0.7831335067749023\n",
      "Ep 70: Batch #159 - Loss: 0.7744354605674744\n",
      "Ep 70: Batch #160 - Loss: 0.8771648406982422\n",
      "Ep 70: Batch #161 - Loss: 0.7857961058616638\n",
      "Ep 70: Batch #162 - Loss: 0.8999170064926147\n",
      "Ep 70: Batch #163 - Loss: 0.9014464020729065\n",
      "Ep 70: Batch #164 - Loss: 0.7544344067573547\n",
      "Ep 70: Batch #165 - Loss: 1.4682883024215698\n",
      "Ep 70: Batch #166 - Loss: 0.6517671942710876\n",
      "Ep 70: Batch #167 - Loss: 1.050123929977417\n",
      "Ep 70: Batch #168 - Loss: 0.8267229795455933\n",
      "Ep 70: Batch #169 - Loss: 0.7733107209205627\n",
      "Ep 70: Batch #170 - Loss: 0.774162232875824\n",
      "Ep 70: Batch #171 - Loss: 0.7471506595611572\n",
      "Ep 70: Batch #172 - Loss: 0.613288402557373\n",
      "Ep 70: Batch #173 - Loss: 1.1486310958862305\n",
      "Ep 70: Batch #174 - Loss: 0.5578104853630066\n",
      "Ep 70: Batch #175 - Loss: 0.7562463879585266\n",
      "Ep 70: Batch #176 - Loss: 1.1094937324523926\n",
      "Ep 70: Batch #177 - Loss: 0.8166362643241882\n",
      "Ep 70: Batch #178 - Loss: 0.7334712147712708\n",
      "Ep 70: Batch #179 - Loss: 0.9052303433418274\n",
      "Ep 70: Batch #180 - Loss: 0.8177334070205688\n",
      "Ep 70: Batch #181 - Loss: 0.9510313868522644\n",
      "Ep 70: Batch #182 - Loss: 0.7409397959709167\n",
      "Ep 70: Batch #183 - Loss: 0.7374466061592102\n",
      "Ep 70: Batch #184 - Loss: 1.0381978750228882\n",
      "Ep 70: Batch #185 - Loss: 0.7297949194908142\n",
      "Ep 70: Batch #186 - Loss: 0.925946056842804\n",
      "Ep 70: Batch #187 - Loss: 1.125990390777588\n",
      "Ep 70: Batch #188 - Loss: 1.3176771402359009\n",
      "Ep 70: Batch #189 - Loss: 0.6803174018859863\n",
      "Ep 70: Batch #190 - Loss: 0.7093800902366638\n",
      "Ep 70: Batch #191 - Loss: 1.024314284324646\n",
      "Ep 70: Batch #192 - Loss: 0.649503231048584\n",
      "Ep 70: Batch #193 - Loss: 0.7116126418113708\n",
      "Ep 70: Batch #194 - Loss: 0.6688747406005859\n",
      "Ep 70: Batch #195 - Loss: 0.9481355547904968\n",
      "Ep 70: Batch #196 - Loss: 0.8323602676391602\n",
      "Ep 70: Batch #197 - Loss: 0.8656644821166992\n",
      "Ep 70: Batch #198 - Loss: 0.6499715447425842\n",
      "Ep 70: Batch #199 - Loss: 0.8298310041427612\n",
      "Ep 71: Batch #0 - Loss: 0.757851243019104\n",
      "Ep 71: Batch #1 - Loss: 0.8417694568634033\n",
      "Ep 71: Batch #2 - Loss: 0.9801915884017944\n",
      "Ep 71: Batch #3 - Loss: 0.8359436392784119\n",
      "Ep 71: Batch #4 - Loss: 0.7572596669197083\n",
      "Ep 71: Batch #5 - Loss: 0.6440306901931763\n",
      "Ep 71: Batch #6 - Loss: 0.8474783301353455\n",
      "Ep 71: Batch #7 - Loss: 0.6764587163925171\n",
      "Ep 71: Batch #8 - Loss: 0.7070611715316772\n",
      "Ep 71: Batch #9 - Loss: 1.3512542247772217\n",
      "Ep 71: Batch #10 - Loss: 0.9735704660415649\n",
      "Ep 71: Batch #11 - Loss: 0.645997166633606\n",
      "Ep 71: Batch #12 - Loss: 1.5209286212921143\n",
      "Ep 71: Batch #13 - Loss: 0.6285608410835266\n",
      "Ep 71: Batch #14 - Loss: 0.7026455402374268\n",
      "Ep 71: Batch #15 - Loss: 1.1951704025268555\n",
      "Ep 71: Batch #16 - Loss: 1.2274703979492188\n",
      "Ep 71: Batch #17 - Loss: 0.8467066287994385\n",
      "Ep 71: Batch #18 - Loss: 0.9200522899627686\n",
      "Ep 71: Batch #19 - Loss: 0.6463887691497803\n",
      "Ep 71: Batch #20 - Loss: 0.6298326253890991\n",
      "Ep 71: Batch #21 - Loss: 1.1798813343048096\n",
      "Ep 71: Batch #22 - Loss: 0.7023195624351501\n",
      "Ep 71: Batch #23 - Loss: 0.7137134671211243\n",
      "Ep 71: Batch #24 - Loss: 0.7983663082122803\n",
      "Ep 71: Batch #25 - Loss: 0.6868292689323425\n",
      "Ep 71: Batch #26 - Loss: 0.6995474100112915\n",
      "Ep 71: Batch #27 - Loss: 1.3062602281570435\n",
      "Ep 71: Batch #28 - Loss: 0.8404716849327087\n",
      "Ep 71: Batch #29 - Loss: 0.8564163446426392\n",
      "Ep 71: Batch #30 - Loss: 1.1648283004760742\n",
      "Ep 71: Batch #31 - Loss: 0.6498730182647705\n",
      "Ep 71: Batch #32 - Loss: 0.7173447608947754\n",
      "Ep 71: Batch #33 - Loss: 0.7797535061836243\n",
      "Ep 71: Batch #34 - Loss: 0.7554765343666077\n",
      "Ep 71: Batch #35 - Loss: 0.909118115901947\n",
      "Ep 71: Batch #36 - Loss: 0.6742914915084839\n",
      "Ep 71: Batch #37 - Loss: 1.1080524921417236\n",
      "Ep 71: Batch #38 - Loss: 0.7125328183174133\n",
      "Ep 71: Batch #39 - Loss: 0.7943956851959229\n",
      "Ep 71: Batch #40 - Loss: 0.7451049089431763\n",
      "Ep 71: Batch #41 - Loss: 0.7041792273521423\n",
      "Ep 71: Batch #42 - Loss: 0.6948104500770569\n",
      "Ep 71: Batch #43 - Loss: 0.7598400712013245\n",
      "Ep 71: Batch #44 - Loss: 0.7521722316741943\n",
      "Ep 71: Batch #45 - Loss: 0.6060090065002441\n",
      "Ep 71: Batch #46 - Loss: 0.7950165271759033\n",
      "Ep 71: Batch #47 - Loss: 0.9172954559326172\n",
      "Ep 71: Batch #48 - Loss: 1.3163281679153442\n",
      "Ep 71: Batch #49 - Loss: 0.9706190228462219\n",
      "Ep 71: Batch #50 - Loss: 0.6840947866439819\n",
      "Ep 71: Batch #51 - Loss: 0.9509252905845642\n",
      "Ep 71: Batch #52 - Loss: 0.7672060132026672\n",
      "Ep 71: Batch #53 - Loss: 0.7906166315078735\n",
      "Ep 71: Batch #54 - Loss: 0.6790646910667419\n",
      "Ep 71: Batch #55 - Loss: 0.7219233512878418\n",
      "Ep 71: Batch #56 - Loss: 1.2143055200576782\n",
      "Ep 71: Batch #57 - Loss: 0.811486005783081\n",
      "Ep 71: Batch #58 - Loss: 0.9556460976600647\n",
      "Ep 71: Batch #59 - Loss: 0.659702718257904\n",
      "Ep 71: Batch #60 - Loss: 1.268295407295227\n",
      "Ep 71: Batch #61 - Loss: 0.6131755709648132\n",
      "Ep 71: Batch #62 - Loss: 0.6926426291465759\n",
      "Ep 71: Batch #63 - Loss: 0.9651691913604736\n",
      "Ep 71: Batch #64 - Loss: 9.398432731628418\n",
      "Ep 71: Batch #65 - Loss: 0.5892196297645569\n",
      "Ep 71: Batch #66 - Loss: 0.7633962035179138\n",
      "Ep 71: Batch #67 - Loss: 0.8774950504302979\n",
      "Ep 71: Batch #68 - Loss: 0.8698666095733643\n",
      "Ep 71: Batch #69 - Loss: 0.7173866629600525\n",
      "Ep 71: Batch #70 - Loss: 0.740569531917572\n",
      "Ep 71: Batch #71 - Loss: 0.6559452414512634\n",
      "Ep 71: Batch #72 - Loss: 0.8213742971420288\n",
      "Ep 71: Batch #73 - Loss: 0.8617972135543823\n",
      "Ep 71: Batch #74 - Loss: 0.707474410533905\n",
      "Ep 71: Batch #75 - Loss: 0.7411839962005615\n",
      "Ep 71: Batch #76 - Loss: 1.0643607378005981\n",
      "Ep 71: Batch #77 - Loss: 0.703281819820404\n",
      "Ep 71: Batch #78 - Loss: 1.1129815578460693\n",
      "Ep 71: Batch #79 - Loss: 0.6013443470001221\n",
      "Ep 71: Batch #80 - Loss: 0.8222063183784485\n",
      "Ep 71: Batch #81 - Loss: 1.646096110343933\n",
      "Ep 71: Batch #82 - Loss: 0.8423821926116943\n",
      "Ep 71: Batch #83 - Loss: 1.7097853422164917\n",
      "Ep 71: Batch #84 - Loss: 0.6852902173995972\n",
      "Ep 71: Batch #85 - Loss: 0.9444258809089661\n",
      "Ep 71: Batch #86 - Loss: 0.676638662815094\n",
      "Ep 71: Batch #87 - Loss: 0.6847680807113647\n",
      "Ep 71: Batch #88 - Loss: 0.7689489126205444\n",
      "Ep 71: Batch #89 - Loss: 0.8627863526344299\n",
      "Ep 71: Batch #90 - Loss: 1.1087723970413208\n",
      "Ep 71: Batch #91 - Loss: 0.7665334343910217\n",
      "Ep 71: Batch #92 - Loss: 0.9898749589920044\n",
      "Ep 71: Batch #93 - Loss: 0.9821760058403015\n",
      "Ep 71: Batch #94 - Loss: 1.0083463191986084\n",
      "Ep 71: Batch #95 - Loss: 0.8863810300827026\n",
      "Ep 71: Batch #96 - Loss: 0.8718080520629883\n",
      "Ep 71: Batch #97 - Loss: 0.6991510391235352\n",
      "Ep 71: Batch #98 - Loss: 0.70919269323349\n",
      "Ep 71: Batch #99 - Loss: 0.9234902858734131\n",
      "Ep 71: Batch #100 - Loss: 0.6498528122901917\n",
      "Ep 71: Batch #101 - Loss: 1.0137492418289185\n",
      "Ep 71: Batch #102 - Loss: 0.7517025470733643\n",
      "Ep 71: Batch #103 - Loss: 0.760108232498169\n",
      "Ep 71: Batch #104 - Loss: 0.7709720134735107\n",
      "Ep 71: Batch #105 - Loss: 0.9895788431167603\n",
      "Ep 71: Batch #106 - Loss: 0.7320519685745239\n",
      "Ep 71: Batch #107 - Loss: 0.7272969484329224\n",
      "Ep 71: Batch #108 - Loss: 0.9959304332733154\n",
      "Ep 71: Batch #109 - Loss: 0.7340933680534363\n",
      "Ep 71: Batch #110 - Loss: 0.8780588507652283\n",
      "Ep 71: Batch #111 - Loss: 1.3340771198272705\n",
      "Ep 71: Batch #112 - Loss: 1.007137417793274\n",
      "Ep 71: Batch #113 - Loss: 0.7853372097015381\n",
      "Ep 71: Batch #114 - Loss: 0.8651107549667358\n",
      "Ep 71: Batch #115 - Loss: 1.0553908348083496\n",
      "Ep 71: Batch #116 - Loss: 0.6140791773796082\n",
      "Ep 71: Batch #117 - Loss: 0.8422577381134033\n",
      "Ep 71: Batch #118 - Loss: 0.5211926698684692\n",
      "Model saved in file: ./weights_autoencoder_low_LR/model_e71b118_1516651278.3522077.ckpt\n",
      "Ep 71: Batch #119 - Loss: 0.9915210008621216\n",
      "Ep 71: Batch #120 - Loss: 0.7714593410491943\n",
      "Ep 71: Batch #121 - Loss: 0.6580641865730286\n",
      "Ep 71: Batch #122 - Loss: 0.794912576675415\n",
      "Ep 71: Batch #123 - Loss: 0.8001323342323303\n",
      "Ep 71: Batch #124 - Loss: 0.640709400177002\n",
      "Ep 71: Batch #125 - Loss: 2.6733174324035645\n",
      "Ep 71: Batch #126 - Loss: 1.1849173307418823\n",
      "Ep 71: Batch #127 - Loss: 0.7161589860916138\n",
      "Ep 71: Batch #128 - Loss: 1.0580508708953857\n",
      "Ep 71: Batch #129 - Loss: 0.8041240572929382\n",
      "Ep 71: Batch #130 - Loss: 0.6954374313354492\n",
      "Ep 71: Batch #131 - Loss: 0.9508159756660461\n",
      "Ep 71: Batch #132 - Loss: 0.7905110120773315\n",
      "Ep 71: Batch #133 - Loss: 0.7842839360237122\n",
      "Ep 71: Batch #134 - Loss: 0.737128734588623\n",
      "Ep 71: Batch #135 - Loss: 0.9266648292541504\n",
      "Ep 71: Batch #136 - Loss: 1.1383591890335083\n",
      "Ep 71: Batch #137 - Loss: 0.9249224066734314\n",
      "Ep 71: Batch #138 - Loss: 1.030676007270813\n",
      "Ep 71: Batch #139 - Loss: 0.8627368807792664\n",
      "Ep 71: Batch #140 - Loss: 1.0127663612365723\n",
      "Ep 71: Batch #141 - Loss: 1.314422845840454\n",
      "Ep 71: Batch #142 - Loss: 0.7640344500541687\n",
      "Ep 71: Batch #143 - Loss: 0.9219325184822083\n",
      "Ep 71: Batch #144 - Loss: 0.6937201023101807\n",
      "Ep 71: Batch #145 - Loss: 0.6531692147254944\n",
      "Ep 71: Batch #146 - Loss: 0.8539546728134155\n",
      "Ep 71: Batch #147 - Loss: 0.8229161500930786\n",
      "Ep 71: Batch #148 - Loss: 0.9358150959014893\n",
      "Ep 71: Batch #149 - Loss: 0.817775309085846\n",
      "Ep 71: Batch #150 - Loss: 0.8508827686309814\n",
      "Ep 71: Batch #151 - Loss: 0.7053123712539673\n",
      "Ep 71: Batch #152 - Loss: 0.716770589351654\n",
      "Ep 71: Batch #153 - Loss: 1.0620107650756836\n",
      "Ep 71: Batch #154 - Loss: 0.7333948016166687\n",
      "Ep 71: Batch #155 - Loss: 0.8024980425834656\n",
      "Ep 71: Batch #156 - Loss: 0.9816359281539917\n",
      "Ep 71: Batch #157 - Loss: 0.7307946085929871\n",
      "Ep 71: Batch #158 - Loss: 0.7823429107666016\n",
      "Ep 71: Batch #159 - Loss: 0.7731205224990845\n",
      "Ep 71: Batch #160 - Loss: 0.8762076497077942\n",
      "Ep 71: Batch #161 - Loss: 0.7846549153327942\n",
      "Ep 71: Batch #162 - Loss: 0.8986247777938843\n",
      "Ep 71: Batch #163 - Loss: 0.900256872177124\n",
      "Ep 71: Batch #164 - Loss: 0.7532142400741577\n",
      "Ep 71: Batch #165 - Loss: 1.46725332736969\n",
      "Ep 71: Batch #166 - Loss: 0.6507439017295837\n",
      "Ep 71: Batch #167 - Loss: 1.048719048500061\n",
      "Ep 71: Batch #168 - Loss: 0.8254057168960571\n",
      "Ep 71: Batch #169 - Loss: 0.7723007202148438\n",
      "Ep 71: Batch #170 - Loss: 0.7730597853660583\n",
      "Ep 71: Batch #171 - Loss: 0.7458412647247314\n",
      "Ep 71: Batch #172 - Loss: 0.6125861406326294\n",
      "Ep 71: Batch #173 - Loss: 1.1467479467391968\n",
      "Ep 71: Batch #174 - Loss: 0.5570030212402344\n",
      "Ep 71: Batch #175 - Loss: 0.75542151927948\n",
      "Ep 71: Batch #176 - Loss: 1.1078156232833862\n",
      "Ep 71: Batch #177 - Loss: 0.815380871295929\n",
      "Ep 71: Batch #178 - Loss: 0.7323846220970154\n",
      "Ep 71: Batch #179 - Loss: 0.9040987491607666\n",
      "Ep 71: Batch #180 - Loss: 0.8163015842437744\n",
      "Ep 71: Batch #181 - Loss: 0.9494813084602356\n",
      "Ep 71: Batch #182 - Loss: 0.7400294542312622\n",
      "Ep 71: Batch #183 - Loss: 0.7365134358406067\n",
      "Ep 71: Batch #184 - Loss: 1.0369516611099243\n",
      "Ep 71: Batch #185 - Loss: 0.7287411093711853\n",
      "Ep 71: Batch #186 - Loss: 0.9243550896644592\n",
      "Ep 71: Batch #187 - Loss: 1.1243398189544678\n",
      "Ep 71: Batch #188 - Loss: 1.3161636590957642\n",
      "Ep 71: Batch #189 - Loss: 0.6795637011528015\n",
      "Ep 71: Batch #190 - Loss: 0.7084165215492249\n",
      "Ep 71: Batch #191 - Loss: 1.0225481986999512\n",
      "Ep 71: Batch #192 - Loss: 0.6488425731658936\n",
      "Ep 71: Batch #193 - Loss: 0.7105957269668579\n",
      "Ep 71: Batch #194 - Loss: 0.6678326725959778\n",
      "Ep 71: Batch #195 - Loss: 0.9468211531639099\n",
      "Ep 71: Batch #196 - Loss: 0.8309890031814575\n",
      "Ep 71: Batch #197 - Loss: 0.8641800284385681\n",
      "Ep 71: Batch #198 - Loss: 0.6489385366439819\n",
      "Ep 71: Batch #199 - Loss: 0.828667163848877\n",
      "Ep 72: Batch #0 - Loss: 0.7566140294075012\n",
      "Ep 72: Batch #1 - Loss: 0.8404249548912048\n",
      "Ep 72: Batch #2 - Loss: 0.9792572855949402\n",
      "Ep 72: Batch #3 - Loss: 0.834818959236145\n",
      "Ep 72: Batch #4 - Loss: 0.7561213374137878\n",
      "Ep 72: Batch #5 - Loss: 0.6430808901786804\n",
      "Ep 72: Batch #6 - Loss: 0.8463413715362549\n",
      "Ep 72: Batch #7 - Loss: 0.6755483150482178\n",
      "Ep 72: Batch #8 - Loss: 0.7060203552246094\n",
      "Ep 72: Batch #9 - Loss: 1.349388599395752\n",
      "Ep 72: Batch #10 - Loss: 0.9723104238510132\n",
      "Ep 72: Batch #11 - Loss: 0.6451268196105957\n",
      "Ep 72: Batch #12 - Loss: 1.5195332765579224\n",
      "Ep 72: Batch #13 - Loss: 0.6277948617935181\n",
      "Ep 72: Batch #14 - Loss: 0.7017478346824646\n",
      "Ep 72: Batch #15 - Loss: 1.193486213684082\n",
      "Ep 72: Batch #16 - Loss: 1.225565791130066\n",
      "Ep 72: Batch #17 - Loss: 0.8455169200897217\n",
      "Ep 72: Batch #18 - Loss: 0.9192685484886169\n",
      "Ep 72: Batch #19 - Loss: 0.6456803679466248\n",
      "Ep 72: Batch #20 - Loss: 0.6289443969726562\n",
      "Ep 72: Batch #21 - Loss: 1.1787570714950562\n",
      "Ep 72: Batch #22 - Loss: 0.7013927102088928\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 72: Batch #23 - Loss: 0.7126031517982483\n",
      "Ep 72: Batch #24 - Loss: 0.7975941896438599\n",
      "Ep 72: Batch #25 - Loss: 0.6858535408973694\n",
      "Ep 72: Batch #26 - Loss: 0.6984469294548035\n",
      "Ep 72: Batch #27 - Loss: 1.3044822216033936\n",
      "Ep 72: Batch #28 - Loss: 0.8395583629608154\n",
      "Ep 72: Batch #29 - Loss: 0.8550938963890076\n",
      "Ep 72: Batch #30 - Loss: 1.1633397340774536\n",
      "Ep 72: Batch #31 - Loss: 0.6489893198013306\n",
      "Ep 72: Batch #32 - Loss: 0.7162294983863831\n",
      "Ep 72: Batch #33 - Loss: 0.7787448167800903\n",
      "Ep 72: Batch #34 - Loss: 0.7543516159057617\n",
      "Ep 72: Batch #35 - Loss: 0.9077028036117554\n",
      "Ep 72: Batch #36 - Loss: 0.6732092499732971\n",
      "Ep 72: Batch #37 - Loss: 1.1069371700286865\n",
      "Ep 72: Batch #38 - Loss: 0.7112693190574646\n",
      "Ep 72: Batch #39 - Loss: 0.7933440804481506\n",
      "Ep 72: Batch #40 - Loss: 0.7441175580024719\n",
      "Ep 72: Batch #41 - Loss: 0.7029257416725159\n",
      "Ep 72: Batch #42 - Loss: 0.6937967538833618\n",
      "Ep 72: Batch #43 - Loss: 0.758812665939331\n",
      "Ep 72: Batch #44 - Loss: 0.7509186863899231\n",
      "Ep 72: Batch #45 - Loss: 0.6051308512687683\n",
      "Ep 72: Batch #46 - Loss: 0.7937122583389282\n",
      "Ep 72: Batch #47 - Loss: 0.915614128112793\n",
      "Ep 72: Batch #48 - Loss: 1.3149948120117188\n",
      "Ep 72: Batch #49 - Loss: 0.969072163105011\n",
      "Ep 72: Batch #50 - Loss: 0.6832854747772217\n",
      "Ep 72: Batch #51 - Loss: 0.9492412209510803\n",
      "Ep 72: Batch #52 - Loss: 0.7661623954772949\n",
      "Ep 72: Batch #53 - Loss: 0.7894226312637329\n",
      "Ep 72: Batch #54 - Loss: 0.6780573725700378\n",
      "Ep 72: Batch #55 - Loss: 0.7209294438362122\n",
      "Ep 72: Batch #56 - Loss: 1.2124618291854858\n",
      "Ep 72: Batch #57 - Loss: 0.8100879788398743\n",
      "Ep 72: Batch #58 - Loss: 0.9539909958839417\n",
      "Ep 72: Batch #59 - Loss: 0.6588540077209473\n",
      "Ep 72: Batch #60 - Loss: 1.266610026359558\n",
      "Ep 72: Batch #61 - Loss: 0.6124311685562134\n",
      "Ep 72: Batch #62 - Loss: 0.6916572451591492\n",
      "Ep 72: Batch #63 - Loss: 0.9637434482574463\n",
      "Ep 72: Batch #64 - Loss: 9.397274017333984\n",
      "Ep 72: Batch #65 - Loss: 0.5883805751800537\n",
      "Ep 72: Batch #66 - Loss: 0.7621816992759705\n",
      "Ep 72: Batch #67 - Loss: 0.8764356970787048\n",
      "Ep 72: Batch #68 - Loss: 0.868388831615448\n",
      "Ep 72: Batch #69 - Loss: 0.7164503335952759\n",
      "Ep 72: Batch #70 - Loss: 0.7393053770065308\n",
      "Ep 72: Batch #71 - Loss: 0.6550815105438232\n",
      "Ep 72: Batch #72 - Loss: 0.8200263977050781\n",
      "Ep 72: Batch #73 - Loss: 0.8602962493896484\n",
      "Ep 72: Batch #74 - Loss: 0.706257700920105\n",
      "Ep 72: Batch #75 - Loss: 0.7402358651161194\n",
      "Ep 72: Batch #76 - Loss: 1.0631210803985596\n",
      "Ep 72: Batch #77 - Loss: 0.7020959854125977\n",
      "Ep 72: Batch #78 - Loss: 1.1111871004104614\n",
      "Ep 72: Batch #79 - Loss: 0.6005246639251709\n",
      "Ep 72: Batch #80 - Loss: 0.8207941055297852\n",
      "Ep 72: Batch #81 - Loss: 1.644914984703064\n",
      "Ep 72: Batch #82 - Loss: 0.8412725329399109\n",
      "Ep 72: Batch #83 - Loss: 1.7089109420776367\n",
      "Ep 72: Batch #84 - Loss: 0.6842663884162903\n",
      "Ep 72: Batch #85 - Loss: 0.9431623220443726\n",
      "Ep 72: Batch #86 - Loss: 0.6755074262619019\n",
      "Ep 72: Batch #87 - Loss: 0.6837918758392334\n",
      "Ep 72: Batch #88 - Loss: 0.767773449420929\n",
      "Ep 72: Batch #89 - Loss: 0.8620728254318237\n",
      "Ep 72: Batch #90 - Loss: 1.107132077217102\n",
      "Ep 72: Batch #91 - Loss: 0.7652689218521118\n",
      "Ep 72: Batch #92 - Loss: 0.9884034991264343\n",
      "Ep 72: Batch #93 - Loss: 0.9803241491317749\n",
      "Ep 72: Batch #94 - Loss: 1.006794810295105\n",
      "Ep 72: Batch #95 - Loss: 0.8852270245552063\n",
      "Ep 72: Batch #96 - Loss: 0.8706260919570923\n",
      "Ep 72: Batch #97 - Loss: 0.6980926394462585\n",
      "Ep 72: Batch #98 - Loss: 0.7081742286682129\n",
      "Ep 72: Batch #99 - Loss: 0.9221944212913513\n",
      "Ep 72: Batch #100 - Loss: 0.6488451957702637\n",
      "Ep 72: Batch #101 - Loss: 1.0126569271087646\n",
      "Ep 72: Batch #102 - Loss: 0.7505581974983215\n",
      "Ep 72: Batch #103 - Loss: 0.7589844465255737\n",
      "Ep 72: Batch #104 - Loss: 0.7699023485183716\n",
      "Ep 72: Batch #105 - Loss: 0.9883308410644531\n",
      "Ep 72: Batch #106 - Loss: 0.7311938405036926\n",
      "Ep 72: Batch #107 - Loss: 0.7262440323829651\n",
      "Ep 72: Batch #108 - Loss: 0.994612991809845\n",
      "Ep 72: Batch #109 - Loss: 0.7330195307731628\n",
      "Ep 72: Batch #110 - Loss: 0.8766148090362549\n",
      "Ep 72: Batch #111 - Loss: 1.3324382305145264\n",
      "Ep 72: Batch #112 - Loss: 1.0055285692214966\n",
      "Ep 72: Batch #113 - Loss: 0.7842904329299927\n",
      "Ep 72: Batch #114 - Loss: 0.8637027740478516\n",
      "Ep 72: Batch #115 - Loss: 1.054027795791626\n",
      "Ep 72: Batch #116 - Loss: 0.6133527755737305\n",
      "Ep 72: Batch #117 - Loss: 0.8411596417427063\n",
      "Ep 72: Batch #118 - Loss: 0.5204063057899475\n",
      "Model saved in file: ./weights_autoencoder_low_LR/model_e72b118_1516651278.4891999.ckpt\n",
      "Ep 72: Batch #119 - Loss: 0.9900946617126465\n",
      "Ep 72: Batch #120 - Loss: 0.7704687714576721\n",
      "Ep 72: Batch #121 - Loss: 0.6570847034454346\n",
      "Ep 72: Batch #122 - Loss: 0.7937833070755005\n",
      "Ep 72: Batch #123 - Loss: 0.7989955544471741\n",
      "Ep 72: Batch #124 - Loss: 0.6399163603782654\n",
      "Ep 72: Batch #125 - Loss: 2.6716299057006836\n",
      "Ep 72: Batch #126 - Loss: 1.1834309101104736\n",
      "Ep 72: Batch #127 - Loss: 0.7149062752723694\n",
      "Ep 72: Batch #128 - Loss: 1.0562517642974854\n",
      "Ep 72: Batch #129 - Loss: 0.8028841614723206\n",
      "Ep 72: Batch #130 - Loss: 0.6944969296455383\n",
      "Ep 72: Batch #131 - Loss: 0.9492174983024597\n",
      "Ep 72: Batch #132 - Loss: 0.7893909215927124\n",
      "Ep 72: Batch #133 - Loss: 0.7830579280853271\n",
      "Ep 72: Batch #134 - Loss: 0.736032247543335\n",
      "Ep 72: Batch #135 - Loss: 0.925372838973999\n",
      "Ep 72: Batch #136 - Loss: 1.1368836164474487\n",
      "Ep 72: Batch #137 - Loss: 0.9234645962715149\n",
      "Ep 72: Batch #138 - Loss: 1.029131531715393\n",
      "Ep 72: Batch #139 - Loss: 0.8613467216491699\n",
      "Ep 72: Batch #140 - Loss: 1.0115680694580078\n",
      "Ep 72: Batch #141 - Loss: 1.312745213508606\n",
      "Ep 72: Batch #142 - Loss: 0.7628840208053589\n",
      "Ep 72: Batch #143 - Loss: 0.9203839302062988\n",
      "Ep 72: Batch #144 - Loss: 0.6928210258483887\n",
      "Ep 72: Batch #145 - Loss: 0.6522983908653259\n",
      "Ep 72: Batch #146 - Loss: 0.8529644012451172\n",
      "Ep 72: Batch #147 - Loss: 0.8215681910514832\n",
      "Ep 72: Batch #148 - Loss: 0.9342716932296753\n",
      "Ep 72: Batch #149 - Loss: 0.8165232539176941\n",
      "Ep 72: Batch #150 - Loss: 0.8498139977455139\n",
      "Ep 72: Batch #151 - Loss: 0.7045304775238037\n",
      "Ep 72: Batch #152 - Loss: 0.7159867286682129\n",
      "Ep 72: Batch #153 - Loss: 1.0604454278945923\n",
      "Ep 72: Batch #154 - Loss: 0.732305109500885\n",
      "Ep 72: Batch #155 - Loss: 0.801315188407898\n",
      "Ep 72: Batch #156 - Loss: 0.9803676009178162\n",
      "Ep 72: Batch #157 - Loss: 0.7295995950698853\n",
      "Ep 72: Batch #158 - Loss: 0.7815635800361633\n",
      "Ep 72: Batch #159 - Loss: 0.7718167304992676\n",
      "Ep 72: Batch #160 - Loss: 0.8752627372741699\n",
      "Ep 72: Batch #161 - Loss: 0.7835173606872559\n",
      "Ep 72: Batch #162 - Loss: 0.8973432779312134\n",
      "Ep 72: Batch #163 - Loss: 0.8990829586982727\n",
      "Ep 72: Batch #164 - Loss: 0.7520132660865784\n",
      "Ep 72: Batch #165 - Loss: 1.466223120689392\n",
      "Ep 72: Batch #166 - Loss: 0.6497213840484619\n",
      "Ep 72: Batch #167 - Loss: 1.0473344326019287\n",
      "Ep 72: Batch #168 - Loss: 0.8240622878074646\n",
      "Ep 72: Batch #169 - Loss: 0.7712990045547485\n",
      "Ep 72: Batch #170 - Loss: 0.7719515562057495\n",
      "Ep 72: Batch #171 - Loss: 0.7445372343063354\n",
      "Ep 72: Batch #172 - Loss: 0.6118907332420349\n",
      "Ep 72: Batch #173 - Loss: 1.144885778427124\n",
      "Ep 72: Batch #174 - Loss: 0.5561985373497009\n",
      "Ep 72: Batch #175 - Loss: 0.7546170949935913\n",
      "Ep 72: Batch #176 - Loss: 1.1061590909957886\n",
      "Ep 72: Batch #177 - Loss: 0.8141335248947144\n",
      "Ep 72: Batch #178 - Loss: 0.731313169002533\n",
      "Ep 72: Batch #179 - Loss: 0.9029114246368408\n",
      "Ep 72: Batch #180 - Loss: 0.8148810863494873\n",
      "Ep 72: Batch #181 - Loss: 0.9479501843452454\n",
      "Ep 72: Batch #182 - Loss: 0.7390577793121338\n",
      "Ep 72: Batch #183 - Loss: 0.7356000542640686\n",
      "Ep 72: Batch #184 - Loss: 1.0357179641723633\n",
      "Ep 72: Batch #185 - Loss: 0.7276965975761414\n",
      "Ep 72: Batch #186 - Loss: 0.9227780103683472\n",
      "Ep 72: Batch #187 - Loss: 1.1227091550827026\n",
      "Ep 72: Batch #188 - Loss: 1.3146450519561768\n",
      "Ep 72: Batch #189 - Loss: 0.6788120865821838\n",
      "Ep 72: Batch #190 - Loss: 0.7074646949768066\n",
      "Ep 72: Batch #191 - Loss: 1.0207866430282593\n",
      "Ep 72: Batch #192 - Loss: 0.6481929421424866\n",
      "Ep 72: Batch #193 - Loss: 0.7095901370048523\n",
      "Ep 72: Batch #194 - Loss: 0.6668058633804321\n",
      "Ep 72: Batch #195 - Loss: 0.9454987645149231\n",
      "Ep 72: Batch #196 - Loss: 0.8296383023262024\n",
      "Ep 72: Batch #197 - Loss: 0.8627050518989563\n",
      "Ep 72: Batch #198 - Loss: 0.6479132771492004\n",
      "Ep 72: Batch #199 - Loss: 0.8275293111801147\n",
      "Ep 73: Batch #0 - Loss: 0.7553909420967102\n",
      "Ep 73: Batch #1 - Loss: 0.8390938639640808\n",
      "Ep 73: Batch #2 - Loss: 0.9783288240432739\n",
      "Ep 73: Batch #3 - Loss: 0.8336995840072632\n",
      "Ep 73: Batch #4 - Loss: 0.754987895488739\n",
      "Ep 73: Batch #5 - Loss: 0.6421537399291992\n",
      "Ep 73: Batch #6 - Loss: 0.8452230095863342\n",
      "Ep 73: Batch #7 - Loss: 0.6746447086334229\n",
      "Ep 73: Batch #8 - Loss: 0.7049935460090637\n",
      "Ep 73: Batch #9 - Loss: 1.347496509552002\n",
      "Ep 73: Batch #10 - Loss: 0.9710693359375\n",
      "Ep 73: Batch #11 - Loss: 0.6442555785179138\n",
      "Ep 73: Batch #12 - Loss: 1.5181427001953125\n",
      "Ep 73: Batch #13 - Loss: 0.6270435452461243\n",
      "Ep 73: Batch #14 - Loss: 0.700851321220398\n",
      "Ep 73: Batch #15 - Loss: 1.191815972328186\n",
      "Ep 73: Batch #16 - Loss: 1.223628044128418\n",
      "Ep 73: Batch #17 - Loss: 0.844319224357605\n",
      "Ep 73: Batch #18 - Loss: 0.9184891581535339\n",
      "Ep 73: Batch #19 - Loss: 0.644986629486084\n",
      "Ep 73: Batch #20 - Loss: 0.6280484795570374\n",
      "Ep 73: Batch #21 - Loss: 1.1776562929153442\n",
      "Ep 73: Batch #22 - Loss: 0.7004506587982178\n",
      "Ep 73: Batch #23 - Loss: 0.7114927172660828\n",
      "Ep 73: Batch #24 - Loss: 0.7967603206634521\n",
      "Ep 73: Batch #25 - Loss: 0.6848965883255005\n",
      "Ep 73: Batch #26 - Loss: 0.6973389387130737\n",
      "Ep 73: Batch #27 - Loss: 1.3027215003967285\n",
      "Ep 73: Batch #28 - Loss: 0.8386142253875732\n",
      "Ep 73: Batch #29 - Loss: 0.8537832498550415\n",
      "Ep 73: Batch #30 - Loss: 1.1618328094482422\n",
      "Ep 73: Batch #31 - Loss: 0.6481149792671204\n",
      "Ep 73: Batch #32 - Loss: 0.7151330709457397\n",
      "Ep 73: Batch #33 - Loss: 0.7777454257011414\n",
      "Ep 73: Batch #34 - Loss: 0.7532390356063843\n",
      "Ep 73: Batch #35 - Loss: 0.9062997698783875\n",
      "Ep 73: Batch #36 - Loss: 0.672144889831543\n",
      "Ep 73: Batch #37 - Loss: 1.1058306694030762\n",
      "Ep 73: Batch #38 - Loss: 0.7100058197975159\n",
      "Ep 73: Batch #39 - Loss: 0.7923073768615723\n",
      "Ep 73: Batch #40 - Loss: 0.7431358695030212\n",
      "Ep 73: Batch #41 - Loss: 0.7016927003860474\n",
      "Ep 73: Batch #42 - Loss: 0.6928034424781799\n",
      "Ep 73: Batch #43 - Loss: 0.7577935457229614\n",
      "Ep 73: Batch #44 - Loss: 0.7496455907821655\n",
      "Ep 73: Batch #45 - Loss: 0.6042628288269043\n",
      "Ep 73: Batch #46 - Loss: 0.7924181222915649\n",
      "Ep 73: Batch #47 - Loss: 0.913940966129303\n",
      "Ep 73: Batch #48 - Loss: 1.3136074542999268\n",
      "Ep 73: Batch #49 - Loss: 0.9675412178039551\n",
      "Ep 73: Batch #50 - Loss: 0.6824848651885986\n",
      "Ep 73: Batch #51 - Loss: 0.9475871324539185\n",
      "Ep 73: Batch #52 - Loss: 0.7651348114013672\n",
      "Ep 73: Batch #53 - Loss: 0.7882439494132996\n",
      "Ep 73: Batch #54 - Loss: 0.6770629286766052\n",
      "Ep 73: Batch #55 - Loss: 0.7199381589889526\n",
      "Ep 73: Batch #56 - Loss: 1.2106349468231201\n",
      "Ep 73: Batch #57 - Loss: 0.8087010979652405\n",
      "Ep 73: Batch #58 - Loss: 0.9523622393608093\n",
      "Ep 73: Batch #59 - Loss: 0.6580158472061157\n",
      "Ep 73: Batch #60 - Loss: 1.264945387840271\n",
      "Ep 73: Batch #61 - Loss: 0.6116948127746582\n",
      "Ep 73: Batch #62 - Loss: 0.690683126449585\n",
      "Ep 73: Batch #63 - Loss: 0.9623289704322815\n",
      "Ep 73: Batch #64 - Loss: 9.396084785461426\n",
      "Ep 73: Batch #65 - Loss: 0.5875484347343445\n",
      "Ep 73: Batch #66 - Loss: 0.7609718441963196\n",
      "Ep 73: Batch #67 - Loss: 0.8753697276115417\n",
      "Ep 73: Batch #68 - Loss: 0.8669124841690063\n",
      "Ep 73: Batch #69 - Loss: 0.715518057346344\n",
      "Ep 73: Batch #70 - Loss: 0.7380545735359192\n",
      "Ep 73: Batch #71 - Loss: 0.6542112827301025\n",
      "Ep 73: Batch #72 - Loss: 0.8186931610107422\n",
      "Ep 73: Batch #73 - Loss: 0.8588138818740845\n",
      "Ep 73: Batch #74 - Loss: 0.7050474286079407\n",
      "Ep 73: Batch #75 - Loss: 0.7393029928207397\n",
      "Ep 73: Batch #76 - Loss: 1.061849594116211\n",
      "Ep 73: Batch #77 - Loss: 0.7009252905845642\n",
      "Ep 73: Batch #78 - Loss: 1.1094131469726562\n",
      "Ep 73: Batch #79 - Loss: 0.5997157096862793\n",
      "Ep 73: Batch #80 - Loss: 0.819389283657074\n",
      "Ep 73: Batch #81 - Loss: 1.6437550783157349\n",
      "Ep 73: Batch #82 - Loss: 0.8401751518249512\n",
      "Ep 73: Batch #83 - Loss: 1.708044409751892\n",
      "Ep 73: Batch #84 - Loss: 0.6832516193389893\n",
      "Ep 73: Batch #85 - Loss: 0.9419254064559937\n",
      "Ep 73: Batch #86 - Loss: 0.6743916869163513\n",
      "Ep 73: Batch #87 - Loss: 0.6828278303146362\n",
      "Ep 73: Batch #88 - Loss: 0.7666120529174805\n",
      "Ep 73: Batch #89 - Loss: 0.861272931098938\n",
      "Ep 73: Batch #90 - Loss: 1.1055073738098145\n",
      "Ep 73: Batch #91 - Loss: 0.7640204429626465\n",
      "Ep 73: Batch #92 - Loss: 0.9869447946548462\n",
      "Ep 73: Batch #93 - Loss: 0.9784892201423645\n",
      "Ep 73: Batch #94 - Loss: 1.0052587985992432\n",
      "Ep 73: Batch #95 - Loss: 0.8840817213058472\n",
      "Ep 73: Batch #96 - Loss: 0.8694519996643066\n",
      "Ep 73: Batch #97 - Loss: 0.6970548033714294\n",
      "Ep 73: Batch #98 - Loss: 0.7071481347084045\n",
      "Ep 73: Batch #99 - Loss: 0.9209107160568237\n",
      "Ep 73: Batch #100 - Loss: 0.6478463411331177\n",
      "Ep 73: Batch #101 - Loss: 1.011566162109375\n",
      "Ep 73: Batch #102 - Loss: 0.749424397945404\n",
      "Ep 73: Batch #103 - Loss: 0.757870078086853\n",
      "Ep 73: Batch #104 - Loss: 0.7688479423522949\n",
      "Ep 73: Batch #105 - Loss: 0.9870919585227966\n",
      "Ep 73: Batch #106 - Loss: 0.7303411960601807\n",
      "Ep 73: Batch #107 - Loss: 0.7251902222633362\n",
      "Ep 73: Batch #108 - Loss: 0.9933094382286072\n",
      "Ep 73: Batch #109 - Loss: 0.7319585084915161\n",
      "Ep 73: Batch #110 - Loss: 0.8751919269561768\n",
      "Ep 73: Batch #111 - Loss: 1.3308111429214478\n",
      "Ep 73: Batch #112 - Loss: 1.0039488077163696\n",
      "Ep 73: Batch #113 - Loss: 0.7832481861114502\n",
      "Ep 73: Batch #114 - Loss: 0.8623183369636536\n",
      "Ep 73: Batch #115 - Loss: 1.0526745319366455\n",
      "Ep 73: Batch #116 - Loss: 0.6126389503479004\n",
      "Ep 73: Batch #117 - Loss: 0.8400768637657166\n",
      "Ep 73: Batch #118 - Loss: 0.5196318626403809\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved in file: ./weights_autoencoder_low_LR/model_e73b118_1516651278.6248834.ckpt\n",
      "Ep 73: Batch #119 - Loss: 0.9886676073074341\n",
      "Ep 73: Batch #120 - Loss: 0.7694692015647888\n",
      "Ep 73: Batch #121 - Loss: 0.6561037302017212\n",
      "Ep 73: Batch #122 - Loss: 0.7926655411720276\n",
      "Ep 73: Batch #123 - Loss: 0.7978750467300415\n",
      "Ep 73: Batch #124 - Loss: 0.6391221284866333\n",
      "Ep 73: Batch #125 - Loss: 2.669955253601074\n",
      "Ep 73: Batch #126 - Loss: 1.1819555759429932\n",
      "Ep 73: Batch #127 - Loss: 0.7136531472206116\n",
      "Ep 73: Batch #128 - Loss: 1.0544606447219849\n",
      "Ep 73: Batch #129 - Loss: 0.8016420602798462\n",
      "Ep 73: Batch #130 - Loss: 0.6935498714447021\n",
      "Ep 73: Batch #131 - Loss: 0.9476239681243896\n",
      "Ep 73: Batch #132 - Loss: 0.7882702350616455\n",
      "Ep 73: Batch #133 - Loss: 0.7818462252616882\n",
      "Ep 73: Batch #134 - Loss: 0.7349485754966736\n",
      "Ep 73: Batch #135 - Loss: 0.924094021320343\n",
      "Ep 73: Batch #136 - Loss: 1.135428786277771\n",
      "Ep 73: Batch #137 - Loss: 0.9220095276832581\n",
      "Ep 73: Batch #138 - Loss: 1.0275958776474\n",
      "Ep 73: Batch #139 - Loss: 0.8599763512611389\n",
      "Ep 73: Batch #140 - Loss: 1.0103579759597778\n",
      "Ep 73: Batch #141 - Loss: 1.3110994100570679\n",
      "Ep 73: Batch #142 - Loss: 0.7617442607879639\n",
      "Ep 73: Batch #143 - Loss: 0.9188572764396667\n",
      "Ep 73: Batch #144 - Loss: 0.6919369101524353\n",
      "Ep 73: Batch #145 - Loss: 0.6514392495155334\n",
      "Ep 73: Batch #146 - Loss: 0.8519895076751709\n",
      "Ep 73: Batch #147 - Loss: 0.8202430605888367\n",
      "Ep 73: Batch #148 - Loss: 0.932732343673706\n",
      "Ep 73: Batch #149 - Loss: 0.8152825236320496\n",
      "Ep 73: Batch #150 - Loss: 0.8487585186958313\n",
      "Ep 73: Batch #151 - Loss: 0.7037610411643982\n",
      "Ep 73: Batch #152 - Loss: 0.7152187824249268\n",
      "Ep 73: Batch #153 - Loss: 1.058890700340271\n",
      "Ep 73: Batch #154 - Loss: 0.7312301397323608\n",
      "Ep 73: Batch #155 - Loss: 0.8001483678817749\n",
      "Ep 73: Batch #156 - Loss: 0.9791171550750732\n",
      "Ep 73: Batch #157 - Loss: 0.7284107208251953\n",
      "Ep 73: Batch #158 - Loss: 0.7807899713516235\n",
      "Ep 73: Batch #159 - Loss: 0.7705268859863281\n",
      "Ep 73: Batch #160 - Loss: 0.874316394329071\n",
      "Ep 73: Batch #161 - Loss: 0.7823953628540039\n",
      "Ep 73: Batch #162 - Loss: 0.8960689306259155\n",
      "Ep 73: Batch #163 - Loss: 0.897926926612854\n",
      "Ep 73: Batch #164 - Loss: 0.7508236765861511\n",
      "Ep 73: Batch #165 - Loss: 1.4651830196380615\n",
      "Ep 73: Batch #166 - Loss: 0.6487009525299072\n",
      "Ep 73: Batch #167 - Loss: 1.0459661483764648\n",
      "Ep 73: Batch #168 - Loss: 0.8227391242980957\n",
      "Ep 73: Batch #169 - Loss: 0.7703050971031189\n",
      "Ep 73: Batch #170 - Loss: 0.770847499370575\n",
      "Ep 73: Batch #171 - Loss: 0.7432569265365601\n",
      "Ep 73: Batch #172 - Loss: 0.6112074851989746\n",
      "Ep 73: Batch #173 - Loss: 1.1430424451828003\n",
      "Ep 73: Batch #174 - Loss: 0.5553928017616272\n",
      "Ep 73: Batch #175 - Loss: 0.7538278102874756\n",
      "Ep 73: Batch #176 - Loss: 1.1045247316360474\n",
      "Ep 73: Batch #177 - Loss: 0.812907874584198\n",
      "Ep 73: Batch #178 - Loss: 0.7302530407905579\n",
      "Ep 73: Batch #179 - Loss: 0.9017341732978821\n",
      "Ep 73: Batch #180 - Loss: 0.8134668469429016\n",
      "Ep 73: Batch #181 - Loss: 0.9464265704154968\n",
      "Ep 73: Batch #182 - Loss: 0.7380885481834412\n",
      "Ep 73: Batch #183 - Loss: 0.7346941828727722\n",
      "Ep 73: Batch #184 - Loss: 1.0344959497451782\n",
      "Ep 73: Batch #185 - Loss: 0.726662278175354\n",
      "Ep 73: Batch #186 - Loss: 0.9212122559547424\n",
      "Ep 73: Batch #187 - Loss: 1.1210956573486328\n",
      "Ep 73: Batch #188 - Loss: 1.3130383491516113\n",
      "Ep 73: Batch #189 - Loss: 0.6780731678009033\n",
      "Ep 73: Batch #190 - Loss: 0.7065206170082092\n",
      "Ep 73: Batch #191 - Loss: 1.0190497636795044\n",
      "Ep 73: Batch #192 - Loss: 0.6475470662117004\n",
      "Ep 73: Batch #193 - Loss: 0.7085978388786316\n",
      "Ep 73: Batch #194 - Loss: 0.665797770023346\n",
      "Ep 73: Batch #195 - Loss: 0.944139301776886\n",
      "Ep 73: Batch #196 - Loss: 0.8283145427703857\n",
      "Ep 73: Batch #197 - Loss: 0.8612446188926697\n",
      "Ep 73: Batch #198 - Loss: 0.6468972563743591\n",
      "Ep 73: Batch #199 - Loss: 0.8264120817184448\n",
      "Ep 74: Batch #0 - Loss: 0.754184901714325\n",
      "Ep 74: Batch #1 - Loss: 0.8377838134765625\n",
      "Ep 74: Batch #2 - Loss: 0.9774069786071777\n",
      "Ep 74: Batch #3 - Loss: 0.8325881958007812\n",
      "Ep 74: Batch #4 - Loss: 0.75385582447052\n",
      "Ep 74: Batch #5 - Loss: 0.6412496566772461\n",
      "Ep 74: Batch #6 - Loss: 0.8441306948661804\n",
      "Ep 74: Batch #7 - Loss: 0.6737521290779114\n",
      "Ep 74: Batch #8 - Loss: 0.7039719223976135\n",
      "Ep 74: Batch #9 - Loss: 1.3455792665481567\n",
      "Ep 74: Batch #10 - Loss: 0.9698445200920105\n",
      "Ep 74: Batch #11 - Loss: 0.6433870792388916\n",
      "Ep 74: Batch #12 - Loss: 1.5167467594146729\n",
      "Ep 74: Batch #13 - Loss: 0.6262974739074707\n",
      "Ep 74: Batch #14 - Loss: 0.6999620199203491\n",
      "Ep 74: Batch #15 - Loss: 1.1901676654815674\n",
      "Ep 74: Batch #16 - Loss: 1.2216827869415283\n",
      "Ep 74: Batch #17 - Loss: 0.843143880367279\n",
      "Ep 74: Batch #18 - Loss: 0.9177166819572449\n",
      "Ep 74: Batch #19 - Loss: 0.6442998647689819\n",
      "Ep 74: Batch #20 - Loss: 0.627142071723938\n",
      "Ep 74: Batch #21 - Loss: 1.176574945449829\n",
      "Ep 74: Batch #22 - Loss: 0.6995079517364502\n",
      "Ep 74: Batch #23 - Loss: 0.7103869915008545\n",
      "Ep 74: Batch #24 - Loss: 0.795947253704071\n",
      "Ep 74: Batch #25 - Loss: 0.683952271938324\n",
      "Ep 74: Batch #26 - Loss: 0.6962451338768005\n",
      "Ep 74: Batch #27 - Loss: 1.3009757995605469\n",
      "Ep 74: Batch #28 - Loss: 0.8376810550689697\n",
      "Ep 74: Batch #29 - Loss: 0.8524752855300903\n",
      "Ep 74: Batch #30 - Loss: 1.160332441329956\n",
      "Ep 74: Batch #31 - Loss: 0.6472559571266174\n",
      "Ep 74: Batch #32 - Loss: 0.7140535116195679\n",
      "Ep 74: Batch #33 - Loss: 0.7767471075057983\n",
      "Ep 74: Batch #34 - Loss: 0.7521421909332275\n",
      "Ep 74: Batch #35 - Loss: 0.9049111008644104\n",
      "Ep 74: Batch #36 - Loss: 0.6710956692695618\n",
      "Ep 74: Batch #37 - Loss: 1.1047362089157104\n",
      "Ep 74: Batch #38 - Loss: 0.7087468504905701\n",
      "Ep 74: Batch #39 - Loss: 0.7912948727607727\n",
      "Ep 74: Batch #40 - Loss: 0.7421593070030212\n",
      "Ep 74: Batch #41 - Loss: 0.7004815936088562\n",
      "Ep 74: Batch #42 - Loss: 0.6918163299560547\n",
      "Ep 74: Batch #43 - Loss: 0.7567687034606934\n",
      "Ep 74: Batch #44 - Loss: 0.7483822107315063\n",
      "Ep 74: Batch #45 - Loss: 0.6034068465232849\n",
      "Ep 74: Batch #46 - Loss: 0.7911301255226135\n",
      "Ep 74: Batch #47 - Loss: 0.9122890830039978\n",
      "Ep 74: Batch #48 - Loss: 1.3121532201766968\n",
      "Ep 74: Batch #49 - Loss: 0.9660247564315796\n",
      "Ep 74: Batch #50 - Loss: 0.6816884279251099\n",
      "Ep 74: Batch #51 - Loss: 0.9459566473960876\n",
      "Ep 74: Batch #52 - Loss: 0.7641246914863586\n",
      "Ep 74: Batch #53 - Loss: 0.7870784997940063\n",
      "Ep 74: Batch #54 - Loss: 0.6760770678520203\n",
      "Ep 74: Batch #55 - Loss: 0.7189285159111023\n",
      "Ep 74: Batch #56 - Loss: 1.2088234424591064\n",
      "Ep 74: Batch #57 - Loss: 0.807312548160553\n",
      "Ep 74: Batch #58 - Loss: 0.9507535099983215\n",
      "Ep 74: Batch #59 - Loss: 0.657191812992096\n",
      "Ep 74: Batch #60 - Loss: 1.263293743133545\n",
      "Ep 74: Batch #61 - Loss: 0.610964298248291\n",
      "Ep 74: Batch #62 - Loss: 0.6897191405296326\n",
      "Ep 74: Batch #63 - Loss: 0.9609227776527405\n",
      "Ep 74: Batch #64 - Loss: 9.394770622253418\n",
      "Ep 74: Batch #65 - Loss: 0.586727499961853\n",
      "Ep 74: Batch #66 - Loss: 0.7597768306732178\n",
      "Ep 74: Batch #67 - Loss: 0.8743141889572144\n",
      "Ep 74: Batch #68 - Loss: 0.8654530048370361\n",
      "Ep 74: Batch #69 - Loss: 0.7145867943763733\n",
      "Ep 74: Batch #70 - Loss: 0.7368065118789673\n",
      "Ep 74: Batch #71 - Loss: 0.6533355116844177\n",
      "Ep 74: Batch #72 - Loss: 0.8173710107803345\n",
      "Ep 74: Batch #73 - Loss: 0.8573458790779114\n",
      "Ep 74: Batch #74 - Loss: 0.703850269317627\n",
      "Ep 74: Batch #75 - Loss: 0.7383758425712585\n",
      "Ep 74: Batch #76 - Loss: 1.0605629682540894\n",
      "Ep 74: Batch #77 - Loss: 0.6997781991958618\n",
      "Ep 74: Batch #78 - Loss: 1.1076639890670776\n",
      "Ep 74: Batch #79 - Loss: 0.5989217162132263\n",
      "Ep 74: Batch #80 - Loss: 0.8179865479469299\n",
      "Ep 74: Batch #81 - Loss: 1.6426059007644653\n",
      "Ep 74: Batch #82 - Loss: 0.8390966057777405\n",
      "Ep 74: Batch #83 - Loss: 1.707177996635437\n",
      "Ep 74: Batch #84 - Loss: 0.6822493076324463\n",
      "Ep 74: Batch #85 - Loss: 0.940706729888916\n",
      "Ep 74: Batch #86 - Loss: 0.6732878088951111\n",
      "Ep 74: Batch #87 - Loss: 0.6818723082542419\n",
      "Ep 74: Batch #88 - Loss: 0.7654712200164795\n",
      "Ep 74: Batch #89 - Loss: 0.8604641556739807\n",
      "Ep 74: Batch #90 - Loss: 1.1038974523544312\n",
      "Ep 74: Batch #91 - Loss: 0.7627875208854675\n",
      "Ep 74: Batch #92 - Loss: 0.9855047464370728\n",
      "Ep 74: Batch #93 - Loss: 0.9766618013381958\n",
      "Ep 74: Batch #94 - Loss: 1.0037367343902588\n",
      "Ep 74: Batch #95 - Loss: 0.8829448223114014\n",
      "Ep 74: Batch #96 - Loss: 0.8682870864868164\n",
      "Ep 74: Batch #97 - Loss: 0.6960346698760986\n",
      "Ep 74: Batch #98 - Loss: 0.7061025500297546\n",
      "Ep 74: Batch #99 - Loss: 0.9196304082870483\n",
      "Ep 74: Batch #100 - Loss: 0.6468566060066223\n",
      "Ep 74: Batch #101 - Loss: 1.0104806423187256\n",
      "Ep 74: Batch #102 - Loss: 0.7482995986938477\n",
      "Ep 74: Batch #103 - Loss: 0.7567761540412903\n",
      "Ep 74: Batch #104 - Loss: 0.7678070068359375\n",
      "Ep 74: Batch #105 - Loss: 0.9858624339103699\n",
      "Ep 74: Batch #106 - Loss: 0.7294687032699585\n",
      "Ep 74: Batch #107 - Loss: 0.7241448760032654\n",
      "Ep 74: Batch #108 - Loss: 0.9920186400413513\n",
      "Ep 74: Batch #109 - Loss: 0.7309133410453796\n",
      "Ep 74: Batch #110 - Loss: 0.8737863898277283\n",
      "Ep 74: Batch #111 - Loss: 1.3291966915130615\n",
      "Ep 74: Batch #112 - Loss: 1.0023893117904663\n",
      "Ep 74: Batch #113 - Loss: 0.7822120189666748\n",
      "Ep 74: Batch #114 - Loss: 0.8609560132026672\n",
      "Ep 74: Batch #115 - Loss: 1.0513287782669067\n",
      "Ep 74: Batch #116 - Loss: 0.6119306087493896\n",
      "Ep 74: Batch #117 - Loss: 0.8390034437179565\n",
      "Ep 74: Batch #118 - Loss: 0.5188640356063843\n",
      "Model saved in file: ./weights_autoencoder_low_LR/model_e74b118_1516651278.7629697.ckpt\n",
      "Ep 74: Batch #119 - Loss: 0.9872573614120483\n",
      "Ep 74: Batch #120 - Loss: 0.7684688568115234\n",
      "Ep 74: Batch #121 - Loss: 0.6551278829574585\n",
      "Ep 74: Batch #122 - Loss: 0.7915531992912292\n",
      "Ep 74: Batch #123 - Loss: 0.7967700958251953\n",
      "Ep 74: Batch #124 - Loss: 0.6383329629898071\n",
      "Ep 74: Batch #125 - Loss: 2.6683285236358643\n",
      "Ep 74: Batch #126 - Loss: 1.180486798286438\n",
      "Ep 74: Batch #127 - Loss: 0.7123891115188599\n",
      "Ep 74: Batch #128 - Loss: 1.0526955127716064\n",
      "Ep 74: Batch #129 - Loss: 0.8004071116447449\n",
      "Ep 74: Batch #130 - Loss: 0.6925972104072571\n",
      "Ep 74: Batch #131 - Loss: 0.9460037350654602\n",
      "Ep 74: Batch #132 - Loss: 0.7871637344360352\n",
      "Ep 74: Batch #133 - Loss: 0.780644953250885\n",
      "Ep 74: Batch #134 - Loss: 0.7338742613792419\n",
      "Ep 74: Batch #135 - Loss: 0.9228267669677734\n",
      "Ep 74: Batch #136 - Loss: 1.1339845657348633\n",
      "Ep 74: Batch #137 - Loss: 0.9205458760261536\n",
      "Ep 74: Batch #138 - Loss: 1.026093602180481\n",
      "Ep 74: Batch #139 - Loss: 0.8586295247077942\n",
      "Ep 74: Batch #140 - Loss: 1.00911545753479\n",
      "Ep 74: Batch #141 - Loss: 1.3094838857650757\n",
      "Ep 74: Batch #142 - Loss: 0.7606133222579956\n",
      "Ep 74: Batch #143 - Loss: 0.9173415303230286\n",
      "Ep 74: Batch #144 - Loss: 0.6910626292228699\n",
      "Ep 74: Batch #145 - Loss: 0.6505876779556274\n",
      "Ep 74: Batch #146 - Loss: 0.8510175347328186\n",
      "Ep 74: Batch #147 - Loss: 0.8189454674720764\n",
      "Ep 74: Batch #148 - Loss: 0.9312164783477783\n",
      "Ep 74: Batch #149 - Loss: 0.8140547275543213\n",
      "Ep 74: Batch #150 - Loss: 0.8477228879928589\n",
      "Ep 74: Batch #151 - Loss: 0.7029933333396912\n",
      "Ep 74: Batch #152 - Loss: 0.7144535183906555\n",
      "Ep 74: Batch #153 - Loss: 1.0573604106903076\n",
      "Ep 74: Batch #154 - Loss: 0.73016357421875\n",
      "Ep 74: Batch #155 - Loss: 0.799002468585968\n",
      "Ep 74: Batch #156 - Loss: 0.9778813123703003\n",
      "Ep 74: Batch #157 - Loss: 0.7272346019744873\n",
      "Ep 74: Batch #158 - Loss: 0.780012309551239\n",
      "Ep 74: Batch #159 - Loss: 0.769255518913269\n",
      "Ep 74: Batch #160 - Loss: 0.8733311295509338\n",
      "Ep 74: Batch #161 - Loss: 0.7812936902046204\n",
      "Ep 74: Batch #162 - Loss: 0.8947855234146118\n",
      "Ep 74: Batch #163 - Loss: 0.8967807292938232\n",
      "Ep 74: Batch #164 - Loss: 0.7496472597122192\n",
      "Ep 74: Batch #165 - Loss: 1.4641309976577759\n",
      "Ep 74: Batch #166 - Loss: 0.6476889252662659\n",
      "Ep 74: Batch #167 - Loss: 1.044589638710022\n",
      "Ep 74: Batch #168 - Loss: 0.8214238286018372\n",
      "Ep 74: Batch #169 - Loss: 0.7693269848823547\n",
      "Ep 74: Batch #170 - Loss: 0.7697563171386719\n",
      "Ep 74: Batch #171 - Loss: 0.7420022487640381\n",
      "Ep 74: Batch #172 - Loss: 0.610535204410553\n",
      "Ep 74: Batch #173 - Loss: 1.141221284866333\n",
      "Ep 74: Batch #174 - Loss: 0.5545986890792847\n",
      "Ep 74: Batch #175 - Loss: 0.753046452999115\n",
      "Ep 74: Batch #176 - Loss: 1.1029081344604492\n",
      "Ep 74: Batch #177 - Loss: 0.8117058277130127\n",
      "Ep 74: Batch #178 - Loss: 0.729202389717102\n",
      "Ep 74: Batch #179 - Loss: 0.9005501866340637\n",
      "Ep 74: Batch #180 - Loss: 0.8120487332344055\n",
      "Ep 74: Batch #181 - Loss: 0.9449259638786316\n",
      "Ep 74: Batch #182 - Loss: 0.7371265292167664\n",
      "Ep 74: Batch #183 - Loss: 0.7337899804115295\n",
      "Ep 74: Batch #184 - Loss: 1.0332878828048706\n",
      "Ep 74: Batch #185 - Loss: 0.7256341576576233\n",
      "Ep 74: Batch #186 - Loss: 0.9196643233299255\n",
      "Ep 74: Batch #187 - Loss: 1.1194995641708374\n",
      "Ep 74: Batch #188 - Loss: 1.3113898038864136\n",
      "Ep 74: Batch #189 - Loss: 0.6773351430892944\n",
      "Ep 74: Batch #190 - Loss: 0.7055821418762207\n",
      "Ep 74: Batch #191 - Loss: 1.0173397064208984\n",
      "Ep 74: Batch #192 - Loss: 0.6469088792800903\n",
      "Ep 74: Batch #193 - Loss: 0.707623302936554\n",
      "Ep 74: Batch #194 - Loss: 0.6648051738739014\n",
      "Ep 74: Batch #195 - Loss: 0.9427945613861084\n",
      "Ep 74: Batch #196 - Loss: 0.8270068168640137\n",
      "Ep 74: Batch #197 - Loss: 0.8598000407218933\n",
      "Ep 74: Batch #198 - Loss: 0.6458922028541565\n",
      "Ep 74: Batch #199 - Loss: 0.8253102898597717\n",
      "Ep 75: Batch #0 - Loss: 0.7529981136322021\n",
      "Ep 75: Batch #1 - Loss: 0.8364900946617126\n",
      "Ep 75: Batch #2 - Loss: 0.9764857888221741\n",
      "Ep 75: Batch #3 - Loss: 0.8314856290817261\n",
      "Ep 75: Batch #4 - Loss: 0.7527375221252441\n",
      "Ep 75: Batch #5 - Loss: 0.640352725982666\n",
      "Ep 75: Batch #6 - Loss: 0.8430536985397339\n",
      "Ep 75: Batch #7 - Loss: 0.6728699207305908\n",
      "Ep 75: Batch #8 - Loss: 0.7029501795768738\n",
      "Ep 75: Batch #9 - Loss: 1.3436822891235352\n",
      "Ep 75: Batch #10 - Loss: 0.9686391949653625\n",
      "Ep 75: Batch #11 - Loss: 0.6425256133079529\n",
      "Ep 75: Batch #12 - Loss: 1.5153446197509766\n",
      "Ep 75: Batch #13 - Loss: 0.6255591511726379\n",
      "Ep 75: Batch #14 - Loss: 0.6990811824798584\n",
      "Ep 75: Batch #15 - Loss: 1.1885255575180054\n",
      "Ep 75: Batch #16 - Loss: 1.2197555303573608\n",
      "Ep 75: Batch #17 - Loss: 0.8419817686080933\n",
      "Ep 75: Batch #18 - Loss: 0.9169484972953796\n",
      "Ep 75: Batch #19 - Loss: 0.6436156630516052\n",
      "Ep 75: Batch #20 - Loss: 0.626236617565155\n",
      "Ep 75: Batch #21 - Loss: 1.1755234003067017\n",
      "Ep 75: Batch #22 - Loss: 0.6985775828361511\n",
      "Ep 75: Batch #23 - Loss: 0.7092790603637695\n",
      "Ep 75: Batch #24 - Loss: 0.7951003313064575\n",
      "Ep 75: Batch #25 - Loss: 0.6830154657363892\n",
      "Ep 75: Batch #26 - Loss: 0.6951673626899719\n",
      "Ep 75: Batch #27 - Loss: 1.2992453575134277\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 75: Batch #28 - Loss: 0.8367551565170288\n",
      "Ep 75: Batch #29 - Loss: 0.8511711955070496\n",
      "Ep 75: Batch #30 - Loss: 1.1588438749313354\n",
      "Ep 75: Batch #31 - Loss: 0.6464008688926697\n",
      "Ep 75: Batch #32 - Loss: 0.7129860520362854\n",
      "Ep 75: Batch #33 - Loss: 0.7757580280303955\n",
      "Ep 75: Batch #34 - Loss: 0.7510557770729065\n",
      "Ep 75: Batch #35 - Loss: 0.9035389423370361\n",
      "Ep 75: Batch #36 - Loss: 0.6700626611709595\n",
      "Ep 75: Batch #37 - Loss: 1.1036584377288818\n",
      "Ep 75: Batch #38 - Loss: 0.7074995040893555\n",
      "Ep 75: Batch #39 - Loss: 0.7902995944023132\n",
      "Ep 75: Batch #40 - Loss: 0.7411896586418152\n",
      "Ep 75: Batch #41 - Loss: 0.6992853879928589\n",
      "Ep 75: Batch #42 - Loss: 0.6908429861068726\n",
      "Ep 75: Batch #43 - Loss: 0.7557611465454102\n",
      "Ep 75: Batch #44 - Loss: 0.747138261795044\n",
      "Ep 75: Batch #45 - Loss: 0.6025667190551758\n",
      "Ep 75: Batch #46 - Loss: 0.7898505926132202\n",
      "Ep 75: Batch #47 - Loss: 0.9106554985046387\n",
      "Ep 75: Batch #48 - Loss: 1.310658574104309\n",
      "Ep 75: Batch #49 - Loss: 0.9645259976387024\n",
      "Ep 75: Batch #50 - Loss: 0.6808954477310181\n",
      "Ep 75: Batch #51 - Loss: 0.9443470239639282\n",
      "Ep 75: Batch #52 - Loss: 0.7631271481513977\n",
      "Ep 75: Batch #53 - Loss: 0.7859253883361816\n",
      "Ep 75: Batch #54 - Loss: 0.6751030087471008\n",
      "Ep 75: Batch #55 - Loss: 0.7179205417633057\n",
      "Ep 75: Batch #56 - Loss: 1.2069908380508423\n",
      "Ep 75: Batch #57 - Loss: 0.8059386610984802\n",
      "Ep 75: Batch #58 - Loss: 0.9491720199584961\n",
      "Ep 75: Batch #59 - Loss: 0.6563839912414551\n",
      "Ep 75: Batch #60 - Loss: 1.2616633176803589\n",
      "Ep 75: Batch #61 - Loss: 0.6102400422096252\n",
      "Ep 75: Batch #62 - Loss: 0.6887713670730591\n",
      "Ep 75: Batch #63 - Loss: 0.9595315456390381\n",
      "Ep 75: Batch #64 - Loss: 9.393112182617188\n",
      "Ep 75: Batch #65 - Loss: 0.5859122276306152\n",
      "Ep 75: Batch #66 - Loss: 0.7585932016372681\n",
      "Ep 75: Batch #67 - Loss: 0.8732705116271973\n",
      "Ep 75: Batch #68 - Loss: 0.8640099167823792\n",
      "Ep 75: Batch #69 - Loss: 0.7136601209640503\n",
      "Ep 75: Batch #70 - Loss: 0.735577404499054\n",
      "Ep 75: Batch #71 - Loss: 0.6524602174758911\n",
      "Ep 75: Batch #72 - Loss: 0.8160684704780579\n",
      "Ep 75: Batch #73 - Loss: 0.8558973073959351\n",
      "Ep 75: Batch #74 - Loss: 0.7026663422584534\n",
      "Ep 75: Batch #75 - Loss: 0.7374579310417175\n",
      "Ep 75: Batch #76 - Loss: 1.0592793226242065\n",
      "Ep 75: Batch #77 - Loss: 0.6986497640609741\n",
      "Ep 75: Batch #78 - Loss: 1.1059372425079346\n",
      "Ep 75: Batch #79 - Loss: 0.5981213450431824\n",
      "Ep 75: Batch #80 - Loss: 0.8165954351425171\n",
      "Ep 75: Batch #81 - Loss: 1.641465663909912\n",
      "Ep 75: Batch #82 - Loss: 0.8380323648452759\n",
      "Ep 75: Batch #83 - Loss: 1.7063242197036743\n",
      "Ep 75: Batch #84 - Loss: 0.6812577843666077\n",
      "Ep 75: Batch #85 - Loss: 0.93951416015625\n",
      "Ep 75: Batch #86 - Loss: 0.6721907258033752\n",
      "Ep 75: Batch #87 - Loss: 0.6809197664260864\n",
      "Ep 75: Batch #88 - Loss: 0.7643508911132812\n",
      "Ep 75: Batch #89 - Loss: 0.8596702814102173\n",
      "Ep 75: Batch #90 - Loss: 1.102293848991394\n",
      "Ep 75: Batch #91 - Loss: 0.76157146692276\n",
      "Ep 75: Batch #92 - Loss: 0.9840953946113586\n",
      "Ep 75: Batch #93 - Loss: 0.9748440384864807\n",
      "Ep 75: Batch #94 - Loss: 1.0022212266921997\n",
      "Ep 75: Batch #95 - Loss: 0.8818156123161316\n",
      "Ep 75: Batch #96 - Loss: 0.8671392798423767\n",
      "Ep 75: Batch #97 - Loss: 0.6950187683105469\n",
      "Ep 75: Batch #98 - Loss: 0.7050626873970032\n",
      "Ep 75: Batch #99 - Loss: 0.9183773398399353\n",
      "Ep 75: Batch #100 - Loss: 0.6458688378334045\n",
      "Ep 75: Batch #101 - Loss: 1.009405493736267\n",
      "Ep 75: Batch #102 - Loss: 0.7471783757209778\n",
      "Ep 75: Batch #103 - Loss: 0.7557007074356079\n",
      "Ep 75: Batch #104 - Loss: 0.7667765617370605\n",
      "Ep 75: Batch #105 - Loss: 0.9846449494361877\n",
      "Ep 75: Batch #106 - Loss: 0.7285918593406677\n",
      "Ep 75: Batch #107 - Loss: 0.7231058478355408\n",
      "Ep 75: Batch #108 - Loss: 0.9907464385032654\n",
      "Ep 75: Batch #109 - Loss: 0.7298793196678162\n",
      "Ep 75: Batch #110 - Loss: 0.8723899722099304\n",
      "Ep 75: Batch #111 - Loss: 1.327586054801941\n",
      "Ep 75: Batch #112 - Loss: 1.0008611679077148\n",
      "Ep 75: Batch #113 - Loss: 0.7811838388442993\n",
      "Ep 75: Batch #114 - Loss: 0.8595966100692749\n",
      "Ep 75: Batch #115 - Loss: 1.050002098083496\n",
      "Ep 75: Batch #116 - Loss: 0.6112143993377686\n",
      "Ep 75: Batch #117 - Loss: 0.8379361629486084\n",
      "Ep 75: Batch #118 - Loss: 0.5181049108505249\n",
      "Model saved in file: ./weights_autoencoder_low_LR/model_e75b118_1516651278.9005005.ckpt\n",
      "Ep 75: Batch #119 - Loss: 0.9858620762825012\n",
      "Ep 75: Batch #120 - Loss: 0.7674756646156311\n",
      "Ep 75: Batch #121 - Loss: 0.6541498899459839\n",
      "Ep 75: Batch #122 - Loss: 0.7904573082923889\n",
      "Ep 75: Batch #123 - Loss: 0.7956787347793579\n",
      "Ep 75: Batch #124 - Loss: 0.6375546455383301\n",
      "Ep 75: Batch #125 - Loss: 2.66672420501709\n",
      "Ep 75: Batch #126 - Loss: 1.1790412664413452\n",
      "Ep 75: Batch #127 - Loss: 0.7111252546310425\n",
      "Ep 75: Batch #128 - Loss: 1.050956130027771\n",
      "Ep 75: Batch #129 - Loss: 0.7991886734962463\n",
      "Ep 75: Batch #130 - Loss: 0.6916525363922119\n",
      "Ep 75: Batch #131 - Loss: 0.944397509098053\n",
      "Ep 75: Batch #132 - Loss: 0.7860720157623291\n",
      "Ep 75: Batch #133 - Loss: 0.7794496417045593\n",
      "Ep 75: Batch #134 - Loss: 0.7328190207481384\n",
      "Ep 75: Batch #135 - Loss: 0.921570360660553\n",
      "Ep 75: Batch #136 - Loss: 1.132556676864624\n",
      "Ep 75: Batch #137 - Loss: 0.9190941452980042\n",
      "Ep 75: Batch #138 - Loss: 1.0246187448501587\n",
      "Ep 75: Batch #139 - Loss: 0.8572810888290405\n",
      "Ep 75: Batch #140 - Loss: 1.007880687713623\n",
      "Ep 75: Batch #141 - Loss: 1.3078871965408325\n",
      "Ep 75: Batch #142 - Loss: 0.7594778537750244\n",
      "Ep 75: Batch #143 - Loss: 0.9158324599266052\n",
      "Ep 75: Batch #144 - Loss: 0.6901957988739014\n",
      "Ep 75: Batch #145 - Loss: 0.6497554779052734\n",
      "Ep 75: Batch #146 - Loss: 0.8500596284866333\n",
      "Ep 75: Batch #147 - Loss: 0.8176701068878174\n",
      "Ep 75: Batch #148 - Loss: 0.9297150373458862\n",
      "Ep 75: Batch #149 - Loss: 0.8128433227539062\n",
      "Ep 75: Batch #150 - Loss: 0.8467090129852295\n",
      "Ep 75: Batch #151 - Loss: 0.7022238969802856\n",
      "Ep 75: Batch #152 - Loss: 0.7136945724487305\n",
      "Ep 75: Batch #153 - Loss: 1.0557959079742432\n",
      "Ep 75: Batch #154 - Loss: 0.7291125655174255\n",
      "Ep 75: Batch #155 - Loss: 0.7978768348693848\n",
      "Ep 75: Batch #156 - Loss: 0.9766586422920227\n",
      "Ep 75: Batch #157 - Loss: 0.7260740399360657\n",
      "Ep 75: Batch #158 - Loss: 0.7792404890060425\n",
      "Ep 75: Batch #159 - Loss: 0.7679968476295471\n",
      "Ep 75: Batch #160 - Loss: 0.8723124265670776\n",
      "Ep 75: Batch #161 - Loss: 0.7802155017852783\n",
      "Ep 75: Batch #162 - Loss: 0.8935250043869019\n",
      "Ep 75: Batch #163 - Loss: 0.8956494331359863\n",
      "Ep 75: Batch #164 - Loss: 0.7484854459762573\n",
      "Ep 75: Batch #165 - Loss: 1.463087558746338\n",
      "Ep 75: Batch #166 - Loss: 0.6466947793960571\n",
      "Ep 75: Batch #167 - Loss: 1.043208122253418\n",
      "Ep 75: Batch #168 - Loss: 0.8201247453689575\n",
      "Ep 75: Batch #169 - Loss: 0.7683618664741516\n",
      "Ep 75: Batch #170 - Loss: 0.7686777114868164\n",
      "Ep 75: Batch #171 - Loss: 0.7407726049423218\n",
      "Ep 75: Batch #172 - Loss: 0.6098698973655701\n",
      "Ep 75: Batch #173 - Loss: 1.1394236087799072\n",
      "Ep 75: Batch #174 - Loss: 0.5538177490234375\n",
      "Ep 75: Batch #175 - Loss: 0.7522799372673035\n",
      "Ep 75: Batch #176 - Loss: 1.1013089418411255\n",
      "Ep 75: Batch #177 - Loss: 0.8105171322822571\n",
      "Ep 75: Batch #178 - Loss: 0.7281578183174133\n",
      "Ep 75: Batch #179 - Loss: 0.8993101716041565\n",
      "Ep 75: Batch #180 - Loss: 0.8106433749198914\n",
      "Ep 75: Batch #181 - Loss: 0.943448543548584\n",
      "Ep 75: Batch #182 - Loss: 0.7361641526222229\n",
      "Ep 75: Batch #183 - Loss: 0.7328976988792419\n",
      "Ep 75: Batch #184 - Loss: 1.0320931673049927\n",
      "Ep 75: Batch #185 - Loss: 0.7246056199073792\n",
      "Ep 75: Batch #186 - Loss: 0.9181212782859802\n",
      "Ep 75: Batch #187 - Loss: 1.11790931224823\n",
      "Ep 75: Batch #188 - Loss: 1.3097999095916748\n",
      "Ep 75: Batch #189 - Loss: 0.6765941381454468\n",
      "Ep 75: Batch #190 - Loss: 0.704647958278656\n",
      "Ep 75: Batch #191 - Loss: 1.0156638622283936\n",
      "Ep 75: Batch #192 - Loss: 0.6462798714637756\n",
      "Ep 75: Batch #193 - Loss: 0.7066619396209717\n",
      "Ep 75: Batch #194 - Loss: 0.6638257503509521\n",
      "Ep 75: Batch #195 - Loss: 0.9414616823196411\n",
      "Ep 75: Batch #196 - Loss: 0.8257144689559937\n",
      "Ep 75: Batch #197 - Loss: 0.8583764433860779\n",
      "Ep 75: Batch #198 - Loss: 0.644896388053894\n",
      "Ep 75: Batch #199 - Loss: 0.8241425156593323\n",
      "Ep 76: Batch #0 - Loss: 0.7518168091773987\n",
      "Ep 76: Batch #1 - Loss: 0.8352087140083313\n",
      "Ep 76: Batch #2 - Loss: 0.9755747318267822\n",
      "Ep 76: Batch #3 - Loss: 0.8303911685943604\n",
      "Ep 76: Batch #4 - Loss: 0.7516091465950012\n",
      "Ep 76: Batch #5 - Loss: 0.6394777894020081\n",
      "Ep 76: Batch #6 - Loss: 0.8419888615608215\n",
      "Ep 76: Batch #7 - Loss: 0.6719968914985657\n",
      "Ep 76: Batch #8 - Loss: 0.7019321918487549\n",
      "Ep 76: Batch #9 - Loss: 1.3418242931365967\n",
      "Ep 76: Batch #10 - Loss: 0.9674574136734009\n",
      "Ep 76: Batch #11 - Loss: 0.6416572332382202\n",
      "Ep 76: Batch #12 - Loss: 1.513966679573059\n",
      "Ep 76: Batch #13 - Loss: 0.6248344779014587\n",
      "Ep 76: Batch #14 - Loss: 0.6981943249702454\n",
      "Ep 76: Batch #15 - Loss: 1.1869008541107178\n",
      "Ep 76: Batch #16 - Loss: 1.2178362607955933\n",
      "Ep 76: Batch #17 - Loss: 0.8407877683639526\n",
      "Ep 76: Batch #18 - Loss: 0.9161925911903381\n",
      "Ep 76: Batch #19 - Loss: 0.6429368853569031\n",
      "Ep 76: Batch #20 - Loss: 0.6253350973129272\n",
      "Ep 76: Batch #21 - Loss: 1.1745301485061646\n",
      "Ep 76: Batch #22 - Loss: 0.6976547241210938\n",
      "Ep 76: Batch #23 - Loss: 0.7081692814826965\n",
      "Ep 76: Batch #24 - Loss: 0.7942233681678772\n",
      "Ep 76: Batch #25 - Loss: 0.6820871829986572\n",
      "Ep 76: Batch #26 - Loss: 0.6941141486167908\n",
      "Ep 76: Batch #27 - Loss: 1.2975234985351562\n",
      "Ep 76: Batch #28 - Loss: 0.8358291387557983\n",
      "Ep 76: Batch #29 - Loss: 0.8498836159706116\n",
      "Ep 76: Batch #30 - Loss: 1.1573700904846191\n",
      "Ep 76: Batch #31 - Loss: 0.6455535888671875\n",
      "Ep 76: Batch #32 - Loss: 0.7119346857070923\n",
      "Ep 76: Batch #33 - Loss: 0.7747822999954224\n",
      "Ep 76: Batch #34 - Loss: 0.7499859929084778\n",
      "Ep 76: Batch #35 - Loss: 0.9021827578544617\n",
      "Ep 76: Batch #36 - Loss: 0.6690488457679749\n",
      "Ep 76: Batch #37 - Loss: 1.1025949716567993\n",
      "Ep 76: Batch #38 - Loss: 0.7062627673149109\n",
      "Ep 76: Batch #39 - Loss: 0.7893140316009521\n",
      "Ep 76: Batch #40 - Loss: 0.7402187585830688\n",
      "Ep 76: Batch #41 - Loss: 0.6981000304222107\n",
      "Ep 76: Batch #42 - Loss: 0.6898840665817261\n",
      "Ep 76: Batch #43 - Loss: 0.7547670602798462\n",
      "Ep 76: Batch #44 - Loss: 0.7459099292755127\n",
      "Ep 76: Batch #45 - Loss: 0.6017342805862427\n",
      "Ep 76: Batch #46 - Loss: 0.7885797023773193\n",
      "Ep 76: Batch #47 - Loss: 0.9090242981910706\n",
      "Ep 76: Batch #48 - Loss: 1.3091719150543213\n",
      "Ep 76: Batch #49 - Loss: 0.9630424380302429\n",
      "Ep 76: Batch #50 - Loss: 0.6801096200942993\n",
      "Ep 76: Batch #51 - Loss: 0.9427587389945984\n",
      "Ep 76: Batch #52 - Loss: 0.7621403336524963\n",
      "Ep 76: Batch #53 - Loss: 0.7847838997840881\n",
      "Ep 76: Batch #54 - Loss: 0.6741399765014648\n",
      "Ep 76: Batch #55 - Loss: 0.7169216871261597\n",
      "Ep 76: Batch #56 - Loss: 1.20518159866333\n",
      "Ep 76: Batch #57 - Loss: 0.8045753240585327\n",
      "Ep 76: Batch #58 - Loss: 0.947613537311554\n",
      "Ep 76: Batch #59 - Loss: 0.6555857062339783\n",
      "Ep 76: Batch #60 - Loss: 1.2600514888763428\n",
      "Ep 76: Batch #61 - Loss: 0.6095189452171326\n",
      "Ep 76: Batch #62 - Loss: 0.6878321766853333\n",
      "Ep 76: Batch #63 - Loss: 0.9581516981124878\n",
      "Ep 76: Batch #64 - Loss: 9.391119003295898\n",
      "Ep 76: Batch #65 - Loss: 0.5851084589958191\n",
      "Ep 76: Batch #66 - Loss: 0.7574242353439331\n",
      "Ep 76: Batch #67 - Loss: 0.872231662273407\n",
      "Ep 76: Batch #68 - Loss: 0.8625801801681519\n",
      "Ep 76: Batch #69 - Loss: 0.7127305865287781\n",
      "Ep 76: Batch #70 - Loss: 0.7343537211418152\n",
      "Ep 76: Batch #71 - Loss: 0.6515856385231018\n",
      "Ep 76: Batch #72 - Loss: 0.8147802948951721\n",
      "Ep 76: Batch #73 - Loss: 0.8544648885726929\n",
      "Ep 76: Batch #74 - Loss: 0.7014944553375244\n",
      "Ep 76: Batch #75 - Loss: 0.7365524768829346\n",
      "Ep 76: Batch #76 - Loss: 1.0580015182495117\n",
      "Ep 76: Batch #77 - Loss: 0.6975358128547668\n",
      "Ep 76: Batch #78 - Loss: 1.1042319536209106\n",
      "Ep 76: Batch #79 - Loss: 0.5973235964775085\n",
      "Ep 76: Batch #80 - Loss: 0.8152201175689697\n",
      "Ep 76: Batch #81 - Loss: 1.6403377056121826\n",
      "Ep 76: Batch #82 - Loss: 0.8369792699813843\n",
      "Ep 76: Batch #83 - Loss: 1.7054859399795532\n",
      "Ep 76: Batch #84 - Loss: 0.6802822351455688\n",
      "Ep 76: Batch #85 - Loss: 0.9383445978164673\n",
      "Ep 76: Batch #86 - Loss: 0.6710847616195679\n",
      "Ep 76: Batch #87 - Loss: 0.6799732446670532\n",
      "Ep 76: Batch #88 - Loss: 0.7632379531860352\n",
      "Ep 76: Batch #89 - Loss: 0.8588805794715881\n",
      "Ep 76: Batch #90 - Loss: 1.1006985902786255\n",
      "Ep 76: Batch #91 - Loss: 0.7603688836097717\n",
      "Ep 76: Batch #92 - Loss: 0.9827123284339905\n",
      "Ep 76: Batch #93 - Loss: 0.9730445146560669\n",
      "Ep 76: Batch #94 - Loss: 1.0007203817367554\n",
      "Ep 76: Batch #95 - Loss: 0.880698561668396\n",
      "Ep 76: Batch #96 - Loss: 0.8660019040107727\n",
      "Ep 76: Batch #97 - Loss: 0.6939957737922668\n",
      "Ep 76: Batch #98 - Loss: 0.7040306925773621\n",
      "Ep 76: Batch #99 - Loss: 0.9171447157859802\n",
      "Ep 76: Batch #100 - Loss: 0.6448908448219299\n",
      "Ep 76: Batch #101 - Loss: 1.0083355903625488\n",
      "Ep 76: Batch #102 - Loss: 0.7460722327232361\n",
      "Ep 76: Batch #103 - Loss: 0.7546384334564209\n",
      "Ep 76: Batch #104 - Loss: 0.7657582759857178\n",
      "Ep 76: Batch #105 - Loss: 0.9834374189376831\n",
      "Ep 76: Batch #106 - Loss: 0.7277224063873291\n",
      "Ep 76: Batch #107 - Loss: 0.7220706343650818\n",
      "Ep 76: Batch #108 - Loss: 0.9894882440567017\n",
      "Ep 76: Batch #109 - Loss: 0.7288553714752197\n",
      "Ep 76: Batch #110 - Loss: 0.871006190776825\n",
      "Ep 76: Batch #111 - Loss: 1.3259812593460083\n",
      "Ep 76: Batch #112 - Loss: 0.9993573427200317\n",
      "Ep 76: Batch #113 - Loss: 0.7801622152328491\n",
      "Ep 76: Batch #114 - Loss: 0.8582496643066406\n",
      "Ep 76: Batch #115 - Loss: 1.0486938953399658\n",
      "Ep 76: Batch #116 - Loss: 0.6105102300643921\n",
      "Ep 76: Batch #117 - Loss: 0.83687824010849\n",
      "Ep 76: Batch #118 - Loss: 0.5173512697219849\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved in file: ./weights_autoencoder_low_LR/model_e76b118_1516651279.0374353.ckpt\n",
      "Ep 76: Batch #119 - Loss: 0.9844852685928345\n",
      "Ep 76: Batch #120 - Loss: 0.7664898633956909\n",
      "Ep 76: Batch #121 - Loss: 0.6531689167022705\n",
      "Ep 76: Batch #122 - Loss: 0.7893794178962708\n",
      "Ep 76: Batch #123 - Loss: 0.7946009635925293\n",
      "Ep 76: Batch #124 - Loss: 0.6367897987365723\n",
      "Ep 76: Batch #125 - Loss: 2.665142774581909\n",
      "Ep 76: Batch #126 - Loss: 1.1776150465011597\n",
      "Ep 76: Batch #127 - Loss: 0.7098853588104248\n",
      "Ep 76: Batch #128 - Loss: 1.0492459535598755\n",
      "Ep 76: Batch #129 - Loss: 0.7979637980461121\n",
      "Ep 76: Batch #130 - Loss: 0.690719485282898\n",
      "Ep 76: Batch #131 - Loss: 0.9428145289421082\n",
      "Ep 76: Batch #132 - Loss: 0.7849857211112976\n",
      "Ep 76: Batch #133 - Loss: 0.7782636284828186\n",
      "Ep 76: Batch #134 - Loss: 0.7317859530448914\n",
      "Ep 76: Batch #135 - Loss: 0.9203285574913025\n",
      "Ep 76: Batch #136 - Loss: 1.1311429738998413\n",
      "Ep 76: Batch #137 - Loss: 0.9176576137542725\n",
      "Ep 76: Batch #138 - Loss: 1.0231512784957886\n",
      "Ep 76: Batch #139 - Loss: 0.8559384346008301\n",
      "Ep 76: Batch #140 - Loss: 1.006664514541626\n",
      "Ep 76: Batch #141 - Loss: 1.3063105344772339\n",
      "Ep 76: Batch #142 - Loss: 0.7583505511283875\n",
      "Ep 76: Batch #143 - Loss: 0.9143394231796265\n",
      "Ep 76: Batch #144 - Loss: 0.689335286617279\n",
      "Ep 76: Batch #145 - Loss: 0.6489286422729492\n",
      "Ep 76: Batch #146 - Loss: 0.8491132855415344\n",
      "Ep 76: Batch #147 - Loss: 0.8164193034172058\n",
      "Ep 76: Batch #148 - Loss: 0.9282345771789551\n",
      "Ep 76: Batch #149 - Loss: 0.8116467595100403\n",
      "Ep 76: Batch #150 - Loss: 0.8457114696502686\n",
      "Ep 76: Batch #151 - Loss: 0.7014654874801636\n",
      "Ep 76: Batch #152 - Loss: 0.7129470109939575\n",
      "Ep 76: Batch #153 - Loss: 1.054234504699707\n",
      "Ep 76: Batch #154 - Loss: 0.7280733585357666\n",
      "Ep 76: Batch #155 - Loss: 0.7967756390571594\n",
      "Ep 76: Batch #156 - Loss: 0.9754441976547241\n",
      "Ep 76: Batch #157 - Loss: 0.724927544593811\n",
      "Ep 76: Batch #158 - Loss: 0.7784751653671265\n",
      "Ep 76: Batch #159 - Loss: 0.7667498588562012\n",
      "Ep 76: Batch #160 - Loss: 0.8713054656982422\n",
      "Ep 76: Batch #161 - Loss: 0.7791579365730286\n",
      "Ep 76: Batch #162 - Loss: 0.892289400100708\n",
      "Ep 76: Batch #163 - Loss: 0.8945277333259583\n",
      "Ep 76: Batch #164 - Loss: 0.747329831123352\n",
      "Ep 76: Batch #165 - Loss: 1.4620529413223267\n",
      "Ep 76: Batch #166 - Loss: 0.6457090973854065\n",
      "Ep 76: Batch #167 - Loss: 1.0418384075164795\n",
      "Ep 76: Batch #168 - Loss: 0.8188473582267761\n",
      "Ep 76: Batch #169 - Loss: 0.7674025893211365\n",
      "Ep 76: Batch #170 - Loss: 0.7676118612289429\n",
      "Ep 76: Batch #171 - Loss: 0.7395415902137756\n",
      "Ep 76: Batch #172 - Loss: 0.6092064380645752\n",
      "Ep 76: Batch #173 - Loss: 1.1376523971557617\n",
      "Ep 76: Batch #174 - Loss: 0.5530482530593872\n",
      "Ep 76: Batch #175 - Loss: 0.7515242099761963\n",
      "Ep 76: Batch #176 - Loss: 1.0997282266616821\n",
      "Ep 76: Batch #177 - Loss: 0.809345543384552\n",
      "Ep 76: Batch #178 - Loss: 0.7271223068237305\n",
      "Ep 76: Batch #179 - Loss: 0.8980820178985596\n",
      "Ep 76: Batch #180 - Loss: 0.8092526793479919\n",
      "Ep 76: Batch #181 - Loss: 0.9419890642166138\n",
      "Ep 76: Batch #182 - Loss: 0.7352113127708435\n",
      "Ep 76: Batch #183 - Loss: 0.7320237159729004\n",
      "Ep 76: Batch #184 - Loss: 1.0309114456176758\n",
      "Ep 76: Batch #185 - Loss: 0.7235844731330872\n",
      "Ep 76: Batch #186 - Loss: 0.9165951013565063\n",
      "Ep 76: Batch #187 - Loss: 1.1163256168365479\n",
      "Ep 76: Batch #188 - Loss: 1.3082627058029175\n",
      "Ep 76: Batch #189 - Loss: 0.6758618354797363\n",
      "Ep 76: Batch #190 - Loss: 0.703728199005127\n",
      "Ep 76: Batch #191 - Loss: 1.014016032218933\n",
      "Ep 76: Batch #192 - Loss: 0.6456612944602966\n",
      "Ep 76: Batch #193 - Loss: 0.7057096362113953\n",
      "Ep 76: Batch #194 - Loss: 0.6628564596176147\n",
      "Ep 76: Batch #195 - Loss: 0.9401502013206482\n",
      "Ep 76: Batch #196 - Loss: 0.8244478702545166\n",
      "Ep 76: Batch #197 - Loss: 0.8569711446762085\n",
      "Ep 76: Batch #198 - Loss: 0.6439034938812256\n",
      "Ep 76: Batch #199 - Loss: 0.8229545950889587\n",
      "Ep 77: Batch #0 - Loss: 0.7506438493728638\n",
      "Ep 77: Batch #1 - Loss: 0.8339439034461975\n",
      "Ep 77: Batch #2 - Loss: 0.9746707081794739\n",
      "Ep 77: Batch #3 - Loss: 0.8293003439903259\n",
      "Ep 77: Batch #4 - Loss: 0.7504847645759583\n",
      "Ep 77: Batch #5 - Loss: 0.6386206746101379\n",
      "Ep 77: Batch #6 - Loss: 0.8409268856048584\n",
      "Ep 77: Batch #7 - Loss: 0.6711271405220032\n",
      "Ep 77: Batch #8 - Loss: 0.7009248733520508\n",
      "Ep 77: Batch #9 - Loss: 1.3399592638015747\n",
      "Ep 77: Batch #10 - Loss: 0.9662814736366272\n",
      "Ep 77: Batch #11 - Loss: 0.6407900452613831\n",
      "Ep 77: Batch #12 - Loss: 1.512610673904419\n",
      "Ep 77: Batch #13 - Loss: 0.6241344213485718\n",
      "Ep 77: Batch #14 - Loss: 0.6973108053207397\n",
      "Ep 77: Batch #15 - Loss: 1.1852983236312866\n",
      "Ep 77: Batch #16 - Loss: 1.2159368991851807\n",
      "Ep 77: Batch #17 - Loss: 0.8395969271659851\n",
      "Ep 77: Batch #18 - Loss: 0.9154394268989563\n",
      "Ep 77: Batch #19 - Loss: 0.6422621607780457\n",
      "Ep 77: Batch #20 - Loss: 0.6244443655014038\n",
      "Ep 77: Batch #21 - Loss: 1.1734901666641235\n",
      "Ep 77: Batch #22 - Loss: 0.6967231035232544\n",
      "Ep 77: Batch #23 - Loss: 0.7070782780647278\n",
      "Ep 77: Batch #24 - Loss: 0.7933571934700012\n",
      "Ep 77: Batch #25 - Loss: 0.6811690330505371\n",
      "Ep 77: Batch #26 - Loss: 0.6930838227272034\n",
      "Ep 77: Batch #27 - Loss: 1.2958163022994995\n",
      "Ep 77: Batch #28 - Loss: 0.8348977565765381\n",
      "Ep 77: Batch #29 - Loss: 0.848608136177063\n",
      "Ep 77: Batch #30 - Loss: 1.1559168100357056\n",
      "Ep 77: Batch #31 - Loss: 0.644719660282135\n",
      "Ep 77: Batch #32 - Loss: 0.7108985781669617\n",
      "Ep 77: Batch #33 - Loss: 0.7738161683082581\n",
      "Ep 77: Batch #34 - Loss: 0.748935878276825\n",
      "Ep 77: Batch #35 - Loss: 0.9008463621139526\n",
      "Ep 77: Batch #36 - Loss: 0.6680418848991394\n",
      "Ep 77: Batch #37 - Loss: 1.1015455722808838\n",
      "Ep 77: Batch #38 - Loss: 0.7050364017486572\n",
      "Ep 77: Batch #39 - Loss: 0.7883381247520447\n",
      "Ep 77: Batch #40 - Loss: 0.73924720287323\n",
      "Ep 77: Batch #41 - Loss: 0.696933925151825\n",
      "Ep 77: Batch #42 - Loss: 0.6889392733573914\n",
      "Ep 77: Batch #43 - Loss: 0.7537866830825806\n",
      "Ep 77: Batch #44 - Loss: 0.7446938157081604\n",
      "Ep 77: Batch #45 - Loss: 0.6009117960929871\n",
      "Ep 77: Batch #46 - Loss: 0.7873202562332153\n",
      "Ep 77: Batch #47 - Loss: 0.9074103832244873\n",
      "Ep 77: Batch #48 - Loss: 1.3077138662338257\n",
      "Ep 77: Batch #49 - Loss: 0.9615735411643982\n",
      "Ep 77: Batch #50 - Loss: 0.6793305277824402\n",
      "Ep 77: Batch #51 - Loss: 0.9411841630935669\n",
      "Ep 77: Batch #52 - Loss: 0.7611633539199829\n",
      "Ep 77: Batch #53 - Loss: 0.7836548686027527\n",
      "Ep 77: Batch #54 - Loss: 0.6731869578361511\n",
      "Ep 77: Batch #55 - Loss: 0.7159318923950195\n",
      "Ep 77: Batch #56 - Loss: 1.203396201133728\n",
      "Ep 77: Batch #57 - Loss: 0.8032199740409851\n",
      "Ep 77: Batch #58 - Loss: 0.9460806846618652\n",
      "Ep 77: Batch #59 - Loss: 0.6547962427139282\n",
      "Ep 77: Batch #60 - Loss: 1.2584606409072876\n",
      "Ep 77: Batch #61 - Loss: 0.6088036298751831\n",
      "Ep 77: Batch #62 - Loss: 0.6868981719017029\n",
      "Ep 77: Batch #63 - Loss: 0.956789493560791\n",
      "Ep 77: Batch #64 - Loss: 9.388969421386719\n",
      "Ep 77: Batch #65 - Loss: 0.5843163132667542\n",
      "Ep 77: Batch #66 - Loss: 0.7562727332115173\n",
      "Ep 77: Batch #67 - Loss: 0.8712037205696106\n",
      "Ep 77: Batch #68 - Loss: 0.861163318157196\n",
      "Ep 77: Batch #69 - Loss: 0.7118098139762878\n",
      "Ep 77: Batch #70 - Loss: 0.7331371307373047\n",
      "Ep 77: Batch #71 - Loss: 0.6507104635238647\n",
      "Ep 77: Batch #72 - Loss: 0.8134927749633789\n",
      "Ep 77: Batch #73 - Loss: 0.853049099445343\n",
      "Ep 77: Batch #74 - Loss: 0.7003294229507446\n",
      "Ep 77: Batch #75 - Loss: 0.7356684803962708\n",
      "Ep 77: Batch #76 - Loss: 1.056713342666626\n",
      "Ep 77: Batch #77 - Loss: 0.6964360475540161\n",
      "Ep 77: Batch #78 - Loss: 1.1025359630584717\n",
      "Ep 77: Batch #79 - Loss: 0.5965350270271301\n",
      "Ep 77: Batch #80 - Loss: 0.8138588666915894\n",
      "Ep 77: Batch #81 - Loss: 1.6392238140106201\n",
      "Ep 77: Batch #82 - Loss: 0.8359338045120239\n",
      "Ep 77: Batch #83 - Loss: 1.7046607732772827\n",
      "Ep 77: Batch #84 - Loss: 0.6793105602264404\n",
      "Ep 77: Batch #85 - Loss: 0.9371974468231201\n",
      "Ep 77: Batch #86 - Loss: 0.669989287853241\n",
      "Ep 77: Batch #87 - Loss: 0.6790377497673035\n",
      "Ep 77: Batch #88 - Loss: 0.7621349096298218\n",
      "Ep 77: Batch #89 - Loss: 0.8580834865570068\n",
      "Ep 77: Batch #90 - Loss: 1.0991297960281372\n",
      "Ep 77: Batch #91 - Loss: 0.7591800093650818\n",
      "Ep 77: Batch #92 - Loss: 0.9813521504402161\n",
      "Ep 77: Batch #93 - Loss: 0.9712656140327454\n",
      "Ep 77: Batch #94 - Loss: 0.9992305636405945\n",
      "Ep 77: Batch #95 - Loss: 0.8795937895774841\n",
      "Ep 77: Batch #96 - Loss: 0.8648728132247925\n",
      "Ep 77: Batch #97 - Loss: 0.6929836869239807\n",
      "Ep 77: Batch #98 - Loss: 0.7029953598976135\n",
      "Ep 77: Batch #99 - Loss: 0.9159151315689087\n",
      "Ep 77: Batch #100 - Loss: 0.6439260840415955\n",
      "Ep 77: Batch #101 - Loss: 1.007269263267517\n",
      "Ep 77: Batch #102 - Loss: 0.7449777722358704\n",
      "Ep 77: Batch #103 - Loss: 0.7535931468009949\n",
      "Ep 77: Batch #104 - Loss: 0.7647221684455872\n",
      "Ep 77: Batch #105 - Loss: 0.9822442531585693\n",
      "Ep 77: Batch #106 - Loss: 0.7268549203872681\n",
      "Ep 77: Batch #107 - Loss: 0.7210406064987183\n",
      "Ep 77: Batch #108 - Loss: 0.9882503747940063\n",
      "Ep 77: Batch #109 - Loss: 0.7278420329093933\n",
      "Ep 77: Batch #110 - Loss: 0.8696352243423462\n",
      "Ep 77: Batch #111 - Loss: 1.3243894577026367\n",
      "Ep 77: Batch #112 - Loss: 0.9978719353675842\n",
      "Ep 77: Batch #113 - Loss: 0.7791442275047302\n",
      "Ep 77: Batch #114 - Loss: 0.856918454170227\n",
      "Ep 77: Batch #115 - Loss: 1.047398567199707\n",
      "Ep 77: Batch #116 - Loss: 0.6098092794418335\n",
      "Ep 77: Batch #117 - Loss: 0.8358396887779236\n",
      "Ep 77: Batch #118 - Loss: 0.5166085362434387\n",
      "Model saved in file: ./weights_autoencoder_low_LR/model_e77b118_1516651279.1736848.ckpt\n",
      "Ep 77: Batch #119 - Loss: 0.9831221699714661\n",
      "Ep 77: Batch #120 - Loss: 0.7655090689659119\n",
      "Ep 77: Batch #121 - Loss: 0.6521961092948914\n",
      "Ep 77: Batch #122 - Loss: 0.7883144617080688\n",
      "Ep 77: Batch #123 - Loss: 0.7935444712638855\n",
      "Ep 77: Batch #124 - Loss: 0.6360292434692383\n",
      "Ep 77: Batch #125 - Loss: 2.6635799407958984\n",
      "Ep 77: Batch #126 - Loss: 1.1762142181396484\n",
      "Ep 77: Batch #127 - Loss: 0.7086582779884338\n",
      "Ep 77: Batch #128 - Loss: 1.0475502014160156\n",
      "Ep 77: Batch #129 - Loss: 0.7967464923858643\n",
      "Ep 77: Batch #130 - Loss: 0.6897916793823242\n",
      "Ep 77: Batch #131 - Loss: 0.9412452578544617\n",
      "Ep 77: Batch #132 - Loss: 0.7839048504829407\n",
      "Ep 77: Batch #133 - Loss: 0.7770885825157166\n",
      "Ep 77: Batch #134 - Loss: 0.7307710647583008\n",
      "Ep 77: Batch #135 - Loss: 0.9190933704376221\n",
      "Ep 77: Batch #136 - Loss: 1.1297410726547241\n",
      "Ep 77: Batch #137 - Loss: 0.916236937046051\n",
      "Ep 77: Batch #138 - Loss: 1.0216889381408691\n",
      "Ep 77: Batch #139 - Loss: 0.8545914888381958\n",
      "Ep 77: Batch #140 - Loss: 1.0054653882980347\n",
      "Ep 77: Batch #141 - Loss: 1.304762840270996\n",
      "Ep 77: Batch #142 - Loss: 0.7572305202484131\n",
      "Ep 77: Batch #143 - Loss: 0.9128702878952026\n",
      "Ep 77: Batch #144 - Loss: 0.6884870529174805\n",
      "Ep 77: Batch #145 - Loss: 0.6481108069419861\n",
      "Ep 77: Batch #146 - Loss: 0.8481830954551697\n",
      "Ep 77: Batch #147 - Loss: 0.8151916861534119\n",
      "Ep 77: Batch #148 - Loss: 0.9267739057540894\n",
      "Ep 77: Batch #149 - Loss: 0.8104686141014099\n",
      "Ep 77: Batch #150 - Loss: 0.8447238802909851\n",
      "Ep 77: Batch #151 - Loss: 0.7007134556770325\n",
      "Ep 77: Batch #152 - Loss: 0.7122148871421814\n",
      "Ep 77: Batch #153 - Loss: 1.0526915788650513\n",
      "Ep 77: Batch #154 - Loss: 0.7270509600639343\n",
      "Ep 77: Batch #155 - Loss: 0.7956868410110474\n",
      "Ep 77: Batch #156 - Loss: 0.9742400646209717\n",
      "Ep 77: Batch #157 - Loss: 0.723797619342804\n",
      "Ep 77: Batch #158 - Loss: 0.777708888053894\n",
      "Ep 77: Batch #159 - Loss: 0.7655152678489685\n",
      "Ep 77: Batch #160 - Loss: 0.8703154921531677\n",
      "Ep 77: Batch #161 - Loss: 0.7781166434288025\n",
      "Ep 77: Batch #162 - Loss: 0.8910539746284485\n",
      "Ep 77: Batch #163 - Loss: 0.8933998346328735\n",
      "Ep 77: Batch #164 - Loss: 0.7461861968040466\n",
      "Ep 77: Batch #165 - Loss: 1.461030125617981\n",
      "Ep 77: Batch #166 - Loss: 0.6447290182113647\n",
      "Ep 77: Batch #167 - Loss: 1.0404773950576782\n",
      "Ep 77: Batch #168 - Loss: 0.8175880312919617\n",
      "Ep 77: Batch #169 - Loss: 0.7664493918418884\n",
      "Ep 77: Batch #170 - Loss: 0.7665567398071289\n",
      "Ep 77: Batch #171 - Loss: 0.7382863163948059\n",
      "Ep 77: Batch #172 - Loss: 0.6085388660430908\n",
      "Ep 77: Batch #173 - Loss: 1.1358957290649414\n",
      "Ep 77: Batch #174 - Loss: 0.5522890686988831\n",
      "Ep 77: Batch #175 - Loss: 0.7507821917533875\n",
      "Ep 77: Batch #176 - Loss: 1.0981647968292236\n",
      "Ep 77: Batch #177 - Loss: 0.8081920146942139\n",
      "Ep 77: Batch #178 - Loss: 0.7260896563529968\n",
      "Ep 77: Batch #179 - Loss: 0.8968626856803894\n",
      "Ep 77: Batch #180 - Loss: 0.8078855872154236\n",
      "Ep 77: Batch #181 - Loss: 0.940547525882721\n",
      "Ep 77: Batch #182 - Loss: 0.7342668175697327\n",
      "Ep 77: Batch #183 - Loss: 0.7311606407165527\n",
      "Ep 77: Batch #184 - Loss: 1.0297423601150513\n",
      "Ep 77: Batch #185 - Loss: 0.7225692868232727\n",
      "Ep 77: Batch #186 - Loss: 0.915090799331665\n",
      "Ep 77: Batch #187 - Loss: 1.114768385887146\n",
      "Ep 77: Batch #188 - Loss: 1.3067631721496582\n",
      "Ep 77: Batch #189 - Loss: 0.6751402020454407\n",
      "Ep 77: Batch #190 - Loss: 0.7028170824050903\n",
      "Ep 77: Batch #191 - Loss: 1.0123947858810425\n",
      "Ep 77: Batch #192 - Loss: 0.6450423002243042\n",
      "Ep 77: Batch #193 - Loss: 0.7047497034072876\n",
      "Ep 77: Batch #194 - Loss: 0.6618824005126953\n",
      "Ep 77: Batch #195 - Loss: 0.938855767250061\n",
      "Ep 77: Batch #196 - Loss: 0.8231932520866394\n",
      "Ep 77: Batch #197 - Loss: 0.8555859327316284\n",
      "Ep 77: Batch #198 - Loss: 0.6429169178009033\n",
      "Ep 77: Batch #199 - Loss: 0.8217324614524841\n",
      "Ep 78: Batch #0 - Loss: 0.7494770884513855\n",
      "Ep 78: Batch #1 - Loss: 0.8326943516731262\n",
      "Ep 78: Batch #2 - Loss: 0.9737751483917236\n",
      "Ep 78: Batch #3 - Loss: 0.8282175660133362\n",
      "Ep 78: Batch #4 - Loss: 0.7493707537651062\n",
      "Ep 78: Batch #5 - Loss: 0.6377822160720825\n",
      "Ep 78: Batch #6 - Loss: 0.8398637771606445\n",
      "Ep 78: Batch #7 - Loss: 0.6702636480331421\n",
      "Ep 78: Batch #8 - Loss: 0.6999269127845764\n",
      "Ep 78: Batch #9 - Loss: 1.338088035583496\n",
      "Ep 78: Batch #10 - Loss: 0.9651070833206177\n",
      "Ep 78: Batch #11 - Loss: 0.6399232149124146\n",
      "Ep 78: Batch #12 - Loss: 1.5112661123275757\n",
      "Ep 78: Batch #13 - Loss: 0.623441755771637\n",
      "Ep 78: Batch #14 - Loss: 0.6964393258094788\n",
      "Ep 78: Batch #15 - Loss: 1.1837142705917358\n",
      "Ep 78: Batch #16 - Loss: 1.2140611410140991\n",
      "Ep 78: Batch #17 - Loss: 0.8384189009666443\n",
      "Ep 78: Batch #18 - Loss: 0.914689838886261\n",
      "Ep 78: Batch #19 - Loss: 0.6415900588035583\n",
      "Ep 78: Batch #20 - Loss: 0.6235635280609131\n",
      "Ep 78: Batch #21 - Loss: 1.172376275062561\n",
      "Ep 78: Batch #22 - Loss: 0.6957796216011047\n",
      "Ep 78: Batch #23 - Loss: 0.7059953212738037\n",
      "Ep 78: Batch #24 - Loss: 0.7924647331237793\n",
      "Ep 78: Batch #25 - Loss: 0.6802580952644348\n",
      "Ep 78: Batch #26 - Loss: 0.6920643448829651\n",
      "Ep 78: Batch #27 - Loss: 1.294119954109192\n",
      "Ep 78: Batch #28 - Loss: 0.8339590430259705\n",
      "Ep 78: Batch #29 - Loss: 0.8473491072654724\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 78: Batch #30 - Loss: 1.1544722318649292\n",
      "Ep 78: Batch #31 - Loss: 0.6439007520675659\n",
      "Ep 78: Batch #32 - Loss: 0.70987468957901\n",
      "Ep 78: Batch #33 - Loss: 0.7728599309921265\n",
      "Ep 78: Batch #34 - Loss: 0.7479038834571838\n",
      "Ep 78: Batch #35 - Loss: 0.8995216488838196\n",
      "Ep 78: Batch #36 - Loss: 0.667047381401062\n",
      "Ep 78: Batch #37 - Loss: 1.1005061864852905\n",
      "Ep 78: Batch #38 - Loss: 0.7038213610649109\n",
      "Ep 78: Batch #39 - Loss: 0.7873765230178833\n",
      "Ep 78: Batch #40 - Loss: 0.7382845282554626\n",
      "Ep 78: Batch #41 - Loss: 0.6957846879959106\n",
      "Ep 78: Batch #42 - Loss: 0.6880063414573669\n",
      "Ep 78: Batch #43 - Loss: 0.7528197169303894\n",
      "Ep 78: Batch #44 - Loss: 0.743489146232605\n",
      "Ep 78: Batch #45 - Loss: 0.6000993251800537\n",
      "Ep 78: Batch #46 - Loss: 0.7860742807388306\n",
      "Ep 78: Batch #47 - Loss: 0.905813992023468\n",
      "Ep 78: Batch #48 - Loss: 1.3062695264816284\n",
      "Ep 78: Batch #49 - Loss: 0.9601088166236877\n",
      "Ep 78: Batch #50 - Loss: 0.6785556077957153\n",
      "Ep 78: Batch #51 - Loss: 0.9396183490753174\n",
      "Ep 78: Batch #52 - Loss: 0.7601945400238037\n",
      "Ep 78: Batch #53 - Loss: 0.7825356125831604\n",
      "Ep 78: Batch #54 - Loss: 0.6722297668457031\n",
      "Ep 78: Batch #55 - Loss: 0.7149400115013123\n",
      "Ep 78: Batch #56 - Loss: 1.2016299962997437\n",
      "Ep 78: Batch #57 - Loss: 0.8018565773963928\n",
      "Ep 78: Batch #58 - Loss: 0.944567084312439\n",
      "Ep 78: Batch #59 - Loss: 0.6540102958679199\n",
      "Ep 78: Batch #60 - Loss: 1.2568724155426025\n",
      "Ep 78: Batch #61 - Loss: 0.6080865859985352\n",
      "Ep 78: Batch #62 - Loss: 0.6859776377677917\n",
      "Ep 78: Batch #63 - Loss: 0.9554568529129028\n",
      "Ep 78: Batch #64 - Loss: 9.386610984802246\n",
      "Ep 78: Batch #65 - Loss: 0.5835303664207458\n",
      "Ep 78: Batch #66 - Loss: 0.7551308870315552\n",
      "Ep 78: Batch #67 - Loss: 0.8701860308647156\n",
      "Ep 78: Batch #68 - Loss: 0.8597505688667297\n",
      "Ep 78: Batch #69 - Loss: 0.7109014391899109\n",
      "Ep 78: Batch #70 - Loss: 0.7319066524505615\n",
      "Ep 78: Batch #71 - Loss: 0.6498358845710754\n",
      "Ep 78: Batch #72 - Loss: 0.8122114539146423\n",
      "Ep 78: Batch #73 - Loss: 0.8516448140144348\n",
      "Ep 78: Batch #74 - Loss: 0.6991695165634155\n",
      "Ep 78: Batch #75 - Loss: 0.7348012924194336\n",
      "Ep 78: Batch #76 - Loss: 1.0554158687591553\n",
      "Ep 78: Batch #77 - Loss: 0.6953456401824951\n",
      "Ep 78: Batch #78 - Loss: 1.1008412837982178\n",
      "Ep 78: Batch #79 - Loss: 0.5957543849945068\n",
      "Ep 78: Batch #80 - Loss: 0.8125070929527283\n",
      "Ep 78: Batch #81 - Loss: 1.638122797012329\n",
      "Ep 78: Batch #82 - Loss: 0.83489990234375\n",
      "Ep 78: Batch #83 - Loss: 1.703845500946045\n",
      "Ep 78: Batch #84 - Loss: 0.6783439517021179\n",
      "Ep 78: Batch #85 - Loss: 0.9360543489456177\n",
      "Ep 78: Batch #86 - Loss: 0.668903112411499\n",
      "Ep 78: Batch #87 - Loss: 0.678108274936676\n",
      "Ep 78: Batch #88 - Loss: 0.7610370516777039\n",
      "Ep 78: Batch #89 - Loss: 0.857286274433136\n",
      "Ep 78: Batch #90 - Loss: 1.097548007965088\n",
      "Ep 78: Batch #91 - Loss: 0.7579941153526306\n",
      "Ep 78: Batch #92 - Loss: 0.9799858927726746\n",
      "Ep 78: Batch #93 - Loss: 0.9694837331771851\n",
      "Ep 78: Batch #94 - Loss: 0.9977400302886963\n",
      "Ep 78: Batch #95 - Loss: 0.8784887194633484\n",
      "Ep 78: Batch #96 - Loss: 0.8637468218803406\n",
      "Ep 78: Batch #97 - Loss: 0.6919746994972229\n",
      "Ep 78: Batch #98 - Loss: 0.7019675970077515\n",
      "Ep 78: Batch #99 - Loss: 0.9146845936775208\n",
      "Ep 78: Batch #100 - Loss: 0.6429721117019653\n",
      "Ep 78: Batch #101 - Loss: 1.006204605102539\n",
      "Ep 78: Batch #102 - Loss: 0.7438874840736389\n",
      "Ep 78: Batch #103 - Loss: 0.752551794052124\n",
      "Ep 78: Batch #104 - Loss: 0.7636801600456238\n",
      "Ep 78: Batch #105 - Loss: 0.9810646176338196\n",
      "Ep 78: Batch #106 - Loss: 0.726007878780365\n",
      "Ep 78: Batch #107 - Loss: 0.720020055770874\n",
      "Ep 78: Batch #108 - Loss: 0.9870249629020691\n",
      "Ep 78: Batch #109 - Loss: 0.7268372178077698\n",
      "Ep 78: Batch #110 - Loss: 0.8682770729064941\n",
      "Ep 78: Batch #111 - Loss: 1.322803020477295\n",
      "Ep 78: Batch #112 - Loss: 0.9964001178741455\n",
      "Ep 78: Batch #113 - Loss: 0.7781317234039307\n",
      "Ep 78: Batch #114 - Loss: 0.8556022644042969\n",
      "Ep 78: Batch #115 - Loss: 1.0461106300354004\n",
      "Ep 78: Batch #116 - Loss: 0.6090939044952393\n",
      "Ep 78: Batch #117 - Loss: 0.8348106741905212\n",
      "Ep 78: Batch #118 - Loss: 0.5158820748329163\n",
      "Model saved in file: ./weights_autoencoder_low_LR/model_e78b118_1516651279.3096855.ckpt\n",
      "Ep 78: Batch #119 - Loss: 0.9817672371864319\n",
      "Ep 78: Batch #120 - Loss: 0.7645218968391418\n",
      "Ep 78: Batch #121 - Loss: 0.6512361168861389\n",
      "Ep 78: Batch #122 - Loss: 0.7872565388679504\n",
      "Ep 78: Batch #123 - Loss: 0.7925039529800415\n",
      "Ep 78: Batch #124 - Loss: 0.6352689266204834\n",
      "Ep 78: Batch #125 - Loss: 2.6619997024536133\n",
      "Ep 78: Batch #126 - Loss: 1.1748303174972534\n",
      "Ep 78: Batch #127 - Loss: 0.707435131072998\n",
      "Ep 78: Batch #128 - Loss: 1.045862078666687\n",
      "Ep 78: Batch #129 - Loss: 0.7955278158187866\n",
      "Ep 78: Batch #130 - Loss: 0.6888651251792908\n",
      "Ep 78: Batch #131 - Loss: 0.9396890997886658\n",
      "Ep 78: Batch #132 - Loss: 0.7828270196914673\n",
      "Ep 78: Batch #133 - Loss: 0.7759200930595398\n",
      "Ep 78: Batch #134 - Loss: 0.7297685146331787\n",
      "Ep 78: Batch #135 - Loss: 0.917868435382843\n",
      "Ep 78: Batch #136 - Loss: 1.1283586025238037\n",
      "Ep 78: Batch #137 - Loss: 0.9148150682449341\n",
      "Ep 78: Batch #138 - Loss: 1.0202195644378662\n",
      "Ep 78: Batch #139 - Loss: 0.853242814540863\n",
      "Ep 78: Batch #140 - Loss: 1.0042858123779297\n",
      "Ep 78: Batch #141 - Loss: 1.3032301664352417\n",
      "Ep 78: Batch #142 - Loss: 0.7561150193214417\n",
      "Ep 78: Batch #143 - Loss: 0.9113969802856445\n",
      "Ep 78: Batch #144 - Loss: 0.6876496076583862\n",
      "Ep 78: Batch #145 - Loss: 0.6472935080528259\n",
      "Ep 78: Batch #146 - Loss: 0.8472605347633362\n",
      "Ep 78: Batch #147 - Loss: 0.8139610886573792\n",
      "Ep 78: Batch #148 - Loss: 0.9253215789794922\n",
      "Ep 78: Batch #149 - Loss: 0.8093053698539734\n",
      "Ep 78: Batch #150 - Loss: 0.8437517285346985\n",
      "Ep 78: Batch #151 - Loss: 0.6999707221984863\n",
      "Ep 78: Batch #152 - Loss: 0.7114938497543335\n",
      "Ep 78: Batch #153 - Loss: 1.0511655807495117\n",
      "Ep 78: Batch #154 - Loss: 0.726039707660675\n",
      "Ep 78: Batch #155 - Loss: 0.7946030497550964\n",
      "Ep 78: Batch #156 - Loss: 0.9730482697486877\n",
      "Ep 78: Batch #157 - Loss: 0.7226817607879639\n",
      "Ep 78: Batch #158 - Loss: 0.7769502401351929\n",
      "Ep 78: Batch #159 - Loss: 0.7642941474914551\n",
      "Ep 78: Batch #160 - Loss: 0.8693391680717468\n",
      "Ep 78: Batch #161 - Loss: 0.7770927548408508\n",
      "Ep 78: Batch #162 - Loss: 0.889834463596344\n",
      "Ep 78: Batch #163 - Loss: 0.8922662734985352\n",
      "Ep 78: Batch #164 - Loss: 0.7450491189956665\n",
      "Ep 78: Batch #165 - Loss: 1.4600216150283813\n",
      "Ep 78: Batch #166 - Loss: 0.643761157989502\n",
      "Ep 78: Batch #167 - Loss: 1.0391278266906738\n",
      "Ep 78: Batch #168 - Loss: 0.8163400292396545\n",
      "Ep 78: Batch #169 - Loss: 0.7654981017112732\n",
      "Ep 78: Batch #170 - Loss: 0.7654852867126465\n",
      "Ep 78: Batch #171 - Loss: 0.7370414733886719\n",
      "Ep 78: Batch #172 - Loss: 0.607883632183075\n",
      "Ep 78: Batch #173 - Loss: 1.1341681480407715\n",
      "Ep 78: Batch #174 - Loss: 0.5515362620353699\n",
      "Ep 78: Batch #175 - Loss: 0.7500492334365845\n",
      "Ep 78: Batch #176 - Loss: 1.0966169834136963\n",
      "Ep 78: Batch #177 - Loss: 0.8070477247238159\n",
      "Ep 78: Batch #178 - Loss: 0.7250630259513855\n",
      "Ep 78: Batch #179 - Loss: 0.8956381678581238\n",
      "Ep 78: Batch #180 - Loss: 0.8065311312675476\n",
      "Ep 78: Batch #181 - Loss: 0.9391305446624756\n",
      "Ep 78: Batch #182 - Loss: 0.7333216667175293\n",
      "Ep 78: Batch #183 - Loss: 0.7303081750869751\n",
      "Ep 78: Batch #184 - Loss: 1.0285815000534058\n",
      "Ep 78: Batch #185 - Loss: 0.7215671539306641\n",
      "Ep 78: Batch #186 - Loss: 0.9136058688163757\n",
      "Ep 78: Batch #187 - Loss: 1.1132287979125977\n",
      "Ep 78: Batch #188 - Loss: 1.3052843809127808\n",
      "Ep 78: Batch #189 - Loss: 0.674429714679718\n",
      "Ep 78: Batch #190 - Loss: 0.7019102573394775\n",
      "Ep 78: Batch #191 - Loss: 1.0107871294021606\n",
      "Ep 78: Batch #192 - Loss: 0.6444277763366699\n",
      "Ep 78: Batch #193 - Loss: 0.7038109302520752\n",
      "Ep 78: Batch #194 - Loss: 0.6609131097793579\n",
      "Ep 78: Batch #195 - Loss: 0.9375729560852051\n",
      "Ep 78: Batch #196 - Loss: 0.8219520449638367\n",
      "Ep 78: Batch #197 - Loss: 0.8542183041572571\n",
      "Ep 78: Batch #198 - Loss: 0.6419388651847839\n",
      "Ep 78: Batch #199 - Loss: 0.8205177187919617\n",
      "Ep 79: Batch #0 - Loss: 0.7483176589012146\n",
      "Ep 79: Batch #1 - Loss: 0.8314605951309204\n",
      "Ep 79: Batch #2 - Loss: 0.9728856086730957\n",
      "Ep 79: Batch #3 - Loss: 0.8271451592445374\n",
      "Ep 79: Batch #4 - Loss: 0.7482684254646301\n",
      "Ep 79: Batch #5 - Loss: 0.6369527578353882\n",
      "Ep 79: Batch #6 - Loss: 0.8388131856918335\n",
      "Ep 79: Batch #7 - Loss: 0.6694127321243286\n",
      "Ep 79: Batch #8 - Loss: 0.698946475982666\n",
      "Ep 79: Batch #9 - Loss: 1.3362138271331787\n",
      "Ep 79: Batch #10 - Loss: 0.9638811945915222\n",
      "Ep 79: Batch #11 - Loss: 0.639064371585846\n",
      "Ep 79: Batch #12 - Loss: 1.5099300146102905\n",
      "Ep 79: Batch #13 - Loss: 0.6227595210075378\n",
      "Ep 79: Batch #14 - Loss: 0.6955890655517578\n",
      "Ep 79: Batch #15 - Loss: 1.1821547746658325\n",
      "Ep 79: Batch #16 - Loss: 1.212201476097107\n",
      "Ep 79: Batch #17 - Loss: 0.8372613191604614\n",
      "Ep 79: Batch #18 - Loss: 0.9139459133148193\n",
      "Ep 79: Batch #19 - Loss: 0.6409274935722351\n",
      "Ep 79: Batch #20 - Loss: 0.6226986050605774\n",
      "Ep 79: Batch #21 - Loss: 1.171223521232605\n",
      "Ep 79: Batch #22 - Loss: 0.6948599815368652\n",
      "Ep 79: Batch #23 - Loss: 0.7049193382263184\n",
      "Ep 79: Batch #24 - Loss: 0.7915482521057129\n",
      "Ep 79: Batch #25 - Loss: 0.6793688535690308\n",
      "Ep 79: Batch #26 - Loss: 0.691059410572052\n",
      "Ep 79: Batch #27 - Loss: 1.2924394607543945\n",
      "Ep 79: Batch #28 - Loss: 0.8330252766609192\n",
      "Ep 79: Batch #29 - Loss: 0.8461124897003174\n",
      "Ep 79: Batch #30 - Loss: 1.153051495552063\n",
      "Ep 79: Batch #31 - Loss: 0.6430955529212952\n",
      "Ep 79: Batch #32 - Loss: 0.7088642716407776\n",
      "Ep 79: Batch #33 - Loss: 0.7719194293022156\n",
      "Ep 79: Batch #34 - Loss: 0.7468904852867126\n",
      "Ep 79: Batch #35 - Loss: 0.8982158303260803\n",
      "Ep 79: Batch #36 - Loss: 0.6660855412483215\n",
      "Ep 79: Batch #37 - Loss: 1.0994833707809448\n",
      "Ep 79: Batch #38 - Loss: 0.7026273608207703\n",
      "Ep 79: Batch #39 - Loss: 0.7864319086074829\n",
      "Ep 79: Batch #40 - Loss: 0.7373347878456116\n",
      "Ep 79: Batch #41 - Loss: 0.6946638822555542\n",
      "Ep 79: Batch #42 - Loss: 0.6870894432067871\n",
      "Ep 79: Batch #43 - Loss: 0.7518646121025085\n",
      "Ep 79: Batch #44 - Loss: 0.7422991991043091\n",
      "Ep 79: Batch #45 - Loss: 0.5992963910102844\n",
      "Ep 79: Batch #46 - Loss: 0.7848496437072754\n",
      "Ep 79: Batch #47 - Loss: 0.9042412042617798\n",
      "Ep 79: Batch #48 - Loss: 1.304830551147461\n",
      "Ep 79: Batch #49 - Loss: 0.9586613178253174\n",
      "Ep 79: Batch #50 - Loss: 0.677787721157074\n",
      "Ep 79: Batch #51 - Loss: 0.9380728602409363\n",
      "Ep 79: Batch #52 - Loss: 0.7592422366142273\n",
      "Ep 79: Batch #53 - Loss: 0.7814308404922485\n",
      "Ep 79: Batch #54 - Loss: 0.671280562877655\n",
      "Ep 79: Batch #55 - Loss: 0.7139500379562378\n",
      "Ep 79: Batch #56 - Loss: 1.1998791694641113\n",
      "Ep 79: Batch #57 - Loss: 0.8005143404006958\n",
      "Ep 79: Batch #58 - Loss: 0.9430718421936035\n",
      "Ep 79: Batch #59 - Loss: 0.6532464027404785\n",
      "Ep 79: Batch #60 - Loss: 1.255294919013977\n",
      "Ep 79: Batch #61 - Loss: 0.6073721051216125\n",
      "Ep 79: Batch #62 - Loss: 0.6850765347480774\n",
      "Ep 79: Batch #63 - Loss: 0.9541572332382202\n",
      "Ep 79: Batch #64 - Loss: 9.379481315612793\n",
      "Ep 79: Batch #65 - Loss: 0.5827537775039673\n",
      "Ep 79: Batch #66 - Loss: 0.7540109753608704\n",
      "Ep 79: Batch #67 - Loss: 0.8691801428794861\n",
      "Ep 79: Batch #68 - Loss: 0.8583760857582092\n",
      "Ep 79: Batch #69 - Loss: 0.7099893093109131\n",
      "Ep 79: Batch #70 - Loss: 0.7306925654411316\n",
      "Ep 79: Batch #71 - Loss: 0.6489807367324829\n",
      "Ep 79: Batch #72 - Loss: 0.8109670877456665\n",
      "Ep 79: Batch #73 - Loss: 0.8502678275108337\n",
      "Ep 79: Batch #74 - Loss: 0.698024332523346\n",
      "Ep 79: Batch #75 - Loss: 0.733953058719635\n",
      "Ep 79: Batch #76 - Loss: 1.0541648864746094\n",
      "Ep 79: Batch #77 - Loss: 0.6942764520645142\n",
      "Ep 79: Batch #78 - Loss: 1.0991798639297485\n",
      "Ep 79: Batch #79 - Loss: 0.5949819684028625\n",
      "Ep 79: Batch #80 - Loss: 0.8111827373504639\n",
      "Ep 79: Batch #81 - Loss: 1.6370354890823364\n",
      "Ep 79: Batch #82 - Loss: 0.8338731527328491\n",
      "Ep 79: Batch #83 - Loss: 1.703046202659607\n",
      "Ep 79: Batch #84 - Loss: 0.6774106621742249\n",
      "Ep 79: Batch #85 - Loss: 0.9349456429481506\n",
      "Ep 79: Batch #86 - Loss: 0.6678354144096375\n",
      "Ep 79: Batch #87 - Loss: 0.6772019267082214\n",
      "Ep 79: Batch #88 - Loss: 0.7599656581878662\n",
      "Ep 79: Batch #89 - Loss: 0.856511652469635\n",
      "Ep 79: Batch #90 - Loss: 1.096014380455017\n",
      "Ep 79: Batch #91 - Loss: 0.7568321824073792\n",
      "Ep 79: Batch #92 - Loss: 0.9786568284034729\n",
      "Ep 79: Batch #93 - Loss: 0.9677204489707947\n",
      "Ep 79: Batch #94 - Loss: 0.9962594509124756\n",
      "Ep 79: Batch #95 - Loss: 0.8774034380912781\n",
      "Ep 79: Batch #96 - Loss: 0.8626254796981812\n",
      "Ep 79: Batch #97 - Loss: 0.6909964084625244\n",
      "Ep 79: Batch #98 - Loss: 0.7009720802307129\n",
      "Ep 79: Batch #99 - Loss: 0.9134923815727234\n",
      "Ep 79: Batch #100 - Loss: 0.6420406103134155\n",
      "Ep 79: Batch #101 - Loss: 1.0051579475402832\n",
      "Ep 79: Batch #102 - Loss: 0.7428038120269775\n",
      "Ep 79: Batch #103 - Loss: 0.7515302896499634\n",
      "Ep 79: Batch #104 - Loss: 0.7626526355743408\n",
      "Ep 79: Batch #105 - Loss: 0.9799003005027771\n",
      "Ep 79: Batch #106 - Loss: 0.7251562476158142\n",
      "Ep 79: Batch #107 - Loss: 0.7190068364143372\n",
      "Ep 79: Batch #108 - Loss: 0.9858341813087463\n",
      "Ep 79: Batch #109 - Loss: 0.7258477807044983\n",
      "Ep 79: Batch #110 - Loss: 0.8669460415840149\n",
      "Ep 79: Batch #111 - Loss: 1.3212311267852783\n",
      "Ep 79: Batch #112 - Loss: 0.9949561357498169\n",
      "Ep 79: Batch #113 - Loss: 0.7771351933479309\n",
      "Ep 79: Batch #114 - Loss: 0.8542997241020203\n",
      "Ep 79: Batch #115 - Loss: 1.0448514223098755\n",
      "Ep 79: Batch #116 - Loss: 0.6084040403366089\n",
      "Ep 79: Batch #117 - Loss: 0.833808422088623\n",
      "Ep 79: Batch #118 - Loss: 0.5151820778846741\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved in file: ./weights_autoencoder_low_LR/model_e79b118_1516651279.4540327.ckpt\n",
      "Ep 79: Batch #119 - Loss: 0.9804341793060303\n",
      "Ep 79: Batch #120 - Loss: 0.7635586857795715\n",
      "Ep 79: Batch #121 - Loss: 0.6502948999404907\n",
      "Ep 79: Batch #122 - Loss: 0.7862198948860168\n",
      "Ep 79: Batch #123 - Loss: 0.791481614112854\n",
      "Ep 79: Batch #124 - Loss: 0.6345072388648987\n",
      "Ep 79: Batch #125 - Loss: 2.6604464054107666\n",
      "Ep 79: Batch #126 - Loss: 1.1734718084335327\n",
      "Ep 79: Batch #127 - Loss: 0.7062517404556274\n",
      "Ep 79: Batch #128 - Loss: 1.0442001819610596\n",
      "Ep 79: Batch #129 - Loss: 0.7943360209465027\n",
      "Ep 79: Batch #130 - Loss: 0.6879502534866333\n",
      "Ep 79: Batch #131 - Loss: 0.9381476640701294\n",
      "Ep 79: Batch #132 - Loss: 0.7817690968513489\n",
      "Ep 79: Batch #133 - Loss: 0.7747544646263123\n",
      "Ep 79: Batch #134 - Loss: 0.7287929058074951\n",
      "Ep 79: Batch #135 - Loss: 0.9166624546051025\n",
      "Ep 79: Batch #136 - Loss: 1.1269997358322144\n",
      "Ep 79: Batch #137 - Loss: 0.9134313464164734\n",
      "Ep 79: Batch #138 - Loss: 1.0187931060791016\n",
      "Ep 79: Batch #139 - Loss: 0.8519123196601868\n",
      "Ep 79: Batch #140 - Loss: 1.003114938735962\n",
      "Ep 79: Batch #141 - Loss: 1.301730990409851\n",
      "Ep 79: Batch #142 - Loss: 0.7550200819969177\n",
      "Ep 79: Batch #143 - Loss: 0.9099444150924683\n",
      "Ep 79: Batch #144 - Loss: 0.6868202090263367\n",
      "Ep 79: Batch #145 - Loss: 0.6464938521385193\n",
      "Ep 79: Batch #146 - Loss: 0.8463438749313354\n",
      "Ep 79: Batch #147 - Loss: 0.8127223253250122\n",
      "Ep 79: Batch #148 - Loss: 0.9239025712013245\n",
      "Ep 79: Batch #149 - Loss: 0.808157205581665\n",
      "Ep 79: Batch #150 - Loss: 0.8428040146827698\n",
      "Ep 79: Batch #151 - Loss: 0.6992473602294922\n",
      "Ep 79: Batch #152 - Loss: 0.7107914090156555\n",
      "Ep 79: Batch #153 - Loss: 1.0496537685394287\n",
      "Ep 79: Batch #154 - Loss: 0.725055456161499\n",
      "Ep 79: Batch #155 - Loss: 0.7935570478439331\n",
      "Ep 79: Batch #156 - Loss: 0.9718716144561768\n",
      "Ep 79: Batch #157 - Loss: 0.7215930819511414\n",
      "Ep 79: Batch #158 - Loss: 0.776208758354187\n",
      "Ep 79: Batch #159 - Loss: 0.7630918622016907\n",
      "Ep 79: Batch #160 - Loss: 0.868381917476654\n",
      "Ep 79: Batch #161 - Loss: 0.776096761226654\n",
      "Ep 79: Batch #162 - Loss: 0.8886372447013855\n",
      "Ep 79: Batch #163 - Loss: 0.8911598920822144\n",
      "Ep 79: Batch #164 - Loss: 0.7439408898353577\n",
      "Ep 79: Batch #165 - Loss: 1.4589946269989014\n",
      "Ep 79: Batch #166 - Loss: 0.6428114771842957\n",
      "Ep 79: Batch #167 - Loss: 1.0377978086471558\n",
      "Ep 79: Batch #168 - Loss: 0.8151286840438843\n",
      "Ep 79: Batch #169 - Loss: 0.764556348323822\n",
      "Ep 79: Batch #170 - Loss: 0.764433741569519\n",
      "Ep 79: Batch #171 - Loss: 0.7358356714248657\n",
      "Ep 79: Batch #172 - Loss: 0.6072542667388916\n",
      "Ep 79: Batch #173 - Loss: 1.132462739944458\n",
      "Ep 79: Batch #174 - Loss: 0.550795316696167\n",
      "Ep 79: Batch #175 - Loss: 0.7493153810501099\n",
      "Ep 79: Batch #176 - Loss: 1.0951051712036133\n",
      "Ep 79: Batch #177 - Loss: 0.8059258460998535\n",
      "Ep 79: Batch #178 - Loss: 0.7240439057350159\n",
      "Ep 79: Batch #179 - Loss: 0.8944368958473206\n",
      "Ep 79: Batch #180 - Loss: 0.8051981329917908\n",
      "Ep 79: Batch #181 - Loss: 0.9377460479736328\n",
      "Ep 79: Batch #182 - Loss: 0.732406497001648\n",
      "Ep 79: Batch #183 - Loss: 0.7294743657112122\n",
      "Ep 79: Batch #184 - Loss: 1.027441143989563\n",
      "Ep 79: Batch #185 - Loss: 0.7205901741981506\n",
      "Ep 79: Batch #186 - Loss: 0.9121428728103638\n",
      "Ep 79: Batch #187 - Loss: 1.111723780632019\n",
      "Ep 79: Batch #188 - Loss: 1.3038486242294312\n",
      "Ep 79: Batch #189 - Loss: 0.6737387180328369\n",
      "Ep 79: Batch #190 - Loss: 0.701012372970581\n",
      "Ep 79: Batch #191 - Loss: 1.0092166662216187\n",
      "Ep 79: Batch #192 - Loss: 0.6438152194023132\n",
      "Ep 79: Batch #193 - Loss: 0.7028898596763611\n",
      "Ep 79: Batch #194 - Loss: 0.6599698662757874\n",
      "Ep 79: Batch #195 - Loss: 0.9363194704055786\n",
      "Ep 79: Batch #196 - Loss: 0.8207361102104187\n",
      "Ep 79: Batch #197 - Loss: 0.8528743982315063\n",
      "Ep 79: Batch #198 - Loss: 0.6409807205200195\n",
      "Ep 79: Batch #199 - Loss: 0.8193300366401672\n",
      "Ep 80: Batch #0 - Loss: 0.7471708059310913\n",
      "Ep 80: Batch #1 - Loss: 0.8302507400512695\n",
      "Ep 80: Batch #2 - Loss: 0.9720174670219421\n",
      "Ep 80: Batch #3 - Loss: 0.8260875940322876\n",
      "Ep 80: Batch #4 - Loss: 0.7471938133239746\n",
      "Ep 80: Batch #5 - Loss: 0.6361419558525085\n",
      "Ep 80: Batch #6 - Loss: 0.8377739787101746\n",
      "Ep 80: Batch #7 - Loss: 0.6685811281204224\n",
      "Ep 80: Batch #8 - Loss: 0.697979748249054\n",
      "Ep 80: Batch #9 - Loss: 1.3343734741210938\n",
      "Ep 80: Batch #10 - Loss: 0.9626762270927429\n",
      "Ep 80: Batch #11 - Loss: 0.6382149457931519\n",
      "Ep 80: Batch #12 - Loss: 1.5086088180541992\n",
      "Ep 80: Batch #13 - Loss: 0.6220884919166565\n",
      "Ep 80: Batch #14 - Loss: 0.6947651505470276\n",
      "Ep 80: Batch #15 - Loss: 1.180620789527893\n",
      "Ep 80: Batch #16 - Loss: 1.210381269454956\n",
      "Ep 80: Batch #17 - Loss: 0.8361218571662903\n",
      "Ep 80: Batch #18 - Loss: 0.9132130742073059\n",
      "Ep 80: Batch #19 - Loss: 0.6402691602706909\n",
      "Ep 80: Batch #20 - Loss: 0.6218509674072266\n",
      "Ep 80: Batch #21 - Loss: 1.1701029539108276\n",
      "Ep 80: Batch #22 - Loss: 0.6939719319343567\n",
      "Ep 80: Batch #23 - Loss: 0.7038594484329224\n",
      "Ep 80: Batch #24 - Loss: 0.7906519174575806\n",
      "Ep 80: Batch #25 - Loss: 0.6784818172454834\n",
      "Ep 80: Batch #26 - Loss: 0.6900752782821655\n",
      "Ep 80: Batch #27 - Loss: 1.2907789945602417\n",
      "Ep 80: Batch #28 - Loss: 0.8321130871772766\n",
      "Ep 80: Batch #29 - Loss: 0.844903290271759\n",
      "Ep 80: Batch #30 - Loss: 1.1516518592834473\n",
      "Ep 80: Batch #31 - Loss: 0.6423097252845764\n",
      "Ep 80: Batch #32 - Loss: 0.7078757286071777\n",
      "Ep 80: Batch #33 - Loss: 0.7709985971450806\n",
      "Ep 80: Batch #34 - Loss: 0.7458981275558472\n",
      "Ep 80: Batch #35 - Loss: 0.896920919418335\n",
      "Ep 80: Batch #36 - Loss: 0.6651380062103271\n",
      "Ep 80: Batch #37 - Loss: 1.0984725952148438\n",
      "Ep 80: Batch #38 - Loss: 0.7014591693878174\n",
      "Ep 80: Batch #39 - Loss: 0.7855046391487122\n",
      "Ep 80: Batch #40 - Loss: 0.7364019155502319\n",
      "Ep 80: Batch #41 - Loss: 0.6935812830924988\n",
      "Ep 80: Batch #42 - Loss: 0.6861893534660339\n",
      "Ep 80: Batch #43 - Loss: 0.7509288191795349\n",
      "Ep 80: Batch #44 - Loss: 0.7411393523216248\n",
      "Ep 80: Batch #45 - Loss: 0.5985113978385925\n",
      "Ep 80: Batch #46 - Loss: 0.7836440205574036\n",
      "Ep 80: Batch #47 - Loss: 0.9026910662651062\n",
      "Ep 80: Batch #48 - Loss: 1.3034019470214844\n",
      "Ep 80: Batch #49 - Loss: 0.9572347402572632\n",
      "Ep 80: Batch #50 - Loss: 0.6770283579826355\n",
      "Ep 80: Batch #51 - Loss: 0.936549961566925\n",
      "Ep 80: Batch #52 - Loss: 0.7583093643188477\n",
      "Ep 80: Batch #53 - Loss: 0.7803345322608948\n",
      "Ep 80: Batch #54 - Loss: 0.6703395843505859\n",
      "Ep 80: Batch #55 - Loss: 0.7129599452018738\n",
      "Ep 80: Batch #56 - Loss: 1.1981589794158936\n",
      "Ep 80: Batch #57 - Loss: 0.7991951107978821\n",
      "Ep 80: Batch #58 - Loss: 0.9416094422340393\n",
      "Ep 80: Batch #59 - Loss: 0.6525022983551025\n",
      "Ep 80: Batch #60 - Loss: 1.253747820854187\n",
      "Ep 80: Batch #61 - Loss: 0.6066651344299316\n",
      "Ep 80: Batch #62 - Loss: 0.6841967701911926\n",
      "Ep 80: Batch #63 - Loss: 0.9528928399085999\n",
      "Ep 80: Batch #64 - Loss: 9.374483108520508\n",
      "Ep 80: Batch #65 - Loss: 0.5819802284240723\n",
      "Ep 80: Batch #66 - Loss: 0.7529203295707703\n",
      "Ep 80: Batch #67 - Loss: 0.868195116519928\n",
      "Ep 80: Batch #68 - Loss: 0.857032835483551\n",
      "Ep 80: Batch #69 - Loss: 0.7090848684310913\n",
      "Ep 80: Batch #70 - Loss: 0.7294948697090149\n",
      "Ep 80: Batch #71 - Loss: 0.6481332778930664\n",
      "Ep 80: Batch #72 - Loss: 0.8097413778305054\n",
      "Ep 80: Batch #73 - Loss: 0.8489183783531189\n",
      "Ep 80: Batch #74 - Loss: 0.6969044804573059\n",
      "Ep 80: Batch #75 - Loss: 0.7331124544143677\n",
      "Ep 80: Batch #76 - Loss: 1.0529366731643677\n",
      "Ep 80: Batch #77 - Loss: 0.6932255625724792\n",
      "Ep 80: Batch #78 - Loss: 1.097556710243225\n",
      "Ep 80: Batch #79 - Loss: 0.5942080616950989\n",
      "Ep 80: Batch #80 - Loss: 0.8098752498626709\n",
      "Ep 80: Batch #81 - Loss: 1.6359599828720093\n",
      "Ep 80: Batch #82 - Loss: 0.8328586220741272\n",
      "Ep 80: Batch #83 - Loss: 1.7022336721420288\n",
      "Ep 80: Batch #84 - Loss: 0.676501989364624\n",
      "Ep 80: Batch #85 - Loss: 0.9338592886924744\n",
      "Ep 80: Batch #86 - Loss: 0.6667898893356323\n",
      "Ep 80: Batch #87 - Loss: 0.6763098835945129\n",
      "Ep 80: Batch #88 - Loss: 0.7589167356491089\n",
      "Ep 80: Batch #89 - Loss: 0.8557601571083069\n",
      "Ep 80: Batch #90 - Loss: 1.0945268869400024\n",
      "Ep 80: Batch #91 - Loss: 0.7556954622268677\n",
      "Ep 80: Batch #92 - Loss: 0.9773188829421997\n",
      "Ep 80: Batch #93 - Loss: 0.9659901261329651\n",
      "Ep 80: Batch #94 - Loss: 0.9948186874389648\n",
      "Ep 80: Batch #95 - Loss: 0.8763306736946106\n",
      "Ep 80: Batch #96 - Loss: 0.8615202903747559\n",
      "Ep 80: Batch #97 - Loss: 0.6900262832641602\n",
      "Ep 80: Batch #98 - Loss: 0.7000019550323486\n",
      "Ep 80: Batch #99 - Loss: 0.9123367667198181\n",
      "Ep 80: Batch #100 - Loss: 0.6411307454109192\n",
      "Ep 80: Batch #101 - Loss: 1.0041271448135376\n",
      "Ep 80: Batch #102 - Loss: 0.7417464852333069\n",
      "Ep 80: Batch #103 - Loss: 0.7505261898040771\n",
      "Ep 80: Batch #104 - Loss: 0.7616478800773621\n",
      "Ep 80: Batch #105 - Loss: 0.9787598252296448\n",
      "Ep 80: Batch #106 - Loss: 0.7243127226829529\n",
      "Ep 80: Batch #107 - Loss: 0.718005359172821\n",
      "Ep 80: Batch #108 - Loss: 0.9846713542938232\n",
      "Ep 80: Batch #109 - Loss: 0.7248653173446655\n",
      "Ep 80: Batch #110 - Loss: 0.8656370639801025\n",
      "Ep 80: Batch #111 - Loss: 1.3196873664855957\n",
      "Ep 80: Batch #112 - Loss: 0.9935483932495117\n",
      "Ep 80: Batch #113 - Loss: 0.7761499881744385\n",
      "Ep 80: Batch #114 - Loss: 0.8530018925666809\n",
      "Ep 80: Batch #115 - Loss: 1.0436207056045532\n",
      "Ep 80: Batch #116 - Loss: 0.6077286005020142\n",
      "Ep 80: Batch #117 - Loss: 0.8328208327293396\n",
      "Ep 80: Batch #118 - Loss: 0.5144780278205872\n",
      "Model saved in file: ./weights_autoencoder_low_LR/model_e80b118_1516651279.5902348.ckpt\n",
      "Ep 80: Batch #119 - Loss: 0.9791195392608643\n",
      "Ep 80: Batch #120 - Loss: 0.7626147270202637\n",
      "Ep 80: Batch #121 - Loss: 0.6493780612945557\n",
      "Ep 80: Batch #122 - Loss: 0.7851960062980652\n",
      "Ep 80: Batch #123 - Loss: 0.7904685735702515\n",
      "Ep 80: Batch #124 - Loss: 0.6337467432022095\n",
      "Ep 80: Batch #125 - Loss: 2.6589231491088867\n",
      "Ep 80: Batch #126 - Loss: 1.1721370220184326\n",
      "Ep 80: Batch #127 - Loss: 0.7051013708114624\n",
      "Ep 80: Batch #128 - Loss: 1.0425891876220703\n",
      "Ep 80: Batch #129 - Loss: 0.7931714057922363\n",
      "Ep 80: Batch #130 - Loss: 0.6870418190956116\n",
      "Ep 80: Batch #131 - Loss: 0.9366415143013\n",
      "Ep 80: Batch #132 - Loss: 0.7807480096817017\n",
      "Ep 80: Batch #133 - Loss: 0.7736060619354248\n",
      "Ep 80: Batch #134 - Loss: 0.72784823179245\n",
      "Ep 80: Batch #135 - Loss: 0.9154808521270752\n",
      "Ep 80: Batch #136 - Loss: 1.125659465789795\n",
      "Ep 80: Batch #137 - Loss: 0.912073016166687\n",
      "Ep 80: Batch #138 - Loss: 1.0173753499984741\n",
      "Ep 80: Batch #139 - Loss: 0.8506030440330505\n",
      "Ep 80: Batch #140 - Loss: 1.0019748210906982\n",
      "Ep 80: Batch #141 - Loss: 1.3002722263336182\n",
      "Ep 80: Batch #142 - Loss: 0.7539606094360352\n",
      "Ep 80: Batch #143 - Loss: 0.9085310101509094\n",
      "Ep 80: Batch #144 - Loss: 0.6859989166259766\n",
      "Ep 80: Batch #145 - Loss: 0.6457064151763916\n",
      "Ep 80: Batch #146 - Loss: 0.845440149307251\n",
      "Ep 80: Batch #147 - Loss: 0.8115400671958923\n",
      "Ep 80: Batch #148 - Loss: 0.9225305318832397\n",
      "Ep 80: Batch #149 - Loss: 0.8070271611213684\n",
      "Ep 80: Batch #150 - Loss: 0.8418768644332886\n",
      "Ep 80: Batch #151 - Loss: 0.6985312104225159\n",
      "Ep 80: Batch #152 - Loss: 0.7100995182991028\n",
      "Ep 80: Batch #153 - Loss: 1.0481879711151123\n",
      "Ep 80: Batch #154 - Loss: 0.7241072058677673\n",
      "Ep 80: Batch #155 - Loss: 0.7925360798835754\n",
      "Ep 80: Batch #156 - Loss: 0.9706969857215881\n",
      "Ep 80: Batch #157 - Loss: 0.7205143570899963\n",
      "Ep 80: Batch #158 - Loss: 0.7754729986190796\n",
      "Ep 80: Batch #159 - Loss: 0.761914849281311\n",
      "Ep 80: Batch #160 - Loss: 0.8674647808074951\n",
      "Ep 80: Batch #161 - Loss: 0.7751181125640869\n",
      "Ep 80: Batch #162 - Loss: 0.8874632716178894\n",
      "Ep 80: Batch #163 - Loss: 0.8900638818740845\n",
      "Ep 80: Batch #164 - Loss: 0.7428609132766724\n",
      "Ep 80: Batch #165 - Loss: 1.457987666130066\n",
      "Ep 80: Batch #166 - Loss: 0.6418637633323669\n",
      "Ep 80: Batch #167 - Loss: 1.0365033149719238\n",
      "Ep 80: Batch #168 - Loss: 0.8139430284500122\n",
      "Ep 80: Batch #169 - Loss: 0.763642430305481\n",
      "Ep 80: Batch #170 - Loss: 0.763404130935669\n",
      "Ep 80: Batch #171 - Loss: 0.7346519231796265\n",
      "Ep 80: Batch #172 - Loss: 0.6066341400146484\n",
      "Ep 80: Batch #173 - Loss: 1.130800724029541\n",
      "Ep 80: Batch #174 - Loss: 0.5500683784484863\n",
      "Ep 80: Batch #175 - Loss: 0.7485910654067993\n",
      "Ep 80: Batch #176 - Loss: 1.0936315059661865\n",
      "Ep 80: Batch #177 - Loss: 0.8048390746116638\n",
      "Ep 80: Batch #178 - Loss: 0.7230144143104553\n",
      "Ep 80: Batch #179 - Loss: 0.8932852745056152\n",
      "Ep 80: Batch #180 - Loss: 0.8038983941078186\n",
      "Ep 80: Batch #181 - Loss: 0.9363738894462585\n",
      "Ep 80: Batch #182 - Loss: 0.731508731842041\n",
      "Ep 80: Batch #183 - Loss: 0.7286447882652283\n",
      "Ep 80: Batch #184 - Loss: 1.0263248682022095\n",
      "Ep 80: Batch #185 - Loss: 0.7196284532546997\n",
      "Ep 80: Batch #186 - Loss: 0.9106977581977844\n",
      "Ep 80: Batch #187 - Loss: 1.11024808883667\n",
      "Ep 80: Batch #188 - Loss: 1.3024699687957764\n",
      "Ep 80: Batch #189 - Loss: 0.6730663776397705\n",
      "Ep 80: Batch #190 - Loss: 0.7001286149024963\n",
      "Ep 80: Batch #191 - Loss: 1.0076981782913208\n",
      "Ep 80: Batch #192 - Loss: 0.6432003378868103\n",
      "Ep 80: Batch #193 - Loss: 0.7019849419593811\n",
      "Ep 80: Batch #194 - Loss: 0.6590555906295776\n",
      "Ep 80: Batch #195 - Loss: 0.9350942969322205\n",
      "Ep 80: Batch #196 - Loss: 0.8195450901985168\n",
      "Ep 80: Batch #197 - Loss: 0.8515605926513672\n",
      "Ep 80: Batch #198 - Loss: 0.6400502324104309\n",
      "Ep 80: Batch #199 - Loss: 0.8181840777397156\n",
      "Ep 81: Batch #0 - Loss: 0.7460474967956543\n",
      "Ep 81: Batch #1 - Loss: 0.8290684819221497\n",
      "Ep 81: Batch #2 - Loss: 0.971172571182251\n",
      "Ep 81: Batch #3 - Loss: 0.8250477313995361\n",
      "Ep 81: Batch #4 - Loss: 0.7461293339729309\n",
      "Ep 81: Batch #5 - Loss: 0.6353504061698914\n",
      "Ep 81: Batch #6 - Loss: 0.8367456793785095\n",
      "Ep 81: Batch #7 - Loss: 0.6677628755569458\n",
      "Ep 81: Batch #8 - Loss: 0.6970230340957642\n",
      "Ep 81: Batch #9 - Loss: 1.3325613737106323\n",
      "Ep 81: Batch #10 - Loss: 0.9615243077278137\n",
      "Ep 81: Batch #11 - Loss: 0.6373572945594788\n",
      "Ep 81: Batch #12 - Loss: 1.5073115825653076\n",
      "Ep 81: Batch #13 - Loss: 0.6214141845703125\n",
      "Ep 81: Batch #14 - Loss: 0.6939511299133301\n",
      "Ep 81: Batch #15 - Loss: 1.1791316270828247\n",
      "Ep 81: Batch #16 - Loss: 1.2086119651794434\n",
      "Ep 81: Batch #17 - Loss: 0.8349928855895996\n",
      "Ep 81: Batch #18 - Loss: 0.9124763607978821\n",
      "Ep 81: Batch #19 - Loss: 0.6396021246910095\n",
      "Ep 81: Batch #20 - Loss: 0.6210311651229858\n",
      "Ep 81: Batch #21 - Loss: 1.1690187454223633\n",
      "Ep 81: Batch #22 - Loss: 0.6931143403053284\n",
      "Ep 81: Batch #23 - Loss: 0.7028159499168396\n",
      "Ep 81: Batch #24 - Loss: 0.7897768020629883\n",
      "Ep 81: Batch #25 - Loss: 0.6775984168052673\n",
      "Ep 81: Batch #26 - Loss: 0.6891028881072998\n",
      "Ep 81: Batch #27 - Loss: 1.2891346216201782\n",
      "Ep 81: Batch #28 - Loss: 0.8312161564826965\n",
      "Ep 81: Batch #29 - Loss: 0.8437046408653259\n",
      "Ep 81: Batch #30 - Loss: 1.1502976417541504\n",
      "Ep 81: Batch #31 - Loss: 0.6415334939956665\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 81: Batch #32 - Loss: 0.7068964242935181\n",
      "Ep 81: Batch #33 - Loss: 0.7700923085212708\n",
      "Ep 81: Batch #34 - Loss: 0.7449309825897217\n",
      "Ep 81: Batch #35 - Loss: 0.8956553936004639\n",
      "Ep 81: Batch #36 - Loss: 0.6642109751701355\n",
      "Ep 81: Batch #37 - Loss: 1.0974702835083008\n",
      "Ep 81: Batch #38 - Loss: 0.700313150882721\n",
      "Ep 81: Batch #39 - Loss: 0.7845953702926636\n",
      "Ep 81: Batch #40 - Loss: 0.7354755997657776\n",
      "Ep 81: Batch #41 - Loss: 0.6925223469734192\n",
      "Ep 81: Batch #42 - Loss: 0.6853036880493164\n",
      "Ep 81: Batch #43 - Loss: 0.7500031590461731\n",
      "Ep 81: Batch #44 - Loss: 0.7400017380714417\n",
      "Ep 81: Batch #45 - Loss: 0.5977271199226379\n",
      "Ep 81: Batch #46 - Loss: 0.7824651002883911\n",
      "Ep 81: Batch #47 - Loss: 0.9011585116386414\n",
      "Ep 81: Batch #48 - Loss: 1.30199134349823\n",
      "Ep 81: Batch #49 - Loss: 0.9558284282684326\n",
      "Ep 81: Batch #50 - Loss: 0.6762815117835999\n",
      "Ep 81: Batch #51 - Loss: 0.9350559711456299\n",
      "Ep 81: Batch #52 - Loss: 0.7573815584182739\n",
      "Ep 81: Batch #53 - Loss: 0.7792415022850037\n",
      "Ep 81: Batch #54 - Loss: 0.6694086194038391\n",
      "Ep 81: Batch #55 - Loss: 0.7119895219802856\n",
      "Ep 81: Batch #56 - Loss: 1.1964693069458008\n",
      "Ep 81: Batch #57 - Loss: 0.7978904843330383\n",
      "Ep 81: Batch #58 - Loss: 0.9401759505271912\n",
      "Ep 81: Batch #59 - Loss: 0.6517775654792786\n",
      "Ep 81: Batch #60 - Loss: 1.2522205114364624\n",
      "Ep 81: Batch #61 - Loss: 0.6059582233428955\n",
      "Ep 81: Batch #62 - Loss: 0.6833280324935913\n",
      "Ep 81: Batch #63 - Loss: 0.9516491889953613\n",
      "Ep 81: Batch #64 - Loss: 9.37054443359375\n",
      "Ep 81: Batch #65 - Loss: 0.5812168717384338\n",
      "Ep 81: Batch #66 - Loss: 0.7518367171287537\n",
      "Ep 81: Batch #67 - Loss: 0.8672143816947937\n",
      "Ep 81: Batch #68 - Loss: 0.8557087779045105\n",
      "Ep 81: Batch #69 - Loss: 0.7082029581069946\n",
      "Ep 81: Batch #70 - Loss: 0.7283006310462952\n",
      "Ep 81: Batch #71 - Loss: 0.6472859382629395\n",
      "Ep 81: Batch #72 - Loss: 0.8085502982139587\n",
      "Ep 81: Batch #73 - Loss: 0.8475912809371948\n",
      "Ep 81: Batch #74 - Loss: 0.695797324180603\n",
      "Ep 81: Batch #75 - Loss: 0.7322758436203003\n",
      "Ep 81: Batch #76 - Loss: 1.0517358779907227\n",
      "Ep 81: Batch #77 - Loss: 0.6921768188476562\n",
      "Ep 81: Batch #78 - Loss: 1.0959606170654297\n",
      "Ep 81: Batch #79 - Loss: 0.5934479832649231\n",
      "Ep 81: Batch #80 - Loss: 0.8085871934890747\n",
      "Ep 81: Batch #81 - Loss: 1.634896993637085\n",
      "Ep 81: Batch #82 - Loss: 0.8318551778793335\n",
      "Ep 81: Batch #83 - Loss: 1.7014349699020386\n",
      "Ep 81: Batch #84 - Loss: 0.675604522228241\n",
      "Ep 81: Batch #85 - Loss: 0.9327879548072815\n",
      "Ep 81: Batch #86 - Loss: 0.6657573580741882\n",
      "Ep 81: Batch #87 - Loss: 0.6754255890846252\n",
      "Ep 81: Batch #88 - Loss: 0.7578900456428528\n",
      "Ep 81: Batch #89 - Loss: 0.8550319075584412\n",
      "Ep 81: Batch #90 - Loss: 1.0930684804916382\n",
      "Ep 81: Batch #91 - Loss: 0.7545690536499023\n",
      "Ep 81: Batch #92 - Loss: 0.9760146737098694\n",
      "Ep 81: Batch #93 - Loss: 0.964285671710968\n",
      "Ep 81: Batch #94 - Loss: 0.9934075474739075\n",
      "Ep 81: Batch #95 - Loss: 0.8752710223197937\n",
      "Ep 81: Batch #96 - Loss: 0.8604219555854797\n",
      "Ep 81: Batch #97 - Loss: 0.6890618801116943\n",
      "Ep 81: Batch #98 - Loss: 0.6990435123443604\n",
      "Ep 81: Batch #99 - Loss: 0.9112048745155334\n",
      "Ep 81: Batch #100 - Loss: 0.6402336955070496\n",
      "Ep 81: Batch #101 - Loss: 1.0031001567840576\n",
      "Ep 81: Batch #102 - Loss: 0.7407057285308838\n",
      "Ep 81: Batch #103 - Loss: 0.7495359778404236\n",
      "Ep 81: Batch #104 - Loss: 0.760657787322998\n",
      "Ep 81: Batch #105 - Loss: 0.9776356220245361\n",
      "Ep 81: Batch #106 - Loss: 0.7234737277030945\n",
      "Ep 81: Batch #107 - Loss: 0.7170104384422302\n",
      "Ep 81: Batch #108 - Loss: 0.9835246801376343\n",
      "Ep 81: Batch #109 - Loss: 0.7238938212394714\n",
      "Ep 81: Batch #110 - Loss: 0.8643433451652527\n",
      "Ep 81: Batch #111 - Loss: 1.318163275718689\n",
      "Ep 81: Batch #112 - Loss: 0.9921709895133972\n",
      "Ep 81: Batch #113 - Loss: 0.7751691937446594\n",
      "Ep 81: Batch #114 - Loss: 0.8517279028892517\n",
      "Ep 81: Batch #115 - Loss: 1.0424021482467651\n",
      "Ep 81: Batch #116 - Loss: 0.6070677638053894\n",
      "Ep 81: Batch #117 - Loss: 0.8318362236022949\n",
      "Ep 81: Batch #118 - Loss: 0.5137702226638794\n",
      "Model saved in file: ./weights_autoencoder_low_LR/model_e81b118_1516651279.7252529.ckpt\n",
      "Ep 81: Batch #119 - Loss: 0.9778155088424683\n",
      "Ep 81: Batch #120 - Loss: 0.7616752982139587\n",
      "Ep 81: Batch #121 - Loss: 0.6484665870666504\n",
      "Ep 81: Batch #122 - Loss: 0.7841815948486328\n",
      "Ep 81: Batch #123 - Loss: 0.7894638180732727\n",
      "Ep 81: Batch #124 - Loss: 0.6329886317253113\n",
      "Ep 81: Batch #125 - Loss: 2.657423973083496\n",
      "Ep 81: Batch #126 - Loss: 1.17081880569458\n",
      "Ep 81: Batch #127 - Loss: 0.7039636373519897\n",
      "Ep 81: Batch #128 - Loss: 1.0410046577453613\n",
      "Ep 81: Batch #129 - Loss: 0.792025089263916\n",
      "Ep 81: Batch #130 - Loss: 0.6861405372619629\n",
      "Ep 81: Batch #131 - Loss: 0.935147762298584\n",
      "Ep 81: Batch #132 - Loss: 0.7797456383705139\n",
      "Ep 81: Batch #133 - Loss: 0.7724646329879761\n",
      "Ep 81: Batch #134 - Loss: 0.7269181609153748\n",
      "Ep 81: Batch #135 - Loss: 0.9143078923225403\n",
      "Ep 81: Batch #136 - Loss: 1.1243318319320679\n",
      "Ep 81: Batch #137 - Loss: 0.9107373952865601\n",
      "Ep 81: Batch #138 - Loss: 1.0159519910812378\n",
      "Ep 81: Batch #139 - Loss: 0.8493139743804932\n",
      "Ep 81: Batch #140 - Loss: 1.0008518695831299\n",
      "Ep 81: Batch #141 - Loss: 1.2988306283950806\n",
      "Ep 81: Batch #142 - Loss: 0.7529141902923584\n",
      "Ep 81: Batch #143 - Loss: 0.9071351885795593\n",
      "Ep 81: Batch #144 - Loss: 0.6851852536201477\n",
      "Ep 81: Batch #145 - Loss: 0.6449241638183594\n",
      "Ep 81: Batch #146 - Loss: 0.8445430397987366\n",
      "Ep 81: Batch #147 - Loss: 0.8103799223899841\n",
      "Ep 81: Batch #148 - Loss: 0.9211771488189697\n",
      "Ep 81: Batch #149 - Loss: 0.805907130241394\n",
      "Ep 81: Batch #150 - Loss: 0.8409620523452759\n",
      "Ep 81: Batch #151 - Loss: 0.6978231072425842\n",
      "Ep 81: Batch #152 - Loss: 0.7094206809997559\n",
      "Ep 81: Batch #153 - Loss: 1.0467358827590942\n",
      "Ep 81: Batch #154 - Loss: 0.7231733798980713\n",
      "Ep 81: Batch #155 - Loss: 0.7915310859680176\n",
      "Ep 81: Batch #156 - Loss: 0.9695302844047546\n",
      "Ep 81: Batch #157 - Loss: 0.7194490432739258\n",
      "Ep 81: Batch #158 - Loss: 0.7747478485107422\n",
      "Ep 81: Batch #159 - Loss: 0.7607472538948059\n",
      "Ep 81: Batch #160 - Loss: 0.8665600419044495\n",
      "Ep 81: Batch #161 - Loss: 0.7741532921791077\n",
      "Ep 81: Batch #162 - Loss: 0.8862996101379395\n",
      "Ep 81: Batch #163 - Loss: 0.8889790177345276\n",
      "Ep 81: Batch #164 - Loss: 0.7417911291122437\n",
      "Ep 81: Batch #165 - Loss: 1.456985592842102\n",
      "Ep 81: Batch #166 - Loss: 0.6409232020378113\n",
      "Ep 81: Batch #167 - Loss: 1.0352267026901245\n",
      "Ep 81: Batch #168 - Loss: 0.812770664691925\n",
      "Ep 81: Batch #169 - Loss: 0.7627437710762024\n",
      "Ep 81: Batch #170 - Loss: 0.762382984161377\n",
      "Ep 81: Batch #171 - Loss: 0.7334837913513184\n",
      "Ep 81: Batch #172 - Loss: 0.6060240268707275\n",
      "Ep 81: Batch #173 - Loss: 1.1291542053222656\n",
      "Ep 81: Batch #174 - Loss: 0.5493496060371399\n",
      "Ep 81: Batch #175 - Loss: 0.7478688955307007\n",
      "Ep 81: Batch #176 - Loss: 1.0921711921691895\n",
      "Ep 81: Batch #177 - Loss: 0.8037596344947815\n",
      "Ep 81: Batch #178 - Loss: 0.7219905853271484\n",
      "Ep 81: Batch #179 - Loss: 0.8921388983726501\n",
      "Ep 81: Batch #180 - Loss: 0.8026108145713806\n",
      "Ep 81: Batch #181 - Loss: 0.9350087642669678\n",
      "Ep 81: Batch #182 - Loss: 0.7306168079376221\n",
      "Ep 81: Batch #183 - Loss: 0.7278213500976562\n",
      "Ep 81: Batch #184 - Loss: 1.0252189636230469\n",
      "Ep 81: Batch #185 - Loss: 0.7186769843101501\n",
      "Ep 81: Batch #186 - Loss: 0.9092612266540527\n",
      "Ep 81: Batch #187 - Loss: 1.1087863445281982\n",
      "Ep 81: Batch #188 - Loss: 1.3011153936386108\n",
      "Ep 81: Batch #189 - Loss: 0.6723941564559937\n",
      "Ep 81: Batch #190 - Loss: 0.6992518305778503\n",
      "Ep 81: Batch #191 - Loss: 1.0061960220336914\n",
      "Ep 81: Batch #192 - Loss: 0.6425809860229492\n",
      "Ep 81: Batch #193 - Loss: 0.7010946869850159\n",
      "Ep 81: Batch #194 - Loss: 0.658150315284729\n",
      "Ep 81: Batch #195 - Loss: 0.9338792562484741\n",
      "Ep 81: Batch #196 - Loss: 0.8183655738830566\n",
      "Ep 81: Batch #197 - Loss: 0.8502600789070129\n",
      "Ep 81: Batch #198 - Loss: 0.639133870601654\n",
      "Ep 81: Batch #199 - Loss: 0.8170397281646729\n",
      "Ep 82: Batch #0 - Loss: 0.7449324131011963\n",
      "Ep 82: Batch #1 - Loss: 0.8279018998146057\n",
      "Ep 82: Batch #2 - Loss: 0.9703418016433716\n",
      "Ep 82: Batch #3 - Loss: 0.8240221738815308\n",
      "Ep 82: Batch #4 - Loss: 0.7450772523880005\n",
      "Ep 82: Batch #5 - Loss: 0.6345712542533875\n",
      "Ep 82: Batch #6 - Loss: 0.8357277512550354\n",
      "Ep 82: Batch #7 - Loss: 0.6669449210166931\n",
      "Ep 82: Batch #8 - Loss: 0.6960755586624146\n",
      "Ep 82: Batch #9 - Loss: 1.3307503461837769\n",
      "Ep 82: Batch #10 - Loss: 0.9603636264801025\n",
      "Ep 82: Batch #11 - Loss: 0.6365041136741638\n",
      "Ep 82: Batch #12 - Loss: 1.5060255527496338\n",
      "Ep 82: Batch #13 - Loss: 0.6207391619682312\n",
      "Ep 82: Batch #14 - Loss: 0.6931436061859131\n",
      "Ep 82: Batch #15 - Loss: 1.1776540279388428\n",
      "Ep 82: Batch #16 - Loss: 1.206861972808838\n",
      "Ep 82: Batch #17 - Loss: 0.83387291431427\n",
      "Ep 82: Batch #18 - Loss: 0.9117396473884583\n",
      "Ep 82: Batch #19 - Loss: 0.6389360427856445\n",
      "Ep 82: Batch #20 - Loss: 0.620220959186554\n",
      "Ep 82: Batch #21 - Loss: 1.167946219444275\n",
      "Ep 82: Batch #22 - Loss: 0.6922629475593567\n",
      "Ep 82: Batch #23 - Loss: 0.7017819285392761\n",
      "Ep 82: Batch #24 - Loss: 0.7889121770858765\n",
      "Ep 82: Batch #25 - Loss: 0.676726222038269\n",
      "Ep 82: Batch #26 - Loss: 0.688145637512207\n",
      "Ep 82: Batch #27 - Loss: 1.2875055074691772\n",
      "Ep 82: Batch #28 - Loss: 0.8303192853927612\n",
      "Ep 82: Batch #29 - Loss: 0.8425197601318359\n",
      "Ep 82: Batch #30 - Loss: 1.1489516496658325\n",
      "Ep 82: Batch #31 - Loss: 0.6407665014266968\n",
      "Ep 82: Batch #32 - Loss: 0.7059272527694702\n",
      "Ep 82: Batch #33 - Loss: 0.7691939473152161\n",
      "Ep 82: Batch #34 - Loss: 0.7439737319946289\n",
      "Ep 82: Batch #35 - Loss: 0.8944061994552612\n",
      "Ep 82: Batch #36 - Loss: 0.6632915139198303\n",
      "Ep 82: Batch #37 - Loss: 1.09647536277771\n",
      "Ep 82: Batch #38 - Loss: 0.6991815567016602\n",
      "Ep 82: Batch #39 - Loss: 0.783692479133606\n",
      "Ep 82: Batch #40 - Loss: 0.7345573306083679\n",
      "Ep 82: Batch #41 - Loss: 0.6914778351783752\n",
      "Ep 82: Batch #42 - Loss: 0.6844266653060913\n",
      "Ep 82: Batch #43 - Loss: 0.7490866780281067\n",
      "Ep 82: Batch #44 - Loss: 0.7388702034950256\n",
      "Ep 82: Batch #45 - Loss: 0.5969433188438416\n",
      "Ep 82: Batch #46 - Loss: 0.7812944054603577\n",
      "Ep 82: Batch #47 - Loss: 0.8996310830116272\n",
      "Ep 82: Batch #48 - Loss: 1.3005924224853516\n",
      "Ep 82: Batch #49 - Loss: 0.9544357061386108\n",
      "Ep 82: Batch #50 - Loss: 0.6755408644676208\n",
      "Ep 82: Batch #51 - Loss: 0.9335728287696838\n",
      "Ep 82: Batch #52 - Loss: 0.756463885307312\n",
      "Ep 82: Batch #53 - Loss: 0.7781569957733154\n",
      "Ep 82: Batch #54 - Loss: 0.6684846878051758\n",
      "Ep 82: Batch #55 - Loss: 0.7110255360603333\n",
      "Ep 82: Batch #56 - Loss: 1.1947978734970093\n",
      "Ep 82: Batch #57 - Loss: 0.7965985536575317\n",
      "Ep 82: Batch #58 - Loss: 0.9387606382369995\n",
      "Ep 82: Batch #59 - Loss: 0.6510618925094604\n",
      "Ep 82: Batch #60 - Loss: 1.250709891319275\n",
      "Ep 82: Batch #61 - Loss: 0.6052581071853638\n",
      "Ep 82: Batch #62 - Loss: 0.6824718713760376\n",
      "Ep 82: Batch #63 - Loss: 0.9504147171974182\n",
      "Ep 82: Batch #64 - Loss: 9.367234230041504\n",
      "Ep 82: Batch #65 - Loss: 0.5804592370986938\n",
      "Ep 82: Batch #66 - Loss: 0.7507647275924683\n",
      "Ep 82: Batch #67 - Loss: 0.8662465214729309\n",
      "Ep 82: Batch #68 - Loss: 0.8543931245803833\n",
      "Ep 82: Batch #69 - Loss: 0.7073271870613098\n",
      "Ep 82: Batch #70 - Loss: 0.7271019816398621\n",
      "Ep 82: Batch #71 - Loss: 0.646443247795105\n",
      "Ep 82: Batch #72 - Loss: 0.807373046875\n",
      "Ep 82: Batch #73 - Loss: 0.8462746739387512\n",
      "Ep 82: Batch #74 - Loss: 0.6946973204612732\n",
      "Ep 82: Batch #75 - Loss: 0.7314518690109253\n",
      "Ep 82: Batch #76 - Loss: 1.050549030303955\n",
      "Ep 82: Batch #77 - Loss: 0.691135585308075\n",
      "Ep 82: Batch #78 - Loss: 1.0943762063980103\n",
      "Ep 82: Batch #79 - Loss: 0.5926892757415771\n",
      "Ep 82: Batch #80 - Loss: 0.8073076605796814\n",
      "Ep 82: Batch #81 - Loss: 1.6338467597961426\n",
      "Ep 82: Batch #82 - Loss: 0.8308656215667725\n",
      "Ep 82: Batch #83 - Loss: 1.7006429433822632\n",
      "Ep 82: Batch #84 - Loss: 0.674718976020813\n",
      "Ep 82: Batch #85 - Loss: 0.9317217469215393\n",
      "Ep 82: Batch #86 - Loss: 0.664734959602356\n",
      "Ep 82: Batch #87 - Loss: 0.6745498180389404\n",
      "Ep 82: Batch #88 - Loss: 0.7568773627281189\n",
      "Ep 82: Batch #89 - Loss: 0.8543125987052917\n",
      "Ep 82: Batch #90 - Loss: 1.0916316509246826\n",
      "Ep 82: Batch #91 - Loss: 0.7534562945365906\n",
      "Ep 82: Batch #92 - Loss: 0.974724531173706\n",
      "Ep 82: Batch #93 - Loss: 0.9625890851020813\n",
      "Ep 82: Batch #94 - Loss: 0.9920008778572083\n",
      "Ep 82: Batch #95 - Loss: 0.8742215633392334\n",
      "Ep 82: Batch #96 - Loss: 0.8593359589576721\n",
      "Ep 82: Batch #97 - Loss: 0.6881060004234314\n",
      "Ep 82: Batch #98 - Loss: 0.6980926990509033\n",
      "Ep 82: Batch #99 - Loss: 0.9100819230079651\n",
      "Ep 82: Batch #100 - Loss: 0.6393466591835022\n",
      "Ep 82: Batch #101 - Loss: 1.0020843744277954\n",
      "Ep 82: Batch #102 - Loss: 0.7396678924560547\n",
      "Ep 82: Batch #103 - Loss: 0.7485581636428833\n",
      "Ep 82: Batch #104 - Loss: 0.7596763968467712\n",
      "Ep 82: Batch #105 - Loss: 0.9765235781669617\n",
      "Ep 82: Batch #106 - Loss: 0.7226393818855286\n",
      "Ep 82: Batch #107 - Loss: 0.7160247564315796\n",
      "Ep 82: Batch #108 - Loss: 0.9823943376541138\n",
      "Ep 82: Batch #109 - Loss: 0.7229295372962952\n",
      "Ep 82: Batch #110 - Loss: 0.8630549311637878\n",
      "Ep 82: Batch #111 - Loss: 1.3166512250900269\n",
      "Ep 82: Batch #112 - Loss: 0.9908077120780945\n",
      "Ep 82: Batch #113 - Loss: 0.7741948366165161\n",
      "Ep 82: Batch #114 - Loss: 0.8504611849784851\n",
      "Ep 82: Batch #115 - Loss: 1.0411911010742188\n",
      "Ep 82: Batch #116 - Loss: 0.6064153909683228\n",
      "Ep 82: Batch #117 - Loss: 0.8308642506599426\n",
      "Ep 82: Batch #118 - Loss: 0.5130676627159119\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved in file: ./weights_autoencoder_low_LR/model_e82b118_1516651279.8597925.ckpt\n",
      "Ep 82: Batch #119 - Loss: 0.9765207767486572\n",
      "Ep 82: Batch #120 - Loss: 0.7607399225234985\n",
      "Ep 82: Batch #121 - Loss: 0.6475636959075928\n",
      "Ep 82: Batch #122 - Loss: 0.7831761837005615\n",
      "Ep 82: Batch #123 - Loss: 0.7884688377380371\n",
      "Ep 82: Batch #124 - Loss: 0.6322400569915771\n",
      "Ep 82: Batch #125 - Loss: 2.6559324264526367\n",
      "Ep 82: Batch #126 - Loss: 1.1695196628570557\n",
      "Ep 82: Batch #127 - Loss: 0.7028318643569946\n",
      "Ep 82: Batch #128 - Loss: 1.039434790611267\n",
      "Ep 82: Batch #129 - Loss: 0.7908869385719299\n",
      "Ep 82: Batch #130 - Loss: 0.6852500438690186\n",
      "Ep 82: Batch #131 - Loss: 0.9336593747138977\n",
      "Ep 82: Batch #132 - Loss: 0.778753399848938\n",
      "Ep 82: Batch #133 - Loss: 0.7713297009468079\n",
      "Ep 82: Batch #134 - Loss: 0.7259942889213562\n",
      "Ep 82: Batch #135 - Loss: 0.9131428003311157\n",
      "Ep 82: Batch #136 - Loss: 1.1230156421661377\n",
      "Ep 82: Batch #137 - Loss: 0.9094175100326538\n",
      "Ep 82: Batch #138 - Loss: 1.0145289897918701\n",
      "Ep 82: Batch #139 - Loss: 0.8480350375175476\n",
      "Ep 82: Batch #140 - Loss: 0.9997371435165405\n",
      "Ep 82: Batch #141 - Loss: 1.297397494316101\n",
      "Ep 82: Batch #142 - Loss: 0.7518727779388428\n",
      "Ep 82: Batch #143 - Loss: 0.9057570099830627\n",
      "Ep 82: Batch #144 - Loss: 0.6843804121017456\n",
      "Ep 82: Batch #145 - Loss: 0.6441420316696167\n",
      "Ep 82: Batch #146 - Loss: 0.8436553478240967\n",
      "Ep 82: Batch #147 - Loss: 0.8092340230941772\n",
      "Ep 82: Batch #148 - Loss: 0.9198242425918579\n",
      "Ep 82: Batch #149 - Loss: 0.8048039078712463\n",
      "Ep 82: Batch #150 - Loss: 0.8400562405586243\n",
      "Ep 82: Batch #151 - Loss: 0.6971226334571838\n",
      "Ep 82: Batch #152 - Loss: 0.7087475657463074\n",
      "Ep 82: Batch #153 - Loss: 1.0452934503555298\n",
      "Ep 82: Batch #154 - Loss: 0.7222498655319214\n",
      "Ep 82: Batch #155 - Loss: 0.7905376553535461\n",
      "Ep 82: Batch #156 - Loss: 0.9683708548545837\n",
      "Ep 82: Batch #157 - Loss: 0.7183965444564819\n",
      "Ep 82: Batch #158 - Loss: 0.7740328311920166\n",
      "Ep 82: Batch #159 - Loss: 0.7595849633216858\n",
      "Ep 82: Batch #160 - Loss: 0.8656581044197083\n",
      "Ep 82: Batch #161 - Loss: 0.7731993198394775\n",
      "Ep 82: Batch #162 - Loss: 0.8851479887962341\n",
      "Ep 82: Batch #163 - Loss: 0.8879073858261108\n",
      "Ep 82: Batch #164 - Loss: 0.7407302260398865\n",
      "Ep 82: Batch #165 - Loss: 1.455992341041565\n",
      "Ep 82: Batch #166 - Loss: 0.6399937272071838\n",
      "Ep 82: Batch #167 - Loss: 1.033961534500122\n",
      "Ep 82: Batch #168 - Loss: 0.8116031289100647\n",
      "Ep 82: Batch #169 - Loss: 0.7618557810783386\n",
      "Ep 82: Batch #170 - Loss: 0.761368453502655\n",
      "Ep 82: Batch #171 - Loss: 0.7323243021965027\n",
      "Ep 82: Batch #172 - Loss: 0.6054242253303528\n",
      "Ep 82: Batch #173 - Loss: 1.1275266408920288\n",
      "Ep 82: Batch #174 - Loss: 0.5486363768577576\n",
      "Ep 82: Batch #175 - Loss: 0.7471551895141602\n",
      "Ep 82: Batch #176 - Loss: 1.0907275676727295\n",
      "Ep 82: Batch #177 - Loss: 0.8026894927024841\n",
      "Ep 82: Batch #178 - Loss: 0.7209841012954712\n",
      "Ep 82: Batch #179 - Loss: 0.8909860253334045\n",
      "Ep 82: Batch #180 - Loss: 0.8013352155685425\n",
      "Ep 82: Batch #181 - Loss: 0.9336584806442261\n",
      "Ep 82: Batch #182 - Loss: 0.7297330498695374\n",
      "Ep 82: Batch #183 - Loss: 0.7270061373710632\n",
      "Ep 82: Batch #184 - Loss: 1.0241236686706543\n",
      "Ep 82: Batch #185 - Loss: 0.7177386283874512\n",
      "Ep 82: Batch #186 - Loss: 0.9078314304351807\n",
      "Ep 82: Batch #187 - Loss: 1.1073411703109741\n",
      "Ep 82: Batch #188 - Loss: 1.2997757196426392\n",
      "Ep 82: Batch #189 - Loss: 0.6717259883880615\n",
      "Ep 82: Batch #190 - Loss: 0.6983845233917236\n",
      "Ep 82: Batch #191 - Loss: 1.0047065019607544\n",
      "Ep 82: Batch #192 - Loss: 0.6419618725776672\n",
      "Ep 82: Batch #193 - Loss: 0.700217068195343\n",
      "Ep 82: Batch #194 - Loss: 0.6572535634040833\n",
      "Ep 82: Batch #195 - Loss: 0.932682454586029\n",
      "Ep 82: Batch #196 - Loss: 0.8171979188919067\n",
      "Ep 82: Batch #197 - Loss: 0.8489674925804138\n",
      "Ep 82: Batch #198 - Loss: 0.6382256746292114\n",
      "Ep 82: Batch #199 - Loss: 0.815899670124054\n",
      "Ep 83: Batch #0 - Loss: 0.743829071521759\n",
      "Ep 83: Batch #1 - Loss: 0.826755940914154\n",
      "Ep 83: Batch #2 - Loss: 0.9695172309875488\n",
      "Ep 83: Batch #3 - Loss: 0.8230049014091492\n",
      "Ep 83: Batch #4 - Loss: 0.7440376281738281\n",
      "Ep 83: Batch #5 - Loss: 0.633800745010376\n",
      "Ep 83: Batch #6 - Loss: 0.8347152471542358\n",
      "Ep 83: Batch #7 - Loss: 0.666130542755127\n",
      "Ep 83: Batch #8 - Loss: 0.6951342821121216\n",
      "Ep 83: Batch #9 - Loss: 1.328936219215393\n",
      "Ep 83: Batch #10 - Loss: 0.9592098593711853\n",
      "Ep 83: Batch #11 - Loss: 0.6356534361839294\n",
      "Ep 83: Batch #12 - Loss: 1.5047476291656494\n",
      "Ep 83: Batch #13 - Loss: 0.6200686097145081\n",
      "Ep 83: Batch #14 - Loss: 0.6923457980155945\n",
      "Ep 83: Batch #15 - Loss: 1.176177740097046\n",
      "Ep 83: Batch #16 - Loss: 1.205121636390686\n",
      "Ep 83: Batch #17 - Loss: 0.8327609896659851\n",
      "Ep 83: Batch #18 - Loss: 0.9110074639320374\n",
      "Ep 83: Batch #19 - Loss: 0.6382720470428467\n",
      "Ep 83: Batch #20 - Loss: 0.6194126009941101\n",
      "Ep 83: Batch #21 - Loss: 1.166878342628479\n",
      "Ep 83: Batch #22 - Loss: 0.6914131045341492\n",
      "Ep 83: Batch #23 - Loss: 0.7007571458816528\n",
      "Ep 83: Batch #24 - Loss: 0.7880568504333496\n",
      "Ep 83: Batch #25 - Loss: 0.6758617162704468\n",
      "Ep 83: Batch #26 - Loss: 0.6871965527534485\n",
      "Ep 83: Batch #27 - Loss: 1.2858887910842896\n",
      "Ep 83: Batch #28 - Loss: 0.8294219970703125\n",
      "Ep 83: Batch #29 - Loss: 0.8413454294204712\n",
      "Ep 83: Batch #30 - Loss: 1.147612452507019\n",
      "Ep 83: Batch #31 - Loss: 0.640007495880127\n",
      "Ep 83: Batch #32 - Loss: 0.7049677968025208\n",
      "Ep 83: Batch #33 - Loss: 0.7683031558990479\n",
      "Ep 83: Batch #34 - Loss: 0.7430248856544495\n",
      "Ep 83: Batch #35 - Loss: 0.8931722640991211\n",
      "Ep 83: Batch #36 - Loss: 0.6623812317848206\n",
      "Ep 83: Batch #37 - Loss: 1.0954891443252563\n",
      "Ep 83: Batch #38 - Loss: 0.6980612277984619\n",
      "Ep 83: Batch #39 - Loss: 0.7827944159507751\n",
      "Ep 83: Batch #40 - Loss: 0.7336447834968567\n",
      "Ep 83: Batch #41 - Loss: 0.6904395818710327\n",
      "Ep 83: Batch #42 - Loss: 0.6835589408874512\n",
      "Ep 83: Batch #43 - Loss: 0.7481780648231506\n",
      "Ep 83: Batch #44 - Loss: 0.7377502918243408\n",
      "Ep 83: Batch #45 - Loss: 0.5961635112762451\n",
      "Ep 83: Batch #46 - Loss: 0.7801324129104614\n",
      "Ep 83: Batch #47 - Loss: 0.898115336894989\n",
      "Ep 83: Batch #48 - Loss: 1.2992032766342163\n",
      "Ep 83: Batch #49 - Loss: 0.9530507922172546\n",
      "Ep 83: Batch #50 - Loss: 0.6748046875\n",
      "Ep 83: Batch #51 - Loss: 0.9320939183235168\n",
      "Ep 83: Batch #52 - Loss: 0.755557119846344\n",
      "Ep 83: Batch #53 - Loss: 0.7770789265632629\n",
      "Ep 83: Batch #54 - Loss: 0.6675685048103333\n",
      "Ep 83: Batch #55 - Loss: 0.710060179233551\n",
      "Ep 83: Batch #56 - Loss: 1.1931411027908325\n",
      "Ep 83: Batch #57 - Loss: 0.7953212261199951\n",
      "Ep 83: Batch #58 - Loss: 0.937358558177948\n",
      "Ep 83: Batch #59 - Loss: 0.6503543257713318\n",
      "Ep 83: Batch #60 - Loss: 1.2492157220840454\n",
      "Ep 83: Batch #61 - Loss: 0.604560375213623\n",
      "Ep 83: Batch #62 - Loss: 0.6816294193267822\n",
      "Ep 83: Batch #63 - Loss: 0.9491896033287048\n",
      "Ep 83: Batch #64 - Loss: 9.364331245422363\n",
      "Ep 83: Batch #65 - Loss: 0.5797080397605896\n",
      "Ep 83: Batch #66 - Loss: 0.7497040629386902\n",
      "Ep 83: Batch #67 - Loss: 0.8652828931808472\n",
      "Ep 83: Batch #68 - Loss: 0.8530891537666321\n",
      "Ep 83: Batch #69 - Loss: 0.706459105014801\n",
      "Ep 83: Batch #70 - Loss: 0.7259074449539185\n",
      "Ep 83: Batch #71 - Loss: 0.6456020474433899\n",
      "Ep 83: Batch #72 - Loss: 0.8062117099761963\n",
      "Ep 83: Batch #73 - Loss: 0.8449705243110657\n",
      "Ep 83: Batch #74 - Loss: 0.693601131439209\n",
      "Ep 83: Batch #75 - Loss: 0.7306379079818726\n",
      "Ep 83: Batch #76 - Loss: 1.0493756532669067\n",
      "Ep 83: Batch #77 - Loss: 0.6901071071624756\n",
      "Ep 83: Batch #78 - Loss: 1.0928031206130981\n",
      "Ep 83: Batch #79 - Loss: 0.5919289588928223\n",
      "Ep 83: Batch #80 - Loss: 0.806037962436676\n",
      "Ep 83: Batch #81 - Loss: 1.6328133344650269\n",
      "Ep 83: Batch #82 - Loss: 0.8298810720443726\n",
      "Ep 83: Batch #83 - Loss: 1.6998594999313354\n",
      "Ep 83: Batch #84 - Loss: 0.6738438606262207\n",
      "Ep 83: Batch #85 - Loss: 0.9306650757789612\n",
      "Ep 83: Batch #86 - Loss: 0.6637240052223206\n",
      "Ep 83: Batch #87 - Loss: 0.6736753582954407\n",
      "Ep 83: Batch #88 - Loss: 0.7558757066726685\n",
      "Ep 83: Batch #89 - Loss: 0.853601336479187\n",
      "Ep 83: Batch #90 - Loss: 1.0902143716812134\n",
      "Ep 83: Batch #91 - Loss: 0.7523528933525085\n",
      "Ep 83: Batch #92 - Loss: 0.9734540581703186\n",
      "Ep 83: Batch #93 - Loss: 0.9608994722366333\n",
      "Ep 83: Batch #94 - Loss: 0.9905991554260254\n",
      "Ep 83: Batch #95 - Loss: 0.8731785416603088\n",
      "Ep 83: Batch #96 - Loss: 0.858256995677948\n",
      "Ep 83: Batch #97 - Loss: 0.6871615052223206\n",
      "Ep 83: Batch #98 - Loss: 0.6971518397331238\n",
      "Ep 83: Batch #99 - Loss: 0.9089682102203369\n",
      "Ep 83: Batch #100 - Loss: 0.6384680271148682\n",
      "Ep 83: Batch #101 - Loss: 1.0010786056518555\n",
      "Ep 83: Batch #102 - Loss: 0.7386300563812256\n",
      "Ep 83: Batch #103 - Loss: 0.7475899457931519\n",
      "Ep 83: Batch #104 - Loss: 0.758708655834198\n",
      "Ep 83: Batch #105 - Loss: 0.9754249453544617\n",
      "Ep 83: Batch #106 - Loss: 0.7218069434165955\n",
      "Ep 83: Batch #107 - Loss: 0.7150431871414185\n",
      "Ep 83: Batch #108 - Loss: 0.9812744855880737\n",
      "Ep 83: Batch #109 - Loss: 0.7219755053520203\n",
      "Ep 83: Batch #110 - Loss: 0.8617672920227051\n",
      "Ep 83: Batch #111 - Loss: 1.315151333808899\n",
      "Ep 83: Batch #112 - Loss: 0.9894575476646423\n",
      "Ep 83: Batch #113 - Loss: 0.7732179164886475\n",
      "Ep 83: Batch #114 - Loss: 0.8492091298103333\n",
      "Ep 83: Batch #115 - Loss: 1.039989709854126\n",
      "Ep 83: Batch #116 - Loss: 0.6057682633399963\n",
      "Ep 83: Batch #117 - Loss: 0.8298786878585815\n",
      "Ep 83: Batch #118 - Loss: 0.5123628377914429\n",
      "Model saved in file: ./weights_autoencoder_low_LR/model_e83b118_1516651279.9974656.ckpt\n",
      "Ep 83: Batch #119 - Loss: 0.9752352237701416\n",
      "Ep 83: Batch #120 - Loss: 0.7598075270652771\n",
      "Ep 83: Batch #121 - Loss: 0.6466666460037231\n",
      "Ep 83: Batch #122 - Loss: 0.7821796536445618\n",
      "Ep 83: Batch #123 - Loss: 0.7874820232391357\n",
      "Ep 83: Batch #124 - Loss: 0.6315006017684937\n",
      "Ep 83: Batch #125 - Loss: 2.6544604301452637\n",
      "Ep 83: Batch #126 - Loss: 1.1682325601577759\n",
      "Ep 83: Batch #127 - Loss: 0.7017045617103577\n",
      "Ep 83: Batch #128 - Loss: 1.0378742218017578\n",
      "Ep 83: Batch #129 - Loss: 0.7897583842277527\n",
      "Ep 83: Batch #130 - Loss: 0.684363603591919\n",
      "Ep 83: Batch #131 - Loss: 0.932174563407898\n",
      "Ep 83: Batch #132 - Loss: 0.7777687311172485\n",
      "Ep 83: Batch #133 - Loss: 0.7702065110206604\n",
      "Ep 83: Batch #134 - Loss: 0.7250764966011047\n",
      "Ep 83: Batch #135 - Loss: 0.9119882583618164\n",
      "Ep 83: Batch #136 - Loss: 1.1217100620269775\n",
      "Ep 83: Batch #137 - Loss: 0.9081094264984131\n",
      "Ep 83: Batch #138 - Loss: 1.0131086111068726\n",
      "Ep 83: Batch #139 - Loss: 0.8467645645141602\n",
      "Ep 83: Batch #140 - Loss: 0.9986381530761719\n",
      "Ep 83: Batch #141 - Loss: 1.2959691286087036\n",
      "Ep 83: Batch #142 - Loss: 0.7508370280265808\n",
      "Ep 83: Batch #143 - Loss: 0.9043893218040466\n",
      "Ep 83: Batch #144 - Loss: 0.6835826635360718\n",
      "Ep 83: Batch #145 - Loss: 0.6433645486831665\n",
      "Ep 83: Batch #146 - Loss: 0.8427813053131104\n",
      "Ep 83: Batch #147 - Loss: 0.8081045150756836\n",
      "Ep 83: Batch #148 - Loss: 0.9184828400611877\n",
      "Ep 83: Batch #149 - Loss: 0.8037106394767761\n",
      "Ep 83: Batch #150 - Loss: 0.8391618132591248\n",
      "Ep 83: Batch #151 - Loss: 0.6964284777641296\n",
      "Ep 83: Batch #152 - Loss: 0.7080712914466858\n",
      "Ep 83: Batch #153 - Loss: 1.0438603162765503\n",
      "Ep 83: Batch #154 - Loss: 0.7213372588157654\n",
      "Ep 83: Batch #155 - Loss: 0.7895412445068359\n",
      "Ep 83: Batch #156 - Loss: 0.9672167897224426\n",
      "Ep 83: Batch #157 - Loss: 0.7173562049865723\n",
      "Ep 83: Batch #158 - Loss: 0.7733272314071655\n",
      "Ep 83: Batch #159 - Loss: 0.7584221363067627\n",
      "Ep 83: Batch #160 - Loss: 0.8647757172584534\n",
      "Ep 83: Batch #161 - Loss: 0.7722519040107727\n",
      "Ep 83: Batch #162 - Loss: 0.8840070366859436\n",
      "Ep 83: Batch #163 - Loss: 0.886846125125885\n",
      "Ep 83: Batch #164 - Loss: 0.7396813631057739\n",
      "Ep 83: Batch #165 - Loss: 1.455011010169983\n",
      "Ep 83: Batch #166 - Loss: 0.6390742063522339\n",
      "Ep 83: Batch #167 - Loss: 1.0327047109603882\n",
      "Ep 83: Batch #168 - Loss: 0.8104416728019714\n",
      "Ep 83: Batch #169 - Loss: 0.7609797120094299\n",
      "Ep 83: Batch #170 - Loss: 0.7603548765182495\n",
      "Ep 83: Batch #171 - Loss: 0.7311745285987854\n",
      "Ep 83: Batch #172 - Loss: 0.6048260927200317\n",
      "Ep 83: Batch #173 - Loss: 1.1259187459945679\n",
      "Ep 83: Batch #174 - Loss: 0.5479331612586975\n",
      "Ep 83: Batch #175 - Loss: 0.7464467883110046\n",
      "Ep 83: Batch #176 - Loss: 1.0892980098724365\n",
      "Ep 83: Batch #177 - Loss: 0.8016207814216614\n",
      "Ep 83: Batch #178 - Loss: 0.7199895977973938\n",
      "Ep 83: Batch #179 - Loss: 0.8898427486419678\n",
      "Ep 83: Batch #180 - Loss: 0.8000699281692505\n",
      "Ep 83: Batch #181 - Loss: 0.9323243498802185\n",
      "Ep 83: Batch #182 - Loss: 0.7288587093353271\n",
      "Ep 83: Batch #183 - Loss: 0.7261965870857239\n",
      "Ep 83: Batch #184 - Loss: 1.0230379104614258\n",
      "Ep 83: Batch #185 - Loss: 0.7168033123016357\n",
      "Ep 83: Batch #186 - Loss: 0.9064067006111145\n",
      "Ep 83: Batch #187 - Loss: 1.105913758277893\n",
      "Ep 83: Batch #188 - Loss: 1.2984468936920166\n",
      "Ep 83: Batch #189 - Loss: 0.6710652112960815\n",
      "Ep 83: Batch #190 - Loss: 0.6975269317626953\n",
      "Ep 83: Batch #191 - Loss: 1.0032316446304321\n",
      "Ep 83: Batch #192 - Loss: 0.6413499116897583\n",
      "Ep 83: Batch #193 - Loss: 0.6993370652198792\n",
      "Ep 83: Batch #194 - Loss: 0.656366765499115\n",
      "Ep 83: Batch #195 - Loss: 0.9314969182014465\n",
      "Ep 83: Batch #196 - Loss: 0.8160326480865479\n",
      "Ep 83: Batch #197 - Loss: 0.8476874232292175\n",
      "Ep 83: Batch #198 - Loss: 0.6373217701911926\n",
      "Ep 83: Batch #199 - Loss: 0.8147642016410828\n",
      "Ep 84: Batch #0 - Loss: 0.7427447438240051\n",
      "Ep 84: Batch #1 - Loss: 0.8256301879882812\n",
      "Ep 84: Batch #2 - Loss: 0.9687029719352722\n",
      "Ep 84: Batch #3 - Loss: 0.8219980001449585\n",
      "Ep 84: Batch #4 - Loss: 0.7430040240287781\n",
      "Ep 84: Batch #5 - Loss: 0.6330384612083435\n",
      "Ep 84: Batch #6 - Loss: 0.8337066173553467\n",
      "Ep 84: Batch #7 - Loss: 0.6653257012367249\n",
      "Ep 84: Batch #8 - Loss: 0.6941991448402405\n",
      "Ep 84: Batch #9 - Loss: 1.3271209001541138\n",
      "Ep 84: Batch #10 - Loss: 0.9580612778663635\n",
      "Ep 84: Batch #11 - Loss: 0.6348059773445129\n",
      "Ep 84: Batch #12 - Loss: 1.5034762620925903\n",
      "Ep 84: Batch #13 - Loss: 0.6194012761116028\n",
      "Ep 84: Batch #14 - Loss: 0.6915579438209534\n",
      "Ep 84: Batch #15 - Loss: 1.1747024059295654\n",
      "Ep 84: Batch #16 - Loss: 1.203391194343567\n",
      "Ep 84: Batch #17 - Loss: 0.8316566944122314\n",
      "Ep 84: Batch #18 - Loss: 0.9102802872657776\n",
      "Ep 84: Batch #19 - Loss: 0.6376140117645264\n",
      "Ep 84: Batch #20 - Loss: 0.6186087727546692\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 84: Batch #21 - Loss: 1.165814757347107\n",
      "Ep 84: Batch #22 - Loss: 0.6905674934387207\n",
      "Ep 84: Batch #23 - Loss: 0.6997312903404236\n",
      "Ep 84: Batch #24 - Loss: 0.787212073802948\n",
      "Ep 84: Batch #25 - Loss: 0.6750058531761169\n",
      "Ep 84: Batch #26 - Loss: 0.6862438321113586\n",
      "Ep 84: Batch #27 - Loss: 1.2842923402786255\n",
      "Ep 84: Batch #28 - Loss: 0.8285253047943115\n",
      "Ep 84: Batch #29 - Loss: 0.840178906917572\n",
      "Ep 84: Batch #30 - Loss: 1.1462721824645996\n",
      "Ep 84: Batch #31 - Loss: 0.63925701379776\n",
      "Ep 84: Batch #32 - Loss: 0.7040165066719055\n",
      "Ep 84: Batch #33 - Loss: 0.767423152923584\n",
      "Ep 84: Batch #34 - Loss: 0.7420884966850281\n",
      "Ep 84: Batch #35 - Loss: 0.8919548392295837\n",
      "Ep 84: Batch #36 - Loss: 0.661475419998169\n",
      "Ep 84: Batch #37 - Loss: 1.0945132970809937\n",
      "Ep 84: Batch #38 - Loss: 0.6969509124755859\n",
      "Ep 84: Batch #39 - Loss: 0.7818975448608398\n",
      "Ep 84: Batch #40 - Loss: 0.7327376008033752\n",
      "Ep 84: Batch #41 - Loss: 0.6894046068191528\n",
      "Ep 84: Batch #42 - Loss: 0.6827024221420288\n",
      "Ep 84: Batch #43 - Loss: 0.7472835779190063\n",
      "Ep 84: Batch #44 - Loss: 0.7366398572921753\n",
      "Ep 84: Batch #45 - Loss: 0.5953915119171143\n",
      "Ep 84: Batch #46 - Loss: 0.7789725661277771\n",
      "Ep 84: Batch #47 - Loss: 0.896613359451294\n",
      "Ep 84: Batch #48 - Loss: 1.2978299856185913\n",
      "Ep 84: Batch #49 - Loss: 0.9516751170158386\n",
      "Ep 84: Batch #50 - Loss: 0.6740744709968567\n",
      "Ep 84: Batch #51 - Loss: 0.9306228756904602\n",
      "Ep 84: Batch #52 - Loss: 0.7546602487564087\n",
      "Ep 84: Batch #53 - Loss: 0.7760056257247925\n",
      "Ep 84: Batch #54 - Loss: 0.6666572690010071\n",
      "Ep 84: Batch #55 - Loss: 0.7091005444526672\n",
      "Ep 84: Batch #56 - Loss: 1.1914966106414795\n",
      "Ep 84: Batch #57 - Loss: 0.7940531969070435\n",
      "Ep 84: Batch #58 - Loss: 0.9359750151634216\n",
      "Ep 84: Batch #59 - Loss: 0.6496531367301941\n",
      "Ep 84: Batch #60 - Loss: 1.2477388381958008\n",
      "Ep 84: Batch #61 - Loss: 0.603870153427124\n",
      "Ep 84: Batch #62 - Loss: 0.6808003187179565\n",
      "Ep 84: Batch #63 - Loss: 0.9479668736457825\n",
      "Ep 84: Batch #64 - Loss: 9.36172866821289\n",
      "Ep 84: Batch #65 - Loss: 0.5789583325386047\n",
      "Ep 84: Batch #66 - Loss: 0.7486469745635986\n",
      "Ep 84: Batch #67 - Loss: 0.8643282055854797\n",
      "Ep 84: Batch #68 - Loss: 0.851783037185669\n",
      "Ep 84: Batch #69 - Loss: 0.7055782079696655\n",
      "Ep 84: Batch #70 - Loss: 0.7247189879417419\n",
      "Ep 84: Batch #71 - Loss: 0.6447619199752808\n",
      "Ep 84: Batch #72 - Loss: 0.8050615191459656\n",
      "Ep 84: Batch #73 - Loss: 0.8436808586120605\n",
      "Ep 84: Batch #74 - Loss: 0.692514955997467\n",
      "Ep 84: Batch #75 - Loss: 0.7298341393470764\n",
      "Ep 84: Batch #76 - Loss: 1.0482065677642822\n",
      "Ep 84: Batch #77 - Loss: 0.6890881061553955\n",
      "Ep 84: Batch #78 - Loss: 1.0912312269210815\n",
      "Ep 84: Batch #79 - Loss: 0.5911575555801392\n",
      "Ep 84: Batch #80 - Loss: 0.8047744631767273\n",
      "Ep 84: Batch #81 - Loss: 1.6317905187606812\n",
      "Ep 84: Batch #82 - Loss: 0.828905463218689\n",
      "Ep 84: Batch #83 - Loss: 1.699084997177124\n",
      "Ep 84: Batch #84 - Loss: 0.6729777455329895\n",
      "Ep 84: Batch #85 - Loss: 0.9296171069145203\n",
      "Ep 84: Batch #86 - Loss: 0.6627153158187866\n",
      "Ep 84: Batch #87 - Loss: 0.6728029847145081\n",
      "Ep 84: Batch #88 - Loss: 0.7548753023147583\n",
      "Ep 84: Batch #89 - Loss: 0.8528920412063599\n",
      "Ep 84: Batch #90 - Loss: 1.088812232017517\n",
      "Ep 84: Batch #91 - Loss: 0.7512591481208801\n",
      "Ep 84: Batch #92 - Loss: 0.9721919298171997\n",
      "Ep 84: Batch #93 - Loss: 0.9592143297195435\n",
      "Ep 84: Batch #94 - Loss: 0.9891999363899231\n",
      "Ep 84: Batch #95 - Loss: 0.872131884098053\n",
      "Ep 84: Batch #96 - Loss: 0.8571823239326477\n",
      "Ep 84: Batch #97 - Loss: 0.6862263679504395\n",
      "Ep 84: Batch #98 - Loss: 0.6962200999259949\n",
      "Ep 84: Batch #99 - Loss: 0.9078653454780579\n",
      "Ep 84: Batch #100 - Loss: 0.6375894546508789\n",
      "Ep 84: Batch #101 - Loss: 1.0000848770141602\n",
      "Ep 84: Batch #102 - Loss: 0.7376054525375366\n",
      "Ep 84: Batch #103 - Loss: 0.7466290593147278\n",
      "Ep 84: Batch #104 - Loss: 0.7577397227287292\n",
      "Ep 84: Batch #105 - Loss: 0.974328875541687\n",
      "Ep 84: Batch #106 - Loss: 0.720970869064331\n",
      "Ep 84: Batch #107 - Loss: 0.7140661478042603\n",
      "Ep 84: Batch #108 - Loss: 0.9801609516143799\n",
      "Ep 84: Batch #109 - Loss: 0.7210243940353394\n",
      "Ep 84: Batch #110 - Loss: 0.8604816794395447\n",
      "Ep 84: Batch #111 - Loss: 1.3136622905731201\n",
      "Ep 84: Batch #112 - Loss: 0.9881133437156677\n",
      "Ep 84: Batch #113 - Loss: 0.7722430229187012\n",
      "Ep 84: Batch #114 - Loss: 0.8479673266410828\n",
      "Ep 84: Batch #115 - Loss: 1.0387904644012451\n",
      "Ep 84: Batch #116 - Loss: 0.605125904083252\n",
      "Ep 84: Batch #117 - Loss: 0.8288981914520264\n",
      "Ep 84: Batch #118 - Loss: 0.511665403842926\n",
      "Model saved in file: ./weights_autoencoder_low_LR/model_e84b118_1516651280.1385088.ckpt\n",
      "Ep 84: Batch #119 - Loss: 0.9739582538604736\n",
      "Ep 84: Batch #120 - Loss: 0.7588794827461243\n",
      "Ep 84: Batch #121 - Loss: 0.645775318145752\n",
      "Ep 84: Batch #122 - Loss: 0.78119295835495\n",
      "Ep 84: Batch #123 - Loss: 0.7865018844604492\n",
      "Ep 84: Batch #124 - Loss: 0.6307680010795593\n",
      "Ep 84: Batch #125 - Loss: 2.6529977321624756\n",
      "Ep 84: Batch #126 - Loss: 1.1669570207595825\n",
      "Ep 84: Batch #127 - Loss: 0.7005736231803894\n",
      "Ep 84: Batch #128 - Loss: 1.0363205671310425\n",
      "Ep 84: Batch #129 - Loss: 0.7886354327201843\n",
      "Ep 84: Batch #130 - Loss: 0.6834800243377686\n",
      "Ep 84: Batch #131 - Loss: 0.9307013750076294\n",
      "Ep 84: Batch #132 - Loss: 0.776793897151947\n",
      "Ep 84: Batch #133 - Loss: 0.7690905928611755\n",
      "Ep 84: Batch #134 - Loss: 0.7241662740707397\n",
      "Ep 84: Batch #135 - Loss: 0.910831868648529\n",
      "Ep 84: Batch #136 - Loss: 1.120409369468689\n",
      "Ep 84: Batch #137 - Loss: 0.9068121314048767\n",
      "Ep 84: Batch #138 - Loss: 1.011688232421875\n",
      "Ep 84: Batch #139 - Loss: 0.8455060720443726\n",
      "Ep 84: Batch #140 - Loss: 0.9975501894950867\n",
      "Ep 84: Batch #141 - Loss: 1.2945444583892822\n",
      "Ep 84: Batch #142 - Loss: 0.7498008012771606\n",
      "Ep 84: Batch #143 - Loss: 0.9030317664146423\n",
      "Ep 84: Batch #144 - Loss: 0.6827970743179321\n",
      "Ep 84: Batch #145 - Loss: 0.6425923109054565\n",
      "Ep 84: Batch #146 - Loss: 0.8419259786605835\n",
      "Ep 84: Batch #147 - Loss: 0.8069868087768555\n",
      "Ep 84: Batch #148 - Loss: 0.9171488881111145\n",
      "Ep 84: Batch #149 - Loss: 0.802624523639679\n",
      "Ep 84: Batch #150 - Loss: 0.838279664516449\n",
      "Ep 84: Batch #151 - Loss: 0.6957381963729858\n",
      "Ep 84: Batch #152 - Loss: 0.7073967456817627\n",
      "Ep 84: Batch #153 - Loss: 1.0424320697784424\n",
      "Ep 84: Batch #154 - Loss: 0.7204291224479675\n",
      "Ep 84: Batch #155 - Loss: 0.7885448932647705\n",
      "Ep 84: Batch #156 - Loss: 0.9660750031471252\n",
      "Ep 84: Batch #157 - Loss: 0.7163223028182983\n",
      "Ep 84: Batch #158 - Loss: 0.7726381421089172\n",
      "Ep 84: Batch #159 - Loss: 0.7572659254074097\n",
      "Ep 84: Batch #160 - Loss: 0.8639033436775208\n",
      "Ep 84: Batch #161 - Loss: 0.7713156938552856\n",
      "Ep 84: Batch #162 - Loss: 0.8828713893890381\n",
      "Ep 84: Batch #163 - Loss: 0.8857895731925964\n",
      "Ep 84: Batch #164 - Loss: 0.7386411428451538\n",
      "Ep 84: Batch #165 - Loss: 1.454032301902771\n",
      "Ep 84: Batch #166 - Loss: 0.6381567120552063\n",
      "Ep 84: Batch #167 - Loss: 1.0314563512802124\n",
      "Ep 84: Batch #168 - Loss: 0.8092835545539856\n",
      "Ep 84: Batch #169 - Loss: 0.760114848613739\n",
      "Ep 84: Batch #170 - Loss: 0.7593441009521484\n",
      "Ep 84: Batch #171 - Loss: 0.7300459146499634\n",
      "Ep 84: Batch #172 - Loss: 0.6042367219924927\n",
      "Ep 84: Batch #173 - Loss: 1.1243174076080322\n",
      "Ep 84: Batch #174 - Loss: 0.5472383499145508\n",
      "Ep 84: Batch #175 - Loss: 0.7457408308982849\n",
      "Ep 84: Batch #176 - Loss: 1.0878738164901733\n",
      "Ep 84: Batch #177 - Loss: 0.8005605936050415\n",
      "Ep 84: Batch #178 - Loss: 0.7190023064613342\n",
      "Ep 84: Batch #179 - Loss: 0.8887091875076294\n",
      "Ep 84: Batch #180 - Loss: 0.7988065481185913\n",
      "Ep 84: Batch #181 - Loss: 0.931003987789154\n",
      "Ep 84: Batch #182 - Loss: 0.7279913425445557\n",
      "Ep 84: Batch #183 - Loss: 0.7253872156143188\n",
      "Ep 84: Batch #184 - Loss: 1.0219600200653076\n",
      "Ep 84: Batch #185 - Loss: 0.7158727645874023\n",
      "Ep 84: Batch #186 - Loss: 0.904990553855896\n",
      "Ep 84: Batch #187 - Loss: 1.1044950485229492\n",
      "Ep 84: Batch #188 - Loss: 1.2971280813217163\n",
      "Ep 84: Batch #189 - Loss: 0.6703993678092957\n",
      "Ep 84: Batch #190 - Loss: 0.6966614127159119\n",
      "Ep 84: Batch #191 - Loss: 1.001760482788086\n",
      "Ep 84: Batch #192 - Loss: 0.6407407522201538\n",
      "Ep 84: Batch #193 - Loss: 0.6984556317329407\n",
      "Ep 84: Batch #194 - Loss: 0.6554890871047974\n",
      "Ep 84: Batch #195 - Loss: 0.9303159713745117\n",
      "Ep 84: Batch #196 - Loss: 0.8148705959320068\n",
      "Ep 84: Batch #197 - Loss: 0.8464203476905823\n",
      "Ep 84: Batch #198 - Loss: 0.6364281177520752\n",
      "Ep 84: Batch #199 - Loss: 0.8136297464370728\n",
      "Ep 85: Batch #0 - Loss: 0.7416688799858093\n",
      "Ep 85: Batch #1 - Loss: 0.8245126008987427\n",
      "Ep 85: Batch #2 - Loss: 0.9678980112075806\n",
      "Ep 85: Batch #3 - Loss: 0.8209970593452454\n",
      "Ep 85: Batch #4 - Loss: 0.7419781684875488\n",
      "Ep 85: Batch #5 - Loss: 0.632281482219696\n",
      "Ep 85: Batch #6 - Loss: 0.8327046036720276\n",
      "Ep 85: Batch #7 - Loss: 0.6645238995552063\n",
      "Ep 85: Batch #8 - Loss: 0.6932713389396667\n",
      "Ep 85: Batch #9 - Loss: 1.3253154754638672\n",
      "Ep 85: Batch #10 - Loss: 0.9569129347801208\n",
      "Ep 85: Batch #11 - Loss: 0.6339593529701233\n",
      "Ep 85: Batch #12 - Loss: 1.5022168159484863\n",
      "Ep 85: Batch #13 - Loss: 0.6187318563461304\n",
      "Ep 85: Batch #14 - Loss: 0.6907749772071838\n",
      "Ep 85: Batch #15 - Loss: 1.1732287406921387\n",
      "Ep 85: Batch #16 - Loss: 1.2016685009002686\n",
      "Ep 85: Batch #17 - Loss: 0.8305581212043762\n",
      "Ep 85: Batch #18 - Loss: 0.909553587436676\n",
      "Ep 85: Batch #19 - Loss: 0.6369614005088806\n",
      "Ep 85: Batch #20 - Loss: 0.6178118586540222\n",
      "Ep 85: Batch #21 - Loss: 1.1647462844848633\n",
      "Ep 85: Batch #22 - Loss: 0.6897292137145996\n",
      "Ep 85: Batch #23 - Loss: 0.6987089514732361\n",
      "Ep 85: Batch #24 - Loss: 0.7863715887069702\n",
      "Ep 85: Batch #25 - Loss: 0.6741573214530945\n",
      "Ep 85: Batch #26 - Loss: 0.6852895021438599\n",
      "Ep 85: Batch #27 - Loss: 1.2827069759368896\n",
      "Ep 85: Batch #28 - Loss: 0.8276360630989075\n",
      "Ep 85: Batch #29 - Loss: 0.8390196561813354\n",
      "Ep 85: Batch #30 - Loss: 1.1449331045150757\n",
      "Ep 85: Batch #31 - Loss: 0.638518750667572\n",
      "Ep 85: Batch #32 - Loss: 0.7030699253082275\n",
      "Ep 85: Batch #33 - Loss: 0.7665520906448364\n",
      "Ep 85: Batch #34 - Loss: 0.741155207157135\n",
      "Ep 85: Batch #35 - Loss: 0.8907474875450134\n",
      "Ep 85: Batch #36 - Loss: 0.6605727672576904\n",
      "Ep 85: Batch #37 - Loss: 1.093546986579895\n",
      "Ep 85: Batch #38 - Loss: 0.6958459615707397\n",
      "Ep 85: Batch #39 - Loss: 0.7809996604919434\n",
      "Ep 85: Batch #40 - Loss: 0.7318441271781921\n",
      "Ep 85: Batch #41 - Loss: 0.6883740425109863\n",
      "Ep 85: Batch #42 - Loss: 0.6818607449531555\n",
      "Ep 85: Batch #43 - Loss: 0.7463945746421814\n",
      "Ep 85: Batch #44 - Loss: 0.7355319261550903\n",
      "Ep 85: Batch #45 - Loss: 0.5946218371391296\n",
      "Ep 85: Batch #46 - Loss: 0.7778187990188599\n",
      "Ep 85: Batch #47 - Loss: 0.895126223564148\n",
      "Ep 85: Batch #48 - Loss: 1.2964729070663452\n",
      "Ep 85: Batch #49 - Loss: 0.9503079056739807\n",
      "Ep 85: Batch #50 - Loss: 0.6733506321907043\n",
      "Ep 85: Batch #51 - Loss: 0.9291620254516602\n",
      "Ep 85: Batch #52 - Loss: 0.7537724375724792\n",
      "Ep 85: Batch #53 - Loss: 0.7749080061912537\n",
      "Ep 85: Batch #54 - Loss: 0.6657511591911316\n",
      "Ep 85: Batch #55 - Loss: 0.7081503868103027\n",
      "Ep 85: Batch #56 - Loss: 1.189859390258789\n",
      "Ep 85: Batch #57 - Loss: 0.79278963804245\n",
      "Ep 85: Batch #58 - Loss: 0.9346100091934204\n",
      "Ep 85: Batch #59 - Loss: 0.6489536762237549\n",
      "Ep 85: Batch #60 - Loss: 1.2462763786315918\n",
      "Ep 85: Batch #61 - Loss: 0.6031872034072876\n",
      "Ep 85: Batch #62 - Loss: 0.6799765229225159\n",
      "Ep 85: Batch #63 - Loss: 0.9467579126358032\n",
      "Ep 85: Batch #64 - Loss: 9.3593168258667\n",
      "Ep 85: Batch #65 - Loss: 0.5782067179679871\n",
      "Ep 85: Batch #66 - Loss: 0.7475980520248413\n",
      "Ep 85: Batch #67 - Loss: 0.8633812665939331\n",
      "Ep 85: Batch #68 - Loss: 0.850479245185852\n",
      "Ep 85: Batch #69 - Loss: 0.7046937942504883\n",
      "Ep 85: Batch #70 - Loss: 0.7235319018363953\n",
      "Ep 85: Batch #71 - Loss: 0.6439229249954224\n",
      "Ep 85: Batch #72 - Loss: 0.8039214611053467\n",
      "Ep 85: Batch #73 - Loss: 0.8423992991447449\n",
      "Ep 85: Batch #74 - Loss: 0.6914342641830444\n",
      "Ep 85: Batch #75 - Loss: 0.7290453910827637\n",
      "Ep 85: Batch #76 - Loss: 1.0470600128173828\n",
      "Ep 85: Batch #77 - Loss: 0.6880801320075989\n",
      "Ep 85: Batch #78 - Loss: 1.0896676778793335\n",
      "Ep 85: Batch #79 - Loss: 0.5903928279876709\n",
      "Ep 85: Batch #80 - Loss: 0.8035268783569336\n",
      "Ep 85: Batch #81 - Loss: 1.6307801008224487\n",
      "Ep 85: Batch #82 - Loss: 0.8279288411140442\n",
      "Ep 85: Batch #83 - Loss: 1.6983201503753662\n",
      "Ep 85: Batch #84 - Loss: 0.6721199154853821\n",
      "Ep 85: Batch #85 - Loss: 0.9285796284675598\n",
      "Ep 85: Batch #86 - Loss: 0.6617090106010437\n",
      "Ep 85: Batch #87 - Loss: 0.6719347238540649\n",
      "Ep 85: Batch #88 - Loss: 0.7538815140724182\n",
      "Ep 85: Batch #89 - Loss: 0.8521902561187744\n",
      "Ep 85: Batch #90 - Loss: 1.0874124765396118\n",
      "Ep 85: Batch #91 - Loss: 0.7501764297485352\n",
      "Ep 85: Batch #92 - Loss: 0.9709413647651672\n",
      "Ep 85: Batch #93 - Loss: 0.9575438499450684\n",
      "Ep 85: Batch #94 - Loss: 0.987796425819397\n",
      "Ep 85: Batch #95 - Loss: 0.8710873126983643\n",
      "Ep 85: Batch #96 - Loss: 0.8561117053031921\n",
      "Ep 85: Batch #97 - Loss: 0.6853000521659851\n",
      "Ep 85: Batch #98 - Loss: 0.6952951550483704\n",
      "Ep 85: Batch #99 - Loss: 0.9067866206169128\n",
      "Ep 85: Batch #100 - Loss: 0.6367090344429016\n",
      "Ep 85: Batch #101 - Loss: 0.999099850654602\n",
      "Ep 85: Batch #102 - Loss: 0.7365947365760803\n",
      "Ep 85: Batch #103 - Loss: 0.745681881904602\n",
      "Ep 85: Batch #104 - Loss: 0.7567747235298157\n",
      "Ep 85: Batch #105 - Loss: 0.973234236240387\n",
      "Ep 85: Batch #106 - Loss: 0.7201381325721741\n",
      "Ep 85: Batch #107 - Loss: 0.7131007313728333\n",
      "Ep 85: Batch #108 - Loss: 0.9790554046630859\n",
      "Ep 85: Batch #109 - Loss: 0.720080554485321\n",
      "Ep 85: Batch #110 - Loss: 0.8592047095298767\n",
      "Ep 85: Batch #111 - Loss: 1.3121776580810547\n",
      "Ep 85: Batch #112 - Loss: 0.9867815971374512\n",
      "Ep 85: Batch #113 - Loss: 0.7712690830230713\n",
      "Ep 85: Batch #114 - Loss: 0.8467395305633545\n",
      "Ep 85: Batch #115 - Loss: 1.037600040435791\n",
      "Ep 85: Batch #116 - Loss: 0.6044923663139343\n",
      "Ep 85: Batch #117 - Loss: 0.8279233574867249\n",
      "Ep 85: Batch #118 - Loss: 0.510970950126648\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved in file: ./weights_autoencoder_low_LR/model_e85b118_1516651280.2730877.ckpt\n",
      "Ep 85: Batch #119 - Loss: 0.9726978540420532\n",
      "Ep 85: Batch #120 - Loss: 0.7579550743103027\n",
      "Ep 85: Batch #121 - Loss: 0.6448938250541687\n",
      "Ep 85: Batch #122 - Loss: 0.780215322971344\n",
      "Ep 85: Batch #123 - Loss: 0.7855220437049866\n",
      "Ep 85: Batch #124 - Loss: 0.630038321018219\n",
      "Ep 85: Batch #125 - Loss: 2.6515486240386963\n",
      "Ep 85: Batch #126 - Loss: 1.1656856536865234\n",
      "Ep 85: Batch #127 - Loss: 0.6994393467903137\n",
      "Ep 85: Batch #128 - Loss: 1.0347827672958374\n",
      "Ep 85: Batch #129 - Loss: 0.7875276207923889\n",
      "Ep 85: Batch #130 - Loss: 0.6826000213623047\n",
      "Ep 85: Batch #131 - Loss: 0.9292242527008057\n",
      "Ep 85: Batch #132 - Loss: 0.7758212685585022\n",
      "Ep 85: Batch #133 - Loss: 0.7679813504219055\n",
      "Ep 85: Batch #134 - Loss: 0.7232576012611389\n",
      "Ep 85: Batch #135 - Loss: 0.9096834063529968\n",
      "Ep 85: Batch #136 - Loss: 1.1191059350967407\n",
      "Ep 85: Batch #137 - Loss: 0.905531108379364\n",
      "Ep 85: Batch #138 - Loss: 1.0102730989456177\n",
      "Ep 85: Batch #139 - Loss: 0.8442555069923401\n",
      "Ep 85: Batch #140 - Loss: 0.996466338634491\n",
      "Ep 85: Batch #141 - Loss: 1.2931221723556519\n",
      "Ep 85: Batch #142 - Loss: 0.7487791180610657\n",
      "Ep 85: Batch #143 - Loss: 0.9016808867454529\n",
      "Ep 85: Batch #144 - Loss: 0.6820082664489746\n",
      "Ep 85: Batch #145 - Loss: 0.6418272852897644\n",
      "Ep 85: Batch #146 - Loss: 0.8410835266113281\n",
      "Ep 85: Batch #147 - Loss: 0.8058776259422302\n",
      "Ep 85: Batch #148 - Loss: 0.9158191084861755\n",
      "Ep 85: Batch #149 - Loss: 0.8015460968017578\n",
      "Ep 85: Batch #150 - Loss: 0.8374055027961731\n",
      "Ep 85: Batch #151 - Loss: 0.695059061050415\n",
      "Ep 85: Batch #152 - Loss: 0.7067253589630127\n",
      "Ep 85: Batch #153 - Loss: 1.041012167930603\n",
      "Ep 85: Batch #154 - Loss: 0.7195295691490173\n",
      "Ep 85: Batch #155 - Loss: 0.7875623106956482\n",
      "Ep 85: Batch #156 - Loss: 0.9649449586868286\n",
      "Ep 85: Batch #157 - Loss: 0.7153044939041138\n",
      "Ep 85: Batch #158 - Loss: 0.7719614505767822\n",
      "Ep 85: Batch #159 - Loss: 0.7561085820198059\n",
      "Ep 85: Batch #160 - Loss: 0.8630307912826538\n",
      "Ep 85: Batch #161 - Loss: 0.770392119884491\n",
      "Ep 85: Batch #162 - Loss: 0.8817459940910339\n",
      "Ep 85: Batch #163 - Loss: 0.8847403526306152\n",
      "Ep 85: Batch #164 - Loss: 0.7376083731651306\n",
      "Ep 85: Batch #165 - Loss: 1.4530624151229858\n",
      "Ep 85: Batch #166 - Loss: 0.6372429728507996\n",
      "Ep 85: Batch #167 - Loss: 1.0302164554595947\n",
      "Ep 85: Batch #168 - Loss: 0.8081278204917908\n",
      "Ep 85: Batch #169 - Loss: 0.7592476010322571\n",
      "Ep 85: Batch #170 - Loss: 0.7583404779434204\n",
      "Ep 85: Batch #171 - Loss: 0.7289345264434814\n",
      "Ep 85: Batch #172 - Loss: 0.6036617755889893\n",
      "Ep 85: Batch #173 - Loss: 1.1227165460586548\n",
      "Ep 85: Batch #174 - Loss: 0.5465492010116577\n",
      "Ep 85: Batch #175 - Loss: 0.7450369596481323\n",
      "Ep 85: Batch #176 - Loss: 1.0864629745483398\n",
      "Ep 85: Batch #177 - Loss: 0.7994999289512634\n",
      "Ep 85: Batch #178 - Loss: 0.7180249691009521\n",
      "Ep 85: Batch #179 - Loss: 0.8875794410705566\n",
      "Ep 85: Batch #180 - Loss: 0.7975481152534485\n",
      "Ep 85: Batch #181 - Loss: 0.9296961426734924\n",
      "Ep 85: Batch #182 - Loss: 0.7271324992179871\n",
      "Ep 85: Batch #183 - Loss: 0.7245835661888123\n",
      "Ep 85: Batch #184 - Loss: 1.0208940505981445\n",
      "Ep 85: Batch #185 - Loss: 0.7149448990821838\n",
      "Ep 85: Batch #186 - Loss: 0.9035831689834595\n",
      "Ep 85: Batch #187 - Loss: 1.1030831336975098\n",
      "Ep 85: Batch #188 - Loss: 1.2958199977874756\n",
      "Ep 85: Batch #189 - Loss: 0.6697383522987366\n",
      "Ep 85: Batch #190 - Loss: 0.6958008408546448\n",
      "Ep 85: Batch #191 - Loss: 1.000300407409668\n",
      "Ep 85: Batch #192 - Loss: 0.6401348114013672\n",
      "Ep 85: Batch #193 - Loss: 0.6975830793380737\n",
      "Ep 85: Batch #194 - Loss: 0.6546195149421692\n",
      "Ep 85: Batch #195 - Loss: 0.9291462302207947\n",
      "Ep 85: Batch #196 - Loss: 0.8137226104736328\n",
      "Ep 85: Batch #197 - Loss: 0.8451604247093201\n",
      "Ep 85: Batch #198 - Loss: 0.6355424523353577\n",
      "Ep 85: Batch #199 - Loss: 0.8124933242797852\n",
      "Ep 86: Batch #0 - Loss: 0.7405981421470642\n",
      "Ep 86: Batch #1 - Loss: 0.823405385017395\n",
      "Ep 86: Batch #2 - Loss: 0.967085063457489\n",
      "Ep 86: Batch #3 - Loss: 0.8200011253356934\n",
      "Ep 86: Batch #4 - Loss: 0.7409611344337463\n",
      "Ep 86: Batch #5 - Loss: 0.6315295100212097\n",
      "Ep 86: Batch #6 - Loss: 0.8317096829414368\n",
      "Ep 86: Batch #7 - Loss: 0.6637252569198608\n",
      "Ep 86: Batch #8 - Loss: 0.6923468112945557\n",
      "Ep 86: Batch #9 - Loss: 1.323528528213501\n",
      "Ep 86: Batch #10 - Loss: 0.9557663798332214\n",
      "Ep 86: Batch #11 - Loss: 0.6331124305725098\n",
      "Ep 86: Batch #12 - Loss: 1.5009737014770508\n",
      "Ep 86: Batch #13 - Loss: 0.618073046207428\n",
      "Ep 86: Batch #14 - Loss: 0.689998209476471\n",
      "Ep 86: Batch #15 - Loss: 1.1717560291290283\n",
      "Ep 86: Batch #16 - Loss: 1.199959397315979\n",
      "Ep 86: Batch #17 - Loss: 0.8294621109962463\n",
      "Ep 86: Batch #18 - Loss: 0.9088302254676819\n",
      "Ep 86: Batch #19 - Loss: 0.6363076567649841\n",
      "Ep 86: Batch #20 - Loss: 0.6170207858085632\n",
      "Ep 86: Batch #21 - Loss: 1.1636688709259033\n",
      "Ep 86: Batch #22 - Loss: 0.6888876557350159\n",
      "Ep 86: Batch #23 - Loss: 0.697691798210144\n",
      "Ep 86: Batch #24 - Loss: 0.7855287790298462\n",
      "Ep 86: Batch #25 - Loss: 0.6733156442642212\n",
      "Ep 86: Batch #26 - Loss: 0.684347927570343\n",
      "Ep 86: Batch #27 - Loss: 1.2811081409454346\n",
      "Ep 86: Batch #28 - Loss: 0.8267488479614258\n",
      "Ep 86: Batch #29 - Loss: 0.8378632068634033\n",
      "Ep 86: Batch #30 - Loss: 1.1435915231704712\n",
      "Ep 86: Batch #31 - Loss: 0.6377760171890259\n",
      "Ep 86: Batch #32 - Loss: 0.7021320462226868\n",
      "Ep 86: Batch #33 - Loss: 0.7656815648078918\n",
      "Ep 86: Batch #34 - Loss: 0.7402238845825195\n",
      "Ep 86: Batch #35 - Loss: 0.8895443081855774\n",
      "Ep 86: Batch #36 - Loss: 0.6596758365631104\n",
      "Ep 86: Batch #37 - Loss: 1.0925880670547485\n",
      "Ep 86: Batch #38 - Loss: 0.6947357058525085\n",
      "Ep 86: Batch #39 - Loss: 0.780108630657196\n",
      "Ep 86: Batch #40 - Loss: 0.7309609055519104\n",
      "Ep 86: Batch #41 - Loss: 0.6873441934585571\n",
      "Ep 86: Batch #42 - Loss: 0.6810286045074463\n",
      "Ep 86: Batch #43 - Loss: 0.7455145716667175\n",
      "Ep 86: Batch #44 - Loss: 0.7344201803207397\n",
      "Ep 86: Batch #45 - Loss: 0.5938568711280823\n",
      "Ep 86: Batch #46 - Loss: 0.7766658067703247\n",
      "Ep 86: Batch #47 - Loss: 0.893650472164154\n",
      "Ep 86: Batch #48 - Loss: 1.2951217889785767\n",
      "Ep 86: Batch #49 - Loss: 0.9489461183547974\n",
      "Ep 86: Batch #50 - Loss: 0.6726357936859131\n",
      "Ep 86: Batch #51 - Loss: 0.9276823997497559\n",
      "Ep 86: Batch #52 - Loss: 0.7528780102729797\n",
      "Ep 86: Batch #53 - Loss: 0.7738099098205566\n",
      "Ep 86: Batch #54 - Loss: 0.6648542284965515\n",
      "Ep 86: Batch #55 - Loss: 0.7071864604949951\n",
      "Ep 86: Batch #56 - Loss: 1.1882139444351196\n",
      "Ep 86: Batch #57 - Loss: 0.7915239334106445\n",
      "Ep 86: Batch #58 - Loss: 0.9332412481307983\n",
      "Ep 86: Batch #59 - Loss: 0.64825838804245\n",
      "Ep 86: Batch #60 - Loss: 1.2448198795318604\n",
      "Ep 86: Batch #61 - Loss: 0.602514386177063\n",
      "Ep 86: Batch #62 - Loss: 0.6791513562202454\n",
      "Ep 86: Batch #63 - Loss: 0.9455556869506836\n",
      "Ep 86: Batch #64 - Loss: 9.357288360595703\n",
      "Ep 86: Batch #65 - Loss: 0.5774533152580261\n",
      "Ep 86: Batch #66 - Loss: 0.7465524077415466\n",
      "Ep 86: Batch #67 - Loss: 0.8624387979507446\n",
      "Ep 86: Batch #68 - Loss: 0.8491777777671814\n",
      "Ep 86: Batch #69 - Loss: 0.7038183808326721\n",
      "Ep 86: Batch #70 - Loss: 0.7223314642906189\n",
      "Ep 86: Batch #71 - Loss: 0.6430837512016296\n",
      "Ep 86: Batch #72 - Loss: 0.8027746081352234\n",
      "Ep 86: Batch #73 - Loss: 0.8411164879798889\n",
      "Ep 86: Batch #74 - Loss: 0.6903515458106995\n",
      "Ep 86: Batch #75 - Loss: 0.7282418608665466\n",
      "Ep 86: Batch #76 - Loss: 1.0459269285202026\n",
      "Ep 86: Batch #77 - Loss: 0.6870751976966858\n",
      "Ep 86: Batch #78 - Loss: 1.0880848169326782\n",
      "Ep 86: Batch #79 - Loss: 0.5896321535110474\n",
      "Ep 86: Batch #80 - Loss: 0.8022840619087219\n",
      "Ep 86: Batch #81 - Loss: 1.6297578811645508\n",
      "Ep 86: Batch #82 - Loss: 0.826932430267334\n",
      "Ep 86: Batch #83 - Loss: 1.697560429573059\n",
      "Ep 86: Batch #84 - Loss: 0.671262264251709\n",
      "Ep 86: Batch #85 - Loss: 0.9275397062301636\n",
      "Ep 86: Batch #86 - Loss: 0.6607083082199097\n",
      "Ep 86: Batch #87 - Loss: 0.6710684895515442\n",
      "Ep 86: Batch #88 - Loss: 0.752880871295929\n",
      "Ep 86: Batch #89 - Loss: 0.8514853119850159\n",
      "Ep 86: Batch #90 - Loss: 1.0860010385513306\n",
      "Ep 86: Batch #91 - Loss: 0.7490870952606201\n",
      "Ep 86: Batch #92 - Loss: 0.9697022438049316\n",
      "Ep 86: Batch #93 - Loss: 0.9558683037757874\n",
      "Ep 86: Batch #94 - Loss: 0.9863766431808472\n",
      "Ep 86: Batch #95 - Loss: 0.8700357675552368\n",
      "Ep 86: Batch #96 - Loss: 0.8550319075584412\n",
      "Ep 86: Batch #97 - Loss: 0.6843806505203247\n",
      "Ep 86: Batch #98 - Loss: 0.6943715214729309\n",
      "Ep 86: Batch #99 - Loss: 0.9056903123855591\n",
      "Ep 86: Batch #100 - Loss: 0.6358289122581482\n",
      "Ep 86: Batch #101 - Loss: 0.998111367225647\n",
      "Ep 86: Batch #102 - Loss: 0.7355684638023376\n",
      "Ep 86: Batch #103 - Loss: 0.7447186708450317\n",
      "Ep 86: Batch #104 - Loss: 0.7558058500289917\n",
      "Ep 86: Batch #105 - Loss: 0.9721312522888184\n",
      "Ep 86: Batch #106 - Loss: 0.7193138599395752\n",
      "Ep 86: Batch #107 - Loss: 0.7121339440345764\n",
      "Ep 86: Batch #108 - Loss: 0.9779482483863831\n",
      "Ep 86: Batch #109 - Loss: 0.7191303968429565\n",
      "Ep 86: Batch #110 - Loss: 0.8579270243644714\n",
      "Ep 86: Batch #111 - Loss: 1.3106876611709595\n",
      "Ep 86: Batch #112 - Loss: 0.9854586720466614\n",
      "Ep 86: Batch #113 - Loss: 0.7702726721763611\n",
      "Ep 86: Batch #114 - Loss: 0.8455036878585815\n",
      "Ep 86: Batch #115 - Loss: 1.036404013633728\n",
      "Ep 86: Batch #116 - Loss: 0.6038604974746704\n",
      "Ep 86: Batch #117 - Loss: 0.8269385695457458\n",
      "Ep 86: Batch #118 - Loss: 0.5102828741073608\n",
      "Model saved in file: ./weights_autoencoder_low_LR/model_e86b118_1516651280.4105797.ckpt\n",
      "Ep 86: Batch #119 - Loss: 0.9714496731758118\n",
      "Ep 86: Batch #120 - Loss: 0.7570063471794128\n",
      "Ep 86: Batch #121 - Loss: 0.6440150737762451\n",
      "Ep 86: Batch #122 - Loss: 0.779235303401947\n",
      "Ep 86: Batch #123 - Loss: 0.7845542430877686\n",
      "Ep 86: Batch #124 - Loss: 0.629310131072998\n",
      "Ep 86: Batch #125 - Loss: 2.6500144004821777\n",
      "Ep 86: Batch #126 - Loss: 1.1644046306610107\n",
      "Ep 86: Batch #127 - Loss: 0.6982957124710083\n",
      "Ep 86: Batch #128 - Loss: 1.0332361459732056\n",
      "Ep 86: Batch #129 - Loss: 0.7864127159118652\n",
      "Ep 86: Batch #130 - Loss: 0.6817240118980408\n",
      "Ep 86: Batch #131 - Loss: 0.9277458190917969\n",
      "Ep 86: Batch #132 - Loss: 0.774835467338562\n",
      "Ep 86: Batch #133 - Loss: 0.7668483257293701\n",
      "Ep 86: Batch #134 - Loss: 0.7223425507545471\n",
      "Ep 86: Batch #135 - Loss: 0.9085580706596375\n",
      "Ep 86: Batch #136 - Loss: 1.1177915334701538\n",
      "Ep 86: Batch #137 - Loss: 0.9042297601699829\n",
      "Ep 86: Batch #138 - Loss: 1.0088402032852173\n",
      "Ep 86: Batch #139 - Loss: 0.8429722189903259\n",
      "Ep 86: Batch #140 - Loss: 0.9953615069389343\n",
      "Ep 86: Batch #141 - Loss: 1.2917160987854004\n",
      "Ep 86: Batch #142 - Loss: 0.7477473020553589\n",
      "Ep 86: Batch #143 - Loss: 0.900316596031189\n",
      "Ep 86: Batch #144 - Loss: 0.6812182068824768\n",
      "Ep 86: Batch #145 - Loss: 0.641060471534729\n",
      "Ep 86: Batch #146 - Loss: 0.8402379751205444\n",
      "Ep 86: Batch #147 - Loss: 0.8047575950622559\n",
      "Ep 86: Batch #148 - Loss: 0.9144862294197083\n",
      "Ep 86: Batch #149 - Loss: 0.8004539608955383\n",
      "Ep 86: Batch #150 - Loss: 0.8365236520767212\n",
      "Ep 86: Batch #151 - Loss: 0.6943749785423279\n",
      "Ep 86: Batch #152 - Loss: 0.7060421109199524\n",
      "Ep 86: Batch #153 - Loss: 1.0395793914794922\n",
      "Ep 86: Batch #154 - Loss: 0.7186270356178284\n",
      "Ep 86: Batch #155 - Loss: 0.7865842580795288\n",
      "Ep 86: Batch #156 - Loss: 0.9637948870658875\n",
      "Ep 86: Batch #157 - Loss: 0.7142941951751709\n",
      "Ep 86: Batch #158 - Loss: 0.7713071703910828\n",
      "Ep 86: Batch #159 - Loss: 0.7549512386322021\n",
      "Ep 86: Batch #160 - Loss: 0.8621744513511658\n",
      "Ep 86: Batch #161 - Loss: 0.7694829702377319\n",
      "Ep 86: Batch #162 - Loss: 0.8806191682815552\n",
      "Ep 86: Batch #163 - Loss: 0.8836706280708313\n",
      "Ep 86: Batch #164 - Loss: 0.7365679144859314\n",
      "Ep 86: Batch #165 - Loss: 1.4520301818847656\n",
      "Ep 86: Batch #166 - Loss: 0.636320948600769\n",
      "Ep 86: Batch #167 - Loss: 1.028967022895813\n",
      "Ep 86: Batch #168 - Loss: 0.8069633841514587\n",
      "Ep 86: Batch #169 - Loss: 0.7583556175231934\n",
      "Ep 86: Batch #170 - Loss: 0.7573350667953491\n",
      "Ep 86: Batch #171 - Loss: 0.727828860282898\n",
      "Ep 86: Batch #172 - Loss: 0.6030994057655334\n",
      "Ep 86: Batch #173 - Loss: 1.1210941076278687\n",
      "Ep 86: Batch #174 - Loss: 0.5458616614341736\n",
      "Ep 86: Batch #175 - Loss: 0.7443364262580872\n",
      "Ep 86: Batch #176 - Loss: 1.0850740671157837\n",
      "Ep 86: Batch #177 - Loss: 0.7984430193901062\n",
      "Ep 86: Batch #178 - Loss: 0.7170517444610596\n",
      "Ep 86: Batch #179 - Loss: 0.8864381313323975\n",
      "Ep 86: Batch #180 - Loss: 0.7962932586669922\n",
      "Ep 86: Batch #181 - Loss: 0.9283660054206848\n",
      "Ep 86: Batch #182 - Loss: 0.7262685894966125\n",
      "Ep 86: Batch #183 - Loss: 0.7237820029258728\n",
      "Ep 86: Batch #184 - Loss: 1.0197829008102417\n",
      "Ep 86: Batch #185 - Loss: 0.714015781879425\n",
      "Ep 86: Batch #186 - Loss: 0.9021401405334473\n",
      "Ep 86: Batch #187 - Loss: 1.1016199588775635\n",
      "Ep 86: Batch #188 - Loss: 1.2945199012756348\n",
      "Ep 86: Batch #189 - Loss: 0.6690828800201416\n",
      "Ep 86: Batch #190 - Loss: 0.6949330568313599\n",
      "Ep 86: Batch #191 - Loss: 0.9988450407981873\n",
      "Ep 86: Batch #192 - Loss: 0.6395198106765747\n",
      "Ep 86: Batch #193 - Loss: 0.696707010269165\n",
      "Ep 86: Batch #194 - Loss: 0.6537521481513977\n",
      "Ep 86: Batch #195 - Loss: 0.9279603362083435\n",
      "Ep 86: Batch #196 - Loss: 0.8125752806663513\n",
      "Ep 86: Batch #197 - Loss: 0.8439090251922607\n",
      "Ep 86: Batch #198 - Loss: 0.6346617341041565\n",
      "Ep 86: Batch #199 - Loss: 0.811331570148468\n",
      "Ep 87: Batch #0 - Loss: 0.7395310401916504\n",
      "Ep 87: Batch #1 - Loss: 0.8223058581352234\n",
      "Ep 87: Batch #2 - Loss: 0.9662444591522217\n",
      "Ep 87: Batch #3 - Loss: 0.8189826607704163\n",
      "Ep 87: Batch #4 - Loss: 0.7399502396583557\n",
      "Ep 87: Batch #5 - Loss: 0.6307732462882996\n",
      "Ep 87: Batch #6 - Loss: 0.8307385444641113\n",
      "Ep 87: Batch #7 - Loss: 0.6629337072372437\n",
      "Ep 87: Batch #8 - Loss: 0.6914217472076416\n",
      "Ep 87: Batch #9 - Loss: 1.321757197380066\n",
      "Ep 87: Batch #10 - Loss: 0.9546168446540833\n",
      "Ep 87: Batch #11 - Loss: 0.6322595477104187\n",
      "Ep 87: Batch #12 - Loss: 1.4997533559799194\n",
      "Ep 87: Batch #13 - Loss: 0.617415726184845\n",
      "Ep 87: Batch #14 - Loss: 0.6892212629318237\n",
      "Ep 87: Batch #15 - Loss: 1.1702784299850464\n",
      "Ep 87: Batch #16 - Loss: 1.1982181072235107\n",
      "Ep 87: Batch #17 - Loss: 0.8283382058143616\n",
      "Ep 87: Batch #18 - Loss: 0.9081165194511414\n",
      "Ep 87: Batch #19 - Loss: 0.6356444358825684\n",
      "Ep 87: Batch #20 - Loss: 0.6162245869636536\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 87: Batch #21 - Loss: 1.162567377090454\n",
      "Ep 87: Batch #22 - Loss: 0.6880457997322083\n",
      "Ep 87: Batch #23 - Loss: 0.6966755986213684\n",
      "Ep 87: Batch #24 - Loss: 0.7846890687942505\n",
      "Ep 87: Batch #25 - Loss: 0.6724848747253418\n",
      "Ep 87: Batch #26 - Loss: 0.6834083795547485\n",
      "Ep 87: Batch #27 - Loss: 1.2795038223266602\n",
      "Ep 87: Batch #28 - Loss: 0.8258590698242188\n",
      "Ep 87: Batch #29 - Loss: 0.8366903066635132\n",
      "Ep 87: Batch #30 - Loss: 1.1422324180603027\n",
      "Ep 87: Batch #31 - Loss: 0.6370264291763306\n",
      "Ep 87: Batch #32 - Loss: 0.7011863589286804\n",
      "Ep 87: Batch #33 - Loss: 0.7647954821586609\n",
      "Ep 87: Batch #34 - Loss: 0.7392830848693848\n",
      "Ep 87: Batch #35 - Loss: 0.888338565826416\n",
      "Ep 87: Batch #36 - Loss: 0.6587657928466797\n",
      "Ep 87: Batch #37 - Loss: 1.09162437915802\n",
      "Ep 87: Batch #38 - Loss: 0.6936202049255371\n",
      "Ep 87: Batch #39 - Loss: 0.7792351245880127\n",
      "Ep 87: Batch #40 - Loss: 0.7300766110420227\n",
      "Ep 87: Batch #41 - Loss: 0.6863090395927429\n",
      "Ep 87: Batch #42 - Loss: 0.6801899671554565\n",
      "Ep 87: Batch #43 - Loss: 0.7446396350860596\n",
      "Ep 87: Batch #44 - Loss: 0.7332990765571594\n",
      "Ep 87: Batch #45 - Loss: 0.5931006669998169\n",
      "Ep 87: Batch #46 - Loss: 0.7755094170570374\n",
      "Ep 87: Batch #47 - Loss: 0.8921713829040527\n",
      "Ep 87: Batch #48 - Loss: 1.293745517730713\n",
      "Ep 87: Batch #49 - Loss: 0.947597324848175\n",
      "Ep 87: Batch #50 - Loss: 0.6719155311584473\n",
      "Ep 87: Batch #51 - Loss: 0.9261791110038757\n",
      "Ep 87: Batch #52 - Loss: 0.7519690990447998\n",
      "Ep 87: Batch #53 - Loss: 0.7727369666099548\n",
      "Ep 87: Batch #54 - Loss: 0.6639639139175415\n",
      "Ep 87: Batch #55 - Loss: 0.7062020301818848\n",
      "Ep 87: Batch #56 - Loss: 1.1865532398223877\n",
      "Ep 87: Batch #57 - Loss: 0.790259599685669\n",
      "Ep 87: Batch #58 - Loss: 0.9318624138832092\n",
      "Ep 87: Batch #59 - Loss: 0.6475644707679749\n",
      "Ep 87: Batch #60 - Loss: 1.2433345317840576\n",
      "Ep 87: Batch #61 - Loss: 0.6018476486206055\n",
      "Ep 87: Batch #62 - Loss: 0.6783255338668823\n",
      "Ep 87: Batch #63 - Loss: 0.9443567395210266\n",
      "Ep 87: Batch #64 - Loss: 9.355359077453613\n",
      "Ep 87: Batch #65 - Loss: 0.5767055749893188\n",
      "Ep 87: Batch #66 - Loss: 0.7454996109008789\n",
      "Ep 87: Batch #67 - Loss: 0.8614955544471741\n",
      "Ep 87: Batch #68 - Loss: 0.8478851318359375\n",
      "Ep 87: Batch #69 - Loss: 0.7029563188552856\n",
      "Ep 87: Batch #70 - Loss: 0.7211293578147888\n",
      "Ep 87: Batch #71 - Loss: 0.642244815826416\n",
      "Ep 87: Batch #72 - Loss: 0.8016305565834045\n",
      "Ep 87: Batch #73 - Loss: 0.8398441672325134\n",
      "Ep 87: Batch #74 - Loss: 0.6892665028572083\n",
      "Ep 87: Batch #75 - Loss: 0.7274373173713684\n",
      "Ep 87: Batch #76 - Loss: 1.0448064804077148\n",
      "Ep 87: Batch #77 - Loss: 0.6860675811767578\n",
      "Ep 87: Batch #78 - Loss: 1.0864832401275635\n",
      "Ep 87: Batch #79 - Loss: 0.5888668894767761\n",
      "Ep 87: Batch #80 - Loss: 0.8010300993919373\n",
      "Ep 87: Batch #81 - Loss: 1.6287119388580322\n",
      "Ep 87: Batch #82 - Loss: 0.8259356021881104\n",
      "Ep 87: Batch #83 - Loss: 1.6968055963516235\n",
      "Ep 87: Batch #84 - Loss: 0.670401394367218\n",
      "Ep 87: Batch #85 - Loss: 0.9264863729476929\n",
      "Ep 87: Batch #86 - Loss: 0.6597110033035278\n",
      "Ep 87: Batch #87 - Loss: 0.6702044606208801\n",
      "Ep 87: Batch #88 - Loss: 0.7518737316131592\n",
      "Ep 87: Batch #89 - Loss: 0.8507744073867798\n",
      "Ep 87: Batch #90 - Loss: 1.0845997333526611\n",
      "Ep 87: Batch #91 - Loss: 0.7480000853538513\n",
      "Ep 87: Batch #92 - Loss: 0.9684720635414124\n",
      "Ep 87: Batch #93 - Loss: 0.9541934728622437\n",
      "Ep 87: Batch #94 - Loss: 0.984955906867981\n",
      "Ep 87: Batch #95 - Loss: 0.868992030620575\n",
      "Ep 87: Batch #96 - Loss: 0.8539642095565796\n",
      "Ep 87: Batch #97 - Loss: 0.6834684610366821\n",
      "Ep 87: Batch #98 - Loss: 0.6934564113616943\n",
      "Ep 87: Batch #99 - Loss: 0.9045993089675903\n",
      "Ep 87: Batch #100 - Loss: 0.6349532008171082\n",
      "Ep 87: Batch #101 - Loss: 0.9971129894256592\n",
      "Ep 87: Batch #102 - Loss: 0.7345432043075562\n",
      "Ep 87: Batch #103 - Loss: 0.7437459230422974\n",
      "Ep 87: Batch #104 - Loss: 0.7548393607139587\n",
      "Ep 87: Batch #105 - Loss: 0.9710372090339661\n",
      "Ep 87: Batch #106 - Loss: 0.7184961438179016\n",
      "Ep 87: Batch #107 - Loss: 0.7111701965332031\n",
      "Ep 87: Batch #108 - Loss: 0.9768454432487488\n",
      "Ep 87: Batch #109 - Loss: 0.718183696269989\n",
      "Ep 87: Batch #110 - Loss: 0.8566517233848572\n",
      "Ep 87: Batch #111 - Loss: 1.3092085123062134\n",
      "Ep 87: Batch #112 - Loss: 0.984140932559967\n",
      "Ep 87: Batch #113 - Loss: 0.7692724466323853\n",
      "Ep 87: Batch #114 - Loss: 0.844275712966919\n",
      "Ep 87: Batch #115 - Loss: 1.0352147817611694\n",
      "Ep 87: Batch #116 - Loss: 0.6032323241233826\n",
      "Ep 87: Batch #117 - Loss: 0.8259473443031311\n",
      "Ep 87: Batch #118 - Loss: 0.5095905661582947\n",
      "Model saved in file: ./weights_autoencoder_low_LR/model_e87b118_1516651280.5503392.ckpt\n",
      "Ep 87: Batch #119 - Loss: 0.9702138304710388\n",
      "Ep 87: Batch #120 - Loss: 0.7560721039772034\n",
      "Ep 87: Batch #121 - Loss: 0.6431265473365784\n",
      "Ep 87: Batch #122 - Loss: 0.7782465219497681\n",
      "Ep 87: Batch #123 - Loss: 0.7835997939109802\n",
      "Ep 87: Batch #124 - Loss: 0.6285874247550964\n",
      "Ep 87: Batch #125 - Loss: 2.648486614227295\n",
      "Ep 87: Batch #126 - Loss: 1.1631271839141846\n",
      "Ep 87: Batch #127 - Loss: 0.6971541047096252\n",
      "Ep 87: Batch #128 - Loss: 1.0316917896270752\n",
      "Ep 87: Batch #129 - Loss: 0.7853001356124878\n",
      "Ep 87: Batch #130 - Loss: 0.6808565258979797\n",
      "Ep 87: Batch #131 - Loss: 0.9262792468070984\n",
      "Ep 87: Batch #132 - Loss: 0.7738542556762695\n",
      "Ep 87: Batch #133 - Loss: 0.7657164931297302\n",
      "Ep 87: Batch #134 - Loss: 0.7214350700378418\n",
      "Ep 87: Batch #135 - Loss: 0.9074387550354004\n",
      "Ep 87: Batch #136 - Loss: 1.1164809465408325\n",
      "Ep 87: Batch #137 - Loss: 0.9029335975646973\n",
      "Ep 87: Batch #138 - Loss: 1.0074056386947632\n",
      "Ep 87: Batch #139 - Loss: 0.8416891098022461\n",
      "Ep 87: Batch #140 - Loss: 0.994266152381897\n",
      "Ep 87: Batch #141 - Loss: 1.2903327941894531\n",
      "Ep 87: Batch #142 - Loss: 0.7467138171195984\n",
      "Ep 87: Batch #143 - Loss: 0.8989711403846741\n",
      "Ep 87: Batch #144 - Loss: 0.6804370284080505\n",
      "Ep 87: Batch #145 - Loss: 0.6403009295463562\n",
      "Ep 87: Batch #146 - Loss: 0.8394025564193726\n",
      "Ep 87: Batch #147 - Loss: 0.8036369681358337\n",
      "Ep 87: Batch #148 - Loss: 0.9131603837013245\n",
      "Ep 87: Batch #149 - Loss: 0.7993641495704651\n",
      "Ep 87: Batch #150 - Loss: 0.8356534838676453\n",
      "Ep 87: Batch #151 - Loss: 0.6936964988708496\n",
      "Ep 87: Batch #152 - Loss: 0.7053632140159607\n",
      "Ep 87: Batch #153 - Loss: 1.0381572246551514\n",
      "Ep 87: Batch #154 - Loss: 0.7177342772483826\n",
      "Ep 87: Batch #155 - Loss: 0.7856107950210571\n",
      "Ep 87: Batch #156 - Loss: 0.9626449346542358\n",
      "Ep 87: Batch #157 - Loss: 0.713292121887207\n",
      "Ep 87: Batch #158 - Loss: 0.7706522345542908\n",
      "Ep 87: Batch #159 - Loss: 0.7537901401519775\n",
      "Ep 87: Batch #160 - Loss: 0.8613181114196777\n",
      "Ep 87: Batch #161 - Loss: 0.7685908079147339\n",
      "Ep 87: Batch #162 - Loss: 0.8794987797737122\n",
      "Ep 87: Batch #163 - Loss: 0.8826000690460205\n",
      "Ep 87: Batch #164 - Loss: 0.7355432510375977\n",
      "Ep 87: Batch #165 - Loss: 1.4510111808776855\n",
      "Ep 87: Batch #166 - Loss: 0.6354143619537354\n",
      "Ep 87: Batch #167 - Loss: 1.0277223587036133\n",
      "Ep 87: Batch #168 - Loss: 0.805797815322876\n",
      "Ep 87: Batch #169 - Loss: 0.7574743032455444\n",
      "Ep 87: Batch #170 - Loss: 0.7563405632972717\n",
      "Ep 87: Batch #171 - Loss: 0.7267275452613831\n",
      "Ep 87: Batch #172 - Loss: 0.602537214756012\n",
      "Ep 87: Batch #173 - Loss: 1.1194860935211182\n",
      "Ep 87: Batch #174 - Loss: 0.5451768040657043\n",
      "Ep 87: Batch #175 - Loss: 0.7436391115188599\n",
      "Ep 87: Batch #176 - Loss: 1.0837057828903198\n",
      "Ep 87: Batch #177 - Loss: 0.7973949313163757\n",
      "Ep 87: Batch #178 - Loss: 0.7160918712615967\n",
      "Ep 87: Batch #179 - Loss: 0.8853112459182739\n",
      "Ep 87: Batch #180 - Loss: 0.795051634311676\n",
      "Ep 87: Batch #181 - Loss: 0.9270502924919128\n",
      "Ep 87: Batch #182 - Loss: 0.7254085540771484\n",
      "Ep 87: Batch #183 - Loss: 0.7229885458946228\n",
      "Ep 87: Batch #184 - Loss: 1.0186847448349\n",
      "Ep 87: Batch #185 - Loss: 0.7130980491638184\n",
      "Ep 87: Batch #186 - Loss: 0.9007086157798767\n",
      "Ep 87: Batch #187 - Loss: 1.1001838445663452\n",
      "Ep 87: Batch #188 - Loss: 1.2932146787643433\n",
      "Ep 87: Batch #189 - Loss: 0.6684331893920898\n",
      "Ep 87: Batch #190 - Loss: 0.694078266620636\n",
      "Ep 87: Batch #191 - Loss: 0.9974130392074585\n",
      "Ep 87: Batch #192 - Loss: 0.6389120221138\n",
      "Ep 87: Batch #193 - Loss: 0.6958385705947876\n",
      "Ep 87: Batch #194 - Loss: 0.6528931260108948\n",
      "Ep 87: Batch #195 - Loss: 0.9267781376838684\n",
      "Ep 87: Batch #196 - Loss: 0.8114348649978638\n",
      "Ep 87: Batch #197 - Loss: 0.842677652835846\n",
      "Ep 87: Batch #198 - Loss: 0.6337905526161194\n",
      "Ep 87: Batch #199 - Loss: 0.8101873397827148\n",
      "Ep 88: Batch #0 - Loss: 0.7384748458862305\n",
      "Ep 88: Batch #1 - Loss: 0.8212175369262695\n",
      "Ep 88: Batch #2 - Loss: 0.9654099941253662\n",
      "Ep 88: Batch #3 - Loss: 0.8179728984832764\n",
      "Ep 88: Batch #4 - Loss: 0.7389490008354187\n",
      "Ep 88: Batch #5 - Loss: 0.6300283670425415\n",
      "Ep 88: Batch #6 - Loss: 0.8297727108001709\n",
      "Ep 88: Batch #7 - Loss: 0.6621609330177307\n",
      "Ep 88: Batch #8 - Loss: 0.6905018091201782\n",
      "Ep 88: Batch #9 - Loss: 1.3199959993362427\n",
      "Ep 88: Batch #10 - Loss: 0.9534742832183838\n",
      "Ep 88: Batch #11 - Loss: 0.6314122080802917\n",
      "Ep 88: Batch #12 - Loss: 1.4985430240631104\n",
      "Ep 88: Batch #13 - Loss: 0.6167685985565186\n",
      "Ep 88: Batch #14 - Loss: 0.6884537935256958\n",
      "Ep 88: Batch #15 - Loss: 1.1688075065612793\n",
      "Ep 88: Batch #16 - Loss: 1.196492075920105\n",
      "Ep 88: Batch #17 - Loss: 0.8272241950035095\n",
      "Ep 88: Batch #18 - Loss: 0.9074114561080933\n",
      "Ep 88: Batch #19 - Loss: 0.634993314743042\n",
      "Ep 88: Batch #20 - Loss: 0.615435004234314\n",
      "Ep 88: Batch #21 - Loss: 1.1614603996276855\n",
      "Ep 88: Batch #22 - Loss: 0.6872092485427856\n",
      "Ep 88: Batch #23 - Loss: 0.6956678628921509\n",
      "Ep 88: Batch #24 - Loss: 0.7838578820228577\n",
      "Ep 88: Batch #25 - Loss: 0.6716573238372803\n",
      "Ep 88: Batch #26 - Loss: 0.6824737191200256\n",
      "Ep 88: Batch #27 - Loss: 1.277923583984375\n",
      "Ep 88: Batch #28 - Loss: 0.8249759078025818\n",
      "Ep 88: Batch #29 - Loss: 0.8355317711830139\n",
      "Ep 88: Batch #30 - Loss: 1.1408867835998535\n",
      "Ep 88: Batch #31 - Loss: 0.6362897753715515\n",
      "Ep 88: Batch #32 - Loss: 0.7002531290054321\n",
      "Ep 88: Batch #33 - Loss: 0.7639182209968567\n",
      "Ep 88: Batch #34 - Loss: 0.7383472323417664\n",
      "Ep 88: Batch #35 - Loss: 0.8871517181396484\n",
      "Ep 88: Batch #36 - Loss: 0.6578689813613892\n",
      "Ep 88: Batch #37 - Loss: 1.0906660556793213\n",
      "Ep 88: Batch #38 - Loss: 0.6925159692764282\n",
      "Ep 88: Batch #39 - Loss: 0.7783602476119995\n",
      "Ep 88: Batch #40 - Loss: 0.7292060852050781\n",
      "Ep 88: Batch #41 - Loss: 0.685284435749054\n",
      "Ep 88: Batch #42 - Loss: 0.6793546676635742\n",
      "Ep 88: Batch #43 - Loss: 0.7437717914581299\n",
      "Ep 88: Batch #44 - Loss: 0.7321860790252686\n",
      "Ep 88: Batch #45 - Loss: 0.5923463702201843\n",
      "Ep 88: Batch #46 - Loss: 0.7743653059005737\n",
      "Ep 88: Batch #47 - Loss: 0.8907070755958557\n",
      "Ep 88: Batch #48 - Loss: 1.2923897504806519\n",
      "Ep 88: Batch #49 - Loss: 0.9462493658065796\n",
      "Ep 88: Batch #50 - Loss: 0.6712045073509216\n",
      "Ep 88: Batch #51 - Loss: 0.9247000813484192\n",
      "Ep 88: Batch #52 - Loss: 0.7510709166526794\n",
      "Ep 88: Batch #53 - Loss: 0.7716692090034485\n",
      "Ep 88: Batch #54 - Loss: 0.6630808711051941\n",
      "Ep 88: Batch #55 - Loss: 0.7052189111709595\n",
      "Ep 88: Batch #56 - Loss: 1.184915542602539\n",
      "Ep 88: Batch #57 - Loss: 0.7889930605888367\n",
      "Ep 88: Batch #58 - Loss: 0.9305223226547241\n",
      "Ep 88: Batch #59 - Loss: 0.646871030330658\n",
      "Ep 88: Batch #60 - Loss: 1.241864562034607\n",
      "Ep 88: Batch #61 - Loss: 0.6011819243431091\n",
      "Ep 88: Batch #62 - Loss: 0.6775049567222595\n",
      "Ep 88: Batch #63 - Loss: 0.9431590437889099\n",
      "Ep 88: Batch #64 - Loss: 9.353549003601074\n",
      "Ep 88: Batch #65 - Loss: 0.5759663581848145\n",
      "Ep 88: Batch #66 - Loss: 0.7444646954536438\n",
      "Ep 88: Batch #67 - Loss: 0.8605619668960571\n",
      "Ep 88: Batch #68 - Loss: 0.8466107249259949\n",
      "Ep 88: Batch #69 - Loss: 0.7020991444587708\n",
      "Ep 88: Batch #70 - Loss: 0.7199451923370361\n",
      "Ep 88: Batch #71 - Loss: 0.6414066553115845\n",
      "Ep 88: Batch #72 - Loss: 0.8005038499832153\n",
      "Ep 88: Batch #73 - Loss: 0.8385937213897705\n",
      "Ep 88: Batch #74 - Loss: 0.6881885528564453\n",
      "Ep 88: Batch #75 - Loss: 0.7266303300857544\n",
      "Ep 88: Batch #76 - Loss: 1.0437047481536865\n",
      "Ep 88: Batch #77 - Loss: 0.6850723028182983\n",
      "Ep 88: Batch #78 - Loss: 1.0849108695983887\n",
      "Ep 88: Batch #79 - Loss: 0.5881161093711853\n",
      "Ep 88: Batch #80 - Loss: 0.7997766733169556\n",
      "Ep 88: Batch #81 - Loss: 1.6276874542236328\n",
      "Ep 88: Batch #82 - Loss: 0.8249587416648865\n",
      "Ep 88: Batch #83 - Loss: 1.6960619688034058\n",
      "Ep 88: Batch #84 - Loss: 0.6695589423179626\n",
      "Ep 88: Batch #85 - Loss: 0.9254343509674072\n",
      "Ep 88: Batch #86 - Loss: 0.6587262153625488\n",
      "Ep 88: Batch #87 - Loss: 0.6693483591079712\n",
      "Ep 88: Batch #88 - Loss: 0.7508817315101624\n",
      "Ep 88: Batch #89 - Loss: 0.8500754237174988\n",
      "Ep 88: Batch #90 - Loss: 1.0832321643829346\n",
      "Ep 88: Batch #91 - Loss: 0.7469263672828674\n",
      "Ep 88: Batch #92 - Loss: 0.9672584533691406\n",
      "Ep 88: Batch #93 - Loss: 0.9525399208068848\n",
      "Ep 88: Batch #94 - Loss: 0.9835537672042847\n",
      "Ep 88: Batch #95 - Loss: 0.8679533004760742\n",
      "Ep 88: Batch #96 - Loss: 0.852920413017273\n",
      "Ep 88: Batch #97 - Loss: 0.6825634837150574\n",
      "Ep 88: Batch #98 - Loss: 0.6925424337387085\n",
      "Ep 88: Batch #99 - Loss: 0.9035241007804871\n",
      "Ep 88: Batch #100 - Loss: 0.6340904831886292\n",
      "Ep 88: Batch #101 - Loss: 0.9961190819740295\n",
      "Ep 88: Batch #102 - Loss: 0.7335231304168701\n",
      "Ep 88: Batch #103 - Loss: 0.7427971959114075\n",
      "Ep 88: Batch #104 - Loss: 0.7538748979568481\n",
      "Ep 88: Batch #105 - Loss: 0.9699618816375732\n",
      "Ep 88: Batch #106 - Loss: 0.7176847457885742\n",
      "Ep 88: Batch #107 - Loss: 0.7102205157279968\n",
      "Ep 88: Batch #108 - Loss: 0.9757469296455383\n",
      "Ep 88: Batch #109 - Loss: 0.7172558307647705\n",
      "Ep 88: Batch #110 - Loss: 0.8553888201713562\n",
      "Ep 88: Batch #111 - Loss: 1.3077424764633179\n",
      "Ep 88: Batch #112 - Loss: 0.9828327894210815\n",
      "Ep 88: Batch #113 - Loss: 0.7682781219482422\n",
      "Ep 88: Batch #114 - Loss: 0.8430728912353516\n",
      "Ep 88: Batch #115 - Loss: 1.0340418815612793\n",
      "Ep 88: Batch #116 - Loss: 0.6025990843772888\n",
      "Ep 88: Batch #117 - Loss: 0.8249704837799072\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 88: Batch #118 - Loss: 0.5088976621627808\n",
      "Model saved in file: ./weights_autoencoder_low_LR/model_e88b118_1516651280.6946015.ckpt\n",
      "Ep 88: Batch #119 - Loss: 0.968974769115448\n",
      "Ep 88: Batch #120 - Loss: 0.7551526427268982\n",
      "Ep 88: Batch #121 - Loss: 0.6422505974769592\n",
      "Ep 88: Batch #122 - Loss: 0.7772652506828308\n",
      "Ep 88: Batch #123 - Loss: 0.7826560735702515\n",
      "Ep 88: Batch #124 - Loss: 0.6278735995292664\n",
      "Ep 88: Batch #125 - Loss: 2.646991014480591\n",
      "Ep 88: Batch #126 - Loss: 1.1618609428405762\n",
      "Ep 88: Batch #127 - Loss: 0.6960254907608032\n",
      "Ep 88: Batch #128 - Loss: 1.0301679372787476\n",
      "Ep 88: Batch #129 - Loss: 0.7842007875442505\n",
      "Ep 88: Batch #130 - Loss: 0.6799860000610352\n",
      "Ep 88: Batch #131 - Loss: 0.9248355031013489\n",
      "Ep 88: Batch #132 - Loss: 0.7728863954544067\n",
      "Ep 88: Batch #133 - Loss: 0.7646060585975647\n",
      "Ep 88: Batch #134 - Loss: 0.7205389738082886\n",
      "Ep 88: Batch #135 - Loss: 0.9063355326652527\n",
      "Ep 88: Batch #136 - Loss: 1.1151891946792603\n",
      "Ep 88: Batch #137 - Loss: 0.901655375957489\n",
      "Ep 88: Batch #138 - Loss: 1.0059853792190552\n",
      "Ep 88: Batch #139 - Loss: 0.8404273390769958\n",
      "Ep 88: Batch #140 - Loss: 0.9931864142417908\n",
      "Ep 88: Batch #141 - Loss: 1.288967490196228\n",
      "Ep 88: Batch #142 - Loss: 0.7456933856010437\n",
      "Ep 88: Batch #143 - Loss: 0.8976444602012634\n",
      "Ep 88: Batch #144 - Loss: 0.6796586513519287\n",
      "Ep 88: Batch #145 - Loss: 0.6395462155342102\n",
      "Ep 88: Batch #146 - Loss: 0.8385852575302124\n",
      "Ep 88: Batch #147 - Loss: 0.8025351166725159\n",
      "Ep 88: Batch #148 - Loss: 0.9118439555168152\n",
      "Ep 88: Batch #149 - Loss: 0.7982881665229797\n",
      "Ep 88: Batch #150 - Loss: 0.8347879648208618\n",
      "Ep 88: Batch #151 - Loss: 0.6930271983146667\n",
      "Ep 88: Batch #152 - Loss: 0.7046957612037659\n",
      "Ep 88: Batch #153 - Loss: 1.0367602109909058\n",
      "Ep 88: Batch #154 - Loss: 0.7168588042259216\n",
      "Ep 88: Batch #155 - Loss: 0.7846527099609375\n",
      "Ep 88: Batch #156 - Loss: 0.9615172147750854\n",
      "Ep 88: Batch #157 - Loss: 0.7123037576675415\n",
      "Ep 88: Batch #158 - Loss: 0.7699975371360779\n",
      "Ep 88: Batch #159 - Loss: 0.7526504397392273\n",
      "Ep 88: Batch #160 - Loss: 0.8604618310928345\n",
      "Ep 88: Batch #161 - Loss: 0.767705500125885\n",
      "Ep 88: Batch #162 - Loss: 0.8783913254737854\n",
      "Ep 88: Batch #163 - Loss: 0.8815511465072632\n",
      "Ep 88: Batch #164 - Loss: 0.734539270401001\n",
      "Ep 88: Batch #165 - Loss: 1.4500137567520142\n",
      "Ep 88: Batch #166 - Loss: 0.6345146894454956\n",
      "Ep 88: Batch #167 - Loss: 1.0264841318130493\n",
      "Ep 88: Batch #168 - Loss: 0.8046515583992004\n",
      "Ep 88: Batch #169 - Loss: 0.7565993666648865\n",
      "Ep 88: Batch #170 - Loss: 0.7553630471229553\n",
      "Ep 88: Batch #171 - Loss: 0.7256402969360352\n",
      "Ep 88: Batch #172 - Loss: 0.6019724011421204\n",
      "Ep 88: Batch #173 - Loss: 1.1179100275039673\n",
      "Ep 88: Batch #174 - Loss: 0.5445002317428589\n",
      "Ep 88: Batch #175 - Loss: 0.7429466843605042\n",
      "Ep 88: Batch #176 - Loss: 1.0823575258255005\n",
      "Ep 88: Batch #177 - Loss: 0.7963604927062988\n",
      "Ep 88: Batch #178 - Loss: 0.7151389122009277\n",
      "Ep 88: Batch #179 - Loss: 0.8841979503631592\n",
      "Ep 88: Batch #180 - Loss: 0.7938246726989746\n",
      "Ep 88: Batch #181 - Loss: 0.9257494211196899\n",
      "Ep 88: Batch #182 - Loss: 0.7245665192604065\n",
      "Ep 88: Batch #183 - Loss: 0.7222059965133667\n",
      "Ep 88: Batch #184 - Loss: 1.0176111459732056\n",
      "Ep 88: Batch #185 - Loss: 0.7121894955635071\n",
      "Ep 88: Batch #186 - Loss: 0.8993031978607178\n",
      "Ep 88: Batch #187 - Loss: 1.09878671169281\n",
      "Ep 88: Batch #188 - Loss: 1.291919231414795\n",
      "Ep 88: Batch #189 - Loss: 0.6678000688552856\n",
      "Ep 88: Batch #190 - Loss: 0.6932343244552612\n",
      "Ep 88: Batch #191 - Loss: 0.9959973692893982\n",
      "Ep 88: Batch #192 - Loss: 0.6383141875267029\n",
      "Ep 88: Batch #193 - Loss: 0.6949901580810547\n",
      "Ep 88: Batch #194 - Loss: 0.6520366072654724\n",
      "Ep 88: Batch #195 - Loss: 0.9256128668785095\n",
      "Ep 88: Batch #196 - Loss: 0.810319185256958\n",
      "Ep 88: Batch #197 - Loss: 0.8414662480354309\n",
      "Ep 88: Batch #198 - Loss: 0.6329256892204285\n",
      "Ep 88: Batch #199 - Loss: 0.8090572953224182\n",
      "Ep 89: Batch #0 - Loss: 0.7374443411827087\n",
      "Ep 89: Batch #1 - Loss: 0.820135235786438\n",
      "Ep 89: Batch #2 - Loss: 0.9645869135856628\n",
      "Ep 89: Batch #3 - Loss: 0.8169800639152527\n",
      "Ep 89: Batch #4 - Loss: 0.7379632592201233\n",
      "Ep 89: Batch #5 - Loss: 0.6293022036552429\n",
      "Ep 89: Batch #6 - Loss: 0.8288167119026184\n",
      "Ep 89: Batch #7 - Loss: 0.6614089012145996\n",
      "Ep 89: Batch #8 - Loss: 0.6895965933799744\n",
      "Ep 89: Batch #9 - Loss: 1.3182488679885864\n",
      "Ep 89: Batch #10 - Loss: 0.9523500800132751\n",
      "Ep 89: Batch #11 - Loss: 0.6305713653564453\n",
      "Ep 89: Batch #12 - Loss: 1.4973474740982056\n",
      "Ep 89: Batch #13 - Loss: 0.6161425113677979\n",
      "Ep 89: Batch #14 - Loss: 0.6877032518386841\n",
      "Ep 89: Batch #15 - Loss: 1.1673550605773926\n",
      "Ep 89: Batch #16 - Loss: 1.194790005683899\n",
      "Ep 89: Batch #17 - Loss: 0.8261517286300659\n",
      "Ep 89: Batch #18 - Loss: 0.906716525554657\n",
      "Ep 89: Batch #19 - Loss: 0.6343503594398499\n",
      "Ep 89: Batch #20 - Loss: 0.614652693271637\n",
      "Ep 89: Batch #21 - Loss: 1.160353183746338\n",
      "Ep 89: Batch #22 - Loss: 0.686379611492157\n",
      "Ep 89: Batch #23 - Loss: 0.6946690678596497\n",
      "Ep 89: Batch #24 - Loss: 0.7830255031585693\n",
      "Ep 89: Batch #25 - Loss: 0.6708381772041321\n",
      "Ep 89: Batch #26 - Loss: 0.6815500855445862\n",
      "Ep 89: Batch #27 - Loss: 1.2763608694076538\n",
      "Ep 89: Batch #28 - Loss: 0.8240957856178284\n",
      "Ep 89: Batch #29 - Loss: 0.8344033360481262\n",
      "Ep 89: Batch #30 - Loss: 1.1395487785339355\n",
      "Ep 89: Batch #31 - Loss: 0.6355671286582947\n",
      "Ep 89: Batch #32 - Loss: 0.6993319988250732\n",
      "Ep 89: Batch #33 - Loss: 0.7630578875541687\n",
      "Ep 89: Batch #34 - Loss: 0.7374160289764404\n",
      "Ep 89: Batch #35 - Loss: 0.8859838247299194\n",
      "Ep 89: Batch #36 - Loss: 0.6569935083389282\n",
      "Ep 89: Batch #37 - Loss: 1.0897024869918823\n",
      "Ep 89: Batch #38 - Loss: 0.691415548324585\n",
      "Ep 89: Batch #39 - Loss: 0.777495801448822\n",
      "Ep 89: Batch #40 - Loss: 0.7283310890197754\n",
      "Ep 89: Batch #41 - Loss: 0.6842837929725647\n",
      "Ep 89: Batch #42 - Loss: 0.6785308122634888\n",
      "Ep 89: Batch #43 - Loss: 0.742918848991394\n",
      "Ep 89: Batch #44 - Loss: 0.7310935258865356\n",
      "Ep 89: Batch #45 - Loss: 0.5915957093238831\n",
      "Ep 89: Batch #46 - Loss: 0.7732388973236084\n",
      "Ep 89: Batch #47 - Loss: 0.8892785906791687\n",
      "Ep 89: Batch #48 - Loss: 1.2910616397857666\n",
      "Ep 89: Batch #49 - Loss: 0.9449232220649719\n",
      "Ep 89: Batch #50 - Loss: 0.6705015897750854\n",
      "Ep 89: Batch #51 - Loss: 0.9232678413391113\n",
      "Ep 89: Batch #52 - Loss: 0.7501880526542664\n",
      "Ep 89: Batch #53 - Loss: 0.7706242203712463\n",
      "Ep 89: Batch #54 - Loss: 0.6622098088264465\n",
      "Ep 89: Batch #55 - Loss: 0.7042532563209534\n",
      "Ep 89: Batch #56 - Loss: 1.1833078861236572\n",
      "Ep 89: Batch #57 - Loss: 0.7877411246299744\n",
      "Ep 89: Batch #58 - Loss: 0.9292004704475403\n",
      "Ep 89: Batch #59 - Loss: 0.6461792588233948\n",
      "Ep 89: Batch #60 - Loss: 1.2404215335845947\n",
      "Ep 89: Batch #61 - Loss: 0.6005207300186157\n",
      "Ep 89: Batch #62 - Loss: 0.6766862869262695\n",
      "Ep 89: Batch #63 - Loss: 0.9419817924499512\n",
      "Ep 89: Batch #64 - Loss: 9.351826667785645\n",
      "Ep 89: Batch #65 - Loss: 0.5752381086349487\n",
      "Ep 89: Batch #66 - Loss: 0.743453860282898\n",
      "Ep 89: Batch #67 - Loss: 0.8596461415290833\n",
      "Ep 89: Batch #68 - Loss: 0.8453631401062012\n",
      "Ep 89: Batch #69 - Loss: 0.7012380957603455\n",
      "Ep 89: Batch #70 - Loss: 0.718792200088501\n",
      "Ep 89: Batch #71 - Loss: 0.6405737996101379\n",
      "Ep 89: Batch #72 - Loss: 0.7993881702423096\n",
      "Ep 89: Batch #73 - Loss: 0.8373744487762451\n",
      "Ep 89: Batch #74 - Loss: 0.6871383786201477\n",
      "Ep 89: Batch #75 - Loss: 0.725836455821991\n",
      "Ep 89: Batch #76 - Loss: 1.0426284074783325\n",
      "Ep 89: Batch #77 - Loss: 0.6841099858283997\n",
      "Ep 89: Batch #78 - Loss: 1.0833759307861328\n",
      "Ep 89: Batch #79 - Loss: 0.5873833894729614\n",
      "Ep 89: Batch #80 - Loss: 0.7985540628433228\n",
      "Ep 89: Batch #81 - Loss: 1.6266796588897705\n",
      "Ep 89: Batch #82 - Loss: 0.8240155577659607\n",
      "Ep 89: Batch #83 - Loss: 1.6953282356262207\n",
      "Ep 89: Batch #84 - Loss: 0.6687266826629639\n",
      "Ep 89: Batch #85 - Loss: 0.9244125485420227\n",
      "Ep 89: Batch #86 - Loss: 0.6577569246292114\n",
      "Ep 89: Batch #87 - Loss: 0.6685007214546204\n",
      "Ep 89: Batch #88 - Loss: 0.7499217391014099\n",
      "Ep 89: Batch #89 - Loss: 0.8493897914886475\n",
      "Ep 89: Batch #90 - Loss: 1.0819000005722046\n",
      "Ep 89: Batch #91 - Loss: 0.745879054069519\n",
      "Ep 89: Batch #92 - Loss: 0.9660480618476868\n",
      "Ep 89: Batch #93 - Loss: 0.9509395360946655\n",
      "Ep 89: Batch #94 - Loss: 0.982180118560791\n",
      "Ep 89: Batch #95 - Loss: 0.8669134378433228\n",
      "Ep 89: Batch #96 - Loss: 0.8518990874290466\n",
      "Ep 89: Batch #97 - Loss: 0.6816556453704834\n",
      "Ep 89: Batch #98 - Loss: 0.691646158695221\n",
      "Ep 89: Batch #99 - Loss: 0.9024699330329895\n",
      "Ep 89: Batch #100 - Loss: 0.6332454085350037\n",
      "Ep 89: Batch #101 - Loss: 0.9951242208480835\n",
      "Ep 89: Batch #102 - Loss: 0.7325272560119629\n",
      "Ep 89: Batch #103 - Loss: 0.7418885231018066\n",
      "Ep 89: Batch #104 - Loss: 0.7529295086860657\n",
      "Ep 89: Batch #105 - Loss: 0.9688861966133118\n",
      "Ep 89: Batch #106 - Loss: 0.7168904542922974\n",
      "Ep 89: Batch #107 - Loss: 0.7092846632003784\n",
      "Ep 89: Batch #108 - Loss: 0.974668025970459\n",
      "Ep 89: Batch #109 - Loss: 0.7163463830947876\n",
      "Ep 89: Batch #110 - Loss: 0.8541439175605774\n",
      "Ep 89: Batch #111 - Loss: 1.3062862157821655\n",
      "Ep 89: Batch #112 - Loss: 0.981543779373169\n",
      "Ep 89: Batch #113 - Loss: 0.7672925591468811\n",
      "Ep 89: Batch #114 - Loss: 0.8419064879417419\n",
      "Ep 89: Batch #115 - Loss: 1.0328865051269531\n",
      "Ep 89: Batch #116 - Loss: 0.601963222026825\n",
      "Ep 89: Batch #117 - Loss: 0.8240171074867249\n",
      "Ep 89: Batch #118 - Loss: 0.5082069635391235\n",
      "Model saved in file: ./weights_autoencoder_low_LR/model_e89b118_1516651280.8302996.ckpt\n",
      "Ep 89: Batch #119 - Loss: 0.9677567481994629\n",
      "Ep 89: Batch #120 - Loss: 0.7542523741722107\n",
      "Ep 89: Batch #121 - Loss: 0.641391932964325\n",
      "Ep 89: Batch #122 - Loss: 0.7763189673423767\n",
      "Ep 89: Batch #123 - Loss: 0.7817182540893555\n",
      "Ep 89: Batch #124 - Loss: 0.6271724700927734\n",
      "Ep 89: Batch #125 - Loss: 2.6455323696136475\n",
      "Ep 89: Batch #126 - Loss: 1.1606097221374512\n",
      "Ep 89: Batch #127 - Loss: 0.6949185729026794\n",
      "Ep 89: Batch #128 - Loss: 1.028679370880127\n",
      "Ep 89: Batch #129 - Loss: 0.7831209897994995\n",
      "Ep 89: Batch #130 - Loss: 0.6791132688522339\n",
      "Ep 89: Batch #131 - Loss: 0.9234359264373779\n",
      "Ep 89: Batch #132 - Loss: 0.7719382643699646\n",
      "Ep 89: Batch #133 - Loss: 0.7635130882263184\n",
      "Ep 89: Batch #134 - Loss: 0.7196545600891113\n",
      "Ep 89: Batch #135 - Loss: 0.9052501916885376\n",
      "Ep 89: Batch #136 - Loss: 1.1139191389083862\n",
      "Ep 89: Batch #137 - Loss: 0.9004018902778625\n",
      "Ep 89: Batch #138 - Loss: 1.0045835971832275\n",
      "Ep 89: Batch #139 - Loss: 0.8391900658607483\n",
      "Ep 89: Batch #140 - Loss: 0.99212247133255\n",
      "Ep 89: Batch #141 - Loss: 1.2876214981079102\n",
      "Ep 89: Batch #142 - Loss: 0.7447076439857483\n",
      "Ep 89: Batch #143 - Loss: 0.8963372111320496\n",
      "Ep 89: Batch #144 - Loss: 0.6788966655731201\n",
      "Ep 89: Batch #145 - Loss: 0.6387994289398193\n",
      "Ep 89: Batch #146 - Loss: 0.8377771973609924\n",
      "Ep 89: Batch #147 - Loss: 0.8014522194862366\n",
      "Ep 89: Batch #148 - Loss: 0.910548985004425\n",
      "Ep 89: Batch #149 - Loss: 0.7972341775894165\n",
      "Ep 89: Batch #150 - Loss: 0.8339338302612305\n",
      "Ep 89: Batch #151 - Loss: 0.6923691034317017\n",
      "Ep 89: Batch #152 - Loss: 0.7040380835533142\n",
      "Ep 89: Batch #153 - Loss: 1.0353968143463135\n",
      "Ep 89: Batch #154 - Loss: 0.7160021066665649\n",
      "Ep 89: Batch #155 - Loss: 0.7837142944335938\n",
      "Ep 89: Batch #156 - Loss: 0.960414469242096\n",
      "Ep 89: Batch #157 - Loss: 0.7113451361656189\n",
      "Ep 89: Batch #158 - Loss: 0.7693349719047546\n",
      "Ep 89: Batch #159 - Loss: 0.7515403032302856\n",
      "Ep 89: Batch #160 - Loss: 0.859610378742218\n",
      "Ep 89: Batch #161 - Loss: 0.7668397426605225\n",
      "Ep 89: Batch #162 - Loss: 0.8773038983345032\n",
      "Ep 89: Batch #163 - Loss: 0.8805210590362549\n",
      "Ep 89: Batch #164 - Loss: 0.7335579991340637\n",
      "Ep 89: Batch #165 - Loss: 1.449033498764038\n",
      "Ep 89: Batch #166 - Loss: 0.6336300373077393\n",
      "Ep 89: Batch #167 - Loss: 1.0252718925476074\n",
      "Ep 89: Batch #168 - Loss: 0.80352383852005\n",
      "Ep 89: Batch #169 - Loss: 0.7557374835014343\n",
      "Ep 89: Batch #170 - Loss: 0.7543938755989075\n",
      "Ep 89: Batch #171 - Loss: 0.7245692014694214\n",
      "Ep 89: Batch #172 - Loss: 0.601406455039978\n",
      "Ep 89: Batch #173 - Loss: 1.1163700819015503\n",
      "Ep 89: Batch #174 - Loss: 0.5438302755355835\n",
      "Ep 89: Batch #175 - Loss: 0.742257297039032\n",
      "Ep 89: Batch #176 - Loss: 1.081027865409851\n",
      "Ep 89: Batch #177 - Loss: 0.7953396439552307\n",
      "Ep 89: Batch #178 - Loss: 0.7141976356506348\n",
      "Ep 89: Batch #179 - Loss: 0.8830900192260742\n",
      "Ep 89: Batch #180 - Loss: 0.7926152944564819\n",
      "Ep 89: Batch #181 - Loss: 0.9244852662086487\n",
      "Ep 89: Batch #182 - Loss: 0.7237451076507568\n",
      "Ep 89: Batch #183 - Loss: 0.7214294075965881\n",
      "Ep 89: Batch #184 - Loss: 1.016554594039917\n",
      "Ep 89: Batch #185 - Loss: 0.7112796306610107\n",
      "Ep 89: Batch #186 - Loss: 0.8979367613792419\n",
      "Ep 89: Batch #187 - Loss: 1.0974087715148926\n",
      "Ep 89: Batch #188 - Loss: 1.2906242609024048\n",
      "Ep 89: Batch #189 - Loss: 0.6671810150146484\n",
      "Ep 89: Batch #190 - Loss: 0.6923996806144714\n",
      "Ep 89: Batch #191 - Loss: 0.9946032166481018\n",
      "Ep 89: Batch #192 - Loss: 0.6377220749855042\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 89: Batch #193 - Loss: 0.6941573023796082\n",
      "Ep 89: Batch #194 - Loss: 0.6511883735656738\n",
      "Ep 89: Batch #195 - Loss: 0.9244640469551086\n",
      "Ep 89: Batch #196 - Loss: 0.8092239499092102\n",
      "Ep 89: Batch #197 - Loss: 0.8402734398841858\n",
      "Ep 89: Batch #198 - Loss: 0.6320627927780151\n",
      "Ep 89: Batch #199 - Loss: 0.8079333305358887\n",
      "Ep 90: Batch #0 - Loss: 0.7364291548728943\n",
      "Ep 90: Batch #1 - Loss: 0.8190743327140808\n",
      "Ep 90: Batch #2 - Loss: 0.9637709259986877\n",
      "Ep 90: Batch #3 - Loss: 0.816002607345581\n",
      "Ep 90: Batch #4 - Loss: 0.7369927167892456\n",
      "Ep 90: Batch #5 - Loss: 0.6285830736160278\n",
      "Ep 90: Batch #6 - Loss: 0.8278725147247314\n",
      "Ep 90: Batch #7 - Loss: 0.6606760621070862\n",
      "Ep 90: Batch #8 - Loss: 0.6887025833129883\n",
      "Ep 90: Batch #9 - Loss: 1.3165236711502075\n",
      "Ep 90: Batch #10 - Loss: 0.9512356519699097\n",
      "Ep 90: Batch #11 - Loss: 0.6297356486320496\n",
      "Ep 90: Batch #12 - Loss: 1.4961658716201782\n",
      "Ep 90: Batch #13 - Loss: 0.6155377626419067\n",
      "Ep 90: Batch #14 - Loss: 0.6869638562202454\n",
      "Ep 90: Batch #15 - Loss: 1.1659135818481445\n",
      "Ep 90: Batch #16 - Loss: 1.1931124925613403\n",
      "Ep 90: Batch #17 - Loss: 0.8250994086265564\n",
      "Ep 90: Batch #18 - Loss: 0.9060235619544983\n",
      "Ep 90: Batch #19 - Loss: 0.6337088346481323\n",
      "Ep 90: Batch #20 - Loss: 0.6138818860054016\n",
      "Ep 90: Batch #21 - Loss: 1.1592586040496826\n",
      "Ep 90: Batch #22 - Loss: 0.6855562329292297\n",
      "Ep 90: Batch #23 - Loss: 0.6936758160591125\n",
      "Ep 90: Batch #24 - Loss: 0.7822036743164062\n",
      "Ep 90: Batch #25 - Loss: 0.6700261235237122\n",
      "Ep 90: Batch #26 - Loss: 0.6806405782699585\n",
      "Ep 90: Batch #27 - Loss: 1.2748183012008667\n",
      "Ep 90: Batch #28 - Loss: 0.8232206106185913\n",
      "Ep 90: Batch #29 - Loss: 0.8333002328872681\n",
      "Ep 90: Batch #30 - Loss: 1.1382241249084473\n",
      "Ep 90: Batch #31 - Loss: 0.6348571181297302\n",
      "Ep 90: Batch #32 - Loss: 0.6984296441078186\n",
      "Ep 90: Batch #33 - Loss: 0.7622082829475403\n",
      "Ep 90: Batch #34 - Loss: 0.7365002632141113\n",
      "Ep 90: Batch #35 - Loss: 0.8848295211791992\n",
      "Ep 90: Batch #36 - Loss: 0.6561293005943298\n",
      "Ep 90: Batch #37 - Loss: 1.0887435674667358\n",
      "Ep 90: Batch #38 - Loss: 0.6903249621391296\n",
      "Ep 90: Batch #39 - Loss: 0.7766414880752563\n",
      "Ep 90: Batch #40 - Loss: 0.7274553179740906\n",
      "Ep 90: Batch #41 - Loss: 0.6833003163337708\n",
      "Ep 90: Batch #42 - Loss: 0.6777180433273315\n",
      "Ep 90: Batch #43 - Loss: 0.7420762777328491\n",
      "Ep 90: Batch #44 - Loss: 0.7300124168395996\n",
      "Ep 90: Batch #45 - Loss: 0.590851366519928\n",
      "Ep 90: Batch #46 - Loss: 0.7721308469772339\n",
      "Ep 90: Batch #47 - Loss: 0.8878698945045471\n",
      "Ep 90: Batch #48 - Loss: 1.2897568941116333\n",
      "Ep 90: Batch #49 - Loss: 0.9436171650886536\n",
      "Ep 90: Batch #50 - Loss: 0.6698070764541626\n",
      "Ep 90: Batch #51 - Loss: 0.9218624830245972\n",
      "Ep 90: Batch #52 - Loss: 0.7493124008178711\n",
      "Ep 90: Batch #53 - Loss: 0.7695953845977783\n",
      "Ep 90: Batch #54 - Loss: 0.6613426804542542\n",
      "Ep 90: Batch #55 - Loss: 0.7032949328422546\n",
      "Ep 90: Batch #56 - Loss: 1.181718111038208\n",
      "Ep 90: Batch #57 - Loss: 0.7865054607391357\n",
      "Ep 90: Batch #58 - Loss: 0.9278932213783264\n",
      "Ep 90: Batch #59 - Loss: 0.6454982757568359\n",
      "Ep 90: Batch #60 - Loss: 1.2389963865280151\n",
      "Ep 90: Batch #61 - Loss: 0.5998607873916626\n",
      "Ep 90: Batch #62 - Loss: 0.6758800148963928\n",
      "Ep 90: Batch #63 - Loss: 0.9408217072486877\n",
      "Ep 90: Batch #64 - Loss: 9.350174903869629\n",
      "Ep 90: Batch #65 - Loss: 0.574517548084259\n",
      "Ep 90: Batch #66 - Loss: 0.7424632906913757\n",
      "Ep 90: Batch #67 - Loss: 0.8587441444396973\n",
      "Ep 90: Batch #68 - Loss: 0.8441222906112671\n",
      "Ep 90: Batch #69 - Loss: 0.7003818154335022\n",
      "Ep 90: Batch #70 - Loss: 0.7176504135131836\n",
      "Ep 90: Batch #71 - Loss: 0.6397370100021362\n",
      "Ep 90: Batch #72 - Loss: 0.7982761859893799\n",
      "Ep 90: Batch #73 - Loss: 0.8361706137657166\n",
      "Ep 90: Batch #74 - Loss: 0.6861022710800171\n",
      "Ep 90: Batch #75 - Loss: 0.7250559329986572\n",
      "Ep 90: Batch #76 - Loss: 1.0415667295455933\n",
      "Ep 90: Batch #77 - Loss: 0.6831629872322083\n",
      "Ep 90: Batch #78 - Loss: 1.0818616151809692\n",
      "Ep 90: Batch #79 - Loss: 0.5866621136665344\n",
      "Ep 90: Batch #80 - Loss: 0.7973489761352539\n",
      "Ep 90: Batch #81 - Loss: 1.6256906986236572\n",
      "Ep 90: Batch #82 - Loss: 0.8230899572372437\n",
      "Ep 90: Batch #83 - Loss: 1.694603443145752\n",
      "Ep 90: Batch #84 - Loss: 0.6679043173789978\n",
      "Ep 90: Batch #85 - Loss: 0.9234070181846619\n",
      "Ep 90: Batch #86 - Loss: 0.6567937135696411\n",
      "Ep 90: Batch #87 - Loss: 0.6676579713821411\n",
      "Ep 90: Batch #88 - Loss: 0.7489790320396423\n",
      "Ep 90: Batch #89 - Loss: 0.8487077951431274\n",
      "Ep 90: Batch #90 - Loss: 1.0805824995040894\n",
      "Ep 90: Batch #91 - Loss: 0.7448459267616272\n",
      "Ep 90: Batch #92 - Loss: 0.9648485779762268\n",
      "Ep 90: Batch #93 - Loss: 0.9493592381477356\n",
      "Ep 90: Batch #94 - Loss: 0.9808237552642822\n",
      "Ep 90: Batch #95 - Loss: 0.865867555141449\n",
      "Ep 90: Batch #96 - Loss: 0.8508890867233276\n",
      "Ep 90: Batch #97 - Loss: 0.6807584762573242\n",
      "Ep 90: Batch #98 - Loss: 0.6907581090927124\n",
      "Ep 90: Batch #99 - Loss: 0.9014289379119873\n",
      "Ep 90: Batch #100 - Loss: 0.6324061155319214\n",
      "Ep 90: Batch #101 - Loss: 0.994137704372406\n",
      "Ep 90: Batch #102 - Loss: 0.7315453290939331\n",
      "Ep 90: Batch #103 - Loss: 0.7409932017326355\n",
      "Ep 90: Batch #104 - Loss: 0.7519931197166443\n",
      "Ep 90: Batch #105 - Loss: 0.9678188562393188\n",
      "Ep 90: Batch #106 - Loss: 0.7161054015159607\n",
      "Ep 90: Batch #107 - Loss: 0.7083551287651062\n",
      "Ep 90: Batch #108 - Loss: 0.9736012816429138\n",
      "Ep 90: Batch #109 - Loss: 0.7154486179351807\n",
      "Ep 90: Batch #110 - Loss: 0.8529118299484253\n",
      "Ep 90: Batch #111 - Loss: 1.304837942123413\n",
      "Ep 90: Batch #112 - Loss: 0.9802669882774353\n",
      "Ep 90: Batch #113 - Loss: 0.7663137912750244\n",
      "Ep 90: Batch #114 - Loss: 0.8407521843910217\n",
      "Ep 90: Batch #115 - Loss: 1.031740665435791\n",
      "Ep 90: Batch #116 - Loss: 0.6013282537460327\n",
      "Ep 90: Batch #117 - Loss: 0.8230792284011841\n",
      "Ep 90: Batch #118 - Loss: 0.5075245499610901\n",
      "Model saved in file: ./weights_autoencoder_low_LR/model_e90b118_1516651280.9666371.ckpt\n",
      "Ep 90: Batch #119 - Loss: 0.966552734375\n",
      "Ep 90: Batch #120 - Loss: 0.753359317779541\n",
      "Ep 90: Batch #121 - Loss: 0.6405423879623413\n",
      "Ep 90: Batch #122 - Loss: 0.7753859758377075\n",
      "Ep 90: Batch #123 - Loss: 0.7807955741882324\n",
      "Ep 90: Batch #124 - Loss: 0.6264785528182983\n",
      "Ep 90: Batch #125 - Loss: 2.6440913677215576\n",
      "Ep 90: Batch #126 - Loss: 1.1593704223632812\n",
      "Ep 90: Batch #127 - Loss: 0.6938177943229675\n",
      "Ep 90: Batch #128 - Loss: 1.027208924293518\n",
      "Ep 90: Batch #129 - Loss: 0.7820528149604797\n",
      "Ep 90: Batch #130 - Loss: 0.678253710269928\n",
      "Ep 90: Batch #131 - Loss: 0.922050416469574\n",
      "Ep 90: Batch #132 - Loss: 0.7710017561912537\n",
      "Ep 90: Batch #133 - Loss: 0.762436032295227\n",
      "Ep 90: Batch #134 - Loss: 0.7187796235084534\n",
      "Ep 90: Batch #135 - Loss: 0.9041716456413269\n",
      "Ep 90: Batch #136 - Loss: 1.1126619577407837\n",
      "Ep 90: Batch #137 - Loss: 0.8991625905036926\n",
      "Ep 90: Batch #138 - Loss: 1.0031927824020386\n",
      "Ep 90: Batch #139 - Loss: 0.8379654288291931\n",
      "Ep 90: Batch #140 - Loss: 0.991069495677948\n",
      "Ep 90: Batch #141 - Loss: 1.2862859964370728\n",
      "Ep 90: Batch #142 - Loss: 0.7437307834625244\n",
      "Ep 90: Batch #143 - Loss: 0.895039439201355\n",
      "Ep 90: Batch #144 - Loss: 0.6781473755836487\n",
      "Ep 90: Batch #145 - Loss: 0.6380646228790283\n",
      "Ep 90: Batch #146 - Loss: 0.8369761109352112\n",
      "Ep 90: Batch #147 - Loss: 0.8003880977630615\n",
      "Ep 90: Batch #148 - Loss: 0.9092684388160706\n",
      "Ep 90: Batch #149 - Loss: 0.7961918711662292\n",
      "Ep 90: Batch #150 - Loss: 0.8330903649330139\n",
      "Ep 90: Batch #151 - Loss: 0.6917160749435425\n",
      "Ep 90: Batch #152 - Loss: 0.7033803462982178\n",
      "Ep 90: Batch #153 - Loss: 1.034049391746521\n",
      "Ep 90: Batch #154 - Loss: 0.7151575088500977\n",
      "Ep 90: Batch #155 - Loss: 0.7827881574630737\n",
      "Ep 90: Batch #156 - Loss: 0.959321141242981\n",
      "Ep 90: Batch #157 - Loss: 0.7103919386863708\n",
      "Ep 90: Batch #158 - Loss: 0.768667995929718\n",
      "Ep 90: Batch #159 - Loss: 0.7504411339759827\n",
      "Ep 90: Batch #160 - Loss: 0.858763575553894\n",
      "Ep 90: Batch #161 - Loss: 0.7659876942634583\n",
      "Ep 90: Batch #162 - Loss: 0.8762295842170715\n",
      "Ep 90: Batch #163 - Loss: 0.8794980645179749\n",
      "Ep 90: Batch #164 - Loss: 0.7325807809829712\n",
      "Ep 90: Batch #165 - Loss: 1.4480657577514648\n",
      "Ep 90: Batch #166 - Loss: 0.6327558159828186\n",
      "Ep 90: Batch #167 - Loss: 1.024072527885437\n",
      "Ep 90: Batch #168 - Loss: 0.8024039268493652\n",
      "Ep 90: Batch #169 - Loss: 0.7548811435699463\n",
      "Ep 90: Batch #170 - Loss: 0.7534319758415222\n",
      "Ep 90: Batch #171 - Loss: 0.7235094308853149\n",
      "Ep 90: Batch #172 - Loss: 0.6008449792861938\n",
      "Ep 90: Batch #173 - Loss: 1.114851474761963\n",
      "Ep 90: Batch #174 - Loss: 0.5431705713272095\n",
      "Ep 90: Batch #175 - Loss: 0.741572916507721\n",
      "Ep 90: Batch #176 - Loss: 1.0797059535980225\n",
      "Ep 90: Batch #177 - Loss: 0.7943279147148132\n",
      "Ep 90: Batch #178 - Loss: 0.7132646441459656\n",
      "Ep 90: Batch #179 - Loss: 0.8819930553436279\n",
      "Ep 90: Batch #180 - Loss: 0.791417121887207\n",
      "Ep 90: Batch #181 - Loss: 0.9232295155525208\n",
      "Ep 90: Batch #182 - Loss: 0.7229359745979309\n",
      "Ep 90: Batch #183 - Loss: 0.7206606268882751\n",
      "Ep 90: Batch #184 - Loss: 1.0155080556869507\n",
      "Ep 90: Batch #185 - Loss: 0.7103838324546814\n",
      "Ep 90: Batch #186 - Loss: 0.8965892791748047\n",
      "Ep 90: Batch #187 - Loss: 1.0960370302200317\n",
      "Ep 90: Batch #188 - Loss: 1.2893476486206055\n",
      "Ep 90: Batch #189 - Loss: 0.6665706634521484\n",
      "Ep 90: Batch #190 - Loss: 0.6915741562843323\n",
      "Ep 90: Batch #191 - Loss: 0.9932166934013367\n",
      "Ep 90: Batch #192 - Loss: 0.6371328234672546\n",
      "Ep 90: Batch #193 - Loss: 0.6933299899101257\n",
      "Ep 90: Batch #194 - Loss: 0.650353193283081\n",
      "Ep 90: Batch #195 - Loss: 0.9233233332633972\n",
      "Ep 90: Batch #196 - Loss: 0.8081542253494263\n",
      "Ep 90: Batch #197 - Loss: 0.8390936851501465\n",
      "Ep 90: Batch #198 - Loss: 0.6312084197998047\n",
      "Ep 90: Batch #199 - Loss: 0.8068203330039978\n",
      "Ep 91: Batch #0 - Loss: 0.7354211807250977\n",
      "Ep 91: Batch #1 - Loss: 0.8180326819419861\n",
      "Ep 91: Batch #2 - Loss: 0.9629611372947693\n",
      "Ep 91: Batch #3 - Loss: 0.8150354623794556\n",
      "Ep 91: Batch #4 - Loss: 0.7360266447067261\n",
      "Ep 91: Batch #5 - Loss: 0.6278741955757141\n",
      "Ep 91: Batch #6 - Loss: 0.8269375562667847\n",
      "Ep 91: Batch #7 - Loss: 0.6599500179290771\n",
      "Ep 91: Batch #8 - Loss: 0.6878206729888916\n",
      "Ep 91: Batch #9 - Loss: 1.3148167133331299\n",
      "Ep 91: Batch #10 - Loss: 0.950122594833374\n",
      "Ep 91: Batch #11 - Loss: 0.6289103627204895\n",
      "Ep 91: Batch #12 - Loss: 1.4949886798858643\n",
      "Ep 91: Batch #13 - Loss: 0.6149382591247559\n",
      "Ep 91: Batch #14 - Loss: 0.6862316727638245\n",
      "Ep 91: Batch #15 - Loss: 1.1644850969314575\n",
      "Ep 91: Batch #16 - Loss: 1.191451907157898\n",
      "Ep 91: Batch #17 - Loss: 0.824063777923584\n",
      "Ep 91: Batch #18 - Loss: 0.9053300619125366\n",
      "Ep 91: Batch #19 - Loss: 0.6330773234367371\n",
      "Ep 91: Batch #20 - Loss: 0.6131182909011841\n",
      "Ep 91: Batch #21 - Loss: 1.158165693283081\n",
      "Ep 91: Batch #22 - Loss: 0.684741199016571\n",
      "Ep 91: Batch #23 - Loss: 0.6926946640014648\n",
      "Ep 91: Batch #24 - Loss: 0.7813897728919983\n",
      "Ep 91: Batch #25 - Loss: 0.6692255139350891\n",
      "Ep 91: Batch #26 - Loss: 0.6797412633895874\n",
      "Ep 91: Batch #27 - Loss: 1.2732864618301392\n",
      "Ep 91: Batch #28 - Loss: 0.8223534226417542\n",
      "Ep 91: Batch #29 - Loss: 0.8322082757949829\n",
      "Ep 91: Batch #30 - Loss: 1.136910080909729\n",
      "Ep 91: Batch #31 - Loss: 0.634153425693512\n",
      "Ep 91: Batch #32 - Loss: 0.697542667388916\n",
      "Ep 91: Batch #33 - Loss: 0.761371910572052\n",
      "Ep 91: Batch #34 - Loss: 0.7356013655662537\n",
      "Ep 91: Batch #35 - Loss: 0.883688747882843\n",
      "Ep 91: Batch #36 - Loss: 0.6552695035934448\n",
      "Ep 91: Batch #37 - Loss: 1.0877975225448608\n",
      "Ep 91: Batch #38 - Loss: 0.6892457008361816\n",
      "Ep 91: Batch #39 - Loss: 0.7757941484451294\n",
      "Ep 91: Batch #40 - Loss: 0.7265895009040833\n",
      "Ep 91: Batch #41 - Loss: 0.6823274493217468\n",
      "Ep 91: Batch #42 - Loss: 0.6769139170646667\n",
      "Ep 91: Batch #43 - Loss: 0.7412452101707458\n",
      "Ep 91: Batch #44 - Loss: 0.7289362549781799\n",
      "Ep 91: Batch #45 - Loss: 0.5901138186454773\n",
      "Ep 91: Batch #46 - Loss: 0.771037220954895\n",
      "Ep 91: Batch #47 - Loss: 0.8864709734916687\n",
      "Ep 91: Batch #48 - Loss: 1.2884633541107178\n",
      "Ep 91: Batch #49 - Loss: 0.9423182606697083\n",
      "Ep 91: Batch #50 - Loss: 0.6691164374351501\n",
      "Ep 91: Batch #51 - Loss: 0.9204679131507874\n",
      "Ep 91: Batch #52 - Loss: 0.7484397888183594\n",
      "Ep 91: Batch #53 - Loss: 0.7685738801956177\n",
      "Ep 91: Batch #54 - Loss: 0.6604750752449036\n",
      "Ep 91: Batch #55 - Loss: 0.7023450136184692\n",
      "Ep 91: Batch #56 - Loss: 1.1801378726959229\n",
      "Ep 91: Batch #57 - Loss: 0.7852750420570374\n",
      "Ep 91: Batch #58 - Loss: 0.926597535610199\n",
      "Ep 91: Batch #59 - Loss: 0.6448262333869934\n",
      "Ep 91: Batch #60 - Loss: 1.2375808954238892\n",
      "Ep 91: Batch #61 - Loss: 0.5992047190666199\n",
      "Ep 91: Batch #62 - Loss: 0.675083339214325\n",
      "Ep 91: Batch #63 - Loss: 0.9396629333496094\n",
      "Ep 91: Batch #64 - Loss: 9.348618507385254\n",
      "Ep 91: Batch #65 - Loss: 0.573803722858429\n",
      "Ep 91: Batch #66 - Loss: 0.7414894700050354\n",
      "Ep 91: Batch #67 - Loss: 0.8578523993492126\n",
      "Ep 91: Batch #68 - Loss: 0.8428922891616821\n",
      "Ep 91: Batch #69 - Loss: 0.6995344161987305\n",
      "Ep 91: Batch #70 - Loss: 0.7165169715881348\n",
      "Ep 91: Batch #71 - Loss: 0.6389066576957703\n",
      "Ep 91: Batch #72 - Loss: 0.7971775531768799\n",
      "Ep 91: Batch #73 - Loss: 0.8349781036376953\n",
      "Ep 91: Batch #74 - Loss: 0.6850751042366028\n",
      "Ep 91: Batch #75 - Loss: 0.7242773175239563\n",
      "Ep 91: Batch #76 - Loss: 1.0405248403549194\n",
      "Ep 91: Batch #77 - Loss: 0.6822274923324585\n",
      "Ep 91: Batch #78 - Loss: 1.0803574323654175\n",
      "Ep 91: Batch #79 - Loss: 0.5859454274177551\n",
      "Ep 91: Batch #80 - Loss: 0.796157956123352\n",
      "Ep 91: Batch #81 - Loss: 1.624712347984314\n",
      "Ep 91: Batch #82 - Loss: 0.8221690654754639\n",
      "Ep 91: Batch #83 - Loss: 1.6938848495483398\n",
      "Ep 91: Batch #84 - Loss: 0.6670917272567749\n",
      "Ep 91: Batch #85 - Loss: 0.9224162101745605\n",
      "Ep 91: Batch #86 - Loss: 0.6558406949043274\n",
      "Ep 91: Batch #87 - Loss: 0.666821300983429\n",
      "Ep 91: Batch #88 - Loss: 0.7480397820472717\n",
      "Ep 91: Batch #89 - Loss: 0.8480291366577148\n",
      "Ep 91: Batch #90 - Loss: 1.0792863368988037\n",
      "Ep 91: Batch #91 - Loss: 0.7438237071037292\n",
      "Ep 91: Batch #92 - Loss: 0.9636591672897339\n",
      "Ep 91: Batch #93 - Loss: 0.9477918148040771\n",
      "Ep 91: Batch #94 - Loss: 0.9794846177101135\n",
      "Ep 91: Batch #95 - Loss: 0.8648308515548706\n",
      "Ep 91: Batch #96 - Loss: 0.8498917818069458\n",
      "Ep 91: Batch #97 - Loss: 0.6798765063285828\n",
      "Ep 91: Batch #98 - Loss: 0.6898801922798157\n",
      "Ep 91: Batch #99 - Loss: 0.9004019498825073\n",
      "Ep 91: Batch #100 - Loss: 0.6315772533416748\n",
      "Ep 91: Batch #101 - Loss: 0.9931599497795105\n",
      "Ep 91: Batch #102 - Loss: 0.7305709719657898\n",
      "Ep 91: Batch #103 - Loss: 0.7401098012924194\n",
      "Ep 91: Batch #104 - Loss: 0.751067042350769\n",
      "Ep 91: Batch #105 - Loss: 0.9667620062828064\n",
      "Ep 91: Batch #106 - Loss: 0.7153238654136658\n",
      "Ep 91: Batch #107 - Loss: 0.7074334025382996\n",
      "Ep 91: Batch #108 - Loss: 0.9725481271743774\n",
      "Ep 91: Batch #109 - Loss: 0.7145591974258423\n",
      "Ep 91: Batch #110 - Loss: 0.8516916632652283\n",
      "Ep 91: Batch #111 - Loss: 1.3034030199050903\n",
      "Ep 91: Batch #112 - Loss: 0.9790006279945374\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 91: Batch #113 - Loss: 0.7653391361236572\n",
      "Ep 91: Batch #114 - Loss: 0.8396114110946655\n",
      "Ep 91: Batch #115 - Loss: 1.0306047201156616\n",
      "Ep 91: Batch #116 - Loss: 0.6007001399993896\n",
      "Ep 91: Batch #117 - Loss: 0.8221558332443237\n",
      "Ep 91: Batch #118 - Loss: 0.5068478584289551\n",
      "Model saved in file: ./weights_autoencoder_low_LR/model_e91b118_1516651281.0987332.ckpt\n",
      "Ep 91: Batch #119 - Loss: 0.9653580188751221\n",
      "Ep 91: Batch #120 - Loss: 0.7524755001068115\n",
      "Ep 91: Batch #121 - Loss: 0.6397045254707336\n",
      "Ep 91: Batch #122 - Loss: 0.7744653224945068\n",
      "Ep 91: Batch #123 - Loss: 0.7798755168914795\n",
      "Ep 91: Batch #124 - Loss: 0.6257898211479187\n",
      "Ep 91: Batch #125 - Loss: 2.6426689624786377\n",
      "Ep 91: Batch #126 - Loss: 1.158137559890747\n",
      "Ep 91: Batch #127 - Loss: 0.692719578742981\n",
      "Ep 91: Batch #128 - Loss: 1.0257562398910522\n",
      "Ep 91: Batch #129 - Loss: 0.7809945940971375\n",
      "Ep 91: Batch #130 - Loss: 0.6774031519889832\n",
      "Ep 91: Batch #131 - Loss: 0.9206748008728027\n",
      "Ep 91: Batch #132 - Loss: 0.7700768709182739\n",
      "Ep 91: Batch #133 - Loss: 0.7613704204559326\n",
      "Ep 91: Batch #134 - Loss: 0.717913806438446\n",
      "Ep 91: Batch #135 - Loss: 0.9031031131744385\n",
      "Ep 91: Batch #136 - Loss: 1.1114146709442139\n",
      "Ep 91: Batch #137 - Loss: 0.8979416489601135\n",
      "Ep 91: Batch #138 - Loss: 1.0018177032470703\n",
      "Ep 91: Batch #139 - Loss: 0.8367540240287781\n",
      "Ep 91: Batch #140 - Loss: 0.9900273084640503\n",
      "Ep 91: Batch #141 - Loss: 1.2849547863006592\n",
      "Ep 91: Batch #142 - Loss: 0.7427605390548706\n",
      "Ep 91: Batch #143 - Loss: 0.8937662839889526\n",
      "Ep 91: Batch #144 - Loss: 0.6774047017097473\n",
      "Ep 91: Batch #145 - Loss: 0.6373457312583923\n",
      "Ep 91: Batch #146 - Loss: 0.836181640625\n",
      "Ep 91: Batch #147 - Loss: 0.7993413209915161\n",
      "Ep 91: Batch #148 - Loss: 0.9080007076263428\n",
      "Ep 91: Batch #149 - Loss: 0.7951627373695374\n",
      "Ep 91: Batch #150 - Loss: 0.8322577476501465\n",
      "Ep 91: Batch #151 - Loss: 0.6910715699195862\n",
      "Ep 91: Batch #152 - Loss: 0.7027340531349182\n",
      "Ep 91: Batch #153 - Loss: 1.032712697982788\n",
      "Ep 91: Batch #154 - Loss: 0.7143220901489258\n",
      "Ep 91: Batch #155 - Loss: 0.7818776965141296\n",
      "Ep 91: Batch #156 - Loss: 0.9582362771034241\n",
      "Ep 91: Batch #157 - Loss: 0.7094493508338928\n",
      "Ep 91: Batch #158 - Loss: 0.7680068016052246\n",
      "Ep 91: Batch #159 - Loss: 0.7493489980697632\n",
      "Ep 91: Batch #160 - Loss: 0.8579280972480774\n",
      "Ep 91: Batch #161 - Loss: 0.7651453614234924\n",
      "Ep 91: Batch #162 - Loss: 0.875163197517395\n",
      "Ep 91: Batch #163 - Loss: 0.8784844875335693\n",
      "Ep 91: Batch #164 - Loss: 0.7316151857376099\n",
      "Ep 91: Batch #165 - Loss: 1.4471046924591064\n",
      "Ep 91: Batch #166 - Loss: 0.6318883299827576\n",
      "Ep 91: Batch #167 - Loss: 1.0228822231292725\n",
      "Ep 91: Batch #168 - Loss: 0.8012944459915161\n",
      "Ep 91: Batch #169 - Loss: 0.7540293335914612\n",
      "Ep 91: Batch #170 - Loss: 0.7524809241294861\n",
      "Ep 91: Batch #171 - Loss: 0.7224542498588562\n",
      "Ep 91: Batch #172 - Loss: 0.6002900004386902\n",
      "Ep 91: Batch #173 - Loss: 1.1133521795272827\n",
      "Ep 91: Batch #174 - Loss: 0.5425174832344055\n",
      "Ep 91: Batch #175 - Loss: 0.7408946752548218\n",
      "Ep 91: Batch #176 - Loss: 1.0783979892730713\n",
      "Ep 91: Batch #177 - Loss: 0.7933226823806763\n",
      "Ep 91: Batch #178 - Loss: 0.7123410701751709\n",
      "Ep 91: Batch #179 - Loss: 0.880901575088501\n",
      "Ep 91: Batch #180 - Loss: 0.7902312278747559\n",
      "Ep 91: Batch #181 - Loss: 0.9219813346862793\n",
      "Ep 91: Batch #182 - Loss: 0.7221357822418213\n",
      "Ep 91: Batch #183 - Loss: 0.719896674156189\n",
      "Ep 91: Batch #184 - Loss: 1.0144710540771484\n",
      "Ep 91: Batch #185 - Loss: 0.7094966173171997\n",
      "Ep 91: Batch #186 - Loss: 0.895257830619812\n",
      "Ep 91: Batch #187 - Loss: 1.0946725606918335\n",
      "Ep 91: Batch #188 - Loss: 1.2880859375\n",
      "Ep 91: Batch #189 - Loss: 0.6659668684005737\n",
      "Ep 91: Batch #190 - Loss: 0.6907643675804138\n",
      "Ep 91: Batch #191 - Loss: 0.991847038269043\n",
      "Ep 91: Batch #192 - Loss: 0.6365469098091125\n",
      "Ep 91: Batch #193 - Loss: 0.6925099492073059\n",
      "Ep 91: Batch #194 - Loss: 0.6495296955108643\n",
      "Ep 91: Batch #195 - Loss: 0.9221905469894409\n",
      "Ep 91: Batch #196 - Loss: 0.8071014285087585\n",
      "Ep 91: Batch #197 - Loss: 0.8379250168800354\n",
      "Ep 91: Batch #198 - Loss: 0.6303653120994568\n",
      "Ep 91: Batch #199 - Loss: 0.8057206273078918\n",
      "Ep 92: Batch #0 - Loss: 0.7344255447387695\n",
      "Ep 92: Batch #1 - Loss: 0.8170089721679688\n",
      "Ep 92: Batch #2 - Loss: 0.9621589779853821\n",
      "Ep 92: Batch #3 - Loss: 0.814073383808136\n",
      "Ep 92: Batch #4 - Loss: 0.7350658178329468\n",
      "Ep 92: Batch #5 - Loss: 0.6271751523017883\n",
      "Ep 92: Batch #6 - Loss: 0.8260106444358826\n",
      "Ep 92: Batch #7 - Loss: 0.659227728843689\n",
      "Ep 92: Batch #8 - Loss: 0.6869423985481262\n",
      "Ep 92: Batch #9 - Loss: 1.313125491142273\n",
      "Ep 92: Batch #10 - Loss: 0.9490126371383667\n",
      "Ep 92: Batch #11 - Loss: 0.6280909180641174\n",
      "Ep 92: Batch #12 - Loss: 1.4938172101974487\n",
      "Ep 92: Batch #13 - Loss: 0.6143470406532288\n",
      "Ep 92: Batch #14 - Loss: 0.6855065226554871\n",
      "Ep 92: Batch #15 - Loss: 1.163068413734436\n",
      "Ep 92: Batch #16 - Loss: 1.189815878868103\n",
      "Ep 92: Batch #17 - Loss: 0.8230399489402771\n",
      "Ep 92: Batch #18 - Loss: 0.904641330242157\n",
      "Ep 92: Batch #19 - Loss: 0.6324536800384521\n",
      "Ep 92: Batch #20 - Loss: 0.6123591661453247\n",
      "Ep 92: Batch #21 - Loss: 1.1570757627487183\n",
      "Ep 92: Batch #22 - Loss: 0.6839355230331421\n",
      "Ep 92: Batch #23 - Loss: 0.6917207837104797\n",
      "Ep 92: Batch #24 - Loss: 0.7805719971656799\n",
      "Ep 92: Batch #25 - Loss: 0.668433427810669\n",
      "Ep 92: Batch #26 - Loss: 0.6788495182991028\n",
      "Ep 92: Batch #27 - Loss: 1.271764874458313\n",
      "Ep 92: Batch #28 - Loss: 0.8214960098266602\n",
      "Ep 92: Batch #29 - Loss: 0.8311266899108887\n",
      "Ep 92: Batch #30 - Loss: 1.1356030702590942\n",
      "Ep 92: Batch #31 - Loss: 0.6334611773490906\n",
      "Ep 92: Batch #32 - Loss: 0.6966665983200073\n",
      "Ep 92: Batch #33 - Loss: 0.7605485916137695\n",
      "Ep 92: Batch #34 - Loss: 0.7347164750099182\n",
      "Ep 92: Batch #35 - Loss: 0.8825526833534241\n",
      "Ep 92: Batch #36 - Loss: 0.6544140577316284\n",
      "Ep 92: Batch #37 - Loss: 1.0868631601333618\n",
      "Ep 92: Batch #38 - Loss: 0.6881790161132812\n",
      "Ep 92: Batch #39 - Loss: 0.7749545574188232\n",
      "Ep 92: Batch #40 - Loss: 0.7257352471351624\n",
      "Ep 92: Batch #41 - Loss: 0.6813659071922302\n",
      "Ep 92: Batch #42 - Loss: 0.6761205196380615\n",
      "Ep 92: Batch #43 - Loss: 0.7404289245605469\n",
      "Ep 92: Batch #44 - Loss: 0.727870762348175\n",
      "Ep 92: Batch #45 - Loss: 0.5893810987472534\n",
      "Ep 92: Batch #46 - Loss: 0.769952118396759\n",
      "Ep 92: Batch #47 - Loss: 0.8850833177566528\n",
      "Ep 92: Batch #48 - Loss: 1.2871828079223633\n",
      "Ep 92: Batch #49 - Loss: 0.9410252571105957\n",
      "Ep 92: Batch #50 - Loss: 0.6684263944625854\n",
      "Ep 92: Batch #51 - Loss: 0.9190852046012878\n",
      "Ep 92: Batch #52 - Loss: 0.7475760579109192\n",
      "Ep 92: Batch #53 - Loss: 0.7675623893737793\n",
      "Ep 92: Batch #54 - Loss: 0.6596114635467529\n",
      "Ep 92: Batch #55 - Loss: 0.7014021277427673\n",
      "Ep 92: Batch #56 - Loss: 1.1785691976547241\n",
      "Ep 92: Batch #57 - Loss: 0.7840511798858643\n",
      "Ep 92: Batch #58 - Loss: 0.9253152012825012\n",
      "Ep 92: Batch #59 - Loss: 0.644159197807312\n",
      "Ep 92: Batch #60 - Loss: 1.23618745803833\n",
      "Ep 92: Batch #61 - Loss: 0.598550021648407\n",
      "Ep 92: Batch #62 - Loss: 0.6742945313453674\n",
      "Ep 92: Batch #63 - Loss: 0.938514232635498\n",
      "Ep 92: Batch #64 - Loss: 9.347037315368652\n",
      "Ep 92: Batch #65 - Loss: 0.5730947852134705\n",
      "Ep 92: Batch #66 - Loss: 0.740533173084259\n",
      "Ep 92: Batch #67 - Loss: 0.8569713234901428\n",
      "Ep 92: Batch #68 - Loss: 0.8416725993156433\n",
      "Ep 92: Batch #69 - Loss: 0.6986965537071228\n",
      "Ep 92: Batch #70 - Loss: 0.7153932452201843\n",
      "Ep 92: Batch #71 - Loss: 0.638080894947052\n",
      "Ep 92: Batch #72 - Loss: 0.7960835099220276\n",
      "Ep 92: Batch #73 - Loss: 0.8337959051132202\n",
      "Ep 92: Batch #74 - Loss: 0.6840623617172241\n",
      "Ep 92: Batch #75 - Loss: 0.723497211933136\n",
      "Ep 92: Batch #76 - Loss: 1.0394923686981201\n",
      "Ep 92: Batch #77 - Loss: 0.6813037395477295\n",
      "Ep 92: Batch #78 - Loss: 1.0788627862930298\n",
      "Ep 92: Batch #79 - Loss: 0.5852336883544922\n",
      "Ep 92: Batch #80 - Loss: 0.794983446598053\n",
      "Ep 92: Batch #81 - Loss: 1.6237462759017944\n",
      "Ep 92: Batch #82 - Loss: 0.8212552666664124\n",
      "Ep 92: Batch #83 - Loss: 1.6931782960891724\n",
      "Ep 92: Batch #84 - Loss: 0.6662921905517578\n",
      "Ep 92: Batch #85 - Loss: 0.9214357137680054\n",
      "Ep 92: Batch #86 - Loss: 0.6549031138420105\n",
      "Ep 92: Batch #87 - Loss: 0.6659942865371704\n",
      "Ep 92: Batch #88 - Loss: 0.7471063733100891\n",
      "Ep 92: Batch #89 - Loss: 0.8473520278930664\n",
      "Ep 92: Batch #90 - Loss: 1.0779907703399658\n",
      "Ep 92: Batch #91 - Loss: 0.7428115606307983\n",
      "Ep 92: Batch #92 - Loss: 0.9624844193458557\n",
      "Ep 92: Batch #93 - Loss: 0.9462436437606812\n",
      "Ep 92: Batch #94 - Loss: 0.9781608581542969\n",
      "Ep 92: Batch #95 - Loss: 0.8638074994087219\n",
      "Ep 92: Batch #96 - Loss: 0.8489016890525818\n",
      "Ep 92: Batch #97 - Loss: 0.6790049076080322\n",
      "Ep 92: Batch #98 - Loss: 0.6890133023262024\n",
      "Ep 92: Batch #99 - Loss: 0.899384081363678\n",
      "Ep 92: Batch #100 - Loss: 0.6307573318481445\n",
      "Ep 92: Batch #101 - Loss: 0.9921827912330627\n",
      "Ep 92: Batch #102 - Loss: 0.7296051383018494\n",
      "Ep 92: Batch #103 - Loss: 0.7392371892929077\n",
      "Ep 92: Batch #104 - Loss: 0.7501541376113892\n",
      "Ep 92: Batch #105 - Loss: 0.9657174348831177\n",
      "Ep 92: Batch #106 - Loss: 0.714547336101532\n",
      "Ep 92: Batch #107 - Loss: 0.7065218091011047\n",
      "Ep 92: Batch #108 - Loss: 0.97150719165802\n",
      "Ep 92: Batch #109 - Loss: 0.7136797308921814\n",
      "Ep 92: Batch #110 - Loss: 0.8504832983016968\n",
      "Ep 92: Batch #111 - Loss: 1.3019814491271973\n",
      "Ep 92: Batch #112 - Loss: 0.977745771408081\n",
      "Ep 92: Batch #113 - Loss: 0.7643709182739258\n",
      "Ep 92: Batch #114 - Loss: 0.8384855389595032\n",
      "Ep 92: Batch #115 - Loss: 1.0294796228408813\n",
      "Ep 92: Batch #116 - Loss: 0.6000781059265137\n",
      "Ep 92: Batch #117 - Loss: 0.8212472200393677\n",
      "Ep 92: Batch #118 - Loss: 0.5061778426170349\n",
      "Model saved in file: ./weights_autoencoder_low_LR/model_e92b118_1516651281.2271564.ckpt\n",
      "Ep 92: Batch #119 - Loss: 0.96417635679245\n",
      "Ep 92: Batch #120 - Loss: 0.7516003251075745\n",
      "Ep 92: Batch #121 - Loss: 0.6388778686523438\n",
      "Ep 92: Batch #122 - Loss: 0.7735524773597717\n",
      "Ep 92: Batch #123 - Loss: 0.778960108757019\n",
      "Ep 92: Batch #124 - Loss: 0.6251075863838196\n",
      "Ep 92: Batch #125 - Loss: 2.6412603855133057\n",
      "Ep 92: Batch #126 - Loss: 1.1569180488586426\n",
      "Ep 92: Batch #127 - Loss: 0.691625714302063\n",
      "Ep 92: Batch #128 - Loss: 1.024322748184204\n",
      "Ep 92: Batch #129 - Loss: 0.7799474000930786\n",
      "Ep 92: Batch #130 - Loss: 0.6765612959861755\n",
      "Ep 92: Batch #131 - Loss: 0.9193106293678284\n",
      "Ep 92: Batch #132 - Loss: 0.7691635489463806\n",
      "Ep 92: Batch #133 - Loss: 0.7603121995925903\n",
      "Ep 92: Batch #134 - Loss: 0.7170557975769043\n",
      "Ep 92: Batch #135 - Loss: 0.902045726776123\n",
      "Ep 92: Batch #136 - Loss: 1.110182762145996\n",
      "Ep 92: Batch #137 - Loss: 0.896731972694397\n",
      "Ep 92: Batch #138 - Loss: 1.0004569292068481\n",
      "Ep 92: Batch #139 - Loss: 0.8355526328086853\n",
      "Ep 92: Batch #140 - Loss: 0.9889949560165405\n",
      "Ep 92: Batch #141 - Loss: 1.283631443977356\n",
      "Ep 92: Batch #142 - Loss: 0.7418011426925659\n",
      "Ep 92: Batch #143 - Loss: 0.8925127387046814\n",
      "Ep 92: Batch #144 - Loss: 0.6766713261604309\n",
      "Ep 92: Batch #145 - Loss: 0.6366381645202637\n",
      "Ep 92: Batch #146 - Loss: 0.8353980779647827\n",
      "Ep 92: Batch #147 - Loss: 0.7983101606369019\n",
      "Ep 92: Batch #148 - Loss: 0.906745970249176\n",
      "Ep 92: Batch #149 - Loss: 0.7941433191299438\n",
      "Ep 92: Batch #150 - Loss: 0.8314339518547058\n",
      "Ep 92: Batch #151 - Loss: 0.6904343366622925\n",
      "Ep 92: Batch #152 - Loss: 0.7020962834358215\n",
      "Ep 92: Batch #153 - Loss: 1.0313892364501953\n",
      "Ep 92: Batch #154 - Loss: 0.7134934067726135\n",
      "Ep 92: Batch #155 - Loss: 0.780980110168457\n",
      "Ep 92: Batch #156 - Loss: 0.9571594595909119\n",
      "Ep 92: Batch #157 - Loss: 0.7085196375846863\n",
      "Ep 92: Batch #158 - Loss: 0.7673512101173401\n",
      "Ep 92: Batch #159 - Loss: 0.748264729976654\n",
      "Ep 92: Batch #160 - Loss: 0.8570969104766846\n",
      "Ep 92: Batch #161 - Loss: 0.7643172740936279\n",
      "Ep 92: Batch #162 - Loss: 0.8741002082824707\n",
      "Ep 92: Batch #163 - Loss: 0.8774840831756592\n",
      "Ep 92: Batch #164 - Loss: 0.7306623458862305\n",
      "Ep 92: Batch #165 - Loss: 1.4461536407470703\n",
      "Ep 92: Batch #166 - Loss: 0.6310285329818726\n",
      "Ep 92: Batch #167 - Loss: 1.0217007398605347\n",
      "Ep 92: Batch #168 - Loss: 0.8001962304115295\n",
      "Ep 92: Batch #169 - Loss: 0.7531824707984924\n",
      "Ep 92: Batch #170 - Loss: 0.7515400052070618\n",
      "Ep 92: Batch #171 - Loss: 0.721405565738678\n",
      "Ep 92: Batch #172 - Loss: 0.5997422337532043\n",
      "Ep 92: Batch #173 - Loss: 1.1118654012680054\n",
      "Ep 92: Batch #174 - Loss: 0.5418729782104492\n",
      "Ep 92: Batch #175 - Loss: 0.7402195930480957\n",
      "Ep 92: Batch #176 - Loss: 1.077101230621338\n",
      "Ep 92: Batch #177 - Loss: 0.792313277721405\n",
      "Ep 92: Batch #178 - Loss: 0.7114238142967224\n",
      "Ep 92: Batch #179 - Loss: 0.8798195123672485\n",
      "Ep 92: Batch #180 - Loss: 0.7890560626983643\n",
      "Ep 92: Batch #181 - Loss: 0.9207403659820557\n",
      "Ep 92: Batch #182 - Loss: 0.7213450074195862\n",
      "Ep 92: Batch #183 - Loss: 0.7191311717033386\n",
      "Ep 92: Batch #184 - Loss: 1.0134453773498535\n",
      "Ep 92: Batch #185 - Loss: 0.7086151838302612\n",
      "Ep 92: Batch #186 - Loss: 0.8939392566680908\n",
      "Ep 92: Batch #187 - Loss: 1.0933221578598022\n",
      "Ep 92: Batch #188 - Loss: 1.2868387699127197\n",
      "Ep 92: Batch #189 - Loss: 0.6653684973716736\n",
      "Ep 92: Batch #190 - Loss: 0.6899617314338684\n",
      "Ep 92: Batch #191 - Loss: 0.9904919266700745\n",
      "Ep 92: Batch #192 - Loss: 0.6359676718711853\n",
      "Ep 92: Batch #193 - Loss: 0.691699206829071\n",
      "Ep 92: Batch #194 - Loss: 0.6487181782722473\n",
      "Ep 92: Batch #195 - Loss: 0.9210672974586487\n",
      "Ep 92: Batch #196 - Loss: 0.8060581684112549\n",
      "Ep 92: Batch #197 - Loss: 0.8367687463760376\n",
      "Ep 92: Batch #198 - Loss: 0.6295333504676819\n",
      "Ep 92: Batch #199 - Loss: 0.804632842540741\n",
      "Ep 93: Batch #0 - Loss: 0.7334511876106262\n",
      "Ep 93: Batch #1 - Loss: 0.8159998655319214\n",
      "Ep 93: Batch #2 - Loss: 0.9613558650016785\n",
      "Ep 93: Batch #3 - Loss: 0.8131194710731506\n",
      "Ep 93: Batch #4 - Loss: 0.7341168522834778\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 93: Batch #5 - Loss: 0.6264885663986206\n",
      "Ep 93: Batch #6 - Loss: 0.8250919580459595\n",
      "Ep 93: Batch #7 - Loss: 0.6585155725479126\n",
      "Ep 93: Batch #8 - Loss: 0.6860697269439697\n",
      "Ep 93: Batch #9 - Loss: 1.3114551305770874\n",
      "Ep 93: Batch #10 - Loss: 0.9479122161865234\n",
      "Ep 93: Batch #11 - Loss: 0.62727290391922\n",
      "Ep 93: Batch #12 - Loss: 1.4926562309265137\n",
      "Ep 93: Batch #13 - Loss: 0.6137653589248657\n",
      "Ep 93: Batch #14 - Loss: 0.6847891211509705\n",
      "Ep 93: Batch #15 - Loss: 1.1616629362106323\n",
      "Ep 93: Batch #16 - Loss: 1.1881933212280273\n",
      "Ep 93: Batch #17 - Loss: 0.8220254182815552\n",
      "Ep 93: Batch #18 - Loss: 0.903956949710846\n",
      "Ep 93: Batch #19 - Loss: 0.6318368911743164\n",
      "Ep 93: Batch #20 - Loss: 0.6116099953651428\n",
      "Ep 93: Batch #21 - Loss: 1.1559934616088867\n",
      "Ep 93: Batch #22 - Loss: 0.6831387281417847\n",
      "Ep 93: Batch #23 - Loss: 0.6907528042793274\n",
      "Ep 93: Batch #24 - Loss: 0.7797606587409973\n",
      "Ep 93: Batch #25 - Loss: 0.6676493883132935\n",
      "Ep 93: Batch #26 - Loss: 0.6779652833938599\n",
      "Ep 93: Batch #27 - Loss: 1.270255208015442\n",
      "Ep 93: Batch #28 - Loss: 0.8206456303596497\n",
      "Ep 93: Batch #29 - Loss: 0.8300577402114868\n",
      "Ep 93: Batch #30 - Loss: 1.1343090534210205\n",
      "Ep 93: Batch #31 - Loss: 0.6327816247940063\n",
      "Ep 93: Batch #32 - Loss: 0.6957994699478149\n",
      "Ep 93: Batch #33 - Loss: 0.7597343325614929\n",
      "Ep 93: Batch #34 - Loss: 0.7338445782661438\n",
      "Ep 93: Batch #35 - Loss: 0.8814314007759094\n",
      "Ep 93: Batch #36 - Loss: 0.6535657048225403\n",
      "Ep 93: Batch #37 - Loss: 1.085939645767212\n",
      "Ep 93: Batch #38 - Loss: 0.6871269941329956\n",
      "Ep 93: Batch #39 - Loss: 0.7741199731826782\n",
      "Ep 93: Batch #40 - Loss: 0.724889874458313\n",
      "Ep 93: Batch #41 - Loss: 0.6804209351539612\n",
      "Ep 93: Batch #42 - Loss: 0.6753350496292114\n",
      "Ep 93: Batch #43 - Loss: 0.7396257519721985\n",
      "Ep 93: Batch #44 - Loss: 0.7268174886703491\n",
      "Ep 93: Batch #45 - Loss: 0.5886557102203369\n",
      "Ep 93: Batch #46 - Loss: 0.7688748836517334\n",
      "Ep 93: Batch #47 - Loss: 0.8837047815322876\n",
      "Ep 93: Batch #48 - Loss: 1.2859141826629639\n",
      "Ep 93: Batch #49 - Loss: 0.9397437572479248\n",
      "Ep 93: Batch #50 - Loss: 0.6677388548851013\n",
      "Ep 93: Batch #51 - Loss: 0.9177167415618896\n",
      "Ep 93: Batch #52 - Loss: 0.7467203140258789\n",
      "Ep 93: Batch #53 - Loss: 0.7665581703186035\n",
      "Ep 93: Batch #54 - Loss: 0.6587541699409485\n",
      "Ep 93: Batch #55 - Loss: 0.7004659175872803\n",
      "Ep 93: Batch #56 - Loss: 1.177013874053955\n",
      "Ep 93: Batch #57 - Loss: 0.7828373908996582\n",
      "Ep 93: Batch #58 - Loss: 0.9240455031394958\n",
      "Ep 93: Batch #59 - Loss: 0.6434979438781738\n",
      "Ep 93: Batch #60 - Loss: 1.2348134517669678\n",
      "Ep 93: Batch #61 - Loss: 0.5979042649269104\n",
      "Ep 93: Batch #62 - Loss: 0.6735148429870605\n",
      "Ep 93: Batch #63 - Loss: 0.9373672008514404\n",
      "Ep 93: Batch #64 - Loss: 9.345366477966309\n",
      "Ep 93: Batch #65 - Loss: 0.5723894834518433\n",
      "Ep 93: Batch #66 - Loss: 0.7395891547203064\n",
      "Ep 93: Batch #67 - Loss: 0.8561065196990967\n",
      "Ep 93: Batch #68 - Loss: 0.840472400188446\n",
      "Ep 93: Batch #69 - Loss: 0.6978669166564941\n",
      "Ep 93: Batch #70 - Loss: 0.7142767906188965\n",
      "Ep 93: Batch #71 - Loss: 0.6372652053833008\n",
      "Ep 93: Batch #72 - Loss: 0.7949941754341125\n",
      "Ep 93: Batch #73 - Loss: 0.8326137065887451\n",
      "Ep 93: Batch #74 - Loss: 0.683059573173523\n",
      "Ep 93: Batch #75 - Loss: 0.7227241396903992\n",
      "Ep 93: Batch #76 - Loss: 1.0384740829467773\n",
      "Ep 93: Batch #77 - Loss: 0.6803901791572571\n",
      "Ep 93: Batch #78 - Loss: 1.0773783922195435\n",
      "Ep 93: Batch #79 - Loss: 0.584534227848053\n",
      "Ep 93: Batch #80 - Loss: 0.7938172817230225\n",
      "Ep 93: Batch #81 - Loss: 1.6227948665618896\n",
      "Ep 93: Batch #82 - Loss: 0.820351243019104\n",
      "Ep 93: Batch #83 - Loss: 1.69248366355896\n",
      "Ep 93: Batch #84 - Loss: 0.665511965751648\n",
      "Ep 93: Batch #85 - Loss: 0.9204633831977844\n",
      "Ep 93: Batch #86 - Loss: 0.6539798378944397\n",
      "Ep 93: Batch #87 - Loss: 0.6651706695556641\n",
      "Ep 93: Batch #88 - Loss: 0.7461823225021362\n",
      "Ep 93: Batch #89 - Loss: 0.8466811776161194\n",
      "Ep 93: Batch #90 - Loss: 1.0766938924789429\n",
      "Ep 93: Batch #91 - Loss: 0.7418074011802673\n",
      "Ep 93: Batch #92 - Loss: 0.961322009563446\n",
      "Ep 93: Batch #93 - Loss: 0.9447018504142761\n",
      "Ep 93: Batch #94 - Loss: 0.9768453240394592\n",
      "Ep 93: Batch #95 - Loss: 0.8627967238426208\n",
      "Ep 93: Batch #96 - Loss: 0.8479142785072327\n",
      "Ep 93: Batch #97 - Loss: 0.6781355738639832\n",
      "Ep 93: Batch #98 - Loss: 0.6881534457206726\n",
      "Ep 93: Batch #99 - Loss: 0.8983771800994873\n",
      "Ep 93: Batch #100 - Loss: 0.6299487352371216\n",
      "Ep 93: Batch #101 - Loss: 0.9912102222442627\n",
      "Ep 93: Batch #102 - Loss: 0.7286432981491089\n",
      "Ep 93: Batch #103 - Loss: 0.7383738160133362\n",
      "Ep 93: Batch #104 - Loss: 0.7492511868476868\n",
      "Ep 93: Batch #105 - Loss: 0.964684009552002\n",
      "Ep 93: Batch #106 - Loss: 0.713776707649231\n",
      "Ep 93: Batch #107 - Loss: 0.7056195735931396\n",
      "Ep 93: Batch #108 - Loss: 0.9704787731170654\n",
      "Ep 93: Batch #109 - Loss: 0.7128044962882996\n",
      "Ep 93: Batch #110 - Loss: 0.8492836356163025\n",
      "Ep 93: Batch #111 - Loss: 1.3005690574645996\n",
      "Ep 93: Batch #112 - Loss: 0.9765049815177917\n",
      "Ep 93: Batch #113 - Loss: 0.7634071707725525\n",
      "Ep 93: Batch #114 - Loss: 0.8373741507530212\n",
      "Ep 93: Batch #115 - Loss: 1.0283647775650024\n",
      "Ep 93: Batch #116 - Loss: 0.5994597673416138\n",
      "Ep 93: Batch #117 - Loss: 0.8203453421592712\n",
      "Ep 93: Batch #118 - Loss: 0.5055137872695923\n",
      "Model saved in file: ./weights_autoencoder_low_LR/model_e93b118_1516651281.3634222.ckpt\n",
      "Ep 93: Batch #119 - Loss: 0.9630024433135986\n",
      "Ep 93: Batch #120 - Loss: 0.7507330775260925\n",
      "Ep 93: Batch #121 - Loss: 0.6380590200424194\n",
      "Ep 93: Batch #122 - Loss: 0.7726510763168335\n",
      "Ep 93: Batch #123 - Loss: 0.7780482769012451\n",
      "Ep 93: Batch #124 - Loss: 0.6244333386421204\n",
      "Ep 93: Batch #125 - Loss: 2.6398603916168213\n",
      "Ep 93: Batch #126 - Loss: 1.155709147453308\n",
      "Ep 93: Batch #127 - Loss: 0.6905393004417419\n",
      "Ep 93: Batch #128 - Loss: 1.0229068994522095\n",
      "Ep 93: Batch #129 - Loss: 0.7789093255996704\n",
      "Ep 93: Batch #130 - Loss: 0.6757233142852783\n",
      "Ep 93: Batch #131 - Loss: 0.9179601073265076\n",
      "Ep 93: Batch #132 - Loss: 0.768259584903717\n",
      "Ep 93: Batch #133 - Loss: 0.7592658400535583\n",
      "Ep 93: Batch #134 - Loss: 0.716210126876831\n",
      "Ep 93: Batch #135 - Loss: 0.9009944200515747\n",
      "Ep 93: Batch #136 - Loss: 1.1089634895324707\n",
      "Ep 93: Batch #137 - Loss: 0.8955270051956177\n",
      "Ep 93: Batch #138 - Loss: 0.9991106986999512\n",
      "Ep 93: Batch #139 - Loss: 0.8343601226806641\n",
      "Ep 93: Batch #140 - Loss: 0.9879724383354187\n",
      "Ep 93: Batch #141 - Loss: 1.2823171615600586\n",
      "Ep 93: Batch #142 - Loss: 0.7408474087715149\n",
      "Ep 93: Batch #143 - Loss: 0.8912637233734131\n",
      "Ep 93: Batch #144 - Loss: 0.6759452223777771\n",
      "Ep 93: Batch #145 - Loss: 0.635937511920929\n",
      "Ep 93: Batch #146 - Loss: 0.8346194624900818\n",
      "Ep 93: Batch #147 - Loss: 0.7972905039787292\n",
      "Ep 93: Batch #148 - Loss: 0.9055014848709106\n",
      "Ep 93: Batch #149 - Loss: 0.7931292653083801\n",
      "Ep 93: Batch #150 - Loss: 0.8306166529655457\n",
      "Ep 93: Batch #151 - Loss: 0.6898015141487122\n",
      "Ep 93: Batch #152 - Loss: 0.7014613747596741\n",
      "Ep 93: Batch #153 - Loss: 1.0300804376602173\n",
      "Ep 93: Batch #154 - Loss: 0.7126696109771729\n",
      "Ep 93: Batch #155 - Loss: 0.7800937294960022\n",
      "Ep 93: Batch #156 - Loss: 0.9560882449150085\n",
      "Ep 93: Batch #157 - Loss: 0.7076019048690796\n",
      "Ep 93: Batch #158 - Loss: 0.7666990756988525\n",
      "Ep 93: Batch #159 - Loss: 0.7471909523010254\n",
      "Ep 93: Batch #160 - Loss: 0.8562702536582947\n",
      "Ep 93: Batch #161 - Loss: 0.7635022401809692\n",
      "Ep 93: Batch #162 - Loss: 0.8730473518371582\n",
      "Ep 93: Batch #163 - Loss: 0.8764898777008057\n",
      "Ep 93: Batch #164 - Loss: 0.729719340801239\n",
      "Ep 93: Batch #165 - Loss: 1.445219874382019\n",
      "Ep 93: Batch #166 - Loss: 0.6301755905151367\n",
      "Ep 93: Batch #167 - Loss: 1.0205317735671997\n",
      "Ep 93: Batch #168 - Loss: 0.7991068959236145\n",
      "Ep 93: Batch #169 - Loss: 0.7523423433303833\n",
      "Ep 93: Batch #170 - Loss: 0.7506023049354553\n",
      "Ep 93: Batch #171 - Loss: 0.7203649282455444\n",
      "Ep 93: Batch #172 - Loss: 0.5991979837417603\n",
      "Ep 93: Batch #173 - Loss: 1.1104004383087158\n",
      "Ep 93: Batch #174 - Loss: 0.5412342548370361\n",
      "Ep 93: Batch #175 - Loss: 0.7395501732826233\n",
      "Ep 93: Batch #176 - Loss: 1.0758094787597656\n",
      "Ep 93: Batch #177 - Loss: 0.7913132309913635\n",
      "Ep 93: Batch #178 - Loss: 0.7105129957199097\n",
      "Ep 93: Batch #179 - Loss: 0.8787427544593811\n",
      "Ep 93: Batch #180 - Loss: 0.7878888249397278\n",
      "Ep 93: Batch #181 - Loss: 0.919514000415802\n",
      "Ep 93: Batch #182 - Loss: 0.7205653190612793\n",
      "Ep 93: Batch #183 - Loss: 0.7183727622032166\n",
      "Ep 93: Batch #184 - Loss: 1.01242995262146\n",
      "Ep 93: Batch #185 - Loss: 0.7077440023422241\n",
      "Ep 93: Batch #186 - Loss: 0.8926190137863159\n",
      "Ep 93: Batch #187 - Loss: 1.091982126235962\n",
      "Ep 93: Batch #188 - Loss: 1.2856062650680542\n",
      "Ep 93: Batch #189 - Loss: 0.6647751331329346\n",
      "Ep 93: Batch #190 - Loss: 0.6891621947288513\n",
      "Ep 93: Batch #191 - Loss: 0.989142656326294\n",
      "Ep 93: Batch #192 - Loss: 0.6353893280029297\n",
      "Ep 93: Batch #193 - Loss: 0.6908965706825256\n",
      "Ep 93: Batch #194 - Loss: 0.6479098200798035\n",
      "Ep 93: Batch #195 - Loss: 0.919951319694519\n",
      "Ep 93: Batch #196 - Loss: 0.8050243854522705\n",
      "Ep 93: Batch #197 - Loss: 0.8356232643127441\n",
      "Ep 93: Batch #198 - Loss: 0.6287185549736023\n",
      "Ep 93: Batch #199 - Loss: 0.8035548329353333\n",
      "Ep 94: Batch #0 - Loss: 0.7324841022491455\n",
      "Ep 94: Batch #1 - Loss: 0.8150107860565186\n",
      "Ep 94: Batch #2 - Loss: 0.9605563282966614\n",
      "Ep 94: Batch #3 - Loss: 0.8121734261512756\n",
      "Ep 94: Batch #4 - Loss: 0.7331745624542236\n",
      "Ep 94: Batch #5 - Loss: 0.6258146166801453\n",
      "Ep 94: Batch #6 - Loss: 0.8241806030273438\n",
      "Ep 94: Batch #7 - Loss: 0.6578102707862854\n",
      "Ep 94: Batch #8 - Loss: 0.6852090358734131\n",
      "Ep 94: Batch #9 - Loss: 1.309790015220642\n",
      "Ep 94: Batch #10 - Loss: 0.9468194246292114\n",
      "Ep 94: Batch #11 - Loss: 0.626463770866394\n",
      "Ep 94: Batch #12 - Loss: 1.4915032386779785\n",
      "Ep 94: Batch #13 - Loss: 0.6131856441497803\n",
      "Ep 94: Batch #14 - Loss: 0.684076189994812\n",
      "Ep 94: Batch #15 - Loss: 1.1602684259414673\n",
      "Ep 94: Batch #16 - Loss: 1.1865856647491455\n",
      "Ep 94: Batch #17 - Loss: 0.8210172057151794\n",
      "Ep 94: Batch #18 - Loss: 0.9032716155052185\n",
      "Ep 94: Batch #19 - Loss: 0.6312277317047119\n",
      "Ep 94: Batch #20 - Loss: 0.6108675003051758\n",
      "Ep 94: Batch #21 - Loss: 1.1549124717712402\n",
      "Ep 94: Batch #22 - Loss: 0.682350218296051\n",
      "Ep 94: Batch #23 - Loss: 0.689799964427948\n",
      "Ep 94: Batch #24 - Loss: 0.7789595127105713\n",
      "Ep 94: Batch #25 - Loss: 0.6668729782104492\n",
      "Ep 94: Batch #26 - Loss: 0.6770893931388855\n",
      "Ep 94: Batch #27 - Loss: 1.2687606811523438\n",
      "Ep 94: Batch #28 - Loss: 0.8198009729385376\n",
      "Ep 94: Batch #29 - Loss: 0.8290045261383057\n",
      "Ep 94: Batch #30 - Loss: 1.1330256462097168\n",
      "Ep 94: Batch #31 - Loss: 0.6321057677268982\n",
      "Ep 94: Batch #32 - Loss: 0.6949391961097717\n",
      "Ep 94: Batch #33 - Loss: 0.7589298486709595\n",
      "Ep 94: Batch #34 - Loss: 0.7329815030097961\n",
      "Ep 94: Batch #35 - Loss: 0.8803243041038513\n",
      "Ep 94: Batch #36 - Loss: 0.6527233719825745\n",
      "Ep 94: Batch #37 - Loss: 1.0850251913070679\n",
      "Ep 94: Batch #38 - Loss: 0.6860836744308472\n",
      "Ep 94: Batch #39 - Loss: 0.7732890248298645\n",
      "Ep 94: Batch #40 - Loss: 0.7240503430366516\n",
      "Ep 94: Batch #41 - Loss: 0.6794863343238831\n",
      "Ep 94: Batch #42 - Loss: 0.6745556592941284\n",
      "Ep 94: Batch #43 - Loss: 0.7388262152671814\n",
      "Ep 94: Batch #44 - Loss: 0.7257692217826843\n",
      "Ep 94: Batch #45 - Loss: 0.5879349708557129\n",
      "Ep 94: Batch #46 - Loss: 0.7678055763244629\n",
      "Ep 94: Batch #47 - Loss: 0.8823357224464417\n",
      "Ep 94: Batch #48 - Loss: 1.2846585512161255\n",
      "Ep 94: Batch #49 - Loss: 0.9384699463844299\n",
      "Ep 94: Batch #50 - Loss: 0.6670535206794739\n",
      "Ep 94: Batch #51 - Loss: 0.9163598418235779\n",
      "Ep 94: Batch #52 - Loss: 0.7458686828613281\n",
      "Ep 94: Batch #53 - Loss: 0.7655558586120605\n",
      "Ep 94: Batch #54 - Loss: 0.6578999757766724\n",
      "Ep 94: Batch #55 - Loss: 0.6995419859886169\n",
      "Ep 94: Batch #56 - Loss: 1.1754745244979858\n",
      "Ep 94: Batch #57 - Loss: 0.7816284894943237\n",
      "Ep 94: Batch #58 - Loss: 0.9227790236473083\n",
      "Ep 94: Batch #59 - Loss: 0.6428431868553162\n",
      "Ep 94: Batch #60 - Loss: 1.2334476709365845\n",
      "Ep 94: Batch #61 - Loss: 0.5972670316696167\n",
      "Ep 94: Batch #62 - Loss: 0.6727419495582581\n",
      "Ep 94: Batch #63 - Loss: 0.9362356662750244\n",
      "Ep 94: Batch #64 - Loss: 9.343815803527832\n",
      "Ep 94: Batch #65 - Loss: 0.571682870388031\n",
      "Ep 94: Batch #66 - Loss: 0.738652765750885\n",
      "Ep 94: Batch #67 - Loss: 0.8552520275115967\n",
      "Ep 94: Batch #68 - Loss: 0.8392862677574158\n",
      "Ep 94: Batch #69 - Loss: 0.697040319442749\n",
      "Ep 94: Batch #70 - Loss: 0.7131666541099548\n",
      "Ep 94: Batch #71 - Loss: 0.6364595293998718\n",
      "Ep 94: Batch #72 - Loss: 0.793912410736084\n",
      "Ep 94: Batch #73 - Loss: 0.8314304947853088\n",
      "Ep 94: Batch #74 - Loss: 0.6820651292800903\n",
      "Ep 94: Batch #75 - Loss: 0.7219589352607727\n",
      "Ep 94: Batch #76 - Loss: 1.0374760627746582\n",
      "Ep 94: Batch #77 - Loss: 0.6794915795326233\n",
      "Ep 94: Batch #78 - Loss: 1.0759061574935913\n",
      "Ep 94: Batch #79 - Loss: 0.583840012550354\n",
      "Ep 94: Batch #80 - Loss: 0.7926559448242188\n",
      "Ep 94: Batch #81 - Loss: 1.6218554973602295\n",
      "Ep 94: Batch #82 - Loss: 0.8194553256034851\n",
      "Ep 94: Batch #83 - Loss: 1.6917990446090698\n",
      "Ep 94: Batch #84 - Loss: 0.6647405624389648\n",
      "Ep 94: Batch #85 - Loss: 0.919499933719635\n",
      "Ep 94: Batch #86 - Loss: 0.6530636548995972\n",
      "Ep 94: Batch #87 - Loss: 0.6643467545509338\n",
      "Ep 94: Batch #88 - Loss: 0.7452696561813354\n",
      "Ep 94: Batch #89 - Loss: 0.8460137248039246\n",
      "Ep 94: Batch #90 - Loss: 1.0754072666168213\n",
      "Ep 94: Batch #91 - Loss: 0.7408092617988586\n",
      "Ep 94: Batch #92 - Loss: 0.9601743817329407\n",
      "Ep 94: Batch #93 - Loss: 0.9431661367416382\n",
      "Ep 94: Batch #94 - Loss: 0.9755403399467468\n",
      "Ep 94: Batch #95 - Loss: 0.8617945313453674\n",
      "Ep 94: Batch #96 - Loss: 0.8469310998916626\n",
      "Ep 94: Batch #97 - Loss: 0.6772659420967102\n",
      "Ep 94: Batch #98 - Loss: 0.6872953772544861\n",
      "Ep 94: Batch #99 - Loss: 0.8973829746246338\n",
      "Ep 94: Batch #100 - Loss: 0.6291465163230896\n",
      "Ep 94: Batch #101 - Loss: 0.990244448184967\n",
      "Ep 94: Batch #102 - Loss: 0.7276885509490967\n",
      "Ep 94: Batch #103 - Loss: 0.7375186085700989\n",
      "Ep 94: Batch #104 - Loss: 0.7483559250831604\n",
      "Ep 94: Batch #105 - Loss: 0.9636585712432861\n",
      "Ep 94: Batch #106 - Loss: 0.7130129933357239\n",
      "Ep 94: Batch #107 - Loss: 0.704721987247467\n",
      "Ep 94: Batch #108 - Loss: 0.9694589376449585\n",
      "Ep 94: Batch #109 - Loss: 0.7119353413581848\n",
      "Ep 94: Batch #110 - Loss: 0.8480896353721619\n",
      "Ep 94: Batch #111 - Loss: 1.2991663217544556\n",
      "Ep 94: Batch #112 - Loss: 0.9752773642539978\n",
      "Ep 94: Batch #113 - Loss: 0.7624486684799194\n",
      "Ep 94: Batch #114 - Loss: 0.8362715840339661\n",
      "Ep 94: Batch #115 - Loss: 1.0272611379623413\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 94: Batch #116 - Loss: 0.5988492965698242\n",
      "Ep 94: Batch #117 - Loss: 0.8194528222084045\n",
      "Ep 94: Batch #118 - Loss: 0.5048550367355347\n",
      "Model saved in file: ./weights_autoencoder_low_LR/model_e94b118_1516651281.4981465.ckpt\n",
      "Ep 94: Batch #119 - Loss: 0.961837112903595\n",
      "Ep 94: Batch #120 - Loss: 0.7498730421066284\n",
      "Ep 94: Batch #121 - Loss: 0.6372423768043518\n",
      "Ep 94: Batch #122 - Loss: 0.7717562317848206\n",
      "Ep 94: Batch #123 - Loss: 0.7771440148353577\n",
      "Ep 94: Batch #124 - Loss: 0.6237662434577942\n",
      "Ep 94: Batch #125 - Loss: 2.638472557067871\n",
      "Ep 94: Batch #126 - Loss: 1.154510736465454\n",
      "Ep 94: Batch #127 - Loss: 0.6894617676734924\n",
      "Ep 94: Batch #128 - Loss: 1.0215024948120117\n",
      "Ep 94: Batch #129 - Loss: 0.7778786420822144\n",
      "Ep 94: Batch #130 - Loss: 0.6748937368392944\n",
      "Ep 94: Batch #131 - Loss: 0.9166206121444702\n",
      "Ep 94: Batch #132 - Loss: 0.7673637270927429\n",
      "Ep 94: Batch #133 - Loss: 0.7582225203514099\n",
      "Ep 94: Batch #134 - Loss: 0.7153732776641846\n",
      "Ep 94: Batch #135 - Loss: 0.8999497294425964\n",
      "Ep 94: Batch #136 - Loss: 1.1077548265457153\n",
      "Ep 94: Batch #137 - Loss: 0.8943275809288025\n",
      "Ep 94: Batch #138 - Loss: 0.9977826476097107\n",
      "Ep 94: Batch #139 - Loss: 0.8331774473190308\n",
      "Ep 94: Batch #140 - Loss: 0.9869610071182251\n",
      "Ep 94: Batch #141 - Loss: 1.2810133695602417\n",
      "Ep 94: Batch #142 - Loss: 0.7399031519889832\n",
      "Ep 94: Batch #143 - Loss: 0.8900212645530701\n",
      "Ep 94: Batch #144 - Loss: 0.675225555896759\n",
      "Ep 94: Batch #145 - Loss: 0.6352458596229553\n",
      "Ep 94: Batch #146 - Loss: 0.8338439464569092\n",
      "Ep 94: Batch #147 - Loss: 0.7962800860404968\n",
      "Ep 94: Batch #148 - Loss: 0.9042643308639526\n",
      "Ep 94: Batch #149 - Loss: 0.7921215295791626\n",
      "Ep 94: Batch #150 - Loss: 0.8298065066337585\n",
      "Ep 94: Batch #151 - Loss: 0.6891758441925049\n",
      "Ep 94: Batch #152 - Loss: 0.7008339166641235\n",
      "Ep 94: Batch #153 - Loss: 1.0287805795669556\n",
      "Ep 94: Batch #154 - Loss: 0.7118554711341858\n",
      "Ep 94: Batch #155 - Loss: 0.7792195081710815\n",
      "Ep 94: Batch #156 - Loss: 0.9550228118896484\n",
      "Ep 94: Batch #157 - Loss: 0.7066938877105713\n",
      "Ep 94: Batch #158 - Loss: 0.7660524845123291\n",
      "Ep 94: Batch #159 - Loss: 0.7461241483688354\n",
      "Ep 94: Batch #160 - Loss: 0.8554446697235107\n",
      "Ep 94: Batch #161 - Loss: 0.7627025842666626\n",
      "Ep 94: Batch #162 - Loss: 0.8720018863677979\n",
      "Ep 94: Batch #163 - Loss: 0.8755037784576416\n",
      "Ep 94: Batch #164 - Loss: 0.7287930250167847\n",
      "Ep 94: Batch #165 - Loss: 1.4442965984344482\n",
      "Ep 94: Batch #166 - Loss: 0.6293330192565918\n",
      "Ep 94: Batch #167 - Loss: 1.019365668296814\n",
      "Ep 94: Batch #168 - Loss: 0.7980236411094666\n",
      "Ep 94: Batch #169 - Loss: 0.7515085339546204\n",
      "Ep 94: Batch #170 - Loss: 0.7496715784072876\n",
      "Ep 94: Batch #171 - Loss: 0.719331681728363\n",
      "Ep 94: Batch #172 - Loss: 0.5986555814743042\n",
      "Ep 94: Batch #173 - Loss: 1.1089489459991455\n",
      "Ep 94: Batch #174 - Loss: 0.540601909160614\n",
      "Ep 94: Batch #175 - Loss: 0.7388840317726135\n",
      "Ep 94: Batch #176 - Loss: 1.074526071548462\n",
      "Ep 94: Batch #177 - Loss: 0.7903217673301697\n",
      "Ep 94: Batch #178 - Loss: 0.7096114158630371\n",
      "Ep 94: Batch #179 - Loss: 0.8776760697364807\n",
      "Ep 94: Batch #180 - Loss: 0.7867284417152405\n",
      "Ep 94: Batch #181 - Loss: 0.9182976484298706\n",
      "Ep 94: Batch #182 - Loss: 0.7198015451431274\n",
      "Ep 94: Batch #183 - Loss: 0.7176197171211243\n",
      "Ep 94: Batch #184 - Loss: 1.011422872543335\n",
      "Ep 94: Batch #185 - Loss: 0.7068809866905212\n",
      "Ep 94: Batch #186 - Loss: 0.8913044333457947\n",
      "Ep 94: Batch #187 - Loss: 1.0906507968902588\n",
      "Ep 94: Batch #188 - Loss: 1.2843860387802124\n",
      "Ep 94: Batch #189 - Loss: 0.6641896963119507\n",
      "Ep 94: Batch #190 - Loss: 0.6883710026741028\n",
      "Ep 94: Batch #191 - Loss: 0.9877994060516357\n",
      "Ep 94: Batch #192 - Loss: 0.6348143219947815\n",
      "Ep 94: Batch #193 - Loss: 0.690105140209198\n",
      "Ep 94: Batch #194 - Loss: 0.647110104560852\n",
      "Ep 94: Batch #195 - Loss: 0.9188393354415894\n",
      "Ep 94: Batch #196 - Loss: 0.8039957284927368\n",
      "Ep 94: Batch #197 - Loss: 0.8344888091087341\n",
      "Ep 94: Batch #198 - Loss: 0.6279132962226868\n",
      "Ep 94: Batch #199 - Loss: 0.8024820685386658\n",
      "Ep 95: Batch #0 - Loss: 0.7315220832824707\n",
      "Ep 95: Batch #1 - Loss: 0.8140376806259155\n",
      "Ep 95: Batch #2 - Loss: 0.9597635865211487\n",
      "Ep 95: Batch #3 - Loss: 0.8112325072288513\n",
      "Ep 95: Batch #4 - Loss: 0.7322387099266052\n",
      "Ep 95: Batch #5 - Loss: 0.625146210193634\n",
      "Ep 95: Batch #6 - Loss: 0.8232796788215637\n",
      "Ep 95: Batch #7 - Loss: 0.6571133732795715\n",
      "Ep 95: Batch #8 - Loss: 0.6843541860580444\n",
      "Ep 95: Batch #9 - Loss: 1.3081024885177612\n",
      "Ep 95: Batch #10 - Loss: 0.9457327127456665\n",
      "Ep 95: Batch #11 - Loss: 0.625661313533783\n",
      "Ep 95: Batch #12 - Loss: 1.4903531074523926\n",
      "Ep 95: Batch #13 - Loss: 0.6126131415367126\n",
      "Ep 95: Batch #14 - Loss: 0.683367908000946\n",
      "Ep 95: Batch #15 - Loss: 1.1588834524154663\n",
      "Ep 95: Batch #16 - Loss: 1.1849926710128784\n",
      "Ep 95: Batch #17 - Loss: 0.8200148344039917\n",
      "Ep 95: Batch #18 - Loss: 0.9025851488113403\n",
      "Ep 95: Batch #19 - Loss: 0.6306211352348328\n",
      "Ep 95: Batch #20 - Loss: 0.6101303100585938\n",
      "Ep 95: Batch #21 - Loss: 1.1538386344909668\n",
      "Ep 95: Batch #22 - Loss: 0.6815661191940308\n",
      "Ep 95: Batch #23 - Loss: 0.6888537406921387\n",
      "Ep 95: Batch #24 - Loss: 0.7781707048416138\n",
      "Ep 95: Batch #25 - Loss: 0.6661031246185303\n",
      "Ep 95: Batch #26 - Loss: 0.6762221455574036\n",
      "Ep 95: Batch #27 - Loss: 1.2672865390777588\n",
      "Ep 95: Batch #28 - Loss: 0.8189614415168762\n",
      "Ep 95: Batch #29 - Loss: 0.827966570854187\n",
      "Ep 95: Batch #30 - Loss: 1.1317529678344727\n",
      "Ep 95: Batch #31 - Loss: 0.6314375400543213\n",
      "Ep 95: Batch #32 - Loss: 0.6940885782241821\n",
      "Ep 95: Batch #33 - Loss: 0.7581351399421692\n",
      "Ep 95: Batch #34 - Loss: 0.7321246266365051\n",
      "Ep 95: Batch #35 - Loss: 0.8792273998260498\n",
      "Ep 95: Batch #36 - Loss: 0.6518843770027161\n",
      "Ep 95: Batch #37 - Loss: 1.0841186046600342\n",
      "Ep 95: Batch #38 - Loss: 0.6850466728210449\n",
      "Ep 95: Batch #39 - Loss: 0.7724672555923462\n",
      "Ep 95: Batch #40 - Loss: 0.7232138514518738\n",
      "Ep 95: Batch #41 - Loss: 0.6785598993301392\n",
      "Ep 95: Batch #42 - Loss: 0.6737822890281677\n",
      "Ep 95: Batch #43 - Loss: 0.738032877445221\n",
      "Ep 95: Batch #44 - Loss: 0.7247319221496582\n",
      "Ep 95: Batch #45 - Loss: 0.5872170329093933\n",
      "Ep 95: Batch #46 - Loss: 0.7667425274848938\n",
      "Ep 95: Batch #47 - Loss: 0.8809746503829956\n",
      "Ep 95: Batch #48 - Loss: 1.283414602279663\n",
      "Ep 95: Batch #49 - Loss: 0.9372037053108215\n",
      "Ep 95: Batch #50 - Loss: 0.6663714647293091\n",
      "Ep 95: Batch #51 - Loss: 0.9150159358978271\n",
      "Ep 95: Batch #52 - Loss: 0.7450228333473206\n",
      "Ep 95: Batch #53 - Loss: 0.7645609974861145\n",
      "Ep 95: Batch #54 - Loss: 0.6570516228675842\n",
      "Ep 95: Batch #55 - Loss: 0.6986271142959595\n",
      "Ep 95: Batch #56 - Loss: 1.1739472150802612\n",
      "Ep 95: Batch #57 - Loss: 0.780427873134613\n",
      "Ep 95: Batch #58 - Loss: 0.9215252995491028\n",
      "Ep 95: Batch #59 - Loss: 0.6421935558319092\n",
      "Ep 95: Batch #60 - Loss: 1.2320972681045532\n",
      "Ep 95: Batch #61 - Loss: 0.5966353416442871\n",
      "Ep 95: Batch #62 - Loss: 0.6719752550125122\n",
      "Ep 95: Batch #63 - Loss: 0.9351161122322083\n",
      "Ep 95: Batch #64 - Loss: 9.342286109924316\n",
      "Ep 95: Batch #65 - Loss: 0.5709823369979858\n",
      "Ep 95: Batch #66 - Loss: 0.7377262115478516\n",
      "Ep 95: Batch #67 - Loss: 0.8544024229049683\n",
      "Ep 95: Batch #68 - Loss: 0.8381057977676392\n",
      "Ep 95: Batch #69 - Loss: 0.6962195038795471\n",
      "Ep 95: Batch #70 - Loss: 0.7120635509490967\n",
      "Ep 95: Batch #71 - Loss: 0.635664165019989\n",
      "Ep 95: Batch #72 - Loss: 0.7928407192230225\n",
      "Ep 95: Batch #73 - Loss: 0.8302589654922485\n",
      "Ep 95: Batch #74 - Loss: 0.681079089641571\n",
      "Ep 95: Batch #75 - Loss: 0.7212011814117432\n",
      "Ep 95: Batch #76 - Loss: 1.0364861488342285\n",
      "Ep 95: Batch #77 - Loss: 0.678602397441864\n",
      "Ep 95: Batch #78 - Loss: 1.0744450092315674\n",
      "Ep 95: Batch #79 - Loss: 0.5831528306007385\n",
      "Ep 95: Batch #80 - Loss: 0.7915031909942627\n",
      "Ep 95: Batch #81 - Loss: 1.620928168296814\n",
      "Ep 95: Batch #82 - Loss: 0.8185675740242004\n",
      "Ep 95: Batch #83 - Loss: 1.6911224126815796\n",
      "Ep 95: Batch #84 - Loss: 0.663975715637207\n",
      "Ep 95: Batch #85 - Loss: 0.9185426235198975\n",
      "Ep 95: Batch #86 - Loss: 0.6521541476249695\n",
      "Ep 95: Batch #87 - Loss: 0.6635271310806274\n",
      "Ep 95: Batch #88 - Loss: 0.7443675398826599\n",
      "Ep 95: Batch #89 - Loss: 0.8453501462936401\n",
      "Ep 95: Batch #90 - Loss: 1.0741344690322876\n",
      "Ep 95: Batch #91 - Loss: 0.7398179173469543\n",
      "Ep 95: Batch #92 - Loss: 0.9590350985527039\n",
      "Ep 95: Batch #93 - Loss: 0.9416425824165344\n",
      "Ep 95: Batch #94 - Loss: 0.974249005317688\n",
      "Ep 95: Batch #95 - Loss: 0.860798716545105\n",
      "Ep 95: Batch #96 - Loss: 0.8459505438804626\n",
      "Ep 95: Batch #97 - Loss: 0.6764063835144043\n",
      "Ep 95: Batch #98 - Loss: 0.6864421367645264\n",
      "Ep 95: Batch #99 - Loss: 0.8963982462882996\n",
      "Ep 95: Batch #100 - Loss: 0.6283518075942993\n",
      "Ep 95: Batch #101 - Loss: 0.9892869591712952\n",
      "Ep 95: Batch #102 - Loss: 0.7267401218414307\n",
      "Ep 95: Batch #103 - Loss: 0.7366708517074585\n",
      "Ep 95: Batch #104 - Loss: 0.7474669218063354\n",
      "Ep 95: Batch #105 - Loss: 0.9626374244689941\n",
      "Ep 95: Batch #106 - Loss: 0.712256669998169\n",
      "Ep 95: Batch #107 - Loss: 0.7038294076919556\n",
      "Ep 95: Batch #108 - Loss: 0.9684492349624634\n",
      "Ep 95: Batch #109 - Loss: 0.7110725045204163\n",
      "Ep 95: Batch #110 - Loss: 0.8468993902206421\n",
      "Ep 95: Batch #111 - Loss: 1.2977739572525024\n",
      "Ep 95: Batch #112 - Loss: 0.9740598201751709\n",
      "Ep 95: Batch #113 - Loss: 0.761491596698761\n",
      "Ep 95: Batch #114 - Loss: 0.83517986536026\n",
      "Ep 95: Batch #115 - Loss: 1.0261682271957397\n",
      "Ep 95: Batch #116 - Loss: 0.598240852355957\n",
      "Ep 95: Batch #117 - Loss: 0.8185728192329407\n",
      "Ep 95: Batch #118 - Loss: 0.5042031407356262\n",
      "Model saved in file: ./weights_autoencoder_low_LR/model_e95b118_1516651281.6346428.ckpt\n",
      "Ep 95: Batch #119 - Loss: 0.9606806039810181\n",
      "Ep 95: Batch #120 - Loss: 0.7490187287330627\n",
      "Ep 95: Batch #121 - Loss: 0.636427104473114\n",
      "Ep 95: Batch #122 - Loss: 0.7708683013916016\n",
      "Ep 95: Batch #123 - Loss: 0.7762471437454224\n",
      "Ep 95: Batch #124 - Loss: 0.6231052875518799\n",
      "Ep 95: Batch #125 - Loss: 2.6371030807495117\n",
      "Ep 95: Batch #126 - Loss: 1.153324007987976\n",
      "Ep 95: Batch #127 - Loss: 0.6883765459060669\n",
      "Ep 95: Batch #128 - Loss: 1.020111322402954\n",
      "Ep 95: Batch #129 - Loss: 0.7768546938896179\n",
      "Ep 95: Batch #130 - Loss: 0.6740735769271851\n",
      "Ep 95: Batch #131 - Loss: 0.9152907133102417\n",
      "Ep 95: Batch #132 - Loss: 0.7664726972579956\n",
      "Ep 95: Batch #133 - Loss: 0.7571815252304077\n",
      "Ep 95: Batch #134 - Loss: 0.7145411968231201\n",
      "Ep 95: Batch #135 - Loss: 0.8989232778549194\n",
      "Ep 95: Batch #136 - Loss: 1.1065585613250732\n",
      "Ep 95: Batch #137 - Loss: 0.8931394219398499\n",
      "Ep 95: Batch #138 - Loss: 0.996465802192688\n",
      "Ep 95: Batch #139 - Loss: 0.8320068120956421\n",
      "Ep 95: Batch #140 - Loss: 0.9859535098075867\n",
      "Ep 95: Batch #141 - Loss: 1.2797167301177979\n",
      "Ep 95: Batch #142 - Loss: 0.7389652132987976\n",
      "Ep 95: Batch #143 - Loss: 0.8887882828712463\n",
      "Ep 95: Batch #144 - Loss: 0.6745087504386902\n",
      "Ep 95: Batch #145 - Loss: 0.6345615983009338\n",
      "Ep 95: Batch #146 - Loss: 0.8330734372138977\n",
      "Ep 95: Batch #147 - Loss: 0.7952797412872314\n",
      "Ep 95: Batch #148 - Loss: 0.9030389189720154\n",
      "Ep 95: Batch #149 - Loss: 0.7911244630813599\n",
      "Ep 95: Batch #150 - Loss: 0.8290044665336609\n",
      "Ep 95: Batch #151 - Loss: 0.6885604858398438\n",
      "Ep 95: Batch #152 - Loss: 0.7002153396606445\n",
      "Ep 95: Batch #153 - Loss: 1.0274882316589355\n",
      "Ep 95: Batch #154 - Loss: 0.7110468149185181\n",
      "Ep 95: Batch #155 - Loss: 0.7783563733100891\n",
      "Ep 95: Batch #156 - Loss: 0.9539648294448853\n",
      "Ep 95: Batch #157 - Loss: 0.7058017253875732\n",
      "Ep 95: Batch #158 - Loss: 0.7654150128364563\n",
      "Ep 95: Batch #159 - Loss: 0.7450666427612305\n",
      "Ep 95: Batch #160 - Loss: 0.8546248078346252\n",
      "Ep 95: Batch #161 - Loss: 0.7619121670722961\n",
      "Ep 95: Batch #162 - Loss: 0.8709623217582703\n",
      "Ep 95: Batch #163 - Loss: 0.8745234608650208\n",
      "Ep 95: Batch #164 - Loss: 0.7278720140457153\n",
      "Ep 95: Batch #165 - Loss: 1.4433815479278564\n",
      "Ep 95: Batch #166 - Loss: 0.6284978985786438\n",
      "Ep 95: Batch #167 - Loss: 1.0182081460952759\n",
      "Ep 95: Batch #168 - Loss: 0.7969480156898499\n",
      "Ep 95: Batch #169 - Loss: 0.7506872415542603\n",
      "Ep 95: Batch #170 - Loss: 0.7487517595291138\n",
      "Ep 95: Batch #171 - Loss: 0.7183048725128174\n",
      "Ep 95: Batch #172 - Loss: 0.598111629486084\n",
      "Ep 95: Batch #173 - Loss: 1.1075106859207153\n",
      "Ep 95: Batch #174 - Loss: 0.5399779677391052\n",
      "Ep 95: Batch #175 - Loss: 0.7382224202156067\n",
      "Ep 95: Batch #176 - Loss: 1.0732516050338745\n",
      "Ep 95: Batch #177 - Loss: 0.7893334031105042\n",
      "Ep 95: Batch #178 - Loss: 0.7087183594703674\n",
      "Ep 95: Batch #179 - Loss: 0.8766100406646729\n",
      "Ep 95: Batch #180 - Loss: 0.785574734210968\n",
      "Ep 95: Batch #181 - Loss: 0.9170916676521301\n",
      "Ep 95: Batch #182 - Loss: 0.7190465927124023\n",
      "Ep 95: Batch #183 - Loss: 0.7168731093406677\n",
      "Ep 95: Batch #184 - Loss: 1.010423183441162\n",
      "Ep 95: Batch #185 - Loss: 0.7060247659683228\n",
      "Ep 95: Batch #186 - Loss: 0.890004575252533\n",
      "Ep 95: Batch #187 - Loss: 1.0893254280090332\n",
      "Ep 95: Batch #188 - Loss: 1.2831748723983765\n",
      "Ep 95: Batch #189 - Loss: 0.663612961769104\n",
      "Ep 95: Batch #190 - Loss: 0.6875889301300049\n",
      "Ep 95: Batch #191 - Loss: 0.9864675402641296\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 95: Batch #192 - Loss: 0.6342424750328064\n",
      "Ep 95: Batch #193 - Loss: 0.6893203258514404\n",
      "Ep 95: Batch #194 - Loss: 0.6463199853897095\n",
      "Ep 95: Batch #195 - Loss: 0.9177275896072388\n",
      "Ep 95: Batch #196 - Loss: 0.8029716610908508\n",
      "Ep 95: Batch #197 - Loss: 0.8333659172058105\n",
      "Ep 95: Batch #198 - Loss: 0.6271176934242249\n",
      "Ep 95: Batch #199 - Loss: 0.8014161586761475\n",
      "Ep 96: Batch #0 - Loss: 0.7305698990821838\n",
      "Ep 96: Batch #1 - Loss: 0.8130753636360168\n",
      "Ep 96: Batch #2 - Loss: 0.9589784145355225\n",
      "Ep 96: Batch #3 - Loss: 0.8102917075157166\n",
      "Ep 96: Batch #4 - Loss: 0.7313106656074524\n",
      "Ep 96: Batch #5 - Loss: 0.6244869232177734\n",
      "Ep 96: Batch #6 - Loss: 0.8223879933357239\n",
      "Ep 96: Batch #7 - Loss: 0.6564211845397949\n",
      "Ep 96: Batch #8 - Loss: 0.6835066676139832\n",
      "Ep 96: Batch #9 - Loss: 1.3064547777175903\n",
      "Ep 96: Batch #10 - Loss: 0.9446526765823364\n",
      "Ep 96: Batch #11 - Loss: 0.6248683333396912\n",
      "Ep 96: Batch #12 - Loss: 1.4892054796218872\n",
      "Ep 96: Batch #13 - Loss: 0.6120462417602539\n",
      "Ep 96: Batch #14 - Loss: 0.682666540145874\n",
      "Ep 96: Batch #15 - Loss: 1.1575095653533936\n",
      "Ep 96: Batch #16 - Loss: 1.1834112405776978\n",
      "Ep 96: Batch #17 - Loss: 0.8190193176269531\n",
      "Ep 96: Batch #18 - Loss: 0.9018997550010681\n",
      "Ep 96: Batch #19 - Loss: 0.630021870136261\n",
      "Ep 96: Batch #20 - Loss: 0.6094000339508057\n",
      "Ep 96: Batch #21 - Loss: 1.152771234512329\n",
      "Ep 96: Batch #22 - Loss: 0.680790364742279\n",
      "Ep 96: Batch #23 - Loss: 0.6879225969314575\n",
      "Ep 96: Batch #24 - Loss: 0.7773910164833069\n",
      "Ep 96: Batch #25 - Loss: 0.6653388142585754\n",
      "Ep 96: Batch #26 - Loss: 0.6753692030906677\n",
      "Ep 96: Batch #27 - Loss: 1.265822172164917\n",
      "Ep 96: Batch #28 - Loss: 0.8181285262107849\n",
      "Ep 96: Batch #29 - Loss: 0.826933741569519\n",
      "Ep 96: Batch #30 - Loss: 1.1304898262023926\n",
      "Ep 96: Batch #31 - Loss: 0.6307791471481323\n",
      "Ep 96: Batch #32 - Loss: 0.6932451725006104\n",
      "Ep 96: Batch #33 - Loss: 0.7573477029800415\n",
      "Ep 96: Batch #34 - Loss: 0.731275200843811\n",
      "Ep 96: Batch #35 - Loss: 0.8781418800354004\n",
      "Ep 96: Batch #36 - Loss: 0.6510545015335083\n",
      "Ep 96: Batch #37 - Loss: 1.0832176208496094\n",
      "Ep 96: Batch #38 - Loss: 0.6840192079544067\n",
      "Ep 96: Batch #39 - Loss: 0.7716538310050964\n",
      "Ep 96: Batch #40 - Loss: 0.7223793268203735\n",
      "Ep 96: Batch #41 - Loss: 0.6776430010795593\n",
      "Ep 96: Batch #42 - Loss: 0.6730150580406189\n",
      "Ep 96: Batch #43 - Loss: 0.7372456192970276\n",
      "Ep 96: Batch #44 - Loss: 0.7237054109573364\n",
      "Ep 96: Batch #45 - Loss: 0.5865037441253662\n",
      "Ep 96: Batch #46 - Loss: 0.7656866908073425\n",
      "Ep 96: Batch #47 - Loss: 0.8796246647834778\n",
      "Ep 96: Batch #48 - Loss: 1.2821816205978394\n",
      "Ep 96: Batch #49 - Loss: 0.9359447956085205\n",
      "Ep 96: Batch #50 - Loss: 0.6656917929649353\n",
      "Ep 96: Batch #51 - Loss: 0.9136860370635986\n",
      "Ep 96: Batch #52 - Loss: 0.7441822290420532\n",
      "Ep 96: Batch #53 - Loss: 0.7635728120803833\n",
      "Ep 96: Batch #54 - Loss: 0.6562067866325378\n",
      "Ep 96: Batch #55 - Loss: 0.6977201700210571\n",
      "Ep 96: Batch #56 - Loss: 1.1724302768707275\n",
      "Ep 96: Batch #57 - Loss: 0.7792385220527649\n",
      "Ep 96: Batch #58 - Loss: 0.9202777147293091\n",
      "Ep 96: Batch #59 - Loss: 0.6415462493896484\n",
      "Ep 96: Batch #60 - Loss: 1.2307630777359009\n",
      "Ep 96: Batch #61 - Loss: 0.5960073471069336\n",
      "Ep 96: Batch #62 - Loss: 0.6712173819541931\n",
      "Ep 96: Batch #63 - Loss: 0.93401038646698\n",
      "Ep 96: Batch #64 - Loss: 9.340774536132812\n",
      "Ep 96: Batch #65 - Loss: 0.570287823677063\n",
      "Ep 96: Batch #66 - Loss: 0.7368108034133911\n",
      "Ep 96: Batch #67 - Loss: 0.8535594344139099\n",
      "Ep 96: Batch #68 - Loss: 0.8369383811950684\n",
      "Ep 96: Batch #69 - Loss: 0.6954126954078674\n",
      "Ep 96: Batch #70 - Loss: 0.7109687924385071\n",
      "Ep 96: Batch #71 - Loss: 0.6348769068717957\n",
      "Ep 96: Batch #72 - Loss: 0.791779100894928\n",
      "Ep 96: Batch #73 - Loss: 0.8290994167327881\n",
      "Ep 96: Batch #74 - Loss: 0.6801027059555054\n",
      "Ep 96: Batch #75 - Loss: 0.720448911190033\n",
      "Ep 96: Batch #76 - Loss: 1.03551185131073\n",
      "Ep 96: Batch #77 - Loss: 0.6777214407920837\n",
      "Ep 96: Batch #78 - Loss: 1.0729944705963135\n",
      "Ep 96: Batch #79 - Loss: 0.5824725031852722\n",
      "Ep 96: Batch #80 - Loss: 0.7903599739074707\n",
      "Ep 96: Batch #81 - Loss: 1.6200145483016968\n",
      "Ep 96: Batch #82 - Loss: 0.8176901936531067\n",
      "Ep 96: Batch #83 - Loss: 1.6904538869857788\n",
      "Ep 96: Batch #84 - Loss: 0.6632158756256104\n",
      "Ep 96: Batch #85 - Loss: 0.9175929427146912\n",
      "Ep 96: Batch #86 - Loss: 0.6512485146522522\n",
      "Ep 96: Batch #87 - Loss: 0.6627098917961121\n",
      "Ep 96: Batch #88 - Loss: 0.7434754371643066\n",
      "Ep 96: Batch #89 - Loss: 0.844690203666687\n",
      "Ep 96: Batch #90 - Loss: 1.0728803873062134\n",
      "Ep 96: Batch #91 - Loss: 0.7388355135917664\n",
      "Ep 96: Batch #92 - Loss: 0.9579055905342102\n",
      "Ep 96: Batch #93 - Loss: 0.940131664276123\n",
      "Ep 96: Batch #94 - Loss: 0.9729660749435425\n",
      "Ep 96: Batch #95 - Loss: 0.8598108887672424\n",
      "Ep 96: Batch #96 - Loss: 0.8449721336364746\n",
      "Ep 96: Batch #97 - Loss: 0.6755560040473938\n",
      "Ep 96: Batch #98 - Loss: 0.6855934858322144\n",
      "Ep 96: Batch #99 - Loss: 0.8954244256019592\n",
      "Ep 96: Batch #100 - Loss: 0.6275643706321716\n",
      "Ep 96: Batch #101 - Loss: 0.9883375763893127\n",
      "Ep 96: Batch #102 - Loss: 0.7257965207099915\n",
      "Ep 96: Batch #103 - Loss: 0.7358344793319702\n",
      "Ep 96: Batch #104 - Loss: 0.7465866208076477\n",
      "Ep 96: Batch #105 - Loss: 0.9616261124610901\n",
      "Ep 96: Batch #106 - Loss: 0.7115074396133423\n",
      "Ep 96: Batch #107 - Loss: 0.702935516834259\n",
      "Ep 96: Batch #108 - Loss: 0.9674507975578308\n",
      "Ep 96: Batch #109 - Loss: 0.7102161645889282\n",
      "Ep 96: Batch #110 - Loss: 0.8457154035568237\n",
      "Ep 96: Batch #111 - Loss: 1.2963910102844238\n",
      "Ep 96: Batch #112 - Loss: 0.9728525876998901\n",
      "Ep 96: Batch #113 - Loss: 0.7605358362197876\n",
      "Ep 96: Batch #114 - Loss: 0.8340965509414673\n",
      "Ep 96: Batch #115 - Loss: 1.0250838994979858\n",
      "Ep 96: Batch #116 - Loss: 0.5976348519325256\n",
      "Ep 96: Batch #117 - Loss: 0.8176972270011902\n",
      "Ep 96: Batch #118 - Loss: 0.5035558938980103\n",
      "Model saved in file: ./weights_autoencoder_low_LR/model_e96b118_1516651281.769064.ckpt\n",
      "Ep 96: Batch #119 - Loss: 0.9595312476158142\n",
      "Ep 96: Batch #120 - Loss: 0.7481714487075806\n",
      "Ep 96: Batch #121 - Loss: 0.6356202363967896\n",
      "Ep 96: Batch #122 - Loss: 0.769985020160675\n",
      "Ep 96: Batch #123 - Loss: 0.7753629088401794\n",
      "Ep 96: Batch #124 - Loss: 0.6224512457847595\n",
      "Ep 96: Batch #125 - Loss: 2.635747194290161\n",
      "Ep 96: Batch #126 - Loss: 1.1521599292755127\n",
      "Ep 96: Batch #127 - Loss: 0.6872738003730774\n",
      "Ep 96: Batch #128 - Loss: 1.0187312364578247\n",
      "Ep 96: Batch #129 - Loss: 0.7758403420448303\n",
      "Ep 96: Batch #130 - Loss: 0.6732596755027771\n",
      "Ep 96: Batch #131 - Loss: 0.9139719605445862\n",
      "Ep 96: Batch #132 - Loss: 0.7655701637268066\n",
      "Ep 96: Batch #133 - Loss: 0.7561468482017517\n",
      "Ep 96: Batch #134 - Loss: 0.7137167453765869\n",
      "Ep 96: Batch #135 - Loss: 0.8979082703590393\n",
      "Ep 96: Batch #136 - Loss: 1.1053730249404907\n",
      "Ep 96: Batch #137 - Loss: 0.891963541507721\n",
      "Ep 96: Batch #138 - Loss: 0.9951618909835815\n",
      "Ep 96: Batch #139 - Loss: 0.830845832824707\n",
      "Ep 96: Batch #140 - Loss: 0.9849556684494019\n",
      "Ep 96: Batch #141 - Loss: 1.27842378616333\n",
      "Ep 96: Batch #142 - Loss: 0.7380356192588806\n",
      "Ep 96: Batch #143 - Loss: 0.8875656723976135\n",
      "Ep 96: Batch #144 - Loss: 0.6737977266311646\n",
      "Ep 96: Batch #145 - Loss: 0.6338866353034973\n",
      "Ep 96: Batch #146 - Loss: 0.8323065638542175\n",
      "Ep 96: Batch #147 - Loss: 0.7942931056022644\n",
      "Ep 96: Batch #148 - Loss: 0.9018197059631348\n",
      "Ep 96: Batch #149 - Loss: 0.7901346683502197\n",
      "Ep 96: Batch #150 - Loss: 0.828209638595581\n",
      "Ep 96: Batch #151 - Loss: 0.6879507899284363\n",
      "Ep 96: Batch #152 - Loss: 0.6996124982833862\n",
      "Ep 96: Batch #153 - Loss: 1.0262045860290527\n",
      "Ep 96: Batch #154 - Loss: 0.7102444767951965\n",
      "Ep 96: Batch #155 - Loss: 0.7775026559829712\n",
      "Ep 96: Batch #156 - Loss: 0.9529149532318115\n",
      "Ep 96: Batch #157 - Loss: 0.7049268484115601\n",
      "Ep 96: Batch #158 - Loss: 0.7647812366485596\n",
      "Ep 96: Batch #159 - Loss: 0.7440202236175537\n",
      "Ep 96: Batch #160 - Loss: 0.8538109660148621\n",
      "Ep 96: Batch #161 - Loss: 0.761142909526825\n",
      "Ep 96: Batch #162 - Loss: 0.8699291348457336\n",
      "Ep 96: Batch #163 - Loss: 0.8735499382019043\n",
      "Ep 96: Batch #164 - Loss: 0.7269585728645325\n",
      "Ep 96: Batch #165 - Loss: 1.4424782991409302\n",
      "Ep 96: Batch #166 - Loss: 0.6276712417602539\n",
      "Ep 96: Batch #167 - Loss: 1.0170576572418213\n",
      "Ep 96: Batch #168 - Loss: 0.7958818078041077\n",
      "Ep 96: Batch #169 - Loss: 0.7498787045478821\n",
      "Ep 96: Batch #170 - Loss: 0.747841477394104\n",
      "Ep 96: Batch #171 - Loss: 0.7172876596450806\n",
      "Ep 96: Batch #172 - Loss: 0.597565770149231\n",
      "Ep 96: Batch #173 - Loss: 1.106087327003479\n",
      "Ep 96: Batch #174 - Loss: 0.5393606424331665\n",
      "Ep 96: Batch #175 - Loss: 0.7375631332397461\n",
      "Ep 96: Batch #176 - Loss: 1.0719902515411377\n",
      "Ep 96: Batch #177 - Loss: 0.7883492708206177\n",
      "Ep 96: Batch #178 - Loss: 0.7078315615653992\n",
      "Ep 96: Batch #179 - Loss: 0.8755500316619873\n",
      "Ep 96: Batch #180 - Loss: 0.7844201922416687\n",
      "Ep 96: Batch #181 - Loss: 0.9158990383148193\n",
      "Ep 96: Batch #182 - Loss: 0.7183015942573547\n",
      "Ep 96: Batch #183 - Loss: 0.7161372303962708\n",
      "Ep 96: Batch #184 - Loss: 1.0094313621520996\n",
      "Ep 96: Batch #185 - Loss: 0.7051793336868286\n",
      "Ep 96: Batch #186 - Loss: 0.8887243270874023\n",
      "Ep 96: Batch #187 - Loss: 1.0880112648010254\n",
      "Ep 96: Batch #188 - Loss: 1.2819746732711792\n",
      "Ep 96: Batch #189 - Loss: 0.6630425453186035\n",
      "Ep 96: Batch #190 - Loss: 0.6868116855621338\n",
      "Ep 96: Batch #191 - Loss: 0.9851503372192383\n",
      "Ep 96: Batch #192 - Loss: 0.6336731314659119\n",
      "Ep 96: Batch #193 - Loss: 0.6885408163070679\n",
      "Ep 96: Batch #194 - Loss: 0.6455386877059937\n",
      "Ep 96: Batch #195 - Loss: 0.9166211485862732\n",
      "Ep 96: Batch #196 - Loss: 0.8019537329673767\n",
      "Ep 96: Batch #197 - Loss: 0.8322464823722839\n",
      "Ep 96: Batch #198 - Loss: 0.6263314485549927\n",
      "Ep 96: Batch #199 - Loss: 0.8003594279289246\n",
      "Ep 97: Batch #0 - Loss: 0.7296281456947327\n",
      "Ep 97: Batch #1 - Loss: 0.8121291995048523\n",
      "Ep 97: Batch #2 - Loss: 0.9582020044326782\n",
      "Ep 97: Batch #3 - Loss: 0.8093535900115967\n",
      "Ep 97: Batch #4 - Loss: 0.7303907871246338\n",
      "Ep 97: Batch #5 - Loss: 0.6238359808921814\n",
      "Ep 97: Batch #6 - Loss: 0.8215029835700989\n",
      "Ep 97: Batch #7 - Loss: 0.6557323932647705\n",
      "Ep 97: Batch #8 - Loss: 0.6826655268669128\n",
      "Ep 97: Batch #9 - Loss: 1.3048568964004517\n",
      "Ep 97: Batch #10 - Loss: 0.9435839653015137\n",
      "Ep 97: Batch #11 - Loss: 0.6240777373313904\n",
      "Ep 97: Batch #12 - Loss: 1.4880597591400146\n",
      "Ep 97: Batch #13 - Loss: 0.6114774942398071\n",
      "Ep 97: Batch #14 - Loss: 0.6819740533828735\n",
      "Ep 97: Batch #15 - Loss: 1.1561450958251953\n",
      "Ep 97: Batch #16 - Loss: 1.1818424463272095\n",
      "Ep 97: Batch #17 - Loss: 0.8180294632911682\n",
      "Ep 97: Batch #18 - Loss: 0.9012135863304138\n",
      "Ep 97: Batch #19 - Loss: 0.6294270753860474\n",
      "Ep 97: Batch #20 - Loss: 0.6086764931678772\n",
      "Ep 97: Batch #21 - Loss: 1.1517109870910645\n",
      "Ep 97: Batch #22 - Loss: 0.6800373792648315\n",
      "Ep 97: Batch #23 - Loss: 0.6870049238204956\n",
      "Ep 97: Batch #24 - Loss: 0.7766159176826477\n",
      "Ep 97: Batch #25 - Loss: 0.6645813584327698\n",
      "Ep 97: Batch #26 - Loss: 0.6745246052742004\n",
      "Ep 97: Batch #27 - Loss: 1.264365792274475\n",
      "Ep 97: Batch #28 - Loss: 0.8173031806945801\n",
      "Ep 97: Batch #29 - Loss: 0.8259136080741882\n",
      "Ep 97: Batch #30 - Loss: 1.129228949546814\n",
      "Ep 97: Batch #31 - Loss: 0.6301313042640686\n",
      "Ep 97: Batch #32 - Loss: 0.6924102902412415\n",
      "Ep 97: Batch #33 - Loss: 0.7565664649009705\n",
      "Ep 97: Batch #34 - Loss: 0.7304366230964661\n",
      "Ep 97: Batch #35 - Loss: 0.8770663738250732\n",
      "Ep 97: Batch #36 - Loss: 0.6502304077148438\n",
      "Ep 97: Batch #37 - Loss: 1.082322359085083\n",
      "Ep 97: Batch #38 - Loss: 0.6830000877380371\n",
      "Ep 97: Batch #39 - Loss: 0.7708386778831482\n",
      "Ep 97: Batch #40 - Loss: 0.7215489745140076\n",
      "Ep 97: Batch #41 - Loss: 0.6767365336418152\n",
      "Ep 97: Batch #42 - Loss: 0.6722536683082581\n",
      "Ep 97: Batch #43 - Loss: 0.7364621758460999\n",
      "Ep 97: Batch #44 - Loss: 0.722682774066925\n",
      "Ep 97: Batch #45 - Loss: 0.5857962369918823\n",
      "Ep 97: Batch #46 - Loss: 0.7646341323852539\n",
      "Ep 97: Batch #47 - Loss: 0.8782802820205688\n",
      "Ep 97: Batch #48 - Loss: 1.2809579372406006\n",
      "Ep 97: Batch #49 - Loss: 0.9346942901611328\n",
      "Ep 97: Batch #50 - Loss: 0.6650159358978271\n",
      "Ep 97: Batch #51 - Loss: 0.9123692512512207\n",
      "Ep 97: Batch #52 - Loss: 0.7433440685272217\n",
      "Ep 97: Batch #53 - Loss: 0.7625913619995117\n",
      "Ep 97: Batch #54 - Loss: 0.6553640961647034\n",
      "Ep 97: Batch #55 - Loss: 0.6968157887458801\n",
      "Ep 97: Batch #56 - Loss: 1.1709253787994385\n",
      "Ep 97: Batch #57 - Loss: 0.7780631184577942\n",
      "Ep 97: Batch #58 - Loss: 0.9190376996994019\n",
      "Ep 97: Batch #59 - Loss: 0.640902042388916\n",
      "Ep 97: Batch #60 - Loss: 1.2294480800628662\n",
      "Ep 97: Batch #61 - Loss: 0.5953800082206726\n",
      "Ep 97: Batch #62 - Loss: 0.6704689264297485\n",
      "Ep 97: Batch #63 - Loss: 0.9329075813293457\n",
      "Ep 97: Batch #64 - Loss: 9.339345932006836\n",
      "Ep 97: Batch #65 - Loss: 0.5695982575416565\n",
      "Ep 97: Batch #66 - Loss: 0.7359091639518738\n",
      "Ep 97: Batch #67 - Loss: 0.8527218699455261\n",
      "Ep 97: Batch #68 - Loss: 0.8357804417610168\n",
      "Ep 97: Batch #69 - Loss: 0.6946106553077698\n",
      "Ep 97: Batch #70 - Loss: 0.7098783850669861\n",
      "Ep 97: Batch #71 - Loss: 0.6340955495834351\n",
      "Ep 97: Batch #72 - Loss: 0.7907270789146423\n",
      "Ep 97: Batch #73 - Loss: 0.8279516100883484\n",
      "Ep 97: Batch #74 - Loss: 0.6791365146636963\n",
      "Ep 97: Batch #75 - Loss: 0.7197054624557495\n",
      "Ep 97: Batch #76 - Loss: 1.034550666809082\n",
      "Ep 97: Batch #77 - Loss: 0.6768431067466736\n",
      "Ep 97: Batch #78 - Loss: 1.0715597867965698\n",
      "Ep 97: Batch #79 - Loss: 0.5817950367927551\n",
      "Ep 97: Batch #80 - Loss: 0.7892242670059204\n",
      "Ep 97: Batch #81 - Loss: 1.6191126108169556\n",
      "Ep 97: Batch #82 - Loss: 0.8168195486068726\n",
      "Ep 97: Batch #83 - Loss: 1.6897951364517212\n",
      "Ep 97: Batch #84 - Loss: 0.662463366985321\n",
      "Ep 97: Batch #85 - Loss: 0.9166504144668579\n",
      "Ep 97: Batch #86 - Loss: 0.6503486633300781\n",
      "Ep 97: Batch #87 - Loss: 0.6618988513946533\n",
      "Ep 97: Batch #88 - Loss: 0.7425931096076965\n",
      "Ep 97: Batch #89 - Loss: 0.8440350890159607\n",
      "Ep 97: Batch #90 - Loss: 1.0716361999511719\n",
      "Ep 97: Batch #91 - Loss: 0.7378581762313843\n",
      "Ep 97: Batch #92 - Loss: 0.9567888975143433\n",
      "Ep 97: Batch #93 - Loss: 0.9386311769485474\n",
      "Ep 97: Batch #94 - Loss: 0.9716951251029968\n",
      "Ep 97: Batch #95 - Loss: 0.8588340282440186\n",
      "Ep 97: Batch #96 - Loss: 0.8440009355545044\n",
      "Ep 97: Batch #97 - Loss: 0.674717903137207\n",
      "Ep 97: Batch #98 - Loss: 0.6847553253173828\n",
      "Ep 97: Batch #99 - Loss: 0.8944652676582336\n",
      "Ep 97: Batch #100 - Loss: 0.6267786622047424\n",
      "Ep 97: Batch #101 - Loss: 0.9873943328857422\n",
      "Ep 97: Batch #102 - Loss: 0.724856972694397\n",
      "Ep 97: Batch #103 - Loss: 0.7350180149078369\n",
      "Ep 97: Batch #104 - Loss: 0.7457088232040405\n",
      "Ep 97: Batch #105 - Loss: 0.9606229662895203\n",
      "Ep 97: Batch #106 - Loss: 0.710760772228241\n",
      "Ep 97: Batch #107 - Loss: 0.7020435333251953\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 97: Batch #108 - Loss: 0.9664624929428101\n",
      "Ep 97: Batch #109 - Loss: 0.7093635201454163\n",
      "Ep 97: Batch #110 - Loss: 0.8445377349853516\n",
      "Ep 97: Batch #111 - Loss: 1.2950173616409302\n",
      "Ep 97: Batch #112 - Loss: 0.9716547727584839\n",
      "Ep 97: Batch #113 - Loss: 0.7595835328102112\n",
      "Ep 97: Batch #114 - Loss: 0.8330259919166565\n",
      "Ep 97: Batch #115 - Loss: 1.0240073204040527\n",
      "Ep 97: Batch #116 - Loss: 0.597034752368927\n",
      "Ep 97: Batch #117 - Loss: 0.8168266415596008\n",
      "Ep 97: Batch #118 - Loss: 0.5029103755950928\n",
      "Model saved in file: ./weights_autoencoder_low_LR/model_e97b118_1516651281.9040434.ckpt\n",
      "Ep 97: Batch #119 - Loss: 0.9583908915519714\n",
      "Ep 97: Batch #120 - Loss: 0.7473323941230774\n",
      "Ep 97: Batch #121 - Loss: 0.6348220109939575\n",
      "Ep 97: Batch #122 - Loss: 0.7691121697425842\n",
      "Ep 97: Batch #123 - Loss: 0.7744966745376587\n",
      "Ep 97: Batch #124 - Loss: 0.6218039393424988\n",
      "Ep 97: Batch #125 - Loss: 2.6344075202941895\n",
      "Ep 97: Batch #126 - Loss: 1.1510066986083984\n",
      "Ep 97: Batch #127 - Loss: 0.6861706376075745\n",
      "Ep 97: Batch #128 - Loss: 1.0173619985580444\n",
      "Ep 97: Batch #129 - Loss: 0.774834930896759\n",
      "Ep 97: Batch #130 - Loss: 0.6724497675895691\n",
      "Ep 97: Batch #131 - Loss: 0.9126626253128052\n",
      "Ep 97: Batch #132 - Loss: 0.7646783590316772\n",
      "Ep 97: Batch #133 - Loss: 0.7551164031028748\n",
      "Ep 97: Batch #134 - Loss: 0.7128968238830566\n",
      "Ep 97: Batch #135 - Loss: 0.8969005942344666\n",
      "Ep 97: Batch #136 - Loss: 1.1041994094848633\n",
      "Ep 97: Batch #137 - Loss: 0.8908015489578247\n",
      "Ep 97: Batch #138 - Loss: 0.9938614964485168\n",
      "Ep 97: Batch #139 - Loss: 0.8296940922737122\n",
      "Ep 97: Batch #140 - Loss: 0.9839680194854736\n",
      "Ep 97: Batch #141 - Loss: 1.2771364450454712\n",
      "Ep 97: Batch #142 - Loss: 0.7371143102645874\n",
      "Ep 97: Batch #143 - Loss: 0.8863548040390015\n",
      "Ep 97: Batch #144 - Loss: 0.6730931997299194\n",
      "Ep 97: Batch #145 - Loss: 0.6332211494445801\n",
      "Ep 97: Batch #146 - Loss: 0.8315466046333313\n",
      "Ep 97: Batch #147 - Loss: 0.7933233976364136\n",
      "Ep 97: Batch #148 - Loss: 0.9006129503250122\n",
      "Ep 97: Batch #149 - Loss: 0.7891533970832825\n",
      "Ep 97: Batch #150 - Loss: 0.8274219036102295\n",
      "Ep 97: Batch #151 - Loss: 0.6873496770858765\n",
      "Ep 97: Batch #152 - Loss: 0.6990152597427368\n",
      "Ep 97: Batch #153 - Loss: 1.024929165840149\n",
      "Ep 97: Batch #154 - Loss: 0.7094495296478271\n",
      "Ep 97: Batch #155 - Loss: 0.7766584157943726\n",
      "Ep 97: Batch #156 - Loss: 0.9518734216690063\n",
      "Ep 97: Batch #157 - Loss: 0.7040581703186035\n",
      "Ep 97: Batch #158 - Loss: 0.7641527652740479\n",
      "Ep 97: Batch #159 - Loss: 0.7429826259613037\n",
      "Ep 97: Batch #160 - Loss: 0.8530026078224182\n",
      "Ep 97: Batch #161 - Loss: 0.760385274887085\n",
      "Ep 97: Batch #162 - Loss: 0.8689046502113342\n",
      "Ep 97: Batch #163 - Loss: 0.8725847601890564\n",
      "Ep 97: Batch #164 - Loss: 0.7260558009147644\n",
      "Ep 97: Batch #165 - Loss: 1.4415847063064575\n",
      "Ep 97: Batch #166 - Loss: 0.626853883266449\n",
      "Ep 97: Batch #167 - Loss: 1.0159156322479248\n",
      "Ep 97: Batch #168 - Loss: 0.794823408126831\n",
      "Ep 97: Batch #169 - Loss: 0.7490854859352112\n",
      "Ep 97: Batch #170 - Loss: 0.746941089630127\n",
      "Ep 97: Batch #171 - Loss: 0.7162788510322571\n",
      "Ep 97: Batch #172 - Loss: 0.5970237851142883\n",
      "Ep 97: Batch #173 - Loss: 1.104676604270935\n",
      "Ep 97: Batch #174 - Loss: 0.538745641708374\n",
      "Ep 97: Batch #175 - Loss: 0.7369050979614258\n",
      "Ep 97: Batch #176 - Loss: 1.070741891860962\n",
      "Ep 97: Batch #177 - Loss: 0.7873755693435669\n",
      "Ep 97: Batch #178 - Loss: 0.7069501876831055\n",
      "Ep 97: Batch #179 - Loss: 0.8744960427284241\n",
      "Ep 97: Batch #180 - Loss: 0.7832744717597961\n",
      "Ep 97: Batch #181 - Loss: 0.9147147536277771\n",
      "Ep 97: Batch #182 - Loss: 0.7175621390342712\n",
      "Ep 97: Batch #183 - Loss: 0.7154058814048767\n",
      "Ep 97: Batch #184 - Loss: 1.0084480047225952\n",
      "Ep 97: Batch #185 - Loss: 0.704336404800415\n",
      "Ep 97: Batch #186 - Loss: 0.887455403804779\n",
      "Ep 97: Batch #187 - Loss: 1.086708664894104\n",
      "Ep 97: Batch #188 - Loss: 1.2807810306549072\n",
      "Ep 97: Batch #189 - Loss: 0.6624675393104553\n",
      "Ep 97: Batch #190 - Loss: 0.686034619808197\n",
      "Ep 97: Batch #191 - Loss: 0.9838463068008423\n",
      "Ep 97: Batch #192 - Loss: 0.6331079602241516\n",
      "Ep 97: Batch #193 - Loss: 0.6877691745758057\n",
      "Ep 97: Batch #194 - Loss: 0.6447659134864807\n",
      "Ep 97: Batch #195 - Loss: 0.9155169725418091\n",
      "Ep 97: Batch #196 - Loss: 0.8009445667266846\n",
      "Ep 97: Batch #197 - Loss: 0.8311377167701721\n",
      "Ep 97: Batch #198 - Loss: 0.6255508661270142\n",
      "Ep 97: Batch #199 - Loss: 0.7993142604827881\n",
      "Ep 98: Batch #0 - Loss: 0.7286962866783142\n",
      "Ep 98: Batch #1 - Loss: 0.811193585395813\n",
      "Ep 98: Batch #2 - Loss: 0.9574352502822876\n",
      "Ep 98: Batch #3 - Loss: 0.8084280490875244\n",
      "Ep 98: Batch #4 - Loss: 0.729478657245636\n",
      "Ep 98: Batch #5 - Loss: 0.623195469379425\n",
      "Ep 98: Batch #6 - Loss: 0.8206233978271484\n",
      "Ep 98: Batch #7 - Loss: 0.6550506949424744\n",
      "Ep 98: Batch #8 - Loss: 0.6818276047706604\n",
      "Ep 98: Batch #9 - Loss: 1.3032678365707397\n",
      "Ep 98: Batch #10 - Loss: 0.9425237774848938\n",
      "Ep 98: Batch #11 - Loss: 0.6232894659042358\n",
      "Ep 98: Batch #12 - Loss: 1.4869199991226196\n",
      "Ep 98: Batch #13 - Loss: 0.6109124422073364\n",
      "Ep 98: Batch #14 - Loss: 0.6812876462936401\n",
      "Ep 98: Batch #15 - Loss: 1.1547908782958984\n",
      "Ep 98: Batch #16 - Loss: 1.1802831888198853\n",
      "Ep 98: Batch #17 - Loss: 0.8170489072799683\n",
      "Ep 98: Batch #18 - Loss: 0.9005314111709595\n",
      "Ep 98: Batch #19 - Loss: 0.6288391351699829\n",
      "Ep 98: Batch #20 - Loss: 0.6079611778259277\n",
      "Ep 98: Batch #21 - Loss: 1.1506518125534058\n",
      "Ep 98: Batch #22 - Loss: 0.6792857050895691\n",
      "Ep 98: Batch #23 - Loss: 0.6860975027084351\n",
      "Ep 98: Batch #24 - Loss: 0.7758433222770691\n",
      "Ep 98: Batch #25 - Loss: 0.6638323664665222\n",
      "Ep 98: Batch #26 - Loss: 0.6736863851547241\n",
      "Ep 98: Batch #27 - Loss: 1.2629226446151733\n",
      "Ep 98: Batch #28 - Loss: 0.8164857029914856\n",
      "Ep 98: Batch #29 - Loss: 0.8249059915542603\n",
      "Ep 98: Batch #30 - Loss: 1.127975344657898\n",
      "Ep 98: Batch #31 - Loss: 0.6294906735420227\n",
      "Ep 98: Batch #32 - Loss: 0.6915826797485352\n",
      "Ep 98: Batch #33 - Loss: 0.7557882070541382\n",
      "Ep 98: Batch #34 - Loss: 0.7296076416969299\n",
      "Ep 98: Batch #35 - Loss: 0.8760039806365967\n",
      "Ep 98: Batch #36 - Loss: 0.6494101285934448\n",
      "Ep 98: Batch #37 - Loss: 1.0814400911331177\n",
      "Ep 98: Batch #38 - Loss: 0.6819886565208435\n",
      "Ep 98: Batch #39 - Loss: 0.7700251936912537\n",
      "Ep 98: Batch #40 - Loss: 0.7207272052764893\n",
      "Ep 98: Batch #41 - Loss: 0.6758400797843933\n",
      "Ep 98: Batch #42 - Loss: 0.6714978218078613\n",
      "Ep 98: Batch #43 - Loss: 0.7356873750686646\n",
      "Ep 98: Batch #44 - Loss: 0.7216675877571106\n",
      "Ep 98: Batch #45 - Loss: 0.5850948095321655\n",
      "Ep 98: Batch #46 - Loss: 0.763588011264801\n",
      "Ep 98: Batch #47 - Loss: 0.8769508600234985\n",
      "Ep 98: Batch #48 - Loss: 1.2797455787658691\n",
      "Ep 98: Batch #49 - Loss: 0.9334508776664734\n",
      "Ep 98: Batch #50 - Loss: 0.664344310760498\n",
      "Ep 98: Batch #51 - Loss: 0.9110629558563232\n",
      "Ep 98: Batch #52 - Loss: 0.7425057291984558\n",
      "Ep 98: Batch #53 - Loss: 0.7616175413131714\n",
      "Ep 98: Batch #54 - Loss: 0.6545307040214539\n",
      "Ep 98: Batch #55 - Loss: 0.6959179639816284\n",
      "Ep 98: Batch #56 - Loss: 1.1694318056106567\n",
      "Ep 98: Batch #57 - Loss: 0.7768958210945129\n",
      "Ep 98: Batch #58 - Loss: 0.9178153276443481\n",
      "Ep 98: Batch #59 - Loss: 0.6402654051780701\n",
      "Ep 98: Batch #60 - Loss: 1.2281436920166016\n",
      "Ep 98: Batch #61 - Loss: 0.5947557091712952\n",
      "Ep 98: Batch #62 - Loss: 0.6697302460670471\n",
      "Ep 98: Batch #63 - Loss: 0.9318058490753174\n",
      "Ep 98: Batch #64 - Loss: 9.337796211242676\n",
      "Ep 98: Batch #65 - Loss: 0.5689077377319336\n",
      "Ep 98: Batch #66 - Loss: 0.735016405582428\n",
      "Ep 98: Batch #67 - Loss: 0.8518921732902527\n",
      "Ep 98: Batch #68 - Loss: 0.8346285223960876\n",
      "Ep 98: Batch #69 - Loss: 0.6938158273696899\n",
      "Ep 98: Batch #70 - Loss: 0.7087944149971008\n",
      "Ep 98: Batch #71 - Loss: 0.6333165168762207\n",
      "Ep 98: Batch #72 - Loss: 0.7896876335144043\n",
      "Ep 98: Batch #73 - Loss: 0.8268121480941772\n",
      "Ep 98: Batch #74 - Loss: 0.6781778335571289\n",
      "Ep 98: Batch #75 - Loss: 0.7189671993255615\n",
      "Ep 98: Batch #76 - Loss: 1.033600091934204\n",
      "Ep 98: Batch #77 - Loss: 0.675976037979126\n",
      "Ep 98: Batch #78 - Loss: 1.0701361894607544\n",
      "Ep 98: Batch #79 - Loss: 0.5811237692832947\n",
      "Ep 98: Batch #80 - Loss: 0.7880969047546387\n",
      "Ep 98: Batch #81 - Loss: 1.618221402168274\n",
      "Ep 98: Batch #82 - Loss: 0.815956175327301\n",
      "Ep 98: Batch #83 - Loss: 1.689141869544983\n",
      "Ep 98: Batch #84 - Loss: 0.6617192029953003\n",
      "Ep 98: Batch #85 - Loss: 0.9157190322875977\n",
      "Ep 98: Batch #86 - Loss: 0.6494587063789368\n",
      "Ep 98: Batch #87 - Loss: 0.6610899567604065\n",
      "Ep 98: Batch #88 - Loss: 0.7417190670967102\n",
      "Ep 98: Batch #89 - Loss: 0.8433778285980225\n",
      "Ep 98: Batch #90 - Loss: 1.0703996419906616\n",
      "Ep 98: Batch #91 - Loss: 0.7368823885917664\n",
      "Ep 98: Batch #92 - Loss: 0.9556776285171509\n",
      "Ep 98: Batch #93 - Loss: 0.937137246131897\n",
      "Ep 98: Batch #94 - Loss: 0.9704304933547974\n",
      "Ep 98: Batch #95 - Loss: 0.8578640222549438\n",
      "Ep 98: Batch #96 - Loss: 0.8430295586585999\n",
      "Ep 98: Batch #97 - Loss: 0.6738900542259216\n",
      "Ep 98: Batch #98 - Loss: 0.6839296221733093\n",
      "Ep 98: Batch #99 - Loss: 0.8935147523880005\n",
      "Ep 98: Batch #100 - Loss: 0.625990092754364\n",
      "Ep 98: Batch #101 - Loss: 0.9864555597305298\n",
      "Ep 98: Batch #102 - Loss: 0.7239232659339905\n",
      "Ep 98: Batch #103 - Loss: 0.7342106103897095\n",
      "Ep 98: Batch #104 - Loss: 0.7448312044143677\n",
      "Ep 98: Batch #105 - Loss: 0.959627628326416\n",
      "Ep 98: Batch #106 - Loss: 0.7100215554237366\n",
      "Ep 98: Batch #107 - Loss: 0.7011576294898987\n",
      "Ep 98: Batch #108 - Loss: 0.9654840230941772\n",
      "Ep 98: Batch #109 - Loss: 0.7085173726081848\n",
      "Ep 98: Batch #110 - Loss: 0.8433663845062256\n",
      "Ep 98: Batch #111 - Loss: 1.2936530113220215\n",
      "Ep 98: Batch #112 - Loss: 0.9704654216766357\n",
      "Ep 98: Batch #113 - Loss: 0.7586350440979004\n",
      "Ep 98: Batch #114 - Loss: 0.8319647908210754\n",
      "Ep 98: Batch #115 - Loss: 1.0229403972625732\n",
      "Ep 98: Batch #116 - Loss: 0.5964367389678955\n",
      "Ep 98: Batch #117 - Loss: 0.8159647583961487\n",
      "Ep 98: Batch #118 - Loss: 0.5022687911987305\n",
      "Model saved in file: ./weights_autoencoder_low_LR/model_e98b118_1516651282.0381882.ckpt\n",
      "Ep 98: Batch #119 - Loss: 0.9572580456733704\n",
      "Ep 98: Batch #120 - Loss: 0.7464987635612488\n",
      "Ep 98: Batch #121 - Loss: 0.6340327262878418\n",
      "Ep 98: Batch #122 - Loss: 0.76824551820755\n",
      "Ep 98: Batch #123 - Loss: 0.7736374735832214\n",
      "Ep 98: Batch #124 - Loss: 0.621163010597229\n",
      "Ep 98: Batch #125 - Loss: 2.633074998855591\n",
      "Ep 98: Batch #126 - Loss: 1.149859070777893\n",
      "Ep 98: Batch #127 - Loss: 0.6850659847259521\n",
      "Ep 98: Batch #128 - Loss: 1.0160021781921387\n",
      "Ep 98: Batch #129 - Loss: 0.773833692073822\n",
      "Ep 98: Batch #130 - Loss: 0.6716433167457581\n",
      "Ep 98: Batch #131 - Loss: 0.9113643765449524\n",
      "Ep 98: Batch #132 - Loss: 0.7637978196144104\n",
      "Ep 98: Batch #133 - Loss: 0.7540895938873291\n",
      "Ep 98: Batch #134 - Loss: 0.712081789970398\n",
      "Ep 98: Batch #135 - Loss: 0.8958992958068848\n",
      "Ep 98: Batch #136 - Loss: 1.1030323505401611\n",
      "Ep 98: Batch #137 - Loss: 0.8896511197090149\n",
      "Ep 98: Batch #138 - Loss: 0.9925700426101685\n",
      "Ep 98: Batch #139 - Loss: 0.8285535573959351\n",
      "Ep 98: Batch #140 - Loss: 0.9829868674278259\n",
      "Ep 98: Batch #141 - Loss: 1.2758533954620361\n",
      "Ep 98: Batch #142 - Loss: 0.7362027764320374\n",
      "Ep 98: Batch #143 - Loss: 0.8851480484008789\n",
      "Ep 98: Batch #144 - Loss: 0.672394335269928\n",
      "Ep 98: Batch #145 - Loss: 0.6325616836547852\n",
      "Ep 98: Batch #146 - Loss: 0.8307932019233704\n",
      "Ep 98: Batch #147 - Loss: 0.7923632860183716\n",
      "Ep 98: Batch #148 - Loss: 0.8994136452674866\n",
      "Ep 98: Batch #149 - Loss: 0.7881851196289062\n",
      "Ep 98: Batch #150 - Loss: 0.8266412615776062\n",
      "Ep 98: Batch #151 - Loss: 0.6867493987083435\n",
      "Ep 98: Batch #152 - Loss: 0.6984203457832336\n",
      "Ep 98: Batch #153 - Loss: 1.023666262626648\n",
      "Ep 98: Batch #154 - Loss: 0.7086650729179382\n",
      "Ep 98: Batch #155 - Loss: 0.7758233547210693\n",
      "Ep 98: Batch #156 - Loss: 0.9508362412452698\n",
      "Ep 98: Batch #157 - Loss: 0.7031951546669006\n",
      "Ep 98: Batch #158 - Loss: 0.7635253667831421\n",
      "Ep 98: Batch #159 - Loss: 0.7419541478157043\n",
      "Ep 98: Batch #160 - Loss: 0.8522012829780579\n",
      "Ep 98: Batch #161 - Loss: 0.7596344947814941\n",
      "Ep 98: Batch #162 - Loss: 0.8678911924362183\n",
      "Ep 98: Batch #163 - Loss: 0.8716284036636353\n",
      "Ep 98: Batch #164 - Loss: 0.7251675128936768\n",
      "Ep 98: Batch #165 - Loss: 1.4406976699829102\n",
      "Ep 98: Batch #166 - Loss: 0.6260454058647156\n",
      "Ep 98: Batch #167 - Loss: 1.0147873163223267\n",
      "Ep 98: Batch #168 - Loss: 0.7937726974487305\n",
      "Ep 98: Batch #169 - Loss: 0.7483015060424805\n",
      "Ep 98: Batch #170 - Loss: 0.7460483908653259\n",
      "Ep 98: Batch #171 - Loss: 0.7152792811393738\n",
      "Ep 98: Batch #172 - Loss: 0.5964864492416382\n",
      "Ep 98: Batch #173 - Loss: 1.1032804250717163\n",
      "Ep 98: Batch #174 - Loss: 0.5381278395652771\n",
      "Ep 98: Batch #175 - Loss: 0.7362509369850159\n",
      "Ep 98: Batch #176 - Loss: 1.0695031881332397\n",
      "Ep 98: Batch #177 - Loss: 0.7864110469818115\n",
      "Ep 98: Batch #178 - Loss: 0.706076443195343\n",
      "Ep 98: Batch #179 - Loss: 0.8734390139579773\n",
      "Ep 98: Batch #180 - Loss: 0.7821366190910339\n",
      "Ep 98: Batch #181 - Loss: 0.9135382175445557\n",
      "Ep 98: Batch #182 - Loss: 0.7168262004852295\n",
      "Ep 98: Batch #183 - Loss: 0.7146785259246826\n",
      "Ep 98: Batch #184 - Loss: 1.0074721574783325\n",
      "Ep 98: Batch #185 - Loss: 0.7035010457038879\n",
      "Ep 98: Batch #186 - Loss: 0.886197566986084\n",
      "Ep 98: Batch #187 - Loss: 1.0854134559631348\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 98: Batch #188 - Loss: 1.279597520828247\n",
      "Ep 98: Batch #189 - Loss: 0.6619002223014832\n",
      "Ep 98: Batch #190 - Loss: 0.6852590441703796\n",
      "Ep 98: Batch #191 - Loss: 0.9825538396835327\n",
      "Ep 98: Batch #192 - Loss: 0.6325455904006958\n",
      "Ep 98: Batch #193 - Loss: 0.6870033740997314\n",
      "Ep 98: Batch #194 - Loss: 0.643995463848114\n",
      "Ep 98: Batch #195 - Loss: 0.9144198894500732\n",
      "Ep 98: Batch #196 - Loss: 0.7999428510665894\n",
      "Ep 98: Batch #197 - Loss: 0.8300379514694214\n",
      "Ep 98: Batch #198 - Loss: 0.6247807741165161\n",
      "Ep 98: Batch #199 - Loss: 0.7982776165008545\n",
      "Ep 99: Batch #0 - Loss: 0.7277711033821106\n",
      "Ep 99: Batch #1 - Loss: 0.8102684020996094\n",
      "Ep 99: Batch #2 - Loss: 0.9566758871078491\n",
      "Ep 99: Batch #3 - Loss: 0.8075103759765625\n",
      "Ep 99: Batch #4 - Loss: 0.728573739528656\n",
      "Ep 99: Batch #5 - Loss: 0.6225587725639343\n",
      "Ep 99: Batch #6 - Loss: 0.8197518587112427\n",
      "Ep 99: Batch #7 - Loss: 0.6543771028518677\n",
      "Ep 99: Batch #8 - Loss: 0.680997908115387\n",
      "Ep 99: Batch #9 - Loss: 1.3016855716705322\n",
      "Ep 99: Batch #10 - Loss: 0.941469669342041\n",
      "Ep 99: Batch #11 - Loss: 0.6225056648254395\n",
      "Ep 99: Batch #12 - Loss: 1.485785961151123\n",
      "Ep 99: Batch #13 - Loss: 0.6103581190109253\n",
      "Ep 99: Batch #14 - Loss: 0.6806054711341858\n",
      "Ep 99: Batch #15 - Loss: 1.1534441709518433\n",
      "Ep 99: Batch #16 - Loss: 1.1787358522415161\n",
      "Ep 99: Batch #17 - Loss: 0.8160765767097473\n",
      "Ep 99: Batch #18 - Loss: 0.8998521566390991\n",
      "Ep 99: Batch #19 - Loss: 0.6282556056976318\n",
      "Ep 99: Batch #20 - Loss: 0.6072502136230469\n",
      "Ep 99: Batch #21 - Loss: 1.149573802947998\n",
      "Ep 99: Batch #22 - Loss: 0.6785376667976379\n",
      "Ep 99: Batch #23 - Loss: 0.6851907968521118\n",
      "Ep 99: Batch #24 - Loss: 0.7750669121742249\n",
      "Ep 99: Batch #25 - Loss: 0.663092315196991\n",
      "Ep 99: Batch #26 - Loss: 0.6728567481040955\n",
      "Ep 99: Batch #27 - Loss: 1.2614867687225342\n",
      "Ep 99: Batch #28 - Loss: 0.8156725764274597\n",
      "Ep 99: Batch #29 - Loss: 0.8239116072654724\n",
      "Ep 99: Batch #30 - Loss: 1.126731276512146\n",
      "Ep 99: Batch #31 - Loss: 0.6288555860519409\n",
      "Ep 99: Batch #32 - Loss: 0.6907620429992676\n",
      "Ep 99: Batch #33 - Loss: 0.7550137042999268\n",
      "Ep 99: Batch #34 - Loss: 0.7287899851799011\n",
      "Ep 99: Batch #35 - Loss: 0.8749478459358215\n",
      "Ep 99: Batch #36 - Loss: 0.6485955119132996\n",
      "Ep 99: Batch #37 - Loss: 1.0805649757385254\n",
      "Ep 99: Batch #38 - Loss: 0.6809841394424438\n",
      "Ep 99: Batch #39 - Loss: 0.7692168354988098\n",
      "Ep 99: Batch #40 - Loss: 0.7199119329452515\n",
      "Ep 99: Batch #41 - Loss: 0.6749532222747803\n",
      "Ep 99: Batch #42 - Loss: 0.6707487106323242\n",
      "Ep 99: Batch #43 - Loss: 0.7349199652671814\n",
      "Ep 99: Batch #44 - Loss: 0.7206614017486572\n",
      "Ep 99: Batch #45 - Loss: 0.5844029784202576\n",
      "Ep 99: Batch #46 - Loss: 0.7625487446784973\n",
      "Ep 99: Batch #47 - Loss: 0.8756420016288757\n",
      "Ep 99: Batch #48 - Loss: 1.2785435914993286\n",
      "Ep 99: Batch #49 - Loss: 0.9322172403335571\n",
      "Ep 99: Batch #50 - Loss: 0.6636788845062256\n",
      "Ep 99: Batch #51 - Loss: 0.9097669124603271\n",
      "Ep 99: Batch #52 - Loss: 0.7416695952415466\n",
      "Ep 99: Batch #53 - Loss: 0.7606484889984131\n",
      "Ep 99: Batch #54 - Loss: 0.6537011861801147\n",
      "Ep 99: Batch #55 - Loss: 0.6950166821479797\n",
      "Ep 99: Batch #56 - Loss: 1.1679531335830688\n",
      "Ep 99: Batch #57 - Loss: 0.7757346034049988\n",
      "Ep 99: Batch #58 - Loss: 0.9166008830070496\n",
      "Ep 99: Batch #59 - Loss: 0.6396310329437256\n",
      "Ep 99: Batch #60 - Loss: 1.2268511056900024\n",
      "Ep 99: Batch #61 - Loss: 0.5941346883773804\n",
      "Ep 99: Batch #62 - Loss: 0.6689997911453247\n",
      "Ep 99: Batch #63 - Loss: 0.9307152628898621\n",
      "Ep 99: Batch #64 - Loss: 9.336156845092773\n",
      "Ep 99: Batch #65 - Loss: 0.5682207942008972\n",
      "Ep 99: Batch #66 - Loss: 0.7341288328170776\n",
      "Ep 99: Batch #67 - Loss: 0.8510691523551941\n",
      "Ep 99: Batch #68 - Loss: 0.8334823846817017\n",
      "Ep 99: Batch #69 - Loss: 0.6930314302444458\n",
      "Ep 99: Batch #70 - Loss: 0.7077189683914185\n",
      "Ep 99: Batch #71 - Loss: 0.6325411796569824\n",
      "Ep 99: Batch #72 - Loss: 0.7886607050895691\n",
      "Ep 99: Batch #73 - Loss: 0.8256872296333313\n",
      "Ep 99: Batch #74 - Loss: 0.6772269010543823\n",
      "Ep 99: Batch #75 - Loss: 0.7182319760322571\n",
      "Ep 99: Batch #76 - Loss: 1.032659888267517\n",
      "Ep 99: Batch #77 - Loss: 0.6751189231872559\n",
      "Ep 99: Batch #78 - Loss: 1.0687233209609985\n",
      "Ep 99: Batch #79 - Loss: 0.580457866191864\n",
      "Ep 99: Batch #80 - Loss: 0.7869783043861389\n",
      "Ep 99: Batch #81 - Loss: 1.6173386573791504\n",
      "Ep 99: Batch #82 - Loss: 0.8151007890701294\n",
      "Ep 99: Batch #83 - Loss: 1.6884962320327759\n",
      "Ep 99: Batch #84 - Loss: 0.6609827876091003\n",
      "Ep 99: Batch #85 - Loss: 0.9147987961769104\n",
      "Ep 99: Batch #86 - Loss: 0.6485779285430908\n",
      "Ep 99: Batch #87 - Loss: 0.660284698009491\n",
      "Ep 99: Batch #88 - Loss: 0.7408539652824402\n",
      "Ep 99: Batch #89 - Loss: 0.8427265286445618\n",
      "Ep 99: Batch #90 - Loss: 1.0691742897033691\n",
      "Ep 99: Batch #91 - Loss: 0.7359142899513245\n",
      "Ep 99: Batch #92 - Loss: 0.9545707106590271\n",
      "Ep 99: Batch #93 - Loss: 0.9356522560119629\n",
      "Ep 99: Batch #94 - Loss: 0.969174325466156\n",
      "Ep 99: Batch #95 - Loss: 0.8569039702415466\n",
      "Ep 99: Batch #96 - Loss: 0.8420630693435669\n",
      "Ep 99: Batch #97 - Loss: 0.6730743050575256\n",
      "Ep 99: Batch #98 - Loss: 0.6831086277961731\n",
      "Ep 99: Batch #99 - Loss: 0.8925760984420776\n",
      "Ep 99: Batch #100 - Loss: 0.6252113580703735\n",
      "Ep 99: Batch #101 - Loss: 0.9855278134346008\n",
      "Ep 99: Batch #102 - Loss: 0.7229977250099182\n",
      "Ep 99: Batch #103 - Loss: 0.7334079146385193\n",
      "Ep 99: Batch #104 - Loss: 0.7439588308334351\n",
      "Ep 99: Batch #105 - Loss: 0.9586430788040161\n",
      "Ep 99: Batch #106 - Loss: 0.7092865705490112\n",
      "Ep 99: Batch #107 - Loss: 0.7002790570259094\n",
      "Ep 99: Batch #108 - Loss: 0.9645181894302368\n",
      "Ep 99: Batch #109 - Loss: 0.7076767086982727\n",
      "Ep 99: Batch #110 - Loss: 0.842205286026001\n",
      "Ep 99: Batch #111 - Loss: 1.2923007011413574\n",
      "Ep 99: Batch #112 - Loss: 0.9692860841751099\n",
      "Ep 99: Batch #113 - Loss: 0.7576897740364075\n",
      "Ep 99: Batch #114 - Loss: 0.830913245677948\n",
      "Ep 99: Batch #115 - Loss: 1.0218836069107056\n",
      "Ep 99: Batch #116 - Loss: 0.5958420634269714\n",
      "Ep 99: Batch #117 - Loss: 0.8151127696037292\n",
      "Ep 99: Batch #118 - Loss: 0.501631498336792\n",
      "Model saved in file: ./weights_autoencoder_low_LR/model_e99b118_1516651282.1736195.ckpt\n",
      "Ep 99: Batch #119 - Loss: 0.9561343789100647\n",
      "Ep 99: Batch #120 - Loss: 0.7456716299057007\n",
      "Ep 99: Batch #121 - Loss: 0.6332536935806274\n",
      "Ep 99: Batch #122 - Loss: 0.7673857808113098\n",
      "Ep 99: Batch #123 - Loss: 0.7727802395820618\n",
      "Ep 99: Batch #124 - Loss: 0.6205272078514099\n",
      "Ep 99: Batch #125 - Loss: 2.6317496299743652\n",
      "Ep 99: Batch #126 - Loss: 1.1487202644348145\n",
      "Ep 99: Batch #127 - Loss: 0.6839715242385864\n",
      "Ep 99: Batch #128 - Loss: 1.0146547555923462\n",
      "Ep 99: Batch #129 - Loss: 0.7728378772735596\n",
      "Ep 99: Batch #130 - Loss: 0.6708440780639648\n",
      "Ep 99: Batch #131 - Loss: 0.9100768566131592\n",
      "Ep 99: Batch #132 - Loss: 0.7629298567771912\n",
      "Ep 99: Batch #133 - Loss: 0.7530671954154968\n",
      "Ep 99: Batch #134 - Loss: 0.7112755179405212\n",
      "Ep 99: Batch #135 - Loss: 0.8949036002159119\n",
      "Ep 99: Batch #136 - Loss: 1.101881742477417\n",
      "Ep 99: Batch #137 - Loss: 0.8885164260864258\n",
      "Ep 99: Batch #138 - Loss: 0.9913396239280701\n",
      "Ep 99: Batch #139 - Loss: 0.8274222016334534\n",
      "Ep 99: Batch #140 - Loss: 0.9820148944854736\n",
      "Ep 99: Batch #141 - Loss: 1.2745745182037354\n",
      "Ep 99: Batch #142 - Loss: 0.7353013157844543\n",
      "Ep 99: Batch #143 - Loss: 0.8839451670646667\n",
      "Ep 99: Batch #144 - Loss: 0.6717005372047424\n",
      "Ep 99: Batch #145 - Loss: 0.6319065093994141\n",
      "Ep 99: Batch #146 - Loss: 0.8300472497940063\n",
      "Ep 99: Batch #147 - Loss: 0.7914151549339294\n",
      "Ep 99: Batch #148 - Loss: 0.8982282280921936\n",
      "Ep 99: Batch #149 - Loss: 0.7872284650802612\n",
      "Ep 99: Batch #150 - Loss: 0.8258697986602783\n",
      "Ep 99: Batch #151 - Loss: 0.6861556768417358\n",
      "Ep 99: Batch #152 - Loss: 0.6978346109390259\n",
      "Ep 99: Batch #153 - Loss: 1.0224148035049438\n",
      "Ep 99: Batch #154 - Loss: 0.7078936100006104\n",
      "Ep 99: Batch #155 - Loss: 0.7750012874603271\n",
      "Ep 99: Batch #156 - Loss: 0.9498090744018555\n",
      "Ep 99: Batch #157 - Loss: 0.7023376226425171\n",
      "Ep 99: Batch #158 - Loss: 0.7628998160362244\n",
      "Ep 99: Batch #159 - Loss: 0.7409366965293884\n",
      "Ep 99: Batch #160 - Loss: 0.8514002561569214\n",
      "Ep 99: Batch #161 - Loss: 0.7588937282562256\n",
      "Ep 99: Batch #162 - Loss: 0.8668871521949768\n",
      "Ep 99: Batch #163 - Loss: 0.8706870675086975\n",
      "Ep 99: Batch #164 - Loss: 0.7242915034294128\n",
      "Ep 99: Batch #165 - Loss: 1.4398173093795776\n",
      "Ep 99: Batch #166 - Loss: 0.6252470016479492\n",
      "Ep 99: Batch #167 - Loss: 1.0136713981628418\n",
      "Ep 99: Batch #168 - Loss: 0.7927300333976746\n",
      "Ep 99: Batch #169 - Loss: 0.7475196123123169\n",
      "Ep 99: Batch #170 - Loss: 0.7451686263084412\n",
      "Ep 99: Batch #171 - Loss: 0.7142904996871948\n",
      "Ep 99: Batch #172 - Loss: 0.5959533452987671\n",
      "Ep 99: Batch #173 - Loss: 1.1019058227539062\n",
      "Ep 99: Batch #174 - Loss: 0.5375099182128906\n",
      "Ep 99: Batch #175 - Loss: 0.7356007695198059\n",
      "Ep 99: Batch #176 - Loss: 1.0682759284973145\n",
      "Ep 99: Batch #177 - Loss: 0.7854514122009277\n",
      "Ep 99: Batch #178 - Loss: 0.7052170634269714\n",
      "Ep 99: Batch #179 - Loss: 0.8723872303962708\n",
      "Ep 99: Batch #180 - Loss: 0.7810109257698059\n",
      "Ep 99: Batch #181 - Loss: 0.9123714566230774\n",
      "Ep 99: Batch #182 - Loss: 0.7161005139350891\n",
      "Ep 99: Batch #183 - Loss: 0.7139527201652527\n",
      "Ep 99: Batch #184 - Loss: 1.0065032243728638\n",
      "Ep 99: Batch #185 - Loss: 0.7026773691177368\n",
      "Ep 99: Batch #186 - Loss: 0.8849494457244873\n",
      "Ep 99: Batch #187 - Loss: 1.0841279029846191\n",
      "Ep 99: Batch #188 - Loss: 1.2784301042556763\n",
      "Ep 99: Batch #189 - Loss: 0.6613382697105408\n",
      "Ep 99: Batch #190 - Loss: 0.684485673904419\n",
      "Ep 99: Batch #191 - Loss: 0.9812758564949036\n",
      "Ep 99: Batch #192 - Loss: 0.6319878697395325\n",
      "Ep 99: Batch #193 - Loss: 0.6862397789955139\n",
      "Ep 99: Batch #194 - Loss: 0.6432334780693054\n",
      "Ep 99: Batch #195 - Loss: 0.9133325815200806\n",
      "Ep 99: Batch #196 - Loss: 0.798951268196106\n",
      "Ep 99: Batch #197 - Loss: 0.8289480805397034\n",
      "Ep 99: Batch #198 - Loss: 0.624020516872406\n",
      "Ep 99: Batch #199 - Loss: 0.7972438931465149\n"
     ]
    }
   ],
   "source": [
    "losses = []\n",
    "min_loss = float(\"inf\")\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for epoch in range(100):\n",
    "        for i in range(200):\n",
    "            batch = next_batch(100, i)\n",
    "    #         print(batch[0].shape, batch[1].shape)\n",
    "#             train_step.run(feed_dict={x: batch})\n",
    "            _, current_loss = sess.run([train_step, loss], feed_dict={x:batch})\n",
    "            losses.append(current_loss)\n",
    "            print(\"Ep {}: Batch #{} - Loss: {}\".format(epoch, i, losses[-1]))\n",
    "            if losses[-1] < min_loss:\n",
    "                min_loss = losses[-1]\n",
    "                save_path = saver.save(sess, \"./weights_autoencoder_low_LR/model_e{}b{}_{}.ckpt\".format(epoch, i, time.time()))\n",
    "                print(\"Model saved in file: %s\" % save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAk0AAAJCCAYAAADdrPONAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f1995b349e8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Pure w/ low learning rate\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.plot(losses)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW4AAAD8CAYAAABXe05zAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nGYaJm4jIMP8PU7OB70IYBcoAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f1993057400>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Pure w/ low learning rate\n",
    "plt.plot(losses)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW4AAAD8CAYAAABXe05zAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nxIyCW0QkZv4/NTeyznjbAfUAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f22bf79ea20>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Pure\n",
    "plt.plot(losses)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW4AAAD8CAYAAABXe05zAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYDsAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fe479a8c748>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Sigmoid\n",
    "plt.plot(losses)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW4AAAD8CAYAAABXe05zAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f09c80f6f28>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#ReLU\n",
    "plt.plot(losses)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlUAAAJOCAYAAACeF/LqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nePEGagms7iUAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f18a06dc898>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Pure w/ low learning rate\n",
    "plot_points_31D = {\"s005\":[], \"s010\":[], \"s011\":[], \"s016\":[]}\n",
    "plot_points_2D = {\"s005\":[], \"s010\":[], \"s011\":[], \"s016\":[]}\n",
    "for i, point in enumerate(norm_keystrokes):\n",
    "    if recordings[i][0] in vis_users:\n",
    "        plot_points_31D[recordings[i][0]].append(point)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for user in plot_points_31D:\n",
    "        points_31D = np.array(plot_points_31D[user])\n",
    "        points_2D = sess.run(embedding_2D, feed_dict={x:points_31D})\n",
    "        plot_points_2D[user] = points_2D\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "for user in plot_points_2D:\n",
    "    plt.scatter(plot_points_2D[user][:,0], plot_points_2D[user][:,1], c=colors[user])\n",
    "plt.title(\"Dados de digitação dos usuários {}\".format(\", \".join(vis_users)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlUAAAJOCAYAAACeF/LqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f22c2277710>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Pure\n",
    "plot_points_31D = {\"s005\":[], \"s010\":[], \"s011\":[], \"s016\":[]}\n",
    "plot_points_2D = {\"s005\":[], \"s010\":[], \"s011\":[], \"s016\":[]}\n",
    "for i, point in enumerate(norm_keystrokes):\n",
    "    if recordings[i][0] in vis_users:\n",
    "        plot_points_31D[recordings[i][0]].append(point)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for user in plot_points_31D:\n",
    "        points_31D = np.array(plot_points_31D[user])\n",
    "        points_2D = sess.run(embedding_2D, feed_dict={x:points_31D})\n",
    "        plot_points_2D[user] = points_2D\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "for user in plot_points_2D:\n",
    "    plt.scatter(plot_points_2D[user][:,0], plot_points_2D[user][:,1], c=colors[user])\n",
    "plt.title(\"Dados de digitação dos usuários {}\".format(\", \".join(vis_users)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlYAAAJOCAYAAAB1IEnpAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fe476f92588>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Sigmoid\n",
    "plot_points_31D = {\"s005\":[], \"s010\":[], \"s011\":[], \"s016\":[]}\n",
    "plot_points_2D = {\"s005\":[], \"s010\":[], \"s011\":[], \"s016\":[]}\n",
    "for i, point in enumerate(norm_keystrokes):\n",
    "    if recordings[i][0] in vis_users:\n",
    "        plot_points_31D[recordings[i][0]].append(point)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for user in plot_points_31D:\n",
    "        points_31D = np.array(plot_points_31D[user])\n",
    "        points_2D = sess.run(embedding_2D, feed_dict={x:points_31D})\n",
    "        plot_points_2D[user] = points_2D\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "for user in plot_points_2D:\n",
    "    plt.scatter(plot_points_2D[user][:,0], plot_points_2D[user][:,1], c=colors[user])\n",
    "plt.title(\"Dados de digitação dos usuários {}\".format(\", \".join(vis_users)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classificação\n",
    "Agora que temos um melhor entendimento dos dados do dataset, passemos à parte de classificação de dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.5  1.5  1.5]\n",
      "[[-1. -1. -1.]\n",
      " [ 1.  1.  1.]]\n"
     ]
    }
   ],
   "source": [
    "s = np.std(a, axis=0)\n",
    "n = (a - m) / s\n",
    "print(s)\n",
    "print(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 0 0 0]\n",
      " [0 2 0 0]\n",
      " [0 0 0 0]\n",
      " [0 0 0 0]] \n",
      "\n",
      " [[ 1  2  3  4]\n",
      " [ 5  6  7  8]\n",
      " [ 9 10 11 12]\n",
      " [13 14 15 16]]\n",
      "\n",
      " [[ 1  2  3  4]\n",
      " [10 12 14 16]\n",
      " [ 0  0  0  0]\n",
      " [ 0  0  0  0]]\n"
     ]
    }
   ],
   "source": [
    "a = np.diag([1,2,0,0])\n",
    "b = np.array([[1,2,3,4],[5,6,7,8],[9,10,11,12],[13,14,15,16]])\n",
    "c = a @ b\n",
    "print(a,\"\\n\\n\", b)\n",
    "print(\"\\n\",c)\n",
    "print(b )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 0 0 0]\n",
      " [2 0 0 0]\n",
      " [0 1 0 0]\n",
      " [0 2 0 0]\n",
      " [0 1 1 0]\n",
      " [1 0 0 1]]\n",
      "\n",
      "[[  0.00000000e+00  -3.94599292e-01  -2.10455217e-01   0.00000000e+00\n",
      "    0.00000000e+00  -8.94427191e-01]\n",
      " [  0.00000000e+00  -7.89198585e-01  -4.20910435e-01   0.00000000e+00\n",
      "    0.00000000e+00   4.47213595e-01]\n",
      " [ -3.94599292e-01   0.00000000e+00   0.00000000e+00  -2.10455217e-01\n",
      "   -8.94427191e-01   0.00000000e+00]\n",
      " [ -7.89198585e-01   0.00000000e+00   0.00000000e+00  -4.20910435e-01\n",
      "    4.47213595e-01   0.00000000e+00]\n",
      " [ -4.70592172e-01   0.00000000e+00   0.00000000e+00   8.82350841e-01\n",
      "    0.00000000e+00   0.00000000e+00]\n",
      " [  0.00000000e+00  -4.70592172e-01   8.82350841e-01   0.00000000e+00\n",
      "    0.00000000e+00   1.11022302e-16]]\n",
      "\n",
      "[ 2.48848998  2.48848998  0.89856419  0.89856419]\n",
      "\n",
      "[[-0.         -0.98195639 -0.18910752  0.        ]\n",
      " [-0.98195639  0.         -0.         -0.18910752]\n",
      " [-0.18910752  0.          0.          0.98195639]\n",
      " [-0.         -0.18910752  0.98195639  0.        ]]\n",
      "\n",
      "[[ 2.48848998  0.          0.          0.        ]\n",
      " [ 0.          2.48848998  0.          0.        ]\n",
      " [ 0.          0.          0.89856419  0.        ]\n",
      " [ 0.          0.          0.          0.89856419]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]]\n",
      "================================================== \n",
      "\n",
      "\n",
      "[[  1.00000000e+00   0.00000000e+00   0.00000000e+00   1.66533454e-16]\n",
      " [  2.00000000e+00   0.00000000e+00   0.00000000e+00  -5.55111512e-17]\n",
      " [  0.00000000e+00   1.00000000e+00   5.55111512e-17   0.00000000e+00]\n",
      " [  0.00000000e+00   2.00000000e+00   0.00000000e+00   0.00000000e+00]\n",
      " [  0.00000000e+00   1.00000000e+00   1.00000000e+00   0.00000000e+00]\n",
      " [  1.00000000e+00   0.00000000e+00   0.00000000e+00   1.00000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "t = np.array([[1,0,0,0],[2,0,0,0],[0,1,0,0],[0,2,0,0],[0,1,1,0],[1,0,0,1]])\n",
    "# t = t.T\n",
    "d = np.linalg.svd(t)\n",
    "print(t, end=\"\\n\\n\")\n",
    "print(d[0], d[1], d[2], sep=\"\\n\\n\", end=\"\\n\\n\")\n",
    "ss = np.zeros((6,4))\n",
    "# d[1][2] = 0\n",
    "# d[1][3] = 0\n",
    "for i, e in enumerate(d[1]):\n",
    "    ss[i,i] = e\n",
    "print(ss)\n",
    "print(\"=\"*50, \"\\n\\n\")\n",
    "print(d[0]@ss@d[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "partial = keystrokes[:2000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.1227,  0.3441,  0.2214, ...,  0.2655,  0.1832,  0.1084],\n",
       "       [ 0.0377,  0.5097,  0.472 , ...,  0.4406,  0.4013,  0.0364],\n",
       "       [ 0.0853,  0.1757,  0.0904, ...,  0.1929,  0.1121,  0.0829],\n",
       "       ..., \n",
       "       [ 0.0776,  0.3103,  0.2327, ...,  0.2907,  0.1917,  0.0945],\n",
       "       [ 0.0591,  0.265 ,  0.2059, ...,  0.5553,  0.4746,  0.0886],\n",
       "       [ 0.0657,  0.409 ,  0.3433, ...,  0.3733,  0.2881,  0.072 ]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "decomp = np.linalg.svd(partial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000, 2000)\n",
      "(31,)\n",
      "(31, 31)\n"
     ]
    }
   ],
   "source": [
    "U, sigma, Vt = decomp\n",
    "print(U.shape)\n",
    "print(sigma.shape)\n",
    "print(Vt.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  5.37860351e+01   1.45971181e+01   1.39542872e+01   1.13840973e+01\n",
      "   9.56374289e+00   9.20264712e+00   7.71927016e+00   7.52113688e+00\n",
      "   6.41529380e+00   5.77067003e+00   5.50869931e+00   1.58892232e+00\n",
      "   1.37413431e+00   1.25452098e+00   1.12088379e+00   1.08756954e+00\n",
      "   9.80826384e-01   8.76163838e-01   8.50212712e-01   8.28806611e-01\n",
      "   7.73274781e-01   3.51964339e-14   1.44156497e-14   1.19870887e-14\n",
      "   7.79112368e-15   7.74209255e-15   5.80840869e-15   4.44215664e-15\n",
      "   4.44215664e-15   3.54364698e-15   2.97049823e-15]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7ff91d897320>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(sigma)\n",
    "plt.plot(sigma)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 53.7860351    0.           0.         ...,   0.           0.           0.        ]\n",
      " [  0.          14.59711807   0.         ...,   0.           0.           0.        ]\n",
      " [  0.           0.           0.         ...,   0.           0.           0.        ]\n",
      " ..., \n",
      " [  0.           0.           0.         ...,   0.           0.           0.        ]\n",
      " [  0.           0.           0.         ...,   0.           0.           0.        ]\n",
      " [  0.           0.           0.         ...,   0.           0.           0.        ]]\n",
      "[[ -6.75936637e-02  -2.49557191e-01]\n",
      " [ -1.83758381e-02   4.50418569e-01]\n",
      " [  1.78634943e-02   1.04421094e-01]\n",
      " [ -6.48506372e-02   4.12272012e-01]\n",
      " [  1.63725324e-01   2.09097054e-01]\n",
      " [ -1.31253972e-01   2.51447174e-02]\n",
      " [  7.42528957e-02   8.41307492e-02]\n",
      " [ -3.02612331e-02  -1.04679674e-01]\n",
      " [  5.76043880e-02   2.65105431e-02]\n",
      " [ -6.14543112e-02  -2.18016951e-02]\n",
      " [  5.57318797e-02   4.99800247e-02]\n",
      " [ -2.57013496e-01  -1.26424121e-01]\n",
      " [  3.85613053e-01   1.98459893e-01]\n",
      " [  7.74264202e-02   4.40429441e-02]\n",
      " [  3.85448027e-01   1.96395380e-01]\n",
      " [  9.79429630e-02   5.08728620e-02]\n",
      " [ -4.20698848e-01  -2.14278003e-01]\n",
      " [ -1.84091623e-01  -9.11536096e-02]\n",
      " [ -7.16081119e-02  -3.72812831e-02]\n",
      " [ -2.48134977e-02  -1.25010711e-02]\n",
      " [ -3.22447406e-02  -1.82936452e-02]\n",
      " [ -1.69083877e-01   1.69083877e-01]\n",
      " [ -5.52036209e-01   5.52036209e-01]\n",
      " [ -0.00000000e+00  -9.29213601e-15]\n",
      " [  0.00000000e+00   2.26755533e-15]\n",
      " [  0.00000000e+00   2.07052325e-15]\n",
      " [  0.00000000e+00  -7.88690537e-16]\n",
      " [  0.00000000e+00   1.32282085e-16]\n",
      " [  0.00000000e+00  -2.35208761e-16]\n",
      " [  0.00000000e+00  -8.93876480e-16]\n",
      " [  0.00000000e+00   1.47847935e-15]]\n",
      "[[ 0.10593932  0.28981998]\n",
      " [ 0.10540816  0.59793701]\n",
      " [ 0.04637591  0.17384805]\n",
      " ..., \n",
      " [ 0.07725431  0.3062696 ]\n",
      " [ 0.06016892  0.36243945]\n",
      " [ 0.08317183  0.42905028]]\n"
     ]
    }
   ],
   "source": [
    "Sigma = np.zeros((2000, 31))\n",
    "Sigma[0][0] = sigma[0]\n",
    "Sigma[1][1] = sigma[1]\n",
    "print(Sigma)\n",
    "\n",
    "Vt_2D = np.zeros((Vt.shape[0],2))\n",
    "Vt_2D[:,:2] = Vt[:,:2]\n",
    "print(Vt_2D)\n",
    "\n",
    "partial_2D = U.dot(Sigma.dot(Vt_2D))\n",
    "print(partial_2D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 53.7860351    0.           0.         ...,   0.           0.           0.        ]\n",
      " [  0.          14.59711807   0.         ...,   0.           0.           0.        ]\n",
      " [  0.           0.           0.         ...,   0.           0.           0.        ]\n",
      " ..., \n",
      " [  0.           0.           0.         ...,   0.           0.           0.        ]\n",
      " [  0.           0.           0.         ...,   0.           0.           0.        ]\n",
      " [  0.           0.           0.         ...,   0.           0.           0.        ]]\n",
      "[[-1.51415386 -0.19548041]\n",
      " [-1.66894887  0.40282269]\n",
      " [-0.68747665  0.0050693 ]\n",
      " ..., \n",
      " [-1.15396163  0.04060706]\n",
      " [-0.96374844  0.27070175]\n",
      " [-1.29445221  0.2353598 ]]\n",
      "(2000, 2)\n"
     ]
    }
   ],
   "source": [
    "print(Sigma)\n",
    "pp_2D = U@Sigma[:,:2]\n",
    "print(pp_2D)\n",
    "print(pp_2D.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = {\n",
    "    \"s002\": \"#0048BA\",\n",
    "    \"s003\": \"#B0BF1A\",\n",
    "    \"s004\": \"#7CB9E8\",\n",
    "    \"s005\": \"#C9FFE5\",\n",
    "    \"s007\": \"#B284BE\",\n",
    "    \"s008\": \"#00308F\",\n",
    "    \"s010\": \"#72A0C1\",\n",
    "    \"s011\": \"#AF002A\",\n",
    "    \"s012\": \"#84DE02\",\n",
    "    \"s013\": \"#E32636\",\n",
    "    \"s015\": \"#C46210\",\n",
    "    \"s016\": \"#EFDECD\",\n",
    "    \"s017\": \"#E52B50\",\n",
    "    \"s018\": \"#9F2B68\",\n",
    "    \"s019\": \"#F19CBB\",\n",
    "    \"s020\": \"#AB274F\",\n",
    "    \"s021\": \"#D3212D\",\n",
    "    \"s022\": \"#3B7A57\",\n",
    "    \"s024\": \"#FFBF00\",\n",
    "    \"s025\": \"#FF7E00\",\n",
    "    \"s026\": \"#3B3B6D\",\n",
    "    \"s027\": \"#391802\",\n",
    "    \"s028\": \"#804040\",\n",
    "    \"s029\": \"#D3AF37\",\n",
    "    \"s030\": \"#34B334\",\n",
    "    \"s031\": \"#FF8B00\",\n",
    "    \"s032\": \"#FF9899\",\n",
    "    \"s033\": \"#431C53\",\n",
    "    \"s034\": \"#B32134\",\n",
    "    \"s035\": \"#FF033E\",\n",
    "    \"s036\": \"#CFCFCF\",\n",
    "    \"s037\": \"#551B8C\",\n",
    "    \"s038\": \"#F2B400\",\n",
    "    \"s039\": \"#9966CC\",\n",
    "    \"s040\": \"#A4C639\",\n",
    "    \"s041\": \"#F2F3F4\",\n",
    "    \"s042\": \"#CD9575\",\n",
    "    \"s043\": \"#665D1E\",\n",
    "    \"s044\": \"#915C83\",\n",
    "    \"s046\": \"#841B2D\",\n",
    "    \"s047\": \"#FAEBD7\",\n",
    "    \"s048\": \"#008000\",\n",
    "    \"s049\": \"#66B447\",\n",
    "    \"s050\": \"#8DB600\",\n",
    "    \"s051\": \"#FBCEB1\",\n",
    "    \"s052\": \"#00FFFF\",\n",
    "    \"s053\": \"#7FFFD4\",\n",
    "    \"s054\": \"#D0FF14\",\n",
    "    \"s055\": \"#C0C0C0\",\n",
    "    \"s056\": \"#4B5320\",\n",
    "    \"s057\": \"#3B444B\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7ff919bf0f28>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(20,20))\n",
    "for i, point in enumerate(partial_2D):\n",
    "    if recordings[i][0] == \"s002\" or recordings[i][0] == \"s004\":\n",
    "        plt.scatter(point[0], point[1], c=colors[recordings[i][0]])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7ff91b5ff860>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(20,20))\n",
    "for i, point in enumerate(pp_2D):\n",
    "    if recordings[i][0] == \"s002\" or recordings[i][0] == \"s013\" or recordings[i][0] == \"s011\" or recordings[i][0] == \"s015\":\n",
    "        plt.scatter(point[0], point[1], c=colors[recordings[i][0]])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.10593932,  0.28981998],\n",
       "       [ 0.10540816,  0.59793701],\n",
       "       [ 0.04637591,  0.17384805],\n",
       "       ..., \n",
       "       [ 0.07725431,  0.3062696 ],\n",
       "       [ 0.06016892,  0.36243945],\n",
       "       [ 0.08317183,  0.42905028]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "partial_2D"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
