{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Análise de Usuários através de Keystrokes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nesse trabalho, busco explorar o quanto o modo como um usuário digita diz sobre ele. É possível dicerní-lo de outros apenas por seu padrão de digitação? Conseguimos agrupar usuários que digitam de forma parecida? O que mais é possível extrair de dados de telcas?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Motivação\n",
    "\n",
    "Qual a utilidade de ser se estudar padrões de digitação de um usuário?\n",
    "\n",
    "Assumindo que cada usuário tem um padrão de digitação único, ou pelo menos razoavelmente único, é possível pensar em uma tarefa de identificação. Sites como o Coursera utilizam esses dados justamente para julgar se um aluno realmente está fazendo os deveres do curso. Logo quando um usuário se cadastra, ele deve digitar um parágrafo para que um perfil associado seja criado. Esse perfil é então comparado posteriormente aos textos (códigos ou respostas discursivas) escritos pelo aluno. Por ser utilizado por tanto tempo na plataforma, podemos suspeitar que esse tipo de dado é um bom indicativo de unicidade.\n",
    "\n",
    "Outra aplicação possível é identificação de usuários fazendo login. Se um sistema for capaz de identificar o usuário pelo modo como digita, uma camada a mais de segurança pode ser criada. Afinal, não basta saber a senha da conta, é necessário digitar como o dono original digita. Dessa forma, fraudes por senhas vazadas, bancos de dados comprometidos, ou até mesmo senhas anotadas em _post-its_ no monitor podem ser evitadas.\n",
    "\n",
    "Para o caso de uso da senha é interessante notar um detalhe que é o não envio da senha em _plain text_ ao servidor verificador. É extremamente comum - se crucial para uma base mínima de segurança - que a senha de um usuário não trafegue a rede em _plain text_. Isso porque é muito fácil um malfeitor capturar dados transientes em uma rede (principalmente pública). Dessa forma, se a senha não tiver nenhum mecanismo de proteção, a conta do usuário estará comprometida.\n",
    "\n",
    "O que normalmente ocorre é o envio de um _hash_ da senha. O _hash_ nada mais é do que uma função que leva uma entrada a uma saída de forma simples, mas garante que a inversão (sabendo uma saída, encontrar a entrada correspondente) é uma tarefa árdua. Utilizando esse método, sites que permitem fazer login não precisam guardar as senhas de seus usuários, basta guardar os hashes das senhas. Afinal, como cada senha sempre produz o mesmo hash, é possível comparar hashes para saber se a senha está correta. Aplicando essa metodologia, mesmo que ocorra um vazamento de senhas ou uma senha seja fisgada em trânsito, o segredo está seguro. Apenas o hash foi comprometido e como dito acima, hashes são difíceis de reverter.\n",
    "\n",
    "O que isso implica na utilização de dados de digitação para verificação do usuário? Imediatamente, significa que não se pode utilizar as teclas nem os tempos de digitação entre elas para tirar tais conclusões. Afinal, se isso fosse utilizado, todo o propósito de não enviar a senha em _plain text_ estará perdido. Soluções mais criativas terão que ser utilizadas, como veremos a frente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "\n",
    "Para começar a exploração desse tópico, escolhi um dataset famoso de dados de _keystrokes_. O dataset é conhecido como _CMU Keystroke Dynamics – Benchmark Data Set_.\n",
    "\n",
    "### Contrução do dataset\n",
    "\n",
    "Esse dataset foi montado com dados de 51 pessoas diferentes digitando a senha `.tie5Roanl` repetidas vezes. Ao todo foram 400 repetições por pessoa espaçadas em sessões distintas. Em cada sessão a pessoa digitava a senha 50 vezes, implicando num total de 8 sessões que foram feitas com pelo menos um dia de folga entre elas para capturar a variação de padrões de digitação ao longo de dias.\n",
    "\n",
    "### Dados coletados\n",
    "\n",
    "Resta, agora, sabermos que métricas foram efetivamente coletadas e armazenadas nesse dataset. Cada sessão de coleta captura três tipos de dados: `Hold`, `Down-Down`, `Up-Down`.\n",
    "\n",
    "![Métricas coletadas](data_explanation.jpg)\n",
    "\n",
    "- Hold: Mede o tempo que uma tecla foi pressionada (desde o momento que foi abaixada até quando é solta).\n",
    "- Down-Down: Mede o tempo entre uma tecla ser abaixada e a próxima ser abaixada.\n",
    "- Up-Down: Mede o tempo entre uma tecla ser solta e a próxima abaixada.\n",
    "\n",
    "Dessa forma, como o texto digitado foi `.tie5Roanl`, cada entrada do dataset será composta dos seguintes atributos:\n",
    "\n",
    "```\n",
    "subject,sessionIndex,rep,H.period,DD.period.t,UD.period.t,H.t,DD.t.i,UD.t.i, ... , H.n,DD.n.l,UD.n.l,H.l,DD.l.Return,UD.l.Return,H.Return\n",
    "```\n",
    "\n",
    "O primeiro parâmetro indica qual participante digitou essa entrada do dataset. O atributo `sessionIndex` indica a qual sessão essa captura faz parte e `rep` qual a repetição dentro dessa sessão. A partir desse ponto começam as medidas de tempo. O primeiro campo, `H.period`, indica o tempo que a tecla de _ponto final_ ficou pressionada (_Hold period_). Em seguida, temos `DD.period.t` que indica o tempo entre a tecla de _ponto final_ ser pressionada para baixo e a tecla `t` ser pressionada para baixo (_Down-Down period t_). Analogamente, `UD.period.t` mostra o tempo entre soltar o _ponto final_ e pressionar a tecla `t`. As mesmas três métricas se repetem para as próximas teclas da senha. É importante notar que a tecla `Enter` foi pressionada ao final da digitação e é expressa no dataset por meio do termo _Return_."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Análise inicial dos dados\n",
    "\n",
    "Sabendo como o dataset foi construído, comecemos por tentar entender seus dados. Comecemos por uma redução de dimensionalidade para ser possível desenhar um plot 2D dos pontos. Com isso teremos alguma ideia de como os dados se comportam."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import time\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comecemos por ler os dados do arquivo em que estão salvos e separá-los por linhas. Aqui também jogaremos o cabeçalho fora, visto que não será utilizado nas manipulações e já temos uma descrição dos dados acima."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lendo dados do arquivo\n",
    "with open(\"DSL-StrongPasswordData.csv\") as f:\n",
    "    data = np.array([line.split(\",\") for line in f.read().strip().split(\"\\n\")[1:]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora, separemos os identificadores de usuários dos dados propriamente ditos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['s040' '5' '44']\n",
      " ['s036' '7' '35']] \n",
      " [[ 0.1227  0.3441  0.2214  0.1071  0.1493  0.0422  0.106   0.3349  0.2289\n",
      "   0.153   0.73    0.577   0.0731  0.5698  0.4967  0.0839  0.3472  0.2633\n",
      "   0.1124  0.16    0.0476  0.1765  0.2884  0.1119  0.1097  0.3012  0.1915\n",
      "   0.0823  0.2655  0.1832  0.1084]\n",
      " [ 0.0377  0.5097  0.472   0.0475  0.2709  0.2234  0.0409  0.2883  0.2474\n",
      "   0.0457  0.4903  0.4446  0.042   0.4409  0.3989  0.0351  0.605   0.5699\n",
      "   0.0285  0.2008  0.1723  0.0525  0.3788  0.3263  0.0327  0.4781  0.4454\n",
      "   0.0393  0.4406  0.4013  0.0364]]\n"
     ]
    }
   ],
   "source": [
    "# Formatando os dados\n",
    "np.random.seed(1234)\n",
    "np.random.shuffle(data)\n",
    "recordings, keystrokes = data[:,:3], data[:,3:].astype(float)\n",
    "print(recordings[:2], \"\\n\", keystrokes[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para termos certeza de que tudo está coerente no dataset, verifiquemos a quantidade de colunas da matriz e comparemos com o tamanho do que foi digitado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de teclas na digitação da senha: 11\n",
      "Número de colunas na matriz do dataset: 31\n"
     ]
    }
   ],
   "source": [
    "password = \".tie5Roanl\\n\" # Lembrando que o enter é pressionado ao final da senha\n",
    "print(\"Número de teclas na digitação da senha: {}\".format(len(password)))\n",
    "print(\"Número de colunas na matriz do dataset: {}\".format(keystrokes.shape[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exatamente como o esperado. Afinal, temos três medições por tecla pressionada (exceto a última) e temos 11 teclas pressionadas. Como não há teclas após o `Enter`, essa tecla só terá a métrica de `Hold` medida. Isso totalizará em exatas **31 medições**, como imaginávamos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verifiquemos agora o número de usuários no dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Identificadores de usuários: ['s002', 's003', 's004', 's005', 's007', 's008', 's010', 's011', 's012', 's013', 's015', 's016', 's017', 's018', 's019', 's020', 's021', 's022', 's024', 's025', 's026', 's027', 's028', 's029', 's030', 's031', 's032', 's033', 's034', 's035', 's036', 's037', 's038', 's039', 's040', 's041', 's042', 's043', 's044', 's046', 's047', 's048', 's049', 's050', 's051', 's052', 's053', 's054', 's055', 's056', 's057']\n",
      "Quantidade de usuários únicos: 51\n"
     ]
    }
   ],
   "source": [
    "users = sorted(list(set(recordings[:,0])))\n",
    "print(\"Identificadores de usuários: {}\".format(users))\n",
    "print(\"Quantidade de usuários únicos: {}\".format(len(users)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Temos 51 usuários únicos, novamente como esperado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Redução de Dimensionalidade\n",
    "\n",
    "Para ganharmos uma intuição sobre comportamento de cada usuário, podemos tentar desenhar os pontos do dataset em um gráfico. Entretanto, como os dados são de dimensão 31, é preciso aplicar algum tipo de redução de dimensionalidade para que esse gráfico se torne possível."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVD\n",
    "\n",
    "Uma técnica que permite essa redução é o SVD (Singular Value Decomposition). Com o SVD conseguimos encontrar uma base boa para representar nossos dados. Não só isso, como também é possível verificar a importância de cada dimensão para a representação dos dados. Isso será importante para analisarmos a quantidade de informação que está sendo perdida com a simplificação dos dados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Antes de fazermos qualquer manipulação com os dados, entretanto, é interessante normalizá-los."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = np.mean(keystrokes, axis=0)\n",
    "std = np.std(keystrokes, axis=0)\n",
    "\n",
    "norm_keystrokes = (keystrokes - mean) / std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uma vez com os dados normalizados, podemos prosseguir com a redução de dimensionalidade. A técnica de SVD decompõe uma matriz em três, $U$, $\\Sigma$ e $V^T$. Juntas elas tais matrizes formam a original de acordo com a relação $U \\Sigma V^T = M$, onde $M$ é a matriz original.\n",
    "\n",
    "Para compreendermos melhor o que o SVD faz com uma matriz, primeiro precisamos entender o que a matriz original significa. No caso desse dataset, cada linha da matriz $M$ representa um usuário e cada coluna uma métrica de digitação. Dessa forma, podemos enxergar a matriz $M$ como a matriz que nos leva de usuário para digitação. É importante manter essa relação em mente, pois se nos propusermos a fazer uma decomposição dessa matriz, é importante que essa relação se mantenha."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "    \\text{Usuários} \\Bigg \\{ \n",
    "    \\overbrace{\n",
    "    \\begin{bmatrix}\n",
    "          &   &  &  \\\\\n",
    "          &   &  &  \\\\\n",
    "          &   &  &  \n",
    "    \\end{bmatrix}\n",
    "    }^\\text{Digitação}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como dito anteriormente, o SVD \"_procura uma base boa_\" para a representação dos dados. O que exatamente significa essa \"_base boa_\"?\n",
    "\n",
    "Por _base boa_, o algoritmo entende ser a base nas quais as dimensões capturam o máximo de informação possível. Em termos estatísticos, são as dimensões com maior variância dos dados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b style=\"color:red;\">[imagem mostrando pontos variando muito sobre um vetor e pouco sobre outros. Ao lado, imagem mostrando o eixo que melhor representa os dados. 2D -> 1D]</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dessa forma, se pegarmos apenas as dimensões com maior informação, seremos capazes de manter os dados quase íntegros e ao mesmo tempo reduzir sua dimensionalidade. Como no exemplo acima, vemos que os pontos variam muito na direção do vetor destacado. Significa que se projetarmos os pontos nesse vetor, poderemos representá-los - quase que fielmente - com apenas um número: a magnitude do deslocamento a partir da origem nessa direção. Dessa forma, reduzimos com sucesso dados originalmente em 2D para dados em 1D."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora, analisemos possíveis interpretações das matrizes resultantes do SVD no dataset de padrões de digitação. O algoritmo leva os pontos do dataset da base original para uma base ideal. Isso pode ser visto analisando o papel de cada matriz resultante."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "U, Sigma, Vt = np.linalg.svd(norm_keystrokes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Começando por $U$, podemos interpretar seu papel como sendo a matriz que leva os usuários a esse espaço ideal encontrado pelo SVD. Em seguida, temos $\\Sigma$. Essa é a matriz responsável por escalar os pontos no espaço ideal de acordo com a _importância_ de cada dimensão nesse espaço. Finalmente temos $V^T$ que pode ser vista como a matriz que traz os dados de volta do espaço ideal para o espaço de digitação.\n",
    "\n",
    "Vendo a decomposição dessa forma, acabamos com a mesma interpretação da matriz original - uma matriz que leva de usuários para métricas de digitação. O grande ganho é que o SVD nos permite enxergar os dados em uma dimensão ideal intermediária. Nela, podemos fazer manipulações nos dados que nos permite, por exemplo, reduzir a dimensionalidade preservando o máximo de informação possível."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A \"importância\" de cada dimensão está atrelada à magnitude dos valores singulares da matriz $\\Sigma$. Vendo a relação desses valores podemos tirar conclusões sobre a dimensão real dos dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAEICAYAAABRSj9aAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fe479ad7cc0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(Sigma)\n",
    "plt.scatter(np.arange(31), Sigma)\n",
    "plt.title(\"Valores Singulares do Dataset de Keystrokes\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Olhando para esse gráfico, vemos de imediado que a partir da dimensão ideal 20 as outras dimensões praticamente não contribuem para a informação real dos dados. Em termos um pouco mais formais, praticamente não há variação dos dados ao longo das dimensões superiores à vigésima.\n",
    "\n",
    "Mais do que isso, é possível notar que as duas primeiras dimensões contribuem com a maior parte da informação dos dados. A partir da terceira, as dimensões ficam progressivamente menos relevantes de forma gradual.\n",
    "\n",
    "Isso tudo indica que nosso gráfico em 2D dos pontos conterá uma boa parte da informação do dataset original. Portanto será uma boa visualização dos dados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para fazermos esse gráfico em 2D dos pontos, basta lembrarmos da interpretação das matrizes resultantes da decompoisção. Queremos levar nossos pontos ao espaço ideal e ignorar todas as dimensões exceto as duas primeiras.\n",
    "\n",
    "O primeiro passo pode ser facilmente feito apenas com a matriz $U$ - afinal ela é a responsável por levar os pontos para o espaço ideal. Em seguida, basta zerarmos os valores singulares indesejáveis da matriz $\\Sigma$ que zeraremos as coordenadas indesejadas dos pontos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz Sigma Reduzida:\n",
      " [[ 407.97342532    0.            0.         ...,    0.            0.            0.        ]\n",
      " [   0.          326.96957765    0.         ...,    0.            0.            0.        ]\n",
      " [   0.            0.            0.         ...,    0.            0.            0.        ]\n",
      " ..., \n",
      " [   0.            0.            0.         ...,    0.            0.            0.        ]\n",
      " [   0.            0.            0.         ...,    0.            0.            0.        ]\n",
      " [   0.            0.            0.         ...,    0.            0.            0.        ]]\n",
      "\n",
      "Dimensões de Sigma Reduzida: (20400, 31)\n"
     ]
    }
   ],
   "source": [
    "reduced_sigma = np.zeros((U.shape[1], Sigma.shape[0]))\n",
    "reduced_sigma[0,0] = Sigma[0]\n",
    "reduced_sigma[1,1] = Sigma[1]\n",
    "print(\"Matriz Sigma Reduzida:\\n\",reduced_sigma, end=\"\\n\\n\")\n",
    "print(\"Dimensões de Sigma Reduzida:\",reduced_sigma.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como queremos ficar no espaço ideal, basta não incluirmos a matriz $V^T$ - cuja função é trazer os pontos de volta ao espaço original."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.79661649 -3.14352362  0.         ...,  0.          0.          0.        ]\n",
      " [ 7.33690199  2.98459802  0.         ...,  0.          0.          0.        ]\n",
      " [-0.41674256  3.11857179  0.         ...,  0.          0.          0.        ]\n",
      " ..., \n",
      " [-1.29789951 -1.33182584  0.         ...,  0.          0.          0.        ]\n",
      " [ 0.54700926 -1.83758573  0.         ...,  0.          0.          0.        ]\n",
      " [ 1.03072995 -1.17526715  0.         ...,  0.          0.          0.        ]]\n",
      "(20400, 31)\n"
     ]
    }
   ],
   "source": [
    "reduced_keystrokes = U @ reduced_sigma\n",
    "print(reduced_keystrokes)\n",
    "print(reduced_keystrokes.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como podemos ver, zeramos as coordenadas menos relevantes com sucesso. Basta então usarmos as que sobraram para desenhar o gráfico."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlUAAAJOCAYAAACeF/LqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nJ6vggh+w1CTNAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fe479a4be48>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "colors = {\"s002\": \"#E32636\", \"s003\": \"#B0BF1A\", \"s004\": \"#7CB9E8\", \"s005\": \"#84DE02\", \"s007\": \"#EFDECD\", \"s008\": \"#00308F\", \"s010\": \"#0048BA\", \"s011\": \"#AF002A\", \"s012\": \"#C9FFE5\", \"s013\": \"#72A0C1\", \"s015\": \"#C46210\", \"s016\": \"#B284BE\", \"s017\": \"#E52B50\", \"s018\": \"#9F2B68\", \"s019\": \"#F19CBB\", \"s020\": \"#AB274F\", \"s021\": \"#D3212D\", \"s022\": \"#3B7A57\", \"s024\": \"#FFBF00\", \"s025\": \"#FF7E00\", \"s026\": \"#3B3B6D\", \"s027\": \"#391802\", \"s028\": \"#804040\", \"s029\": \"#D3AF37\", \"s030\": \"#34B334\", \"s031\": \"#FF8B00\", \"s032\": \"#FF9899\", \"s033\": \"#431C53\", \"s034\": \"#B32134\", \"s035\": \"#FF033E\", \"s036\": \"#CFCFCF\", \"s037\": \"#551B8C\", \"s038\": \"#F2B400\", \"s039\": \"#9966CC\", \"s040\": \"#A4C639\", \"s041\": \"#F2F3F4\", \"s042\": \"#CD9575\", \"s043\": \"#665D1E\", \"s044\": \"#915C83\", \"s046\": \"#841B2D\", \"s047\": \"#FAEBD7\", \"s048\": \"#008000\", \"s049\": \"#66B447\", \"s050\": \"#8DB600\", \"s051\": \"#FBCEB1\", \"s052\": \"#00FFFF\", \"s053\": \"#7FFFD4\", \"s054\": \"#D0FF14\", \"s055\": \"#C0C0C0\", \"s056\": \"#4B5320\", \"s057\": \"#3B444B\"}\n",
    "reduced_keystrokes_ = reduced_keystrokes[:,:2]\n",
    "\n",
    "vis_users = [\"s005\", \"s010\", \"s011\", \"s016\"]\n",
    "plt.figure(figsize=(10,10))\n",
    "for i, point in enumerate(reduced_keystrokes_):\n",
    "    #Para facilitar a visualização, faremos o plot de apenas quatro usuários\n",
    "    if recordings[i][0] in vis_users:\n",
    "        plt.scatter(point[0], point[1], c=colors[recordings[i][0]])\n",
    "plt.title(\"Dados de digitação dos usuários {}\".format(\", \".join(vis_users)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observando o gráfico, vemos que a redução de dimensionalidade realmente funcionou. Usando a técnica de SVD conseguimos visualizar as diferenças nos padrões de digitação das pessoas utilizadas na criação do dataset.\n",
    "\n",
    "Podemos ver que usando apenas duas dimensões não é sempre óbiva a distinção de cada par de usuários. No exemplo do gráfico acima, vemos uma clara separação entre os usuários azul, vermelho escuro e verde - com pontos concentrados em regiões diferentes do espaço. Já o usuário roxo, se mistura consideravelmente com o verde. Isso pode ser reflexo de uma possível proximidade do modo como ambos digitam, ou simplesmente uma limitação da visualização em 2D do dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos, por fim, tentar estimar a grosso modo quanta informação retemos ao simplificar os dados para 2D. Para isso, podemos usar os valores singulares obtidos em $\\Sigma$. A ideia é simplesmente verificar a proporção das dimensões retidas em relação ao total."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimativa de informação retida: 22.684216838113194%\n"
     ]
    }
   ],
   "source": [
    "retained_info = (Sigma[0] + Sigma[1]) / np.sum(Sigma)\n",
    "print(\"Estimativa de informação retida: {}%\".format(100*retained_info))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Diminuindo o espaço dos pontos do dataset da forma que fizemos, somos capazes de reter em torno de 22% da informação do dado original. Essa estimativa não pode ser levada tão literalmente, mas ajuda a entender o que estamos preservando.\n",
    "\n",
    "Mesmo com apenas um quinto da informação original, ainda somos capazes de visualmente discernir alguns usuários. Isso realmente é um indicativo motivador para a próxima tarefa: classificação."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Autoencoder\n",
    "\n",
    "Vimos uma forma de redução de dimensionalidade, o SVD. Entretanto, essa decomposição não é a única forma de se reduzir as dimensões de dados. Existe outro método muito popular conhecido como _Autoencoder_."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A técnica de _Autoencoder_ foi desenvolvida com a popularização de redes neurais no cenário acadêmico. A proposta consiste de uma ideia muito simples. Criamos uma rede neural dividida em duas partes: um _encoder_ e um _decoder_. O encoder é responsável por pegar o dado no espaço original e levá-lo para um espaço latente (_embedding space_). O decoder faz justamente o oposto, ou seja, recebe como entrada um vetor no espaço latente e o converte de volta ao espaço original.\n",
    "\n",
    "<center>\n",
    "```\n",
    "embedding = encoder(dado original)\n",
    "dado reconstruido = decoder(embedding)\n",
    "```\n",
    "</center>\n",
    "\n",
    "A ideia é treinar a rede para encontrar o melhor espaço latente possível para representar os dados. Em termos mais concretos, estamos tentando minimizar a diferença entre o dado reconstruido e o dado original controlando as funções de _encoding_ e _decoding_.\n",
    "\n",
    "$$\n",
    "    decoder, encoder = \\arg \\min_{d,e}{\\lVert X - d(e(X)) \\rVert ^2}\n",
    "$$\n",
    "\n",
    "O espaço de embedding pode ser arbitrariamente escolhido, mas como nosso objetivo é realizar uma redução de dimensionalidade, é interessante escolhermos um espaço com dimensão menor. Mais especificamente, queremos um espaço em 2D para fazermos um gráfico representativo do dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para isso, construimos uma rede neural que afunila e depois expande os dados. A camada inicial da rede é da dimensão original do dado. A partir da primeira, as camadas ficam progressivamente menores, forçando uma representação mais densa de nossos dados. Quando chegamos na dimensão desejada, começamos o processo de reconstrução do dado. A partir desse ponto, as camadas ficam progressivamente maiores até atingirem o tamanho original."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Estrutura de um Autoencoder](Autoencoder_structure.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construiremos uma rede com a mesma quantidade de camadas que a imagem acima mostra. Aproveitando que já calculamos os valores singulares previamente usando o SVD, vemos que realmente só precisamos de 20 dimensões para representar fielmente nossos dados. Dessa forma, podemos supor que é uma boa escolha fazer as camadas intermediárias entre o dado original e a representação 2D ter ser de tamanho 20.\n",
    "\n",
    "\n",
    "<center>\n",
    "```\n",
    "dado (31D) -> dado (20D) -> dado (2D) -> dado (20D) -> dado (31D)\n",
    "```\n",
    "</center>\n",
    "\n",
    "O fato de termos camadas intermediárias entre a representação 2D e a original ajuda a dar mais flexibilidade para manipulação da rede."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device(\"/device:CPU:0\"):\n",
    "    x = tf.placeholder(tf.float32, shape=[None, 31])\n",
    "    \n",
    "    encoder_W1 = tf.get_variable(\"e_W1\", shape=[31, 20], initializer=tf.contrib.layers.xavier_initializer())\n",
    "    encoder_b1 = tf.Variable(tf.zeros([20]), name=\"e_b1\")\n",
    "    \n",
    "    embedding_20D = tf.nn.relu(tf.matmul(x, encoder_W1) + encoder_b1)\n",
    "    \n",
    "    encoder_W2 = tf.get_variable(\"e_W2\", shape=[20, 2], initializer=tf.contrib.layers.xavier_initializer())\n",
    "    encoder_b2 = tf.Variable(tf.zeros([2]), name=\"e_b2\")\n",
    "    \n",
    "    embedding_2D = tf.matmul(embedding_20D, encoder_W2) + encoder_b2\n",
    "    embedding_2D_activated = tf.nn.sigmoid(embedding_2D)\n",
    "    \n",
    "    decoder_W1 = tf.get_variable(\"d_W1\", shape=[2, 20], initializer=tf.contrib.layers.xavier_initializer())\n",
    "    decoder_b1 = tf.Variable(tf.zeros([20]), name=\"d_b1\")\n",
    "    \n",
    "    reconstruction_20D = tf.nn.relu(tf.matmul(embedding_2D_activated, decoder_W1) + decoder_b1)\n",
    "    \n",
    "    decoder_W2 = tf.get_variable(\"d_W2\", shape=[20, 31], initializer=tf.contrib.layers.xavier_initializer())\n",
    "    decoder_b2 = tf.Variable(tf.zeros([31]), name=\"d_b2\")\n",
    "    \n",
    "    reconstruction_31D = tf.nn.relu(tf.matmul(reconstruction_20D, decoder_W2) + decoder_b2)\n",
    "    \n",
    "    loss = tf.reduce_mean(tf.pow(x - reconstruction_31D, 2))\n",
    "    \n",
    "    train_step = tf.train.AdamOptimizer().minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_data_idx = 20000\n",
    "train_data = norm_keystrokes[:split_data_idx]\n",
    "test_data = norm_keystrokes[split_data_idx:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def next_batch(size, i):\n",
    "    k = train_data[i*size:(i+1)*size]\n",
    "    return k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 0: Batch #0 - Loss: 0.8707777857780457\n",
      "Model saved in file: ./weights_autoencoder_sigmoid/model_e0b0_1516648791.4536164.ckpt\n",
      "Ep 0: Batch #1 - Loss: 0.9559489488601685\n",
      "Ep 0: Batch #2 - Loss: 1.0723260641098022\n",
      "Ep 0: Batch #3 - Loss: 0.9363692998886108\n",
      "Ep 0: Batch #4 - Loss: 0.8582368493080139\n",
      "Model saved in file: ./weights_autoencoder_sigmoid/model_e0b4_1516648791.477895.ckpt\n",
      "Ep 0: Batch #5 - Loss: 0.720664918422699\n",
      "Model saved in file: ./weights_autoencoder_sigmoid/model_e0b5_1516648791.4978225.ckpt\n",
      "Ep 0: Batch #6 - Loss: 0.9497442841529846\n",
      "Ep 0: Batch #7 - Loss: 0.7588295340538025\n",
      "Ep 0: Batch #8 - Loss: 0.7876214385032654\n",
      "Ep 0: Batch #9 - Loss: 1.4914780855178833\n",
      "Ep 0: Batch #10 - Loss: 1.0780930519104004\n",
      "Ep 0: Batch #11 - Loss: 0.7289762496948242\n",
      "Ep 0: Batch #12 - Loss: 1.622048258781433\n",
      "Ep 0: Batch #13 - Loss: 0.6911936402320862\n",
      "Model saved in file: ./weights_autoencoder_sigmoid/model_e0b13_1516648791.522711.ckpt\n",
      "Ep 0: Batch #14 - Loss: 0.7784948348999023\n",
      "Ep 0: Batch #15 - Loss: 1.3209772109985352\n",
      "Ep 0: Batch #16 - Loss: 1.373350977897644\n",
      "Ep 0: Batch #17 - Loss: 0.9475303888320923\n",
      "Ep 0: Batch #18 - Loss: 0.9810193777084351\n",
      "Ep 0: Batch #19 - Loss: 0.713569164276123\n",
      "Ep 0: Batch #20 - Loss: 0.7034596800804138\n",
      "Ep 0: Batch #21 - Loss: 1.269844889640808\n",
      "Ep 0: Batch #22 - Loss: 0.7701297998428345\n",
      "Ep 0: Batch #23 - Loss: 0.8042725920677185\n",
      "Ep 0: Batch #24 - Loss: 0.8712736368179321\n",
      "Ep 0: Batch #25 - Loss: 0.7738950848579407\n",
      "Ep 0: Batch #26 - Loss: 0.7902679443359375\n",
      "Ep 0: Batch #27 - Loss: 1.4286929368972778\n",
      "Ep 0: Batch #28 - Loss: 0.9187158346176147\n",
      "Ep 0: Batch #29 - Loss: 0.9623823165893555\n",
      "Ep 0: Batch #30 - Loss: 1.2697631120681763\n",
      "Ep 0: Batch #31 - Loss: 0.708033561706543\n",
      "Ep 0: Batch #32 - Loss: 0.7979900240898132\n",
      "Ep 0: Batch #33 - Loss: 0.8541070222854614\n",
      "Ep 0: Batch #34 - Loss: 0.8326050639152527\n",
      "Ep 0: Batch #35 - Loss: 1.019564151763916\n",
      "Ep 0: Batch #36 - Loss: 0.741590142250061\n",
      "Ep 0: Batch #37 - Loss: 1.1929806470870972\n",
      "Ep 0: Batch #38 - Loss: 0.7987651228904724\n",
      "Ep 0: Batch #39 - Loss: 0.8595430850982666\n",
      "Ep 0: Batch #40 - Loss: 0.826831579208374\n",
      "Ep 0: Batch #41 - Loss: 0.7819613814353943\n",
      "Ep 0: Batch #42 - Loss: 0.7579688429832458\n",
      "Ep 0: Batch #43 - Loss: 0.8386905193328857\n",
      "Ep 0: Batch #44 - Loss: 0.8274154663085938\n",
      "Ep 0: Batch #45 - Loss: 0.6831359267234802\n",
      "Model saved in file: ./weights_autoencoder_sigmoid/model_e0b45_1516648791.5600998.ckpt\n",
      "Ep 0: Batch #46 - Loss: 0.882217526435852\n",
      "Ep 0: Batch #47 - Loss: 1.0270005464553833\n",
      "Ep 0: Batch #48 - Loss: 1.425134539604187\n",
      "Ep 0: Batch #49 - Loss: 1.064095377922058\n",
      "Ep 0: Batch #50 - Loss: 0.7321563363075256\n",
      "Ep 0: Batch #51 - Loss: 1.0487918853759766\n",
      "Ep 0: Batch #52 - Loss: 0.825074315071106\n",
      "Ep 0: Batch #53 - Loss: 0.8645588159561157\n",
      "Ep 0: Batch #54 - Loss: 0.7358230948448181\n",
      "Ep 0: Batch #55 - Loss: 0.7967607975006104\n",
      "Ep 0: Batch #56 - Loss: 1.3166544437408447\n",
      "Ep 0: Batch #57 - Loss: 0.9002553224563599\n",
      "Ep 0: Batch #58 - Loss: 1.052211880683899\n",
      "Ep 0: Batch #59 - Loss: 0.7097577452659607\n",
      "Ep 0: Batch #60 - Loss: 1.363237738609314\n",
      "Ep 0: Batch #61 - Loss: 0.6736500859260559\n",
      "Model saved in file: ./weights_autoencoder_sigmoid/model_e0b61_1516648791.58827.ckpt\n",
      "Ep 0: Batch #62 - Loss: 0.7612316608428955\n",
      "Ep 0: Batch #63 - Loss: 1.052298665046692\n",
      "Ep 0: Batch #64 - Loss: 9.446821212768555\n",
      "Ep 0: Batch #65 - Loss: 0.6319109797477722\n",
      "Model saved in file: ./weights_autoencoder_sigmoid/model_e0b65_1516648791.6107013.ckpt\n",
      "Ep 0: Batch #66 - Loss: 0.8465973734855652\n",
      "Ep 0: Batch #67 - Loss: 0.9549151659011841\n",
      "Ep 0: Batch #68 - Loss: 0.9408228993415833\n",
      "Ep 0: Batch #69 - Loss: 0.7757675647735596\n",
      "Ep 0: Batch #70 - Loss: 0.8183196187019348\n",
      "Ep 0: Batch #71 - Loss: 0.6991716623306274\n",
      "Ep 0: Batch #72 - Loss: 0.8804705739021301\n",
      "Ep 0: Batch #73 - Loss: 0.9417842626571655\n",
      "Ep 0: Batch #74 - Loss: 0.7653424143791199\n",
      "Ep 0: Batch #75 - Loss: 0.7919058203697205\n",
      "Ep 0: Batch #76 - Loss: 1.118942141532898\n",
      "Ep 0: Batch #77 - Loss: 0.7632489800453186\n",
      "Ep 0: Batch #78 - Loss: 1.1919994354248047\n",
      "Ep 0: Batch #79 - Loss: 0.6551059484481812\n",
      "Ep 0: Batch #80 - Loss: 0.8929208517074585\n",
      "Ep 0: Batch #81 - Loss: 1.7077122926712036\n",
      "Ep 0: Batch #82 - Loss: 0.906920850276947\n",
      "Ep 0: Batch #83 - Loss: 1.7524350881576538\n",
      "Ep 0: Batch #84 - Loss: 0.7413682341575623\n",
      "Ep 0: Batch #85 - Loss: 0.9950622916221619\n",
      "Ep 0: Batch #86 - Loss: 0.7332032918930054\n",
      "Ep 0: Batch #87 - Loss: 0.7353900074958801\n",
      "Ep 0: Batch #88 - Loss: 0.8262331485748291\n",
      "Ep 0: Batch #89 - Loss: 0.8917160630226135\n",
      "Ep 0: Batch #90 - Loss: 1.186117172241211\n",
      "Ep 0: Batch #91 - Loss: 0.8281477093696594\n",
      "Ep 0: Batch #92 - Loss: 1.0529122352600098\n",
      "Ep 0: Batch #93 - Loss: 1.0566614866256714\n",
      "Ep 0: Batch #94 - Loss: 1.0622469186782837\n",
      "Ep 0: Batch #95 - Loss: 0.9359833598136902\n",
      "Ep 0: Batch #96 - Loss: 0.9246686100959778\n",
      "Ep 0: Batch #97 - Loss: 0.7399542927742004\n",
      "Ep 0: Batch #98 - Loss: 0.7572428584098816\n",
      "Ep 0: Batch #99 - Loss: 0.9627767205238342\n",
      "Ep 0: Batch #100 - Loss: 0.6944947242736816\n",
      "Ep 0: Batch #101 - Loss: 1.0639677047729492\n",
      "Ep 0: Batch #102 - Loss: 0.7967551946640015\n",
      "Ep 0: Batch #103 - Loss: 0.7953352332115173\n",
      "Ep 0: Batch #104 - Loss: 0.8175825476646423\n",
      "Ep 0: Batch #105 - Loss: 1.0386574268341064\n",
      "Ep 0: Batch #106 - Loss: 0.7660524845123291\n",
      "Ep 0: Batch #107 - Loss: 0.7681132555007935\n",
      "Ep 0: Batch #108 - Loss: 1.0547606945037842\n",
      "Ep 0: Batch #109 - Loss: 0.7627835273742676\n",
      "Ep 0: Batch #110 - Loss: 0.9261276125907898\n",
      "Ep 0: Batch #111 - Loss: 1.3795397281646729\n",
      "Ep 0: Batch #112 - Loss: 1.0720142126083374\n",
      "Ep 0: Batch #113 - Loss: 0.8276038765907288\n",
      "Ep 0: Batch #114 - Loss: 0.901375949382782\n",
      "Ep 0: Batch #115 - Loss: 1.1069304943084717\n",
      "Ep 0: Batch #116 - Loss: 0.6311764717102051\n",
      "Model saved in file: ./weights_autoencoder_sigmoid/model_e0b116_1516648791.70544.ckpt\n",
      "Ep 0: Batch #117 - Loss: 0.8746673464775085\n",
      "Ep 0: Batch #118 - Loss: 0.5602532029151917\n",
      "Model saved in file: ./weights_autoencoder_sigmoid/model_e0b118_1516648791.7273424.ckpt\n",
      "Ep 0: Batch #119 - Loss: 1.0318533182144165\n",
      "Ep 0: Batch #120 - Loss: 0.7895558476448059\n",
      "Ep 0: Batch #121 - Loss: 0.6896671652793884\n",
      "Ep 0: Batch #122 - Loss: 0.8331166505813599\n",
      "Ep 0: Batch #123 - Loss: 0.8383373022079468\n",
      "Ep 0: Batch #124 - Loss: 0.6614223122596741\n",
      "Ep 0: Batch #125 - Loss: 2.722529649734497\n",
      "Ep 0: Batch #126 - Loss: 1.2291123867034912\n",
      "Ep 0: Batch #127 - Loss: 0.7422804236412048\n",
      "Ep 0: Batch #128 - Loss: 1.1087563037872314\n",
      "Ep 0: Batch #129 - Loss: 0.8385767936706543\n",
      "Ep 0: Batch #130 - Loss: 0.7245515584945679\n",
      "Ep 0: Batch #131 - Loss: 1.0003505945205688\n",
      "Ep 0: Batch #132 - Loss: 0.8210092186927795\n",
      "Ep 0: Batch #133 - Loss: 0.8126574158668518\n",
      "Ep 0: Batch #134 - Loss: 0.772278368473053\n",
      "Ep 0: Batch #135 - Loss: 0.9660532474517822\n",
      "Ep 0: Batch #136 - Loss: 1.1802409887313843\n",
      "Ep 0: Batch #137 - Loss: 0.9493962526321411\n",
      "Ep 0: Batch #138 - Loss: 1.0637147426605225\n",
      "Ep 0: Batch #139 - Loss: 0.8862619996070862\n",
      "Ep 0: Batch #140 - Loss: 1.0373680591583252\n",
      "Ep 0: Batch #141 - Loss: 1.3411177396774292\n",
      "Ep 0: Batch #142 - Loss: 0.7687073945999146\n",
      "Ep 0: Batch #143 - Loss: 0.9665106534957886\n",
      "Ep 0: Batch #144 - Loss: 0.7211962938308716\n",
      "Ep 0: Batch #145 - Loss: 0.6754279732704163\n",
      "Ep 0: Batch #146 - Loss: 0.8679569959640503\n",
      "Ep 0: Batch #147 - Loss: 0.8517783880233765\n",
      "Ep 0: Batch #148 - Loss: 0.9394280910491943\n",
      "Ep 0: Batch #149 - Loss: 0.8503621220588684\n",
      "Ep 0: Batch #150 - Loss: 0.8549422025680542\n",
      "Ep 0: Batch #151 - Loss: 0.7145403027534485\n",
      "Ep 0: Batch #152 - Loss: 0.721497654914856\n",
      "Ep 0: Batch #153 - Loss: 1.0676889419555664\n",
      "Ep 0: Batch #154 - Loss: 0.7314872145652771\n",
      "Ep 0: Batch #155 - Loss: 0.8310903906822205\n",
      "Ep 0: Batch #156 - Loss: 1.0014322996139526\n",
      "Ep 0: Batch #157 - Loss: 0.7468817234039307\n",
      "Ep 0: Batch #158 - Loss: 0.8086972236633301\n",
      "Ep 0: Batch #159 - Loss: 0.7838446497917175\n",
      "Ep 0: Batch #160 - Loss: 0.8715341687202454\n",
      "Ep 0: Batch #161 - Loss: 0.7951275706291199\n",
      "Ep 0: Batch #162 - Loss: 0.9078108668327332\n",
      "Ep 0: Batch #163 - Loss: 0.907974898815155\n",
      "Ep 0: Batch #164 - Loss: 0.7588062286376953\n",
      "Ep 0: Batch #165 - Loss: 1.4714131355285645\n",
      "Ep 0: Batch #166 - Loss: 0.6611396074295044\n",
      "Ep 0: Batch #167 - Loss: 1.045088768005371\n",
      "Ep 0: Batch #168 - Loss: 0.8319783210754395\n",
      "Ep 0: Batch #169 - Loss: 0.7779247760772705\n",
      "Ep 0: Batch #170 - Loss: 0.7681183218955994\n",
      "Ep 0: Batch #171 - Loss: 0.764508068561554\n",
      "Ep 0: Batch #172 - Loss: 0.6215452551841736\n",
      "Ep 0: Batch #173 - Loss: 1.150766372680664\n",
      "Ep 0: Batch #174 - Loss: 0.5666857361793518\n",
      "Ep 0: Batch #175 - Loss: 0.7573169469833374\n",
      "Ep 0: Batch #176 - Loss: 1.094423532485962\n",
      "Ep 0: Batch #177 - Loss: 0.8047259449958801\n",
      "Ep 0: Batch #178 - Loss: 0.7406086325645447\n",
      "Ep 0: Batch #179 - Loss: 0.8938941359519958\n",
      "Ep 0: Batch #180 - Loss: 0.8082601428031921\n",
      "Ep 0: Batch #181 - Loss: 0.9610757827758789\n",
      "Ep 0: Batch #182 - Loss: 0.7442351579666138\n",
      "Ep 0: Batch #183 - Loss: 0.7377681732177734\n",
      "Ep 0: Batch #184 - Loss: 1.0340580940246582\n",
      "Ep 0: Batch #185 - Loss: 0.7267005443572998\n",
      "Ep 0: Batch #186 - Loss: 0.9395310878753662\n",
      "Ep 0: Batch #187 - Loss: 1.1078436374664307\n",
      "Ep 0: Batch #188 - Loss: 1.2884851694107056\n",
      "Ep 0: Batch #189 - Loss: 0.6628509163856506\n",
      "Ep 0: Batch #190 - Loss: 0.7084363698959351\n",
      "Ep 0: Batch #191 - Loss: 0.9985576868057251\n",
      "Ep 0: Batch #192 - Loss: 0.6455055475234985\n",
      "Ep 0: Batch #193 - Loss: 0.7220892310142517\n",
      "Ep 0: Batch #194 - Loss: 0.6655332446098328\n",
      "Ep 0: Batch #195 - Loss: 0.9175398349761963\n",
      "Ep 0: Batch #196 - Loss: 0.8224827647209167\n",
      "Ep 0: Batch #197 - Loss: 0.8622125387191772\n",
      "Ep 0: Batch #198 - Loss: 0.6377351880073547\n",
      "Ep 0: Batch #199 - Loss: 0.8043847680091858\n",
      "Ep 1: Batch #0 - Loss: 0.7526582479476929\n",
      "Ep 1: Batch #1 - Loss: 0.8244168758392334\n",
      "Ep 1: Batch #2 - Loss: 0.966035783290863\n",
      "Ep 1: Batch #3 - Loss: 0.8162761330604553\n",
      "Ep 1: Batch #4 - Loss: 0.7511748671531677\n",
      "Ep 1: Batch #5 - Loss: 0.636375904083252\n",
      "Ep 1: Batch #6 - Loss: 0.8440972566604614\n",
      "Ep 1: Batch #7 - Loss: 0.670741081237793\n",
      "Ep 1: Batch #8 - Loss: 0.6915575265884399\n",
      "Ep 1: Batch #9 - Loss: 1.3178164958953857\n",
      "Ep 1: Batch #10 - Loss: 0.9542198777198792\n",
      "Ep 1: Batch #11 - Loss: 0.6509487628936768\n",
      "Ep 1: Batch #12 - Loss: 1.498317837715149\n",
      "Ep 1: Batch #13 - Loss: 0.6297770738601685\n",
      "Ep 1: Batch #14 - Loss: 0.6857683062553406\n",
      "Ep 1: Batch #15 - Loss: 1.160617709159851\n",
      "Ep 1: Batch #16 - Loss: 1.1944608688354492\n",
      "Ep 1: Batch #17 - Loss: 0.8333792090415955\n",
      "Ep 1: Batch #18 - Loss: 0.8997408151626587\n",
      "Ep 1: Batch #19 - Loss: 0.6327754259109497\n",
      "Ep 1: Batch #20 - Loss: 0.610478937625885\n",
      "Ep 1: Batch #21 - Loss: 1.140259861946106\n",
      "Ep 1: Batch #22 - Loss: 0.6886351704597473\n",
      "Ep 1: Batch #23 - Loss: 0.7033019065856934\n",
      "Ep 1: Batch #24 - Loss: 0.7809373140335083\n",
      "Ep 1: Batch #25 - Loss: 0.6925559043884277\n",
      "Ep 1: Batch #26 - Loss: 0.6871509552001953\n",
      "Ep 1: Batch #27 - Loss: 1.2860811948776245\n",
      "Ep 1: Batch #28 - Loss: 0.8097744584083557\n",
      "Ep 1: Batch #29 - Loss: 0.8500500321388245\n",
      "Ep 1: Batch #30 - Loss: 1.1255226135253906\n",
      "Ep 1: Batch #31 - Loss: 0.6264304518699646\n",
      "Ep 1: Batch #32 - Loss: 0.6961572170257568\n",
      "Ep 1: Batch #33 - Loss: 0.7615395188331604\n",
      "Ep 1: Batch #34 - Loss: 0.7311937808990479\n",
      "Ep 1: Batch #35 - Loss: 0.8800488114356995\n",
      "Ep 1: Batch #36 - Loss: 0.6457018256187439\n",
      "Ep 1: Batch #37 - Loss: 1.072771430015564\n",
      "Ep 1: Batch #38 - Loss: 0.6765347123146057\n",
      "Ep 1: Batch #39 - Loss: 0.7739548683166504\n",
      "Ep 1: Batch #40 - Loss: 0.723668098449707\n",
      "Ep 1: Batch #41 - Loss: 0.6754022836685181\n",
      "Ep 1: Batch #42 - Loss: 0.6676579713821411\n",
      "Ep 1: Batch #43 - Loss: 0.742460310459137\n",
      "Ep 1: Batch #44 - Loss: 0.7108456492424011\n",
      "Ep 1: Batch #45 - Loss: 0.5998178124427795\n",
      "Ep 1: Batch #46 - Loss: 0.7707210779190063\n",
      "Ep 1: Batch #47 - Loss: 0.909192681312561\n",
      "Ep 1: Batch #48 - Loss: 1.2726069688796997\n",
      "Ep 1: Batch #49 - Loss: 0.934040367603302\n",
      "Ep 1: Batch #50 - Loss: 0.6573288440704346\n",
      "Ep 1: Batch #51 - Loss: 0.9151891469955444\n",
      "Ep 1: Batch #52 - Loss: 0.7413073182106018\n",
      "Ep 1: Batch #53 - Loss: 0.7777432203292847\n",
      "Ep 1: Batch #54 - Loss: 0.6511178612709045\n",
      "Ep 1: Batch #55 - Loss: 0.694547712802887\n",
      "Ep 1: Batch #56 - Loss: 1.1573870182037354\n",
      "Ep 1: Batch #57 - Loss: 0.7832349538803101\n",
      "Ep 1: Batch #58 - Loss: 0.9145885705947876\n",
      "Ep 1: Batch #59 - Loss: 0.6363282203674316\n",
      "Ep 1: Batch #60 - Loss: 1.2276663780212402\n",
      "Ep 1: Batch #61 - Loss: 0.6057028770446777\n",
      "Ep 1: Batch #62 - Loss: 0.66726154088974\n",
      "Ep 1: Batch #63 - Loss: 0.9322201609611511\n",
      "Ep 1: Batch #64 - Loss: 9.283031463623047\n",
      "Ep 1: Batch #65 - Loss: 0.5634319186210632\n",
      "Ep 1: Batch #66 - Loss: 0.7538731694221497\n",
      "Ep 1: Batch #67 - Loss: 0.8682098388671875\n",
      "Ep 1: Batch #68 - Loss: 0.8280043601989746\n",
      "Ep 1: Batch #69 - Loss: 0.6822044849395752\n",
      "Ep 1: Batch #70 - Loss: 0.6991098523139954\n",
      "Ep 1: Batch #71 - Loss: 0.6005486249923706\n",
      "Ep 1: Batch #72 - Loss: 0.7639282941818237\n",
      "Ep 1: Batch #73 - Loss: 0.8289740681648254\n",
      "Ep 1: Batch #74 - Loss: 0.6676770448684692\n",
      "Ep 1: Batch #75 - Loss: 0.7144247889518738\n",
      "Ep 1: Batch #76 - Loss: 1.0239969491958618\n",
      "Ep 1: Batch #77 - Loss: 0.6779295206069946\n",
      "Ep 1: Batch #78 - Loss: 1.053220510482788\n",
      "Ep 1: Batch #79 - Loss: 0.5961134433746338\n",
      "Ep 1: Batch #80 - Loss: 0.7854470014572144\n",
      "Ep 1: Batch #81 - Loss: 1.5985257625579834\n",
      "Ep 1: Batch #82 - Loss: 0.8296301960945129\n",
      "Ep 1: Batch #83 - Loss: 1.666724443435669\n",
      "Ep 1: Batch #84 - Loss: 0.6623438000679016\n",
      "Ep 1: Batch #85 - Loss: 0.9075905680656433\n",
      "Ep 1: Batch #86 - Loss: 0.6431428790092468\n",
      "Ep 1: Batch #87 - Loss: 0.6456717252731323\n",
      "Ep 1: Batch #88 - Loss: 0.7353616952896118\n",
      "Ep 1: Batch #89 - Loss: 0.8187770247459412\n",
      "Ep 1: Batch #90 - Loss: 1.041990876197815\n",
      "Ep 1: Batch #91 - Loss: 0.733170747756958\n",
      "Ep 1: Batch #92 - Loss: 0.9223605394363403\n",
      "Ep 1: Batch #93 - Loss: 0.9290114641189575\n",
      "Ep 1: Batch #94 - Loss: 0.9319353103637695\n",
      "Ep 1: Batch #95 - Loss: 0.8375369906425476\n",
      "Ep 1: Batch #96 - Loss: 0.8383124470710754\n",
      "Ep 1: Batch #97 - Loss: 0.6530383825302124\n",
      "Ep 1: Batch #98 - Loss: 0.6734055280685425\n",
      "Ep 1: Batch #99 - Loss: 0.8676652908325195\n",
      "Ep 1: Batch #100 - Loss: 0.6186489462852478\n",
      "Ep 1: Batch #101 - Loss: 0.9675900936126709\n",
      "Ep 1: Batch #102 - Loss: 0.7199684977531433\n",
      "Ep 1: Batch #103 - Loss: 0.7217168807983398\n",
      "Ep 1: Batch #104 - Loss: 0.737339973449707\n",
      "Ep 1: Batch #105 - Loss: 0.932394802570343\n",
      "Ep 1: Batch #106 - Loss: 0.6929397583007812\n",
      "Ep 1: Batch #107 - Loss: 0.6830827593803406\n",
      "Ep 1: Batch #108 - Loss: 0.9653897881507874\n",
      "Ep 1: Batch #109 - Loss: 0.6912010312080383\n",
      "Ep 1: Batch #110 - Loss: 0.8193809986114502\n",
      "Ep 1: Batch #111 - Loss: 1.2400063276290894\n",
      "Ep 1: Batch #112 - Loss: 0.9706106781959534\n",
      "Ep 1: Batch #113 - Loss: 0.7387294173240662\n",
      "Ep 1: Batch #114 - Loss: 0.8101445436477661\n",
      "Ep 1: Batch #115 - Loss: 1.0146968364715576\n",
      "Ep 1: Batch #116 - Loss: 0.5704744458198547\n",
      "Ep 1: Batch #117 - Loss: 0.7902047634124756\n",
      "Ep 1: Batch #118 - Loss: 0.5082210302352905\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved in file: ./weights_autoencoder_sigmoid/model_e1b118_1516648791.8594916.ckpt\n",
      "Ep 1: Batch #119 - Loss: 0.9239827990531921\n",
      "Ep 1: Batch #120 - Loss: 0.713852047920227\n",
      "Ep 1: Batch #121 - Loss: 0.6199213862419128\n",
      "Ep 1: Batch #122 - Loss: 0.7689291834831238\n",
      "Ep 1: Batch #123 - Loss: 0.7768160700798035\n",
      "Ep 1: Batch #124 - Loss: 0.6044211387634277\n",
      "Ep 1: Batch #125 - Loss: 2.6055197715759277\n",
      "Ep 1: Batch #126 - Loss: 1.120701551437378\n",
      "Ep 1: Batch #127 - Loss: 0.6483591198921204\n",
      "Ep 1: Batch #128 - Loss: 0.9993104338645935\n",
      "Ep 1: Batch #129 - Loss: 0.752450168132782\n",
      "Ep 1: Batch #130 - Loss: 0.6548218727111816\n",
      "Ep 1: Batch #131 - Loss: 0.8960357308387756\n",
      "Ep 1: Batch #132 - Loss: 0.7373558282852173\n",
      "Ep 1: Batch #133 - Loss: 0.7333171367645264\n",
      "Ep 1: Batch #134 - Loss: 0.7053238153457642\n",
      "Ep 1: Batch #135 - Loss: 0.8817945122718811\n",
      "Ep 1: Batch #136 - Loss: 1.09908926486969\n",
      "Ep 1: Batch #137 - Loss: 0.8473682999610901\n",
      "Ep 1: Batch #138 - Loss: 0.9736446142196655\n",
      "Ep 1: Batch #139 - Loss: 0.7878592610359192\n",
      "Ep 1: Batch #140 - Loss: 0.9510440826416016\n",
      "Ep 1: Batch #141 - Loss: 1.2462555170059204\n",
      "Ep 1: Batch #142 - Loss: 0.7056552171707153\n",
      "Ep 1: Batch #143 - Loss: 0.8691917657852173\n",
      "Ep 1: Batch #144 - Loss: 0.6605752110481262\n",
      "Ep 1: Batch #145 - Loss: 0.6320867538452148\n",
      "Ep 1: Batch #146 - Loss: 0.796575129032135\n",
      "Ep 1: Batch #147 - Loss: 0.772319495677948\n",
      "Ep 1: Batch #148 - Loss: 0.8430776000022888\n",
      "Ep 1: Batch #149 - Loss: 0.7651545405387878\n",
      "Ep 1: Batch #150 - Loss: 0.7863739728927612\n",
      "Ep 1: Batch #151 - Loss: 0.676578938961029\n",
      "Ep 1: Batch #152 - Loss: 0.6692864894866943\n",
      "Ep 1: Batch #153 - Loss: 0.9620234370231628\n",
      "Ep 1: Batch #154 - Loss: 0.6745452880859375\n",
      "Ep 1: Batch #155 - Loss: 0.7650322914123535\n",
      "Ep 1: Batch #156 - Loss: 0.918212354183197\n",
      "Ep 1: Batch #157 - Loss: 0.6780362725257874\n",
      "Ep 1: Batch #158 - Loss: 0.770491361618042\n",
      "Ep 1: Batch #159 - Loss: 0.7091637849807739\n",
      "Ep 1: Batch #160 - Loss: 0.8029209971427917\n",
      "Ep 1: Batch #161 - Loss: 0.7334693670272827\n",
      "Ep 1: Batch #162 - Loss: 0.8299202919006348\n",
      "Ep 1: Batch #163 - Loss: 0.8450143337249756\n",
      "Ep 1: Batch #164 - Loss: 0.7000757455825806\n",
      "Ep 1: Batch #165 - Loss: 1.405322551727295\n",
      "Ep 1: Batch #166 - Loss: 0.6017270088195801\n",
      "Ep 1: Batch #167 - Loss: 0.957025408744812\n",
      "Ep 1: Batch #168 - Loss: 0.762271523475647\n",
      "Ep 1: Batch #169 - Loss: 0.7282999157905579\n",
      "Ep 1: Batch #170 - Loss: 0.7014964818954468\n",
      "Ep 1: Batch #171 - Loss: 0.7073137164115906\n",
      "Ep 1: Batch #172 - Loss: 0.5810321569442749\n",
      "Ep 1: Batch #173 - Loss: 1.0587568283081055\n",
      "Ep 1: Batch #174 - Loss: 0.528306782245636\n",
      "Ep 1: Batch #175 - Loss: 0.7140321135520935\n",
      "Ep 1: Batch #176 - Loss: 1.0111953020095825\n",
      "Ep 1: Batch #177 - Loss: 0.7371314167976379\n",
      "Ep 1: Batch #178 - Loss: 0.6870999336242676\n",
      "Ep 1: Batch #179 - Loss: 0.8171834945678711\n",
      "Ep 1: Batch #180 - Loss: 0.7203452587127686\n",
      "Ep 1: Batch #181 - Loss: 0.8891252875328064\n",
      "Ep 1: Batch #182 - Loss: 0.6921614408493042\n",
      "Ep 1: Batch #183 - Loss: 0.6825454235076904\n",
      "Ep 1: Batch #184 - Loss: 0.9798897504806519\n",
      "Ep 1: Batch #185 - Loss: 0.6801797747612\n",
      "Ep 1: Batch #186 - Loss: 0.8610371947288513\n",
      "Ep 1: Batch #187 - Loss: 1.024454116821289\n",
      "Ep 1: Batch #188 - Loss: 1.1909695863723755\n",
      "Ep 1: Batch #189 - Loss: 0.624531090259552\n",
      "Ep 1: Batch #190 - Loss: 0.6672572493553162\n",
      "Ep 1: Batch #191 - Loss: 0.925137996673584\n",
      "Ep 1: Batch #192 - Loss: 0.608857274055481\n",
      "Ep 1: Batch #193 - Loss: 0.670893132686615\n",
      "Ep 1: Batch #194 - Loss: 0.6240403652191162\n",
      "Ep 1: Batch #195 - Loss: 0.851203203201294\n",
      "Ep 1: Batch #196 - Loss: 0.7605658769607544\n",
      "Ep 1: Batch #197 - Loss: 0.7953611612319946\n",
      "Ep 1: Batch #198 - Loss: 0.5889402627944946\n",
      "Ep 1: Batch #199 - Loss: 0.7370080351829529\n",
      "Ep 2: Batch #0 - Loss: 0.6928395628929138\n",
      "Ep 2: Batch #1 - Loss: 0.7691572308540344\n",
      "Ep 2: Batch #2 - Loss: 0.9206094145774841\n",
      "Ep 2: Batch #3 - Loss: 0.7669282555580139\n",
      "Ep 2: Batch #4 - Loss: 0.699323832988739\n",
      "Ep 2: Batch #5 - Loss: 0.6024676561355591\n",
      "Ep 2: Batch #6 - Loss: 0.7940864562988281\n",
      "Ep 2: Batch #7 - Loss: 0.6382970213890076\n",
      "Ep 2: Batch #8 - Loss: 0.6431990265846252\n",
      "Ep 2: Batch #9 - Loss: 1.2210651636123657\n",
      "Ep 2: Batch #10 - Loss: 0.9019688963890076\n",
      "Ep 2: Batch #11 - Loss: 0.6057465076446533\n",
      "Ep 2: Batch #12 - Loss: 1.4354759454727173\n",
      "Ep 2: Batch #13 - Loss: 0.612066388130188\n",
      "Ep 2: Batch #14 - Loss: 0.6449314951896667\n",
      "Ep 2: Batch #15 - Loss: 1.0691726207733154\n",
      "Ep 2: Batch #16 - Loss: 1.1002414226531982\n",
      "Ep 2: Batch #17 - Loss: 0.7857751250267029\n",
      "Ep 2: Batch #18 - Loss: 0.8561970591545105\n",
      "Ep 2: Batch #19 - Loss: 0.5981861352920532\n",
      "Ep 2: Batch #20 - Loss: 0.58209627866745\n",
      "Ep 2: Batch #21 - Loss: 1.0796750783920288\n",
      "Ep 2: Batch #22 - Loss: 0.6547738313674927\n",
      "Ep 2: Batch #23 - Loss: 0.6574830412864685\n",
      "Ep 2: Batch #24 - Loss: 0.7372274994850159\n",
      "Ep 2: Batch #25 - Loss: 0.6631315350532532\n",
      "Ep 2: Batch #26 - Loss: 0.6444210410118103\n",
      "Ep 2: Batch #27 - Loss: 1.2227988243103027\n",
      "Ep 2: Batch #28 - Loss: 0.7611992955207825\n",
      "Ep 2: Batch #29 - Loss: 0.8050763010978699\n",
      "Ep 2: Batch #30 - Loss: 1.056321382522583\n",
      "Ep 2: Batch #31 - Loss: 0.597015380859375\n",
      "Ep 2: Batch #32 - Loss: 0.6489841938018799\n",
      "Ep 2: Batch #33 - Loss: 0.7276062965393066\n",
      "Ep 2: Batch #34 - Loss: 0.6974313855171204\n",
      "Ep 2: Batch #35 - Loss: 0.8179026246070862\n",
      "Ep 2: Batch #36 - Loss: 0.6091411113739014\n",
      "Ep 2: Batch #37 - Loss: 1.0117241144180298\n",
      "Ep 2: Batch #38 - Loss: 0.630634069442749\n",
      "Ep 2: Batch #39 - Loss: 0.7390785813331604\n",
      "Ep 2: Batch #40 - Loss: 0.6743926405906677\n",
      "Ep 2: Batch #41 - Loss: 0.6518122553825378\n",
      "Ep 2: Batch #42 - Loss: 0.6312767863273621\n",
      "Ep 2: Batch #43 - Loss: 0.7023575901985168\n",
      "Ep 2: Batch #44 - Loss: 0.6739016771316528\n",
      "Ep 2: Batch #45 - Loss: 0.5721454620361328\n",
      "Ep 2: Batch #46 - Loss: 0.731663167476654\n",
      "Ep 2: Batch #47 - Loss: 0.8638896942138672\n",
      "Ep 2: Batch #48 - Loss: 1.2023253440856934\n",
      "Ep 2: Batch #49 - Loss: 0.8760350942611694\n",
      "Ep 2: Batch #50 - Loss: 0.6244828104972839\n",
      "Ep 2: Batch #51 - Loss: 0.8656086325645447\n",
      "Ep 2: Batch #52 - Loss: 0.7109022736549377\n",
      "Ep 2: Batch #53 - Loss: 0.7519626021385193\n",
      "Ep 2: Batch #54 - Loss: 0.6230826377868652\n",
      "Ep 2: Batch #55 - Loss: 0.6591043472290039\n",
      "Ep 2: Batch #56 - Loss: 1.0739244222640991\n",
      "Ep 2: Batch #57 - Loss: 0.7307263016700745\n",
      "Ep 2: Batch #58 - Loss: 0.8695802092552185\n",
      "Ep 2: Batch #59 - Loss: 0.6063742637634277\n",
      "Ep 2: Batch #60 - Loss: 1.1539998054504395\n",
      "Ep 2: Batch #61 - Loss: 0.5725092887878418\n",
      "Ep 2: Batch #62 - Loss: 0.633568286895752\n",
      "Ep 2: Batch #63 - Loss: 0.872816264629364\n",
      "Ep 2: Batch #64 - Loss: 9.189265251159668\n",
      "Ep 2: Batch #65 - Loss: 0.5508283376693726\n",
      "Ep 2: Batch #66 - Loss: 0.7232611179351807\n",
      "Ep 2: Batch #67 - Loss: 0.825823962688446\n",
      "Ep 2: Batch #68 - Loss: 0.7820575833320618\n",
      "Ep 2: Batch #69 - Loss: 0.6524785161018372\n",
      "Ep 2: Batch #70 - Loss: 0.6573715209960938\n",
      "Ep 2: Batch #71 - Loss: 0.5706533789634705\n",
      "Ep 2: Batch #72 - Loss: 0.724868655204773\n",
      "Ep 2: Batch #73 - Loss: 0.7946419715881348\n",
      "Ep 2: Batch #74 - Loss: 0.6326828598976135\n",
      "Ep 2: Batch #75 - Loss: 0.6971327066421509\n",
      "Ep 2: Batch #76 - Loss: 0.9970975518226624\n",
      "Ep 2: Batch #77 - Loss: 0.6435584425926208\n",
      "Ep 2: Batch #78 - Loss: 0.9962920546531677\n",
      "Ep 2: Batch #79 - Loss: 0.5684475898742676\n",
      "Ep 2: Batch #80 - Loss: 0.7461594343185425\n",
      "Ep 2: Batch #81 - Loss: 1.567986249923706\n",
      "Ep 2: Batch #82 - Loss: 0.8005072474479675\n",
      "Ep 2: Batch #83 - Loss: 1.6154391765594482\n",
      "Ep 2: Batch #84 - Loss: 0.630554735660553\n",
      "Ep 2: Batch #85 - Loss: 0.8739131689071655\n",
      "Ep 2: Batch #86 - Loss: 0.6097981333732605\n",
      "Ep 2: Batch #87 - Loss: 0.6102138757705688\n",
      "Ep 2: Batch #88 - Loss: 0.6980100274085999\n",
      "Ep 2: Batch #89 - Loss: 0.7953804135322571\n",
      "Ep 2: Batch #90 - Loss: 0.9811673760414124\n",
      "Ep 2: Batch #91 - Loss: 0.6938066482543945\n",
      "Ep 2: Batch #92 - Loss: 0.8641424179077148\n",
      "Ep 2: Batch #93 - Loss: 0.8762285709381104\n",
      "Ep 2: Batch #94 - Loss: 0.877564549446106\n",
      "Ep 2: Batch #95 - Loss: 0.8026861548423767\n",
      "Ep 2: Batch #96 - Loss: 0.8036727905273438\n",
      "Ep 2: Batch #97 - Loss: 0.6245781779289246\n",
      "Ep 2: Batch #98 - Loss: 0.6414300203323364\n",
      "Ep 2: Batch #99 - Loss: 0.8347750902175903\n",
      "Ep 2: Batch #100 - Loss: 0.5932430028915405\n",
      "Ep 2: Batch #101 - Loss: 0.9227200150489807\n",
      "Ep 2: Batch #102 - Loss: 0.6874161958694458\n",
      "Ep 2: Batch #103 - Loss: 0.6873001456260681\n",
      "Ep 2: Batch #104 - Loss: 0.7050248980522156\n",
      "Ep 2: Batch #105 - Loss: 0.8804624676704407\n",
      "Ep 2: Batch #106 - Loss: 0.6630061864852905\n",
      "Ep 2: Batch #107 - Loss: 0.6452205777168274\n",
      "Ep 2: Batch #108 - Loss: 0.9338155388832092\n",
      "Ep 2: Batch #109 - Loss: 0.6697306632995605\n",
      "Ep 2: Batch #110 - Loss: 0.7779033780097961\n",
      "Ep 2: Batch #111 - Loss: 1.190909504890442\n",
      "Ep 2: Batch #112 - Loss: 0.9201087355613708\n",
      "Ep 2: Batch #113 - Loss: 0.7020543813705444\n",
      "Ep 2: Batch #114 - Loss: 0.7808369994163513\n",
      "Ep 2: Batch #115 - Loss: 0.9746997952461243\n",
      "Ep 2: Batch #116 - Loss: 0.5520111918449402\n",
      "Ep 2: Batch #117 - Loss: 0.7585956454277039\n",
      "Ep 2: Batch #118 - Loss: 0.4864963889122009\n",
      "Model saved in file: ./weights_autoencoder_sigmoid/model_e2b118_1516648791.9973834.ckpt\n",
      "Ep 2: Batch #119 - Loss: 0.8816839456558228\n",
      "Ep 2: Batch #120 - Loss: 0.6917118430137634\n",
      "Ep 2: Batch #121 - Loss: 0.5955513715744019\n",
      "Ep 2: Batch #122 - Loss: 0.7460020184516907\n",
      "Ep 2: Batch #123 - Loss: 0.7566223740577698\n",
      "Ep 2: Batch #124 - Loss: 0.5857937932014465\n",
      "Ep 2: Batch #125 - Loss: 2.558366537094116\n",
      "Ep 2: Batch #126 - Loss: 1.0692620277404785\n",
      "Ep 2: Batch #127 - Loss: 0.623114287853241\n",
      "Ep 2: Batch #128 - Loss: 0.954621434211731\n",
      "Ep 2: Batch #129 - Loss: 0.7234342098236084\n",
      "Ep 2: Batch #130 - Loss: 0.6313971877098083\n",
      "Ep 2: Batch #131 - Loss: 0.8524268269538879\n",
      "Ep 2: Batch #132 - Loss: 0.7126511931419373\n",
      "Ep 2: Batch #133 - Loss: 0.7068530917167664\n",
      "Ep 2: Batch #134 - Loss: 0.6847173571586609\n",
      "Ep 2: Batch #135 - Loss: 0.8586539030075073\n",
      "Ep 2: Batch #136 - Loss: 1.0755290985107422\n",
      "Ep 2: Batch #137 - Loss: 0.8136599063873291\n",
      "Ep 2: Batch #138 - Loss: 0.950779914855957\n",
      "Ep 2: Batch #139 - Loss: 0.7497050762176514\n",
      "Ep 2: Batch #140 - Loss: 0.9223579168319702\n",
      "Ep 2: Batch #141 - Loss: 1.2076202630996704\n",
      "Ep 2: Batch #142 - Loss: 0.6972616910934448\n",
      "Ep 2: Batch #143 - Loss: 0.8329002261161804\n",
      "Ep 2: Batch #144 - Loss: 0.6424058675765991\n",
      "Ep 2: Batch #145 - Loss: 0.6177070736885071\n",
      "Ep 2: Batch #146 - Loss: 0.774157702922821\n",
      "Ep 2: Batch #147 - Loss: 0.747741162776947\n",
      "Ep 2: Batch #148 - Loss: 0.8186275959014893\n",
      "Ep 2: Batch #149 - Loss: 0.7322967052459717\n",
      "Ep 2: Batch #150 - Loss: 0.7703085541725159\n",
      "Ep 2: Batch #151 - Loss: 0.6638906598091125\n",
      "Ep 2: Batch #152 - Loss: 0.6527411341667175\n",
      "Ep 2: Batch #153 - Loss: 0.9275064468383789\n",
      "Ep 2: Batch #154 - Loss: 0.6613679528236389\n",
      "Ep 2: Batch #155 - Loss: 0.7431796789169312\n",
      "Ep 2: Batch #156 - Loss: 0.8840404748916626\n",
      "Ep 2: Batch #157 - Loss: 0.6609801054000854\n",
      "Ep 2: Batch #158 - Loss: 0.7546018362045288\n",
      "Ep 2: Batch #159 - Loss: 0.6897774338722229\n",
      "Ep 2: Batch #160 - Loss: 0.7783139944076538\n",
      "Ep 2: Batch #161 - Loss: 0.7181349396705627\n",
      "Ep 2: Batch #162 - Loss: 0.8010064959526062\n",
      "Ep 2: Batch #163 - Loss: 0.8280980587005615\n",
      "Ep 2: Batch #164 - Loss: 0.6857324242591858\n",
      "Ep 2: Batch #165 - Loss: 1.3836419582366943\n",
      "Ep 2: Batch #166 - Loss: 0.5870951414108276\n",
      "Ep 2: Batch #167 - Loss: 0.9205378890037537\n",
      "Ep 2: Batch #168 - Loss: 0.74283367395401\n",
      "Ep 2: Batch #169 - Loss: 0.7150719165802002\n",
      "Ep 2: Batch #170 - Loss: 0.6837744116783142\n",
      "Ep 2: Batch #171 - Loss: 0.6840530633926392\n",
      "Ep 2: Batch #172 - Loss: 0.5683997869491577\n",
      "Ep 2: Batch #173 - Loss: 1.0279507637023926\n",
      "Ep 2: Batch #174 - Loss: 0.5170565843582153\n",
      "Ep 2: Batch #175 - Loss: 0.6960489153862\n",
      "Ep 2: Batch #176 - Loss: 0.9829484820365906\n",
      "Ep 2: Batch #177 - Loss: 0.7173793315887451\n",
      "Ep 2: Batch #178 - Loss: 0.6730465888977051\n",
      "Ep 2: Batch #179 - Loss: 0.7959418296813965\n",
      "Ep 2: Batch #180 - Loss: 0.6956167817115784\n",
      "Ep 2: Batch #181 - Loss: 0.8647851347923279\n",
      "Ep 2: Batch #182 - Loss: 0.6714782118797302\n",
      "Ep 2: Batch #183 - Loss: 0.6683706641197205\n",
      "Ep 2: Batch #184 - Loss: 0.9599981307983398\n",
      "Ep 2: Batch #185 - Loss: 0.6681649088859558\n",
      "Ep 2: Batch #186 - Loss: 0.8309795260429382\n",
      "Ep 2: Batch #187 - Loss: 0.9888731837272644\n",
      "Ep 2: Batch #188 - Loss: 1.1510323286056519\n",
      "Ep 2: Batch #189 - Loss: 0.6170740127563477\n",
      "Ep 2: Batch #190 - Loss: 0.6568529605865479\n",
      "Ep 2: Batch #191 - Loss: 0.9020706415176392\n",
      "Ep 2: Batch #192 - Loss: 0.5979454517364502\n",
      "Ep 2: Batch #193 - Loss: 0.6573426723480225\n",
      "Ep 2: Batch #194 - Loss: 0.6090695858001709\n",
      "Ep 2: Batch #195 - Loss: 0.8325014710426331\n",
      "Ep 2: Batch #196 - Loss: 0.7379792332649231\n",
      "Ep 2: Batch #197 - Loss: 0.771218478679657\n",
      "Ep 2: Batch #198 - Loss: 0.5762573480606079\n",
      "Ep 2: Batch #199 - Loss: 0.7116201519966125\n",
      "Ep 3: Batch #0 - Loss: 0.6796227693557739\n",
      "Ep 3: Batch #1 - Loss: 0.7511851191520691\n",
      "Ep 3: Batch #2 - Loss: 0.9044831991195679\n",
      "Ep 3: Batch #3 - Loss: 0.754376232624054\n",
      "Ep 3: Batch #4 - Loss: 0.6842764019966125\n",
      "Ep 3: Batch #5 - Loss: 0.5926573276519775\n",
      "Ep 3: Batch #6 - Loss: 0.7779068350791931\n",
      "Ep 3: Batch #7 - Loss: 0.6278905868530273\n",
      "Ep 3: Batch #8 - Loss: 0.6299999952316284\n",
      "Ep 3: Batch #9 - Loss: 1.1867331266403198\n",
      "Ep 3: Batch #10 - Loss: 0.8883939385414124\n",
      "Ep 3: Batch #11 - Loss: 0.5872074365615845\n",
      "Ep 3: Batch #12 - Loss: 1.403794765472412\n",
      "Ep 3: Batch #13 - Loss: 0.6057473421096802\n",
      "Ep 3: Batch #14 - Loss: 0.6307329535484314\n",
      "Ep 3: Batch #15 - Loss: 1.0309120416641235\n",
      "Ep 3: Batch #16 - Loss: 1.0657684803009033\n",
      "Ep 3: Batch #17 - Loss: 0.769399106502533\n",
      "Ep 3: Batch #18 - Loss: 0.84348064661026\n",
      "Ep 3: Batch #19 - Loss: 0.5886873602867126\n",
      "Ep 3: Batch #20 - Loss: 0.5764660835266113\n",
      "Ep 3: Batch #21 - Loss: 1.0516157150268555\n",
      "Ep 3: Batch #22 - Loss: 0.6455827951431274\n",
      "Ep 3: Batch #23 - Loss: 0.6430578827857971\n",
      "Ep 3: Batch #24 - Loss: 0.7159688472747803\n",
      "Ep 3: Batch #25 - Loss: 0.655163049697876\n",
      "Ep 3: Batch #26 - Loss: 0.6312640309333801\n",
      "Ep 3: Batch #27 - Loss: 1.1976040601730347\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 3: Batch #28 - Loss: 0.7439182996749878\n",
      "Ep 3: Batch #29 - Loss: 0.7915074229240417\n",
      "Ep 3: Batch #30 - Loss: 1.0244781970977783\n",
      "Ep 3: Batch #31 - Loss: 0.5898144245147705\n",
      "Ep 3: Batch #32 - Loss: 0.6318385601043701\n",
      "Ep 3: Batch #33 - Loss: 0.7124435901641846\n",
      "Ep 3: Batch #34 - Loss: 0.687017560005188\n",
      "Ep 3: Batch #35 - Loss: 0.7966593503952026\n",
      "Ep 3: Batch #36 - Loss: 0.6022839546203613\n",
      "Ep 3: Batch #37 - Loss: 0.9851767420768738\n",
      "Ep 3: Batch #38 - Loss: 0.6131783723831177\n",
      "Ep 3: Batch #39 - Loss: 0.7268926501274109\n",
      "Ep 3: Batch #40 - Loss: 0.6562013030052185\n",
      "Ep 3: Batch #41 - Loss: 0.6469074487686157\n",
      "Ep 3: Batch #42 - Loss: 0.6189828515052795\n",
      "Ep 3: Batch #43 - Loss: 0.6837652921676636\n",
      "Ep 3: Batch #44 - Loss: 0.6655813455581665\n",
      "Ep 3: Batch #45 - Loss: 0.5645639300346375\n",
      "Ep 3: Batch #46 - Loss: 0.7202762961387634\n",
      "Ep 3: Batch #47 - Loss: 0.8470287322998047\n",
      "Ep 3: Batch #48 - Loss: 1.1675084829330444\n",
      "Ep 3: Batch #49 - Loss: 0.857027530670166\n",
      "Ep 3: Batch #50 - Loss: 0.6105228662490845\n",
      "Ep 3: Batch #51 - Loss: 0.8489946126937866\n",
      "Ep 3: Batch #52 - Loss: 0.702450156211853\n",
      "Ep 3: Batch #53 - Loss: 0.7432268857955933\n",
      "Ep 3: Batch #54 - Loss: 0.6173569560050964\n",
      "Ep 3: Batch #55 - Loss: 0.6502769589424133\n",
      "Ep 3: Batch #56 - Loss: 1.0335572957992554\n",
      "Ep 3: Batch #57 - Loss: 0.7173072099685669\n",
      "Ep 3: Batch #58 - Loss: 0.8579690456390381\n",
      "Ep 3: Batch #59 - Loss: 0.5960215926170349\n",
      "Ep 3: Batch #60 - Loss: 1.1239213943481445\n",
      "Ep 3: Batch #61 - Loss: 0.5611832737922668\n",
      "Ep 3: Batch #62 - Loss: 0.6232091784477234\n",
      "Ep 3: Batch #63 - Loss: 0.8512226939201355\n",
      "Ep 3: Batch #64 - Loss: 9.105880737304688\n",
      "Ep 3: Batch #65 - Loss: 0.545378565788269\n",
      "Ep 3: Batch #66 - Loss: 0.711596667766571\n",
      "Ep 3: Batch #67 - Loss: 0.8126065731048584\n",
      "Ep 3: Batch #68 - Loss: 0.7698456645011902\n",
      "Ep 3: Batch #69 - Loss: 0.6471010446548462\n",
      "Ep 3: Batch #70 - Loss: 0.6466784477233887\n",
      "Ep 3: Batch #71 - Loss: 0.5645526051521301\n",
      "Ep 3: Batch #72 - Loss: 0.7139480113983154\n",
      "Ep 3: Batch #73 - Loss: 0.7866674065589905\n",
      "Ep 3: Batch #74 - Loss: 0.6204925179481506\n",
      "Ep 3: Batch #75 - Loss: 0.6934521198272705\n",
      "Ep 3: Batch #76 - Loss: 0.9871519207954407\n",
      "Ep 3: Batch #77 - Loss: 0.6336288452148438\n",
      "Ep 3: Batch #78 - Loss: 0.9767447113990784\n",
      "Ep 3: Batch #79 - Loss: 0.559735119342804\n",
      "Ep 3: Batch #80 - Loss: 0.7358750700950623\n",
      "Ep 3: Batch #81 - Loss: 1.5603463649749756\n",
      "Ep 3: Batch #82 - Loss: 0.789631724357605\n",
      "Ep 3: Batch #83 - Loss: 1.5838923454284668\n",
      "Ep 3: Batch #84 - Loss: 0.6196970343589783\n",
      "Ep 3: Batch #85 - Loss: 0.8634235858917236\n",
      "Ep 3: Batch #86 - Loss: 0.5977279543876648\n",
      "Ep 3: Batch #87 - Loss: 0.5981593728065491\n",
      "Ep 3: Batch #88 - Loss: 0.6850301027297974\n",
      "Ep 3: Batch #89 - Loss: 0.7889683246612549\n",
      "Ep 3: Batch #90 - Loss: 0.9612129330635071\n",
      "Ep 3: Batch #91 - Loss: 0.6818168759346008\n",
      "Ep 3: Batch #92 - Loss: 0.8466237187385559\n",
      "Ep 3: Batch #93 - Loss: 0.8572216629981995\n",
      "Ep 3: Batch #94 - Loss: 0.8584547638893127\n",
      "Ep 3: Batch #95 - Loss: 0.7908691167831421\n",
      "Ep 3: Batch #96 - Loss: 0.7903395295143127\n",
      "Ep 3: Batch #97 - Loss: 0.6168645024299622\n",
      "Ep 3: Batch #98 - Loss: 0.6315425634384155\n",
      "Ep 3: Batch #99 - Loss: 0.8261953592300415\n",
      "Ep 3: Batch #100 - Loss: 0.5852489471435547\n",
      "Ep 3: Batch #101 - Loss: 0.9061472415924072\n",
      "Ep 3: Batch #102 - Loss: 0.671861469745636\n",
      "Ep 3: Batch #103 - Loss: 0.6765925884246826\n",
      "Ep 3: Batch #104 - Loss: 0.6941876411437988\n",
      "Ep 3: Batch #105 - Loss: 0.8599696159362793\n",
      "Ep 3: Batch #106 - Loss: 0.6550066471099854\n",
      "Ep 3: Batch #107 - Loss: 0.6351204514503479\n",
      "Ep 3: Batch #108 - Loss: 0.9235866665840149\n",
      "Ep 3: Batch #109 - Loss: 0.6619858741760254\n",
      "Ep 3: Batch #110 - Loss: 0.7637559771537781\n",
      "Ep 3: Batch #111 - Loss: 1.1602660417556763\n",
      "Ep 3: Batch #112 - Loss: 0.8980159759521484\n",
      "Ep 3: Batch #113 - Loss: 0.6906651854515076\n",
      "Ep 3: Batch #114 - Loss: 0.7718179225921631\n",
      "Ep 3: Batch #115 - Loss: 0.9593616724014282\n",
      "Ep 3: Batch #116 - Loss: 0.5467810034751892\n",
      "Ep 3: Batch #117 - Loss: 0.7483428120613098\n",
      "Ep 3: Batch #118 - Loss: 0.4794653356075287\n",
      "Model saved in file: ./weights_autoencoder_sigmoid/model_e3b118_1516648792.1339262.ckpt\n",
      "Ep 3: Batch #119 - Loss: 0.8599340319633484\n",
      "Ep 3: Batch #120 - Loss: 0.6858705878257751\n",
      "Ep 3: Batch #121 - Loss: 0.5872361063957214\n",
      "Ep 3: Batch #122 - Loss: 0.7378128170967102\n",
      "Ep 3: Batch #123 - Loss: 0.7481701374053955\n",
      "Ep 3: Batch #124 - Loss: 0.5796467661857605\n",
      "Ep 3: Batch #125 - Loss: 2.5380945205688477\n",
      "Ep 3: Batch #126 - Loss: 1.0480492115020752\n",
      "Ep 3: Batch #127 - Loss: 0.6164302825927734\n",
      "Ep 3: Batch #128 - Loss: 0.93706876039505\n",
      "Ep 3: Batch #129 - Loss: 0.7121268510818481\n",
      "Ep 3: Batch #130 - Loss: 0.6247938275337219\n",
      "Ep 3: Batch #131 - Loss: 0.837661623954773\n",
      "Ep 3: Batch #132 - Loss: 0.7079148888587952\n",
      "Ep 3: Batch #133 - Loss: 0.6984348893165588\n",
      "Ep 3: Batch #134 - Loss: 0.6768567562103271\n",
      "Ep 3: Batch #135 - Loss: 0.8495289087295532\n",
      "Ep 3: Batch #136 - Loss: 1.06926429271698\n",
      "Ep 3: Batch #137 - Loss: 0.7994644641876221\n",
      "Ep 3: Batch #138 - Loss: 0.94232577085495\n",
      "Ep 3: Batch #139 - Loss: 0.7319520115852356\n",
      "Ep 3: Batch #140 - Loss: 0.9112040996551514\n",
      "Ep 3: Batch #141 - Loss: 1.1904915571212769\n",
      "Ep 3: Batch #142 - Loss: 0.6965475082397461\n",
      "Ep 3: Batch #143 - Loss: 0.8172200322151184\n",
      "Ep 3: Batch #144 - Loss: 0.6351900100708008\n",
      "Ep 3: Batch #145 - Loss: 0.6108366250991821\n",
      "Ep 3: Batch #146 - Loss: 0.764125645160675\n",
      "Ep 3: Batch #147 - Loss: 0.7387036681175232\n",
      "Ep 3: Batch #148 - Loss: 0.8072407245635986\n",
      "Ep 3: Batch #149 - Loss: 0.7185433506965637\n",
      "Ep 3: Batch #150 - Loss: 0.7632176876068115\n",
      "Ep 3: Batch #151 - Loss: 0.660272479057312\n",
      "Ep 3: Batch #152 - Loss: 0.6480944752693176\n",
      "Ep 3: Batch #153 - Loss: 0.9108811616897583\n",
      "Ep 3: Batch #154 - Loss: 0.6577789783477783\n",
      "Ep 3: Batch #155 - Loss: 0.7373989820480347\n",
      "Ep 3: Batch #156 - Loss: 0.8680713176727295\n",
      "Ep 3: Batch #157 - Loss: 0.6536945700645447\n",
      "Ep 3: Batch #158 - Loss: 0.7476711869239807\n",
      "Ep 3: Batch #159 - Loss: 0.68060702085495\n",
      "Ep 3: Batch #160 - Loss: 0.7675901651382446\n",
      "Ep 3: Batch #161 - Loss: 0.7129399180412292\n",
      "Ep 3: Batch #162 - Loss: 0.7877088785171509\n",
      "Ep 3: Batch #163 - Loss: 0.8194493651390076\n",
      "Ep 3: Batch #164 - Loss: 0.681329607963562\n",
      "Ep 3: Batch #165 - Loss: 1.3748283386230469\n",
      "Ep 3: Batch #166 - Loss: 0.5817265510559082\n",
      "Ep 3: Batch #167 - Loss: 0.901935875415802\n",
      "Ep 3: Batch #168 - Loss: 0.7344701290130615\n",
      "Ep 3: Batch #169 - Loss: 0.7083142399787903\n",
      "Ep 3: Batch #170 - Loss: 0.6787273287773132\n",
      "Ep 3: Batch #171 - Loss: 0.6752130389213562\n",
      "Ep 3: Batch #172 - Loss: 0.5637391805648804\n",
      "Ep 3: Batch #173 - Loss: 1.0147764682769775\n",
      "Ep 3: Batch #174 - Loss: 0.5125885009765625\n",
      "Ep 3: Batch #175 - Loss: 0.6881065964698792\n",
      "Ep 3: Batch #176 - Loss: 0.9704086780548096\n",
      "Ep 3: Batch #177 - Loss: 0.7110793590545654\n",
      "Ep 3: Batch #178 - Loss: 0.6686304211616516\n",
      "Ep 3: Batch #179 - Loss: 0.7896742820739746\n",
      "Ep 3: Batch #180 - Loss: 0.6886309385299683\n",
      "Ep 3: Batch #181 - Loss: 0.8531912565231323\n",
      "Ep 3: Batch #182 - Loss: 0.6608781218528748\n",
      "Ep 3: Batch #183 - Loss: 0.6611723303794861\n",
      "Ep 3: Batch #184 - Loss: 0.9496812224388123\n",
      "Ep 3: Batch #185 - Loss: 0.6632227897644043\n",
      "Ep 3: Batch #186 - Loss: 0.8171237707138062\n",
      "Ep 3: Batch #187 - Loss: 0.9687625169754028\n",
      "Ep 3: Batch #188 - Loss: 1.1281582117080688\n",
      "Ep 3: Batch #189 - Loss: 0.6145243048667908\n",
      "Ep 3: Batch #190 - Loss: 0.6522701382637024\n",
      "Ep 3: Batch #191 - Loss: 0.8897095322608948\n",
      "Ep 3: Batch #192 - Loss: 0.5939629673957825\n",
      "Ep 3: Batch #193 - Loss: 0.6511830687522888\n",
      "Ep 3: Batch #194 - Loss: 0.60329669713974\n",
      "Ep 3: Batch #195 - Loss: 0.8247016072273254\n",
      "Ep 3: Batch #196 - Loss: 0.7281734347343445\n",
      "Ep 3: Batch #197 - Loss: 0.7595531344413757\n",
      "Ep 3: Batch #198 - Loss: 0.5717633366584778\n",
      "Ep 3: Batch #199 - Loss: 0.6999235153198242\n",
      "Ep 4: Batch #0 - Loss: 0.6748872399330139\n",
      "Ep 4: Batch #1 - Loss: 0.7469702363014221\n",
      "Ep 4: Batch #2 - Loss: 0.8956793546676636\n",
      "Ep 4: Batch #3 - Loss: 0.7501674294471741\n",
      "Ep 4: Batch #4 - Loss: 0.6770814061164856\n",
      "Ep 4: Batch #5 - Loss: 0.5894715785980225\n",
      "Ep 4: Batch #6 - Loss: 0.770056962966919\n",
      "Ep 4: Batch #7 - Loss: 0.6224730610847473\n",
      "Ep 4: Batch #8 - Loss: 0.6211850047111511\n",
      "Ep 4: Batch #9 - Loss: 1.1696263551712036\n",
      "Ep 4: Batch #10 - Loss: 0.8818551301956177\n",
      "Ep 4: Batch #11 - Loss: 0.5773979425430298\n",
      "Ep 4: Batch #12 - Loss: 1.3827142715454102\n",
      "Ep 4: Batch #13 - Loss: 0.6028698086738586\n",
      "Ep 4: Batch #14 - Loss: 0.6244859099388123\n",
      "Ep 4: Batch #15 - Loss: 1.009278655052185\n",
      "Ep 4: Batch #16 - Loss: 1.0500199794769287\n",
      "Ep 4: Batch #17 - Loss: 0.7608467936515808\n",
      "Ep 4: Batch #18 - Loss: 0.8386102914810181\n",
      "Ep 4: Batch #19 - Loss: 0.5852290987968445\n",
      "Ep 4: Batch #20 - Loss: 0.574345588684082\n",
      "Ep 4: Batch #21 - Loss: 1.034193754196167\n",
      "Ep 4: Batch #22 - Loss: 0.6417702436447144\n",
      "Ep 4: Batch #23 - Loss: 0.6370164155960083\n",
      "Ep 4: Batch #24 - Loss: 0.7042655944824219\n",
      "Ep 4: Batch #25 - Loss: 0.651935338973999\n",
      "Ep 4: Batch #26 - Loss: 0.6245253682136536\n",
      "Ep 4: Batch #27 - Loss: 1.1844664812088013\n",
      "Ep 4: Batch #28 - Loss: 0.7347763180732727\n",
      "Ep 4: Batch #29 - Loss: 0.7849975824356079\n",
      "Ep 4: Batch #30 - Loss: 1.0046679973602295\n",
      "Ep 4: Batch #31 - Loss: 0.5863827466964722\n",
      "Ep 4: Batch #32 - Loss: 0.6247353553771973\n",
      "Ep 4: Batch #33 - Loss: 0.7050490379333496\n",
      "Ep 4: Batch #34 - Loss: 0.6815165281295776\n",
      "Ep 4: Batch #35 - Loss: 0.7883237600326538\n",
      "Ep 4: Batch #36 - Loss: 0.6002479791641235\n",
      "Ep 4: Batch #37 - Loss: 0.9711740016937256\n",
      "Ep 4: Batch #38 - Loss: 0.60530024766922\n",
      "Ep 4: Batch #39 - Loss: 0.7212222814559937\n",
      "Ep 4: Batch #40 - Loss: 0.6470760107040405\n",
      "Ep 4: Batch #41 - Loss: 0.6441860795021057\n",
      "Ep 4: Batch #42 - Loss: 0.6123887896537781\n",
      "Ep 4: Batch #43 - Loss: 0.6744961142539978\n",
      "Ep 4: Batch #44 - Loss: 0.6626179814338684\n",
      "Ep 4: Batch #45 - Loss: 0.5612184405326843\n",
      "Ep 4: Batch #46 - Loss: 0.7156825661659241\n",
      "Ep 4: Batch #47 - Loss: 0.8400830626487732\n",
      "Ep 4: Batch #48 - Loss: 1.1470556259155273\n",
      "Ep 4: Batch #49 - Loss: 0.8484382629394531\n",
      "Ep 4: Batch #50 - Loss: 0.6036312580108643\n",
      "Ep 4: Batch #51 - Loss: 0.8426768183708191\n",
      "Ep 4: Batch #52 - Loss: 0.7003975510597229\n",
      "Ep 4: Batch #53 - Loss: 0.7384192943572998\n",
      "Ep 4: Batch #54 - Loss: 0.6147681474685669\n",
      "Ep 4: Batch #55 - Loss: 0.6460114121437073\n",
      "Ep 4: Batch #56 - Loss: 1.0082303285598755\n",
      "Ep 4: Batch #57 - Loss: 0.7118387818336487\n",
      "Ep 4: Batch #58 - Loss: 0.8523988127708435\n",
      "Ep 4: Batch #59 - Loss: 0.5912081599235535\n",
      "Ep 4: Batch #60 - Loss: 1.105096459388733\n",
      "Ep 4: Batch #61 - Loss: 0.5550937652587891\n",
      "Ep 4: Batch #62 - Loss: 0.61931973695755\n",
      "Ep 4: Batch #63 - Loss: 0.8401716947555542\n",
      "Ep 4: Batch #64 - Loss: 9.054522514343262\n",
      "Ep 4: Batch #65 - Loss: 0.5434577465057373\n",
      "Ep 4: Batch #66 - Loss: 0.7060130834579468\n",
      "Ep 4: Batch #67 - Loss: 0.8071438670158386\n",
      "Ep 4: Batch #68 - Loss: 0.7641698718070984\n",
      "Ep 4: Batch #69 - Loss: 0.6435896754264832\n",
      "Ep 4: Batch #70 - Loss: 0.6414154767990112\n",
      "Ep 4: Batch #71 - Loss: 0.5626569390296936\n",
      "Ep 4: Batch #72 - Loss: 0.7076862454414368\n",
      "Ep 4: Batch #73 - Loss: 0.7830572128295898\n",
      "Ep 4: Batch #74 - Loss: 0.6144575476646423\n",
      "Ep 4: Batch #75 - Loss: 0.6908064484596252\n",
      "Ep 4: Batch #76 - Loss: 0.9822549223899841\n",
      "Ep 4: Batch #77 - Loss: 0.627840518951416\n",
      "Ep 4: Batch #78 - Loss: 0.9656065702438354\n",
      "Ep 4: Batch #79 - Loss: 0.5547072291374207\n",
      "Ep 4: Batch #80 - Loss: 0.7313455939292908\n",
      "Ep 4: Batch #81 - Loss: 1.5560497045516968\n",
      "Ep 4: Batch #82 - Loss: 0.7832399606704712\n",
      "Ep 4: Batch #83 - Loss: 1.5585416555404663\n",
      "Ep 4: Batch #84 - Loss: 0.6152475476264954\n",
      "Ep 4: Batch #85 - Loss: 0.8568759560585022\n",
      "Ep 4: Batch #86 - Loss: 0.5919716358184814\n",
      "Ep 4: Batch #87 - Loss: 0.5930911898612976\n",
      "Ep 4: Batch #88 - Loss: 0.6798250079154968\n",
      "Ep 4: Batch #89 - Loss: 0.7862577438354492\n",
      "Ep 4: Batch #90 - Loss: 0.9526489973068237\n",
      "Ep 4: Batch #91 - Loss: 0.6763610243797302\n",
      "Ep 4: Batch #92 - Loss: 0.8370285630226135\n",
      "Ep 4: Batch #93 - Loss: 0.8454416394233704\n",
      "Ep 4: Batch #94 - Loss: 0.8476235866546631\n",
      "Ep 4: Batch #95 - Loss: 0.7854581475257874\n",
      "Ep 4: Batch #96 - Loss: 0.7848761677742004\n",
      "Ep 4: Batch #97 - Loss: 0.6121780872344971\n",
      "Ep 4: Batch #98 - Loss: 0.6260596513748169\n",
      "Ep 4: Batch #99 - Loss: 0.8227517008781433\n",
      "Ep 4: Batch #100 - Loss: 0.5816685557365417\n",
      "Ep 4: Batch #101 - Loss: 0.8970567584037781\n",
      "Ep 4: Batch #102 - Loss: 0.6638653874397278\n",
      "Ep 4: Batch #103 - Loss: 0.6720241904258728\n",
      "Ep 4: Batch #104 - Loss: 0.6889363527297974\n",
      "Ep 4: Batch #105 - Loss: 0.8507699966430664\n",
      "Ep 4: Batch #106 - Loss: 0.651809573173523\n",
      "Ep 4: Batch #107 - Loss: 0.6311265230178833\n",
      "Ep 4: Batch #108 - Loss: 0.9185830354690552\n",
      "Ep 4: Batch #109 - Loss: 0.6590648293495178\n",
      "Ep 4: Batch #110 - Loss: 0.7565774917602539\n",
      "Ep 4: Batch #111 - Loss: 1.1469404697418213\n",
      "Ep 4: Batch #112 - Loss: 0.8863194584846497\n",
      "Ep 4: Batch #113 - Loss: 0.6859551668167114\n",
      "Ep 4: Batch #114 - Loss: 0.766749918460846\n",
      "Ep 4: Batch #115 - Loss: 0.9506272673606873\n",
      "Ep 4: Batch #116 - Loss: 0.544601321220398\n",
      "Ep 4: Batch #117 - Loss: 0.7433204650878906\n",
      "Ep 4: Batch #118 - Loss: 0.4756643772125244\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved in file: ./weights_autoencoder_sigmoid/model_e4b118_1516648792.2697096.ckpt\n",
      "Ep 4: Batch #119 - Loss: 0.8479302525520325\n",
      "Ep 4: Batch #120 - Loss: 0.6837577223777771\n",
      "Ep 4: Batch #121 - Loss: 0.583983838558197\n",
      "Ep 4: Batch #122 - Loss: 0.7335646748542786\n",
      "Ep 4: Batch #123 - Loss: 0.7444546818733215\n",
      "Ep 4: Batch #124 - Loss: 0.5766264796257019\n",
      "Ep 4: Batch #125 - Loss: 2.5256874561309814\n",
      "Ep 4: Batch #126 - Loss: 1.0369359254837036\n",
      "Ep 4: Batch #127 - Loss: 0.6121613383293152\n",
      "Ep 4: Batch #128 - Loss: 0.9267159700393677\n",
      "Ep 4: Batch #129 - Loss: 0.7054951190948486\n",
      "Ep 4: Batch #130 - Loss: 0.6221753358840942\n",
      "Ep 4: Batch #131 - Loss: 0.8297778964042664\n",
      "Ep 4: Batch #132 - Loss: 0.7064998149871826\n",
      "Ep 4: Batch #133 - Loss: 0.6948533058166504\n",
      "Ep 4: Batch #134 - Loss: 0.6727768182754517\n",
      "Ep 4: Batch #135 - Loss: 0.845299243927002\n",
      "Ep 4: Batch #136 - Loss: 1.0670422315597534\n",
      "Ep 4: Batch #137 - Loss: 0.791467547416687\n",
      "Ep 4: Batch #138 - Loss: 0.9375894069671631\n",
      "Ep 4: Batch #139 - Loss: 0.7238596081733704\n",
      "Ep 4: Batch #140 - Loss: 0.9059281945228577\n",
      "Ep 4: Batch #141 - Loss: 1.182043194770813\n",
      "Ep 4: Batch #142 - Loss: 0.6954627633094788\n",
      "Ep 4: Batch #143 - Loss: 0.8088213801383972\n",
      "Ep 4: Batch #144 - Loss: 0.6320947408676147\n",
      "Ep 4: Batch #145 - Loss: 0.6086113452911377\n",
      "Ep 4: Batch #146 - Loss: 0.7573798298835754\n",
      "Ep 4: Batch #147 - Loss: 0.7345612645149231\n",
      "Ep 4: Batch #148 - Loss: 0.8022066950798035\n",
      "Ep 4: Batch #149 - Loss: 0.7113564610481262\n",
      "Ep 4: Batch #150 - Loss: 0.7602789402008057\n",
      "Ep 4: Batch #151 - Loss: 0.6586155891418457\n",
      "Ep 4: Batch #152 - Loss: 0.6450548768043518\n",
      "Ep 4: Batch #153 - Loss: 0.9015021920204163\n",
      "Ep 4: Batch #154 - Loss: 0.6562035083770752\n",
      "Ep 4: Batch #155 - Loss: 0.7327765226364136\n",
      "Ep 4: Batch #156 - Loss: 0.8593587875366211\n",
      "Ep 4: Batch #157 - Loss: 0.6502156853675842\n",
      "Ep 4: Batch #158 - Loss: 0.7442757487297058\n",
      "Ep 4: Batch #159 - Loss: 0.674593448638916\n",
      "Ep 4: Batch #160 - Loss: 0.7625965476036072\n",
      "Ep 4: Batch #161 - Loss: 0.7098435759544373\n",
      "Ep 4: Batch #162 - Loss: 0.7786406874656677\n",
      "Ep 4: Batch #163 - Loss: 0.814146876335144\n",
      "Ep 4: Batch #164 - Loss: 0.679172933101654\n",
      "Ep 4: Batch #165 - Loss: 1.3702207803726196\n",
      "Ep 4: Batch #166 - Loss: 0.5778801441192627\n",
      "Ep 4: Batch #167 - Loss: 0.8906850218772888\n",
      "Ep 4: Batch #168 - Loss: 0.730757474899292\n",
      "Ep 4: Batch #169 - Loss: 0.7046847343444824\n",
      "Ep 4: Batch #170 - Loss: 0.676459789276123\n",
      "Ep 4: Batch #171 - Loss: 0.6713081002235413\n",
      "Ep 4: Batch #172 - Loss: 0.5609111785888672\n",
      "Ep 4: Batch #173 - Loss: 1.0075199604034424\n",
      "Ep 4: Batch #174 - Loss: 0.5106731653213501\n",
      "Ep 4: Batch #175 - Loss: 0.6838265657424927\n",
      "Ep 4: Batch #176 - Loss: 0.9629821181297302\n",
      "Ep 4: Batch #177 - Loss: 0.7073875665664673\n",
      "Ep 4: Batch #178 - Loss: 0.6656461358070374\n",
      "Ep 4: Batch #179 - Loss: 0.7854418158531189\n",
      "Ep 4: Batch #180 - Loss: 0.6860770583152771\n",
      "Ep 4: Batch #181 - Loss: 0.8465779423713684\n",
      "Ep 4: Batch #182 - Loss: 0.6552271842956543\n",
      "Ep 4: Batch #183 - Loss: 0.6566567420959473\n",
      "Ep 4: Batch #184 - Loss: 0.9443379640579224\n",
      "Ep 4: Batch #185 - Loss: 0.6605916619300842\n",
      "Ep 4: Batch #186 - Loss: 0.8094455599784851\n",
      "Ep 4: Batch #187 - Loss: 0.9581072926521301\n",
      "Ep 4: Batch #188 - Loss: 1.1130707263946533\n",
      "Ep 4: Batch #189 - Loss: 0.6123499870300293\n",
      "Ep 4: Batch #190 - Loss: 0.6492509841918945\n",
      "Ep 4: Batch #191 - Loss: 0.8804673552513123\n",
      "Ep 4: Batch #192 - Loss: 0.5920508503913879\n",
      "Ep 4: Batch #193 - Loss: 0.6479512453079224\n",
      "Ep 4: Batch #194 - Loss: 0.5998880863189697\n",
      "Ep 4: Batch #195 - Loss: 0.8195869326591492\n",
      "Ep 4: Batch #196 - Loss: 0.7239803075790405\n",
      "Ep 4: Batch #197 - Loss: 0.7533363699913025\n",
      "Ep 4: Batch #198 - Loss: 0.5686454772949219\n",
      "Ep 4: Batch #199 - Loss: 0.6932160258293152\n",
      "Ep 5: Batch #0 - Loss: 0.6721857786178589\n",
      "Ep 5: Batch #1 - Loss: 0.7452061772346497\n",
      "Ep 5: Batch #2 - Loss: 0.889799177646637\n",
      "Ep 5: Batch #3 - Loss: 0.7476127743721008\n",
      "Ep 5: Batch #4 - Loss: 0.6738198399543762\n",
      "Ep 5: Batch #5 - Loss: 0.5872422456741333\n",
      "Ep 5: Batch #6 - Loss: 0.765698254108429\n",
      "Ep 5: Batch #7 - Loss: 0.6195061802864075\n",
      "Ep 5: Batch #8 - Loss: 0.6170998215675354\n",
      "Ep 5: Batch #9 - Loss: 1.159415602684021\n",
      "Ep 5: Batch #10 - Loss: 0.8789499402046204\n",
      "Ep 5: Batch #11 - Loss: 0.5716615915298462\n",
      "Ep 5: Batch #12 - Loss: 1.3664419651031494\n",
      "Ep 5: Batch #13 - Loss: 0.6003351211547852\n",
      "Ep 5: Batch #14 - Loss: 0.6209915280342102\n",
      "Ep 5: Batch #15 - Loss: 0.9969590902328491\n",
      "Ep 5: Batch #16 - Loss: 1.0411243438720703\n",
      "Ep 5: Batch #17 - Loss: 0.7565078735351562\n",
      "Ep 5: Batch #18 - Loss: 0.8359884023666382\n",
      "Ep 5: Batch #19 - Loss: 0.583565354347229\n",
      "Ep 5: Batch #20 - Loss: 0.5731033682823181\n",
      "Ep 5: Batch #21 - Loss: 1.0218600034713745\n",
      "Ep 5: Batch #22 - Loss: 0.6401005983352661\n",
      "Ep 5: Batch #23 - Loss: 0.6334381103515625\n",
      "Ep 5: Batch #24 - Loss: 0.6971257328987122\n",
      "Ep 5: Batch #25 - Loss: 0.6490997672080994\n",
      "Ep 5: Batch #26 - Loss: 0.620745837688446\n",
      "Ep 5: Batch #27 - Loss: 1.1774811744689941\n",
      "Ep 5: Batch #28 - Loss: 0.7295100092887878\n",
      "Ep 5: Batch #29 - Loss: 0.7821270227432251\n",
      "Ep 5: Batch #30 - Loss: 0.9912993907928467\n",
      "Ep 5: Batch #31 - Loss: 0.5838272571563721\n",
      "Ep 5: Batch #32 - Loss: 0.6193534731864929\n",
      "Ep 5: Batch #33 - Loss: 0.7017734050750732\n",
      "Ep 5: Batch #34 - Loss: 0.6781018376350403\n",
      "Ep 5: Batch #35 - Loss: 0.7842116355895996\n",
      "Ep 5: Batch #36 - Loss: 0.5990017652511597\n",
      "Ep 5: Batch #37 - Loss: 0.9616636037826538\n",
      "Ep 5: Batch #38 - Loss: 0.601560115814209\n",
      "Ep 5: Batch #39 - Loss: 0.7185314297676086\n",
      "Ep 5: Batch #40 - Loss: 0.641991376876831\n",
      "Ep 5: Batch #41 - Loss: 0.6429411768913269\n",
      "Ep 5: Batch #42 - Loss: 0.6073400378227234\n",
      "Ep 5: Batch #43 - Loss: 0.6690536141395569\n",
      "Ep 5: Batch #44 - Loss: 0.6609137058258057\n",
      "Ep 5: Batch #45 - Loss: 0.5584304928779602\n",
      "Ep 5: Batch #46 - Loss: 0.7140666842460632\n",
      "Ep 5: Batch #47 - Loss: 0.8361448049545288\n",
      "Ep 5: Batch #48 - Loss: 1.134077787399292\n",
      "Ep 5: Batch #49 - Loss: 0.844144880771637\n",
      "Ep 5: Batch #50 - Loss: 0.5993475317955017\n",
      "Ep 5: Batch #51 - Loss: 0.8401070833206177\n",
      "Ep 5: Batch #52 - Loss: 0.6991336941719055\n",
      "Ep 5: Batch #53 - Loss: 0.7351875901222229\n",
      "Ep 5: Batch #54 - Loss: 0.613041341304779\n",
      "Ep 5: Batch #55 - Loss: 0.643378734588623\n",
      "Ep 5: Batch #56 - Loss: 0.9901198744773865\n",
      "Ep 5: Batch #57 - Loss: 0.7085824012756348\n",
      "Ep 5: Batch #58 - Loss: 0.8494157791137695\n",
      "Ep 5: Batch #59 - Loss: 0.5885558724403381\n",
      "Ep 5: Batch #60 - Loss: 1.0916749238967896\n",
      "Ep 5: Batch #61 - Loss: 0.5515081286430359\n",
      "Ep 5: Batch #62 - Loss: 0.6167538166046143\n",
      "Ep 5: Batch #63 - Loss: 0.8332534432411194\n",
      "Ep 5: Batch #64 - Loss: 9.017995834350586\n",
      "Ep 5: Batch #65 - Loss: 0.5421937108039856\n",
      "Ep 5: Batch #66 - Loss: 0.7029166221618652\n",
      "Ep 5: Batch #67 - Loss: 0.8040336966514587\n",
      "Ep 5: Batch #68 - Loss: 0.7609335780143738\n",
      "Ep 5: Batch #69 - Loss: 0.6410700678825378\n",
      "Ep 5: Batch #70 - Loss: 0.6392869353294373\n",
      "Ep 5: Batch #71 - Loss: 0.5612605810165405\n",
      "Ep 5: Batch #72 - Loss: 0.7029516696929932\n",
      "Ep 5: Batch #73 - Loss: 0.7805361151695251\n",
      "Ep 5: Batch #74 - Loss: 0.6108354926109314\n",
      "Ep 5: Batch #75 - Loss: 0.6881458163261414\n",
      "Ep 5: Batch #76 - Loss: 0.9789838194847107\n",
      "Ep 5: Batch #77 - Loss: 0.6241123676300049\n",
      "Ep 5: Batch #78 - Loss: 0.9601126313209534\n",
      "Ep 5: Batch #79 - Loss: 0.5520619750022888\n",
      "Ep 5: Batch #80 - Loss: 0.7294716835021973\n",
      "Ep 5: Batch #81 - Loss: 1.554002285003662\n",
      "Ep 5: Batch #82 - Loss: 0.7789963483810425\n",
      "Ep 5: Batch #83 - Loss: 1.5404541492462158\n",
      "Ep 5: Batch #84 - Loss: 0.6123084425926208\n",
      "Ep 5: Batch #85 - Loss: 0.8519324660301208\n",
      "Ep 5: Batch #86 - Loss: 0.58791583776474\n",
      "Ep 5: Batch #87 - Loss: 0.5906304121017456\n",
      "Ep 5: Batch #88 - Loss: 0.6774111390113831\n",
      "Ep 5: Batch #89 - Loss: 0.7850672602653503\n",
      "Ep 5: Batch #90 - Loss: 0.9479612112045288\n",
      "Ep 5: Batch #91 - Loss: 0.6721960306167603\n",
      "Ep 5: Batch #92 - Loss: 0.8324871063232422\n",
      "Ep 5: Batch #93 - Loss: 0.837425172328949\n",
      "Ep 5: Batch #94 - Loss: 0.8407605886459351\n",
      "Ep 5: Batch #95 - Loss: 0.7823651432991028\n",
      "Ep 5: Batch #96 - Loss: 0.7823321223258972\n",
      "Ep 5: Batch #97 - Loss: 0.6091436743736267\n",
      "Ep 5: Batch #98 - Loss: 0.6217408180236816\n",
      "Ep 5: Batch #99 - Loss: 0.8215584754943848\n",
      "Ep 5: Batch #100 - Loss: 0.5794957876205444\n",
      "Ep 5: Batch #101 - Loss: 0.891142725944519\n",
      "Ep 5: Batch #102 - Loss: 0.6586192846298218\n",
      "Ep 5: Batch #103 - Loss: 0.6688398718833923\n",
      "Ep 5: Batch #104 - Loss: 0.6859480738639832\n",
      "Ep 5: Batch #105 - Loss: 0.8463001847267151\n",
      "Ep 5: Batch #106 - Loss: 0.6501368880271912\n",
      "Ep 5: Batch #107 - Loss: 0.6280979514122009\n",
      "Ep 5: Batch #108 - Loss: 0.9162793755531311\n",
      "Ep 5: Batch #109 - Loss: 0.6581428050994873\n",
      "Ep 5: Batch #110 - Loss: 0.7519509792327881\n",
      "Ep 5: Batch #111 - Loss: 1.1332069635391235\n",
      "Ep 5: Batch #112 - Loss: 0.879149317741394\n",
      "Ep 5: Batch #113 - Loss: 0.6831656098365784\n",
      "Ep 5: Batch #114 - Loss: 0.7639093995094299\n",
      "Ep 5: Batch #115 - Loss: 0.9441277384757996\n",
      "Ep 5: Batch #116 - Loss: 0.5429175496101379\n",
      "Ep 5: Batch #117 - Loss: 0.7403088808059692\n",
      "Ep 5: Batch #118 - Loss: 0.4723226726055145\n",
      "Model saved in file: ./weights_autoencoder_sigmoid/model_e5b118_1516648792.4079175.ckpt\n",
      "Ep 5: Batch #119 - Loss: 0.8402425050735474\n",
      "Ep 5: Batch #120 - Loss: 0.6824274063110352\n",
      "Ep 5: Batch #121 - Loss: 0.581655740737915\n",
      "Ep 5: Batch #122 - Loss: 0.7311449646949768\n",
      "Ep 5: Batch #123 - Loss: 0.74196857213974\n",
      "Ep 5: Batch #124 - Loss: 0.5744480490684509\n",
      "Ep 5: Batch #125 - Loss: 2.516937732696533\n",
      "Ep 5: Batch #126 - Loss: 1.029754877090454\n",
      "Ep 5: Batch #127 - Loss: 0.6091983914375305\n",
      "Ep 5: Batch #128 - Loss: 0.9207423329353333\n",
      "Ep 5: Batch #129 - Loss: 0.7016881704330444\n",
      "Ep 5: Batch #130 - Loss: 0.6201173663139343\n",
      "Ep 5: Batch #131 - Loss: 0.8258405327796936\n",
      "Ep 5: Batch #132 - Loss: 0.7063478827476501\n",
      "Ep 5: Batch #133 - Loss: 0.6924070119857788\n",
      "Ep 5: Batch #134 - Loss: 0.6701620221138\n",
      "Ep 5: Batch #135 - Loss: 0.8418790698051453\n",
      "Ep 5: Batch #136 - Loss: 1.0649960041046143\n",
      "Ep 5: Batch #137 - Loss: 0.7861520051956177\n",
      "Ep 5: Batch #138 - Loss: 0.9353007674217224\n",
      "Ep 5: Batch #139 - Loss: 0.718457043170929\n",
      "Ep 5: Batch #140 - Loss: 0.9032762050628662\n",
      "Ep 5: Batch #141 - Loss: 1.1770710945129395\n",
      "Ep 5: Batch #142 - Loss: 0.6943685412406921\n",
      "Ep 5: Batch #143 - Loss: 0.8038032650947571\n",
      "Ep 5: Batch #144 - Loss: 0.6301066279411316\n",
      "Ep 5: Batch #145 - Loss: 0.6066303253173828\n",
      "Ep 5: Batch #146 - Loss: 0.7520768642425537\n",
      "Ep 5: Batch #147 - Loss: 0.7314735651016235\n",
      "Ep 5: Batch #148 - Loss: 0.7985484600067139\n",
      "Ep 5: Batch #149 - Loss: 0.706933856010437\n",
      "Ep 5: Batch #150 - Loss: 0.7582473754882812\n",
      "Ep 5: Batch #151 - Loss: 0.6563283801078796\n",
      "Ep 5: Batch #152 - Loss: 0.6416409015655518\n",
      "Ep 5: Batch #153 - Loss: 0.895253598690033\n",
      "Ep 5: Batch #154 - Loss: 0.6545625329017639\n",
      "Ep 5: Batch #155 - Loss: 0.7286523580551147\n",
      "Ep 5: Batch #156 - Loss: 0.8538112044334412\n",
      "Ep 5: Batch #157 - Loss: 0.6477607488632202\n",
      "Ep 5: Batch #158 - Loss: 0.7415258288383484\n",
      "Ep 5: Batch #159 - Loss: 0.6698010563850403\n",
      "Ep 5: Batch #160 - Loss: 0.7587566375732422\n",
      "Ep 5: Batch #161 - Loss: 0.7065549492835999\n",
      "Ep 5: Batch #162 - Loss: 0.7714405655860901\n",
      "Ep 5: Batch #163 - Loss: 0.811149537563324\n",
      "Ep 5: Batch #164 - Loss: 0.677534818649292\n",
      "Ep 5: Batch #165 - Loss: 1.3670908212661743\n",
      "Ep 5: Batch #166 - Loss: 0.5743215084075928\n",
      "Ep 5: Batch #167 - Loss: 0.8824408650398254\n",
      "Ep 5: Batch #168 - Loss: 0.7277682423591614\n",
      "Ep 5: Batch #169 - Loss: 0.7018131017684937\n",
      "Ep 5: Batch #170 - Loss: 0.6740585565567017\n",
      "Ep 5: Batch #171 - Loss: 0.6683499217033386\n",
      "Ep 5: Batch #172 - Loss: 0.5586510300636292\n",
      "Ep 5: Batch #173 - Loss: 1.0038875341415405\n",
      "Ep 5: Batch #174 - Loss: 0.5095435380935669\n",
      "Ep 5: Batch #175 - Loss: 0.680438756942749\n",
      "Ep 5: Batch #176 - Loss: 0.9577004313468933\n",
      "Ep 5: Batch #177 - Loss: 0.7042762637138367\n",
      "Ep 5: Batch #178 - Loss: 0.6630240082740784\n",
      "Ep 5: Batch #179 - Loss: 0.78178870677948\n",
      "Ep 5: Batch #180 - Loss: 0.6839264631271362\n",
      "Ep 5: Batch #181 - Loss: 0.8418530821800232\n",
      "Ep 5: Batch #182 - Loss: 0.6514698266983032\n",
      "Ep 5: Batch #183 - Loss: 0.6528264284133911\n",
      "Ep 5: Batch #184 - Loss: 0.9412582516670227\n",
      "Ep 5: Batch #185 - Loss: 0.658258855342865\n",
      "Ep 5: Batch #186 - Loss: 0.8035661578178406\n",
      "Ep 5: Batch #187 - Loss: 0.9504626989364624\n",
      "Ep 5: Batch #188 - Loss: 1.103000521659851\n",
      "Ep 5: Batch #189 - Loss: 0.6101166605949402\n",
      "Ep 5: Batch #190 - Loss: 0.646644115447998\n",
      "Ep 5: Batch #191 - Loss: 0.8735032677650452\n",
      "Ep 5: Batch #192 - Loss: 0.5902579426765442\n",
      "Ep 5: Batch #193 - Loss: 0.6459929347038269\n",
      "Ep 5: Batch #194 - Loss: 0.5970001816749573\n",
      "Ep 5: Batch #195 - Loss: 0.8153848648071289\n",
      "Ep 5: Batch #196 - Loss: 0.7208913564682007\n",
      "Ep 5: Batch #197 - Loss: 0.7490677833557129\n",
      "Ep 5: Batch #198 - Loss: 0.5654997229576111\n",
      "Ep 5: Batch #199 - Loss: 0.6883078813552856\n",
      "Ep 6: Batch #0 - Loss: 0.6704062819480896\n",
      "Ep 6: Batch #1 - Loss: 0.7426164150238037\n",
      "Ep 6: Batch #2 - Loss: 0.8857777714729309\n",
      "Ep 6: Batch #3 - Loss: 0.7440757155418396\n",
      "Ep 6: Batch #4 - Loss: 0.6719588041305542\n",
      "Ep 6: Batch #5 - Loss: 0.5867844223976135\n",
      "Ep 6: Batch #6 - Loss: 0.7625051736831665\n",
      "Ep 6: Batch #7 - Loss: 0.6163482666015625\n",
      "Ep 6: Batch #8 - Loss: 0.6137062311172485\n",
      "Ep 6: Batch #9 - Loss: 1.1531774997711182\n",
      "Ep 6: Batch #10 - Loss: 0.8773902058601379\n",
      "Ep 6: Batch #11 - Loss: 0.5670867562294006\n",
      "Ep 6: Batch #12 - Loss: 1.3530303239822388\n",
      "Ep 6: Batch #13 - Loss: 0.5977324843406677\n",
      "Ep 6: Batch #14 - Loss: 0.6184214353561401\n",
      "Ep 6: Batch #15 - Loss: 0.9876606464385986\n",
      "Ep 6: Batch #16 - Loss: 1.035813808441162\n",
      "Ep 6: Batch #17 - Loss: 0.7544019222259521\n",
      "Ep 6: Batch #18 - Loss: 0.8336710929870605\n",
      "Ep 6: Batch #19 - Loss: 0.5818061828613281\n",
      "Ep 6: Batch #20 - Loss: 0.5716020464897156\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 6: Batch #21 - Loss: 1.0125850439071655\n",
      "Ep 6: Batch #22 - Loss: 0.6376116871833801\n",
      "Ep 6: Batch #23 - Loss: 0.6306099891662598\n",
      "Ep 6: Batch #24 - Loss: 0.6927551627159119\n",
      "Ep 6: Batch #25 - Loss: 0.6460191011428833\n",
      "Ep 6: Batch #26 - Loss: 0.6180130839347839\n",
      "Ep 6: Batch #27 - Loss: 1.1722215414047241\n",
      "Ep 6: Batch #28 - Loss: 0.7263911366462708\n",
      "Ep 6: Batch #29 - Loss: 0.7803313732147217\n",
      "Ep 6: Batch #30 - Loss: 0.9815211296081543\n",
      "Ep 6: Batch #31 - Loss: 0.5810614824295044\n",
      "Ep 6: Batch #32 - Loss: 0.6148707866668701\n",
      "Ep 6: Batch #33 - Loss: 0.6992362141609192\n",
      "Ep 6: Batch #34 - Loss: 0.6748377680778503\n",
      "Ep 6: Batch #35 - Loss: 0.7808274030685425\n",
      "Ep 6: Batch #36 - Loss: 0.5978136658668518\n",
      "Ep 6: Batch #37 - Loss: 0.9548478722572327\n",
      "Ep 6: Batch #38 - Loss: 0.5984206199645996\n",
      "Ep 6: Batch #39 - Loss: 0.7151491641998291\n",
      "Ep 6: Batch #40 - Loss: 0.6382154226303101\n",
      "Ep 6: Batch #41 - Loss: 0.6411537528038025\n",
      "Ep 6: Batch #42 - Loss: 0.6026487946510315\n",
      "Ep 6: Batch #43 - Loss: 0.664962649345398\n",
      "Ep 6: Batch #44 - Loss: 0.6591680645942688\n",
      "Ep 6: Batch #45 - Loss: 0.5556156039237976\n",
      "Ep 6: Batch #46 - Loss: 0.7127982974052429\n",
      "Ep 6: Batch #47 - Loss: 0.8333267569541931\n",
      "Ep 6: Batch #48 - Loss: 1.1252304315567017\n",
      "Ep 6: Batch #49 - Loss: 0.8406071066856384\n",
      "Ep 6: Batch #50 - Loss: 0.5959048271179199\n",
      "Ep 6: Batch #51 - Loss: 0.8394403457641602\n",
      "Ep 6: Batch #52 - Loss: 0.697409987449646\n",
      "Ep 6: Batch #53 - Loss: 0.7326248288154602\n",
      "Ep 6: Batch #54 - Loss: 0.6113894581794739\n",
      "Ep 6: Batch #55 - Loss: 0.6413214802742004\n",
      "Ep 6: Batch #56 - Loss: 0.976218044757843\n",
      "Ep 6: Batch #57 - Loss: 0.7055805921554565\n",
      "Ep 6: Batch #58 - Loss: 0.8473281860351562\n",
      "Ep 6: Batch #59 - Loss: 0.586349606513977\n",
      "Ep 6: Batch #60 - Loss: 1.08194100856781\n",
      "Ep 6: Batch #61 - Loss: 0.5483110547065735\n",
      "Ep 6: Batch #62 - Loss: 0.6140168905258179\n",
      "Ep 6: Batch #63 - Loss: 0.8278874754905701\n",
      "Ep 6: Batch #64 - Loss: 8.987715721130371\n",
      "Ep 6: Batch #65 - Loss: 0.5406856536865234\n",
      "Ep 6: Batch #66 - Loss: 0.6996912956237793\n",
      "Ep 6: Batch #67 - Loss: 0.8004794716835022\n",
      "Ep 6: Batch #68 - Loss: 0.7580101490020752\n",
      "Ep 6: Batch #69 - Loss: 0.6386299729347229\n",
      "Ep 6: Batch #70 - Loss: 0.6370108723640442\n",
      "Ep 6: Batch #71 - Loss: 0.5604679584503174\n",
      "Ep 6: Batch #72 - Loss: 0.6988677382469177\n",
      "Ep 6: Batch #73 - Loss: 0.7785362005233765\n",
      "Ep 6: Batch #74 - Loss: 0.6079134941101074\n",
      "Ep 6: Batch #75 - Loss: 0.6852898001670837\n",
      "Ep 6: Batch #76 - Loss: 0.9759724736213684\n",
      "Ep 6: Batch #77 - Loss: 0.620686411857605\n",
      "Ep 6: Batch #78 - Loss: 0.9570997953414917\n",
      "Ep 6: Batch #79 - Loss: 0.5499041080474854\n",
      "Ep 6: Batch #80 - Loss: 0.7272478938102722\n",
      "Ep 6: Batch #81 - Loss: 1.5522089004516602\n",
      "Ep 6: Batch #82 - Loss: 0.7752075791358948\n",
      "Ep 6: Batch #83 - Loss: 1.527428150177002\n",
      "Ep 6: Batch #84 - Loss: 0.6090782284736633\n",
      "Ep 6: Batch #85 - Loss: 0.84743732213974\n",
      "Ep 6: Batch #86 - Loss: 0.5843297243118286\n",
      "Ep 6: Batch #87 - Loss: 0.588259220123291\n",
      "Ep 6: Batch #88 - Loss: 0.6750490665435791\n",
      "Ep 6: Batch #89 - Loss: 0.784100353717804\n",
      "Ep 6: Batch #90 - Loss: 0.9443202018737793\n",
      "Ep 6: Batch #91 - Loss: 0.6687777042388916\n",
      "Ep 6: Batch #92 - Loss: 0.8296375870704651\n",
      "Ep 6: Batch #93 - Loss: 0.8314985632896423\n",
      "Ep 6: Batch #94 - Loss: 0.8351732492446899\n",
      "Ep 6: Batch #95 - Loss: 0.7799615859985352\n",
      "Ep 6: Batch #96 - Loss: 0.7801244258880615\n",
      "Ep 6: Batch #97 - Loss: 0.6063166856765747\n",
      "Ep 6: Batch #98 - Loss: 0.6168155670166016\n",
      "Ep 6: Batch #99 - Loss: 0.8209260106086731\n",
      "Ep 6: Batch #100 - Loss: 0.5773895978927612\n",
      "Ep 6: Batch #101 - Loss: 0.8865417838096619\n",
      "Ep 6: Batch #102 - Loss: 0.6533454060554504\n",
      "Ep 6: Batch #103 - Loss: 0.6652966141700745\n",
      "Ep 6: Batch #104 - Loss: 0.6837119460105896\n",
      "Ep 6: Batch #105 - Loss: 0.843167781829834\n",
      "Ep 6: Batch #106 - Loss: 0.6481700539588928\n",
      "Ep 6: Batch #107 - Loss: 0.625399112701416\n",
      "Ep 6: Batch #108 - Loss: 0.9144174456596375\n",
      "Ep 6: Batch #109 - Loss: 0.6563383340835571\n",
      "Ep 6: Batch #110 - Loss: 0.7483052611351013\n",
      "Ep 6: Batch #111 - Loss: 1.1228455305099487\n",
      "Ep 6: Batch #112 - Loss: 0.8732861876487732\n",
      "Ep 6: Batch #113 - Loss: 0.6803745627403259\n",
      "Ep 6: Batch #114 - Loss: 0.7608376145362854\n",
      "Ep 6: Batch #115 - Loss: 0.9383689165115356\n",
      "Ep 6: Batch #116 - Loss: 0.5411626100540161\n",
      "Ep 6: Batch #117 - Loss: 0.7369565963745117\n",
      "Ep 6: Batch #118 - Loss: 0.4684966802597046\n",
      "Model saved in file: ./weights_autoencoder_sigmoid/model_e6b118_1516648792.549596.ckpt\n",
      "Ep 6: Batch #119 - Loss: 0.8351321220397949\n",
      "Ep 6: Batch #120 - Loss: 0.6803074479103088\n",
      "Ep 6: Batch #121 - Loss: 0.5796180963516235\n",
      "Ep 6: Batch #122 - Loss: 0.7293630242347717\n",
      "Ep 6: Batch #123 - Loss: 0.7401173710823059\n",
      "Ep 6: Batch #124 - Loss: 0.5723169445991516\n",
      "Ep 6: Batch #125 - Loss: 2.5097343921661377\n",
      "Ep 6: Batch #126 - Loss: 1.0244547128677368\n",
      "Ep 6: Batch #127 - Loss: 0.6061244606971741\n",
      "Ep 6: Batch #128 - Loss: 0.9166644215583801\n",
      "Ep 6: Batch #129 - Loss: 0.6990377902984619\n",
      "Ep 6: Batch #130 - Loss: 0.6183429956436157\n",
      "Ep 6: Batch #131 - Loss: 0.823283314704895\n",
      "Ep 6: Batch #132 - Loss: 0.706312358379364\n",
      "Ep 6: Batch #133 - Loss: 0.6892890930175781\n",
      "Ep 6: Batch #134 - Loss: 0.6679457426071167\n",
      "Ep 6: Batch #135 - Loss: 0.8398547172546387\n",
      "Ep 6: Batch #136 - Loss: 1.0630168914794922\n",
      "Ep 6: Batch #137 - Loss: 0.7815106511116028\n",
      "Ep 6: Batch #138 - Loss: 0.9322198033332825\n",
      "Ep 6: Batch #139 - Loss: 0.7138123512268066\n",
      "Ep 6: Batch #140 - Loss: 0.9010632038116455\n",
      "Ep 6: Batch #141 - Loss: 1.1724859476089478\n",
      "Ep 6: Batch #142 - Loss: 0.6921871304512024\n",
      "Ep 6: Batch #143 - Loss: 0.7992938756942749\n",
      "Ep 6: Batch #144 - Loss: 0.6280071139335632\n",
      "Ep 6: Batch #145 - Loss: 0.6043701171875\n",
      "Ep 6: Batch #146 - Loss: 0.7474396228790283\n",
      "Ep 6: Batch #147 - Loss: 0.728158712387085\n",
      "Ep 6: Batch #148 - Loss: 0.7951734066009521\n",
      "Ep 6: Batch #149 - Loss: 0.7030411958694458\n",
      "Ep 6: Batch #150 - Loss: 0.7559442520141602\n",
      "Ep 6: Batch #151 - Loss: 0.6533851027488708\n",
      "Ep 6: Batch #152 - Loss: 0.6371725797653198\n",
      "Ep 6: Batch #153 - Loss: 0.8905541300773621\n",
      "Ep 6: Batch #154 - Loss: 0.6524863243103027\n",
      "Ep 6: Batch #155 - Loss: 0.7247213125228882\n",
      "Ep 6: Batch #156 - Loss: 0.8500263094902039\n",
      "Ep 6: Batch #157 - Loss: 0.6451584696769714\n",
      "Ep 6: Batch #158 - Loss: 0.7367563843727112\n",
      "Ep 6: Batch #159 - Loss: 0.6651044487953186\n",
      "Ep 6: Batch #160 - Loss: 0.7549053430557251\n",
      "Ep 6: Batch #161 - Loss: 0.7031575441360474\n",
      "Ep 6: Batch #162 - Loss: 0.7647167444229126\n",
      "Ep 6: Batch #163 - Loss: 0.807807981967926\n",
      "Ep 6: Batch #164 - Loss: 0.6753060221672058\n",
      "Ep 6: Batch #165 - Loss: 1.364750862121582\n",
      "Ep 6: Batch #166 - Loss: 0.5706929564476013\n",
      "Ep 6: Batch #167 - Loss: 0.8753578662872314\n",
      "Ep 6: Batch #168 - Loss: 0.724818229675293\n",
      "Ep 6: Batch #169 - Loss: 0.6991300582885742\n",
      "Ep 6: Batch #170 - Loss: 0.6714141368865967\n",
      "Ep 6: Batch #171 - Loss: 0.6650932431221008\n",
      "Ep 6: Batch #172 - Loss: 0.5554389953613281\n",
      "Ep 6: Batch #173 - Loss: 1.0011495351791382\n",
      "Ep 6: Batch #174 - Loss: 0.5087132453918457\n",
      "Ep 6: Batch #175 - Loss: 0.6764813661575317\n",
      "Ep 6: Batch #176 - Loss: 0.9532009959220886\n",
      "Ep 6: Batch #177 - Loss: 0.7007877230644226\n",
      "Ep 6: Batch #178 - Loss: 0.6602669954299927\n",
      "Ep 6: Batch #179 - Loss: 0.7771221399307251\n",
      "Ep 6: Batch #180 - Loss: 0.6814084053039551\n",
      "Ep 6: Batch #181 - Loss: 0.8371297121047974\n",
      "Ep 6: Batch #182 - Loss: 0.6484225392341614\n",
      "Ep 6: Batch #183 - Loss: 0.6494736671447754\n",
      "Ep 6: Batch #184 - Loss: 0.9388954639434814\n",
      "Ep 6: Batch #185 - Loss: 0.6555247902870178\n",
      "Ep 6: Batch #186 - Loss: 0.7988067865371704\n",
      "Ep 6: Batch #187 - Loss: 0.9435285925865173\n",
      "Ep 6: Batch #188 - Loss: 1.0953298807144165\n",
      "Ep 6: Batch #189 - Loss: 0.6076577305793762\n",
      "Ep 6: Batch #190 - Loss: 0.6435028910636902\n",
      "Ep 6: Batch #191 - Loss: 0.8683922290802002\n",
      "Ep 6: Batch #192 - Loss: 0.588509738445282\n",
      "Ep 6: Batch #193 - Loss: 0.6443217396736145\n",
      "Ep 6: Batch #194 - Loss: 0.5938158631324768\n",
      "Ep 6: Batch #195 - Loss: 0.8119094967842102\n",
      "Ep 6: Batch #196 - Loss: 0.7188209295272827\n",
      "Ep 6: Batch #197 - Loss: 0.7462858557701111\n",
      "Ep 6: Batch #198 - Loss: 0.5618834495544434\n",
      "Ep 6: Batch #199 - Loss: 0.6845975518226624\n",
      "Ep 7: Batch #0 - Loss: 0.6684793829917908\n",
      "Ep 7: Batch #1 - Loss: 0.7392924427986145\n",
      "Ep 7: Batch #2 - Loss: 0.8823626637458801\n",
      "Ep 7: Batch #3 - Loss: 0.7411789894104004\n",
      "Ep 7: Batch #4 - Loss: 0.6704084873199463\n",
      "Ep 7: Batch #5 - Loss: 0.5855038166046143\n",
      "Ep 7: Batch #6 - Loss: 0.7595025897026062\n",
      "Ep 7: Batch #7 - Loss: 0.613150417804718\n",
      "Ep 7: Batch #8 - Loss: 0.6108143925666809\n",
      "Ep 7: Batch #9 - Loss: 1.1490168571472168\n",
      "Ep 7: Batch #10 - Loss: 0.8760645985603333\n",
      "Ep 7: Batch #11 - Loss: 0.562773585319519\n",
      "Ep 7: Batch #12 - Loss: 1.3416424989700317\n",
      "Ep 7: Batch #13 - Loss: 0.5949199199676514\n",
      "Ep 7: Batch #14 - Loss: 0.6154594421386719\n",
      "Ep 7: Batch #15 - Loss: 0.9797152280807495\n",
      "Ep 7: Batch #16 - Loss: 1.0319331884384155\n",
      "Ep 7: Batch #17 - Loss: 0.7518070936203003\n",
      "Ep 7: Batch #18 - Loss: 0.8310254812240601\n",
      "Ep 7: Batch #19 - Loss: 0.5798976421356201\n",
      "Ep 7: Batch #20 - Loss: 0.5692839622497559\n",
      "Ep 7: Batch #21 - Loss: 1.006136178970337\n",
      "Ep 7: Batch #22 - Loss: 0.6347629427909851\n",
      "Ep 7: Batch #23 - Loss: 0.628251850605011\n",
      "Ep 7: Batch #24 - Loss: 0.6897150874137878\n",
      "Ep 7: Batch #25 - Loss: 0.6424728035926819\n",
      "Ep 7: Batch #26 - Loss: 0.6154939532279968\n",
      "Ep 7: Batch #27 - Loss: 1.1672511100769043\n",
      "Ep 7: Batch #28 - Loss: 0.7239388823509216\n",
      "Ep 7: Batch #29 - Loss: 0.7784597277641296\n",
      "Ep 7: Batch #30 - Loss: 0.9728384613990784\n",
      "Ep 7: Batch #31 - Loss: 0.5781323313713074\n",
      "Ep 7: Batch #32 - Loss: 0.610978901386261\n",
      "Ep 7: Batch #33 - Loss: 0.6963117718696594\n",
      "Ep 7: Batch #34 - Loss: 0.671586275100708\n",
      "Ep 7: Batch #35 - Loss: 0.7774792313575745\n",
      "Ep 7: Batch #36 - Loss: 0.5966194272041321\n",
      "Ep 7: Batch #37 - Loss: 0.9495930075645447\n",
      "Ep 7: Batch #38 - Loss: 0.5950700640678406\n",
      "Ep 7: Batch #39 - Loss: 0.7104659080505371\n",
      "Ep 7: Batch #40 - Loss: 0.6345224976539612\n",
      "Ep 7: Batch #41 - Loss: 0.6390578746795654\n",
      "Ep 7: Batch #42 - Loss: 0.598118782043457\n",
      "Ep 7: Batch #43 - Loss: 0.6611124873161316\n",
      "Ep 7: Batch #44 - Loss: 0.6568822264671326\n",
      "Ep 7: Batch #45 - Loss: 0.55271315574646\n",
      "Ep 7: Batch #46 - Loss: 0.7115858197212219\n",
      "Ep 7: Batch #47 - Loss: 0.8305913805961609\n",
      "Ep 7: Batch #48 - Loss: 1.1169648170471191\n",
      "Ep 7: Batch #49 - Loss: 0.8372447490692139\n",
      "Ep 7: Batch #50 - Loss: 0.5928030610084534\n",
      "Ep 7: Batch #51 - Loss: 0.8385609984397888\n",
      "Ep 7: Batch #52 - Loss: 0.6954777240753174\n",
      "Ep 7: Batch #53 - Loss: 0.7300844192504883\n",
      "Ep 7: Batch #54 - Loss: 0.6094251871109009\n",
      "Ep 7: Batch #55 - Loss: 0.6388232707977295\n",
      "Ep 7: Batch #56 - Loss: 0.9650886654853821\n",
      "Ep 7: Batch #57 - Loss: 0.702269971370697\n",
      "Ep 7: Batch #58 - Loss: 0.8454768061637878\n",
      "Ep 7: Batch #59 - Loss: 0.5842862725257874\n",
      "Ep 7: Batch #60 - Loss: 1.0745114088058472\n",
      "Ep 7: Batch #61 - Loss: 0.5457413196563721\n",
      "Ep 7: Batch #62 - Loss: 0.6107756495475769\n",
      "Ep 7: Batch #63 - Loss: 0.8234790563583374\n",
      "Ep 7: Batch #64 - Loss: 8.963318824768066\n",
      "Ep 7: Batch #65 - Loss: 0.5388578176498413\n",
      "Ep 7: Batch #66 - Loss: 0.6964436769485474\n",
      "Ep 7: Batch #67 - Loss: 0.7967669367790222\n",
      "Ep 7: Batch #68 - Loss: 0.7550567984580994\n",
      "Ep 7: Batch #69 - Loss: 0.6357914805412292\n",
      "Ep 7: Batch #70 - Loss: 0.6351804137229919\n",
      "Ep 7: Batch #71 - Loss: 0.5596210360527039\n",
      "Ep 7: Batch #72 - Loss: 0.6949129700660706\n",
      "Ep 7: Batch #73 - Loss: 0.7759174108505249\n",
      "Ep 7: Batch #74 - Loss: 0.6058518290519714\n",
      "Ep 7: Batch #75 - Loss: 0.6827917695045471\n",
      "Ep 7: Batch #76 - Loss: 0.973263144493103\n",
      "Ep 7: Batch #77 - Loss: 0.617642879486084\n",
      "Ep 7: Batch #78 - Loss: 0.9550699591636658\n",
      "Ep 7: Batch #79 - Loss: 0.5475896000862122\n",
      "Ep 7: Batch #80 - Loss: 0.7245368957519531\n",
      "Ep 7: Batch #81 - Loss: 1.5500115156173706\n",
      "Ep 7: Batch #82 - Loss: 0.7705244421958923\n",
      "Ep 7: Batch #83 - Loss: 1.5169717073440552\n",
      "Ep 7: Batch #84 - Loss: 0.6062270402908325\n",
      "Ep 7: Batch #85 - Loss: 0.8430851697921753\n",
      "Ep 7: Batch #86 - Loss: 0.5813804864883423\n",
      "Ep 7: Batch #87 - Loss: 0.5860244631767273\n",
      "Ep 7: Batch #88 - Loss: 0.6726266145706177\n",
      "Ep 7: Batch #89 - Loss: 0.783241868019104\n",
      "Ep 7: Batch #90 - Loss: 0.94084632396698\n",
      "Ep 7: Batch #91 - Loss: 0.6659052968025208\n",
      "Ep 7: Batch #92 - Loss: 0.8274374604225159\n",
      "Ep 7: Batch #93 - Loss: 0.8265131115913391\n",
      "Ep 7: Batch #94 - Loss: 0.8301305770874023\n",
      "Ep 7: Batch #95 - Loss: 0.777101993560791\n",
      "Ep 7: Batch #96 - Loss: 0.7780911326408386\n",
      "Ep 7: Batch #97 - Loss: 0.6033156514167786\n",
      "Ep 7: Batch #98 - Loss: 0.611829400062561\n",
      "Ep 7: Batch #99 - Loss: 0.8202294111251831\n",
      "Ep 7: Batch #100 - Loss: 0.5752854347229004\n",
      "Ep 7: Batch #101 - Loss: 0.8829777240753174\n",
      "Ep 7: Batch #102 - Loss: 0.6490449905395508\n",
      "Ep 7: Batch #103 - Loss: 0.6617742776870728\n",
      "Ep 7: Batch #104 - Loss: 0.6815101504325867\n",
      "Ep 7: Batch #105 - Loss: 0.840278685092926\n",
      "Ep 7: Batch #106 - Loss: 0.6457342505455017\n",
      "Ep 7: Batch #107 - Loss: 0.6228581070899963\n",
      "Ep 7: Batch #108 - Loss: 0.9123684763908386\n",
      "Ep 7: Batch #109 - Loss: 0.6542969942092896\n",
      "Ep 7: Batch #110 - Loss: 0.7451125979423523\n",
      "Ep 7: Batch #111 - Loss: 1.1154813766479492\n",
      "Ep 7: Batch #112 - Loss: 0.8677809834480286\n",
      "Ep 7: Batch #113 - Loss: 0.6773059368133545\n",
      "Ep 7: Batch #114 - Loss: 0.7585172057151794\n",
      "Ep 7: Batch #115 - Loss: 0.9327579736709595\n",
      "Ep 7: Batch #116 - Loss: 0.5388496518135071\n",
      "Ep 7: Batch #117 - Loss: 0.7337701320648193\n",
      "Ep 7: Batch #118 - Loss: 0.4656412899494171\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved in file: ./weights_autoencoder_sigmoid/model_e7b118_1516648792.686956.ckpt\n",
      "Ep 7: Batch #119 - Loss: 0.8321343660354614\n",
      "Ep 7: Batch #120 - Loss: 0.678157389163971\n",
      "Ep 7: Batch #121 - Loss: 0.5778576135635376\n",
      "Ep 7: Batch #122 - Loss: 0.7282341718673706\n",
      "Ep 7: Batch #123 - Loss: 0.7378814816474915\n",
      "Ep 7: Batch #124 - Loss: 0.5697720646858215\n",
      "Ep 7: Batch #125 - Loss: 2.5036211013793945\n",
      "Ep 7: Batch #126 - Loss: 1.0200450420379639\n",
      "Ep 7: Batch #127 - Loss: 0.6024447679519653\n",
      "Ep 7: Batch #128 - Loss: 0.9133450388908386\n",
      "Ep 7: Batch #129 - Loss: 0.6961909532546997\n",
      "Ep 7: Batch #130 - Loss: 0.6162388920783997\n",
      "Ep 7: Batch #131 - Loss: 0.8200004696846008\n",
      "Ep 7: Batch #132 - Loss: 0.7053666710853577\n",
      "Ep 7: Batch #133 - Loss: 0.6864590048789978\n",
      "Ep 7: Batch #134 - Loss: 0.6671898365020752\n",
      "Ep 7: Batch #135 - Loss: 0.8388708233833313\n",
      "Ep 7: Batch #136 - Loss: 1.0614169836044312\n",
      "Ep 7: Batch #137 - Loss: 0.7771319150924683\n",
      "Ep 7: Batch #138 - Loss: 0.9289332032203674\n",
      "Ep 7: Batch #139 - Loss: 0.7112439870834351\n",
      "Ep 7: Batch #140 - Loss: 0.8984575271606445\n",
      "Ep 7: Batch #141 - Loss: 1.1680679321289062\n",
      "Ep 7: Batch #142 - Loss: 0.6897847056388855\n",
      "Ep 7: Batch #143 - Loss: 0.7959336638450623\n",
      "Ep 7: Batch #144 - Loss: 0.6255792379379272\n",
      "Ep 7: Batch #145 - Loss: 0.6027755737304688\n",
      "Ep 7: Batch #146 - Loss: 0.7445873022079468\n",
      "Ep 7: Batch #147 - Loss: 0.7263707518577576\n",
      "Ep 7: Batch #148 - Loss: 0.7927371263504028\n",
      "Ep 7: Batch #149 - Loss: 0.7001875042915344\n",
      "Ep 7: Batch #150 - Loss: 0.7535291910171509\n",
      "Ep 7: Batch #151 - Loss: 0.650419294834137\n",
      "Ep 7: Batch #152 - Loss: 0.6330015659332275\n",
      "Ep 7: Batch #153 - Loss: 0.8867364525794983\n",
      "Ep 7: Batch #154 - Loss: 0.6508582830429077\n",
      "Ep 7: Batch #155 - Loss: 0.7225565314292908\n",
      "Ep 7: Batch #156 - Loss: 0.847251296043396\n",
      "Ep 7: Batch #157 - Loss: 0.6433643102645874\n",
      "Ep 7: Batch #158 - Loss: 0.7340357899665833\n",
      "Ep 7: Batch #159 - Loss: 0.6610901951789856\n",
      "Ep 7: Batch #160 - Loss: 0.7514327168464661\n",
      "Ep 7: Batch #161 - Loss: 0.700545072555542\n",
      "Ep 7: Batch #162 - Loss: 0.7595080733299255\n",
      "Ep 7: Batch #163 - Loss: 0.8053640127182007\n",
      "Ep 7: Batch #164 - Loss: 0.6734263300895691\n",
      "Ep 7: Batch #165 - Loss: 1.3628290891647339\n",
      "Ep 7: Batch #166 - Loss: 0.5671398639678955\n",
      "Ep 7: Batch #167 - Loss: 0.8697956800460815\n",
      "Ep 7: Batch #168 - Loss: 0.7217571139335632\n",
      "Ep 7: Batch #169 - Loss: 0.6968644261360168\n",
      "Ep 7: Batch #170 - Loss: 0.6688644886016846\n",
      "Ep 7: Batch #171 - Loss: 0.6625645756721497\n",
      "Ep 7: Batch #172 - Loss: 0.552886426448822\n",
      "Ep 7: Batch #173 - Loss: 0.9988256692886353\n",
      "Ep 7: Batch #174 - Loss: 0.5077613592147827\n",
      "Ep 7: Batch #175 - Loss: 0.6724552512168884\n",
      "Ep 7: Batch #176 - Loss: 0.9496347904205322\n",
      "Ep 7: Batch #177 - Loss: 0.6974254250526428\n",
      "Ep 7: Batch #178 - Loss: 0.658199667930603\n",
      "Ep 7: Batch #179 - Loss: 0.7733744978904724\n",
      "Ep 7: Batch #180 - Loss: 0.679358720779419\n",
      "Ep 7: Batch #181 - Loss: 0.8336524963378906\n",
      "Ep 7: Batch #182 - Loss: 0.6458935737609863\n",
      "Ep 7: Batch #183 - Loss: 0.6465038061141968\n",
      "Ep 7: Batch #184 - Loss: 0.9366796612739563\n",
      "Ep 7: Batch #185 - Loss: 0.6532031297683716\n",
      "Ep 7: Batch #186 - Loss: 0.795624852180481\n",
      "Ep 7: Batch #187 - Loss: 0.9373514652252197\n",
      "Ep 7: Batch #188 - Loss: 1.0883272886276245\n",
      "Ep 7: Batch #189 - Loss: 0.6057521104812622\n",
      "Ep 7: Batch #190 - Loss: 0.6407575607299805\n",
      "Ep 7: Batch #191 - Loss: 0.863908588886261\n",
      "Ep 7: Batch #192 - Loss: 0.586691677570343\n",
      "Ep 7: Batch #193 - Loss: 0.6428420543670654\n",
      "Ep 7: Batch #194 - Loss: 0.5907639861106873\n",
      "Ep 7: Batch #195 - Loss: 0.8092636466026306\n",
      "Ep 7: Batch #196 - Loss: 0.7168235182762146\n",
      "Ep 7: Batch #197 - Loss: 0.7431309819221497\n",
      "Ep 7: Batch #198 - Loss: 0.5582937598228455\n",
      "Ep 7: Batch #199 - Loss: 0.6815908551216125\n",
      "Ep 8: Batch #0 - Loss: 0.6670319437980652\n",
      "Ep 8: Batch #1 - Loss: 0.7359374165534973\n",
      "Ep 8: Batch #2 - Loss: 0.8801853060722351\n",
      "Ep 8: Batch #3 - Loss: 0.7388752698898315\n",
      "Ep 8: Batch #4 - Loss: 0.668794572353363\n",
      "Ep 8: Batch #5 - Loss: 0.5847550630569458\n",
      "Ep 8: Batch #6 - Loss: 0.7569891810417175\n",
      "Ep 8: Batch #7 - Loss: 0.6103833913803101\n",
      "Ep 8: Batch #8 - Loss: 0.6086266040802002\n",
      "Ep 8: Batch #9 - Loss: 1.1448606252670288\n",
      "Ep 8: Batch #10 - Loss: 0.8744754791259766\n",
      "Ep 8: Batch #11 - Loss: 0.5594347715377808\n",
      "Ep 8: Batch #12 - Loss: 1.3315722942352295\n",
      "Ep 8: Batch #13 - Loss: 0.5924307703971863\n",
      "Ep 8: Batch #14 - Loss: 0.6128971576690674\n",
      "Ep 8: Batch #15 - Loss: 0.9730158448219299\n",
      "Ep 8: Batch #16 - Loss: 1.0287925004959106\n",
      "Ep 8: Batch #17 - Loss: 0.7501107454299927\n",
      "Ep 8: Batch #18 - Loss: 0.8280735015869141\n",
      "Ep 8: Batch #19 - Loss: 0.5784198641777039\n",
      "Ep 8: Batch #20 - Loss: 0.566955029964447\n",
      "Ep 8: Batch #21 - Loss: 0.9999367594718933\n",
      "Ep 8: Batch #22 - Loss: 0.6320809125900269\n",
      "Ep 8: Batch #23 - Loss: 0.625511646270752\n",
      "Ep 8: Batch #24 - Loss: 0.6863964796066284\n",
      "Ep 8: Batch #25 - Loss: 0.6394041180610657\n",
      "Ep 8: Batch #26 - Loss: 0.6137228012084961\n",
      "Ep 8: Batch #27 - Loss: 1.1630851030349731\n",
      "Ep 8: Batch #28 - Loss: 0.7209968566894531\n",
      "Ep 8: Batch #29 - Loss: 0.7770112752914429\n",
      "Ep 8: Batch #30 - Loss: 0.9646317958831787\n",
      "Ep 8: Batch #31 - Loss: 0.5749881267547607\n",
      "Ep 8: Batch #32 - Loss: 0.6074619889259338\n",
      "Ep 8: Batch #33 - Loss: 0.6934704184532166\n",
      "Ep 8: Batch #34 - Loss: 0.6683962345123291\n",
      "Ep 8: Batch #35 - Loss: 0.7746207118034363\n",
      "Ep 8: Batch #36 - Loss: 0.595012903213501\n",
      "Ep 8: Batch #37 - Loss: 0.9461432099342346\n",
      "Ep 8: Batch #38 - Loss: 0.592441737651825\n",
      "Ep 8: Batch #39 - Loss: 0.7066743969917297\n",
      "Ep 8: Batch #40 - Loss: 0.6314442753791809\n",
      "Ep 8: Batch #41 - Loss: 0.6371192932128906\n",
      "Ep 8: Batch #42 - Loss: 0.5945563912391663\n",
      "Ep 8: Batch #43 - Loss: 0.6581372022628784\n",
      "Ep 8: Batch #44 - Loss: 0.6546748280525208\n",
      "Ep 8: Batch #45 - Loss: 0.5496810674667358\n",
      "Ep 8: Batch #46 - Loss: 0.7112022638320923\n",
      "Ep 8: Batch #47 - Loss: 0.8274878859519958\n",
      "Ep 8: Batch #48 - Loss: 1.110695719718933\n",
      "Ep 8: Batch #49 - Loss: 0.8346466422080994\n",
      "Ep 8: Batch #50 - Loss: 0.5899253487586975\n",
      "Ep 8: Batch #51 - Loss: 0.837270200252533\n",
      "Ep 8: Batch #52 - Loss: 0.6938011050224304\n",
      "Ep 8: Batch #53 - Loss: 0.7276265621185303\n",
      "Ep 8: Batch #54 - Loss: 0.6073792576789856\n",
      "Ep 8: Batch #55 - Loss: 0.6368192434310913\n",
      "Ep 8: Batch #56 - Loss: 0.9564070105552673\n",
      "Ep 8: Batch #57 - Loss: 0.6997814774513245\n",
      "Ep 8: Batch #58 - Loss: 0.8435823917388916\n",
      "Ep 8: Batch #59 - Loss: 0.5826969146728516\n",
      "Ep 8: Batch #60 - Loss: 1.0689195394515991\n",
      "Ep 8: Batch #61 - Loss: 0.5439388751983643\n",
      "Ep 8: Batch #62 - Loss: 0.6078711748123169\n",
      "Ep 8: Batch #63 - Loss: 0.8197914361953735\n",
      "Ep 8: Batch #64 - Loss: 8.940278053283691\n",
      "Ep 8: Batch #65 - Loss: 0.5368605256080627\n",
      "Ep 8: Batch #66 - Loss: 0.6940711736679077\n",
      "Ep 8: Batch #67 - Loss: 0.7944997549057007\n",
      "Ep 8: Batch #68 - Loss: 0.7530224323272705\n",
      "Ep 8: Batch #69 - Loss: 0.6330956816673279\n",
      "Ep 8: Batch #70 - Loss: 0.6337860226631165\n",
      "Ep 8: Batch #71 - Loss: 0.5581865906715393\n",
      "Ep 8: Batch #72 - Loss: 0.6909403204917908\n",
      "Ep 8: Batch #73 - Loss: 0.7734345197677612\n",
      "Ep 8: Batch #74 - Loss: 0.6046255230903625\n",
      "Ep 8: Batch #75 - Loss: 0.680425763130188\n",
      "Ep 8: Batch #76 - Loss: 0.9706484079360962\n",
      "Ep 8: Batch #77 - Loss: 0.6150223016738892\n",
      "Ep 8: Batch #78 - Loss: 0.9530444145202637\n",
      "Ep 8: Batch #79 - Loss: 0.5454718470573425\n",
      "Ep 8: Batch #80 - Loss: 0.7221764922142029\n",
      "Ep 8: Batch #81 - Loss: 1.547510027885437\n",
      "Ep 8: Batch #82 - Loss: 0.7666543126106262\n",
      "Ep 8: Batch #83 - Loss: 1.507074236869812\n",
      "Ep 8: Batch #84 - Loss: 0.6043649911880493\n",
      "Ep 8: Batch #85 - Loss: 0.8388892412185669\n",
      "Ep 8: Batch #86 - Loss: 0.5786378383636475\n",
      "Ep 8: Batch #87 - Loss: 0.5846327543258667\n",
      "Ep 8: Batch #88 - Loss: 0.6706146001815796\n",
      "Ep 8: Batch #89 - Loss: 0.7820633053779602\n",
      "Ep 8: Batch #90 - Loss: 0.9376562237739563\n",
      "Ep 8: Batch #91 - Loss: 0.6634700298309326\n",
      "Ep 8: Batch #92 - Loss: 0.8248599171638489\n",
      "Ep 8: Batch #93 - Loss: 0.8224194049835205\n",
      "Ep 8: Batch #94 - Loss: 0.826593816280365\n",
      "Ep 8: Batch #95 - Loss: 0.7743959426879883\n",
      "Ep 8: Batch #96 - Loss: 0.776853084564209\n",
      "Ep 8: Batch #97 - Loss: 0.6013056635856628\n",
      "Ep 8: Batch #98 - Loss: 0.607376217842102\n",
      "Ep 8: Batch #99 - Loss: 0.819473922252655\n",
      "Ep 8: Batch #100 - Loss: 0.5734535455703735\n",
      "Ep 8: Batch #101 - Loss: 0.880262553691864\n",
      "Ep 8: Batch #102 - Loss: 0.6456931233406067\n",
      "Ep 8: Batch #103 - Loss: 0.6589614748954773\n",
      "Ep 8: Batch #104 - Loss: 0.679535448551178\n",
      "Ep 8: Batch #105 - Loss: 0.8381134271621704\n",
      "Ep 8: Batch #106 - Loss: 0.6442381739616394\n",
      "Ep 8: Batch #107 - Loss: 0.620952844619751\n",
      "Ep 8: Batch #108 - Loss: 0.9107991456985474\n",
      "Ep 8: Batch #109 - Loss: 0.6526488065719604\n",
      "Ep 8: Batch #110 - Loss: 0.7441973090171814\n",
      "Ep 8: Batch #111 - Loss: 1.1096700429916382\n",
      "Ep 8: Batch #112 - Loss: 0.863585352897644\n",
      "Ep 8: Batch #113 - Loss: 0.6748388409614563\n",
      "Ep 8: Batch #114 - Loss: 0.757546603679657\n",
      "Ep 8: Batch #115 - Loss: 0.9284650087356567\n",
      "Ep 8: Batch #116 - Loss: 0.5375403761863708\n",
      "Ep 8: Batch #117 - Loss: 0.7313057780265808\n",
      "Ep 8: Batch #118 - Loss: 0.46386852860450745\n",
      "Model saved in file: ./weights_autoencoder_sigmoid/model_e8b118_1516648792.825575.ckpt\n",
      "Ep 8: Batch #119 - Loss: 0.8294765949249268\n",
      "Ep 8: Batch #120 - Loss: 0.6766354441642761\n",
      "Ep 8: Batch #121 - Loss: 0.5762925148010254\n",
      "Ep 8: Batch #122 - Loss: 0.7272311449050903\n",
      "Ep 8: Batch #123 - Loss: 0.7371217608451843\n",
      "Ep 8: Batch #124 - Loss: 0.567939281463623\n",
      "Ep 8: Batch #125 - Loss: 2.4986629486083984\n",
      "Ep 8: Batch #126 - Loss: 1.0160269737243652\n",
      "Ep 8: Batch #127 - Loss: 0.599765419960022\n",
      "Ep 8: Batch #128 - Loss: 0.9099027514457703\n",
      "Ep 8: Batch #129 - Loss: 0.6937410235404968\n",
      "Ep 8: Batch #130 - Loss: 0.6148000359535217\n",
      "Ep 8: Batch #131 - Loss: 0.8177056908607483\n",
      "Ep 8: Batch #132 - Loss: 0.7039374113082886\n",
      "Ep 8: Batch #133 - Loss: 0.6835824251174927\n",
      "Ep 8: Batch #134 - Loss: 0.6652611494064331\n",
      "Ep 8: Batch #135 - Loss: 0.8364753127098083\n",
      "Ep 8: Batch #136 - Loss: 1.0595383644104004\n",
      "Ep 8: Batch #137 - Loss: 0.7741771936416626\n",
      "Ep 8: Batch #138 - Loss: 0.9263138175010681\n",
      "Ep 8: Batch #139 - Loss: 0.7109189033508301\n",
      "Ep 8: Batch #140 - Loss: 0.8961541056632996\n",
      "Ep 8: Batch #141 - Loss: 1.1639918088912964\n",
      "Ep 8: Batch #142 - Loss: 0.6881910562515259\n",
      "Ep 8: Batch #143 - Loss: 0.7935477495193481\n",
      "Ep 8: Batch #144 - Loss: 0.6240173578262329\n",
      "Ep 8: Batch #145 - Loss: 0.6019898653030396\n",
      "Ep 8: Batch #146 - Loss: 0.742385983467102\n",
      "Ep 8: Batch #147 - Loss: 0.7251099944114685\n",
      "Ep 8: Batch #148 - Loss: 0.7914124131202698\n",
      "Ep 8: Batch #149 - Loss: 0.6982768177986145\n",
      "Ep 8: Batch #150 - Loss: 0.7515853643417358\n",
      "Ep 8: Batch #151 - Loss: 0.6486296653747559\n",
      "Ep 8: Batch #152 - Loss: 0.6300565004348755\n",
      "Ep 8: Batch #153 - Loss: 0.8839260339736938\n",
      "Ep 8: Batch #154 - Loss: 0.6494191288948059\n",
      "Ep 8: Batch #155 - Loss: 0.720596194267273\n",
      "Ep 8: Batch #156 - Loss: 0.8446306586265564\n",
      "Ep 8: Batch #157 - Loss: 0.6420180201530457\n",
      "Ep 8: Batch #158 - Loss: 0.7327790856361389\n",
      "Ep 8: Batch #159 - Loss: 0.6581699848175049\n",
      "Ep 8: Batch #160 - Loss: 0.7487264275550842\n",
      "Ep 8: Batch #161 - Loss: 0.6984605193138123\n",
      "Ep 8: Batch #162 - Loss: 0.7553972601890564\n",
      "Ep 8: Batch #163 - Loss: 0.8033196330070496\n",
      "Ep 8: Batch #164 - Loss: 0.6720499992370605\n",
      "Ep 8: Batch #165 - Loss: 1.3611674308776855\n",
      "Ep 8: Batch #166 - Loss: 0.5641226172447205\n",
      "Ep 8: Batch #167 - Loss: 0.8658638000488281\n",
      "Ep 8: Batch #168 - Loss: 0.7193807363510132\n",
      "Ep 8: Batch #169 - Loss: 0.6948056221008301\n",
      "Ep 8: Batch #170 - Loss: 0.6674540638923645\n",
      "Ep 8: Batch #171 - Loss: 0.660972535610199\n",
      "Ep 8: Batch #172 - Loss: 0.5510010719299316\n",
      "Ep 8: Batch #173 - Loss: 0.9971762895584106\n",
      "Ep 8: Batch #174 - Loss: 0.5073930621147156\n",
      "Ep 8: Batch #175 - Loss: 0.669285774230957\n",
      "Ep 8: Batch #176 - Loss: 0.9467795491218567\n",
      "Ep 8: Batch #177 - Loss: 0.6951291561126709\n",
      "Ep 8: Batch #178 - Loss: 0.6567297577857971\n",
      "Ep 8: Batch #179 - Loss: 0.7700948715209961\n",
      "Ep 8: Batch #180 - Loss: 0.6779916882514954\n",
      "Ep 8: Batch #181 - Loss: 0.8313523530960083\n",
      "Ep 8: Batch #182 - Loss: 0.6439903378486633\n",
      "Ep 8: Batch #183 - Loss: 0.6446239352226257\n",
      "Ep 8: Batch #184 - Loss: 0.9352095127105713\n",
      "Ep 8: Batch #185 - Loss: 0.6518360376358032\n",
      "Ep 8: Batch #186 - Loss: 0.7936813235282898\n",
      "Ep 8: Batch #187 - Loss: 0.9316396713256836\n",
      "Ep 8: Batch #188 - Loss: 1.0816045999526978\n",
      "Ep 8: Batch #189 - Loss: 0.6043091416358948\n",
      "Ep 8: Batch #190 - Loss: 0.6387149691581726\n",
      "Ep 8: Batch #191 - Loss: 0.8601508736610413\n",
      "Ep 8: Batch #192 - Loss: 0.5852311253547668\n",
      "Ep 8: Batch #193 - Loss: 0.6414784789085388\n",
      "Ep 8: Batch #194 - Loss: 0.5883166790008545\n",
      "Ep 8: Batch #195 - Loss: 0.8073599934577942\n",
      "Ep 8: Batch #196 - Loss: 0.715212881565094\n",
      "Ep 8: Batch #197 - Loss: 0.7404073476791382\n",
      "Ep 8: Batch #198 - Loss: 0.5557515025138855\n",
      "Ep 8: Batch #199 - Loss: 0.6793209910392761\n",
      "Ep 9: Batch #0 - Loss: 0.6661708354949951\n",
      "Ep 9: Batch #1 - Loss: 0.7336291670799255\n",
      "Ep 9: Batch #2 - Loss: 0.8787005543708801\n",
      "Ep 9: Batch #3 - Loss: 0.7369871735572815\n",
      "Ep 9: Batch #4 - Loss: 0.667316734790802\n",
      "Ep 9: Batch #5 - Loss: 0.5837981700897217\n",
      "Ep 9: Batch #6 - Loss: 0.7554378509521484\n",
      "Ep 9: Batch #7 - Loss: 0.6084210872650146\n",
      "Ep 9: Batch #8 - Loss: 0.6071722507476807\n",
      "Ep 9: Batch #9 - Loss: 1.1412131786346436\n",
      "Ep 9: Batch #10 - Loss: 0.8726784586906433\n",
      "Ep 9: Batch #11 - Loss: 0.5572313666343689\n",
      "Ep 9: Batch #12 - Loss: 1.322035312652588\n",
      "Ep 9: Batch #13 - Loss: 0.5904480218887329\n",
      "Ep 9: Batch #14 - Loss: 0.6110900640487671\n",
      "Ep 9: Batch #15 - Loss: 0.967568039894104\n",
      "Ep 9: Batch #16 - Loss: 1.0259405374526978\n",
      "Ep 9: Batch #17 - Loss: 0.7486107349395752\n",
      "Ep 9: Batch #18 - Loss: 0.8256193399429321\n",
      "Ep 9: Batch #19 - Loss: 0.5774982571601868\n",
      "Ep 9: Batch #20 - Loss: 0.5654506087303162\n",
      "Ep 9: Batch #21 - Loss: 0.992931604385376\n",
      "Ep 9: Batch #22 - Loss: 0.6300420761108398\n",
      "Ep 9: Batch #23 - Loss: 0.623493492603302\n",
      "Ep 9: Batch #24 - Loss: 0.6827681660652161\n",
      "Ep 9: Batch #25 - Loss: 0.637039065361023\n",
      "Ep 9: Batch #26 - Loss: 0.6123606562614441\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 9: Batch #27 - Loss: 1.1599432229995728\n",
      "Ep 9: Batch #28 - Loss: 0.718598484992981\n",
      "Ep 9: Batch #29 - Loss: 0.7757543325424194\n",
      "Ep 9: Batch #30 - Loss: 0.9574117660522461\n",
      "Ep 9: Batch #31 - Loss: 0.5729880332946777\n",
      "Ep 9: Batch #32 - Loss: 0.6051888465881348\n",
      "Ep 9: Batch #33 - Loss: 0.6916730999946594\n",
      "Ep 9: Batch #34 - Loss: 0.6657267808914185\n",
      "Ep 9: Batch #35 - Loss: 0.7722979187965393\n",
      "Ep 9: Batch #36 - Loss: 0.5938791036605835\n",
      "Ep 9: Batch #37 - Loss: 0.9439539909362793\n",
      "Ep 9: Batch #38 - Loss: 0.5907159447669983\n",
      "Ep 9: Batch #39 - Loss: 0.7039250135421753\n",
      "Ep 9: Batch #40 - Loss: 0.6294240951538086\n",
      "Ep 9: Batch #41 - Loss: 0.6355865001678467\n",
      "Ep 9: Batch #42 - Loss: 0.5921102166175842\n",
      "Ep 9: Batch #43 - Loss: 0.6562970280647278\n",
      "Ep 9: Batch #44 - Loss: 0.652743935585022\n",
      "Ep 9: Batch #45 - Loss: 0.5473933219909668\n",
      "Ep 9: Batch #46 - Loss: 0.71084064245224\n",
      "Ep 9: Batch #47 - Loss: 0.8253185749053955\n",
      "Ep 9: Batch #48 - Loss: 1.106019139289856\n",
      "Ep 9: Batch #49 - Loss: 0.8326632380485535\n",
      "Ep 9: Batch #50 - Loss: 0.5878106951713562\n",
      "Ep 9: Batch #51 - Loss: 0.8359794616699219\n",
      "Ep 9: Batch #52 - Loss: 0.692781925201416\n",
      "Ep 9: Batch #53 - Loss: 0.7260177731513977\n",
      "Ep 9: Batch #54 - Loss: 0.6058210134506226\n",
      "Ep 9: Batch #55 - Loss: 0.6361970901489258\n",
      "Ep 9: Batch #56 - Loss: 0.9491174817085266\n",
      "Ep 9: Batch #57 - Loss: 0.6976584792137146\n",
      "Ep 9: Batch #58 - Loss: 0.8423734903335571\n",
      "Ep 9: Batch #59 - Loss: 0.5817074775695801\n",
      "Ep 9: Batch #60 - Loss: 1.0637822151184082\n",
      "Ep 9: Batch #61 - Loss: 0.5427838563919067\n",
      "Ep 9: Batch #62 - Loss: 0.6057166457176208\n",
      "Ep 9: Batch #63 - Loss: 0.8163415193557739\n",
      "Ep 9: Batch #64 - Loss: 8.918892860412598\n",
      "Ep 9: Batch #65 - Loss: 0.5357090830802917\n",
      "Ep 9: Batch #66 - Loss: 0.692078173160553\n",
      "Ep 9: Batch #67 - Loss: 0.7927820086479187\n",
      "Ep 9: Batch #68 - Loss: 0.7516122460365295\n",
      "Ep 9: Batch #69 - Loss: 0.6308555006980896\n",
      "Ep 9: Batch #70 - Loss: 0.6329019069671631\n",
      "Ep 9: Batch #71 - Loss: 0.5572550892829895\n",
      "Ep 9: Batch #72 - Loss: 0.687551736831665\n",
      "Ep 9: Batch #73 - Loss: 0.7717081308364868\n",
      "Ep 9: Batch #74 - Loss: 0.6042026877403259\n",
      "Ep 9: Batch #75 - Loss: 0.6786832809448242\n",
      "Ep 9: Batch #76 - Loss: 0.9689179062843323\n",
      "Ep 9: Batch #77 - Loss: 0.6132853627204895\n",
      "Ep 9: Batch #78 - Loss: 0.951612651348114\n",
      "Ep 9: Batch #79 - Loss: 0.5440422892570496\n",
      "Ep 9: Batch #80 - Loss: 0.7208999991416931\n",
      "Ep 9: Batch #81 - Loss: 1.5460904836654663\n",
      "Ep 9: Batch #82 - Loss: 0.7637296915054321\n",
      "Ep 9: Batch #83 - Loss: 1.4954781532287598\n",
      "Ep 9: Batch #84 - Loss: 0.6032516956329346\n",
      "Ep 9: Batch #85 - Loss: 0.8352435231208801\n",
      "Ep 9: Batch #86 - Loss: 0.5767547488212585\n",
      "Ep 9: Batch #87 - Loss: 0.5840200781822205\n",
      "Ep 9: Batch #88 - Loss: 0.6692298054695129\n",
      "Ep 9: Batch #89 - Loss: 0.7808108329772949\n",
      "Ep 9: Batch #90 - Loss: 0.9355093240737915\n",
      "Ep 9: Batch #91 - Loss: 0.6616308093070984\n",
      "Ep 9: Batch #92 - Loss: 0.8232853412628174\n",
      "Ep 9: Batch #93 - Loss: 0.819672703742981\n",
      "Ep 9: Batch #94 - Loss: 0.8240070343017578\n",
      "Ep 9: Batch #95 - Loss: 0.7732609510421753\n",
      "Ep 9: Batch #96 - Loss: 0.7759661078453064\n",
      "Ep 9: Batch #97 - Loss: 0.6000499129295349\n",
      "Ep 9: Batch #98 - Loss: 0.6044114232063293\n",
      "Ep 9: Batch #99 - Loss: 0.818558931350708\n",
      "Ep 9: Batch #100 - Loss: 0.572210431098938\n",
      "Ep 9: Batch #101 - Loss: 0.8786305785179138\n",
      "Ep 9: Batch #102 - Loss: 0.643630862236023\n",
      "Ep 9: Batch #103 - Loss: 0.6568726897239685\n",
      "Ep 9: Batch #104 - Loss: 0.6780241131782532\n",
      "Ep 9: Batch #105 - Loss: 0.8366062045097351\n",
      "Ep 9: Batch #106 - Loss: 0.643100380897522\n",
      "Ep 9: Batch #107 - Loss: 0.6195116639137268\n",
      "Ep 9: Batch #108 - Loss: 0.9092782735824585\n",
      "Ep 9: Batch #109 - Loss: 0.6511794328689575\n",
      "Ep 9: Batch #110 - Loss: 0.74199378490448\n",
      "Ep 9: Batch #111 - Loss: 1.103070616722107\n",
      "Ep 9: Batch #112 - Loss: 0.8591122627258301\n",
      "Ep 9: Batch #113 - Loss: 0.6731391549110413\n",
      "Ep 9: Batch #114 - Loss: 0.7562236189842224\n",
      "Ep 9: Batch #115 - Loss: 0.9250146746635437\n",
      "Ep 9: Batch #116 - Loss: 0.5367923974990845\n",
      "Ep 9: Batch #117 - Loss: 0.7289085388183594\n",
      "Ep 9: Batch #118 - Loss: 0.4626666009426117\n",
      "Model saved in file: ./weights_autoencoder_sigmoid/model_e9b118_1516648792.960044.ckpt\n",
      "Ep 9: Batch #119 - Loss: 0.8271687030792236\n",
      "Ep 9: Batch #120 - Loss: 0.6753348112106323\n",
      "Ep 9: Batch #121 - Loss: 0.5753049254417419\n",
      "Ep 9: Batch #122 - Loss: 0.7264147400856018\n",
      "Ep 9: Batch #123 - Loss: 0.7360785007476807\n",
      "Ep 9: Batch #124 - Loss: 0.5668292045593262\n",
      "Ep 9: Batch #125 - Loss: 2.494175672531128\n",
      "Ep 9: Batch #126 - Loss: 1.0129565000534058\n",
      "Ep 9: Batch #127 - Loss: 0.5978483557701111\n",
      "Ep 9: Batch #128 - Loss: 0.9071369171142578\n",
      "Ep 9: Batch #129 - Loss: 0.6915199160575867\n",
      "Ep 9: Batch #130 - Loss: 0.6137626767158508\n",
      "Ep 9: Batch #131 - Loss: 0.8157255053520203\n",
      "Ep 9: Batch #132 - Loss: 0.7025067806243896\n",
      "Ep 9: Batch #133 - Loss: 0.681867778301239\n",
      "Ep 9: Batch #134 - Loss: 0.6642488241195679\n",
      "Ep 9: Batch #135 - Loss: 0.8359068632125854\n",
      "Ep 9: Batch #136 - Loss: 1.0579030513763428\n",
      "Ep 9: Batch #137 - Loss: 0.7719380855560303\n",
      "Ep 9: Batch #138 - Loss: 0.9246271848678589\n",
      "Ep 9: Batch #139 - Loss: 0.7110387682914734\n",
      "Ep 9: Batch #140 - Loss: 0.8939958810806274\n",
      "Ep 9: Batch #141 - Loss: 1.1623283624649048\n",
      "Ep 9: Batch #142 - Loss: 0.6869151592254639\n",
      "Ep 9: Batch #143 - Loss: 0.7915378212928772\n",
      "Ep 9: Batch #144 - Loss: 0.6230891942977905\n",
      "Ep 9: Batch #145 - Loss: 0.6016039252281189\n",
      "Ep 9: Batch #146 - Loss: 0.7411777973175049\n",
      "Ep 9: Batch #147 - Loss: 0.7237266898155212\n",
      "Ep 9: Batch #148 - Loss: 0.7900334000587463\n",
      "Ep 9: Batch #149 - Loss: 0.6967207789421082\n",
      "Ep 9: Batch #150 - Loss: 0.7500598430633545\n",
      "Ep 9: Batch #151 - Loss: 0.6475446820259094\n",
      "Ep 9: Batch #152 - Loss: 0.6280211806297302\n",
      "Ep 9: Batch #153 - Loss: 0.8812540173530579\n",
      "Ep 9: Batch #154 - Loss: 0.6480773687362671\n",
      "Ep 9: Batch #155 - Loss: 0.7192568778991699\n",
      "Ep 9: Batch #156 - Loss: 0.8434144854545593\n",
      "Ep 9: Batch #157 - Loss: 0.641173243522644\n",
      "Ep 9: Batch #158 - Loss: 0.7320627570152283\n",
      "Ep 9: Batch #159 - Loss: 0.655949056148529\n",
      "Ep 9: Batch #160 - Loss: 0.7467315196990967\n",
      "Ep 9: Batch #161 - Loss: 0.6968313455581665\n",
      "Ep 9: Batch #162 - Loss: 0.7530139684677124\n",
      "Ep 9: Batch #163 - Loss: 0.8012621402740479\n",
      "Ep 9: Batch #164 - Loss: 0.6712943911552429\n",
      "Ep 9: Batch #165 - Loss: 1.3604365587234497\n",
      "Ep 9: Batch #166 - Loss: 0.5623236894607544\n",
      "Ep 9: Batch #167 - Loss: 0.8630272746086121\n",
      "Ep 9: Batch #168 - Loss: 0.7176092863082886\n",
      "Ep 9: Batch #169 - Loss: 0.6934564113616943\n",
      "Ep 9: Batch #170 - Loss: 0.6663355827331543\n",
      "Ep 9: Batch #171 - Loss: 0.6597274541854858\n",
      "Ep 9: Batch #172 - Loss: 0.5497161149978638\n",
      "Ep 9: Batch #173 - Loss: 0.9952005743980408\n",
      "Ep 9: Batch #174 - Loss: 0.5070693492889404\n",
      "Ep 9: Batch #175 - Loss: 0.6672696471214294\n",
      "Ep 9: Batch #176 - Loss: 0.9447170495986938\n",
      "Ep 9: Batch #177 - Loss: 0.6932154893875122\n",
      "Ep 9: Batch #178 - Loss: 0.6556317210197449\n",
      "Ep 9: Batch #179 - Loss: 0.7679186463356018\n",
      "Ep 9: Batch #180 - Loss: 0.6768149733543396\n",
      "Ep 9: Batch #181 - Loss: 0.8303202390670776\n",
      "Ep 9: Batch #182 - Loss: 0.642608106136322\n",
      "Ep 9: Batch #183 - Loss: 0.6431828737258911\n",
      "Ep 9: Batch #184 - Loss: 0.9344719648361206\n",
      "Ep 9: Batch #185 - Loss: 0.6508086323738098\n",
      "Ep 9: Batch #186 - Loss: 0.7926143407821655\n",
      "Ep 9: Batch #187 - Loss: 0.9272313117980957\n",
      "Ep 9: Batch #188 - Loss: 1.0749648809432983\n",
      "Ep 9: Batch #189 - Loss: 0.603152871131897\n",
      "Ep 9: Batch #190 - Loss: 0.6378250122070312\n",
      "Ep 9: Batch #191 - Loss: 0.8570284247398376\n",
      "Ep 9: Batch #192 - Loss: 0.5839759707450867\n",
      "Ep 9: Batch #193 - Loss: 0.6402973532676697\n",
      "Ep 9: Batch #194 - Loss: 0.5863860249519348\n",
      "Ep 9: Batch #195 - Loss: 0.8064465522766113\n",
      "Ep 9: Batch #196 - Loss: 0.7141130566596985\n",
      "Ep 9: Batch #197 - Loss: 0.7380699515342712\n",
      "Ep 9: Batch #198 - Loss: 0.5537945628166199\n",
      "Ep 9: Batch #199 - Loss: 0.6778036952018738\n",
      "Ep 10: Batch #0 - Loss: 0.6657820343971252\n",
      "Ep 10: Batch #1 - Loss: 0.7323182225227356\n",
      "Ep 10: Batch #2 - Loss: 0.8774341344833374\n",
      "Ep 10: Batch #3 - Loss: 0.7359376549720764\n",
      "Ep 10: Batch #4 - Loss: 0.6663597822189331\n",
      "Ep 10: Batch #5 - Loss: 0.58258056640625\n",
      "Ep 10: Batch #6 - Loss: 0.7547710537910461\n",
      "Ep 10: Batch #7 - Loss: 0.6066940426826477\n",
      "Ep 10: Batch #8 - Loss: 0.6061684489250183\n",
      "Ep 10: Batch #9 - Loss: 1.138109564781189\n",
      "Ep 10: Batch #10 - Loss: 0.8709881901741028\n",
      "Ep 10: Batch #11 - Loss: 0.555709958076477\n",
      "Ep 10: Batch #12 - Loss: 1.3137315511703491\n",
      "Ep 10: Batch #13 - Loss: 0.5889409780502319\n",
      "Ep 10: Batch #14 - Loss: 0.6098019480705261\n",
      "Ep 10: Batch #15 - Loss: 0.9635679721832275\n",
      "Ep 10: Batch #16 - Loss: 1.0233222246170044\n",
      "Ep 10: Batch #17 - Loss: 0.7477458715438843\n",
      "Ep 10: Batch #18 - Loss: 0.8236690163612366\n",
      "Ep 10: Batch #19 - Loss: 0.5766235589981079\n",
      "Ep 10: Batch #20 - Loss: 0.5643523335456848\n",
      "Ep 10: Batch #21 - Loss: 0.9855243563652039\n",
      "Ep 10: Batch #22 - Loss: 0.6286894679069519\n",
      "Ep 10: Batch #23 - Loss: 0.6220035552978516\n",
      "Ep 10: Batch #24 - Loss: 0.6790465712547302\n",
      "Ep 10: Batch #25 - Loss: 0.6350542306900024\n",
      "Ep 10: Batch #26 - Loss: 0.6111007332801819\n",
      "Ep 10: Batch #27 - Loss: 1.1577372550964355\n",
      "Ep 10: Batch #28 - Loss: 0.716249942779541\n",
      "Ep 10: Batch #29 - Loss: 0.774553120136261\n",
      "Ep 10: Batch #30 - Loss: 0.9506434202194214\n",
      "Ep 10: Batch #31 - Loss: 0.5717648863792419\n",
      "Ep 10: Batch #32 - Loss: 0.603568971157074\n",
      "Ep 10: Batch #33 - Loss: 0.6901200413703918\n",
      "Ep 10: Batch #34 - Loss: 0.6640207767486572\n",
      "Ep 10: Batch #35 - Loss: 0.7703573703765869\n",
      "Ep 10: Batch #36 - Loss: 0.5929625034332275\n",
      "Ep 10: Batch #37 - Loss: 0.9420700073242188\n",
      "Ep 10: Batch #38 - Loss: 0.5895746946334839\n",
      "Ep 10: Batch #39 - Loss: 0.7019005417823792\n",
      "Ep 10: Batch #40 - Loss: 0.6281468868255615\n",
      "Ep 10: Batch #41 - Loss: 0.634434163570404\n",
      "Ep 10: Batch #42 - Loss: 0.5903157591819763\n",
      "Ep 10: Batch #43 - Loss: 0.6550861597061157\n",
      "Ep 10: Batch #44 - Loss: 0.6510540246963501\n",
      "Ep 10: Batch #45 - Loss: 0.5459383726119995\n",
      "Ep 10: Batch #46 - Loss: 0.710269033908844\n",
      "Ep 10: Batch #47 - Loss: 0.8234891891479492\n",
      "Ep 10: Batch #48 - Loss: 1.1026372909545898\n",
      "Ep 10: Batch #49 - Loss: 0.8312625288963318\n",
      "Ep 10: Batch #50 - Loss: 0.586474597454071\n",
      "Ep 10: Batch #51 - Loss: 0.8347812294960022\n",
      "Ep 10: Batch #52 - Loss: 0.6920980215072632\n",
      "Ep 10: Batch #53 - Loss: 0.7250505685806274\n",
      "Ep 10: Batch #54 - Loss: 0.6043323278427124\n",
      "Ep 10: Batch #55 - Loss: 0.6355881690979004\n",
      "Ep 10: Batch #56 - Loss: 0.9430857300758362\n",
      "Ep 10: Batch #57 - Loss: 0.696010410785675\n",
      "Ep 10: Batch #58 - Loss: 0.8416649103164673\n",
      "Ep 10: Batch #59 - Loss: 0.5806690454483032\n",
      "Ep 10: Batch #60 - Loss: 1.0596086978912354\n",
      "Ep 10: Batch #61 - Loss: 0.5421115159988403\n",
      "Ep 10: Batch #62 - Loss: 0.6041576266288757\n",
      "Ep 10: Batch #63 - Loss: 0.8137028813362122\n",
      "Ep 10: Batch #64 - Loss: 8.905535697937012\n",
      "Ep 10: Batch #65 - Loss: 0.534837543964386\n",
      "Ep 10: Batch #66 - Loss: 0.6904653906822205\n",
      "Ep 10: Batch #67 - Loss: 0.7913374304771423\n",
      "Ep 10: Batch #68 - Loss: 0.7508736848831177\n",
      "Ep 10: Batch #69 - Loss: 0.6294834017753601\n",
      "Ep 10: Batch #70 - Loss: 0.6324533224105835\n",
      "Ep 10: Batch #71 - Loss: 0.5570695996284485\n",
      "Ep 10: Batch #72 - Loss: 0.6856284737586975\n",
      "Ep 10: Batch #73 - Loss: 0.7704146504402161\n",
      "Ep 10: Batch #74 - Loss: 0.6041088700294495\n",
      "Ep 10: Batch #75 - Loss: 0.6778748631477356\n",
      "Ep 10: Batch #76 - Loss: 0.9681462049484253\n",
      "Ep 10: Batch #77 - Loss: 0.6121389269828796\n",
      "Ep 10: Batch #78 - Loss: 0.9523413777351379\n",
      "Ep 10: Batch #79 - Loss: 0.543183445930481\n",
      "Ep 10: Batch #80 - Loss: 0.7202290296554565\n",
      "Ep 10: Batch #81 - Loss: 1.5463101863861084\n",
      "Ep 10: Batch #82 - Loss: 0.7616316676139832\n",
      "Ep 10: Batch #83 - Loss: 1.4829851388931274\n",
      "Ep 10: Batch #84 - Loss: 0.6033197045326233\n",
      "Ep 10: Batch #85 - Loss: 0.832901656627655\n",
      "Ep 10: Batch #86 - Loss: 0.5762135982513428\n",
      "Ep 10: Batch #87 - Loss: 0.5841273665428162\n",
      "Ep 10: Batch #88 - Loss: 0.6682758927345276\n",
      "Ep 10: Batch #89 - Loss: 0.7792573571205139\n",
      "Ep 10: Batch #90 - Loss: 0.9347391724586487\n",
      "Ep 10: Batch #91 - Loss: 0.6602790951728821\n",
      "Ep 10: Batch #92 - Loss: 0.822728157043457\n",
      "Ep 10: Batch #93 - Loss: 0.8180782198905945\n",
      "Ep 10: Batch #94 - Loss: 0.822004497051239\n",
      "Ep 10: Batch #95 - Loss: 0.7735123038291931\n",
      "Ep 10: Batch #96 - Loss: 0.7754435539245605\n",
      "Ep 10: Batch #97 - Loss: 0.5993298292160034\n",
      "Ep 10: Batch #98 - Loss: 0.6027300357818604\n",
      "Ep 10: Batch #99 - Loss: 0.8174450993537903\n",
      "Ep 10: Batch #100 - Loss: 0.5716740489006042\n",
      "Ep 10: Batch #101 - Loss: 0.877720057964325\n",
      "Ep 10: Batch #102 - Loss: 0.6426727771759033\n",
      "Ep 10: Batch #103 - Loss: 0.6558315753936768\n",
      "Ep 10: Batch #104 - Loss: 0.6767383813858032\n",
      "Ep 10: Batch #105 - Loss: 0.8357436060905457\n",
      "Ep 10: Batch #106 - Loss: 0.6419761776924133\n",
      "Ep 10: Batch #107 - Loss: 0.6185495257377625\n",
      "Ep 10: Batch #108 - Loss: 0.9087004661560059\n",
      "Ep 10: Batch #109 - Loss: 0.6499789953231812\n",
      "Ep 10: Batch #110 - Loss: 0.7405606508255005\n",
      "Ep 10: Batch #111 - Loss: 1.097851037979126\n",
      "Ep 10: Batch #112 - Loss: 0.8549545407295227\n",
      "Ep 10: Batch #113 - Loss: 0.6724830865859985\n",
      "Ep 10: Batch #114 - Loss: 0.7550818920135498\n",
      "Ep 10: Batch #115 - Loss: 0.9228222370147705\n",
      "Ep 10: Batch #116 - Loss: 0.5363990664482117\n",
      "Ep 10: Batch #117 - Loss: 0.7276170253753662\n",
      "Ep 10: Batch #118 - Loss: 0.46202147006988525\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved in file: ./weights_autoencoder_sigmoid/model_e10b118_1516648793.0947208.ckpt\n",
      "Ep 10: Batch #119 - Loss: 0.8255793452262878\n",
      "Ep 10: Batch #120 - Loss: 0.6751126050949097\n",
      "Ep 10: Batch #121 - Loss: 0.5748674869537354\n",
      "Ep 10: Batch #122 - Loss: 0.7264404296875\n",
      "Ep 10: Batch #123 - Loss: 0.7357275485992432\n",
      "Ep 10: Batch #124 - Loss: 0.5660727024078369\n",
      "Ep 10: Batch #125 - Loss: 2.490953207015991\n",
      "Ep 10: Batch #126 - Loss: 1.0108554363250732\n",
      "Ep 10: Batch #127 - Loss: 0.5967926383018494\n",
      "Ep 10: Batch #128 - Loss: 0.9046397805213928\n",
      "Ep 10: Batch #129 - Loss: 0.6902354955673218\n",
      "Ep 10: Batch #130 - Loss: 0.6129277944564819\n",
      "Ep 10: Batch #131 - Loss: 0.8144788146018982\n",
      "Ep 10: Batch #132 - Loss: 0.7017567157745361\n",
      "Ep 10: Batch #133 - Loss: 0.6807133555412292\n",
      "Ep 10: Batch #134 - Loss: 0.6641122698783875\n",
      "Ep 10: Batch #135 - Loss: 0.8359902501106262\n",
      "Ep 10: Batch #136 - Loss: 1.0568506717681885\n",
      "Ep 10: Batch #137 - Loss: 0.7701930403709412\n",
      "Ep 10: Batch #138 - Loss: 0.9235861897468567\n",
      "Ep 10: Batch #139 - Loss: 0.7122231125831604\n",
      "Ep 10: Batch #140 - Loss: 0.8923709988594055\n",
      "Ep 10: Batch #141 - Loss: 1.1602470874786377\n",
      "Ep 10: Batch #142 - Loss: 0.6860370635986328\n",
      "Ep 10: Batch #143 - Loss: 0.7902408242225647\n",
      "Ep 10: Batch #144 - Loss: 0.6222678422927856\n",
      "Ep 10: Batch #145 - Loss: 0.6014596223831177\n",
      "Ep 10: Batch #146 - Loss: 0.7410562634468079\n",
      "Ep 10: Batch #147 - Loss: 0.7214793562889099\n",
      "Ep 10: Batch #148 - Loss: 0.7885639667510986\n",
      "Ep 10: Batch #149 - Loss: 0.6960790157318115\n",
      "Ep 10: Batch #150 - Loss: 0.7486109733581543\n",
      "Ep 10: Batch #151 - Loss: 0.646851658821106\n",
      "Ep 10: Batch #152 - Loss: 0.6264736652374268\n",
      "Ep 10: Batch #153 - Loss: 0.8785577416419983\n",
      "Ep 10: Batch #154 - Loss: 0.6467562913894653\n",
      "Ep 10: Batch #155 - Loss: 0.7194496393203735\n",
      "Ep 10: Batch #156 - Loss: 0.8430188298225403\n",
      "Ep 10: Batch #157 - Loss: 0.6405227184295654\n",
      "Ep 10: Batch #158 - Loss: 0.7307242155075073\n",
      "Ep 10: Batch #159 - Loss: 0.654427707195282\n",
      "Ep 10: Batch #160 - Loss: 0.745109498500824\n",
      "Ep 10: Batch #161 - Loss: 0.695746898651123\n",
      "Ep 10: Batch #162 - Loss: 0.7502003312110901\n",
      "Ep 10: Batch #163 - Loss: 0.7998682260513306\n",
      "Ep 10: Batch #164 - Loss: 0.6707257032394409\n",
      "Ep 10: Batch #165 - Loss: 1.3601505756378174\n",
      "Ep 10: Batch #166 - Loss: 0.5616667866706848\n",
      "Ep 10: Batch #167 - Loss: 0.8608354330062866\n",
      "Ep 10: Batch #168 - Loss: 0.7164179682731628\n",
      "Ep 10: Batch #169 - Loss: 0.6927245855331421\n",
      "Ep 10: Batch #170 - Loss: 0.6651532649993896\n",
      "Ep 10: Batch #171 - Loss: 0.6585012674331665\n",
      "Ep 10: Batch #172 - Loss: 0.5483822822570801\n",
      "Ep 10: Batch #173 - Loss: 0.9931170344352722\n",
      "Ep 10: Batch #174 - Loss: 0.5069364309310913\n",
      "Ep 10: Batch #175 - Loss: 0.6651331186294556\n",
      "Ep 10: Batch #176 - Loss: 0.943546712398529\n",
      "Ep 10: Batch #177 - Loss: 0.6911214590072632\n",
      "Ep 10: Batch #178 - Loss: 0.6546660661697388\n",
      "Ep 10: Batch #179 - Loss: 0.7680240273475647\n",
      "Ep 10: Batch #180 - Loss: 0.675926148891449\n",
      "Ep 10: Batch #181 - Loss: 0.8295685648918152\n",
      "Ep 10: Batch #182 - Loss: 0.6411439776420593\n",
      "Ep 10: Batch #183 - Loss: 0.641645610332489\n",
      "Ep 10: Batch #184 - Loss: 0.934194028377533\n",
      "Ep 10: Batch #185 - Loss: 0.6501911878585815\n",
      "Ep 10: Batch #186 - Loss: 0.7923160195350647\n",
      "Ep 10: Batch #187 - Loss: 0.9238344430923462\n",
      "Ep 10: Batch #188 - Loss: 1.068689227104187\n",
      "Ep 10: Batch #189 - Loss: 0.6022161841392517\n",
      "Ep 10: Batch #190 - Loss: 0.6371476650238037\n",
      "Ep 10: Batch #191 - Loss: 0.8549432754516602\n",
      "Ep 10: Batch #192 - Loss: 0.583227276802063\n",
      "Ep 10: Batch #193 - Loss: 0.6394199728965759\n",
      "Ep 10: Batch #194 - Loss: 0.5847076773643494\n",
      "Ep 10: Batch #195 - Loss: 0.8058100938796997\n",
      "Ep 10: Batch #196 - Loss: 0.7133362889289856\n",
      "Ep 10: Batch #197 - Loss: 0.7367445826530457\n",
      "Ep 10: Batch #198 - Loss: 0.5523008704185486\n",
      "Ep 10: Batch #199 - Loss: 0.6760947108268738\n",
      "Ep 11: Batch #0 - Loss: 0.6654936075210571\n",
      "Ep 11: Batch #1 - Loss: 0.7315269708633423\n",
      "Ep 11: Batch #2 - Loss: 0.8769615292549133\n",
      "Ep 11: Batch #3 - Loss: 0.7351379990577698\n",
      "Ep 11: Batch #4 - Loss: 0.6661748886108398\n",
      "Ep 11: Batch #5 - Loss: 0.5820066332817078\n",
      "Ep 11: Batch #6 - Loss: 0.7547122240066528\n",
      "Ep 11: Batch #7 - Loss: 0.6052359342575073\n",
      "Ep 11: Batch #8 - Loss: 0.6054056882858276\n",
      "Ep 11: Batch #9 - Loss: 1.135807752609253\n",
      "Ep 11: Batch #10 - Loss: 0.8694071173667908\n",
      "Ep 11: Batch #11 - Loss: 0.5549723505973816\n",
      "Ep 11: Batch #12 - Loss: 1.3072975873947144\n",
      "Ep 11: Batch #13 - Loss: 0.5878220200538635\n",
      "Ep 11: Batch #14 - Loss: 0.6088090538978577\n",
      "Ep 11: Batch #15 - Loss: 0.9598802924156189\n",
      "Ep 11: Batch #16 - Loss: 1.0207116603851318\n",
      "Ep 11: Batch #17 - Loss: 0.7471992373466492\n",
      "Ep 11: Batch #18 - Loss: 0.8224562406539917\n",
      "Ep 11: Batch #19 - Loss: 0.5758501887321472\n",
      "Ep 11: Batch #20 - Loss: 0.5632690191268921\n",
      "Ep 11: Batch #21 - Loss: 0.9772123694419861\n",
      "Ep 11: Batch #22 - Loss: 0.6272695064544678\n",
      "Ep 11: Batch #23 - Loss: 0.6208353638648987\n",
      "Ep 11: Batch #24 - Loss: 0.6751275062561035\n",
      "Ep 11: Batch #25 - Loss: 0.6336344480514526\n",
      "Ep 11: Batch #26 - Loss: 0.6108211278915405\n",
      "Ep 11: Batch #27 - Loss: 1.1561204195022583\n",
      "Ep 11: Batch #28 - Loss: 0.7138396501541138\n",
      "Ep 11: Batch #29 - Loss: 0.7735975384712219\n",
      "Ep 11: Batch #30 - Loss: 0.944936990737915\n",
      "Ep 11: Batch #31 - Loss: 0.5709479451179504\n",
      "Ep 11: Batch #32 - Loss: 0.6023095846176147\n",
      "Ep 11: Batch #33 - Loss: 0.6890003681182861\n",
      "Ep 11: Batch #34 - Loss: 0.6627817749977112\n",
      "Ep 11: Batch #35 - Loss: 0.7684627771377563\n",
      "Ep 11: Batch #36 - Loss: 0.5925663709640503\n",
      "Ep 11: Batch #37 - Loss: 0.9406226277351379\n",
      "Ep 11: Batch #38 - Loss: 0.5886698961257935\n",
      "Ep 11: Batch #39 - Loss: 0.7005755305290222\n",
      "Ep 11: Batch #40 - Loss: 0.6270033121109009\n",
      "Ep 11: Batch #41 - Loss: 0.6333953738212585\n",
      "Ep 11: Batch #42 - Loss: 0.5888638496398926\n",
      "Ep 11: Batch #43 - Loss: 0.6546722054481506\n",
      "Ep 11: Batch #44 - Loss: 0.6495198607444763\n",
      "Ep 11: Batch #45 - Loss: 0.5445768237113953\n",
      "Ep 11: Batch #46 - Loss: 0.709732711315155\n",
      "Ep 11: Batch #47 - Loss: 0.8222960829734802\n",
      "Ep 11: Batch #48 - Loss: 1.09796941280365\n",
      "Ep 11: Batch #49 - Loss: 0.8300349116325378\n",
      "Ep 11: Batch #50 - Loss: 0.585444986820221\n",
      "Ep 11: Batch #51 - Loss: 0.8336191177368164\n",
      "Ep 11: Batch #52 - Loss: 0.6913583874702454\n",
      "Ep 11: Batch #53 - Loss: 0.724247395992279\n",
      "Ep 11: Batch #54 - Loss: 0.6033020615577698\n",
      "Ep 11: Batch #55 - Loss: 0.634488046169281\n",
      "Ep 11: Batch #56 - Loss: 0.937902569770813\n",
      "Ep 11: Batch #57 - Loss: 0.6944453120231628\n",
      "Ep 11: Batch #58 - Loss: 0.841494619846344\n",
      "Ep 11: Batch #59 - Loss: 0.5797920823097229\n",
      "Ep 11: Batch #60 - Loss: 1.0564157962799072\n",
      "Ep 11: Batch #61 - Loss: 0.5414490103721619\n",
      "Ep 11: Batch #62 - Loss: 0.6026194095611572\n",
      "Ep 11: Batch #63 - Loss: 0.8120515942573547\n",
      "Ep 11: Batch #64 - Loss: 8.881515502929688\n",
      "Ep 11: Batch #65 - Loss: 0.5343233942985535\n",
      "Ep 11: Batch #66 - Loss: 0.6886835098266602\n",
      "Ep 11: Batch #67 - Loss: 0.7906898856163025\n",
      "Ep 11: Batch #68 - Loss: 0.7501125931739807\n",
      "Ep 11: Batch #69 - Loss: 0.6270585656166077\n",
      "Ep 11: Batch #70 - Loss: 0.631440281867981\n",
      "Ep 11: Batch #71 - Loss: 0.5560014843940735\n",
      "Ep 11: Batch #72 - Loss: 0.68329256772995\n",
      "Ep 11: Batch #73 - Loss: 0.7688919305801392\n",
      "Ep 11: Batch #74 - Loss: 0.6040565371513367\n",
      "Ep 11: Batch #75 - Loss: 0.6763079762458801\n",
      "Ep 11: Batch #76 - Loss: 0.9664632678031921\n",
      "Ep 11: Batch #77 - Loss: 0.610824465751648\n",
      "Ep 11: Batch #78 - Loss: 0.9505293369293213\n",
      "Ep 11: Batch #79 - Loss: 0.5423401594161987\n",
      "Ep 11: Batch #80 - Loss: 0.7189642190933228\n",
      "Ep 11: Batch #81 - Loss: 1.5450469255447388\n",
      "Ep 11: Batch #82 - Loss: 0.7594112157821655\n",
      "Ep 11: Batch #83 - Loss: 1.4720227718353271\n",
      "Ep 11: Batch #84 - Loss: 0.60102379322052\n",
      "Ep 11: Batch #85 - Loss: 0.8301388621330261\n",
      "Ep 11: Batch #86 - Loss: 0.5744186043739319\n",
      "Ep 11: Batch #87 - Loss: 0.5836493372917175\n",
      "Ep 11: Batch #88 - Loss: 0.6669701337814331\n",
      "Ep 11: Batch #89 - Loss: 0.7769904732704163\n",
      "Ep 11: Batch #90 - Loss: 0.9325061440467834\n",
      "Ep 11: Batch #91 - Loss: 0.6592450737953186\n",
      "Ep 11: Batch #92 - Loss: 0.820681095123291\n",
      "Ep 11: Batch #93 - Loss: 0.8161226511001587\n",
      "Ep 11: Batch #94 - Loss: 0.819467306137085\n",
      "Ep 11: Batch #95 - Loss: 0.771808385848999\n",
      "Ep 11: Batch #96 - Loss: 0.7748991847038269\n",
      "Ep 11: Batch #97 - Loss: 0.5982888340950012\n",
      "Ep 11: Batch #98 - Loss: 0.6002638339996338\n",
      "Ep 11: Batch #99 - Loss: 0.815970242023468\n",
      "Ep 11: Batch #100 - Loss: 0.5708382725715637\n",
      "Ep 11: Batch #101 - Loss: 0.8764065504074097\n",
      "Ep 11: Batch #102 - Loss: 0.6408106088638306\n",
      "Ep 11: Batch #103 - Loss: 0.6545758843421936\n",
      "Ep 11: Batch #104 - Loss: 0.6754266023635864\n",
      "Ep 11: Batch #105 - Loss: 0.8347373008728027\n",
      "Ep 11: Batch #106 - Loss: 0.641241192817688\n",
      "Ep 11: Batch #107 - Loss: 0.6180500388145447\n",
      "Ep 11: Batch #108 - Loss: 0.9082046151161194\n",
      "Ep 11: Batch #109 - Loss: 0.6487542390823364\n",
      "Ep 11: Batch #110 - Loss: 0.7402306199073792\n",
      "Ep 11: Batch #111 - Loss: 1.0923229455947876\n",
      "Ep 11: Batch #112 - Loss: 0.8521941304206848\n",
      "Ep 11: Batch #113 - Loss: 0.6716784238815308\n",
      "Ep 11: Batch #114 - Loss: 0.7534661889076233\n",
      "Ep 11: Batch #115 - Loss: 0.9205347299575806\n",
      "Ep 11: Batch #116 - Loss: 0.5356435775756836\n",
      "Ep 11: Batch #117 - Loss: 0.7249316573143005\n",
      "Ep 11: Batch #118 - Loss: 0.46159541606903076\n",
      "Model saved in file: ./weights_autoencoder_sigmoid/model_e11b118_1516648793.2308915.ckpt\n",
      "Ep 11: Batch #119 - Loss: 0.8243099451065063\n",
      "Ep 11: Batch #120 - Loss: 0.6738516688346863\n",
      "Ep 11: Batch #121 - Loss: 0.5740432739257812\n",
      "Ep 11: Batch #122 - Loss: 0.725427508354187\n",
      "Ep 11: Batch #123 - Loss: 0.7355715036392212\n",
      "Ep 11: Batch #124 - Loss: 0.565429151058197\n",
      "Ep 11: Batch #125 - Loss: 2.48714280128479\n",
      "Ep 11: Batch #126 - Loss: 1.008550763130188\n",
      "Ep 11: Batch #127 - Loss: 0.5956994295120239\n",
      "Ep 11: Batch #128 - Loss: 0.9022729396820068\n",
      "Ep 11: Batch #129 - Loss: 0.6888881325721741\n",
      "Ep 11: Batch #130 - Loss: 0.6119066476821899\n",
      "Ep 11: Batch #131 - Loss: 0.8133934140205383\n",
      "Ep 11: Batch #132 - Loss: 0.7006963491439819\n",
      "Ep 11: Batch #133 - Loss: 0.679341197013855\n",
      "Ep 11: Batch #134 - Loss: 0.6629030108451843\n",
      "Ep 11: Batch #135 - Loss: 0.8341348767280579\n",
      "Ep 11: Batch #136 - Loss: 1.0555917024612427\n",
      "Ep 11: Batch #137 - Loss: 0.7689319849014282\n",
      "Ep 11: Batch #138 - Loss: 0.9224459528923035\n",
      "Ep 11: Batch #139 - Loss: 0.7115009427070618\n",
      "Ep 11: Batch #140 - Loss: 0.8897716999053955\n",
      "Ep 11: Batch #141 - Loss: 1.1582924127578735\n",
      "Ep 11: Batch #142 - Loss: 0.685446560382843\n",
      "Ep 11: Batch #143 - Loss: 0.7886579632759094\n",
      "Ep 11: Batch #144 - Loss: 0.6216303706169128\n",
      "Ep 11: Batch #145 - Loss: 0.6017850041389465\n",
      "Ep 11: Batch #146 - Loss: 0.7399225234985352\n",
      "Ep 11: Batch #147 - Loss: 0.719504177570343\n",
      "Ep 11: Batch #148 - Loss: 0.7877578735351562\n",
      "Ep 11: Batch #149 - Loss: 0.6945964694023132\n",
      "Ep 11: Batch #150 - Loss: 0.7472374439239502\n",
      "Ep 11: Batch #151 - Loss: 0.6462785601615906\n",
      "Ep 11: Batch #152 - Loss: 0.6248602271080017\n",
      "Ep 11: Batch #153 - Loss: 0.8757387399673462\n",
      "Ep 11: Batch #154 - Loss: 0.6454861760139465\n",
      "Ep 11: Batch #155 - Loss: 0.7177145481109619\n",
      "Ep 11: Batch #156 - Loss: 0.8431220054626465\n",
      "Ep 11: Batch #157 - Loss: 0.6398023366928101\n",
      "Ep 11: Batch #158 - Loss: 0.7300034761428833\n",
      "Ep 11: Batch #159 - Loss: 0.6524319648742676\n",
      "Ep 11: Batch #160 - Loss: 0.7431949377059937\n",
      "Ep 11: Batch #161 - Loss: 0.6939399838447571\n",
      "Ep 11: Batch #162 - Loss: 0.7488991618156433\n",
      "Ep 11: Batch #163 - Loss: 0.7983893156051636\n",
      "Ep 11: Batch #164 - Loss: 0.6699209213256836\n",
      "Ep 11: Batch #165 - Loss: 1.3597313165664673\n",
      "Ep 11: Batch #166 - Loss: 0.5591543912887573\n",
      "Ep 11: Batch #167 - Loss: 0.8580267429351807\n",
      "Ep 11: Batch #168 - Loss: 0.714506983757019\n",
      "Ep 11: Batch #169 - Loss: 0.691791832447052\n",
      "Ep 11: Batch #170 - Loss: 0.6636685729026794\n",
      "Ep 11: Batch #171 - Loss: 0.65766841173172\n",
      "Ep 11: Batch #172 - Loss: 0.5471705198287964\n",
      "Ep 11: Batch #173 - Loss: 0.9903295040130615\n",
      "Ep 11: Batch #174 - Loss: 0.5063760280609131\n",
      "Ep 11: Batch #175 - Loss: 0.6637462973594666\n",
      "Ep 11: Batch #176 - Loss: 0.9408724308013916\n",
      "Ep 11: Batch #177 - Loss: 0.6889075040817261\n",
      "Ep 11: Batch #178 - Loss: 0.6531943678855896\n",
      "Ep 11: Batch #179 - Loss: 0.7666370272636414\n",
      "Ep 11: Batch #180 - Loss: 0.6744479537010193\n",
      "Ep 11: Batch #181 - Loss: 0.8285936117172241\n",
      "Ep 11: Batch #182 - Loss: 0.6400486826896667\n",
      "Ep 11: Batch #183 - Loss: 0.6402469277381897\n",
      "Ep 11: Batch #184 - Loss: 0.9335975050926208\n",
      "Ep 11: Batch #185 - Loss: 0.6494347453117371\n",
      "Ep 11: Batch #186 - Loss: 0.7918165922164917\n",
      "Ep 11: Batch #187 - Loss: 0.9202078580856323\n",
      "Ep 11: Batch #188 - Loss: 1.0635366439819336\n",
      "Ep 11: Batch #189 - Loss: 0.6011334657669067\n",
      "Ep 11: Batch #190 - Loss: 0.6364499926567078\n",
      "Ep 11: Batch #191 - Loss: 0.852760374546051\n",
      "Ep 11: Batch #192 - Loss: 0.5821775794029236\n",
      "Ep 11: Batch #193 - Loss: 0.6383253335952759\n",
      "Ep 11: Batch #194 - Loss: 0.5826225280761719\n",
      "Ep 11: Batch #195 - Loss: 0.8052892684936523\n",
      "Ep 11: Batch #196 - Loss: 0.7122542858123779\n",
      "Ep 11: Batch #197 - Loss: 0.7346311807632446\n",
      "Ep 11: Batch #198 - Loss: 0.5509068369865417\n",
      "Ep 11: Batch #199 - Loss: 0.6740264296531677\n",
      "Ep 12: Batch #0 - Loss: 0.664492130279541\n",
      "Ep 12: Batch #1 - Loss: 0.7303798198699951\n",
      "Ep 12: Batch #2 - Loss: 0.8760196566581726\n",
      "Ep 12: Batch #3 - Loss: 0.7342208027839661\n",
      "Ep 12: Batch #4 - Loss: 0.665016770362854\n",
      "Ep 12: Batch #5 - Loss: 0.5804179310798645\n",
      "Ep 12: Batch #6 - Loss: 0.7545006275177002\n",
      "Ep 12: Batch #7 - Loss: 0.6041259765625\n",
      "Ep 12: Batch #8 - Loss: 0.604598879814148\n",
      "Ep 12: Batch #9 - Loss: 1.1329236030578613\n",
      "Ep 12: Batch #10 - Loss: 0.8671404123306274\n",
      "Ep 12: Batch #11 - Loss: 0.5546404123306274\n",
      "Ep 12: Batch #12 - Loss: 1.2996203899383545\n",
      "Ep 12: Batch #13 - Loss: 0.5864126682281494\n",
      "Ep 12: Batch #14 - Loss: 0.6079580187797546\n",
      "Ep 12: Batch #15 - Loss: 0.9562968611717224\n",
      "Ep 12: Batch #16 - Loss: 1.017003059387207\n",
      "Ep 12: Batch #17 - Loss: 0.7463605999946594\n",
      "Ep 12: Batch #18 - Loss: 0.8210716843605042\n",
      "Ep 12: Batch #19 - Loss: 0.5747937560081482\n",
      "Ep 12: Batch #20 - Loss: 0.5618703365325928\n",
      "Ep 12: Batch #21 - Loss: 0.9691370129585266\n",
      "Ep 12: Batch #22 - Loss: 0.625911295413971\n",
      "Ep 12: Batch #23 - Loss: 0.6196197867393494\n",
      "Ep 12: Batch #24 - Loss: 0.6712194681167603\n",
      "Ep 12: Batch #25 - Loss: 0.6319150328636169\n",
      "Ep 12: Batch #26 - Loss: 0.6105451583862305\n",
      "Ep 12: Batch #27 - Loss: 1.1550261974334717\n",
      "Ep 12: Batch #28 - Loss: 0.7115232944488525\n",
      "Ep 12: Batch #29 - Loss: 0.7724592685699463\n",
      "Ep 12: Batch #30 - Loss: 0.9394079446792603\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 12: Batch #31 - Loss: 0.5702235102653503\n",
      "Ep 12: Batch #32 - Loss: 0.6007434725761414\n",
      "Ep 12: Batch #33 - Loss: 0.6879709362983704\n",
      "Ep 12: Batch #34 - Loss: 0.6614835858345032\n",
      "Ep 12: Batch #35 - Loss: 0.7658484578132629\n",
      "Ep 12: Batch #36 - Loss: 0.5920268297195435\n",
      "Ep 12: Batch #37 - Loss: 0.9399254322052002\n",
      "Ep 12: Batch #38 - Loss: 0.587854266166687\n",
      "Ep 12: Batch #39 - Loss: 0.6995312571525574\n",
      "Ep 12: Batch #40 - Loss: 0.6258984208106995\n",
      "Ep 12: Batch #41 - Loss: 0.6322560906410217\n",
      "Ep 12: Batch #42 - Loss: 0.5871602296829224\n",
      "Ep 12: Batch #43 - Loss: 0.6539942026138306\n",
      "Ep 12: Batch #44 - Loss: 0.6475809812545776\n",
      "Ep 12: Batch #45 - Loss: 0.5430757999420166\n",
      "Ep 12: Batch #46 - Loss: 0.7091239094734192\n",
      "Ep 12: Batch #47 - Loss: 0.8211691975593567\n",
      "Ep 12: Batch #48 - Loss: 1.0948002338409424\n",
      "Ep 12: Batch #49 - Loss: 0.8285139203071594\n",
      "Ep 12: Batch #50 - Loss: 0.5838621258735657\n",
      "Ep 12: Batch #51 - Loss: 0.8322629332542419\n",
      "Ep 12: Batch #52 - Loss: 0.6905414462089539\n",
      "Ep 12: Batch #53 - Loss: 0.723668098449707\n",
      "Ep 12: Batch #54 - Loss: 0.6020941734313965\n",
      "Ep 12: Batch #55 - Loss: 0.6336994767189026\n",
      "Ep 12: Batch #56 - Loss: 0.933330774307251\n",
      "Ep 12: Batch #57 - Loss: 0.6930975914001465\n",
      "Ep 12: Batch #58 - Loss: 0.8406045436859131\n",
      "Ep 12: Batch #59 - Loss: 0.5787946581840515\n",
      "Ep 12: Batch #60 - Loss: 1.0525858402252197\n",
      "Ep 12: Batch #61 - Loss: 0.541092574596405\n",
      "Ep 12: Batch #62 - Loss: 0.6005618572235107\n",
      "Ep 12: Batch #63 - Loss: 0.8100017309188843\n",
      "Ep 12: Batch #64 - Loss: 8.86136245727539\n",
      "Ep 12: Batch #65 - Loss: 0.5335765480995178\n",
      "Ep 12: Batch #66 - Loss: 0.6865741014480591\n",
      "Ep 12: Batch #67 - Loss: 0.7894365787506104\n",
      "Ep 12: Batch #68 - Loss: 0.7487048506736755\n",
      "Ep 12: Batch #69 - Loss: 0.6248025894165039\n",
      "Ep 12: Batch #70 - Loss: 0.6306139230728149\n",
      "Ep 12: Batch #71 - Loss: 0.5552276968955994\n",
      "Ep 12: Batch #72 - Loss: 0.6807233691215515\n",
      "Ep 12: Batch #73 - Loss: 0.7670978903770447\n",
      "Ep 12: Batch #74 - Loss: 0.6034871339797974\n",
      "Ep 12: Batch #75 - Loss: 0.6752932667732239\n",
      "Ep 12: Batch #76 - Loss: 0.9642927646636963\n",
      "Ep 12: Batch #77 - Loss: 0.6094201803207397\n",
      "Ep 12: Batch #78 - Loss: 0.950734555721283\n",
      "Ep 12: Batch #79 - Loss: 0.5413068532943726\n",
      "Ep 12: Batch #80 - Loss: 0.7182447910308838\n",
      "Ep 12: Batch #81 - Loss: 1.543887972831726\n",
      "Ep 12: Batch #82 - Loss: 0.7574998140335083\n",
      "Ep 12: Batch #83 - Loss: 1.4607340097427368\n",
      "Ep 12: Batch #84 - Loss: 0.5995763540267944\n",
      "Ep 12: Batch #85 - Loss: 0.827294111251831\n",
      "Ep 12: Batch #86 - Loss: 0.5724889039993286\n",
      "Ep 12: Batch #87 - Loss: 0.5835566520690918\n",
      "Ep 12: Batch #88 - Loss: 0.6660417914390564\n",
      "Ep 12: Batch #89 - Loss: 0.7747347354888916\n",
      "Ep 12: Batch #90 - Loss: 0.9293789267539978\n",
      "Ep 12: Batch #91 - Loss: 0.6581337451934814\n",
      "Ep 12: Batch #92 - Loss: 0.8179720640182495\n",
      "Ep 12: Batch #93 - Loss: 0.8147293925285339\n",
      "Ep 12: Batch #94 - Loss: 0.8168211579322815\n",
      "Ep 12: Batch #95 - Loss: 0.7711358070373535\n",
      "Ep 12: Batch #96 - Loss: 0.7742900252342224\n",
      "Ep 12: Batch #97 - Loss: 0.5979152321815491\n",
      "Ep 12: Batch #98 - Loss: 0.598407506942749\n",
      "Ep 12: Batch #99 - Loss: 0.8146629333496094\n",
      "Ep 12: Batch #100 - Loss: 0.5702463984489441\n",
      "Ep 12: Batch #101 - Loss: 0.8753166794776917\n",
      "Ep 12: Batch #102 - Loss: 0.6392977237701416\n",
      "Ep 12: Batch #103 - Loss: 0.653536319732666\n",
      "Ep 12: Batch #104 - Loss: 0.6743373274803162\n",
      "Ep 12: Batch #105 - Loss: 0.833810031414032\n",
      "Ep 12: Batch #106 - Loss: 0.64003986120224\n",
      "Ep 12: Batch #107 - Loss: 0.6177159547805786\n",
      "Ep 12: Batch #108 - Loss: 0.9081265926361084\n",
      "Ep 12: Batch #109 - Loss: 0.6473315358161926\n",
      "Ep 12: Batch #110 - Loss: 0.7395460605621338\n",
      "Ep 12: Batch #111 - Loss: 1.087593674659729\n",
      "Ep 12: Batch #112 - Loss: 0.8503009080886841\n",
      "Ep 12: Batch #113 - Loss: 0.670491099357605\n",
      "Ep 12: Batch #114 - Loss: 0.7510446906089783\n",
      "Ep 12: Batch #115 - Loss: 0.9185788631439209\n",
      "Ep 12: Batch #116 - Loss: 0.5350844264030457\n",
      "Ep 12: Batch #117 - Loss: 0.722125768661499\n",
      "Ep 12: Batch #118 - Loss: 0.46147194504737854\n",
      "Model saved in file: ./weights_autoencoder_sigmoid/model_e12b118_1516648793.36733.ckpt\n",
      "Ep 12: Batch #119 - Loss: 0.8241674304008484\n",
      "Ep 12: Batch #120 - Loss: 0.6729977130889893\n",
      "Ep 12: Batch #121 - Loss: 0.5729721188545227\n",
      "Ep 12: Batch #122 - Loss: 0.7244212031364441\n",
      "Ep 12: Batch #123 - Loss: 0.7362621426582336\n",
      "Ep 12: Batch #124 - Loss: 0.5649293065071106\n",
      "Ep 12: Batch #125 - Loss: 2.4835598468780518\n",
      "Ep 12: Batch #126 - Loss: 1.0067946910858154\n",
      "Ep 12: Batch #127 - Loss: 0.5944245457649231\n",
      "Ep 12: Batch #128 - Loss: 0.8998514413833618\n",
      "Ep 12: Batch #129 - Loss: 0.6874266266822815\n",
      "Ep 12: Batch #130 - Loss: 0.6111817955970764\n",
      "Ep 12: Batch #131 - Loss: 0.8130154013633728\n",
      "Ep 12: Batch #132 - Loss: 0.7004663348197937\n",
      "Ep 12: Batch #133 - Loss: 0.6790189743041992\n",
      "Ep 12: Batch #134 - Loss: 0.6617792248725891\n",
      "Ep 12: Batch #135 - Loss: 0.8366069197654724\n",
      "Ep 12: Batch #136 - Loss: 1.0543513298034668\n",
      "Ep 12: Batch #137 - Loss: 0.7676252126693726\n",
      "Ep 12: Batch #138 - Loss: 0.9208214282989502\n",
      "Ep 12: Batch #139 - Loss: 0.7140388488769531\n",
      "Ep 12: Batch #140 - Loss: 0.8874083161354065\n",
      "Ep 12: Batch #141 - Loss: 1.1584566831588745\n",
      "Ep 12: Batch #142 - Loss: 0.6848580837249756\n",
      "Ep 12: Batch #143 - Loss: 0.7867875099182129\n",
      "Ep 12: Batch #144 - Loss: 0.6210601925849915\n",
      "Ep 12: Batch #145 - Loss: 0.601691722869873\n",
      "Ep 12: Batch #146 - Loss: 0.7379662394523621\n",
      "Ep 12: Batch #147 - Loss: 0.7156856656074524\n",
      "Ep 12: Batch #148 - Loss: 0.7872757315635681\n",
      "Ep 12: Batch #149 - Loss: 0.6923145055770874\n",
      "Ep 12: Batch #150 - Loss: 0.7453213334083557\n",
      "Ep 12: Batch #151 - Loss: 0.6455253958702087\n",
      "Ep 12: Batch #152 - Loss: 0.6232349276542664\n",
      "Ep 12: Batch #153 - Loss: 0.8723573088645935\n",
      "Ep 12: Batch #154 - Loss: 0.6440469622612\n",
      "Ep 12: Batch #155 - Loss: 0.7160046100616455\n",
      "Ep 12: Batch #156 - Loss: 0.8426896333694458\n",
      "Ep 12: Batch #157 - Loss: 0.6388007402420044\n",
      "Ep 12: Batch #158 - Loss: 0.7288143634796143\n",
      "Ep 12: Batch #159 - Loss: 0.6499677896499634\n",
      "Ep 12: Batch #160 - Loss: 0.7408552765846252\n",
      "Ep 12: Batch #161 - Loss: 0.6922026872634888\n",
      "Ep 12: Batch #162 - Loss: 0.7468255162239075\n",
      "Ep 12: Batch #163 - Loss: 0.796794056892395\n",
      "Ep 12: Batch #164 - Loss: 0.6685764193534851\n",
      "Ep 12: Batch #165 - Loss: 1.3590857982635498\n",
      "Ep 12: Batch #166 - Loss: 0.5562270879745483\n",
      "Ep 12: Batch #167 - Loss: 0.8548427820205688\n",
      "Ep 12: Batch #168 - Loss: 0.7122586369514465\n",
      "Ep 12: Batch #169 - Loss: 0.6907711625099182\n",
      "Ep 12: Batch #170 - Loss: 0.6617370247840881\n",
      "Ep 12: Batch #171 - Loss: 0.6568059325218201\n",
      "Ep 12: Batch #172 - Loss: 0.5456602573394775\n",
      "Ep 12: Batch #173 - Loss: 0.985794186592102\n",
      "Ep 12: Batch #174 - Loss: 0.505800724029541\n",
      "Ep 12: Batch #175 - Loss: 0.6621360182762146\n",
      "Ep 12: Batch #176 - Loss: 0.9383867979049683\n",
      "Ep 12: Batch #177 - Loss: 0.6865999698638916\n",
      "Ep 12: Batch #178 - Loss: 0.6515513062477112\n",
      "Ep 12: Batch #179 - Loss: 0.7652345895767212\n",
      "Ep 12: Batch #180 - Loss: 0.6727432608604431\n",
      "Ep 12: Batch #181 - Loss: 0.8276571035385132\n",
      "Ep 12: Batch #182 - Loss: 0.6393699645996094\n",
      "Ep 12: Batch #183 - Loss: 0.6385345458984375\n",
      "Ep 12: Batch #184 - Loss: 0.9331557154655457\n",
      "Ep 12: Batch #185 - Loss: 0.6486945748329163\n",
      "Ep 12: Batch #186 - Loss: 0.7911386489868164\n",
      "Ep 12: Batch #187 - Loss: 0.9169214367866516\n",
      "Ep 12: Batch #188 - Loss: 1.0586161613464355\n",
      "Ep 12: Batch #189 - Loss: 0.600141704082489\n",
      "Ep 12: Batch #190 - Loss: 0.635364294052124\n",
      "Ep 12: Batch #191 - Loss: 0.849753737449646\n",
      "Ep 12: Batch #192 - Loss: 0.581122100353241\n",
      "Ep 12: Batch #193 - Loss: 0.6375795006752014\n",
      "Ep 12: Batch #194 - Loss: 0.5799645185470581\n",
      "Ep 12: Batch #195 - Loss: 0.8050151467323303\n",
      "Ep 12: Batch #196 - Loss: 0.7106032371520996\n",
      "Ep 12: Batch #197 - Loss: 0.7324394583702087\n",
      "Ep 12: Batch #198 - Loss: 0.5494705438613892\n",
      "Ep 12: Batch #199 - Loss: 0.6715138554573059\n",
      "Ep 13: Batch #0 - Loss: 0.663409948348999\n",
      "Ep 13: Batch #1 - Loss: 0.7289234399795532\n",
      "Ep 13: Batch #2 - Loss: 0.8753194212913513\n",
      "Ep 13: Batch #3 - Loss: 0.7330357432365417\n",
      "Ep 13: Batch #4 - Loss: 0.6639723181724548\n",
      "Ep 13: Batch #5 - Loss: 0.5788639187812805\n",
      "Ep 13: Batch #6 - Loss: 0.7547997832298279\n",
      "Ep 13: Batch #7 - Loss: 0.6025152206420898\n",
      "Ep 13: Batch #8 - Loss: 0.6037404537200928\n",
      "Ep 13: Batch #9 - Loss: 1.130014181137085\n",
      "Ep 13: Batch #10 - Loss: 0.8639766573905945\n",
      "Ep 13: Batch #11 - Loss: 0.5548862218856812\n",
      "Ep 13: Batch #12 - Loss: 1.2918599843978882\n",
      "Ep 13: Batch #13 - Loss: 0.5848948359489441\n",
      "Ep 13: Batch #14 - Loss: 0.6076282262802124\n",
      "Ep 13: Batch #15 - Loss: 0.9521622061729431\n",
      "Ep 13: Batch #16 - Loss: 1.0127090215682983\n",
      "Ep 13: Batch #17 - Loss: 0.7448064088821411\n",
      "Ep 13: Batch #18 - Loss: 0.8187817931175232\n",
      "Ep 13: Batch #19 - Loss: 0.5736568570137024\n",
      "Ep 13: Batch #20 - Loss: 0.5608210563659668\n",
      "Ep 13: Batch #21 - Loss: 0.9604756832122803\n",
      "Ep 13: Batch #22 - Loss: 0.6245781779289246\n",
      "Ep 13: Batch #23 - Loss: 0.6182452440261841\n",
      "Ep 13: Batch #24 - Loss: 0.6670358180999756\n",
      "Ep 13: Batch #25 - Loss: 0.6299782395362854\n",
      "Ep 13: Batch #26 - Loss: 0.610558271408081\n",
      "Ep 13: Batch #27 - Loss: 1.1548326015472412\n",
      "Ep 13: Batch #28 - Loss: 0.7091891169548035\n",
      "Ep 13: Batch #29 - Loss: 0.771747887134552\n",
      "Ep 13: Batch #30 - Loss: 0.9339470267295837\n",
      "Ep 13: Batch #31 - Loss: 0.5694307088851929\n",
      "Ep 13: Batch #32 - Loss: 0.5986804366111755\n",
      "Ep 13: Batch #33 - Loss: 0.6863741874694824\n",
      "Ep 13: Batch #34 - Loss: 0.6604681015014648\n",
      "Ep 13: Batch #35 - Loss: 0.7621950507164001\n",
      "Ep 13: Batch #36 - Loss: 0.5919347405433655\n",
      "Ep 13: Batch #37 - Loss: 0.9391745924949646\n",
      "Ep 13: Batch #38 - Loss: 0.5870714783668518\n",
      "Ep 13: Batch #39 - Loss: 0.6984343528747559\n",
      "Ep 13: Batch #40 - Loss: 0.6247957944869995\n",
      "Ep 13: Batch #41 - Loss: 0.6308958530426025\n",
      "Ep 13: Batch #42 - Loss: 0.5853548645973206\n",
      "Ep 13: Batch #43 - Loss: 0.6529006958007812\n",
      "Ep 13: Batch #44 - Loss: 0.6449572443962097\n",
      "Ep 13: Batch #45 - Loss: 0.5417295098304749\n",
      "Ep 13: Batch #46 - Loss: 0.7081931829452515\n",
      "Ep 13: Batch #47 - Loss: 0.8206114768981934\n",
      "Ep 13: Batch #48 - Loss: 1.0905611515045166\n",
      "Ep 13: Batch #49 - Loss: 0.8268288373947144\n",
      "Ep 13: Batch #50 - Loss: 0.5822287797927856\n",
      "Ep 13: Batch #51 - Loss: 0.8298646807670593\n",
      "Ep 13: Batch #52 - Loss: 0.6891792416572571\n",
      "Ep 13: Batch #53 - Loss: 0.7230067849159241\n",
      "Ep 13: Batch #54 - Loss: 0.600581169128418\n",
      "Ep 13: Batch #55 - Loss: 0.6315317749977112\n",
      "Ep 13: Batch #56 - Loss: 0.9294038414955139\n",
      "Ep 13: Batch #57 - Loss: 0.6919052600860596\n",
      "Ep 13: Batch #58 - Loss: 0.8411387801170349\n",
      "Ep 13: Batch #59 - Loss: 0.5779032111167908\n",
      "Ep 13: Batch #60 - Loss: 1.050950527191162\n",
      "Ep 13: Batch #61 - Loss: 0.541374146938324\n",
      "Ep 13: Batch #62 - Loss: 0.5983007550239563\n",
      "Ep 13: Batch #63 - Loss: 0.8076286315917969\n",
      "Ep 13: Batch #64 - Loss: 8.84440803527832\n",
      "Ep 13: Batch #65 - Loss: 0.532837986946106\n",
      "Ep 13: Batch #66 - Loss: 0.6844466924667358\n",
      "Ep 13: Batch #67 - Loss: 0.7886254191398621\n",
      "Ep 13: Batch #68 - Loss: 0.7476263046264648\n",
      "Ep 13: Batch #69 - Loss: 0.6223540902137756\n",
      "Ep 13: Batch #70 - Loss: 0.6300334930419922\n",
      "Ep 13: Batch #71 - Loss: 0.5539332032203674\n",
      "Ep 13: Batch #72 - Loss: 0.678056001663208\n",
      "Ep 13: Batch #73 - Loss: 0.7648212909698486\n",
      "Ep 13: Batch #74 - Loss: 0.6018804311752319\n",
      "Ep 13: Batch #75 - Loss: 0.6742218136787415\n",
      "Ep 13: Batch #76 - Loss: 0.9615637063980103\n",
      "Ep 13: Batch #77 - Loss: 0.6067008972167969\n",
      "Ep 13: Batch #78 - Loss: 0.9511880278587341\n",
      "Ep 13: Batch #79 - Loss: 0.5398102402687073\n",
      "Ep 13: Batch #80 - Loss: 0.7173130512237549\n",
      "Ep 13: Batch #81 - Loss: 1.5419813394546509\n",
      "Ep 13: Batch #82 - Loss: 0.7569190859794617\n",
      "Ep 13: Batch #83 - Loss: 1.4504108428955078\n",
      "Ep 13: Batch #84 - Loss: 0.5976437926292419\n",
      "Ep 13: Batch #85 - Loss: 0.8244364261627197\n",
      "Ep 13: Batch #86 - Loss: 0.5698978900909424\n",
      "Ep 13: Batch #87 - Loss: 0.5841851830482483\n",
      "Ep 13: Batch #88 - Loss: 0.6652423143386841\n",
      "Ep 13: Batch #89 - Loss: 0.7721790075302124\n",
      "Ep 13: Batch #90 - Loss: 0.9263530373573303\n",
      "Ep 13: Batch #91 - Loss: 0.656989574432373\n",
      "Ep 13: Batch #92 - Loss: 0.8123267292976379\n",
      "Ep 13: Batch #93 - Loss: 0.812645435333252\n",
      "Ep 13: Batch #94 - Loss: 0.8135247826576233\n",
      "Ep 13: Batch #95 - Loss: 0.770305871963501\n",
      "Ep 13: Batch #96 - Loss: 0.7728540897369385\n",
      "Ep 13: Batch #97 - Loss: 0.5965263843536377\n",
      "Ep 13: Batch #98 - Loss: 0.596615731716156\n",
      "Ep 13: Batch #99 - Loss: 0.8126041293144226\n",
      "Ep 13: Batch #100 - Loss: 0.5694418549537659\n",
      "Ep 13: Batch #101 - Loss: 0.8739402890205383\n",
      "Ep 13: Batch #102 - Loss: 0.6374202966690063\n",
      "Ep 13: Batch #103 - Loss: 0.6523764133453369\n",
      "Ep 13: Batch #104 - Loss: 0.6731069684028625\n",
      "Ep 13: Batch #105 - Loss: 0.8325995206832886\n",
      "Ep 13: Batch #106 - Loss: 0.6383002400398254\n",
      "Ep 13: Batch #107 - Loss: 0.6173757314682007\n",
      "Ep 13: Batch #108 - Loss: 0.9074582457542419\n",
      "Ep 13: Batch #109 - Loss: 0.6445978879928589\n",
      "Ep 13: Batch #110 - Loss: 0.7391141653060913\n",
      "Ep 13: Batch #111 - Loss: 1.0832735300064087\n",
      "Ep 13: Batch #112 - Loss: 0.8492181301116943\n",
      "Ep 13: Batch #113 - Loss: 0.6691970229148865\n",
      "Ep 13: Batch #114 - Loss: 0.748168408870697\n",
      "Ep 13: Batch #115 - Loss: 0.9164894819259644\n",
      "Ep 13: Batch #116 - Loss: 0.5353705286979675\n",
      "Ep 13: Batch #117 - Loss: 0.7185795903205872\n",
      "Ep 13: Batch #118 - Loss: 0.46216583251953125\n",
      "Ep 13: Batch #119 - Loss: 0.8244897723197937\n",
      "Ep 13: Batch #120 - Loss: 0.6719721555709839\n",
      "Ep 13: Batch #121 - Loss: 0.5717521905899048\n",
      "Ep 13: Batch #122 - Loss: 0.7225930690765381\n",
      "Ep 13: Batch #123 - Loss: 0.734866201877594\n",
      "Ep 13: Batch #124 - Loss: 0.5642257928848267\n",
      "Ep 13: Batch #125 - Loss: 2.4794952869415283\n",
      "Ep 13: Batch #126 - Loss: 1.0050338506698608\n",
      "Ep 13: Batch #127 - Loss: 0.5934873223304749\n",
      "Ep 13: Batch #128 - Loss: 0.8968910574913025\n",
      "Ep 13: Batch #129 - Loss: 0.6862900257110596\n",
      "Ep 13: Batch #130 - Loss: 0.6094549894332886\n",
      "Ep 13: Batch #131 - Loss: 0.8120107054710388\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 13: Batch #132 - Loss: 0.6988333463668823\n",
      "Ep 13: Batch #133 - Loss: 0.6778251528739929\n",
      "Ep 13: Batch #134 - Loss: 0.6601073145866394\n",
      "Ep 13: Batch #135 - Loss: 0.832595944404602\n",
      "Ep 13: Batch #136 - Loss: 1.0528920888900757\n",
      "Ep 13: Batch #137 - Loss: 0.7665655016899109\n",
      "Ep 13: Batch #138 - Loss: 0.9181837439537048\n",
      "Ep 13: Batch #139 - Loss: 0.7126950621604919\n",
      "Ep 13: Batch #140 - Loss: 0.8837846517562866\n",
      "Ep 13: Batch #141 - Loss: 1.1569751501083374\n",
      "Ep 13: Batch #142 - Loss: 0.6839202642440796\n",
      "Ep 13: Batch #143 - Loss: 0.7852222323417664\n",
      "Ep 13: Batch #144 - Loss: 0.6201769113540649\n",
      "Ep 13: Batch #145 - Loss: 0.6015942096710205\n",
      "Ep 13: Batch #146 - Loss: 0.7352704405784607\n",
      "Ep 13: Batch #147 - Loss: 0.7107782363891602\n",
      "Ep 13: Batch #148 - Loss: 0.7867076992988586\n",
      "Ep 13: Batch #149 - Loss: 0.689489483833313\n",
      "Ep 13: Batch #150 - Loss: 0.7431391477584839\n",
      "Ep 13: Batch #151 - Loss: 0.6444857716560364\n",
      "Ep 13: Batch #152 - Loss: 0.6210603713989258\n",
      "Ep 13: Batch #153 - Loss: 0.8688653111457825\n",
      "Ep 13: Batch #154 - Loss: 0.642703652381897\n",
      "Ep 13: Batch #155 - Loss: 0.7128722667694092\n",
      "Ep 13: Batch #156 - Loss: 0.8416659235954285\n",
      "Ep 13: Batch #157 - Loss: 0.6382408738136292\n",
      "Ep 13: Batch #158 - Loss: 0.727745532989502\n",
      "Ep 13: Batch #159 - Loss: 0.647151529788971\n",
      "Ep 13: Batch #160 - Loss: 0.7373976111412048\n",
      "Ep 13: Batch #161 - Loss: 0.689935028553009\n",
      "Ep 13: Batch #162 - Loss: 0.7439033389091492\n",
      "Ep 13: Batch #163 - Loss: 0.7938938140869141\n",
      "Ep 13: Batch #164 - Loss: 0.6672791838645935\n",
      "Ep 13: Batch #165 - Loss: 1.3580613136291504\n",
      "Ep 13: Batch #166 - Loss: 0.5537397861480713\n",
      "Ep 13: Batch #167 - Loss: 0.8496248126029968\n",
      "Ep 13: Batch #168 - Loss: 0.7102190256118774\n",
      "Ep 13: Batch #169 - Loss: 0.6887329816818237\n",
      "Ep 13: Batch #170 - Loss: 0.6592532992362976\n",
      "Ep 13: Batch #171 - Loss: 0.6555268168449402\n",
      "Ep 13: Batch #172 - Loss: 0.5441516637802124\n",
      "Ep 13: Batch #173 - Loss: 0.9799643754959106\n",
      "Ep 13: Batch #174 - Loss: 0.5047091841697693\n",
      "Ep 13: Batch #175 - Loss: 0.660121500492096\n",
      "Ep 13: Batch #176 - Loss: 0.9343430995941162\n",
      "Ep 13: Batch #177 - Loss: 0.6832437515258789\n",
      "Ep 13: Batch #178 - Loss: 0.6496049761772156\n",
      "Ep 13: Batch #179 - Loss: 0.7632017135620117\n",
      "Ep 13: Batch #180 - Loss: 0.6704918146133423\n",
      "Ep 13: Batch #181 - Loss: 0.8260498046875\n",
      "Ep 13: Batch #182 - Loss: 0.6383379697799683\n",
      "Ep 13: Batch #183 - Loss: 0.6358036994934082\n",
      "Ep 13: Batch #184 - Loss: 0.9315089583396912\n",
      "Ep 13: Batch #185 - Loss: 0.6476245522499084\n",
      "Ep 13: Batch #186 - Loss: 0.7914391756057739\n",
      "Ep 13: Batch #187 - Loss: 0.9137646555900574\n",
      "Ep 13: Batch #188 - Loss: 1.0547386407852173\n",
      "Ep 13: Batch #189 - Loss: 0.5989099740982056\n",
      "Ep 13: Batch #190 - Loss: 0.6341750621795654\n",
      "Ep 13: Batch #191 - Loss: 0.8445315361022949\n",
      "Ep 13: Batch #192 - Loss: 0.5798931121826172\n",
      "Ep 13: Batch #193 - Loss: 0.6359914541244507\n",
      "Ep 13: Batch #194 - Loss: 0.5764964818954468\n",
      "Ep 13: Batch #195 - Loss: 0.8037090301513672\n",
      "Ep 13: Batch #196 - Loss: 0.708149790763855\n",
      "Ep 13: Batch #197 - Loss: 0.7296333312988281\n",
      "Ep 13: Batch #198 - Loss: 0.5478255152702332\n",
      "Ep 13: Batch #199 - Loss: 0.6683660745620728\n",
      "Ep 14: Batch #0 - Loss: 0.6615710854530334\n",
      "Ep 14: Batch #1 - Loss: 0.7274437546730042\n",
      "Ep 14: Batch #2 - Loss: 0.8741190433502197\n",
      "Ep 14: Batch #3 - Loss: 0.7314257025718689\n",
      "Ep 14: Batch #4 - Loss: 0.6632634401321411\n",
      "Ep 14: Batch #5 - Loss: 0.5773860216140747\n",
      "Ep 14: Batch #6 - Loss: 0.7547421455383301\n",
      "Ep 14: Batch #7 - Loss: 0.6001952886581421\n",
      "Ep 14: Batch #8 - Loss: 0.6021285653114319\n",
      "Ep 14: Batch #9 - Loss: 1.1260411739349365\n",
      "Ep 14: Batch #10 - Loss: 0.8590136766433716\n",
      "Ep 14: Batch #11 - Loss: 0.5542430281639099\n",
      "Ep 14: Batch #12 - Loss: 1.2839797735214233\n",
      "Ep 14: Batch #13 - Loss: 0.5834853053092957\n",
      "Ep 14: Batch #14 - Loss: 0.6076173782348633\n",
      "Ep 14: Batch #15 - Loss: 0.9469578266143799\n",
      "Ep 14: Batch #16 - Loss: 1.0070805549621582\n",
      "Ep 14: Batch #17 - Loss: 0.7428154945373535\n",
      "Ep 14: Batch #18 - Loss: 0.8162561655044556\n",
      "Ep 14: Batch #19 - Loss: 0.5719537734985352\n",
      "Ep 14: Batch #20 - Loss: 0.559319794178009\n",
      "Ep 14: Batch #21 - Loss: 0.9518624544143677\n",
      "Ep 14: Batch #22 - Loss: 0.6227344870567322\n",
      "Ep 14: Batch #23 - Loss: 0.6166092753410339\n",
      "Ep 14: Batch #24 - Loss: 0.6629619598388672\n",
      "Ep 14: Batch #25 - Loss: 0.6274939775466919\n",
      "Ep 14: Batch #26 - Loss: 0.6068615913391113\n",
      "Ep 14: Batch #27 - Loss: 1.1542264223098755\n",
      "Ep 14: Batch #28 - Loss: 0.7068408131599426\n",
      "Ep 14: Batch #29 - Loss: 0.7708274126052856\n",
      "Ep 14: Batch #30 - Loss: 0.9285556077957153\n",
      "Ep 14: Batch #31 - Loss: 0.5687974095344543\n",
      "Ep 14: Batch #32 - Loss: 0.5967799425125122\n",
      "Ep 14: Batch #33 - Loss: 0.6845889687538147\n",
      "Ep 14: Batch #34 - Loss: 0.6597903370857239\n",
      "Ep 14: Batch #35 - Loss: 0.7576401829719543\n",
      "Ep 14: Batch #36 - Loss: 0.5905963182449341\n",
      "Ep 14: Batch #37 - Loss: 0.9377536177635193\n",
      "Ep 14: Batch #38 - Loss: 0.5866149663925171\n",
      "Ep 14: Batch #39 - Loss: 0.6976946592330933\n",
      "Ep 14: Batch #40 - Loss: 0.6231344938278198\n",
      "Ep 14: Batch #41 - Loss: 0.628810465335846\n",
      "Ep 14: Batch #42 - Loss: 0.583000659942627\n",
      "Ep 14: Batch #43 - Loss: 0.6505014896392822\n",
      "Ep 14: Batch #44 - Loss: 0.6420125961303711\n",
      "Ep 14: Batch #45 - Loss: 0.5397982597351074\n",
      "Ep 14: Batch #46 - Loss: 0.7065240144729614\n",
      "Ep 14: Batch #47 - Loss: 0.8174468278884888\n",
      "Ep 14: Batch #48 - Loss: 1.0848780870437622\n",
      "Ep 14: Batch #49 - Loss: 0.8249037861824036\n",
      "Ep 14: Batch #50 - Loss: 0.5801104307174683\n",
      "Ep 14: Batch #51 - Loss: 0.8272043466567993\n",
      "Ep 14: Batch #52 - Loss: 0.6873416900634766\n",
      "Ep 14: Batch #53 - Loss: 0.7220378518104553\n",
      "Ep 14: Batch #54 - Loss: 0.598649799823761\n",
      "Ep 14: Batch #55 - Loss: 0.6297877430915833\n",
      "Ep 14: Batch #56 - Loss: 0.9250332117080688\n",
      "Ep 14: Batch #57 - Loss: 0.6906909942626953\n",
      "Ep 14: Batch #58 - Loss: 0.8425818085670471\n",
      "Ep 14: Batch #59 - Loss: 0.5763205885887146\n",
      "Ep 14: Batch #60 - Loss: 1.052255392074585\n",
      "Ep 14: Batch #61 - Loss: 0.5416553020477295\n",
      "Ep 14: Batch #62 - Loss: 0.5956282019615173\n",
      "Ep 14: Batch #63 - Loss: 0.8057775497436523\n",
      "Ep 14: Batch #64 - Loss: 8.827290534973145\n",
      "Ep 14: Batch #65 - Loss: 0.5320985913276672\n",
      "Ep 14: Batch #66 - Loss: 0.6822714805603027\n",
      "Ep 14: Batch #67 - Loss: 0.7872692346572876\n",
      "Ep 14: Batch #68 - Loss: 0.7459135055541992\n",
      "Ep 14: Batch #69 - Loss: 0.6195337176322937\n",
      "Ep 14: Batch #70 - Loss: 0.6291956901550293\n",
      "Ep 14: Batch #71 - Loss: 0.5528124570846558\n",
      "Ep 14: Batch #72 - Loss: 0.6757385730743408\n",
      "Ep 14: Batch #73 - Loss: 0.7618062496185303\n",
      "Ep 14: Batch #74 - Loss: 0.5998720526695251\n",
      "Ep 14: Batch #75 - Loss: 0.6732897758483887\n",
      "Ep 14: Batch #76 - Loss: 0.9591895937919617\n",
      "Ep 14: Batch #77 - Loss: 0.60328209400177\n",
      "Ep 14: Batch #78 - Loss: 0.9495139122009277\n",
      "Ep 14: Batch #79 - Loss: 0.5386502742767334\n",
      "Ep 14: Batch #80 - Loss: 0.7154908180236816\n",
      "Ep 14: Batch #81 - Loss: 1.5393683910369873\n",
      "Ep 14: Batch #82 - Loss: 0.7573390007019043\n",
      "Ep 14: Batch #83 - Loss: 1.4422343969345093\n",
      "Ep 14: Batch #84 - Loss: 0.5955807566642761\n",
      "Ep 14: Batch #85 - Loss: 0.8210500478744507\n",
      "Ep 14: Batch #86 - Loss: 0.5671418905258179\n",
      "Ep 14: Batch #87 - Loss: 0.5840922594070435\n",
      "Ep 14: Batch #88 - Loss: 0.6635234355926514\n",
      "Ep 14: Batch #89 - Loss: 0.7683363556861877\n",
      "Ep 14: Batch #90 - Loss: 0.9223573207855225\n",
      "Ep 14: Batch #91 - Loss: 0.6558135151863098\n",
      "Ep 14: Batch #92 - Loss: 0.8046053051948547\n",
      "Ep 14: Batch #93 - Loss: 0.8090198040008545\n",
      "Ep 14: Batch #94 - Loss: 0.8091315627098083\n",
      "Ep 14: Batch #95 - Loss: 0.769400417804718\n",
      "Ep 14: Batch #96 - Loss: 0.7709315419197083\n",
      "Ep 14: Batch #97 - Loss: 0.594412088394165\n",
      "Ep 14: Batch #98 - Loss: 0.5944349765777588\n",
      "Ep 14: Batch #99 - Loss: 0.8111229538917542\n",
      "Ep 14: Batch #100 - Loss: 0.5678005814552307\n",
      "Ep 14: Batch #101 - Loss: 0.8718321323394775\n",
      "Ep 14: Batch #102 - Loss: 0.6352975964546204\n",
      "Ep 14: Batch #103 - Loss: 0.6507172584533691\n",
      "Ep 14: Batch #104 - Loss: 0.6717784404754639\n",
      "Ep 14: Batch #105 - Loss: 0.830806314945221\n",
      "Ep 14: Batch #106 - Loss: 0.6367388963699341\n",
      "Ep 14: Batch #107 - Loss: 0.616759181022644\n",
      "Ep 14: Batch #108 - Loss: 0.9073964953422546\n",
      "Ep 14: Batch #109 - Loss: 0.64137202501297\n",
      "Ep 14: Batch #110 - Loss: 0.7382579445838928\n",
      "Ep 14: Batch #111 - Loss: 1.0780552625656128\n",
      "Ep 14: Batch #112 - Loss: 0.8490784764289856\n",
      "Ep 14: Batch #113 - Loss: 0.667759895324707\n",
      "Ep 14: Batch #114 - Loss: 0.7451522946357727\n",
      "Ep 14: Batch #115 - Loss: 0.9146118760108948\n",
      "Ep 14: Batch #116 - Loss: 0.5352152585983276\n",
      "Ep 14: Batch #117 - Loss: 0.7145209908485413\n",
      "Ep 14: Batch #118 - Loss: 0.46257221698760986\n",
      "Ep 14: Batch #119 - Loss: 0.8225346803665161\n",
      "Ep 14: Batch #120 - Loss: 0.6707227230072021\n",
      "Ep 14: Batch #121 - Loss: 0.5712198615074158\n",
      "Ep 14: Batch #122 - Loss: 0.7204205393791199\n",
      "Ep 14: Batch #123 - Loss: 0.733514666557312\n",
      "Ep 14: Batch #124 - Loss: 0.5632303357124329\n",
      "Ep 14: Batch #125 - Loss: 2.475520372390747\n",
      "Ep 14: Batch #126 - Loss: 1.0033589601516724\n",
      "Ep 14: Batch #127 - Loss: 0.5922126770019531\n",
      "Ep 14: Batch #128 - Loss: 0.8935244679450989\n",
      "Ep 14: Batch #129 - Loss: 0.6867474913597107\n",
      "Ep 14: Batch #130 - Loss: 0.6075693368911743\n",
      "Ep 14: Batch #131 - Loss: 0.8104826211929321\n",
      "Ep 14: Batch #132 - Loss: 0.6966266632080078\n",
      "Ep 14: Batch #133 - Loss: 0.676186203956604\n",
      "Ep 14: Batch #134 - Loss: 0.6580366492271423\n",
      "Ep 14: Batch #135 - Loss: 0.8303942680358887\n",
      "Ep 14: Batch #136 - Loss: 1.05193030834198\n",
      "Ep 14: Batch #137 - Loss: 0.7648360133171082\n",
      "Ep 14: Batch #138 - Loss: 0.9145177006721497\n",
      "Ep 14: Batch #139 - Loss: 0.7098332047462463\n",
      "Ep 14: Batch #140 - Loss: 0.8795281052589417\n",
      "Ep 14: Batch #141 - Loss: 1.1542420387268066\n",
      "Ep 14: Batch #142 - Loss: 0.6826794743537903\n",
      "Ep 14: Batch #143 - Loss: 0.7822656035423279\n",
      "Ep 14: Batch #144 - Loss: 0.6187629103660583\n",
      "Ep 14: Batch #145 - Loss: 0.6017636060714722\n",
      "Ep 14: Batch #146 - Loss: 0.7320904731750488\n",
      "Ep 14: Batch #147 - Loss: 0.7057632207870483\n",
      "Ep 14: Batch #148 - Loss: 0.7838556170463562\n",
      "Ep 14: Batch #149 - Loss: 0.6854210495948792\n",
      "Ep 14: Batch #150 - Loss: 0.7397698760032654\n",
      "Ep 14: Batch #151 - Loss: 0.6434656977653503\n",
      "Ep 14: Batch #152 - Loss: 0.6189154386520386\n",
      "Ep 14: Batch #153 - Loss: 0.8646117448806763\n",
      "Ep 14: Batch #154 - Loss: 0.6408100128173828\n",
      "Ep 14: Batch #155 - Loss: 0.7091388702392578\n",
      "Ep 14: Batch #156 - Loss: 0.8378280997276306\n",
      "Ep 14: Batch #157 - Loss: 0.6355672478675842\n",
      "Ep 14: Batch #158 - Loss: 0.7266662120819092\n",
      "Ep 14: Batch #159 - Loss: 0.6434580087661743\n",
      "Ep 14: Batch #160 - Loss: 0.7333940267562866\n",
      "Ep 14: Batch #161 - Loss: 0.6875737309455872\n",
      "Ep 14: Batch #162 - Loss: 0.7411155700683594\n",
      "Ep 14: Batch #163 - Loss: 0.7900983095169067\n",
      "Ep 14: Batch #164 - Loss: 0.6652457118034363\n",
      "Ep 14: Batch #165 - Loss: 1.3568134307861328\n",
      "Ep 14: Batch #166 - Loss: 0.5512927770614624\n",
      "Ep 14: Batch #167 - Loss: 0.841829776763916\n",
      "Ep 14: Batch #168 - Loss: 0.707796573638916\n",
      "Ep 14: Batch #169 - Loss: 0.6867964863777161\n",
      "Ep 14: Batch #170 - Loss: 0.6563824415206909\n",
      "Ep 14: Batch #171 - Loss: 0.6527365446090698\n",
      "Ep 14: Batch #172 - Loss: 0.5424872636795044\n",
      "Ep 14: Batch #173 - Loss: 0.9720407128334045\n",
      "Ep 14: Batch #174 - Loss: 0.503532350063324\n",
      "Ep 14: Batch #175 - Loss: 0.6577979922294617\n",
      "Ep 14: Batch #176 - Loss: 0.9287754893302917\n",
      "Ep 14: Batch #177 - Loss: 0.6801183819770813\n",
      "Ep 14: Batch #178 - Loss: 0.6480755805969238\n",
      "Ep 14: Batch #179 - Loss: 0.761388897895813\n",
      "Ep 14: Batch #180 - Loss: 0.6683592200279236\n",
      "Ep 14: Batch #181 - Loss: 0.8236917853355408\n",
      "Ep 14: Batch #182 - Loss: 0.636222779750824\n",
      "Ep 14: Batch #183 - Loss: 0.6318888068199158\n",
      "Ep 14: Batch #184 - Loss: 0.9293364882469177\n",
      "Ep 14: Batch #185 - Loss: 0.6451708078384399\n",
      "Ep 14: Batch #186 - Loss: 0.7905144095420837\n",
      "Ep 14: Batch #187 - Loss: 0.9100508093833923\n",
      "Ep 14: Batch #188 - Loss: 1.0503313541412354\n",
      "Ep 14: Batch #189 - Loss: 0.5976384282112122\n",
      "Ep 14: Batch #190 - Loss: 0.6326526403427124\n",
      "Ep 14: Batch #191 - Loss: 0.8392702341079712\n",
      "Ep 14: Batch #192 - Loss: 0.5787385106086731\n",
      "Ep 14: Batch #193 - Loss: 0.6341720223426819\n",
      "Ep 14: Batch #194 - Loss: 0.5730230808258057\n",
      "Ep 14: Batch #195 - Loss: 0.8039774298667908\n",
      "Ep 14: Batch #196 - Loss: 0.7054322361946106\n",
      "Ep 14: Batch #197 - Loss: 0.7259398698806763\n",
      "Ep 14: Batch #198 - Loss: 0.5458848476409912\n",
      "Ep 14: Batch #199 - Loss: 0.6653807163238525\n",
      "Ep 15: Batch #0 - Loss: 0.6593774557113647\n",
      "Ep 15: Batch #1 - Loss: 0.7254125475883484\n",
      "Ep 15: Batch #2 - Loss: 0.872589647769928\n",
      "Ep 15: Batch #3 - Loss: 0.7298536896705627\n",
      "Ep 15: Batch #4 - Loss: 0.662594199180603\n",
      "Ep 15: Batch #5 - Loss: 0.5754620432853699\n",
      "Ep 15: Batch #6 - Loss: 0.7532520294189453\n",
      "Ep 15: Batch #7 - Loss: 0.5976979732513428\n",
      "Ep 15: Batch #8 - Loss: 0.5999773740768433\n",
      "Ep 15: Batch #9 - Loss: 1.1215158700942993\n",
      "Ep 15: Batch #10 - Loss: 0.8535762429237366\n",
      "Ep 15: Batch #11 - Loss: 0.5528836250305176\n",
      "Ep 15: Batch #12 - Loss: 1.2752647399902344\n",
      "Ep 15: Batch #13 - Loss: 0.5821024775505066\n",
      "Ep 15: Batch #14 - Loss: 0.6074003577232361\n",
      "Ep 15: Batch #15 - Loss: 0.9407801628112793\n",
      "Ep 15: Batch #16 - Loss: 0.9994189739227295\n",
      "Ep 15: Batch #17 - Loss: 0.7398625016212463\n",
      "Ep 15: Batch #18 - Loss: 0.8143134713172913\n",
      "Ep 15: Batch #19 - Loss: 0.570380687713623\n",
      "Ep 15: Batch #20 - Loss: 0.5578464269638062\n",
      "Ep 15: Batch #21 - Loss: 0.9435650110244751\n",
      "Ep 15: Batch #22 - Loss: 0.6213095188140869\n",
      "Ep 15: Batch #23 - Loss: 0.6156362891197205\n",
      "Ep 15: Batch #24 - Loss: 0.6595343351364136\n",
      "Ep 15: Batch #25 - Loss: 0.624602735042572\n",
      "Ep 15: Batch #26 - Loss: 0.6014600992202759\n",
      "Ep 15: Batch #27 - Loss: 1.1531143188476562\n",
      "Ep 15: Batch #28 - Loss: 0.7050840854644775\n",
      "Ep 15: Batch #29 - Loss: 0.7686760425567627\n",
      "Ep 15: Batch #30 - Loss: 0.9234165549278259\n",
      "Ep 15: Batch #31 - Loss: 0.5681703686714172\n",
      "Ep 15: Batch #32 - Loss: 0.5946546792984009\n",
      "Ep 15: Batch #33 - Loss: 0.682611346244812\n",
      "Ep 15: Batch #34 - Loss: 0.6586630344390869\n",
      "Ep 15: Batch #35 - Loss: 0.7525970339775085\n",
      "Ep 15: Batch #36 - Loss: 0.5887907147407532\n",
      "Ep 15: Batch #37 - Loss: 0.9356774687767029\n",
      "Ep 15: Batch #38 - Loss: 0.5854247808456421\n",
      "Ep 15: Batch #39 - Loss: 0.696520209312439\n",
      "Ep 15: Batch #40 - Loss: 0.6212478876113892\n",
      "Ep 15: Batch #41 - Loss: 0.627024233341217\n",
      "Ep 15: Batch #42 - Loss: 0.5811371207237244\n",
      "Ep 15: Batch #43 - Loss: 0.6481577754020691\n",
      "Ep 15: Batch #44 - Loss: 0.6388364434242249\n",
      "Ep 15: Batch #45 - Loss: 0.5378744602203369\n",
      "Ep 15: Batch #46 - Loss: 0.7049253582954407\n",
      "Ep 15: Batch #47 - Loss: 0.8140292763710022\n",
      "Ep 15: Batch #48 - Loss: 1.0787906646728516\n",
      "Ep 15: Batch #49 - Loss: 0.8225464820861816\n",
      "Ep 15: Batch #50 - Loss: 0.5778018832206726\n",
      "Ep 15: Batch #51 - Loss: 0.8252545595169067\n",
      "Ep 15: Batch #52 - Loss: 0.6854710578918457\n",
      "Ep 15: Batch #53 - Loss: 0.7217530012130737\n",
      "Ep 15: Batch #54 - Loss: 0.5962584614753723\n",
      "Ep 15: Batch #55 - Loss: 0.6277905702590942\n",
      "Ep 15: Batch #56 - Loss: 0.9201641082763672\n",
      "Ep 15: Batch #57 - Loss: 0.6902003288269043\n",
      "Ep 15: Batch #58 - Loss: 0.8430408239364624\n",
      "Ep 15: Batch #59 - Loss: 0.5747054219245911\n",
      "Ep 15: Batch #60 - Loss: 1.0466376543045044\n",
      "Ep 15: Batch #61 - Loss: 0.5400353074073792\n",
      "Ep 15: Batch #62 - Loss: 0.5938231348991394\n",
      "Ep 15: Batch #63 - Loss: 0.8039763569831848\n",
      "Ep 15: Batch #64 - Loss: 8.8110933303833\n",
      "Ep 15: Batch #65 - Loss: 0.5315524339675903\n",
      "Ep 15: Batch #66 - Loss: 0.6809889078140259\n",
      "Ep 15: Batch #67 - Loss: 0.7855183482170105\n",
      "Ep 15: Batch #68 - Loss: 0.7442492842674255\n",
      "Ep 15: Batch #69 - Loss: 0.6165195107460022\n",
      "Ep 15: Batch #70 - Loss: 0.6269100308418274\n",
      "Ep 15: Batch #71 - Loss: 0.550545871257782\n",
      "Ep 15: Batch #72 - Loss: 0.6733167767524719\n",
      "Ep 15: Batch #73 - Loss: 0.7581210732460022\n",
      "Ep 15: Batch #74 - Loss: 0.5976976156234741\n",
      "Ep 15: Batch #75 - Loss: 0.6723880767822266\n",
      "Ep 15: Batch #76 - Loss: 0.9552958011627197\n",
      "Ep 15: Batch #77 - Loss: 0.5993737578392029\n",
      "Ep 15: Batch #78 - Loss: 0.9461755156517029\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 15: Batch #79 - Loss: 0.5370499491691589\n",
      "Ep 15: Batch #80 - Loss: 0.7120561599731445\n",
      "Ep 15: Batch #81 - Loss: 1.5389002561569214\n",
      "Ep 15: Batch #82 - Loss: 0.7566885352134705\n",
      "Ep 15: Batch #83 - Loss: 1.4352506399154663\n",
      "Ep 15: Batch #84 - Loss: 0.5916801691055298\n",
      "Ep 15: Batch #85 - Loss: 0.817359209060669\n",
      "Ep 15: Batch #86 - Loss: 0.5647398233413696\n",
      "Ep 15: Batch #87 - Loss: 0.5833304524421692\n",
      "Ep 15: Batch #88 - Loss: 0.6620210409164429\n",
      "Ep 15: Batch #89 - Loss: 0.7637523412704468\n",
      "Ep 15: Batch #90 - Loss: 0.9168585538864136\n",
      "Ep 15: Batch #91 - Loss: 0.6538740396499634\n",
      "Ep 15: Batch #92 - Loss: 0.7968617677688599\n",
      "Ep 15: Batch #93 - Loss: 0.8050295114517212\n",
      "Ep 15: Batch #94 - Loss: 0.8051868677139282\n",
      "Ep 15: Batch #95 - Loss: 0.7689628005027771\n",
      "Ep 15: Batch #96 - Loss: 0.7689186930656433\n",
      "Ep 15: Batch #97 - Loss: 0.5923641324043274\n",
      "Ep 15: Batch #98 - Loss: 0.5923597812652588\n",
      "Ep 15: Batch #99 - Loss: 0.8097240924835205\n",
      "Ep 15: Batch #100 - Loss: 0.566230297088623\n",
      "Ep 15: Batch #101 - Loss: 0.8700172305107117\n",
      "Ep 15: Batch #102 - Loss: 0.6340473294258118\n",
      "Ep 15: Batch #103 - Loss: 0.6488839387893677\n",
      "Ep 15: Batch #104 - Loss: 0.6702604293823242\n",
      "Ep 15: Batch #105 - Loss: 0.828452467918396\n",
      "Ep 15: Batch #106 - Loss: 0.634834885597229\n",
      "Ep 15: Batch #107 - Loss: 0.6161244511604309\n",
      "Ep 15: Batch #108 - Loss: 0.9069725275039673\n",
      "Ep 15: Batch #109 - Loss: 0.6389155387878418\n",
      "Ep 15: Batch #110 - Loss: 0.7374286651611328\n",
      "Ep 15: Batch #111 - Loss: 1.0753663778305054\n",
      "Ep 15: Batch #112 - Loss: 0.8482886552810669\n",
      "Ep 15: Batch #113 - Loss: 0.6664217114448547\n",
      "Ep 15: Batch #114 - Loss: 0.7424125075340271\n",
      "Ep 15: Batch #115 - Loss: 0.9136524796485901\n",
      "Ep 15: Batch #116 - Loss: 0.5347449779510498\n",
      "Ep 15: Batch #117 - Loss: 0.7105582356452942\n",
      "Ep 15: Batch #118 - Loss: 0.4624207615852356\n",
      "Ep 15: Batch #119 - Loss: 0.819425642490387\n",
      "Ep 15: Batch #120 - Loss: 0.6696213483810425\n",
      "Ep 15: Batch #121 - Loss: 0.5716213583946228\n",
      "Ep 15: Batch #122 - Loss: 0.719033420085907\n",
      "Ep 15: Batch #123 - Loss: 0.7315399646759033\n",
      "Ep 15: Batch #124 - Loss: 0.5621438026428223\n",
      "Ep 15: Batch #125 - Loss: 2.4737436771392822\n",
      "Ep 15: Batch #126 - Loss: 1.001887559890747\n",
      "Ep 15: Batch #127 - Loss: 0.5909344553947449\n",
      "Ep 15: Batch #128 - Loss: 0.8911606669425964\n",
      "Ep 15: Batch #129 - Loss: 0.6873614192008972\n",
      "Ep 15: Batch #130 - Loss: 0.6064456701278687\n",
      "Ep 15: Batch #131 - Loss: 0.8090665936470032\n",
      "Ep 15: Batch #132 - Loss: 0.6948003768920898\n",
      "Ep 15: Batch #133 - Loss: 0.6746966242790222\n",
      "Ep 15: Batch #134 - Loss: 0.6555631160736084\n",
      "Ep 15: Batch #135 - Loss: 0.8289345502853394\n",
      "Ep 15: Batch #136 - Loss: 1.0511345863342285\n",
      "Ep 15: Batch #137 - Loss: 0.7633043527603149\n",
      "Ep 15: Batch #138 - Loss: 0.9109379649162292\n",
      "Ep 15: Batch #139 - Loss: 0.7066819071769714\n",
      "Ep 15: Batch #140 - Loss: 0.8754308819770813\n",
      "Ep 15: Batch #141 - Loss: 1.1511691808700562\n",
      "Ep 15: Batch #142 - Loss: 0.6817129254341125\n",
      "Ep 15: Batch #143 - Loss: 0.7796712517738342\n",
      "Ep 15: Batch #144 - Loss: 0.6176570057868958\n",
      "Ep 15: Batch #145 - Loss: 0.601864755153656\n",
      "Ep 15: Batch #146 - Loss: 0.7282016277313232\n",
      "Ep 15: Batch #147 - Loss: 0.7005779147148132\n",
      "Ep 15: Batch #148 - Loss: 0.7801978588104248\n",
      "Ep 15: Batch #149 - Loss: 0.6804664134979248\n",
      "Ep 15: Batch #150 - Loss: 0.736733078956604\n",
      "Ep 15: Batch #151 - Loss: 0.6417705416679382\n",
      "Ep 15: Batch #152 - Loss: 0.6171662211418152\n",
      "Ep 15: Batch #153 - Loss: 0.8610778450965881\n",
      "Ep 15: Batch #154 - Loss: 0.639320969581604\n",
      "Ep 15: Batch #155 - Loss: 0.7059586048126221\n",
      "Ep 15: Batch #156 - Loss: 0.8336766958236694\n",
      "Ep 15: Batch #157 - Loss: 0.6323341131210327\n",
      "Ep 15: Batch #158 - Loss: 0.7251160740852356\n",
      "Ep 15: Batch #159 - Loss: 0.6396843791007996\n",
      "Ep 15: Batch #160 - Loss: 0.7292649149894714\n",
      "Ep 15: Batch #161 - Loss: 0.685093104839325\n",
      "Ep 15: Batch #162 - Loss: 0.7385988831520081\n",
      "Ep 15: Batch #163 - Loss: 0.7863922119140625\n",
      "Ep 15: Batch #164 - Loss: 0.6628351211547852\n",
      "Ep 15: Batch #165 - Loss: 1.3548113107681274\n",
      "Ep 15: Batch #166 - Loss: 0.548233151435852\n",
      "Ep 15: Batch #167 - Loss: 0.8328668475151062\n",
      "Ep 15: Batch #168 - Loss: 0.705663800239563\n",
      "Ep 15: Batch #169 - Loss: 0.6846244931221008\n",
      "Ep 15: Batch #170 - Loss: 0.653319239616394\n",
      "Ep 15: Batch #171 - Loss: 0.6506239175796509\n",
      "Ep 15: Batch #172 - Loss: 0.54129558801651\n",
      "Ep 15: Batch #173 - Loss: 0.9653431177139282\n",
      "Ep 15: Batch #174 - Loss: 0.5020062327384949\n",
      "Ep 15: Batch #175 - Loss: 0.6564150452613831\n",
      "Ep 15: Batch #176 - Loss: 0.9239096641540527\n",
      "Ep 15: Batch #177 - Loss: 0.6765235066413879\n",
      "Ep 15: Batch #178 - Loss: 0.6458956003189087\n",
      "Ep 15: Batch #179 - Loss: 0.7600148320198059\n",
      "Ep 15: Batch #180 - Loss: 0.6663104891777039\n",
      "Ep 15: Batch #181 - Loss: 0.8209612965583801\n",
      "Ep 15: Batch #182 - Loss: 0.6347935199737549\n",
      "Ep 15: Batch #183 - Loss: 0.6284425258636475\n",
      "Ep 15: Batch #184 - Loss: 0.928016185760498\n",
      "Ep 15: Batch #185 - Loss: 0.6425387263298035\n",
      "Ep 15: Batch #186 - Loss: 0.7884094715118408\n",
      "Ep 15: Batch #187 - Loss: 0.9062190651893616\n",
      "Ep 15: Batch #188 - Loss: 1.0455018281936646\n",
      "Ep 15: Batch #189 - Loss: 0.5962663888931274\n",
      "Ep 15: Batch #190 - Loss: 0.6310283541679382\n",
      "Ep 15: Batch #191 - Loss: 0.8342911005020142\n",
      "Ep 15: Batch #192 - Loss: 0.5775888562202454\n",
      "Ep 15: Batch #193 - Loss: 0.632624089717865\n",
      "Ep 15: Batch #194 - Loss: 0.5696221590042114\n",
      "Ep 15: Batch #195 - Loss: 0.8036507964134216\n",
      "Ep 15: Batch #196 - Loss: 0.7035862803459167\n",
      "Ep 15: Batch #197 - Loss: 0.7222023010253906\n",
      "Ep 15: Batch #198 - Loss: 0.5442449450492859\n",
      "Ep 15: Batch #199 - Loss: 0.6627948880195618\n",
      "Ep 16: Batch #0 - Loss: 0.6577572822570801\n",
      "Ep 16: Batch #1 - Loss: 0.7236722707748413\n",
      "Ep 16: Batch #2 - Loss: 0.8713207840919495\n",
      "Ep 16: Batch #3 - Loss: 0.7282946109771729\n",
      "Ep 16: Batch #4 - Loss: 0.6619117259979248\n",
      "Ep 16: Batch #5 - Loss: 0.57420814037323\n",
      "Ep 16: Batch #6 - Loss: 0.7523202896118164\n",
      "Ep 16: Batch #7 - Loss: 0.595374584197998\n",
      "Ep 16: Batch #8 - Loss: 0.5982850193977356\n",
      "Ep 16: Batch #9 - Loss: 1.1166763305664062\n",
      "Ep 16: Batch #10 - Loss: 0.8488331437110901\n",
      "Ep 16: Batch #11 - Loss: 0.5517192482948303\n",
      "Ep 16: Batch #12 - Loss: 1.2670276165008545\n",
      "Ep 16: Batch #13 - Loss: 0.5806573629379272\n",
      "Ep 16: Batch #14 - Loss: 0.6069017052650452\n",
      "Ep 16: Batch #15 - Loss: 0.9337864518165588\n",
      "Ep 16: Batch #16 - Loss: 0.9917373657226562\n",
      "Ep 16: Batch #17 - Loss: 0.7377246618270874\n",
      "Ep 16: Batch #18 - Loss: 0.8126765489578247\n",
      "Ep 16: Batch #19 - Loss: 0.5689888000488281\n",
      "Ep 16: Batch #20 - Loss: 0.5559746623039246\n",
      "Ep 16: Batch #21 - Loss: 0.9350867867469788\n",
      "Ep 16: Batch #22 - Loss: 0.6198798418045044\n",
      "Ep 16: Batch #23 - Loss: 0.6136131882667542\n",
      "Ep 16: Batch #24 - Loss: 0.6565138101577759\n",
      "Ep 16: Batch #25 - Loss: 0.6220171451568604\n",
      "Ep 16: Batch #26 - Loss: 0.5967949628829956\n",
      "Ep 16: Batch #27 - Loss: 1.1515038013458252\n",
      "Ep 16: Batch #28 - Loss: 0.7033135294914246\n",
      "Ep 16: Batch #29 - Loss: 0.7666544318199158\n",
      "Ep 16: Batch #30 - Loss: 0.9191237688064575\n",
      "Ep 16: Batch #31 - Loss: 0.5675467848777771\n",
      "Ep 16: Batch #32 - Loss: 0.5928443074226379\n",
      "Ep 16: Batch #33 - Loss: 0.6806610822677612\n",
      "Ep 16: Batch #34 - Loss: 0.6570810079574585\n",
      "Ep 16: Batch #35 - Loss: 0.7481152415275574\n",
      "Ep 16: Batch #36 - Loss: 0.5875955820083618\n",
      "Ep 16: Batch #37 - Loss: 0.9337783455848694\n",
      "Ep 16: Batch #38 - Loss: 0.5844557881355286\n",
      "Ep 16: Batch #39 - Loss: 0.6942025423049927\n",
      "Ep 16: Batch #40 - Loss: 0.6194381713867188\n",
      "Ep 16: Batch #41 - Loss: 0.6257174015045166\n",
      "Ep 16: Batch #42 - Loss: 0.5791841149330139\n",
      "Ep 16: Batch #43 - Loss: 0.6464920043945312\n",
      "Ep 16: Batch #44 - Loss: 0.635715126991272\n",
      "Ep 16: Batch #45 - Loss: 0.5359439849853516\n",
      "Ep 16: Batch #46 - Loss: 0.7036527395248413\n",
      "Ep 16: Batch #47 - Loss: 0.8117958307266235\n",
      "Ep 16: Batch #48 - Loss: 1.0729789733886719\n",
      "Ep 16: Batch #49 - Loss: 0.8203462362289429\n",
      "Ep 16: Batch #50 - Loss: 0.5759690403938293\n",
      "Ep 16: Batch #51 - Loss: 0.8229761719703674\n",
      "Ep 16: Batch #52 - Loss: 0.6841250061988831\n",
      "Ep 16: Batch #53 - Loss: 0.7207788825035095\n",
      "Ep 16: Batch #54 - Loss: 0.5942791700363159\n",
      "Ep 16: Batch #55 - Loss: 0.6258871555328369\n",
      "Ep 16: Batch #56 - Loss: 0.9127190709114075\n",
      "Ep 16: Batch #57 - Loss: 0.6902629733085632\n",
      "Ep 16: Batch #58 - Loss: 0.8410184383392334\n",
      "Ep 16: Batch #59 - Loss: 0.5739573836326599\n",
      "Ep 16: Batch #60 - Loss: 1.040984869003296\n",
      "Ep 16: Batch #61 - Loss: 0.5390315651893616\n",
      "Ep 16: Batch #62 - Loss: 0.591151237487793\n",
      "Ep 16: Batch #63 - Loss: 0.8030069470405579\n",
      "Ep 16: Batch #64 - Loss: 8.801708221435547\n",
      "Ep 16: Batch #65 - Loss: 0.5309122204780579\n",
      "Ep 16: Batch #66 - Loss: 0.6804547309875488\n",
      "Ep 16: Batch #67 - Loss: 0.7845963835716248\n",
      "Ep 16: Batch #68 - Loss: 0.7440248727798462\n",
      "Ep 16: Batch #69 - Loss: 0.614244282245636\n",
      "Ep 16: Batch #70 - Loss: 0.6254454255104065\n",
      "Ep 16: Batch #71 - Loss: 0.549717128276825\n",
      "Ep 16: Batch #72 - Loss: 0.6746350526809692\n",
      "Ep 16: Batch #73 - Loss: 0.7564513087272644\n",
      "Ep 16: Batch #74 - Loss: 0.596729040145874\n",
      "Ep 16: Batch #75 - Loss: 0.6721746921539307\n",
      "Ep 16: Batch #76 - Loss: 0.9529938101768494\n",
      "Ep 16: Batch #77 - Loss: 0.5958303213119507\n",
      "Ep 16: Batch #78 - Loss: 0.9457299113273621\n",
      "Ep 16: Batch #79 - Loss: 0.5359671711921692\n",
      "Ep 16: Batch #80 - Loss: 0.7102828621864319\n",
      "Ep 16: Batch #81 - Loss: 1.5400639772415161\n",
      "Ep 16: Batch #82 - Loss: 0.757472813129425\n",
      "Ep 16: Batch #83 - Loss: 1.4266765117645264\n",
      "Ep 16: Batch #84 - Loss: 0.5903421640396118\n",
      "Ep 16: Batch #85 - Loss: 0.8159258365631104\n",
      "Ep 16: Batch #86 - Loss: 0.5635939836502075\n",
      "Ep 16: Batch #87 - Loss: 0.5819367170333862\n",
      "Ep 16: Batch #88 - Loss: 0.6618491411209106\n",
      "Ep 16: Batch #89 - Loss: 0.7607049942016602\n",
      "Ep 16: Batch #90 - Loss: 0.9130749702453613\n",
      "Ep 16: Batch #91 - Loss: 0.6523918509483337\n",
      "Ep 16: Batch #92 - Loss: 0.7910999059677124\n",
      "Ep 16: Batch #93 - Loss: 0.8027361035346985\n",
      "Ep 16: Batch #94 - Loss: 0.8014156818389893\n",
      "Ep 16: Batch #95 - Loss: 0.7704945802688599\n",
      "Ep 16: Batch #96 - Loss: 0.7676393985748291\n",
      "Ep 16: Batch #97 - Loss: 0.592918872833252\n",
      "Ep 16: Batch #98 - Loss: 0.591225802898407\n",
      "Ep 16: Batch #99 - Loss: 0.8084863424301147\n",
      "Ep 16: Batch #100 - Loss: 0.5656192302703857\n",
      "Ep 16: Batch #101 - Loss: 0.8687070608139038\n",
      "Ep 16: Batch #102 - Loss: 0.6330781579017639\n",
      "Ep 16: Batch #103 - Loss: 0.6478863954544067\n",
      "Ep 16: Batch #104 - Loss: 0.6692396402359009\n",
      "Ep 16: Batch #105 - Loss: 0.8271807432174683\n",
      "Ep 16: Batch #106 - Loss: 0.6330553889274597\n",
      "Ep 16: Batch #107 - Loss: 0.6157763600349426\n",
      "Ep 16: Batch #108 - Loss: 0.9071343541145325\n",
      "Ep 16: Batch #109 - Loss: 0.6376643776893616\n",
      "Ep 16: Batch #110 - Loss: 0.7366496324539185\n",
      "Ep 16: Batch #111 - Loss: 1.0716748237609863\n",
      "Ep 16: Batch #112 - Loss: 0.8430774211883545\n",
      "Ep 16: Batch #113 - Loss: 0.665518581867218\n",
      "Ep 16: Batch #114 - Loss: 0.7401167154312134\n",
      "Ep 16: Batch #115 - Loss: 0.9124770164489746\n",
      "Ep 16: Batch #116 - Loss: 0.5340121388435364\n",
      "Ep 16: Batch #117 - Loss: 0.707281768321991\n",
      "Ep 16: Batch #118 - Loss: 0.4624497592449188\n",
      "Ep 16: Batch #119 - Loss: 0.8170722723007202\n",
      "Ep 16: Batch #120 - Loss: 0.6688176393508911\n",
      "Ep 16: Batch #121 - Loss: 0.5727009773254395\n",
      "Ep 16: Batch #122 - Loss: 0.7186778783798218\n",
      "Ep 16: Batch #123 - Loss: 0.7293583154678345\n",
      "Ep 16: Batch #124 - Loss: 0.5609976053237915\n",
      "Ep 16: Batch #125 - Loss: 2.4714982509613037\n",
      "Ep 16: Batch #126 - Loss: 1.0013799667358398\n",
      "Ep 16: Batch #127 - Loss: 0.5899338126182556\n",
      "Ep 16: Batch #128 - Loss: 0.8896766304969788\n",
      "Ep 16: Batch #129 - Loss: 0.6883929371833801\n",
      "Ep 16: Batch #130 - Loss: 0.6055756211280823\n",
      "Ep 16: Batch #131 - Loss: 0.808226466178894\n",
      "Ep 16: Batch #132 - Loss: 0.6935149431228638\n",
      "Ep 16: Batch #133 - Loss: 0.673711895942688\n",
      "Ep 16: Batch #134 - Loss: 0.6531003713607788\n",
      "Ep 16: Batch #135 - Loss: 0.828567624092102\n",
      "Ep 16: Batch #136 - Loss: 1.0502145290374756\n",
      "Ep 16: Batch #137 - Loss: 0.7612974047660828\n",
      "Ep 16: Batch #138 - Loss: 0.9085646271705627\n",
      "Ep 16: Batch #139 - Loss: 0.7026522159576416\n",
      "Ep 16: Batch #140 - Loss: 0.8719689249992371\n",
      "Ep 16: Batch #141 - Loss: 1.148006558418274\n",
      "Ep 16: Batch #142 - Loss: 0.6805251240730286\n",
      "Ep 16: Batch #143 - Loss: 0.7786728143692017\n",
      "Ep 16: Batch #144 - Loss: 0.6165916323661804\n",
      "Ep 16: Batch #145 - Loss: 0.6023246645927429\n",
      "Ep 16: Batch #146 - Loss: 0.7263928055763245\n",
      "Ep 16: Batch #147 - Loss: 0.6966572999954224\n",
      "Ep 16: Batch #148 - Loss: 0.777358889579773\n",
      "Ep 16: Batch #149 - Loss: 0.6768421530723572\n",
      "Ep 16: Batch #150 - Loss: 0.7342864274978638\n",
      "Ep 16: Batch #151 - Loss: 0.6402174234390259\n",
      "Ep 16: Batch #152 - Loss: 0.6160564422607422\n",
      "Ep 16: Batch #153 - Loss: 0.8581482172012329\n",
      "Ep 16: Batch #154 - Loss: 0.6381387710571289\n",
      "Ep 16: Batch #155 - Loss: 0.7068555355072021\n",
      "Ep 16: Batch #156 - Loss: 0.8290774822235107\n",
      "Ep 16: Batch #157 - Loss: 0.6296720504760742\n",
      "Ep 16: Batch #158 - Loss: 0.724388837814331\n",
      "Ep 16: Batch #159 - Loss: 0.6362093091011047\n",
      "Ep 16: Batch #160 - Loss: 0.725841760635376\n",
      "Ep 16: Batch #161 - Loss: 0.6830980777740479\n",
      "Ep 16: Batch #162 - Loss: 0.735688328742981\n",
      "Ep 16: Batch #163 - Loss: 0.7836975455284119\n",
      "Ep 16: Batch #164 - Loss: 0.6612706184387207\n",
      "Ep 16: Batch #165 - Loss: 1.3525906801223755\n",
      "Ep 16: Batch #166 - Loss: 0.5459737777709961\n",
      "Ep 16: Batch #167 - Loss: 0.8254827857017517\n",
      "Ep 16: Batch #168 - Loss: 0.7039744257926941\n",
      "Ep 16: Batch #169 - Loss: 0.6828696727752686\n",
      "Ep 16: Batch #170 - Loss: 0.6502605080604553\n",
      "Ep 16: Batch #171 - Loss: 0.6488415598869324\n",
      "Ep 16: Batch #172 - Loss: 0.5398657917976379\n",
      "Ep 16: Batch #173 - Loss: 0.9588517546653748\n",
      "Ep 16: Batch #174 - Loss: 0.5011125206947327\n",
      "Ep 16: Batch #175 - Loss: 0.6538435816764832\n",
      "Ep 16: Batch #176 - Loss: 0.9223975539207458\n",
      "Ep 16: Batch #177 - Loss: 0.6737254858016968\n",
      "Ep 16: Batch #178 - Loss: 0.6437962055206299\n",
      "Ep 16: Batch #179 - Loss: 0.7611184120178223\n",
      "Ep 16: Batch #180 - Loss: 0.6653517484664917\n",
      "Ep 16: Batch #181 - Loss: 0.8182993531227112\n",
      "Ep 16: Batch #182 - Loss: 0.6341770887374878\n",
      "Ep 16: Batch #183 - Loss: 0.6252722144126892\n",
      "Ep 16: Batch #184 - Loss: 0.9276630282402039\n",
      "Ep 16: Batch #185 - Loss: 0.6407539248466492\n",
      "Ep 16: Batch #186 - Loss: 0.7865386605262756\n",
      "Ep 16: Batch #187 - Loss: 0.9021795392036438\n",
      "Ep 16: Batch #188 - Loss: 1.0398776531219482\n",
      "Ep 16: Batch #189 - Loss: 0.5953913331031799\n",
      "Ep 16: Batch #190 - Loss: 0.6302395462989807\n",
      "Ep 16: Batch #191 - Loss: 0.8322359919548035\n",
      "Ep 16: Batch #192 - Loss: 0.5766682028770447\n",
      "Ep 16: Batch #193 - Loss: 0.6316711902618408\n",
      "Ep 16: Batch #194 - Loss: 0.5669372081756592\n",
      "Ep 16: Batch #195 - Loss: 0.8033040165901184\n",
      "Ep 16: Batch #196 - Loss: 0.701677143573761\n",
      "Ep 16: Batch #197 - Loss: 0.7186447978019714\n",
      "Ep 16: Batch #198 - Loss: 0.5429159998893738\n",
      "Ep 16: Batch #199 - Loss: 0.6605197787284851\n",
      "Ep 17: Batch #0 - Loss: 0.6567296981811523\n",
      "Ep 17: Batch #1 - Loss: 0.7218392491340637\n",
      "Ep 17: Batch #2 - Loss: 0.8700698018074036\n",
      "Ep 17: Batch #3 - Loss: 0.7268725037574768\n",
      "Ep 17: Batch #4 - Loss: 0.6617105007171631\n",
      "Ep 17: Batch #5 - Loss: 0.5733342170715332\n",
      "Ep 17: Batch #6 - Loss: 0.7518496513366699\n",
      "Ep 17: Batch #7 - Loss: 0.5928784012794495\n",
      "Ep 17: Batch #8 - Loss: 0.5982544422149658\n",
      "Ep 17: Batch #9 - Loss: 1.113871693611145\n",
      "Ep 17: Batch #10 - Loss: 0.8458779454231262\n",
      "Ep 17: Batch #11 - Loss: 0.550890326499939\n",
      "Ep 17: Batch #12 - Loss: 1.260584831237793\n",
      "Ep 17: Batch #13 - Loss: 0.5796374082565308\n",
      "Ep 17: Batch #14 - Loss: 0.6065247654914856\n",
      "Ep 17: Batch #15 - Loss: 0.9275691509246826\n",
      "Ep 17: Batch #16 - Loss: 0.9857237339019775\n",
      "Ep 17: Batch #17 - Loss: 0.7361791133880615\n",
      "Ep 17: Batch #18 - Loss: 0.8106676936149597\n",
      "Ep 17: Batch #19 - Loss: 0.5680451989173889\n",
      "Ep 17: Batch #20 - Loss: 0.5543552041053772\n",
      "Ep 17: Batch #21 - Loss: 0.9259705543518066\n",
      "Ep 17: Batch #22 - Loss: 0.6187216639518738\n",
      "Ep 17: Batch #23 - Loss: 0.6124155521392822\n",
      "Ep 17: Batch #24 - Loss: 0.6536350250244141\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 17: Batch #25 - Loss: 0.6199902892112732\n",
      "Ep 17: Batch #26 - Loss: 0.592825710773468\n",
      "Ep 17: Batch #27 - Loss: 1.1502166986465454\n",
      "Ep 17: Batch #28 - Loss: 0.7014998197555542\n",
      "Ep 17: Batch #29 - Loss: 0.7655024528503418\n",
      "Ep 17: Batch #30 - Loss: 0.9142245650291443\n",
      "Ep 17: Batch #31 - Loss: 0.5671176910400391\n",
      "Ep 17: Batch #32 - Loss: 0.5914669632911682\n",
      "Ep 17: Batch #33 - Loss: 0.6782997846603394\n",
      "Ep 17: Batch #34 - Loss: 0.6559197306632996\n",
      "Ep 17: Batch #35 - Loss: 0.7442072629928589\n",
      "Ep 17: Batch #36 - Loss: 0.5865880250930786\n",
      "Ep 17: Batch #37 - Loss: 0.9317676424980164\n",
      "Ep 17: Batch #38 - Loss: 0.5830546617507935\n",
      "Ep 17: Batch #39 - Loss: 0.6922033429145813\n",
      "Ep 17: Batch #40 - Loss: 0.6175252795219421\n",
      "Ep 17: Batch #41 - Loss: 0.6248571276664734\n",
      "Ep 17: Batch #42 - Loss: 0.5777957439422607\n",
      "Ep 17: Batch #43 - Loss: 0.644618809223175\n",
      "Ep 17: Batch #44 - Loss: 0.6329354047775269\n",
      "Ep 17: Batch #45 - Loss: 0.5347573757171631\n",
      "Ep 17: Batch #46 - Loss: 0.7024231553077698\n",
      "Ep 17: Batch #47 - Loss: 0.8104307055473328\n",
      "Ep 17: Batch #48 - Loss: 1.0681599378585815\n",
      "Ep 17: Batch #49 - Loss: 0.8188910484313965\n",
      "Ep 17: Batch #50 - Loss: 0.575138509273529\n",
      "Ep 17: Batch #51 - Loss: 0.8220584988594055\n",
      "Ep 17: Batch #52 - Loss: 0.682815432548523\n",
      "Ep 17: Batch #53 - Loss: 0.7198063135147095\n",
      "Ep 17: Batch #54 - Loss: 0.5926405191421509\n",
      "Ep 17: Batch #55 - Loss: 0.6245031952857971\n",
      "Ep 17: Batch #56 - Loss: 0.9069049954414368\n",
      "Ep 17: Batch #57 - Loss: 0.6901450753211975\n",
      "Ep 17: Batch #58 - Loss: 0.839971125125885\n",
      "Ep 17: Batch #59 - Loss: 0.5730481147766113\n",
      "Ep 17: Batch #60 - Loss: 1.0370328426361084\n",
      "Ep 17: Batch #61 - Loss: 0.5384597778320312\n",
      "Ep 17: Batch #62 - Loss: 0.5895687937736511\n",
      "Ep 17: Batch #63 - Loss: 0.8018705248832703\n",
      "Ep 17: Batch #64 - Loss: 8.803333282470703\n",
      "Ep 17: Batch #65 - Loss: 0.5300359725952148\n",
      "Ep 17: Batch #66 - Loss: 0.6776997447013855\n",
      "Ep 17: Batch #67 - Loss: 0.7840338349342346\n",
      "Ep 17: Batch #68 - Loss: 0.7414370179176331\n",
      "Ep 17: Batch #69 - Loss: 0.6104852557182312\n",
      "Ep 17: Batch #70 - Loss: 0.623587429523468\n",
      "Ep 17: Batch #71 - Loss: 0.546916663646698\n",
      "Ep 17: Batch #72 - Loss: 0.6711912751197815\n",
      "Ep 17: Batch #73 - Loss: 0.7511869668960571\n",
      "Ep 17: Batch #74 - Loss: 0.5930365920066833\n",
      "Ep 17: Batch #75 - Loss: 0.6713642477989197\n",
      "Ep 17: Batch #76 - Loss: 0.9480641484260559\n",
      "Ep 17: Batch #77 - Loss: 0.5920789837837219\n",
      "Ep 17: Batch #78 - Loss: 0.9406007528305054\n",
      "Ep 17: Batch #79 - Loss: 0.5348170399665833\n",
      "Ep 17: Batch #80 - Loss: 0.7077440023422241\n",
      "Ep 17: Batch #81 - Loss: 1.5349621772766113\n",
      "Ep 17: Batch #82 - Loss: 0.755721926689148\n",
      "Ep 17: Batch #83 - Loss: 1.4215202331542969\n",
      "Ep 17: Batch #84 - Loss: 0.5887281894683838\n",
      "Ep 17: Batch #85 - Loss: 0.8123558759689331\n",
      "Ep 17: Batch #86 - Loss: 0.5607588887214661\n",
      "Ep 17: Batch #87 - Loss: 0.5802065134048462\n",
      "Ep 17: Batch #88 - Loss: 0.6602288484573364\n",
      "Ep 17: Batch #89 - Loss: 0.7560816407203674\n",
      "Ep 17: Batch #90 - Loss: 0.9101694822311401\n",
      "Ep 17: Batch #91 - Loss: 0.650874137878418\n",
      "Ep 17: Batch #92 - Loss: 0.7859357595443726\n",
      "Ep 17: Batch #93 - Loss: 0.7989643812179565\n",
      "Ep 17: Batch #94 - Loss: 0.7964662909507751\n",
      "Ep 17: Batch #95 - Loss: 0.7681355476379395\n",
      "Ep 17: Batch #96 - Loss: 0.7655740976333618\n",
      "Ep 17: Batch #97 - Loss: 0.5884596109390259\n",
      "Ep 17: Batch #98 - Loss: 0.5884349942207336\n",
      "Ep 17: Batch #99 - Loss: 0.807704746723175\n",
      "Ep 17: Batch #100 - Loss: 0.5641560554504395\n",
      "Ep 17: Batch #101 - Loss: 0.86674964427948\n",
      "Ep 17: Batch #102 - Loss: 0.6312987208366394\n",
      "Ep 17: Batch #103 - Loss: 0.6467912197113037\n",
      "Ep 17: Batch #104 - Loss: 0.6679282188415527\n",
      "Ep 17: Batch #105 - Loss: 0.8252066373825073\n",
      "Ep 17: Batch #106 - Loss: 0.6313833594322205\n",
      "Ep 17: Batch #107 - Loss: 0.61530601978302\n",
      "Ep 17: Batch #108 - Loss: 0.9068799018859863\n",
      "Ep 17: Batch #109 - Loss: 0.6360715627670288\n",
      "Ep 17: Batch #110 - Loss: 0.73602694272995\n",
      "Ep 17: Batch #111 - Loss: 1.0676085948944092\n",
      "Ep 17: Batch #112 - Loss: 0.8395385146141052\n",
      "Ep 17: Batch #113 - Loss: 0.6643183827400208\n",
      "Ep 17: Batch #114 - Loss: 0.7389785647392273\n",
      "Ep 17: Batch #115 - Loss: 0.9112873077392578\n",
      "Ep 17: Batch #116 - Loss: 0.5343188643455505\n",
      "Ep 17: Batch #117 - Loss: 0.7037196755409241\n",
      "Ep 17: Batch #118 - Loss: 0.462114542722702\n",
      "Ep 17: Batch #119 - Loss: 0.814720869064331\n",
      "Ep 17: Batch #120 - Loss: 0.6686312556266785\n",
      "Ep 17: Batch #121 - Loss: 0.5711237192153931\n",
      "Ep 17: Batch #122 - Loss: 0.7169522047042847\n",
      "Ep 17: Batch #123 - Loss: 0.7279913425445557\n",
      "Ep 17: Batch #124 - Loss: 0.5603398084640503\n",
      "Ep 17: Batch #125 - Loss: 2.473259210586548\n",
      "Ep 17: Batch #126 - Loss: 1.0012304782867432\n",
      "Ep 17: Batch #127 - Loss: 0.5889833569526672\n",
      "Ep 17: Batch #128 - Loss: 0.8893185257911682\n",
      "Ep 17: Batch #129 - Loss: 0.6879725456237793\n",
      "Ep 17: Batch #130 - Loss: 0.603754460811615\n",
      "Ep 17: Batch #131 - Loss: 0.8074825406074524\n",
      "Ep 17: Batch #132 - Loss: 0.6920555830001831\n",
      "Ep 17: Batch #133 - Loss: 0.6721957921981812\n",
      "Ep 17: Batch #134 - Loss: 0.6501653790473938\n",
      "Ep 17: Batch #135 - Loss: 0.8270312547683716\n",
      "Ep 17: Batch #136 - Loss: 1.0505465269088745\n",
      "Ep 17: Batch #137 - Loss: 0.7605994939804077\n",
      "Ep 17: Batch #138 - Loss: 0.907067060470581\n",
      "Ep 17: Batch #139 - Loss: 0.6998239755630493\n",
      "Ep 17: Batch #140 - Loss: 0.8682096004486084\n",
      "Ep 17: Batch #141 - Loss: 1.1458426713943481\n",
      "Ep 17: Batch #142 - Loss: 0.6800882816314697\n",
      "Ep 17: Batch #143 - Loss: 0.7765640020370483\n",
      "Ep 17: Batch #144 - Loss: 0.6160376667976379\n",
      "Ep 17: Batch #145 - Loss: 0.6018924117088318\n",
      "Ep 17: Batch #146 - Loss: 0.7222975492477417\n",
      "Ep 17: Batch #147 - Loss: 0.6925152540206909\n",
      "Ep 17: Batch #148 - Loss: 0.7739806175231934\n",
      "Ep 17: Batch #149 - Loss: 0.6715369820594788\n",
      "Ep 17: Batch #150 - Loss: 0.7321814894676208\n",
      "Ep 17: Batch #151 - Loss: 0.638878345489502\n",
      "Ep 17: Batch #152 - Loss: 0.6147069931030273\n",
      "Ep 17: Batch #153 - Loss: 0.8545649647712708\n",
      "Ep 17: Batch #154 - Loss: 0.6370166540145874\n",
      "Ep 17: Batch #155 - Loss: 0.7033736109733582\n",
      "Ep 17: Batch #156 - Loss: 0.8247359395027161\n",
      "Ep 17: Batch #157 - Loss: 0.6273339986801147\n",
      "Ep 17: Batch #158 - Loss: 0.7232249975204468\n",
      "Ep 17: Batch #159 - Loss: 0.6323400735855103\n",
      "Ep 17: Batch #160 - Loss: 0.7231637239456177\n",
      "Ep 17: Batch #161 - Loss: 0.6811521053314209\n",
      "Ep 17: Batch #162 - Loss: 0.73393714427948\n",
      "Ep 17: Batch #163 - Loss: 0.7802401185035706\n",
      "Ep 17: Batch #164 - Loss: 0.6595459580421448\n",
      "Ep 17: Batch #165 - Loss: 1.3502609729766846\n",
      "Ep 17: Batch #166 - Loss: 0.5439466834068298\n",
      "Ep 17: Batch #167 - Loss: 0.8163991570472717\n",
      "Ep 17: Batch #168 - Loss: 0.7018898129463196\n",
      "Ep 17: Batch #169 - Loss: 0.6809626221656799\n",
      "Ep 17: Batch #170 - Loss: 0.6476526856422424\n",
      "Ep 17: Batch #171 - Loss: 0.6474917531013489\n",
      "Ep 17: Batch #172 - Loss: 0.5388113260269165\n",
      "Ep 17: Batch #173 - Loss: 0.9549236297607422\n",
      "Ep 17: Batch #174 - Loss: 0.5002948045730591\n",
      "Ep 17: Batch #175 - Loss: 0.6521240472793579\n",
      "Ep 17: Batch #176 - Loss: 0.9169988036155701\n",
      "Ep 17: Batch #177 - Loss: 0.671541690826416\n",
      "Ep 17: Batch #178 - Loss: 0.6418119668960571\n",
      "Ep 17: Batch #179 - Loss: 0.7588760256767273\n",
      "Ep 17: Batch #180 - Loss: 0.6637545824050903\n",
      "Ep 17: Batch #181 - Loss: 0.8159971833229065\n",
      "Ep 17: Batch #182 - Loss: 0.6331667304039001\n",
      "Ep 17: Batch #183 - Loss: 0.6223053932189941\n",
      "Ep 17: Batch #184 - Loss: 0.9273102283477783\n",
      "Ep 17: Batch #185 - Loss: 0.6390687823295593\n",
      "Ep 17: Batch #186 - Loss: 0.7842657566070557\n",
      "Ep 17: Batch #187 - Loss: 0.8986934423446655\n",
      "Ep 17: Batch #188 - Loss: 1.0351637601852417\n",
      "Ep 17: Batch #189 - Loss: 0.5945396423339844\n",
      "Ep 17: Batch #190 - Loss: 0.6291539072990417\n",
      "Ep 17: Batch #191 - Loss: 0.8288012146949768\n",
      "Ep 17: Batch #192 - Loss: 0.5759813785552979\n",
      "Ep 17: Batch #193 - Loss: 0.6308164596557617\n",
      "Ep 17: Batch #194 - Loss: 0.5641257166862488\n",
      "Ep 17: Batch #195 - Loss: 0.8035425543785095\n",
      "Ep 17: Batch #196 - Loss: 0.7003253102302551\n",
      "Ep 17: Batch #197 - Loss: 0.7158987522125244\n",
      "Ep 17: Batch #198 - Loss: 0.5414642095565796\n",
      "Ep 17: Batch #199 - Loss: 0.6587006449699402\n",
      "Ep 18: Batch #0 - Loss: 0.6557486653327942\n",
      "Ep 18: Batch #1 - Loss: 0.7210924625396729\n",
      "Ep 18: Batch #2 - Loss: 0.8682857155799866\n",
      "Ep 18: Batch #3 - Loss: 0.7259750366210938\n",
      "Ep 18: Batch #4 - Loss: 0.6605507135391235\n",
      "Ep 18: Batch #5 - Loss: 0.5720325708389282\n",
      "Ep 18: Batch #6 - Loss: 0.751289427280426\n",
      "Ep 18: Batch #7 - Loss: 0.5910806655883789\n",
      "Ep 18: Batch #8 - Loss: 0.5972979664802551\n",
      "Ep 18: Batch #9 - Loss: 1.1102663278579712\n",
      "Ep 18: Batch #10 - Loss: 0.8418652415275574\n",
      "Ep 18: Batch #11 - Loss: 0.5501679182052612\n",
      "Ep 18: Batch #12 - Loss: 1.2548388242721558\n",
      "Ep 18: Batch #13 - Loss: 0.5784434080123901\n",
      "Ep 18: Batch #14 - Loss: 0.6062319874763489\n",
      "Ep 18: Batch #15 - Loss: 0.9216298460960388\n",
      "Ep 18: Batch #16 - Loss: 0.980109453201294\n",
      "Ep 18: Batch #17 - Loss: 0.735256016254425\n",
      "Ep 18: Batch #18 - Loss: 0.8098966479301453\n",
      "Ep 18: Batch #19 - Loss: 0.5671524405479431\n",
      "Ep 18: Batch #20 - Loss: 0.5533334612846375\n",
      "Ep 18: Batch #21 - Loss: 0.919951319694519\n",
      "Ep 18: Batch #22 - Loss: 0.6184626817703247\n",
      "Ep 18: Batch #23 - Loss: 0.6107853651046753\n",
      "Ep 18: Batch #24 - Loss: 0.6527191996574402\n",
      "Ep 18: Batch #25 - Loss: 0.6183633208274841\n",
      "Ep 18: Batch #26 - Loss: 0.5888460874557495\n",
      "Ep 18: Batch #27 - Loss: 1.1493253707885742\n",
      "Ep 18: Batch #28 - Loss: 0.7003710865974426\n",
      "Ep 18: Batch #29 - Loss: 0.7642902731895447\n",
      "Ep 18: Batch #30 - Loss: 0.9117456674575806\n",
      "Ep 18: Batch #31 - Loss: 0.5666083097457886\n",
      "Ep 18: Batch #32 - Loss: 0.5903919339179993\n",
      "Ep 18: Batch #33 - Loss: 0.6769293546676636\n",
      "Ep 18: Batch #34 - Loss: 0.6546280384063721\n",
      "Ep 18: Batch #35 - Loss: 0.7410939931869507\n",
      "Ep 18: Batch #36 - Loss: 0.5855138301849365\n",
      "Ep 18: Batch #37 - Loss: 0.9306116700172424\n",
      "Ep 18: Batch #38 - Loss: 0.5821661353111267\n",
      "Ep 18: Batch #39 - Loss: 0.6915920972824097\n",
      "Ep 18: Batch #40 - Loss: 0.6156477332115173\n",
      "Ep 18: Batch #41 - Loss: 0.6239748001098633\n",
      "Ep 18: Batch #42 - Loss: 0.57645183801651\n",
      "Ep 18: Batch #43 - Loss: 0.6427024006843567\n",
      "Ep 18: Batch #44 - Loss: 0.6302174925804138\n",
      "Ep 18: Batch #45 - Loss: 0.5339125990867615\n",
      "Ep 18: Batch #46 - Loss: 0.7016675472259521\n",
      "Ep 18: Batch #47 - Loss: 0.8093112111091614\n",
      "Ep 18: Batch #48 - Loss: 1.063904881477356\n",
      "Ep 18: Batch #49 - Loss: 0.8172650933265686\n",
      "Ep 18: Batch #50 - Loss: 0.5745081901550293\n",
      "Ep 18: Batch #51 - Loss: 0.8210350275039673\n",
      "Ep 18: Batch #52 - Loss: 0.6819766163825989\n",
      "Ep 18: Batch #53 - Loss: 0.719134509563446\n",
      "Ep 18: Batch #54 - Loss: 0.5912216305732727\n",
      "Ep 18: Batch #55 - Loss: 0.6225461363792419\n",
      "Ep 18: Batch #56 - Loss: 0.9006499648094177\n",
      "Ep 18: Batch #57 - Loss: 0.6895521879196167\n",
      "Ep 18: Batch #58 - Loss: 0.8380396962165833\n",
      "Ep 18: Batch #59 - Loss: 0.5720359086990356\n",
      "Ep 18: Batch #60 - Loss: 1.0314134359359741\n",
      "Ep 18: Batch #61 - Loss: 0.5379937887191772\n",
      "Ep 18: Batch #62 - Loss: 0.5875064730644226\n",
      "Ep 18: Batch #63 - Loss: 0.8010560870170593\n",
      "Ep 18: Batch #64 - Loss: 8.77035140991211\n",
      "Ep 18: Batch #65 - Loss: 0.5296716094017029\n",
      "Ep 18: Batch #66 - Loss: 0.6765315532684326\n",
      "Ep 18: Batch #67 - Loss: 0.7823868989944458\n",
      "Ep 18: Batch #68 - Loss: 0.7384845018386841\n",
      "Ep 18: Batch #69 - Loss: 0.6076273322105408\n",
      "Ep 18: Batch #70 - Loss: 0.6219903826713562\n",
      "Ep 18: Batch #71 - Loss: 0.5454977750778198\n",
      "Ep 18: Batch #72 - Loss: 0.6693254113197327\n",
      "Ep 18: Batch #73 - Loss: 0.7478730082511902\n",
      "Ep 18: Batch #74 - Loss: 0.5907378792762756\n",
      "Ep 18: Batch #75 - Loss: 0.6709538698196411\n",
      "Ep 18: Batch #76 - Loss: 0.9464516043663025\n",
      "Ep 18: Batch #77 - Loss: 0.5892302989959717\n",
      "Ep 18: Batch #78 - Loss: 0.9380207061767578\n",
      "Ep 18: Batch #79 - Loss: 0.5334152579307556\n",
      "Ep 18: Batch #80 - Loss: 0.7055101990699768\n",
      "Ep 18: Batch #81 - Loss: 1.5343601703643799\n",
      "Ep 18: Batch #82 - Loss: 0.7551010251045227\n",
      "Ep 18: Batch #83 - Loss: 1.415522813796997\n",
      "Ep 18: Batch #84 - Loss: 0.5847625732421875\n",
      "Ep 18: Batch #85 - Loss: 0.8077801465988159\n",
      "Ep 18: Batch #86 - Loss: 0.5578774809837341\n",
      "Ep 18: Batch #87 - Loss: 0.5782124400138855\n",
      "Ep 18: Batch #88 - Loss: 0.6586838960647583\n",
      "Ep 18: Batch #89 - Loss: 0.7533056735992432\n",
      "Ep 18: Batch #90 - Loss: 0.9075157642364502\n",
      "Ep 18: Batch #91 - Loss: 0.6503426432609558\n",
      "Ep 18: Batch #92 - Loss: 0.7771549224853516\n",
      "Ep 18: Batch #93 - Loss: 0.7968084812164307\n",
      "Ep 18: Batch #94 - Loss: 0.7922670245170593\n",
      "Ep 18: Batch #95 - Loss: 0.7672957181930542\n",
      "Ep 18: Batch #96 - Loss: 0.7644938230514526\n",
      "Ep 18: Batch #97 - Loss: 0.5886433720588684\n",
      "Ep 18: Batch #98 - Loss: 0.5872122645378113\n",
      "Ep 18: Batch #99 - Loss: 0.8066114783287048\n",
      "Ep 18: Batch #100 - Loss: 0.5635488033294678\n",
      "Ep 18: Batch #101 - Loss: 0.8655495643615723\n",
      "Ep 18: Batch #102 - Loss: 0.6281954646110535\n",
      "Ep 18: Batch #103 - Loss: 0.6459001302719116\n",
      "Ep 18: Batch #104 - Loss: 0.6671880483627319\n",
      "Ep 18: Batch #105 - Loss: 0.8239246010780334\n",
      "Ep 18: Batch #106 - Loss: 0.6306440830230713\n",
      "Ep 18: Batch #107 - Loss: 0.6148751974105835\n",
      "Ep 18: Batch #108 - Loss: 0.9060940742492676\n",
      "Ep 18: Batch #109 - Loss: 0.6347613334655762\n",
      "Ep 18: Batch #110 - Loss: 0.7355392575263977\n",
      "Ep 18: Batch #111 - Loss: 1.0647386312484741\n",
      "Ep 18: Batch #112 - Loss: 0.8370126485824585\n",
      "Ep 18: Batch #113 - Loss: 0.6637484431266785\n",
      "Ep 18: Batch #114 - Loss: 0.7371705174446106\n",
      "Ep 18: Batch #115 - Loss: 0.9114560484886169\n",
      "Ep 18: Batch #116 - Loss: 0.5332846641540527\n",
      "Ep 18: Batch #117 - Loss: 0.70126873254776\n",
      "Ep 18: Batch #118 - Loss: 0.4622022211551666\n",
      "Ep 18: Batch #119 - Loss: 0.8126183152198792\n",
      "Ep 18: Batch #120 - Loss: 0.6674307584762573\n",
      "Ep 18: Batch #121 - Loss: 0.5714751482009888\n",
      "Ep 18: Batch #122 - Loss: 0.7168022990226746\n",
      "Ep 18: Batch #123 - Loss: 0.7274879217147827\n",
      "Ep 18: Batch #124 - Loss: 0.5601320266723633\n",
      "Ep 18: Batch #125 - Loss: 2.4717156887054443\n",
      "Ep 18: Batch #126 - Loss: 1.0008262395858765\n",
      "Ep 18: Batch #127 - Loss: 0.5881844162940979\n",
      "Ep 18: Batch #128 - Loss: 0.8884987831115723\n",
      "Ep 18: Batch #129 - Loss: 0.6876286864280701\n",
      "Ep 18: Batch #130 - Loss: 0.603355348110199\n",
      "Ep 18: Batch #131 - Loss: 0.8077477812767029\n",
      "Ep 18: Batch #132 - Loss: 0.6917151212692261\n",
      "Ep 18: Batch #133 - Loss: 0.6719385385513306\n",
      "Ep 18: Batch #134 - Loss: 0.6483535766601562\n",
      "Ep 18: Batch #135 - Loss: 0.8269496560096741\n",
      "Ep 18: Batch #136 - Loss: 1.049230933189392\n",
      "Ep 18: Batch #137 - Loss: 0.7595984935760498\n",
      "Ep 18: Batch #138 - Loss: 0.904522716999054\n",
      "Ep 18: Batch #139 - Loss: 0.6969056129455566\n",
      "Ep 18: Batch #140 - Loss: 0.8654748797416687\n",
      "Ep 18: Batch #141 - Loss: 1.1443575620651245\n",
      "Ep 18: Batch #142 - Loss: 0.6792284250259399\n",
      "Ep 18: Batch #143 - Loss: 0.7749741673469543\n",
      "Ep 18: Batch #144 - Loss: 0.6155043244361877\n",
      "Ep 18: Batch #145 - Loss: 0.6021789312362671\n",
      "Ep 18: Batch #146 - Loss: 0.7193548679351807\n",
      "Ep 18: Batch #147 - Loss: 0.6894626617431641\n",
      "Ep 18: Batch #148 - Loss: 0.7717024683952332\n",
      "Ep 18: Batch #149 - Loss: 0.6669070720672607\n",
      "Ep 18: Batch #150 - Loss: 0.7307883501052856\n",
      "Ep 18: Batch #151 - Loss: 0.6380087733268738\n",
      "Ep 18: Batch #152 - Loss: 0.6138704419136047\n",
      "Ep 18: Batch #153 - Loss: 0.8514033555984497\n",
      "Ep 18: Batch #154 - Loss: 0.6366174817085266\n",
      "Ep 18: Batch #155 - Loss: 0.7001713514328003\n",
      "Ep 18: Batch #156 - Loss: 0.8218332529067993\n",
      "Ep 18: Batch #157 - Loss: 0.6252763271331787\n",
      "Ep 18: Batch #158 - Loss: 0.7221147418022156\n",
      "Ep 18: Batch #159 - Loss: 0.6289780139923096\n",
      "Ep 18: Batch #160 - Loss: 0.720429539680481\n",
      "Ep 18: Batch #161 - Loss: 0.6795082688331604\n",
      "Ep 18: Batch #162 - Loss: 0.7319151759147644\n",
      "Ep 18: Batch #163 - Loss: 0.7774540185928345\n",
      "Ep 18: Batch #164 - Loss: 0.6582024097442627\n",
      "Ep 18: Batch #165 - Loss: 1.349198579788208\n",
      "Ep 18: Batch #166 - Loss: 0.5424242615699768\n",
      "Ep 18: Batch #167 - Loss: 0.8086051940917969\n",
      "Ep 18: Batch #168 - Loss: 0.6995906233787537\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 18: Batch #169 - Loss: 0.67962247133255\n",
      "Ep 18: Batch #170 - Loss: 0.6452523469924927\n",
      "Ep 18: Batch #171 - Loss: 0.6466729044914246\n",
      "Ep 18: Batch #172 - Loss: 0.5383965969085693\n",
      "Ep 18: Batch #173 - Loss: 0.9503925442695618\n",
      "Ep 18: Batch #174 - Loss: 0.4998009204864502\n",
      "Ep 18: Batch #175 - Loss: 0.6507916450500488\n",
      "Ep 18: Batch #176 - Loss: 0.9125478863716125\n",
      "Ep 18: Batch #177 - Loss: 0.6694847345352173\n",
      "Ep 18: Batch #178 - Loss: 0.6397624015808105\n",
      "Ep 18: Batch #179 - Loss: 0.7586621046066284\n",
      "Ep 18: Batch #180 - Loss: 0.6624290943145752\n",
      "Ep 18: Batch #181 - Loss: 0.8138859272003174\n",
      "Ep 18: Batch #182 - Loss: 0.6319423913955688\n",
      "Ep 18: Batch #183 - Loss: 0.6198098659515381\n",
      "Ep 18: Batch #184 - Loss: 0.9268503785133362\n",
      "Ep 18: Batch #185 - Loss: 0.6383100748062134\n",
      "Ep 18: Batch #186 - Loss: 0.7819052338600159\n",
      "Ep 18: Batch #187 - Loss: 0.895965039730072\n",
      "Ep 18: Batch #188 - Loss: 1.03147292137146\n",
      "Ep 18: Batch #189 - Loss: 0.5936433672904968\n",
      "Ep 18: Batch #190 - Loss: 0.6286018490791321\n",
      "Ep 18: Batch #191 - Loss: 0.825648307800293\n",
      "Ep 18: Batch #192 - Loss: 0.5756280422210693\n",
      "Ep 18: Batch #193 - Loss: 0.630086362361908\n",
      "Ep 18: Batch #194 - Loss: 0.5621218681335449\n",
      "Ep 18: Batch #195 - Loss: 0.8041632771492004\n",
      "Ep 18: Batch #196 - Loss: 0.699264407157898\n",
      "Ep 18: Batch #197 - Loss: 0.7135358452796936\n",
      "Ep 18: Batch #198 - Loss: 0.5404896140098572\n",
      "Ep 18: Batch #199 - Loss: 0.6574212908744812\n",
      "Ep 19: Batch #0 - Loss: 0.6549853086471558\n",
      "Ep 19: Batch #1 - Loss: 0.7200940251350403\n",
      "Ep 19: Batch #2 - Loss: 0.867647647857666\n",
      "Ep 19: Batch #3 - Loss: 0.7255169749259949\n",
      "Ep 19: Batch #4 - Loss: 0.6601136326789856\n",
      "Ep 19: Batch #5 - Loss: 0.5702531933784485\n",
      "Ep 19: Batch #6 - Loss: 0.750532329082489\n",
      "Ep 19: Batch #7 - Loss: 0.589264988899231\n",
      "Ep 19: Batch #8 - Loss: 0.5958922505378723\n",
      "Ep 19: Batch #9 - Loss: 1.1073925495147705\n",
      "Ep 19: Batch #10 - Loss: 0.8388445973396301\n",
      "Ep 19: Batch #11 - Loss: 0.5486753582954407\n",
      "Ep 19: Batch #12 - Loss: 1.2490731477737427\n",
      "Ep 19: Batch #13 - Loss: 0.5777002573013306\n",
      "Ep 19: Batch #14 - Loss: 0.6064701080322266\n",
      "Ep 19: Batch #15 - Loss: 0.9154217839241028\n",
      "Ep 19: Batch #16 - Loss: 0.9748243093490601\n",
      "Ep 19: Batch #17 - Loss: 0.7345774173736572\n",
      "Ep 19: Batch #18 - Loss: 0.8090399503707886\n",
      "Ep 19: Batch #19 - Loss: 0.5668668746948242\n",
      "Ep 19: Batch #20 - Loss: 0.5519465208053589\n",
      "Ep 19: Batch #21 - Loss: 0.9138134121894836\n",
      "Ep 19: Batch #22 - Loss: 0.6179102063179016\n",
      "Ep 19: Batch #23 - Loss: 0.6096525192260742\n",
      "Ep 19: Batch #24 - Loss: 0.6506507992744446\n",
      "Ep 19: Batch #25 - Loss: 0.6170571446418762\n",
      "Ep 19: Batch #26 - Loss: 0.5850920677185059\n",
      "Ep 19: Batch #27 - Loss: 1.1489065885543823\n",
      "Ep 19: Batch #28 - Loss: 0.6995419859886169\n",
      "Ep 19: Batch #29 - Loss: 0.7628254294395447\n",
      "Ep 19: Batch #30 - Loss: 0.9079754948616028\n",
      "Ep 19: Batch #31 - Loss: 0.5662528872489929\n",
      "Ep 19: Batch #32 - Loss: 0.5896469354629517\n",
      "Ep 19: Batch #33 - Loss: 0.6759033799171448\n",
      "Ep 19: Batch #34 - Loss: 0.6533939838409424\n",
      "Ep 19: Batch #35 - Loss: 0.7384003400802612\n",
      "Ep 19: Batch #36 - Loss: 0.5852704644203186\n",
      "Ep 19: Batch #37 - Loss: 0.9298875331878662\n",
      "Ep 19: Batch #38 - Loss: 0.5806856155395508\n",
      "Ep 19: Batch #39 - Loss: 0.6899076700210571\n",
      "Ep 19: Batch #40 - Loss: 0.6136640310287476\n",
      "Ep 19: Batch #41 - Loss: 0.6233653426170349\n",
      "Ep 19: Batch #42 - Loss: 0.5755854249000549\n",
      "Ep 19: Batch #43 - Loss: 0.641115665435791\n",
      "Ep 19: Batch #44 - Loss: 0.6280717849731445\n",
      "Ep 19: Batch #45 - Loss: 0.5333355665206909\n",
      "Ep 19: Batch #46 - Loss: 0.7011046409606934\n",
      "Ep 19: Batch #47 - Loss: 0.8083350658416748\n",
      "Ep 19: Batch #48 - Loss: 1.0599700212478638\n",
      "Ep 19: Batch #49 - Loss: 0.8162940740585327\n",
      "Ep 19: Batch #50 - Loss: 0.5740042328834534\n",
      "Ep 19: Batch #51 - Loss: 0.8207221627235413\n",
      "Ep 19: Batch #52 - Loss: 0.6818656921386719\n",
      "Ep 19: Batch #53 - Loss: 0.7188629508018494\n",
      "Ep 19: Batch #54 - Loss: 0.5897899866104126\n",
      "Ep 19: Batch #55 - Loss: 0.6209908127784729\n",
      "Ep 19: Batch #56 - Loss: 0.8948942422866821\n",
      "Ep 19: Batch #57 - Loss: 0.6892028450965881\n",
      "Ep 19: Batch #58 - Loss: 0.8367084264755249\n",
      "Ep 19: Batch #59 - Loss: 0.5714212656021118\n",
      "Ep 19: Batch #60 - Loss: 1.027631402015686\n",
      "Ep 19: Batch #61 - Loss: 0.5377898216247559\n",
      "Ep 19: Batch #62 - Loss: 0.5861627459526062\n",
      "Ep 19: Batch #63 - Loss: 0.7997217774391174\n",
      "Ep 19: Batch #64 - Loss: 8.756032943725586\n",
      "Ep 19: Batch #65 - Loss: 0.5288928747177124\n",
      "Ep 19: Batch #66 - Loss: 0.6749517917633057\n",
      "Ep 19: Batch #67 - Loss: 0.7818657159805298\n",
      "Ep 19: Batch #68 - Loss: 0.7362073659896851\n",
      "Ep 19: Batch #69 - Loss: 0.60527503490448\n",
      "Ep 19: Batch #70 - Loss: 0.6211351156234741\n",
      "Ep 19: Batch #71 - Loss: 0.5441696047782898\n",
      "Ep 19: Batch #72 - Loss: 0.6686394214630127\n",
      "Ep 19: Batch #73 - Loss: 0.7454302906990051\n",
      "Ep 19: Batch #74 - Loss: 0.5891037583351135\n",
      "Ep 19: Batch #75 - Loss: 0.6711520552635193\n",
      "Ep 19: Batch #76 - Loss: 0.9444599747657776\n",
      "Ep 19: Batch #77 - Loss: 0.5866608619689941\n",
      "Ep 19: Batch #78 - Loss: 0.9366891384124756\n",
      "Ep 19: Batch #79 - Loss: 0.5325125455856323\n",
      "Ep 19: Batch #80 - Loss: 0.7042263150215149\n",
      "Ep 19: Batch #81 - Loss: 1.5335506200790405\n",
      "Ep 19: Batch #82 - Loss: 0.7547322511672974\n",
      "Ep 19: Batch #83 - Loss: 1.4086486101150513\n",
      "Ep 19: Batch #84 - Loss: 0.5831543803215027\n",
      "Ep 19: Batch #85 - Loss: 0.8055416941642761\n",
      "Ep 19: Batch #86 - Loss: 0.5568714737892151\n",
      "Ep 19: Batch #87 - Loss: 0.5772151350975037\n",
      "Ep 19: Batch #88 - Loss: 0.6580283641815186\n",
      "Ep 19: Batch #89 - Loss: 0.7509458661079407\n",
      "Ep 19: Batch #90 - Loss: 0.9056121706962585\n",
      "Ep 19: Batch #91 - Loss: 0.6499454379081726\n",
      "Ep 19: Batch #92 - Loss: 0.7718603610992432\n",
      "Ep 19: Batch #93 - Loss: 0.7948277592658997\n",
      "Ep 19: Batch #94 - Loss: 0.7886551022529602\n",
      "Ep 19: Batch #95 - Loss: 0.7665387988090515\n",
      "Ep 19: Batch #96 - Loss: 0.7642428278923035\n",
      "Ep 19: Batch #97 - Loss: 0.5877280831336975\n",
      "Ep 19: Batch #98 - Loss: 0.586380660533905\n",
      "Ep 19: Batch #99 - Loss: 0.8059364557266235\n",
      "Ep 19: Batch #100 - Loss: 0.5628870129585266\n",
      "Ep 19: Batch #101 - Loss: 0.8646742105484009\n",
      "Ep 19: Batch #102 - Loss: 0.6271736025810242\n",
      "Ep 19: Batch #103 - Loss: 0.645123302936554\n",
      "Ep 19: Batch #104 - Loss: 0.6665017008781433\n",
      "Ep 19: Batch #105 - Loss: 0.8229960799217224\n",
      "Ep 19: Batch #106 - Loss: 0.6293530464172363\n",
      "Ep 19: Batch #107 - Loss: 0.614568293094635\n",
      "Ep 19: Batch #108 - Loss: 0.9059916138648987\n",
      "Ep 19: Batch #109 - Loss: 0.633912980556488\n",
      "Ep 19: Batch #110 - Loss: 0.7349836230278015\n",
      "Ep 19: Batch #111 - Loss: 1.0614739656448364\n",
      "Ep 19: Batch #112 - Loss: 0.8337041735649109\n",
      "Ep 19: Batch #113 - Loss: 0.6632992625236511\n",
      "Ep 19: Batch #114 - Loss: 0.7360047698020935\n",
      "Ep 19: Batch #115 - Loss: 0.9109028577804565\n",
      "Ep 19: Batch #116 - Loss: 0.5337418913841248\n",
      "Ep 19: Batch #117 - Loss: 0.698819637298584\n",
      "Ep 19: Batch #118 - Loss: 0.46211645007133484\n",
      "Ep 19: Batch #119 - Loss: 0.8108958601951599\n",
      "Ep 19: Batch #120 - Loss: 0.666250467300415\n",
      "Ep 19: Batch #121 - Loss: 0.5708326101303101\n",
      "Ep 19: Batch #122 - Loss: 0.7161016464233398\n",
      "Ep 19: Batch #123 - Loss: 0.7266578674316406\n",
      "Ep 19: Batch #124 - Loss: 0.559663712978363\n",
      "Ep 19: Batch #125 - Loss: 2.471928119659424\n",
      "Ep 19: Batch #126 - Loss: 1.0004348754882812\n",
      "Ep 19: Batch #127 - Loss: 0.5878908634185791\n",
      "Ep 19: Batch #128 - Loss: 0.8881580829620361\n",
      "Ep 19: Batch #129 - Loss: 0.6871504187583923\n",
      "Ep 19: Batch #130 - Loss: 0.6030256748199463\n",
      "Ep 19: Batch #131 - Loss: 0.8073564171791077\n",
      "Ep 19: Batch #132 - Loss: 0.6907758116722107\n",
      "Ep 19: Batch #133 - Loss: 0.6712225675582886\n",
      "Ep 19: Batch #134 - Loss: 0.6469132900238037\n",
      "Ep 19: Batch #135 - Loss: 0.8267321586608887\n",
      "Ep 19: Batch #136 - Loss: 1.0478931665420532\n",
      "Ep 19: Batch #137 - Loss: 0.7586108446121216\n",
      "Ep 19: Batch #138 - Loss: 0.9036808013916016\n",
      "Ep 19: Batch #139 - Loss: 0.6964765191078186\n",
      "Ep 19: Batch #140 - Loss: 0.8629712462425232\n",
      "Ep 19: Batch #141 - Loss: 1.1429673433303833\n",
      "Ep 19: Batch #142 - Loss: 0.6781516075134277\n",
      "Ep 19: Batch #143 - Loss: 0.7740625143051147\n",
      "Ep 19: Batch #144 - Loss: 0.615016758441925\n",
      "Ep 19: Batch #145 - Loss: 0.6021415591239929\n",
      "Ep 19: Batch #146 - Loss: 0.7173475027084351\n",
      "Ep 19: Batch #147 - Loss: 0.6866752505302429\n",
      "Ep 19: Batch #148 - Loss: 0.769612193107605\n",
      "Ep 19: Batch #149 - Loss: 0.6631293296813965\n",
      "Ep 19: Batch #150 - Loss: 0.7296145558357239\n",
      "Ep 19: Batch #151 - Loss: 0.6373242139816284\n",
      "Ep 19: Batch #152 - Loss: 0.6133769750595093\n",
      "Ep 19: Batch #153 - Loss: 0.849176824092865\n",
      "Ep 19: Batch #154 - Loss: 0.6363770365715027\n",
      "Ep 19: Batch #155 - Loss: 0.6989262700080872\n",
      "Ep 19: Batch #156 - Loss: 0.818484902381897\n",
      "Ep 19: Batch #157 - Loss: 0.6237714290618896\n",
      "Ep 19: Batch #158 - Loss: 0.7215411067008972\n",
      "Ep 19: Batch #159 - Loss: 0.6262180805206299\n",
      "Ep 19: Batch #160 - Loss: 0.7184640169143677\n",
      "Ep 19: Batch #161 - Loss: 0.6783294677734375\n",
      "Ep 19: Batch #162 - Loss: 0.7299623489379883\n",
      "Ep 19: Batch #163 - Loss: 0.7750493288040161\n",
      "Ep 19: Batch #164 - Loss: 0.6571424007415771\n",
      "Ep 19: Batch #165 - Loss: 1.3478682041168213\n",
      "Ep 19: Batch #166 - Loss: 0.5412244200706482\n",
      "Ep 19: Batch #167 - Loss: 0.8017619848251343\n",
      "Ep 19: Batch #168 - Loss: 0.6983066201210022\n",
      "Ep 19: Batch #169 - Loss: 0.6783919930458069\n",
      "Ep 19: Batch #170 - Loss: 0.6433597207069397\n",
      "Ep 19: Batch #171 - Loss: 0.6459883451461792\n",
      "Ep 19: Batch #172 - Loss: 0.5379927158355713\n",
      "Ep 19: Batch #173 - Loss: 0.9469839930534363\n",
      "Ep 19: Batch #174 - Loss: 0.4994072914123535\n",
      "Ep 19: Batch #175 - Loss: 0.6495730876922607\n",
      "Ep 19: Batch #176 - Loss: 0.909771740436554\n",
      "Ep 19: Batch #177 - Loss: 0.6680062413215637\n",
      "Ep 19: Batch #178 - Loss: 0.6377824544906616\n",
      "Ep 19: Batch #179 - Loss: 0.7588093876838684\n",
      "Ep 19: Batch #180 - Loss: 0.6617203950881958\n",
      "Ep 19: Batch #181 - Loss: 0.8121922016143799\n",
      "Ep 19: Batch #182 - Loss: 0.6310878992080688\n",
      "Ep 19: Batch #183 - Loss: 0.6178220510482788\n",
      "Ep 19: Batch #184 - Loss: 0.9265151023864746\n",
      "Ep 19: Batch #185 - Loss: 0.6376543641090393\n",
      "Ep 19: Batch #186 - Loss: 0.7793362736701965\n",
      "Ep 19: Batch #187 - Loss: 0.8929858207702637\n",
      "Ep 19: Batch #188 - Loss: 1.027431607246399\n",
      "Ep 19: Batch #189 - Loss: 0.59298175573349\n",
      "Ep 19: Batch #190 - Loss: 0.6280666589736938\n",
      "Ep 19: Batch #191 - Loss: 0.8234870433807373\n",
      "Ep 19: Batch #192 - Loss: 0.575215756893158\n",
      "Ep 19: Batch #193 - Loss: 0.6295896172523499\n",
      "Ep 19: Batch #194 - Loss: 0.5605745315551758\n",
      "Ep 19: Batch #195 - Loss: 0.8035353422164917\n",
      "Ep 19: Batch #196 - Loss: 0.6983534693717957\n",
      "Ep 19: Batch #197 - Loss: 0.711714506149292\n",
      "Ep 19: Batch #198 - Loss: 0.5397782325744629\n",
      "Ep 19: Batch #199 - Loss: 0.6558781266212463\n",
      "Ep 20: Batch #0 - Loss: 0.6542353630065918\n",
      "Ep 20: Batch #1 - Loss: 0.7192715406417847\n",
      "Ep 20: Batch #2 - Loss: 0.8667656779289246\n",
      "Ep 20: Batch #3 - Loss: 0.7250083684921265\n",
      "Ep 20: Batch #4 - Loss: 0.6597345471382141\n",
      "Ep 20: Batch #5 - Loss: 0.5690900683403015\n",
      "Ep 20: Batch #6 - Loss: 0.750150740146637\n",
      "Ep 20: Batch #7 - Loss: 0.5877246260643005\n",
      "Ep 20: Batch #8 - Loss: 0.5949177742004395\n",
      "Ep 20: Batch #9 - Loss: 1.104965090751648\n",
      "Ep 20: Batch #10 - Loss: 0.8364768028259277\n",
      "Ep 20: Batch #11 - Loss: 0.5482513904571533\n",
      "Ep 20: Batch #12 - Loss: 1.2442518472671509\n",
      "Ep 20: Batch #13 - Loss: 0.577065646648407\n",
      "Ep 20: Batch #14 - Loss: 0.6063762307167053\n",
      "Ep 20: Batch #15 - Loss: 0.9104820489883423\n",
      "Ep 20: Batch #16 - Loss: 0.9709715843200684\n",
      "Ep 20: Batch #17 - Loss: 0.7341796159744263\n",
      "Ep 20: Batch #18 - Loss: 0.8085657358169556\n",
      "Ep 20: Batch #19 - Loss: 0.5668614506721497\n",
      "Ep 20: Batch #20 - Loss: 0.5512460470199585\n",
      "Ep 20: Batch #21 - Loss: 0.9082244038581848\n",
      "Ep 20: Batch #22 - Loss: 0.6174034476280212\n",
      "Ep 20: Batch #23 - Loss: 0.6087200045585632\n",
      "Ep 20: Batch #24 - Loss: 0.6492773294448853\n",
      "Ep 20: Batch #25 - Loss: 0.6159400343894958\n",
      "Ep 20: Batch #26 - Loss: 0.5821632146835327\n",
      "Ep 20: Batch #27 - Loss: 1.1482247114181519\n",
      "Ep 20: Batch #28 - Loss: 0.6989538073539734\n",
      "Ep 20: Batch #29 - Loss: 0.7619034051895142\n",
      "Ep 20: Batch #30 - Loss: 0.904076099395752\n",
      "Ep 20: Batch #31 - Loss: 0.5660349130630493\n",
      "Ep 20: Batch #32 - Loss: 0.5891468524932861\n",
      "Ep 20: Batch #33 - Loss: 0.6750128865242004\n",
      "Ep 20: Batch #34 - Loss: 0.6525207757949829\n",
      "Ep 20: Batch #35 - Loss: 0.7365384101867676\n",
      "Ep 20: Batch #36 - Loss: 0.5852499008178711\n",
      "Ep 20: Batch #37 - Loss: 0.9290564656257629\n",
      "Ep 20: Batch #38 - Loss: 0.5798013806343079\n",
      "Ep 20: Batch #39 - Loss: 0.6892316937446594\n",
      "Ep 20: Batch #40 - Loss: 0.6122470498085022\n",
      "Ep 20: Batch #41 - Loss: 0.6230769753456116\n",
      "Ep 20: Batch #42 - Loss: 0.575120747089386\n",
      "Ep 20: Batch #43 - Loss: 0.6398867964744568\n",
      "Ep 20: Batch #44 - Loss: 0.6262674927711487\n",
      "Ep 20: Batch #45 - Loss: 0.5331095457077026\n",
      "Ep 20: Batch #46 - Loss: 0.7004569172859192\n",
      "Ep 20: Batch #47 - Loss: 0.807691216468811\n",
      "Ep 20: Batch #48 - Loss: 1.056632161140442\n",
      "Ep 20: Batch #49 - Loss: 0.8156735301017761\n",
      "Ep 20: Batch #50 - Loss: 0.5738454461097717\n",
      "Ep 20: Batch #51 - Loss: 0.8202781081199646\n",
      "Ep 20: Batch #52 - Loss: 0.6816071271896362\n",
      "Ep 20: Batch #53 - Loss: 0.7185085415840149\n",
      "Ep 20: Batch #54 - Loss: 0.5885655283927917\n",
      "Ep 20: Batch #55 - Loss: 0.6193938255310059\n",
      "Ep 20: Batch #56 - Loss: 0.890377402305603\n",
      "Ep 20: Batch #57 - Loss: 0.6889305114746094\n",
      "Ep 20: Batch #58 - Loss: 0.8357445001602173\n",
      "Ep 20: Batch #59 - Loss: 0.5711296200752258\n",
      "Ep 20: Batch #60 - Loss: 1.0258430242538452\n",
      "Ep 20: Batch #61 - Loss: 0.5374677181243896\n",
      "Ep 20: Batch #62 - Loss: 0.5847482085227966\n",
      "Ep 20: Batch #63 - Loss: 0.7987226843833923\n",
      "Ep 20: Batch #64 - Loss: 8.743131637573242\n",
      "Ep 20: Batch #65 - Loss: 0.5284609794616699\n",
      "Ep 20: Batch #66 - Loss: 0.673658013343811\n",
      "Ep 20: Batch #67 - Loss: 0.7817433476448059\n",
      "Ep 20: Batch #68 - Loss: 0.7346619963645935\n",
      "Ep 20: Batch #69 - Loss: 0.603342592716217\n",
      "Ep 20: Batch #70 - Loss: 0.620965838432312\n",
      "Ep 20: Batch #71 - Loss: 0.543393611907959\n",
      "Ep 20: Batch #72 - Loss: 0.6685906648635864\n",
      "Ep 20: Batch #73 - Loss: 0.7435000538825989\n",
      "Ep 20: Batch #74 - Loss: 0.5877658724784851\n",
      "Ep 20: Batch #75 - Loss: 0.6711386442184448\n",
      "Ep 20: Batch #76 - Loss: 0.9429897665977478\n",
      "Ep 20: Batch #77 - Loss: 0.585075318813324\n",
      "Ep 20: Batch #78 - Loss: 0.9359930753707886\n",
      "Ep 20: Batch #79 - Loss: 0.532223641872406\n",
      "Ep 20: Batch #80 - Loss: 0.7030794620513916\n",
      "Ep 20: Batch #81 - Loss: 1.5330506563186646\n",
      "Ep 20: Batch #82 - Loss: 0.7545139193534851\n",
      "Ep 20: Batch #83 - Loss: 1.4022265672683716\n",
      "Ep 20: Batch #84 - Loss: 0.5823145508766174\n",
      "Ep 20: Batch #85 - Loss: 0.8039976954460144\n",
      "Ep 20: Batch #86 - Loss: 0.556006908416748\n",
      "Ep 20: Batch #87 - Loss: 0.5765326023101807\n",
      "Ep 20: Batch #88 - Loss: 0.6578049659729004\n",
      "Ep 20: Batch #89 - Loss: 0.7488096356391907\n",
      "Ep 20: Batch #90 - Loss: 0.9053093791007996\n",
      "Ep 20: Batch #91 - Loss: 0.6496398448944092\n",
      "Ep 20: Batch #92 - Loss: 0.7671803832054138\n",
      "Ep 20: Batch #93 - Loss: 0.793357789516449\n",
      "Ep 20: Batch #94 - Loss: 0.785904586315155\n",
      "Ep 20: Batch #95 - Loss: 0.7661665081977844\n",
      "Ep 20: Batch #96 - Loss: 0.7641009092330933\n",
      "Ep 20: Batch #97 - Loss: 0.587115466594696\n",
      "Ep 20: Batch #98 - Loss: 0.5855901837348938\n",
      "Ep 20: Batch #99 - Loss: 0.8050456047058105\n",
      "Ep 20: Batch #100 - Loss: 0.5623693466186523\n",
      "Ep 20: Batch #101 - Loss: 0.8641818761825562\n",
      "Ep 20: Batch #102 - Loss: 0.6259651780128479\n",
      "Ep 20: Batch #103 - Loss: 0.6444545984268188\n",
      "Ep 20: Batch #104 - Loss: 0.6659083366394043\n",
      "Ep 20: Batch #105 - Loss: 0.821921169757843\n",
      "Ep 20: Batch #106 - Loss: 0.6283825039863586\n",
      "Ep 20: Batch #107 - Loss: 0.614258885383606\n",
      "Ep 20: Batch #108 - Loss: 0.9056979417800903\n",
      "Ep 20: Batch #109 - Loss: 0.6332481503486633\n",
      "Ep 20: Batch #110 - Loss: 0.7348345518112183\n",
      "Ep 20: Batch #111 - Loss: 1.058785319328308\n",
      "Ep 20: Batch #112 - Loss: 0.8312676548957825\n",
      "Ep 20: Batch #113 - Loss: 0.6629896759986877\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 20: Batch #114 - Loss: 0.7352879047393799\n",
      "Ep 20: Batch #115 - Loss: 0.909980297088623\n",
      "Ep 20: Batch #116 - Loss: 0.5336548089981079\n",
      "Ep 20: Batch #117 - Loss: 0.6969199180603027\n",
      "Ep 20: Batch #118 - Loss: 0.46200111508369446\n",
      "Ep 20: Batch #119 - Loss: 0.8095837235450745\n",
      "Ep 20: Batch #120 - Loss: 0.6653072834014893\n",
      "Ep 20: Batch #121 - Loss: 0.5703896880149841\n",
      "Ep 20: Batch #122 - Loss: 0.715522289276123\n",
      "Ep 20: Batch #123 - Loss: 0.7261125445365906\n",
      "Ep 20: Batch #124 - Loss: 0.5593675971031189\n",
      "Ep 20: Batch #125 - Loss: 2.471816062927246\n",
      "Ep 20: Batch #126 - Loss: 1.0005167722702026\n",
      "Ep 20: Batch #127 - Loss: 0.5874446630477905\n",
      "Ep 20: Batch #128 - Loss: 0.8875829577445984\n",
      "Ep 20: Batch #129 - Loss: 0.6866436004638672\n",
      "Ep 20: Batch #130 - Loss: 0.6024936437606812\n",
      "Ep 20: Batch #131 - Loss: 0.8072044849395752\n",
      "Ep 20: Batch #132 - Loss: 0.6900295615196228\n",
      "Ep 20: Batch #133 - Loss: 0.6710237860679626\n",
      "Ep 20: Batch #134 - Loss: 0.6457780003547668\n",
      "Ep 20: Batch #135 - Loss: 0.8264995813369751\n",
      "Ep 20: Batch #136 - Loss: 1.046778678894043\n",
      "Ep 20: Batch #137 - Loss: 0.7578416466712952\n",
      "Ep 20: Batch #138 - Loss: 0.9028722047805786\n",
      "Ep 20: Batch #139 - Loss: 0.6952664256095886\n",
      "Ep 20: Batch #140 - Loss: 0.860926628112793\n",
      "Ep 20: Batch #141 - Loss: 1.141460657119751\n",
      "Ep 20: Batch #142 - Loss: 0.6773282885551453\n",
      "Ep 20: Batch #143 - Loss: 0.7735335230827332\n",
      "Ep 20: Batch #144 - Loss: 0.6146961450576782\n",
      "Ep 20: Batch #145 - Loss: 0.602147102355957\n",
      "Ep 20: Batch #146 - Loss: 0.7157619595527649\n",
      "Ep 20: Batch #147 - Loss: 0.6844121813774109\n",
      "Ep 20: Batch #148 - Loss: 0.7679234147071838\n",
      "Ep 20: Batch #149 - Loss: 0.6600292325019836\n",
      "Ep 20: Batch #150 - Loss: 0.7286046147346497\n",
      "Ep 20: Batch #151 - Loss: 0.636827290058136\n",
      "Ep 20: Batch #152 - Loss: 0.6129535436630249\n",
      "Ep 20: Batch #153 - Loss: 0.8474009037017822\n",
      "Ep 20: Batch #154 - Loss: 0.6361501216888428\n",
      "Ep 20: Batch #155 - Loss: 0.6980724930763245\n",
      "Ep 20: Batch #156 - Loss: 0.8157005906105042\n",
      "Ep 20: Batch #157 - Loss: 0.6225003004074097\n",
      "Ep 20: Batch #158 - Loss: 0.7211180329322815\n",
      "Ep 20: Batch #159 - Loss: 0.6239783763885498\n",
      "Ep 20: Batch #160 - Loss: 0.7166926264762878\n",
      "Ep 20: Batch #161 - Loss: 0.6773382425308228\n",
      "Ep 20: Batch #162 - Loss: 0.728223979473114\n",
      "Ep 20: Batch #163 - Loss: 0.7732398509979248\n",
      "Ep 20: Batch #164 - Loss: 0.6562352776527405\n",
      "Ep 20: Batch #165 - Loss: 1.347152590751648\n",
      "Ep 20: Batch #166 - Loss: 0.5404563546180725\n",
      "Ep 20: Batch #167 - Loss: 0.7960383296012878\n",
      "Ep 20: Batch #168 - Loss: 0.6972727179527283\n",
      "Ep 20: Batch #169 - Loss: 0.6774574518203735\n",
      "Ep 20: Batch #170 - Loss: 0.6416527032852173\n",
      "Ep 20: Batch #171 - Loss: 0.6454649567604065\n",
      "Ep 20: Batch #172 - Loss: 0.5378608703613281\n",
      "Ep 20: Batch #173 - Loss: 0.9446302652359009\n",
      "Ep 20: Batch #174 - Loss: 0.4990587532520294\n",
      "Ep 20: Batch #175 - Loss: 0.6484869718551636\n",
      "Ep 20: Batch #176 - Loss: 0.9078807234764099\n",
      "Ep 20: Batch #177 - Loss: 0.6668830513954163\n",
      "Ep 20: Batch #178 - Loss: 0.6362648010253906\n",
      "Ep 20: Batch #179 - Loss: 0.7586626410484314\n",
      "Ep 20: Batch #180 - Loss: 0.661014974117279\n",
      "Ep 20: Batch #181 - Loss: 0.8108974695205688\n",
      "Ep 20: Batch #182 - Loss: 0.6305226683616638\n",
      "Ep 20: Batch #183 - Loss: 0.6162014603614807\n",
      "Ep 20: Batch #184 - Loss: 0.9262158274650574\n",
      "Ep 20: Batch #185 - Loss: 0.6371951103210449\n",
      "Ep 20: Batch #186 - Loss: 0.7776212692260742\n",
      "Ep 20: Batch #187 - Loss: 0.8904585838317871\n",
      "Ep 20: Batch #188 - Loss: 1.0235545635223389\n",
      "Ep 20: Batch #189 - Loss: 0.5925308465957642\n",
      "Ep 20: Batch #190 - Loss: 0.6278666257858276\n",
      "Ep 20: Batch #191 - Loss: 0.8221049904823303\n",
      "Ep 20: Batch #192 - Loss: 0.5746832489967346\n",
      "Ep 20: Batch #193 - Loss: 0.629544198513031\n",
      "Ep 20: Batch #194 - Loss: 0.5590616464614868\n",
      "Ep 20: Batch #195 - Loss: 0.8030816912651062\n",
      "Ep 20: Batch #196 - Loss: 0.6976466178894043\n",
      "Ep 20: Batch #197 - Loss: 0.7102570533752441\n",
      "Ep 20: Batch #198 - Loss: 0.5391284227371216\n",
      "Ep 20: Batch #199 - Loss: 0.6547091007232666\n",
      "Ep 21: Batch #0 - Loss: 0.6536667346954346\n",
      "Ep 21: Batch #1 - Loss: 0.718782901763916\n",
      "Ep 21: Batch #2 - Loss: 0.8659082055091858\n",
      "Ep 21: Batch #3 - Loss: 0.7249163389205933\n",
      "Ep 21: Batch #4 - Loss: 0.6594123840332031\n",
      "Ep 21: Batch #5 - Loss: 0.5684226155281067\n",
      "Ep 21: Batch #6 - Loss: 0.7500502467155457\n",
      "Ep 21: Batch #7 - Loss: 0.5862701535224915\n",
      "Ep 21: Batch #8 - Loss: 0.5942249894142151\n",
      "Ep 21: Batch #9 - Loss: 1.1036276817321777\n",
      "Ep 21: Batch #10 - Loss: 0.8344641327857971\n",
      "Ep 21: Batch #11 - Loss: 0.5477983355522156\n",
      "Ep 21: Batch #12 - Loss: 1.2406412363052368\n",
      "Ep 21: Batch #13 - Loss: 0.5764691829681396\n",
      "Ep 21: Batch #14 - Loss: 0.6063280701637268\n",
      "Ep 21: Batch #15 - Loss: 0.9061635136604309\n",
      "Ep 21: Batch #16 - Loss: 0.9677722454071045\n",
      "Ep 21: Batch #17 - Loss: 0.7338432669639587\n",
      "Ep 21: Batch #18 - Loss: 0.8080868124961853\n",
      "Ep 21: Batch #19 - Loss: 0.566831111907959\n",
      "Ep 21: Batch #20 - Loss: 0.5507042407989502\n",
      "Ep 21: Batch #21 - Loss: 0.9032167792320251\n",
      "Ep 21: Batch #22 - Loss: 0.6172317862510681\n",
      "Ep 21: Batch #23 - Loss: 0.6080321669578552\n",
      "Ep 21: Batch #24 - Loss: 0.6482201218605042\n",
      "Ep 21: Batch #25 - Loss: 0.6153528690338135\n",
      "Ep 21: Batch #26 - Loss: 0.5800884366035461\n",
      "Ep 21: Batch #27 - Loss: 1.1479003429412842\n",
      "Ep 21: Batch #28 - Loss: 0.698406457901001\n",
      "Ep 21: Batch #29 - Loss: 0.7615560293197632\n",
      "Ep 21: Batch #30 - Loss: 0.9005271792411804\n",
      "Ep 21: Batch #31 - Loss: 0.5659157037734985\n",
      "Ep 21: Batch #32 - Loss: 0.5887724161148071\n",
      "Ep 21: Batch #33 - Loss: 0.6741426587104797\n",
      "Ep 21: Batch #34 - Loss: 0.651899516582489\n",
      "Ep 21: Batch #35 - Loss: 0.7352063655853271\n",
      "Ep 21: Batch #36 - Loss: 0.5850401520729065\n",
      "Ep 21: Batch #37 - Loss: 0.9280593395233154\n",
      "Ep 21: Batch #38 - Loss: 0.5791420340538025\n",
      "Ep 21: Batch #39 - Loss: 0.6889601945877075\n",
      "Ep 21: Batch #40 - Loss: 0.6111295223236084\n",
      "Ep 21: Batch #41 - Loss: 0.6229870915412903\n",
      "Ep 21: Batch #42 - Loss: 0.5746765732765198\n",
      "Ep 21: Batch #43 - Loss: 0.6388576030731201\n",
      "Ep 21: Batch #44 - Loss: 0.6247701644897461\n",
      "Ep 21: Batch #45 - Loss: 0.5328402519226074\n",
      "Ep 21: Batch #46 - Loss: 0.7000027298927307\n",
      "Ep 21: Batch #47 - Loss: 0.8074647188186646\n",
      "Ep 21: Batch #48 - Loss: 1.0539977550506592\n",
      "Ep 21: Batch #49 - Loss: 0.8154152035713196\n",
      "Ep 21: Batch #50 - Loss: 0.5736910104751587\n",
      "Ep 21: Batch #51 - Loss: 0.8195610046386719\n",
      "Ep 21: Batch #52 - Loss: 0.6814472079277039\n",
      "Ep 21: Batch #53 - Loss: 0.7181813716888428\n",
      "Ep 21: Batch #54 - Loss: 0.5875770449638367\n",
      "Ep 21: Batch #55 - Loss: 0.6180024147033691\n",
      "Ep 21: Batch #56 - Loss: 0.8866158127784729\n",
      "Ep 21: Batch #57 - Loss: 0.6887139081954956\n",
      "Ep 21: Batch #58 - Loss: 0.8350846767425537\n",
      "Ep 21: Batch #59 - Loss: 0.5703691840171814\n",
      "Ep 21: Batch #60 - Loss: 1.0237488746643066\n",
      "Ep 21: Batch #61 - Loss: 0.5372197031974792\n",
      "Ep 21: Batch #62 - Loss: 0.5833868980407715\n",
      "Ep 21: Batch #63 - Loss: 0.7977412939071655\n",
      "Ep 21: Batch #64 - Loss: 8.730751991271973\n",
      "Ep 21: Batch #65 - Loss: 0.5280181765556335\n",
      "Ep 21: Batch #66 - Loss: 0.6725936532020569\n",
      "Ep 21: Batch #67 - Loss: 0.7812036871910095\n",
      "Ep 21: Batch #68 - Loss: 0.7328464984893799\n",
      "Ep 21: Batch #69 - Loss: 0.6016696691513062\n",
      "Ep 21: Batch #70 - Loss: 0.6210406422615051\n",
      "Ep 21: Batch #71 - Loss: 0.542614758014679\n",
      "Ep 21: Batch #72 - Loss: 0.6676805019378662\n",
      "Ep 21: Batch #73 - Loss: 0.7415003776550293\n",
      "Ep 21: Batch #74 - Loss: 0.5864659547805786\n",
      "Ep 21: Batch #75 - Loss: 0.6712019443511963\n",
      "Ep 21: Batch #76 - Loss: 0.94146329164505\n",
      "Ep 21: Batch #77 - Loss: 0.5835906863212585\n",
      "Ep 21: Batch #78 - Loss: 0.9350607395172119\n",
      "Ep 21: Batch #79 - Loss: 0.5318956971168518\n",
      "Ep 21: Batch #80 - Loss: 0.7021226286888123\n",
      "Ep 21: Batch #81 - Loss: 1.5322813987731934\n",
      "Ep 21: Batch #82 - Loss: 0.7540568113327026\n",
      "Ep 21: Batch #83 - Loss: 1.3961398601531982\n",
      "Ep 21: Batch #84 - Loss: 0.5818277597427368\n",
      "Ep 21: Batch #85 - Loss: 0.8016158938407898\n",
      "Ep 21: Batch #86 - Loss: 0.5554282665252686\n",
      "Ep 21: Batch #87 - Loss: 0.576225757598877\n",
      "Ep 21: Batch #88 - Loss: 0.6575450301170349\n",
      "Ep 21: Batch #89 - Loss: 0.747253954410553\n",
      "Ep 21: Batch #90 - Loss: 0.9043266177177429\n",
      "Ep 21: Batch #91 - Loss: 0.6496201753616333\n",
      "Ep 21: Batch #92 - Loss: 0.7640215754508972\n",
      "Ep 21: Batch #93 - Loss: 0.7921077013015747\n",
      "Ep 21: Batch #94 - Loss: 0.7830380797386169\n",
      "Ep 21: Batch #95 - Loss: 0.7660688757896423\n",
      "Ep 21: Batch #96 - Loss: 0.7635974287986755\n",
      "Ep 21: Batch #97 - Loss: 0.5863114595413208\n",
      "Ep 21: Batch #98 - Loss: 0.5848235487937927\n",
      "Ep 21: Batch #99 - Loss: 0.8047396540641785\n",
      "Ep 21: Batch #100 - Loss: 0.5621447563171387\n",
      "Ep 21: Batch #101 - Loss: 0.863903284072876\n",
      "Ep 21: Batch #102 - Loss: 0.6249335408210754\n",
      "Ep 21: Batch #103 - Loss: 0.6441285610198975\n",
      "Ep 21: Batch #104 - Loss: 0.6655579209327698\n",
      "Ep 21: Batch #105 - Loss: 0.8215963840484619\n",
      "Ep 21: Batch #106 - Loss: 0.627543568611145\n",
      "Ep 21: Batch #107 - Loss: 0.6143012642860413\n",
      "Ep 21: Batch #108 - Loss: 0.9059625267982483\n",
      "Ep 21: Batch #109 - Loss: 0.6324063539505005\n",
      "Ep 21: Batch #110 - Loss: 0.7346599102020264\n",
      "Ep 21: Batch #111 - Loss: 1.056254267692566\n",
      "Ep 21: Batch #112 - Loss: 0.829171359539032\n",
      "Ep 21: Batch #113 - Loss: 0.6626023650169373\n",
      "Ep 21: Batch #114 - Loss: 0.7348618507385254\n",
      "Ep 21: Batch #115 - Loss: 0.9094361066818237\n",
      "Ep 21: Batch #116 - Loss: 0.5332110524177551\n",
      "Ep 21: Batch #117 - Loss: 0.6951963901519775\n",
      "Ep 21: Batch #118 - Loss: 0.4616255760192871\n",
      "Ep 21: Batch #119 - Loss: 0.8084642887115479\n",
      "Ep 21: Batch #120 - Loss: 0.664798378944397\n",
      "Ep 21: Batch #121 - Loss: 0.5706081986427307\n",
      "Ep 21: Batch #122 - Loss: 0.7151506543159485\n",
      "Ep 21: Batch #123 - Loss: 0.7256291508674622\n",
      "Ep 21: Batch #124 - Loss: 0.5591907501220703\n",
      "Ep 21: Batch #125 - Loss: 2.4714443683624268\n",
      "Ep 21: Batch #126 - Loss: 1.0006752014160156\n",
      "Ep 21: Batch #127 - Loss: 0.5871668457984924\n",
      "Ep 21: Batch #128 - Loss: 0.8868584036827087\n",
      "Ep 21: Batch #129 - Loss: 0.6856382489204407\n",
      "Ep 21: Batch #130 - Loss: 0.6019296646118164\n",
      "Ep 21: Batch #131 - Loss: 0.807018518447876\n",
      "Ep 21: Batch #132 - Loss: 0.6895577311515808\n",
      "Ep 21: Batch #133 - Loss: 0.6709025502204895\n",
      "Ep 21: Batch #134 - Loss: 0.6448619365692139\n",
      "Ep 21: Batch #135 - Loss: 0.8261751532554626\n",
      "Ep 21: Batch #136 - Loss: 1.0459085702896118\n",
      "Ep 21: Batch #137 - Loss: 0.7585882544517517\n",
      "Ep 21: Batch #138 - Loss: 0.9021909832954407\n",
      "Ep 21: Batch #139 - Loss: 0.6937180161476135\n",
      "Ep 21: Batch #140 - Loss: 0.8594903945922852\n",
      "Ep 21: Batch #141 - Loss: 1.1405633687973022\n",
      "Ep 21: Batch #142 - Loss: 0.6767941117286682\n",
      "Ep 21: Batch #143 - Loss: 0.7725774049758911\n",
      "Ep 21: Batch #144 - Loss: 0.6145623326301575\n",
      "Ep 21: Batch #145 - Loss: 0.6019871234893799\n",
      "Ep 21: Batch #146 - Loss: 0.7144412398338318\n",
      "Ep 21: Batch #147 - Loss: 0.6824490427970886\n",
      "Ep 21: Batch #148 - Loss: 0.7667697072029114\n",
      "Ep 21: Batch #149 - Loss: 0.6571623086929321\n",
      "Ep 21: Batch #150 - Loss: 0.7277839779853821\n",
      "Ep 21: Batch #151 - Loss: 0.6366370916366577\n",
      "Ep 21: Batch #152 - Loss: 0.612751305103302\n",
      "Ep 21: Batch #153 - Loss: 0.8459186553955078\n",
      "Ep 21: Batch #154 - Loss: 0.6360710859298706\n",
      "Ep 21: Batch #155 - Loss: 0.6971452832221985\n",
      "Ep 21: Batch #156 - Loss: 0.8141369819641113\n",
      "Ep 21: Batch #157 - Loss: 0.6215687394142151\n",
      "Ep 21: Batch #158 - Loss: 0.7209972143173218\n",
      "Ep 21: Batch #159 - Loss: 0.6219322681427002\n",
      "Ep 21: Batch #160 - Loss: 0.7153609991073608\n",
      "Ep 21: Batch #161 - Loss: 0.6765982508659363\n",
      "Ep 21: Batch #162 - Loss: 0.7266973257064819\n",
      "Ep 21: Batch #163 - Loss: 0.7713231444358826\n",
      "Ep 21: Batch #164 - Loss: 0.6554428339004517\n",
      "Ep 21: Batch #165 - Loss: 1.3466317653656006\n",
      "Ep 21: Batch #166 - Loss: 0.5396448969841003\n",
      "Ep 21: Batch #167 - Loss: 0.7907713055610657\n",
      "Ep 21: Batch #168 - Loss: 0.6965664625167847\n",
      "Ep 21: Batch #169 - Loss: 0.676673948764801\n",
      "Ep 21: Batch #170 - Loss: 0.640082836151123\n",
      "Ep 21: Batch #171 - Loss: 0.6448531150817871\n",
      "Ep 21: Batch #172 - Loss: 0.5376916527748108\n",
      "Ep 21: Batch #173 - Loss: 0.9427743554115295\n",
      "Ep 21: Batch #174 - Loss: 0.4986817538738251\n",
      "Ep 21: Batch #175 - Loss: 0.6477912068367004\n",
      "Ep 21: Batch #176 - Loss: 0.9059391617774963\n",
      "Ep 21: Batch #177 - Loss: 0.6658947467803955\n",
      "Ep 21: Batch #178 - Loss: 0.6349828839302063\n",
      "Ep 21: Batch #179 - Loss: 0.7585559487342834\n",
      "Ep 21: Batch #180 - Loss: 0.660486102104187\n",
      "Ep 21: Batch #181 - Loss: 0.809899091720581\n",
      "Ep 21: Batch #182 - Loss: 0.6299973130226135\n",
      "Ep 21: Batch #183 - Loss: 0.6150345206260681\n",
      "Ep 21: Batch #184 - Loss: 0.9260263442993164\n",
      "Ep 21: Batch #185 - Loss: 0.6365883350372314\n",
      "Ep 21: Batch #186 - Loss: 0.7757543325424194\n",
      "Ep 21: Batch #187 - Loss: 0.8873663544654846\n",
      "Ep 21: Batch #188 - Loss: 1.0197231769561768\n",
      "Ep 21: Batch #189 - Loss: 0.5919727683067322\n",
      "Ep 21: Batch #190 - Loss: 0.6276493072509766\n",
      "Ep 21: Batch #191 - Loss: 0.8204708099365234\n",
      "Ep 21: Batch #192 - Loss: 0.5743163824081421\n",
      "Ep 21: Batch #193 - Loss: 0.6293740272521973\n",
      "Ep 21: Batch #194 - Loss: 0.5575982332229614\n",
      "Ep 21: Batch #195 - Loss: 0.8020747303962708\n",
      "Ep 21: Batch #196 - Loss: 0.6969963908195496\n",
      "Ep 21: Batch #197 - Loss: 0.7089787125587463\n",
      "Ep 21: Batch #198 - Loss: 0.5385982990264893\n",
      "Ep 21: Batch #199 - Loss: 0.6537058353424072\n",
      "Ep 22: Batch #0 - Loss: 0.6531668901443481\n",
      "Ep 22: Batch #1 - Loss: 0.71855628490448\n",
      "Ep 22: Batch #2 - Loss: 0.8651885390281677\n",
      "Ep 22: Batch #3 - Loss: 0.7245743870735168\n",
      "Ep 22: Batch #4 - Loss: 0.659244954586029\n",
      "Ep 22: Batch #5 - Loss: 0.56770259141922\n",
      "Ep 22: Batch #6 - Loss: 0.7496474981307983\n",
      "Ep 22: Batch #7 - Loss: 0.5850537419319153\n",
      "Ep 22: Batch #8 - Loss: 0.5935574173927307\n",
      "Ep 22: Batch #9 - Loss: 1.1023508310317993\n",
      "Ep 22: Batch #10 - Loss: 0.8326268196105957\n",
      "Ep 22: Batch #11 - Loss: 0.5473970770835876\n",
      "Ep 22: Batch #12 - Loss: 1.2373569011688232\n",
      "Ep 22: Batch #13 - Loss: 0.5759375691413879\n",
      "Ep 22: Batch #14 - Loss: 0.6061495542526245\n",
      "Ep 22: Batch #15 - Loss: 0.9020390510559082\n",
      "Ep 22: Batch #16 - Loss: 0.9652231931686401\n",
      "Ep 22: Batch #17 - Loss: 0.7335445880889893\n",
      "Ep 22: Batch #18 - Loss: 0.807889997959137\n",
      "Ep 22: Batch #19 - Loss: 0.566940426826477\n",
      "Ep 22: Batch #20 - Loss: 0.5500933527946472\n",
      "Ep 22: Batch #21 - Loss: 0.8987164497375488\n",
      "Ep 22: Batch #22 - Loss: 0.6169604659080505\n",
      "Ep 22: Batch #23 - Loss: 0.6073912978172302\n",
      "Ep 22: Batch #24 - Loss: 0.6471900343894958\n",
      "Ep 22: Batch #25 - Loss: 0.6148728132247925\n",
      "Ep 22: Batch #26 - Loss: 0.5780515074729919\n",
      "Ep 22: Batch #27 - Loss: 1.1477247476577759\n",
      "Ep 22: Batch #28 - Loss: 0.6977651119232178\n",
      "Ep 22: Batch #29 - Loss: 0.7610971331596375\n",
      "Ep 22: Batch #30 - Loss: 0.8967481851577759\n",
      "Ep 22: Batch #31 - Loss: 0.5656183958053589\n",
      "Ep 22: Batch #32 - Loss: 0.5881516337394714\n",
      "Ep 22: Batch #33 - Loss: 0.6735067367553711\n",
      "Ep 22: Batch #34 - Loss: 0.6512319445610046\n",
      "Ep 22: Batch #35 - Loss: 0.734301745891571\n",
      "Ep 22: Batch #36 - Loss: 0.5848954916000366\n",
      "Ep 22: Batch #37 - Loss: 0.9272799491882324\n",
      "Ep 22: Batch #38 - Loss: 0.5785154104232788\n",
      "Ep 22: Batch #39 - Loss: 0.6884088516235352\n",
      "Ep 22: Batch #40 - Loss: 0.610036313533783\n",
      "Ep 22: Batch #41 - Loss: 0.6227392554283142\n",
      "Ep 22: Batch #42 - Loss: 0.5742073059082031\n",
      "Ep 22: Batch #43 - Loss: 0.6381127238273621\n",
      "Ep 22: Batch #44 - Loss: 0.623709499835968\n",
      "Ep 22: Batch #45 - Loss: 0.5324810743331909\n",
      "Ep 22: Batch #46 - Loss: 0.6996660828590393\n",
      "Ep 22: Batch #47 - Loss: 0.8072646260261536\n",
      "Ep 22: Batch #48 - Loss: 1.0520305633544922\n",
      "Ep 22: Batch #49 - Loss: 0.8151435852050781\n",
      "Ep 22: Batch #50 - Loss: 0.573739230632782\n",
      "Ep 22: Batch #51 - Loss: 0.8195834755897522\n",
      "Ep 22: Batch #52 - Loss: 0.6813499927520752\n",
      "Ep 22: Batch #53 - Loss: 0.7179121375083923\n",
      "Ep 22: Batch #54 - Loss: 0.5867800116539001\n",
      "Ep 22: Batch #55 - Loss: 0.6168944239616394\n",
      "Ep 22: Batch #56 - Loss: 0.8834282159805298\n",
      "Ep 22: Batch #57 - Loss: 0.6884382367134094\n",
      "Ep 22: Batch #58 - Loss: 0.8347040414810181\n",
      "Ep 22: Batch #59 - Loss: 0.5696328282356262\n",
      "Ep 22: Batch #60 - Loss: 1.0221943855285645\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 22: Batch #61 - Loss: 0.5370617508888245\n",
      "Ep 22: Batch #62 - Loss: 0.5823206901550293\n",
      "Ep 22: Batch #63 - Loss: 0.7966983318328857\n",
      "Ep 22: Batch #64 - Loss: 8.749855041503906\n",
      "Ep 22: Batch #65 - Loss: 0.5275104641914368\n",
      "Ep 22: Batch #66 - Loss: 0.6726192235946655\n",
      "Ep 22: Batch #67 - Loss: 0.7817658185958862\n",
      "Ep 22: Batch #68 - Loss: 0.7326468229293823\n",
      "Ep 22: Batch #69 - Loss: 0.6017115712165833\n",
      "Ep 22: Batch #70 - Loss: 0.6214082837104797\n",
      "Ep 22: Batch #71 - Loss: 0.5428489446640015\n",
      "Ep 22: Batch #72 - Loss: 0.6729013323783875\n",
      "Ep 22: Batch #73 - Loss: 0.742453396320343\n",
      "Ep 22: Batch #74 - Loss: 0.5873825550079346\n",
      "Ep 22: Batch #75 - Loss: 0.6716312766075134\n",
      "Ep 22: Batch #76 - Loss: 0.9429057240486145\n",
      "Ep 22: Batch #77 - Loss: 0.5835651755332947\n",
      "Ep 22: Batch #78 - Loss: 0.9350191354751587\n",
      "Ep 22: Batch #79 - Loss: 0.5322166681289673\n",
      "Ep 22: Batch #80 - Loss: 0.7028319239616394\n",
      "Ep 22: Batch #81 - Loss: 1.5387203693389893\n",
      "Ep 22: Batch #82 - Loss: 0.7562500238418579\n",
      "Ep 22: Batch #83 - Loss: 1.388449788093567\n",
      "Ep 22: Batch #84 - Loss: 0.5838227868080139\n",
      "Ep 22: Batch #85 - Loss: 0.8052181601524353\n",
      "Ep 22: Batch #86 - Loss: 0.5560932159423828\n",
      "Ep 22: Batch #87 - Loss: 0.5757496356964111\n",
      "Ep 22: Batch #88 - Loss: 0.6581357717514038\n",
      "Ep 22: Batch #89 - Loss: 0.7460386753082275\n",
      "Ep 22: Batch #90 - Loss: 0.9041889309883118\n",
      "Ep 22: Batch #91 - Loss: 0.6493391394615173\n",
      "Ep 22: Batch #92 - Loss: 0.7636443376541138\n",
      "Ep 22: Batch #93 - Loss: 0.791380763053894\n",
      "Ep 22: Batch #94 - Loss: 0.7816706895828247\n",
      "Ep 22: Batch #95 - Loss: 0.7672621607780457\n",
      "Ep 22: Batch #96 - Loss: 0.7660824060440063\n",
      "Ep 22: Batch #97 - Loss: 0.5883201360702515\n",
      "Ep 22: Batch #98 - Loss: 0.585465133190155\n",
      "Ep 22: Batch #99 - Loss: 0.8053252696990967\n",
      "Ep 22: Batch #100 - Loss: 0.5620372891426086\n",
      "Ep 22: Batch #101 - Loss: 0.8637014627456665\n",
      "Ep 22: Batch #102 - Loss: 0.6243340969085693\n",
      "Ep 22: Batch #103 - Loss: 0.6437155604362488\n",
      "Ep 22: Batch #104 - Loss: 0.6650193929672241\n",
      "Ep 22: Batch #105 - Loss: 0.8213937282562256\n",
      "Ep 22: Batch #106 - Loss: 0.6278352737426758\n",
      "Ep 22: Batch #107 - Loss: 0.6137412786483765\n",
      "Ep 22: Batch #108 - Loss: 0.9064438939094543\n",
      "Ep 22: Batch #109 - Loss: 0.6334118247032166\n",
      "Ep 22: Batch #110 - Loss: 0.7341905832290649\n",
      "Ep 22: Batch #111 - Loss: 1.0545580387115479\n",
      "Ep 22: Batch #112 - Loss: 0.8267969489097595\n",
      "Ep 22: Batch #113 - Loss: 0.6628689169883728\n",
      "Ep 22: Batch #114 - Loss: 0.734194278717041\n",
      "Ep 22: Batch #115 - Loss: 0.9098400473594666\n",
      "Ep 22: Batch #116 - Loss: 0.5337029695510864\n",
      "Ep 22: Batch #117 - Loss: 0.6939412355422974\n",
      "Ep 22: Batch #118 - Loss: 0.46131452918052673\n",
      "Model saved in file: ./weights_autoencoder_sigmoid/model_e22b118_1516648794.5526369.ckpt\n",
      "Ep 22: Batch #119 - Loss: 0.8077460527420044\n",
      "Ep 22: Batch #120 - Loss: 0.6652753353118896\n",
      "Ep 22: Batch #121 - Loss: 0.5704095363616943\n",
      "Ep 22: Batch #122 - Loss: 0.7150001525878906\n",
      "Ep 22: Batch #123 - Loss: 0.7254025936126709\n",
      "Ep 22: Batch #124 - Loss: 0.558944821357727\n",
      "Ep 22: Batch #125 - Loss: 2.4707465171813965\n",
      "Ep 22: Batch #126 - Loss: 1.0010697841644287\n",
      "Ep 22: Batch #127 - Loss: 0.5866634845733643\n",
      "Ep 22: Batch #128 - Loss: 0.8868634104728699\n",
      "Ep 22: Batch #129 - Loss: 0.6851973533630371\n",
      "Ep 22: Batch #130 - Loss: 0.6020290851593018\n",
      "Ep 22: Batch #131 - Loss: 0.806896448135376\n",
      "Ep 22: Batch #132 - Loss: 0.6890491247177124\n",
      "Ep 22: Batch #133 - Loss: 0.6706861257553101\n",
      "Ep 22: Batch #134 - Loss: 0.6443444490432739\n",
      "Ep 22: Batch #135 - Loss: 0.8269280791282654\n",
      "Ep 22: Batch #136 - Loss: 1.0452195405960083\n",
      "Ep 22: Batch #137 - Loss: 0.7564032673835754\n",
      "Ep 22: Batch #138 - Loss: 0.9023228883743286\n",
      "Ep 22: Batch #139 - Loss: 0.6927521824836731\n",
      "Ep 22: Batch #140 - Loss: 0.8582962155342102\n",
      "Ep 22: Batch #141 - Loss: 1.1389931440353394\n",
      "Ep 22: Batch #142 - Loss: 0.6760873794555664\n",
      "Ep 22: Batch #143 - Loss: 0.7747085094451904\n",
      "Ep 22: Batch #144 - Loss: 0.6143215894699097\n",
      "Ep 22: Batch #145 - Loss: 0.6023314595222473\n",
      "Ep 22: Batch #146 - Loss: 0.7135775089263916\n",
      "Ep 22: Batch #147 - Loss: 0.6816829442977905\n",
      "Ep 22: Batch #148 - Loss: 0.7659832835197449\n",
      "Ep 22: Batch #149 - Loss: 0.6559721827507019\n",
      "Ep 22: Batch #150 - Loss: 0.7272543907165527\n",
      "Ep 22: Batch #151 - Loss: 0.6360428333282471\n",
      "Ep 22: Batch #152 - Loss: 0.612481415271759\n",
      "Ep 22: Batch #153 - Loss: 0.8448399901390076\n",
      "Ep 22: Batch #154 - Loss: 0.6365262866020203\n",
      "Ep 22: Batch #155 - Loss: 0.7009022831916809\n",
      "Ep 22: Batch #156 - Loss: 0.8117241263389587\n",
      "Ep 22: Batch #157 - Loss: 0.621167778968811\n",
      "Ep 22: Batch #158 - Loss: 0.7204871773719788\n",
      "Ep 22: Batch #159 - Loss: 0.6208556890487671\n",
      "Ep 22: Batch #160 - Loss: 0.7138395309448242\n",
      "Ep 22: Batch #161 - Loss: 0.6762381792068481\n",
      "Ep 22: Batch #162 - Loss: 0.725631833076477\n",
      "Ep 22: Batch #163 - Loss: 0.7708499431610107\n",
      "Ep 22: Batch #164 - Loss: 0.6549479961395264\n",
      "Ep 22: Batch #165 - Loss: 1.3463321924209595\n",
      "Ep 22: Batch #166 - Loss: 0.5391439199447632\n",
      "Ep 22: Batch #167 - Loss: 0.7874661087989807\n",
      "Ep 22: Batch #168 - Loss: 0.6968374848365784\n",
      "Ep 22: Batch #169 - Loss: 0.6761909127235413\n",
      "Ep 22: Batch #170 - Loss: 0.6389456987380981\n",
      "Ep 22: Batch #171 - Loss: 0.6443012356758118\n",
      "Ep 22: Batch #172 - Loss: 0.5373044013977051\n",
      "Ep 22: Batch #173 - Loss: 0.940685510635376\n",
      "Ep 22: Batch #174 - Loss: 0.49857422709465027\n",
      "Ep 22: Batch #175 - Loss: 0.6471513509750366\n",
      "Ep 22: Batch #176 - Loss: 0.9075599312782288\n",
      "Ep 22: Batch #177 - Loss: 0.6647065877914429\n",
      "Ep 22: Batch #178 - Loss: 0.6338464021682739\n",
      "Ep 22: Batch #179 - Loss: 0.7590892910957336\n",
      "Ep 22: Batch #180 - Loss: 0.6609484553337097\n",
      "Ep 22: Batch #181 - Loss: 0.8088822364807129\n",
      "Ep 22: Batch #182 - Loss: 0.6299551129341125\n",
      "Ep 22: Batch #183 - Loss: 0.6142138838768005\n",
      "Ep 22: Batch #184 - Loss: 0.9260438084602356\n",
      "Ep 22: Batch #185 - Loss: 0.6369069218635559\n",
      "Ep 22: Batch #186 - Loss: 0.7746648192405701\n",
      "Ep 22: Batch #187 - Loss: 0.884871780872345\n",
      "Ep 22: Batch #188 - Loss: 1.0165481567382812\n",
      "Ep 22: Batch #189 - Loss: 0.5917137265205383\n",
      "Ep 22: Batch #190 - Loss: 0.6278112530708313\n",
      "Ep 22: Batch #191 - Loss: 0.8215613961219788\n",
      "Ep 22: Batch #192 - Loss: 0.574198305606842\n",
      "Ep 22: Batch #193 - Loss: 0.6295874714851379\n",
      "Ep 22: Batch #194 - Loss: 0.5565605163574219\n",
      "Ep 22: Batch #195 - Loss: 0.8013253808021545\n",
      "Ep 22: Batch #196 - Loss: 0.6968780159950256\n",
      "Ep 22: Batch #197 - Loss: 0.7079864740371704\n",
      "Ep 22: Batch #198 - Loss: 0.5380305051803589\n",
      "Ep 22: Batch #199 - Loss: 0.653087854385376\n",
      "Ep 23: Batch #0 - Loss: 0.6528869271278381\n",
      "Ep 23: Batch #1 - Loss: 0.7182865142822266\n",
      "Ep 23: Batch #2 - Loss: 0.8646600246429443\n",
      "Ep 23: Batch #3 - Loss: 0.7245753407478333\n",
      "Ep 23: Batch #4 - Loss: 0.6591358184814453\n",
      "Ep 23: Batch #5 - Loss: 0.566963255405426\n",
      "Ep 23: Batch #6 - Loss: 0.7494431734085083\n",
      "Ep 23: Batch #7 - Loss: 0.5843287110328674\n",
      "Ep 23: Batch #8 - Loss: 0.5942211747169495\n",
      "Ep 23: Batch #9 - Loss: 1.1024974584579468\n",
      "Ep 23: Batch #10 - Loss: 0.8314105272293091\n",
      "Ep 23: Batch #11 - Loss: 0.5472773909568787\n",
      "Ep 23: Batch #12 - Loss: 1.2349523305892944\n",
      "Ep 23: Batch #13 - Loss: 0.5753781199455261\n",
      "Ep 23: Batch #14 - Loss: 0.6060783863067627\n",
      "Ep 23: Batch #15 - Loss: 0.8994525074958801\n",
      "Ep 23: Batch #16 - Loss: 0.9636492133140564\n",
      "Ep 23: Batch #17 - Loss: 0.7328276038169861\n",
      "Ep 23: Batch #18 - Loss: 0.8075392246246338\n",
      "Ep 23: Batch #19 - Loss: 0.5668690204620361\n",
      "Ep 23: Batch #20 - Loss: 0.5500158071517944\n",
      "Ep 23: Batch #21 - Loss: 0.8936179280281067\n",
      "Ep 23: Batch #22 - Loss: 0.6175298690795898\n",
      "Ep 23: Batch #23 - Loss: 0.6078757643699646\n",
      "Ep 23: Batch #24 - Loss: 0.6459906101226807\n",
      "Ep 23: Batch #25 - Loss: 0.6145462393760681\n",
      "Ep 23: Batch #26 - Loss: 0.5763949155807495\n",
      "Ep 23: Batch #27 - Loss: 1.1475285291671753\n",
      "Ep 23: Batch #28 - Loss: 0.6972519159317017\n",
      "Ep 23: Batch #29 - Loss: 0.7613793015480042\n",
      "Ep 23: Batch #30 - Loss: 0.8930414915084839\n",
      "Ep 23: Batch #31 - Loss: 0.5656883120536804\n",
      "Ep 23: Batch #32 - Loss: 0.587853193283081\n",
      "Ep 23: Batch #33 - Loss: 0.6730298399925232\n",
      "Ep 23: Batch #34 - Loss: 0.651435136795044\n",
      "Ep 23: Batch #35 - Loss: 0.7331423759460449\n",
      "Ep 23: Batch #36 - Loss: 0.5847904086112976\n",
      "Ep 23: Batch #37 - Loss: 0.9268315434455872\n",
      "Ep 23: Batch #38 - Loss: 0.5777580142021179\n",
      "Ep 23: Batch #39 - Loss: 0.6879047751426697\n",
      "Ep 23: Batch #40 - Loss: 0.6099425554275513\n",
      "Ep 23: Batch #41 - Loss: 0.6227245926856995\n",
      "Ep 23: Batch #42 - Loss: 0.5738250017166138\n",
      "Ep 23: Batch #43 - Loss: 0.6375423669815063\n",
      "Ep 23: Batch #44 - Loss: 0.6226107478141785\n",
      "Ep 23: Batch #45 - Loss: 0.5320461392402649\n",
      "Ep 23: Batch #46 - Loss: 0.6992716193199158\n",
      "Ep 23: Batch #47 - Loss: 0.8070679306983948\n",
      "Ep 23: Batch #48 - Loss: 1.0498883724212646\n",
      "Ep 23: Batch #49 - Loss: 0.8146898746490479\n",
      "Ep 23: Batch #50 - Loss: 0.5736785531044006\n",
      "Ep 23: Batch #51 - Loss: 0.8195882439613342\n",
      "Ep 23: Batch #52 - Loss: 0.680910587310791\n",
      "Ep 23: Batch #53 - Loss: 0.7179062962532043\n",
      "Ep 23: Batch #54 - Loss: 0.5860384106636047\n",
      "Ep 23: Batch #55 - Loss: 0.6158562898635864\n",
      "Ep 23: Batch #56 - Loss: 0.8807581663131714\n",
      "Ep 23: Batch #57 - Loss: 0.6884649991989136\n",
      "Ep 23: Batch #58 - Loss: 0.8340771198272705\n",
      "Ep 23: Batch #59 - Loss: 0.5691115856170654\n",
      "Ep 23: Batch #60 - Loss: 1.0218950510025024\n",
      "Ep 23: Batch #61 - Loss: 0.5369986295700073\n",
      "Ep 23: Batch #62 - Loss: 0.5817277431488037\n",
      "Ep 23: Batch #63 - Loss: 0.7956656217575073\n",
      "Ep 23: Batch #64 - Loss: 8.72032356262207\n",
      "Ep 23: Batch #65 - Loss: 0.5273659825325012\n",
      "Ep 23: Batch #66 - Loss: 0.6714127063751221\n",
      "Ep 23: Batch #67 - Loss: 0.7813034653663635\n",
      "Ep 23: Batch #68 - Loss: 0.7304018139839172\n",
      "Ep 23: Batch #69 - Loss: 0.5992497205734253\n",
      "Ep 23: Batch #70 - Loss: 0.621232807636261\n",
      "Ep 23: Batch #71 - Loss: 0.5416446328163147\n",
      "Ep 23: Batch #72 - Loss: 0.6680852174758911\n",
      "Ep 23: Batch #73 - Loss: 0.7388607263565063\n",
      "Ep 23: Batch #74 - Loss: 0.5854487419128418\n",
      "Ep 23: Batch #75 - Loss: 0.6710535883903503\n",
      "Ep 23: Batch #76 - Loss: 0.9391820430755615\n",
      "Ep 23: Batch #77 - Loss: 0.5820081233978271\n",
      "Ep 23: Batch #78 - Loss: 0.9337683320045471\n",
      "Ep 23: Batch #79 - Loss: 0.5315003991127014\n",
      "Ep 23: Batch #80 - Loss: 0.7010394334793091\n",
      "Ep 23: Batch #81 - Loss: 1.5347249507904053\n",
      "Ep 23: Batch #82 - Loss: 0.7537204027175903\n",
      "Ep 23: Batch #83 - Loss: 1.383839726448059\n",
      "Ep 23: Batch #84 - Loss: 0.5816924571990967\n",
      "Ep 23: Batch #85 - Loss: 0.8011139035224915\n",
      "Ep 23: Batch #86 - Loss: 0.5547299981117249\n",
      "Ep 23: Batch #87 - Loss: 0.5754978060722351\n",
      "Ep 23: Batch #88 - Loss: 0.6575427651405334\n",
      "Ep 23: Batch #89 - Loss: 0.7441620230674744\n",
      "Ep 23: Batch #90 - Loss: 0.9028170704841614\n",
      "Ep 23: Batch #91 - Loss: 0.649768590927124\n",
      "Ep 23: Batch #92 - Loss: 0.7583262920379639\n",
      "Ep 23: Batch #93 - Loss: 0.7904449701309204\n",
      "Ep 23: Batch #94 - Loss: 0.7788308262825012\n",
      "Ep 23: Batch #95 - Loss: 0.7647096514701843\n",
      "Ep 23: Batch #96 - Loss: 0.7634785175323486\n",
      "Ep 23: Batch #97 - Loss: 0.5864980220794678\n",
      "Ep 23: Batch #98 - Loss: 0.5839165449142456\n",
      "Ep 23: Batch #99 - Loss: 0.8037895560264587\n",
      "Ep 23: Batch #100 - Loss: 0.5613808631896973\n",
      "Ep 23: Batch #101 - Loss: 0.8628807067871094\n",
      "Ep 23: Batch #102 - Loss: 0.6225115060806274\n",
      "Ep 23: Batch #103 - Loss: 0.6425997018814087\n",
      "Ep 23: Batch #104 - Loss: 0.6646369099617004\n",
      "Ep 23: Batch #105 - Loss: 0.8210479021072388\n",
      "Ep 23: Batch #106 - Loss: 0.6269316077232361\n",
      "Ep 23: Batch #107 - Loss: 0.6135326623916626\n",
      "Ep 23: Batch #108 - Loss: 0.9051997065544128\n",
      "Ep 23: Batch #109 - Loss: 0.632311224937439\n",
      "Ep 23: Batch #110 - Loss: 0.7334129214286804\n",
      "Ep 23: Batch #111 - Loss: 1.0526117086410522\n",
      "Ep 23: Batch #112 - Loss: 0.8255987167358398\n",
      "Ep 23: Batch #113 - Loss: 0.6621050238609314\n",
      "Ep 23: Batch #114 - Loss: 0.7334497570991516\n",
      "Ep 23: Batch #115 - Loss: 0.9084855318069458\n",
      "Ep 23: Batch #116 - Loss: 0.5326986312866211\n",
      "Ep 23: Batch #117 - Loss: 0.6925620436668396\n",
      "Ep 23: Batch #118 - Loss: 0.46119484305381775\n",
      "Model saved in file: ./weights_autoencoder_sigmoid/model_e23b118_1516648794.6946375.ckpt\n",
      "Ep 23: Batch #119 - Loss: 0.8070956468582153\n",
      "Ep 23: Batch #120 - Loss: 0.6641645431518555\n",
      "Ep 23: Batch #121 - Loss: 0.56962651014328\n",
      "Ep 23: Batch #122 - Loss: 0.7152094841003418\n",
      "Ep 23: Batch #123 - Loss: 0.724478542804718\n",
      "Ep 23: Batch #124 - Loss: 0.5587645769119263\n",
      "Ep 23: Batch #125 - Loss: 2.470742702484131\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 23: Batch #126 - Loss: 1.000799536705017\n",
      "Ep 23: Batch #127 - Loss: 0.5862936973571777\n",
      "Ep 23: Batch #128 - Loss: 0.8871288299560547\n",
      "Ep 23: Batch #129 - Loss: 0.6848182082176208\n",
      "Ep 23: Batch #130 - Loss: 0.6015253067016602\n",
      "Ep 23: Batch #131 - Loss: 0.8071044683456421\n",
      "Ep 23: Batch #132 - Loss: 0.6887271404266357\n",
      "Ep 23: Batch #133 - Loss: 0.6703665256500244\n",
      "Ep 23: Batch #134 - Loss: 0.6433733701705933\n",
      "Ep 23: Batch #135 - Loss: 0.8265637755393982\n",
      "Ep 23: Batch #136 - Loss: 1.0447670221328735\n",
      "Ep 23: Batch #137 - Loss: 0.7567013502120972\n",
      "Ep 23: Batch #138 - Loss: 0.9017806649208069\n",
      "Ep 23: Batch #139 - Loss: 0.693289041519165\n",
      "Ep 23: Batch #140 - Loss: 0.8564807772636414\n",
      "Ep 23: Batch #141 - Loss: 1.13883376121521\n",
      "Ep 23: Batch #142 - Loss: 0.6756464242935181\n",
      "Ep 23: Batch #143 - Loss: 0.7729106545448303\n",
      "Ep 23: Batch #144 - Loss: 0.61429363489151\n",
      "Ep 23: Batch #145 - Loss: 0.6019376516342163\n",
      "Ep 23: Batch #146 - Loss: 0.7122053503990173\n",
      "Ep 23: Batch #147 - Loss: 0.6802438497543335\n",
      "Ep 23: Batch #148 - Loss: 0.7649681568145752\n",
      "Ep 23: Batch #149 - Loss: 0.6530827283859253\n",
      "Ep 23: Batch #150 - Loss: 0.7264940738677979\n",
      "Ep 23: Batch #151 - Loss: 0.6354683041572571\n",
      "Ep 23: Batch #152 - Loss: 0.612230122089386\n",
      "Ep 23: Batch #153 - Loss: 0.8433811664581299\n",
      "Ep 23: Batch #154 - Loss: 0.636269211769104\n",
      "Ep 23: Batch #155 - Loss: 0.697914719581604\n",
      "Ep 23: Batch #156 - Loss: 0.810745358467102\n",
      "Ep 23: Batch #157 - Loss: 0.6205266714096069\n",
      "Ep 23: Batch #158 - Loss: 0.7201715111732483\n",
      "Ep 23: Batch #159 - Loss: 0.6189977526664734\n",
      "Ep 23: Batch #160 - Loss: 0.7127033472061157\n",
      "Ep 23: Batch #161 - Loss: 0.675518274307251\n",
      "Ep 23: Batch #162 - Loss: 0.7245356440544128\n",
      "Ep 23: Batch #163 - Loss: 0.7691780924797058\n",
      "Ep 23: Batch #164 - Loss: 0.6539784073829651\n",
      "Ep 23: Batch #165 - Loss: 1.3463339805603027\n",
      "Ep 23: Batch #166 - Loss: 0.5386770367622375\n",
      "Ep 23: Batch #167 - Loss: 0.7831059694290161\n",
      "Ep 23: Batch #168 - Loss: 0.6956579089164734\n",
      "Ep 23: Batch #169 - Loss: 0.675273597240448\n",
      "Ep 23: Batch #170 - Loss: 0.6376877427101135\n",
      "Ep 23: Batch #171 - Loss: 0.6438493132591248\n",
      "Ep 23: Batch #172 - Loss: 0.5370355844497681\n",
      "Ep 23: Batch #173 - Loss: 0.939468264579773\n",
      "Ep 23: Batch #174 - Loss: 0.49836432933807373\n",
      "Ep 23: Batch #175 - Loss: 0.6464020609855652\n",
      "Ep 23: Batch #176 - Loss: 0.905309796333313\n",
      "Ep 23: Batch #177 - Loss: 0.6637376546859741\n",
      "Ep 23: Batch #178 - Loss: 0.6330226063728333\n",
      "Ep 23: Batch #179 - Loss: 0.7575114369392395\n",
      "Ep 23: Batch #180 - Loss: 0.6600548624992371\n",
      "Ep 23: Batch #181 - Loss: 0.8082603216171265\n",
      "Ep 23: Batch #182 - Loss: 0.629400908946991\n",
      "Ep 23: Batch #183 - Loss: 0.6134495735168457\n",
      "Ep 23: Batch #184 - Loss: 0.9260392785072327\n",
      "Ep 23: Batch #185 - Loss: 0.6364504098892212\n",
      "Ep 23: Batch #186 - Loss: 0.7728621363639832\n",
      "Ep 23: Batch #187 - Loss: 0.88297039270401\n",
      "Ep 23: Batch #188 - Loss: 1.0134646892547607\n",
      "Ep 23: Batch #189 - Loss: 0.5915505886077881\n",
      "Ep 23: Batch #190 - Loss: 0.627396821975708\n",
      "Ep 23: Batch #191 - Loss: 0.8197173476219177\n",
      "Ep 23: Batch #192 - Loss: 0.5737531781196594\n",
      "Ep 23: Batch #193 - Loss: 0.6297249794006348\n",
      "Ep 23: Batch #194 - Loss: 0.5555694103240967\n",
      "Ep 23: Batch #195 - Loss: 0.8003787994384766\n",
      "Ep 23: Batch #196 - Loss: 0.6964541077613831\n",
      "Ep 23: Batch #197 - Loss: 0.7072202563285828\n",
      "Ep 23: Batch #198 - Loss: 0.5376102328300476\n",
      "Ep 23: Batch #199 - Loss: 0.6524460315704346\n",
      "Ep 24: Batch #0 - Loss: 0.6526328325271606\n",
      "Ep 24: Batch #1 - Loss: 0.7179021239280701\n",
      "Ep 24: Batch #2 - Loss: 0.863855242729187\n",
      "Ep 24: Batch #3 - Loss: 0.7243978381156921\n",
      "Ep 24: Batch #4 - Loss: 0.6590472459793091\n",
      "Ep 24: Batch #5 - Loss: 0.5665730237960815\n",
      "Ep 24: Batch #6 - Loss: 0.7497331500053406\n",
      "Ep 24: Batch #7 - Loss: 0.5837154388427734\n",
      "Ep 24: Batch #8 - Loss: 0.5935226082801819\n",
      "Ep 24: Batch #9 - Loss: 1.1017173528671265\n",
      "Ep 24: Batch #10 - Loss: 0.8296786546707153\n",
      "Ep 24: Batch #11 - Loss: 0.5470082759857178\n",
      "Ep 24: Batch #12 - Loss: 1.2330358028411865\n",
      "Ep 24: Batch #13 - Loss: 0.5750822424888611\n",
      "Ep 24: Batch #14 - Loss: 0.6059339046478271\n",
      "Ep 24: Batch #15 - Loss: 0.8958710432052612\n",
      "Ep 24: Batch #16 - Loss: 0.9620417356491089\n",
      "Ep 24: Batch #17 - Loss: 0.732671856880188\n",
      "Ep 24: Batch #18 - Loss: 0.8073845505714417\n",
      "Ep 24: Batch #19 - Loss: 0.5668110251426697\n",
      "Ep 24: Batch #20 - Loss: 0.5497532486915588\n",
      "Ep 24: Batch #21 - Loss: 0.8902116417884827\n",
      "Ep 24: Batch #22 - Loss: 0.6171111464500427\n",
      "Ep 24: Batch #23 - Loss: 0.6068457961082458\n",
      "Ep 24: Batch #24 - Loss: 0.6456092000007629\n",
      "Ep 24: Batch #25 - Loss: 0.6141296029090881\n",
      "Ep 24: Batch #26 - Loss: 0.5748587250709534\n",
      "Ep 24: Batch #27 - Loss: 1.147385597229004\n",
      "Ep 24: Batch #28 - Loss: 0.6966941952705383\n",
      "Ep 24: Batch #29 - Loss: 0.7608617544174194\n",
      "Ep 24: Batch #30 - Loss: 0.8902983069419861\n",
      "Ep 24: Batch #31 - Loss: 0.5653383135795593\n",
      "Ep 24: Batch #32 - Loss: 0.5875258445739746\n",
      "Ep 24: Batch #33 - Loss: 0.672722578048706\n",
      "Ep 24: Batch #34 - Loss: 0.6507750153541565\n",
      "Ep 24: Batch #35 - Loss: 0.732463538646698\n",
      "Ep 24: Batch #36 - Loss: 0.5844748616218567\n",
      "Ep 24: Batch #37 - Loss: 0.9270737767219543\n",
      "Ep 24: Batch #38 - Loss: 0.5774534344673157\n",
      "Ep 24: Batch #39 - Loss: 0.6875869631767273\n",
      "Ep 24: Batch #40 - Loss: 0.6089998483657837\n",
      "Ep 24: Batch #41 - Loss: 0.6225536465644836\n",
      "Ep 24: Batch #42 - Loss: 0.5737199187278748\n",
      "Ep 24: Batch #43 - Loss: 0.6370669007301331\n",
      "Ep 24: Batch #44 - Loss: 0.6218633055686951\n",
      "Ep 24: Batch #45 - Loss: 0.5315185189247131\n",
      "Ep 24: Batch #46 - Loss: 0.6991483569145203\n",
      "Ep 24: Batch #47 - Loss: 0.806909441947937\n",
      "Ep 24: Batch #48 - Loss: 1.0486211776733398\n",
      "Ep 24: Batch #49 - Loss: 0.8144335150718689\n",
      "Ep 24: Batch #50 - Loss: 0.5734909176826477\n",
      "Ep 24: Batch #51 - Loss: 0.8194854855537415\n",
      "Ep 24: Batch #52 - Loss: 0.6808704733848572\n",
      "Ep 24: Batch #53 - Loss: 0.7177402973175049\n",
      "Ep 24: Batch #54 - Loss: 0.5854432582855225\n",
      "Ep 24: Batch #55 - Loss: 0.6150389909744263\n",
      "Ep 24: Batch #56 - Loss: 0.8787728548049927\n",
      "Ep 24: Batch #57 - Loss: 0.6879435777664185\n",
      "Ep 24: Batch #58 - Loss: 0.8338014483451843\n",
      "Ep 24: Batch #59 - Loss: 0.5684253573417664\n",
      "Ep 24: Batch #60 - Loss: 1.0205172300338745\n",
      "Ep 24: Batch #61 - Loss: 0.5369504690170288\n",
      "Ep 24: Batch #62 - Loss: 0.5812263488769531\n",
      "Ep 24: Batch #63 - Loss: 0.7955536246299744\n",
      "Ep 24: Batch #64 - Loss: 8.70799446105957\n",
      "Ep 24: Batch #65 - Loss: 0.5271827578544617\n",
      "Ep 24: Batch #66 - Loss: 0.6710307598114014\n",
      "Ep 24: Batch #67 - Loss: 0.7806235551834106\n",
      "Ep 24: Batch #68 - Loss: 0.7289048433303833\n",
      "Ep 24: Batch #69 - Loss: 0.5981607437133789\n",
      "Ep 24: Batch #70 - Loss: 0.621174156665802\n",
      "Ep 24: Batch #71 - Loss: 0.5413225889205933\n",
      "Ep 24: Batch #72 - Loss: 0.6671454310417175\n",
      "Ep 24: Batch #73 - Loss: 0.7376230359077454\n",
      "Ep 24: Batch #74 - Loss: 0.5842291116714478\n",
      "Ep 24: Batch #75 - Loss: 0.6713405847549438\n",
      "Ep 24: Batch #76 - Loss: 0.9383096098899841\n",
      "Ep 24: Batch #77 - Loss: 0.5813166499137878\n",
      "Ep 24: Batch #78 - Loss: 0.9335508942604065\n",
      "Ep 24: Batch #79 - Loss: 0.5313547253608704\n",
      "Ep 24: Batch #80 - Loss: 0.7001656293869019\n",
      "Ep 24: Batch #81 - Loss: 1.5325534343719482\n",
      "Ep 24: Batch #82 - Loss: 0.7539181709289551\n",
      "Ep 24: Batch #83 - Loss: 1.3789671659469604\n",
      "Ep 24: Batch #84 - Loss: 0.5808591246604919\n",
      "Ep 24: Batch #85 - Loss: 0.7996549606323242\n",
      "Ep 24: Batch #86 - Loss: 0.5542700886726379\n",
      "Ep 24: Batch #87 - Loss: 0.5752851963043213\n",
      "Ep 24: Batch #88 - Loss: 0.6571261286735535\n",
      "Ep 24: Batch #89 - Loss: 0.7429504990577698\n",
      "Ep 24: Batch #90 - Loss: 0.9016086459159851\n",
      "Ep 24: Batch #91 - Loss: 0.6498833894729614\n",
      "Ep 24: Batch #92 - Loss: 0.7553406953811646\n",
      "Ep 24: Batch #93 - Loss: 0.7900820374488831\n",
      "Ep 24: Batch #94 - Loss: 0.7768660187721252\n",
      "Ep 24: Batch #95 - Loss: 0.7643070220947266\n",
      "Ep 24: Batch #96 - Loss: 0.7630220055580139\n",
      "Ep 24: Batch #97 - Loss: 0.5862391591072083\n",
      "Ep 24: Batch #98 - Loss: 0.5834088921546936\n",
      "Ep 24: Batch #99 - Loss: 0.8037926554679871\n",
      "Ep 24: Batch #100 - Loss: 0.5614299774169922\n",
      "Ep 24: Batch #101 - Loss: 0.8626466393470764\n",
      "Ep 24: Batch #102 - Loss: 0.6210760474205017\n",
      "Ep 24: Batch #103 - Loss: 0.6422623991966248\n",
      "Ep 24: Batch #104 - Loss: 0.6643475890159607\n",
      "Ep 24: Batch #105 - Loss: 0.8202921748161316\n",
      "Ep 24: Batch #106 - Loss: 0.6267843246459961\n",
      "Ep 24: Batch #107 - Loss: 0.6135212182998657\n",
      "Ep 24: Batch #108 - Loss: 0.9049239158630371\n",
      "Ep 24: Batch #109 - Loss: 0.6321739554405212\n",
      "Ep 24: Batch #110 - Loss: 0.7328400015830994\n",
      "Ep 24: Batch #111 - Loss: 1.051174521446228\n",
      "Ep 24: Batch #112 - Loss: 0.8238750696182251\n",
      "Ep 24: Batch #113 - Loss: 0.6617234945297241\n",
      "Ep 24: Batch #114 - Loss: 0.733015239238739\n",
      "Ep 24: Batch #115 - Loss: 0.9078827500343323\n",
      "Ep 24: Batch #116 - Loss: 0.5317265391349792\n",
      "Ep 24: Batch #117 - Loss: 0.6911725997924805\n",
      "Ep 24: Batch #118 - Loss: 0.46077537536621094\n",
      "Model saved in file: ./weights_autoencoder_sigmoid/model_e24b118_1516648794.839575.ckpt\n",
      "Ep 24: Batch #119 - Loss: 0.8069781064987183\n",
      "Ep 24: Batch #120 - Loss: 0.6637793779373169\n",
      "Ep 24: Batch #121 - Loss: 0.5691467523574829\n",
      "Ep 24: Batch #122 - Loss: 0.7153699994087219\n",
      "Ep 24: Batch #123 - Loss: 0.7242200374603271\n",
      "Ep 24: Batch #124 - Loss: 0.558586597442627\n",
      "Ep 24: Batch #125 - Loss: 2.470292568206787\n",
      "Ep 24: Batch #126 - Loss: 1.0000219345092773\n",
      "Ep 24: Batch #127 - Loss: 0.5859578847885132\n",
      "Ep 24: Batch #128 - Loss: 0.8862302303314209\n",
      "Ep 24: Batch #129 - Loss: 0.684756875038147\n",
      "Ep 24: Batch #130 - Loss: 0.6012502312660217\n",
      "Ep 24: Batch #131 - Loss: 0.8071120381355286\n",
      "Ep 24: Batch #132 - Loss: 0.6881818771362305\n",
      "Ep 24: Batch #133 - Loss: 0.6701024770736694\n",
      "Ep 24: Batch #134 - Loss: 0.642514705657959\n",
      "Ep 24: Batch #135 - Loss: 0.8267229199409485\n",
      "Ep 24: Batch #136 - Loss: 1.0442255735397339\n",
      "Ep 24: Batch #137 - Loss: 0.7565946578979492\n",
      "Ep 24: Batch #138 - Loss: 0.9013128280639648\n",
      "Ep 24: Batch #139 - Loss: 0.6934486031532288\n",
      "Ep 24: Batch #140 - Loss: 0.855195939540863\n",
      "Ep 24: Batch #141 - Loss: 1.1381492614746094\n",
      "Ep 24: Batch #142 - Loss: 0.6752652525901794\n",
      "Ep 24: Batch #143 - Loss: 0.7722473740577698\n",
      "Ep 24: Batch #144 - Loss: 0.6140120029449463\n",
      "Ep 24: Batch #145 - Loss: 0.6015551090240479\n",
      "Ep 24: Batch #146 - Loss: 0.7112804055213928\n",
      "Ep 24: Batch #147 - Loss: 0.6793162226676941\n",
      "Ep 24: Batch #148 - Loss: 0.7643483877182007\n",
      "Ep 24: Batch #149 - Loss: 0.6506492495536804\n",
      "Ep 24: Batch #150 - Loss: 0.7260986566543579\n",
      "Ep 24: Batch #151 - Loss: 0.6350875496864319\n",
      "Ep 24: Batch #152 - Loss: 0.61185222864151\n",
      "Ep 24: Batch #153 - Loss: 0.8420331478118896\n",
      "Ep 24: Batch #154 - Loss: 0.6362616419792175\n",
      "Ep 24: Batch #155 - Loss: 0.6964825391769409\n",
      "Ep 24: Batch #156 - Loss: 0.8089832663536072\n",
      "Ep 24: Batch #157 - Loss: 0.6203902363777161\n",
      "Ep 24: Batch #158 - Loss: 0.7198056578636169\n",
      "Ep 24: Batch #159 - Loss: 0.6174061298370361\n",
      "Ep 24: Batch #160 - Loss: 0.7117059230804443\n",
      "Ep 24: Batch #161 - Loss: 0.6748912334442139\n",
      "Ep 24: Batch #162 - Loss: 0.723747968673706\n",
      "Ep 24: Batch #163 - Loss: 0.7679712772369385\n",
      "Ep 24: Batch #164 - Loss: 0.653282880783081\n",
      "Ep 24: Batch #165 - Loss: 1.3462353944778442\n",
      "Ep 24: Batch #166 - Loss: 0.5380726456642151\n",
      "Ep 24: Batch #167 - Loss: 0.7792772054672241\n",
      "Ep 24: Batch #168 - Loss: 0.695206344127655\n",
      "Ep 24: Batch #169 - Loss: 0.674354612827301\n",
      "Ep 24: Batch #170 - Loss: 0.6366972923278809\n",
      "Ep 24: Batch #171 - Loss: 0.6434812545776367\n",
      "Ep 24: Batch #172 - Loss: 0.5367811322212219\n",
      "Ep 24: Batch #173 - Loss: 0.938225507736206\n",
      "Ep 24: Batch #174 - Loss: 0.49807173013687134\n",
      "Ep 24: Batch #175 - Loss: 0.6455634236335754\n",
      "Ep 24: Batch #176 - Loss: 0.9038276672363281\n",
      "Ep 24: Batch #177 - Loss: 0.6627292037010193\n",
      "Ep 24: Batch #178 - Loss: 0.6319977641105652\n",
      "Ep 24: Batch #179 - Loss: 0.7562745809555054\n",
      "Ep 24: Batch #180 - Loss: 0.6591185331344604\n",
      "Ep 24: Batch #181 - Loss: 0.8081070184707642\n",
      "Ep 24: Batch #182 - Loss: 0.6292912364006042\n",
      "Ep 24: Batch #183 - Loss: 0.6128129959106445\n",
      "Ep 24: Batch #184 - Loss: 0.9256724119186401\n",
      "Ep 24: Batch #185 - Loss: 0.6365081071853638\n",
      "Ep 24: Batch #186 - Loss: 0.7709973454475403\n",
      "Ep 24: Batch #187 - Loss: 0.8819684982299805\n",
      "Ep 24: Batch #188 - Loss: 1.0106678009033203\n",
      "Ep 24: Batch #189 - Loss: 0.5910911560058594\n",
      "Ep 24: Batch #190 - Loss: 0.6269980072975159\n",
      "Ep 24: Batch #191 - Loss: 0.8188145160675049\n",
      "Ep 24: Batch #192 - Loss: 0.5733804106712341\n",
      "Ep 24: Batch #193 - Loss: 0.6296996474266052\n",
      "Ep 24: Batch #194 - Loss: 0.5544900298118591\n",
      "Ep 24: Batch #195 - Loss: 0.7994367480278015\n",
      "Ep 24: Batch #196 - Loss: 0.6958876252174377\n",
      "Ep 24: Batch #197 - Loss: 0.706482470035553\n",
      "Ep 24: Batch #198 - Loss: 0.5371333956718445\n",
      "Ep 24: Batch #199 - Loss: 0.6516243815422058\n",
      "Ep 25: Batch #0 - Loss: 0.6526190042495728\n",
      "Ep 25: Batch #1 - Loss: 0.717587947845459\n",
      "Ep 25: Batch #2 - Loss: 0.8628684282302856\n",
      "Ep 25: Batch #3 - Loss: 0.7239642143249512\n",
      "Ep 25: Batch #4 - Loss: 0.6590939164161682\n",
      "Ep 25: Batch #5 - Loss: 0.5663233995437622\n",
      "Ep 25: Batch #6 - Loss: 0.7498428225517273\n",
      "Ep 25: Batch #7 - Loss: 0.5829337239265442\n",
      "Ep 25: Batch #8 - Loss: 0.5924298167228699\n",
      "Ep 25: Batch #9 - Loss: 1.1009503602981567\n",
      "Ep 25: Batch #10 - Loss: 0.828371524810791\n",
      "Ep 25: Batch #11 - Loss: 0.546786904335022\n",
      "Ep 25: Batch #12 - Loss: 1.2314704656600952\n",
      "Ep 25: Batch #13 - Loss: 0.5745783448219299\n",
      "Ep 25: Batch #14 - Loss: 0.6055163741111755\n",
      "Ep 25: Batch #15 - Loss: 0.8931999206542969\n",
      "Ep 25: Batch #16 - Loss: 0.960786759853363\n",
      "Ep 25: Batch #17 - Loss: 0.7320215702056885\n",
      "Ep 25: Batch #18 - Loss: 0.8073269128799438\n",
      "Ep 25: Batch #19 - Loss: 0.5665907263755798\n",
      "Ep 25: Batch #20 - Loss: 0.5495129823684692\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 25: Batch #21 - Loss: 0.8868288993835449\n",
      "Ep 25: Batch #22 - Loss: 0.6168692708015442\n",
      "Ep 25: Batch #23 - Loss: 0.6059675216674805\n",
      "Ep 25: Batch #24 - Loss: 0.6451094150543213\n",
      "Ep 25: Batch #25 - Loss: 0.613574743270874\n",
      "Ep 25: Batch #26 - Loss: 0.5735501050949097\n",
      "Ep 25: Batch #27 - Loss: 1.1468100547790527\n",
      "Ep 25: Batch #28 - Loss: 0.696222722530365\n",
      "Ep 25: Batch #29 - Loss: 0.7607964277267456\n",
      "Ep 25: Batch #30 - Loss: 0.8880274891853333\n",
      "Ep 25: Batch #31 - Loss: 0.5649698376655579\n",
      "Ep 25: Batch #32 - Loss: 0.5867366790771484\n",
      "Ep 25: Batch #33 - Loss: 0.6729379296302795\n",
      "Ep 25: Batch #34 - Loss: 0.6504454612731934\n",
      "Ep 25: Batch #35 - Loss: 0.731727123260498\n",
      "Ep 25: Batch #36 - Loss: 0.5843538641929626\n",
      "Ep 25: Batch #37 - Loss: 0.9260469079017639\n",
      "Ep 25: Batch #38 - Loss: 0.5773270726203918\n",
      "Ep 25: Batch #39 - Loss: 0.687483012676239\n",
      "Ep 25: Batch #40 - Loss: 0.6087932586669922\n",
      "Ep 25: Batch #41 - Loss: 0.6224479079246521\n",
      "Ep 25: Batch #42 - Loss: 0.5733760595321655\n",
      "Ep 25: Batch #43 - Loss: 0.6365230679512024\n",
      "Ep 25: Batch #44 - Loss: 0.6210575699806213\n",
      "Ep 25: Batch #45 - Loss: 0.5313214063644409\n",
      "Ep 25: Batch #46 - Loss: 0.6989717483520508\n",
      "Ep 25: Batch #47 - Loss: 0.8067867755889893\n",
      "Ep 25: Batch #48 - Loss: 1.0472408533096313\n",
      "Ep 25: Batch #49 - Loss: 0.8143940567970276\n",
      "Ep 25: Batch #50 - Loss: 0.5736053586006165\n",
      "Ep 25: Batch #51 - Loss: 0.8188595771789551\n",
      "Ep 25: Batch #52 - Loss: 0.6803410053253174\n",
      "Ep 25: Batch #53 - Loss: 0.7176693081855774\n",
      "Ep 25: Batch #54 - Loss: 0.584926187992096\n",
      "Ep 25: Batch #55 - Loss: 0.6149131655693054\n",
      "Ep 25: Batch #56 - Loss: 0.8768893480300903\n",
      "Ep 25: Batch #57 - Loss: 0.6874694228172302\n",
      "Ep 25: Batch #58 - Loss: 0.8334420919418335\n",
      "Ep 25: Batch #59 - Loss: 0.5680370926856995\n",
      "Ep 25: Batch #60 - Loss: 1.0216251611709595\n",
      "Ep 25: Batch #61 - Loss: 0.5365476012229919\n",
      "Ep 25: Batch #62 - Loss: 0.5797812938690186\n",
      "Ep 25: Batch #63 - Loss: 0.7944573760032654\n",
      "Ep 25: Batch #64 - Loss: 8.697442054748535\n",
      "Ep 25: Batch #65 - Loss: 0.5268105864524841\n",
      "Ep 25: Batch #66 - Loss: 0.6703509092330933\n",
      "Ep 25: Batch #67 - Loss: 0.7808107137680054\n",
      "Ep 25: Batch #68 - Loss: 0.7273048162460327\n",
      "Ep 25: Batch #69 - Loss: 0.5971866846084595\n",
      "Ep 25: Batch #70 - Loss: 0.620924174785614\n",
      "Ep 25: Batch #71 - Loss: 0.5406399369239807\n",
      "Ep 25: Batch #72 - Loss: 0.6667625904083252\n",
      "Ep 25: Batch #73 - Loss: 0.7364226579666138\n",
      "Ep 25: Batch #74 - Loss: 0.5839376449584961\n",
      "Ep 25: Batch #75 - Loss: 0.6712229251861572\n",
      "Ep 25: Batch #76 - Loss: 0.937488317489624\n",
      "Ep 25: Batch #77 - Loss: 0.5810633301734924\n",
      "Ep 25: Batch #78 - Loss: 0.9327059388160706\n",
      "Ep 25: Batch #79 - Loss: 0.5313729047775269\n",
      "Ep 25: Batch #80 - Loss: 0.6993418335914612\n",
      "Ep 25: Batch #81 - Loss: 1.5312753915786743\n",
      "Ep 25: Batch #82 - Loss: 0.7536160349845886\n",
      "Ep 25: Batch #83 - Loss: 1.3736960887908936\n",
      "Ep 25: Batch #84 - Loss: 0.5803709030151367\n",
      "Ep 25: Batch #85 - Loss: 0.7981499433517456\n",
      "Ep 25: Batch #86 - Loss: 0.5535215139389038\n",
      "Ep 25: Batch #87 - Loss: 0.5750405192375183\n",
      "Ep 25: Batch #88 - Loss: 0.6571443676948547\n",
      "Ep 25: Batch #89 - Loss: 0.7413379549980164\n",
      "Ep 25: Batch #90 - Loss: 0.9014509916305542\n",
      "Ep 25: Batch #91 - Loss: 0.6497647762298584\n",
      "Ep 25: Batch #92 - Loss: 0.7529025077819824\n",
      "Ep 25: Batch #93 - Loss: 0.7894120216369629\n",
      "Ep 25: Batch #94 - Loss: 0.7752680778503418\n",
      "Ep 25: Batch #95 - Loss: 0.7634682059288025\n",
      "Ep 25: Batch #96 - Loss: 0.7630062103271484\n",
      "Ep 25: Batch #97 - Loss: 0.5864191055297852\n",
      "Ep 25: Batch #98 - Loss: 0.5829973220825195\n",
      "Ep 25: Batch #99 - Loss: 0.8037112355232239\n",
      "Ep 25: Batch #100 - Loss: 0.561240017414093\n",
      "Ep 25: Batch #101 - Loss: 0.8626086711883545\n",
      "Ep 25: Batch #102 - Loss: 0.6200107932090759\n",
      "Ep 25: Batch #103 - Loss: 0.6421248912811279\n",
      "Ep 25: Batch #104 - Loss: 0.664121150970459\n",
      "Ep 25: Batch #105 - Loss: 0.8200308680534363\n",
      "Ep 25: Batch #106 - Loss: 0.6268002390861511\n",
      "Ep 25: Batch #107 - Loss: 0.6135335564613342\n",
      "Ep 25: Batch #108 - Loss: 0.9046105742454529\n",
      "Ep 25: Batch #109 - Loss: 0.6321879625320435\n",
      "Ep 25: Batch #110 - Loss: 0.7325973510742188\n",
      "Ep 25: Batch #111 - Loss: 1.0503923892974854\n",
      "Ep 25: Batch #112 - Loss: 0.8211072683334351\n",
      "Ep 25: Batch #113 - Loss: 0.6617413759231567\n",
      "Ep 25: Batch #114 - Loss: 0.7325365543365479\n",
      "Ep 25: Batch #115 - Loss: 0.9078444242477417\n",
      "Ep 25: Batch #116 - Loss: 0.5306991338729858\n",
      "Ep 25: Batch #117 - Loss: 0.6898640394210815\n",
      "Ep 25: Batch #118 - Loss: 0.46041810512542725\n",
      "Model saved in file: ./weights_autoencoder_sigmoid/model_e25b118_1516648794.9773517.ckpt\n",
      "Ep 25: Batch #119 - Loss: 0.806536853313446\n",
      "Ep 25: Batch #120 - Loss: 0.6632592082023621\n",
      "Ep 25: Batch #121 - Loss: 0.5686480402946472\n",
      "Ep 25: Batch #122 - Loss: 0.7151646018028259\n",
      "Ep 25: Batch #123 - Loss: 0.7238039970397949\n",
      "Ep 25: Batch #124 - Loss: 0.5585881471633911\n",
      "Ep 25: Batch #125 - Loss: 2.470132827758789\n",
      "Ep 25: Batch #126 - Loss: 1.000583291053772\n",
      "Ep 25: Batch #127 - Loss: 0.5856791734695435\n",
      "Ep 25: Batch #128 - Loss: 0.8861326575279236\n",
      "Ep 25: Batch #129 - Loss: 0.684288501739502\n",
      "Ep 25: Batch #130 - Loss: 0.6004278063774109\n",
      "Ep 25: Batch #131 - Loss: 0.8068317770957947\n",
      "Ep 25: Batch #132 - Loss: 0.6877310872077942\n",
      "Ep 25: Batch #133 - Loss: 0.6698037981987\n",
      "Ep 25: Batch #134 - Loss: 0.6417428255081177\n",
      "Ep 25: Batch #135 - Loss: 0.8269180059432983\n",
      "Ep 25: Batch #136 - Loss: 1.0438326597213745\n",
      "Ep 25: Batch #137 - Loss: 0.7557995319366455\n",
      "Ep 25: Batch #138 - Loss: 0.9007384777069092\n",
      "Ep 25: Batch #139 - Loss: 0.69350665807724\n",
      "Ep 25: Batch #140 - Loss: 0.8536739945411682\n",
      "Ep 25: Batch #141 - Loss: 1.1373540163040161\n",
      "Ep 25: Batch #142 - Loss: 0.6748210191726685\n",
      "Ep 25: Batch #143 - Loss: 0.7718054056167603\n",
      "Ep 25: Batch #144 - Loss: 0.6134792566299438\n",
      "Ep 25: Batch #145 - Loss: 0.6013733744621277\n",
      "Ep 25: Batch #146 - Loss: 0.7105516195297241\n",
      "Ep 25: Batch #147 - Loss: 0.6782281398773193\n",
      "Ep 25: Batch #148 - Loss: 0.763518750667572\n",
      "Ep 25: Batch #149 - Loss: 0.6486455202102661\n",
      "Ep 25: Batch #150 - Loss: 0.7256001234054565\n",
      "Ep 25: Batch #151 - Loss: 0.6347531080245972\n",
      "Ep 25: Batch #152 - Loss: 0.6116440892219543\n",
      "Ep 25: Batch #153 - Loss: 0.8406026363372803\n",
      "Ep 25: Batch #154 - Loss: 0.6361528635025024\n",
      "Ep 25: Batch #155 - Loss: 0.6954911351203918\n",
      "Ep 25: Batch #156 - Loss: 0.8076723217964172\n",
      "Ep 25: Batch #157 - Loss: 0.6199769973754883\n",
      "Ep 25: Batch #158 - Loss: 0.719646692276001\n",
      "Ep 25: Batch #159 - Loss: 0.6158937811851501\n",
      "Ep 25: Batch #160 - Loss: 0.710525631904602\n",
      "Ep 25: Batch #161 - Loss: 0.6744281053543091\n",
      "Ep 25: Batch #162 - Loss: 0.7230465412139893\n",
      "Ep 25: Batch #163 - Loss: 0.7666783332824707\n",
      "Ep 25: Batch #164 - Loss: 0.6528255939483643\n",
      "Ep 25: Batch #165 - Loss: 1.346297264099121\n",
      "Ep 25: Batch #166 - Loss: 0.5375404357910156\n",
      "Ep 25: Batch #167 - Loss: 0.7759509086608887\n",
      "Ep 25: Batch #168 - Loss: 0.6949362754821777\n",
      "Ep 25: Batch #169 - Loss: 0.6737492084503174\n",
      "Ep 25: Batch #170 - Loss: 0.6358463764190674\n",
      "Ep 25: Batch #171 - Loss: 0.6432127952575684\n",
      "Ep 25: Batch #172 - Loss: 0.5365443825721741\n",
      "Ep 25: Batch #173 - Loss: 0.9373691082000732\n",
      "Ep 25: Batch #174 - Loss: 0.4978232979774475\n",
      "Ep 25: Batch #175 - Loss: 0.6450318694114685\n",
      "Ep 25: Batch #176 - Loss: 0.9027997255325317\n",
      "Ep 25: Batch #177 - Loss: 0.661865770816803\n",
      "Ep 25: Batch #178 - Loss: 0.6313075423240662\n",
      "Ep 25: Batch #179 - Loss: 0.7550839781761169\n",
      "Ep 25: Batch #180 - Loss: 0.658767819404602\n",
      "Ep 25: Batch #181 - Loss: 0.8075957894325256\n",
      "Ep 25: Batch #182 - Loss: 0.6291783452033997\n",
      "Ep 25: Batch #183 - Loss: 0.6123517751693726\n",
      "Ep 25: Batch #184 - Loss: 0.9254520535469055\n",
      "Ep 25: Batch #185 - Loss: 0.6361951231956482\n",
      "Ep 25: Batch #186 - Loss: 0.7698172926902771\n",
      "Ep 25: Batch #187 - Loss: 0.8806912899017334\n",
      "Ep 25: Batch #188 - Loss: 1.0078403949737549\n",
      "Ep 25: Batch #189 - Loss: 0.5910854935646057\n",
      "Ep 25: Batch #190 - Loss: 0.6267737746238708\n",
      "Ep 25: Batch #191 - Loss: 0.8181648254394531\n",
      "Ep 25: Batch #192 - Loss: 0.5730823278427124\n",
      "Ep 25: Batch #193 - Loss: 0.6297704577445984\n",
      "Ep 25: Batch #194 - Loss: 0.5535675287246704\n",
      "Ep 25: Batch #195 - Loss: 0.7988602519035339\n",
      "Ep 25: Batch #196 - Loss: 0.6955856084823608\n",
      "Ep 25: Batch #197 - Loss: 0.7057477235794067\n",
      "Ep 25: Batch #198 - Loss: 0.5367493033409119\n",
      "Ep 25: Batch #199 - Loss: 0.651153564453125\n",
      "Ep 26: Batch #0 - Loss: 0.6523376703262329\n",
      "Ep 26: Batch #1 - Loss: 0.7173071503639221\n",
      "Ep 26: Batch #2 - Loss: 0.8625625371932983\n",
      "Ep 26: Batch #3 - Loss: 0.7239266633987427\n",
      "Ep 26: Batch #4 - Loss: 0.658909261226654\n",
      "Ep 26: Batch #5 - Loss: 0.565827488899231\n",
      "Ep 26: Batch #6 - Loss: 0.7491960525512695\n",
      "Ep 26: Batch #7 - Loss: 0.582172155380249\n",
      "Ep 26: Batch #8 - Loss: 0.5919679999351501\n",
      "Ep 26: Batch #9 - Loss: 1.1004360914230347\n",
      "Ep 26: Batch #10 - Loss: 0.8269596099853516\n",
      "Ep 26: Batch #11 - Loss: 0.5465326309204102\n",
      "Ep 26: Batch #12 - Loss: 1.229910969734192\n",
      "Ep 26: Batch #13 - Loss: 0.574233889579773\n",
      "Ep 26: Batch #14 - Loss: 0.6050878763198853\n",
      "Ep 26: Batch #15 - Loss: 0.8902575969696045\n",
      "Ep 26: Batch #16 - Loss: 0.9597152471542358\n",
      "Ep 26: Batch #17 - Loss: 0.7317145466804504\n",
      "Ep 26: Batch #18 - Loss: 0.807296633720398\n",
      "Ep 26: Batch #19 - Loss: 0.5662648677825928\n",
      "Ep 26: Batch #20 - Loss: 0.5493191480636597\n",
      "Ep 26: Batch #21 - Loss: 0.8832184076309204\n",
      "Ep 26: Batch #22 - Loss: 0.6167173385620117\n",
      "Ep 26: Batch #23 - Loss: 0.6053621768951416\n",
      "Ep 26: Batch #24 - Loss: 0.6446068286895752\n",
      "Ep 26: Batch #25 - Loss: 0.6129918098449707\n",
      "Ep 26: Batch #26 - Loss: 0.5721721053123474\n",
      "Ep 26: Batch #27 - Loss: 1.1467037200927734\n",
      "Ep 26: Batch #28 - Loss: 0.695728063583374\n",
      "Ep 26: Batch #29 - Loss: 0.7606634497642517\n",
      "Ep 26: Batch #30 - Loss: 0.8853367567062378\n",
      "Ep 26: Batch #31 - Loss: 0.5648053288459778\n",
      "Ep 26: Batch #32 - Loss: 0.5860938429832458\n",
      "Ep 26: Batch #33 - Loss: 0.6728883385658264\n",
      "Ep 26: Batch #34 - Loss: 0.6496758460998535\n",
      "Ep 26: Batch #35 - Loss: 0.7311685681343079\n",
      "Ep 26: Batch #36 - Loss: 0.584190845489502\n",
      "Ep 26: Batch #37 - Loss: 0.9256664514541626\n",
      "Ep 26: Batch #38 - Loss: 0.5772585868835449\n",
      "Ep 26: Batch #39 - Loss: 0.6876042485237122\n",
      "Ep 26: Batch #40 - Loss: 0.6083195209503174\n",
      "Ep 26: Batch #41 - Loss: 0.62250816822052\n",
      "Ep 26: Batch #42 - Loss: 0.5730754733085632\n",
      "Ep 26: Batch #43 - Loss: 0.6362152099609375\n",
      "Ep 26: Batch #44 - Loss: 0.6204549670219421\n",
      "Ep 26: Batch #45 - Loss: 0.53117835521698\n",
      "Ep 26: Batch #46 - Loss: 0.69890296459198\n",
      "Ep 26: Batch #47 - Loss: 0.8068506121635437\n",
      "Ep 26: Batch #48 - Loss: 1.0461907386779785\n",
      "Ep 26: Batch #49 - Loss: 0.8142818212509155\n",
      "Ep 26: Batch #50 - Loss: 0.573681116104126\n",
      "Ep 26: Batch #51 - Loss: 0.8187692165374756\n",
      "Ep 26: Batch #52 - Loss: 0.6801028251647949\n",
      "Ep 26: Batch #53 - Loss: 0.7175912261009216\n",
      "Ep 26: Batch #54 - Loss: 0.5844380259513855\n",
      "Ep 26: Batch #55 - Loss: 0.6142741441726685\n",
      "Ep 26: Batch #56 - Loss: 0.8752549886703491\n",
      "Ep 26: Batch #57 - Loss: 0.6871945261955261\n",
      "Ep 26: Batch #58 - Loss: 0.8333020210266113\n",
      "Ep 26: Batch #59 - Loss: 0.5676895380020142\n",
      "Ep 26: Batch #60 - Loss: 1.0200631618499756\n",
      "Ep 26: Batch #61 - Loss: 0.5362032055854797\n",
      "Ep 26: Batch #62 - Loss: 0.5790836215019226\n",
      "Ep 26: Batch #63 - Loss: 0.7941191792488098\n",
      "Ep 26: Batch #64 - Loss: 8.685677528381348\n",
      "Ep 26: Batch #65 - Loss: 0.5266256332397461\n",
      "Ep 26: Batch #66 - Loss: 0.6699770092964172\n",
      "Ep 26: Batch #67 - Loss: 0.7801976799964905\n",
      "Ep 26: Batch #68 - Loss: 0.7255740165710449\n",
      "Ep 26: Batch #69 - Loss: 0.5964603424072266\n",
      "Ep 26: Batch #70 - Loss: 0.62088543176651\n",
      "Ep 26: Batch #71 - Loss: 0.5402087569236755\n",
      "Ep 26: Batch #72 - Loss: 0.6661841869354248\n",
      "Ep 26: Batch #73 - Loss: 0.7353380918502808\n",
      "Ep 26: Batch #74 - Loss: 0.5835151672363281\n",
      "Ep 26: Batch #75 - Loss: 0.6713898181915283\n",
      "Ep 26: Batch #76 - Loss: 0.9365972876548767\n",
      "Ep 26: Batch #77 - Loss: 0.5808181762695312\n",
      "Ep 26: Batch #78 - Loss: 0.932042121887207\n",
      "Ep 26: Batch #79 - Loss: 0.530860424041748\n",
      "Ep 26: Batch #80 - Loss: 0.6985530853271484\n",
      "Ep 26: Batch #81 - Loss: 1.5309748649597168\n",
      "Ep 26: Batch #82 - Loss: 0.7533985376358032\n",
      "Ep 26: Batch #83 - Loss: 1.368923544883728\n",
      "Ep 26: Batch #84 - Loss: 0.580193042755127\n",
      "Ep 26: Batch #85 - Loss: 0.7971722483634949\n",
      "Ep 26: Batch #86 - Loss: 0.5531666874885559\n",
      "Ep 26: Batch #87 - Loss: 0.5749515891075134\n",
      "Ep 26: Batch #88 - Loss: 0.6575119495391846\n",
      "Ep 26: Batch #89 - Loss: 0.7401849031448364\n",
      "Ep 26: Batch #90 - Loss: 0.9011162519454956\n",
      "Ep 26: Batch #91 - Loss: 0.6495398879051208\n",
      "Ep 26: Batch #92 - Loss: 0.7511233687400818\n",
      "Ep 26: Batch #93 - Loss: 0.789033055305481\n",
      "Ep 26: Batch #94 - Loss: 0.7734888195991516\n",
      "Ep 26: Batch #95 - Loss: 0.7623423337936401\n",
      "Ep 26: Batch #96 - Loss: 0.7617639303207397\n",
      "Ep 26: Batch #97 - Loss: 0.5865265727043152\n",
      "Ep 26: Batch #98 - Loss: 0.5828078389167786\n",
      "Ep 26: Batch #99 - Loss: 0.8033729791641235\n",
      "Ep 26: Batch #100 - Loss: 0.560932457447052\n",
      "Ep 26: Batch #101 - Loss: 0.8623108267784119\n",
      "Ep 26: Batch #102 - Loss: 0.6190232634544373\n",
      "Ep 26: Batch #103 - Loss: 0.6417381763458252\n",
      "Ep 26: Batch #104 - Loss: 0.6636672019958496\n",
      "Ep 26: Batch #105 - Loss: 0.8190457820892334\n",
      "Ep 26: Batch #106 - Loss: 0.6265813112258911\n",
      "Ep 26: Batch #107 - Loss: 0.6134920120239258\n",
      "Ep 26: Batch #108 - Loss: 0.9039536714553833\n",
      "Ep 26: Batch #109 - Loss: 0.6318590044975281\n",
      "Ep 26: Batch #110 - Loss: 0.7321813702583313\n",
      "Ep 26: Batch #111 - Loss: 1.049546480178833\n",
      "Ep 26: Batch #112 - Loss: 0.8187128305435181\n",
      "Ep 26: Batch #113 - Loss: 0.661300003528595\n",
      "Ep 26: Batch #114 - Loss: 0.732129693031311\n",
      "Ep 26: Batch #115 - Loss: 0.9070463180541992\n",
      "Ep 26: Batch #116 - Loss: 0.5298826694488525\n",
      "Ep 26: Batch #117 - Loss: 0.6886321306228638\n",
      "Ep 26: Batch #118 - Loss: 0.46004247665405273\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved in file: ./weights_autoencoder_sigmoid/model_e26b118_1516648795.1142564.ckpt\n",
      "Ep 26: Batch #119 - Loss: 0.8066004514694214\n",
      "Ep 26: Batch #120 - Loss: 0.6628807187080383\n",
      "Ep 26: Batch #121 - Loss: 0.5680215358734131\n",
      "Ep 26: Batch #122 - Loss: 0.7153114080429077\n",
      "Ep 26: Batch #123 - Loss: 0.7232739925384521\n",
      "Ep 26: Batch #124 - Loss: 0.5583462119102478\n",
      "Ep 26: Batch #125 - Loss: 2.4692325592041016\n",
      "Ep 26: Batch #126 - Loss: 1.000472068786621\n",
      "Ep 26: Batch #127 - Loss: 0.5855252146720886\n",
      "Ep 26: Batch #128 - Loss: 0.8849440813064575\n",
      "Ep 26: Batch #129 - Loss: 0.6837702989578247\n",
      "Ep 26: Batch #130 - Loss: 0.6001564264297485\n",
      "Ep 26: Batch #131 - Loss: 0.8067019581794739\n",
      "Ep 26: Batch #132 - Loss: 0.6872806549072266\n",
      "Ep 26: Batch #133 - Loss: 0.6694486141204834\n",
      "Ep 26: Batch #134 - Loss: 0.6408522129058838\n",
      "Ep 26: Batch #135 - Loss: 0.8277118802070618\n",
      "Ep 26: Batch #136 - Loss: 1.0433075428009033\n",
      "Ep 26: Batch #137 - Loss: 0.7557382583618164\n",
      "Ep 26: Batch #138 - Loss: 0.9007259011268616\n",
      "Ep 26: Batch #139 - Loss: 0.6931877136230469\n",
      "Ep 26: Batch #140 - Loss: 0.8524478673934937\n",
      "Ep 26: Batch #141 - Loss: 1.1370368003845215\n",
      "Ep 26: Batch #142 - Loss: 0.6743048429489136\n",
      "Ep 26: Batch #143 - Loss: 0.7715634703636169\n",
      "Ep 26: Batch #144 - Loss: 0.6131532788276672\n",
      "Ep 26: Batch #145 - Loss: 0.6011102795600891\n",
      "Ep 26: Batch #146 - Loss: 0.7097615003585815\n",
      "Ep 26: Batch #147 - Loss: 0.6773744821548462\n",
      "Ep 26: Batch #148 - Loss: 0.7630853056907654\n",
      "Ep 26: Batch #149 - Loss: 0.6465815305709839\n",
      "Ep 26: Batch #150 - Loss: 0.7250491380691528\n",
      "Ep 26: Batch #151 - Loss: 0.6342575550079346\n",
      "Ep 26: Batch #152 - Loss: 0.6114627718925476\n",
      "Ep 26: Batch #153 - Loss: 0.8391910195350647\n",
      "Ep 26: Batch #154 - Loss: 0.636017382144928\n",
      "Ep 26: Batch #155 - Loss: 0.6950635313987732\n",
      "Ep 26: Batch #156 - Loss: 0.806466281414032\n",
      "Ep 26: Batch #157 - Loss: 0.6200073957443237\n",
      "Ep 26: Batch #158 - Loss: 0.7195848226547241\n",
      "Ep 26: Batch #159 - Loss: 0.614727258682251\n",
      "Ep 26: Batch #160 - Loss: 0.7095884084701538\n",
      "Ep 26: Batch #161 - Loss: 0.673913836479187\n",
      "Ep 26: Batch #162 - Loss: 0.7221905589103699\n",
      "Ep 26: Batch #163 - Loss: 0.7655442953109741\n",
      "Ep 26: Batch #164 - Loss: 0.6523818969726562\n",
      "Ep 26: Batch #165 - Loss: 1.3460370302200317\n",
      "Ep 26: Batch #166 - Loss: 0.5369405746459961\n",
      "Ep 26: Batch #167 - Loss: 0.7727522253990173\n",
      "Ep 26: Batch #168 - Loss: 0.6946246027946472\n",
      "Ep 26: Batch #169 - Loss: 0.6734540462493896\n",
      "Ep 26: Batch #170 - Loss: 0.6351776719093323\n",
      "Ep 26: Batch #171 - Loss: 0.6431453227996826\n",
      "Ep 26: Batch #172 - Loss: 0.5363104939460754\n",
      "Ep 26: Batch #173 - Loss: 0.9363766312599182\n",
      "Ep 26: Batch #174 - Loss: 0.49786055088043213\n",
      "Ep 26: Batch #175 - Loss: 0.6444578766822815\n",
      "Ep 26: Batch #176 - Loss: 0.901698887348175\n",
      "Ep 26: Batch #177 - Loss: 0.6610797047615051\n",
      "Ep 26: Batch #178 - Loss: 0.6307328343391418\n",
      "Ep 26: Batch #179 - Loss: 0.7543795704841614\n",
      "Ep 26: Batch #180 - Loss: 0.6582760810852051\n",
      "Ep 26: Batch #181 - Loss: 0.8069970607757568\n",
      "Ep 26: Batch #182 - Loss: 0.6289714574813843\n",
      "Ep 26: Batch #183 - Loss: 0.611657977104187\n",
      "Ep 26: Batch #184 - Loss: 0.9250811338424683\n",
      "Ep 26: Batch #185 - Loss: 0.6358789801597595\n",
      "Ep 26: Batch #186 - Loss: 0.7685438394546509\n",
      "Ep 26: Batch #187 - Loss: 0.8796111345291138\n",
      "Ep 26: Batch #188 - Loss: 1.0051504373550415\n",
      "Ep 26: Batch #189 - Loss: 0.5909220576286316\n",
      "Ep 26: Batch #190 - Loss: 0.6266064643859863\n",
      "Ep 26: Batch #191 - Loss: 0.8173695802688599\n",
      "Ep 26: Batch #192 - Loss: 0.572830855846405\n",
      "Ep 26: Batch #193 - Loss: 0.6296236515045166\n",
      "Ep 26: Batch #194 - Loss: 0.5525853633880615\n",
      "Ep 26: Batch #195 - Loss: 0.7983234524726868\n",
      "Ep 26: Batch #196 - Loss: 0.6951294541358948\n",
      "Ep 26: Batch #197 - Loss: 0.7048757076263428\n",
      "Ep 26: Batch #198 - Loss: 0.5363634824752808\n",
      "Ep 26: Batch #199 - Loss: 0.650443971157074\n",
      "Ep 27: Batch #0 - Loss: 0.6519949436187744\n",
      "Ep 27: Batch #1 - Loss: 0.7170224189758301\n",
      "Ep 27: Batch #2 - Loss: 0.8620068430900574\n",
      "Ep 27: Batch #3 - Loss: 0.7238465547561646\n",
      "Ep 27: Batch #4 - Loss: 0.6589528918266296\n",
      "Ep 27: Batch #5 - Loss: 0.5658491253852844\n",
      "Ep 27: Batch #6 - Loss: 0.7478013038635254\n",
      "Ep 27: Batch #7 - Loss: 0.5813830494880676\n",
      "Ep 27: Batch #8 - Loss: 0.5912556648254395\n",
      "Ep 27: Batch #9 - Loss: 1.0994187593460083\n",
      "Ep 27: Batch #10 - Loss: 0.8259003162384033\n",
      "Ep 27: Batch #11 - Loss: 0.546256422996521\n",
      "Ep 27: Batch #12 - Loss: 1.22841215133667\n",
      "Ep 27: Batch #13 - Loss: 0.5738716125488281\n",
      "Ep 27: Batch #14 - Loss: 0.6045726537704468\n",
      "Ep 27: Batch #15 - Loss: 0.8880926966667175\n",
      "Ep 27: Batch #16 - Loss: 0.9582224488258362\n",
      "Ep 27: Batch #17 - Loss: 0.7314220666885376\n",
      "Ep 27: Batch #18 - Loss: 0.8074955940246582\n",
      "Ep 27: Batch #19 - Loss: 0.5659135580062866\n",
      "Ep 27: Batch #20 - Loss: 0.5488468408584595\n",
      "Ep 27: Batch #21 - Loss: 0.8798607587814331\n",
      "Ep 27: Batch #22 - Loss: 0.6161453127861023\n",
      "Ep 27: Batch #23 - Loss: 0.6049178838729858\n",
      "Ep 27: Batch #24 - Loss: 0.643879771232605\n",
      "Ep 27: Batch #25 - Loss: 0.6124860644340515\n",
      "Ep 27: Batch #26 - Loss: 0.5712301731109619\n",
      "Ep 27: Batch #27 - Loss: 1.1461864709854126\n",
      "Ep 27: Batch #28 - Loss: 0.695231556892395\n",
      "Ep 27: Batch #29 - Loss: 0.7599751353263855\n",
      "Ep 27: Batch #30 - Loss: 0.882797360420227\n",
      "Ep 27: Batch #31 - Loss: 0.5643573999404907\n",
      "Ep 27: Batch #32 - Loss: 0.5856102108955383\n",
      "Ep 27: Batch #33 - Loss: 0.6724732518196106\n",
      "Ep 27: Batch #34 - Loss: 0.6491221189498901\n",
      "Ep 27: Batch #35 - Loss: 0.7303973436355591\n",
      "Ep 27: Batch #36 - Loss: 0.5840638875961304\n",
      "Ep 27: Batch #37 - Loss: 0.9252157807350159\n",
      "Ep 27: Batch #38 - Loss: 0.5766018629074097\n",
      "Ep 27: Batch #39 - Loss: 0.6876798868179321\n",
      "Ep 27: Batch #40 - Loss: 0.6080639362335205\n",
      "Ep 27: Batch #41 - Loss: 0.6222991943359375\n",
      "Ep 27: Batch #42 - Loss: 0.5727067589759827\n",
      "Ep 27: Batch #43 - Loss: 0.63587486743927\n",
      "Ep 27: Batch #44 - Loss: 0.6198588013648987\n",
      "Ep 27: Batch #45 - Loss: 0.531042218208313\n",
      "Ep 27: Batch #46 - Loss: 0.6987791657447815\n",
      "Ep 27: Batch #47 - Loss: 0.8066903948783875\n",
      "Ep 27: Batch #48 - Loss: 1.045710802078247\n",
      "Ep 27: Batch #49 - Loss: 0.8143119812011719\n",
      "Ep 27: Batch #50 - Loss: 0.5736857652664185\n",
      "Ep 27: Batch #51 - Loss: 0.8186293244361877\n",
      "Ep 27: Batch #52 - Loss: 0.6799482703208923\n",
      "Ep 27: Batch #53 - Loss: 0.717567503452301\n",
      "Ep 27: Batch #54 - Loss: 0.5839554667472839\n",
      "Ep 27: Batch #55 - Loss: 0.6135751008987427\n",
      "Ep 27: Batch #56 - Loss: 0.8737878203392029\n",
      "Ep 27: Batch #57 - Loss: 0.6867170929908752\n",
      "Ep 27: Batch #58 - Loss: 0.8328661918640137\n",
      "Ep 27: Batch #59 - Loss: 0.567029595375061\n",
      "Ep 27: Batch #60 - Loss: 1.019776463508606\n",
      "Ep 27: Batch #61 - Loss: 0.5360352993011475\n",
      "Ep 27: Batch #62 - Loss: 0.5786302089691162\n",
      "Ep 27: Batch #63 - Loss: 0.7936868667602539\n",
      "Ep 27: Batch #64 - Loss: 8.671184539794922\n",
      "Ep 27: Batch #65 - Loss: 0.5265818238258362\n",
      "Ep 27: Batch #66 - Loss: 0.6696084141731262\n",
      "Ep 27: Batch #67 - Loss: 0.7798153758049011\n",
      "Ep 27: Batch #68 - Loss: 0.7243919968605042\n",
      "Ep 27: Batch #69 - Loss: 0.5958999991416931\n",
      "Ep 27: Batch #70 - Loss: 0.6211951375007629\n",
      "Ep 27: Batch #71 - Loss: 0.5399789214134216\n",
      "Ep 27: Batch #72 - Loss: 0.6662635207176208\n",
      "Ep 27: Batch #73 - Loss: 0.7344677448272705\n",
      "Ep 27: Batch #74 - Loss: 0.5829237699508667\n",
      "Ep 27: Batch #75 - Loss: 0.6712378859519958\n",
      "Ep 27: Batch #76 - Loss: 0.9357767701148987\n",
      "Ep 27: Batch #77 - Loss: 0.5805291533470154\n",
      "Ep 27: Batch #78 - Loss: 0.9314132332801819\n",
      "Ep 27: Batch #79 - Loss: 0.530583918094635\n",
      "Ep 27: Batch #80 - Loss: 0.6980112195014954\n",
      "Ep 27: Batch #81 - Loss: 1.530853271484375\n",
      "Ep 27: Batch #82 - Loss: 0.7532383799552917\n",
      "Ep 27: Batch #83 - Loss: 1.3649818897247314\n",
      "Ep 27: Batch #84 - Loss: 0.580807089805603\n",
      "Ep 27: Batch #85 - Loss: 0.7964350581169128\n",
      "Ep 27: Batch #86 - Loss: 0.5527390241622925\n",
      "Ep 27: Batch #87 - Loss: 0.575028657913208\n",
      "Ep 27: Batch #88 - Loss: 0.6577020287513733\n",
      "Ep 27: Batch #89 - Loss: 0.7397512793540955\n",
      "Ep 27: Batch #90 - Loss: 0.9007754921913147\n",
      "Ep 27: Batch #91 - Loss: 0.6495274305343628\n",
      "Ep 27: Batch #92 - Loss: 0.750347912311554\n",
      "Ep 27: Batch #93 - Loss: 0.7887561321258545\n",
      "Ep 27: Batch #94 - Loss: 0.7723121047019958\n",
      "Ep 27: Batch #95 - Loss: 0.7621099948883057\n",
      "Ep 27: Batch #96 - Loss: 0.7619624137878418\n",
      "Ep 27: Batch #97 - Loss: 0.5868702530860901\n",
      "Ep 27: Batch #98 - Loss: 0.5829741954803467\n",
      "Ep 27: Batch #99 - Loss: 0.8037323355674744\n",
      "Ep 27: Batch #100 - Loss: 0.560738742351532\n",
      "Ep 27: Batch #101 - Loss: 0.8625261187553406\n",
      "Ep 27: Batch #102 - Loss: 0.6185768842697144\n",
      "Ep 27: Batch #103 - Loss: 0.6417425274848938\n",
      "Ep 27: Batch #104 - Loss: 0.663529634475708\n",
      "Ep 27: Batch #105 - Loss: 0.8190807700157166\n",
      "Ep 27: Batch #106 - Loss: 0.6266499161720276\n",
      "Ep 27: Batch #107 - Loss: 0.6136219501495361\n",
      "Ep 27: Batch #108 - Loss: 0.9039166569709778\n",
      "Ep 27: Batch #109 - Loss: 0.6312033534049988\n",
      "Ep 27: Batch #110 - Loss: 0.7319556474685669\n",
      "Ep 27: Batch #111 - Loss: 1.0487045049667358\n",
      "Ep 27: Batch #112 - Loss: 0.8170509934425354\n",
      "Ep 27: Batch #113 - Loss: 0.6611385345458984\n",
      "Ep 27: Batch #114 - Loss: 0.7321593761444092\n",
      "Ep 27: Batch #115 - Loss: 0.9066292643547058\n",
      "Ep 27: Batch #116 - Loss: 0.5291882157325745\n",
      "Ep 27: Batch #117 - Loss: 0.6876990795135498\n",
      "Ep 27: Batch #118 - Loss: 0.45992738008499146\n",
      "Model saved in file: ./weights_autoencoder_sigmoid/model_e27b118_1516648795.2521138.ckpt\n",
      "Ep 27: Batch #119 - Loss: 0.8065584301948547\n",
      "Ep 27: Batch #120 - Loss: 0.6624160408973694\n",
      "Ep 27: Batch #121 - Loss: 0.5673724412918091\n",
      "Ep 27: Batch #122 - Loss: 0.7153651118278503\n",
      "Ep 27: Batch #123 - Loss: 0.7232195734977722\n",
      "Ep 27: Batch #124 - Loss: 0.5581783056259155\n",
      "Ep 27: Batch #125 - Loss: 2.469241142272949\n",
      "Ep 27: Batch #126 - Loss: 1.0002416372299194\n",
      "Ep 27: Batch #127 - Loss: 0.5856119394302368\n",
      "Ep 27: Batch #128 - Loss: 0.8849489688873291\n",
      "Ep 27: Batch #129 - Loss: 0.6829646825790405\n",
      "Ep 27: Batch #130 - Loss: 0.5999398231506348\n",
      "Ep 27: Batch #131 - Loss: 0.8069181442260742\n",
      "Ep 27: Batch #132 - Loss: 0.6873365044593811\n",
      "Ep 27: Batch #133 - Loss: 0.6695488691329956\n",
      "Ep 27: Batch #134 - Loss: 0.6406963467597961\n",
      "Ep 27: Batch #135 - Loss: 0.8261894583702087\n",
      "Ep 27: Batch #136 - Loss: 1.043194055557251\n",
      "Ep 27: Batch #137 - Loss: 0.7555201649665833\n",
      "Ep 27: Batch #138 - Loss: 0.9004426598548889\n",
      "Ep 27: Batch #139 - Loss: 0.6919052600860596\n",
      "Ep 27: Batch #140 - Loss: 0.8513877987861633\n",
      "Ep 27: Batch #141 - Loss: 1.1361329555511475\n",
      "Ep 27: Batch #142 - Loss: 0.6741514801979065\n",
      "Ep 27: Batch #143 - Loss: 0.7712583541870117\n",
      "Ep 27: Batch #144 - Loss: 0.6128996014595032\n",
      "Ep 27: Batch #145 - Loss: 0.6010550260543823\n",
      "Ep 27: Batch #146 - Loss: 0.7090878486633301\n",
      "Ep 27: Batch #147 - Loss: 0.676246702671051\n",
      "Ep 27: Batch #148 - Loss: 0.7625837326049805\n",
      "Ep 27: Batch #149 - Loss: 0.6444607377052307\n",
      "Ep 27: Batch #150 - Loss: 0.72461998462677\n",
      "Ep 27: Batch #151 - Loss: 0.6339389681816101\n",
      "Ep 27: Batch #152 - Loss: 0.6111904382705688\n",
      "Ep 27: Batch #153 - Loss: 0.8380980491638184\n",
      "Ep 27: Batch #154 - Loss: 0.6358497142791748\n",
      "Ep 27: Batch #155 - Loss: 0.695094108581543\n",
      "Ep 27: Batch #156 - Loss: 0.804926335811615\n",
      "Ep 27: Batch #157 - Loss: 0.6194939017295837\n",
      "Ep 27: Batch #158 - Loss: 0.7194503545761108\n",
      "Ep 27: Batch #159 - Loss: 0.6135947704315186\n",
      "Ep 27: Batch #160 - Loss: 0.7088389992713928\n",
      "Ep 27: Batch #161 - Loss: 0.6734424829483032\n",
      "Ep 27: Batch #162 - Loss: 0.7216706275939941\n",
      "Ep 27: Batch #163 - Loss: 0.7645259499549866\n",
      "Ep 27: Batch #164 - Loss: 0.6517891883850098\n",
      "Ep 27: Batch #165 - Loss: 1.3450069427490234\n",
      "Ep 27: Batch #166 - Loss: 0.5364537835121155\n",
      "Ep 27: Batch #167 - Loss: 0.7693576812744141\n",
      "Ep 27: Batch #168 - Loss: 0.6944210529327393\n",
      "Ep 27: Batch #169 - Loss: 0.6731153726577759\n",
      "Ep 27: Batch #170 - Loss: 0.6345050930976868\n",
      "Ep 27: Batch #171 - Loss: 0.6430268883705139\n",
      "Ep 27: Batch #172 - Loss: 0.5360859632492065\n",
      "Ep 27: Batch #173 - Loss: 0.9358897805213928\n",
      "Ep 27: Batch #174 - Loss: 0.49779799580574036\n",
      "Ep 27: Batch #175 - Loss: 0.6443641185760498\n",
      "Ep 27: Batch #176 - Loss: 0.901072084903717\n",
      "Ep 27: Batch #177 - Loss: 0.660406768321991\n",
      "Ep 27: Batch #178 - Loss: 0.6297687888145447\n",
      "Ep 27: Batch #179 - Loss: 0.7540716528892517\n",
      "Ep 27: Batch #180 - Loss: 0.6576603651046753\n",
      "Ep 27: Batch #181 - Loss: 0.806326150894165\n",
      "Ep 27: Batch #182 - Loss: 0.6284345984458923\n",
      "Ep 27: Batch #183 - Loss: 0.6112330555915833\n",
      "Ep 27: Batch #184 - Loss: 0.9245795011520386\n",
      "Ep 27: Batch #185 - Loss: 0.6354362964630127\n",
      "Ep 27: Batch #186 - Loss: 0.7671999335289001\n",
      "Ep 27: Batch #187 - Loss: 0.8796244263648987\n",
      "Ep 27: Batch #188 - Loss: 1.0033600330352783\n",
      "Ep 27: Batch #189 - Loss: 0.5907959938049316\n",
      "Ep 27: Batch #190 - Loss: 0.6264035105705261\n",
      "Ep 27: Batch #191 - Loss: 0.8167055249214172\n",
      "Ep 27: Batch #192 - Loss: 0.5728500485420227\n",
      "Ep 27: Batch #193 - Loss: 0.6296697854995728\n",
      "Ep 27: Batch #194 - Loss: 0.5518099665641785\n",
      "Ep 27: Batch #195 - Loss: 0.7979229688644409\n",
      "Ep 27: Batch #196 - Loss: 0.694990336894989\n",
      "Ep 27: Batch #197 - Loss: 0.7044544816017151\n",
      "Ep 27: Batch #198 - Loss: 0.5362094640731812\n",
      "Ep 27: Batch #199 - Loss: 0.6499195694923401\n",
      "Ep 28: Batch #0 - Loss: 0.651881992816925\n",
      "Ep 28: Batch #1 - Loss: 0.7166689038276672\n",
      "Ep 28: Batch #2 - Loss: 0.8618471026420593\n",
      "Ep 28: Batch #3 - Loss: 0.7237585186958313\n",
      "Ep 28: Batch #4 - Loss: 0.6591561436653137\n",
      "Ep 28: Batch #5 - Loss: 0.5655848979949951\n",
      "Ep 28: Batch #6 - Loss: 0.7472242712974548\n",
      "Ep 28: Batch #7 - Loss: 0.5808351039886475\n",
      "Ep 28: Batch #8 - Loss: 0.5911659598350525\n",
      "Ep 28: Batch #9 - Loss: 1.0990421772003174\n",
      "Ep 28: Batch #10 - Loss: 0.8248457908630371\n",
      "Ep 28: Batch #11 - Loss: 0.5459156632423401\n",
      "Ep 28: Batch #12 - Loss: 1.2271074056625366\n",
      "Ep 28: Batch #13 - Loss: 0.5736483335494995\n",
      "Ep 28: Batch #14 - Loss: 0.6044217944145203\n",
      "Ep 28: Batch #15 - Loss: 0.8850415945053101\n",
      "Ep 28: Batch #16 - Loss: 0.957467794418335\n",
      "Ep 28: Batch #17 - Loss: 0.7312480807304382\n",
      "Ep 28: Batch #18 - Loss: 0.8075637817382812\n",
      "Ep 28: Batch #19 - Loss: 0.5658966898918152\n",
      "Ep 28: Batch #20 - Loss: 0.548673689365387\n",
      "Ep 28: Batch #21 - Loss: 0.8772515058517456\n",
      "Ep 28: Batch #22 - Loss: 0.6156190037727356\n",
      "Ep 28: Batch #23 - Loss: 0.6044696569442749\n",
      "Ep 28: Batch #24 - Loss: 0.6435496807098389\n",
      "Ep 28: Batch #25 - Loss: 0.6120679378509521\n",
      "Ep 28: Batch #26 - Loss: 0.5701422095298767\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 28: Batch #27 - Loss: 1.1461060047149658\n",
      "Ep 28: Batch #28 - Loss: 0.6949286460876465\n",
      "Ep 28: Batch #29 - Loss: 0.7604185938835144\n",
      "Ep 28: Batch #30 - Loss: 0.880251407623291\n",
      "Ep 28: Batch #31 - Loss: 0.5641400218009949\n",
      "Ep 28: Batch #32 - Loss: 0.5854611992835999\n",
      "Ep 28: Batch #33 - Loss: 0.6719620823860168\n",
      "Ep 28: Batch #34 - Loss: 0.6486573219299316\n",
      "Ep 28: Batch #35 - Loss: 0.7298933863639832\n",
      "Ep 28: Batch #36 - Loss: 0.5840443968772888\n",
      "Ep 28: Batch #37 - Loss: 0.9250701665878296\n",
      "Ep 28: Batch #38 - Loss: 0.5761396288871765\n",
      "Ep 28: Batch #39 - Loss: 0.6875990629196167\n",
      "Ep 28: Batch #40 - Loss: 0.6076542735099792\n",
      "Ep 28: Batch #41 - Loss: 0.6222489476203918\n",
      "Ep 28: Batch #42 - Loss: 0.5725935101509094\n",
      "Ep 28: Batch #43 - Loss: 0.6359022855758667\n",
      "Ep 28: Batch #44 - Loss: 0.6192325353622437\n",
      "Ep 28: Batch #45 - Loss: 0.5307798385620117\n",
      "Ep 28: Batch #46 - Loss: 0.6985676884651184\n",
      "Ep 28: Batch #47 - Loss: 0.806617259979248\n",
      "Ep 28: Batch #48 - Loss: 1.0446964502334595\n",
      "Ep 28: Batch #49 - Loss: 0.8143724799156189\n",
      "Ep 28: Batch #50 - Loss: 0.5737255215644836\n",
      "Ep 28: Batch #51 - Loss: 0.8188316822052002\n",
      "Ep 28: Batch #52 - Loss: 0.6796867847442627\n",
      "Ep 28: Batch #53 - Loss: 0.7175900936126709\n",
      "Ep 28: Batch #54 - Loss: 0.5834311246871948\n",
      "Ep 28: Batch #55 - Loss: 0.6129627823829651\n",
      "Ep 28: Batch #56 - Loss: 0.872387170791626\n",
      "Ep 28: Batch #57 - Loss: 0.686352550983429\n",
      "Ep 28: Batch #58 - Loss: 0.8326277136802673\n",
      "Ep 28: Batch #59 - Loss: 0.5665737390518188\n",
      "Ep 28: Batch #60 - Loss: 1.0185414552688599\n",
      "Ep 28: Batch #61 - Loss: 0.5358551740646362\n",
      "Ep 28: Batch #62 - Loss: 0.5780316591262817\n",
      "Ep 28: Batch #63 - Loss: 0.7930721044540405\n",
      "Ep 28: Batch #64 - Loss: 8.70761489868164\n",
      "Ep 28: Batch #65 - Loss: 0.5265715718269348\n",
      "Ep 28: Batch #66 - Loss: 0.6693995594978333\n",
      "Ep 28: Batch #67 - Loss: 0.7800770401954651\n",
      "Ep 28: Batch #68 - Loss: 0.7232967019081116\n",
      "Ep 28: Batch #69 - Loss: 0.5954763293266296\n",
      "Ep 28: Batch #70 - Loss: 0.6208801865577698\n",
      "Ep 28: Batch #71 - Loss: 0.5400011539459229\n",
      "Ep 28: Batch #72 - Loss: 0.6675829887390137\n",
      "Ep 28: Batch #73 - Loss: 0.733931303024292\n",
      "Ep 28: Batch #74 - Loss: 0.5830387473106384\n",
      "Ep 28: Batch #75 - Loss: 0.6714750528335571\n",
      "Ep 28: Batch #76 - Loss: 0.9372463226318359\n",
      "Ep 28: Batch #77 - Loss: 0.5799014568328857\n",
      "Ep 28: Batch #78 - Loss: 0.9310334324836731\n",
      "Ep 28: Batch #79 - Loss: 0.5304195284843445\n",
      "Ep 28: Batch #80 - Loss: 0.6978700757026672\n",
      "Ep 28: Batch #81 - Loss: 1.5304137468338013\n",
      "Ep 28: Batch #82 - Loss: 0.7532936334609985\n",
      "Ep 28: Batch #83 - Loss: 1.3589847087860107\n",
      "Ep 28: Batch #84 - Loss: 0.5799948573112488\n",
      "Ep 28: Batch #85 - Loss: 0.7977961897850037\n",
      "Ep 28: Batch #86 - Loss: 0.5526242256164551\n",
      "Ep 28: Batch #87 - Loss: 0.5746718645095825\n",
      "Ep 28: Batch #88 - Loss: 0.6579873561859131\n",
      "Ep 28: Batch #89 - Loss: 0.7390037775039673\n",
      "Ep 28: Batch #90 - Loss: 0.9009475708007812\n",
      "Ep 28: Batch #91 - Loss: 0.6488675475120544\n",
      "Ep 28: Batch #92 - Loss: 0.7486104369163513\n",
      "Ep 28: Batch #93 - Loss: 0.7883763909339905\n",
      "Ep 28: Batch #94 - Loss: 0.7708872556686401\n",
      "Ep 28: Batch #95 - Loss: 0.7620947360992432\n",
      "Ep 28: Batch #96 - Loss: 0.7629970908164978\n",
      "Ep 28: Batch #97 - Loss: 0.585843026638031\n",
      "Ep 28: Batch #98 - Loss: 0.5824815034866333\n",
      "Ep 28: Batch #99 - Loss: 0.803411602973938\n",
      "Ep 28: Batch #100 - Loss: 0.5608499050140381\n",
      "Ep 28: Batch #101 - Loss: 0.8633754253387451\n",
      "Ep 28: Batch #102 - Loss: 0.6180336475372314\n",
      "Ep 28: Batch #103 - Loss: 0.641747236251831\n",
      "Ep 28: Batch #104 - Loss: 0.6632087826728821\n",
      "Ep 28: Batch #105 - Loss: 0.818541944026947\n",
      "Ep 28: Batch #106 - Loss: 0.6270524263381958\n",
      "Ep 28: Batch #107 - Loss: 0.6135921478271484\n",
      "Ep 28: Batch #108 - Loss: 0.9040042161941528\n",
      "Ep 28: Batch #109 - Loss: 0.631498396396637\n",
      "Ep 28: Batch #110 - Loss: 0.7314537167549133\n",
      "Ep 28: Batch #111 - Loss: 1.0473747253417969\n",
      "Ep 28: Batch #112 - Loss: 0.8151099681854248\n",
      "Ep 28: Batch #113 - Loss: 0.6615133285522461\n",
      "Ep 28: Batch #114 - Loss: 0.7319112420082092\n",
      "Ep 28: Batch #115 - Loss: 0.9077285528182983\n",
      "Ep 28: Batch #116 - Loss: 0.5285399556159973\n",
      "Ep 28: Batch #117 - Loss: 0.6866312623023987\n",
      "Ep 28: Batch #118 - Loss: 0.45916393399238586\n",
      "Model saved in file: ./weights_autoencoder_sigmoid/model_e28b118_1516648795.3893332.ckpt\n",
      "Ep 28: Batch #119 - Loss: 0.8057013750076294\n",
      "Ep 28: Batch #120 - Loss: 0.6623490452766418\n",
      "Ep 28: Batch #121 - Loss: 0.5672958493232727\n",
      "Ep 28: Batch #122 - Loss: 0.714121401309967\n",
      "Ep 28: Batch #123 - Loss: 0.7232281565666199\n",
      "Ep 28: Batch #124 - Loss: 0.558005154132843\n",
      "Ep 28: Batch #125 - Loss: 2.4692933559417725\n",
      "Ep 28: Batch #126 - Loss: 0.9999160766601562\n",
      "Ep 28: Batch #127 - Loss: 0.5848956108093262\n",
      "Ep 28: Batch #128 - Loss: 0.8851426839828491\n",
      "Ep 28: Batch #129 - Loss: 0.6825056672096252\n",
      "Ep 28: Batch #130 - Loss: 0.6000798344612122\n",
      "Ep 28: Batch #131 - Loss: 0.806893527507782\n",
      "Ep 28: Batch #132 - Loss: 0.6863613724708557\n",
      "Ep 28: Batch #133 - Loss: 0.6701887249946594\n",
      "Ep 28: Batch #134 - Loss: 0.6405749917030334\n",
      "Ep 28: Batch #135 - Loss: 0.826168417930603\n",
      "Ep 28: Batch #136 - Loss: 1.0424505472183228\n",
      "Ep 28: Batch #137 - Loss: 0.7554745674133301\n",
      "Ep 28: Batch #138 - Loss: 0.9008535742759705\n",
      "Ep 28: Batch #139 - Loss: 0.6911869049072266\n",
      "Ep 28: Batch #140 - Loss: 0.8508325219154358\n",
      "Ep 28: Batch #141 - Loss: 1.135212779045105\n",
      "Ep 28: Batch #142 - Loss: 0.6738445162773132\n",
      "Ep 28: Batch #143 - Loss: 0.771695613861084\n",
      "Ep 28: Batch #144 - Loss: 0.6126481890678406\n",
      "Ep 28: Batch #145 - Loss: 0.6011026501655579\n",
      "Ep 28: Batch #146 - Loss: 0.7085321545600891\n",
      "Ep 28: Batch #147 - Loss: 0.6755571365356445\n",
      "Ep 28: Batch #148 - Loss: 0.7621307373046875\n",
      "Ep 28: Batch #149 - Loss: 0.6427204012870789\n",
      "Ep 28: Batch #150 - Loss: 0.7243817448616028\n",
      "Ep 28: Batch #151 - Loss: 0.6335533261299133\n",
      "Ep 28: Batch #152 - Loss: 0.6106683015823364\n",
      "Ep 28: Batch #153 - Loss: 0.8372527360916138\n",
      "Ep 28: Batch #154 - Loss: 0.6359529495239258\n",
      "Ep 28: Batch #155 - Loss: 0.6946602463722229\n",
      "Ep 28: Batch #156 - Loss: 0.8032553195953369\n",
      "Ep 28: Batch #157 - Loss: 0.6197499632835388\n",
      "Ep 28: Batch #158 - Loss: 0.7190508246421814\n",
      "Ep 28: Batch #159 - Loss: 0.6122682094573975\n",
      "Ep 28: Batch #160 - Loss: 0.7078636884689331\n",
      "Ep 28: Batch #161 - Loss: 0.6731586456298828\n",
      "Ep 28: Batch #162 - Loss: 0.7211563587188721\n",
      "Ep 28: Batch #163 - Loss: 0.7641523480415344\n",
      "Ep 28: Batch #164 - Loss: 0.6516504883766174\n",
      "Ep 28: Batch #165 - Loss: 1.345715045928955\n",
      "Ep 28: Batch #166 - Loss: 0.5362151265144348\n",
      "Ep 28: Batch #167 - Loss: 0.7660707831382751\n",
      "Ep 28: Batch #168 - Loss: 0.6942217946052551\n",
      "Ep 28: Batch #169 - Loss: 0.6726359128952026\n",
      "Ep 28: Batch #170 - Loss: 0.6339749097824097\n",
      "Ep 28: Batch #171 - Loss: 0.6427531242370605\n",
      "Ep 28: Batch #172 - Loss: 0.5358465313911438\n",
      "Ep 28: Batch #173 - Loss: 0.9348325729370117\n",
      "Ep 28: Batch #174 - Loss: 0.4974902868270874\n",
      "Ep 28: Batch #175 - Loss: 0.643917441368103\n",
      "Ep 28: Batch #176 - Loss: 0.9007073640823364\n",
      "Ep 28: Batch #177 - Loss: 0.6593616008758545\n",
      "Ep 28: Batch #178 - Loss: 0.6292521953582764\n",
      "Ep 28: Batch #179 - Loss: 0.7533434629440308\n",
      "Ep 28: Batch #180 - Loss: 0.657256543636322\n",
      "Ep 28: Batch #181 - Loss: 0.8058356046676636\n",
      "Ep 28: Batch #182 - Loss: 0.6285402178764343\n",
      "Ep 28: Batch #183 - Loss: 0.6107004880905151\n",
      "Ep 28: Batch #184 - Loss: 0.9240732192993164\n",
      "Ep 28: Batch #185 - Loss: 0.6353605389595032\n",
      "Ep 28: Batch #186 - Loss: 0.7660394310951233\n",
      "Ep 28: Batch #187 - Loss: 0.8779032826423645\n",
      "Ep 28: Batch #188 - Loss: 1.0001254081726074\n",
      "Ep 28: Batch #189 - Loss: 0.5903984308242798\n",
      "Ep 28: Batch #190 - Loss: 0.626433253288269\n",
      "Ep 28: Batch #191 - Loss: 0.8168354034423828\n",
      "Ep 28: Batch #192 - Loss: 0.572555661201477\n",
      "Ep 28: Batch #193 - Loss: 0.6298076510429382\n",
      "Ep 28: Batch #194 - Loss: 0.551086962223053\n",
      "Ep 28: Batch #195 - Loss: 0.797400712966919\n",
      "Ep 28: Batch #196 - Loss: 0.6949027180671692\n",
      "Ep 28: Batch #197 - Loss: 0.7041010856628418\n",
      "Ep 28: Batch #198 - Loss: 0.5358487367630005\n",
      "Ep 28: Batch #199 - Loss: 0.6496200561523438\n",
      "Ep 29: Batch #0 - Loss: 0.6514748930931091\n",
      "Ep 29: Batch #1 - Loss: 0.716558039188385\n",
      "Ep 29: Batch #2 - Loss: 0.8618502616882324\n",
      "Ep 29: Batch #3 - Loss: 0.7235317826271057\n",
      "Ep 29: Batch #4 - Loss: 0.6589735746383667\n",
      "Ep 29: Batch #5 - Loss: 0.564655601978302\n",
      "Ep 29: Batch #6 - Loss: 0.7464955449104309\n",
      "Ep 29: Batch #7 - Loss: 0.5801386833190918\n",
      "Ep 29: Batch #8 - Loss: 0.5911908745765686\n",
      "Ep 29: Batch #9 - Loss: 1.0986946821212769\n",
      "Ep 29: Batch #10 - Loss: 0.8235759735107422\n",
      "Ep 29: Batch #11 - Loss: 0.5456671714782715\n",
      "Ep 29: Batch #12 - Loss: 1.2256909608840942\n",
      "Ep 29: Batch #13 - Loss: 0.5733404755592346\n",
      "Ep 29: Batch #14 - Loss: 0.6038916707038879\n",
      "Ep 29: Batch #15 - Loss: 0.8825712203979492\n",
      "Ep 29: Batch #16 - Loss: 0.9569718837738037\n",
      "Ep 29: Batch #17 - Loss: 0.7311874628067017\n",
      "Ep 29: Batch #18 - Loss: 0.8077216148376465\n",
      "Ep 29: Batch #19 - Loss: 0.5657994151115417\n",
      "Ep 29: Batch #20 - Loss: 0.5485814809799194\n",
      "Ep 29: Batch #21 - Loss: 0.8736422657966614\n",
      "Ep 29: Batch #22 - Loss: 0.6153935194015503\n",
      "Ep 29: Batch #23 - Loss: 0.6042656302452087\n",
      "Ep 29: Batch #24 - Loss: 0.6429393887519836\n",
      "Ep 29: Batch #25 - Loss: 0.6117132902145386\n",
      "Ep 29: Batch #26 - Loss: 0.5685766339302063\n",
      "Ep 29: Batch #27 - Loss: 1.1459434032440186\n",
      "Ep 29: Batch #28 - Loss: 0.6947763562202454\n",
      "Ep 29: Batch #29 - Loss: 0.7598061561584473\n",
      "Ep 29: Batch #30 - Loss: 0.8773815631866455\n",
      "Ep 29: Batch #31 - Loss: 0.5638738870620728\n",
      "Ep 29: Batch #32 - Loss: 0.5850090384483337\n",
      "Ep 29: Batch #33 - Loss: 0.6715075969696045\n",
      "Ep 29: Batch #34 - Loss: 0.6484296917915344\n",
      "Ep 29: Batch #35 - Loss: 0.729174792766571\n",
      "Ep 29: Batch #36 - Loss: 0.5840767621994019\n",
      "Ep 29: Batch #37 - Loss: 0.9247843623161316\n",
      "Ep 29: Batch #38 - Loss: 0.575555145740509\n",
      "Ep 29: Batch #39 - Loss: 0.6871991753578186\n",
      "Ep 29: Batch #40 - Loss: 0.6073805093765259\n",
      "Ep 29: Batch #41 - Loss: 0.6222699284553528\n",
      "Ep 29: Batch #42 - Loss: 0.5723515152931213\n",
      "Ep 29: Batch #43 - Loss: 0.6357060670852661\n",
      "Ep 29: Batch #44 - Loss: 0.6187962293624878\n",
      "Ep 29: Batch #45 - Loss: 0.530561625957489\n",
      "Ep 29: Batch #46 - Loss: 0.6983885765075684\n",
      "Ep 29: Batch #47 - Loss: 0.806607723236084\n",
      "Ep 29: Batch #48 - Loss: 1.04389226436615\n",
      "Ep 29: Batch #49 - Loss: 0.8140168786048889\n",
      "Ep 29: Batch #50 - Loss: 0.5735729336738586\n",
      "Ep 29: Batch #51 - Loss: 0.8189703822135925\n",
      "Ep 29: Batch #52 - Loss: 0.6795002222061157\n",
      "Ep 29: Batch #53 - Loss: 0.7176140546798706\n",
      "Ep 29: Batch #54 - Loss: 0.5831348299980164\n",
      "Ep 29: Batch #55 - Loss: 0.6122678518295288\n",
      "Ep 29: Batch #56 - Loss: 0.8712312579154968\n",
      "Ep 29: Batch #57 - Loss: 0.6861369013786316\n",
      "Ep 29: Batch #58 - Loss: 0.832312822341919\n",
      "Ep 29: Batch #59 - Loss: 0.5661169290542603\n",
      "Ep 29: Batch #60 - Loss: 1.0176711082458496\n",
      "Ep 29: Batch #61 - Loss: 0.535624623298645\n",
      "Ep 29: Batch #62 - Loss: 0.5776815414428711\n",
      "Ep 29: Batch #63 - Loss: 0.7923169136047363\n",
      "Ep 29: Batch #64 - Loss: 8.660526275634766\n",
      "Ep 29: Batch #65 - Loss: 0.5263860821723938\n",
      "Ep 29: Batch #66 - Loss: 0.6686379909515381\n",
      "Ep 29: Batch #67 - Loss: 0.7793872952461243\n",
      "Ep 29: Batch #68 - Loss: 0.7220985293388367\n",
      "Ep 29: Batch #69 - Loss: 0.5945731401443481\n",
      "Ep 29: Batch #70 - Loss: 0.6208558678627014\n",
      "Ep 29: Batch #71 - Loss: 0.5395916104316711\n",
      "Ep 29: Batch #72 - Loss: 0.6657930016517639\n",
      "Ep 29: Batch #73 - Loss: 0.7327920794487\n",
      "Ep 29: Batch #74 - Loss: 0.5825234055519104\n",
      "Ep 29: Batch #75 - Loss: 0.6710504293441772\n",
      "Ep 29: Batch #76 - Loss: 0.9344676733016968\n",
      "Ep 29: Batch #77 - Loss: 0.579698920249939\n",
      "Ep 29: Batch #78 - Loss: 0.9299522638320923\n",
      "Ep 29: Batch #79 - Loss: 0.5297845005989075\n",
      "Ep 29: Batch #80 - Loss: 0.6972578167915344\n",
      "Ep 29: Batch #81 - Loss: 1.5312812328338623\n",
      "Ep 29: Batch #82 - Loss: 0.7529632449150085\n",
      "Ep 29: Batch #83 - Loss: 1.3546534776687622\n",
      "Ep 29: Batch #84 - Loss: 0.5806204080581665\n",
      "Ep 29: Batch #85 - Loss: 0.7951167821884155\n",
      "Ep 29: Batch #86 - Loss: 0.551986813545227\n",
      "Ep 29: Batch #87 - Loss: 0.5747769474983215\n",
      "Ep 29: Batch #88 - Loss: 0.6580688953399658\n",
      "Ep 29: Batch #89 - Loss: 0.7382315397262573\n",
      "Ep 29: Batch #90 - Loss: 0.9005857110023499\n",
      "Ep 29: Batch #91 - Loss: 0.649452805519104\n",
      "Ep 29: Batch #92 - Loss: 0.7474105358123779\n",
      "Ep 29: Batch #93 - Loss: 0.7882224917411804\n",
      "Ep 29: Batch #94 - Loss: 0.7691881656646729\n",
      "Ep 29: Batch #95 - Loss: 0.7619190812110901\n",
      "Ep 29: Batch #96 - Loss: 0.7611721158027649\n",
      "Ep 29: Batch #97 - Loss: 0.5868107676506042\n",
      "Ep 29: Batch #98 - Loss: 0.5824937224388123\n",
      "Ep 29: Batch #99 - Loss: 0.8033255338668823\n",
      "Ep 29: Batch #100 - Loss: 0.5605877637863159\n",
      "Ep 29: Batch #101 - Loss: 0.8621320724487305\n",
      "Ep 29: Batch #102 - Loss: 0.6179600954055786\n",
      "Ep 29: Batch #103 - Loss: 0.6414610147476196\n",
      "Ep 29: Batch #104 - Loss: 0.6628615856170654\n",
      "Ep 29: Batch #105 - Loss: 0.8182623386383057\n",
      "Ep 29: Batch #106 - Loss: 0.6264896392822266\n",
      "Ep 29: Batch #107 - Loss: 0.6137862205505371\n",
      "Ep 29: Batch #108 - Loss: 0.9037281274795532\n",
      "Ep 29: Batch #109 - Loss: 0.630744993686676\n",
      "Ep 29: Batch #110 - Loss: 0.7308900952339172\n",
      "Ep 29: Batch #111 - Loss: 1.0468536615371704\n",
      "Ep 29: Batch #112 - Loss: 0.8129144310951233\n",
      "Ep 29: Batch #113 - Loss: 0.6608505249023438\n",
      "Ep 29: Batch #114 - Loss: 0.731357753276825\n",
      "Ep 29: Batch #115 - Loss: 0.906389057636261\n",
      "Ep 29: Batch #116 - Loss: 0.5274800658226013\n",
      "Ep 29: Batch #117 - Loss: 0.6859856247901917\n",
      "Ep 29: Batch #118 - Loss: 0.45916303992271423\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved in file: ./weights_autoencoder_sigmoid/model_e29b118_1516648795.5295837.ckpt\n",
      "Ep 29: Batch #119 - Loss: 0.8064915537834167\n",
      "Ep 29: Batch #120 - Loss: 0.6622791886329651\n",
      "Ep 29: Batch #121 - Loss: 0.5671602487564087\n",
      "Ep 29: Batch #122 - Loss: 0.7145456075668335\n",
      "Ep 29: Batch #123 - Loss: 0.7226030230522156\n",
      "Ep 29: Batch #124 - Loss: 0.5577052235603333\n",
      "Ep 29: Batch #125 - Loss: 2.468243360519409\n",
      "Ep 29: Batch #126 - Loss: 1.0000759363174438\n",
      "Ep 29: Batch #127 - Loss: 0.5848511457443237\n",
      "Ep 29: Batch #128 - Loss: 0.8839530348777771\n",
      "Ep 29: Batch #129 - Loss: 0.6817879676818848\n",
      "Ep 29: Batch #130 - Loss: 0.5995933413505554\n",
      "Ep 29: Batch #131 - Loss: 0.8070250153541565\n",
      "Ep 29: Batch #132 - Loss: 0.6867572069168091\n",
      "Ep 29: Batch #133 - Loss: 0.6696892380714417\n",
      "Ep 29: Batch #134 - Loss: 0.6400781273841858\n",
      "Ep 29: Batch #135 - Loss: 0.8272632360458374\n",
      "Ep 29: Batch #136 - Loss: 1.0423592329025269\n",
      "Ep 29: Batch #137 - Loss: 0.7554218173027039\n",
      "Ep 29: Batch #138 - Loss: 0.9006747603416443\n",
      "Ep 29: Batch #139 - Loss: 0.6900712847709656\n",
      "Ep 29: Batch #140 - Loss: 0.8501371741294861\n",
      "Ep 29: Batch #141 - Loss: 1.1347112655639648\n",
      "Ep 29: Batch #142 - Loss: 0.6735459566116333\n",
      "Ep 29: Batch #143 - Loss: 0.7715201377868652\n",
      "Ep 29: Batch #144 - Loss: 0.6125960946083069\n",
      "Ep 29: Batch #145 - Loss: 0.6005250811576843\n",
      "Ep 29: Batch #146 - Loss: 0.7079936265945435\n",
      "Ep 29: Batch #147 - Loss: 0.6746885180473328\n",
      "Ep 29: Batch #148 - Loss: 0.7619548439979553\n",
      "Ep 29: Batch #149 - Loss: 0.6409854888916016\n",
      "Ep 29: Batch #150 - Loss: 0.723839282989502\n",
      "Ep 29: Batch #151 - Loss: 0.6331382989883423\n",
      "Ep 29: Batch #152 - Loss: 0.6106724143028259\n",
      "Ep 29: Batch #153 - Loss: 0.8364574313163757\n",
      "Ep 29: Batch #154 - Loss: 0.6356854438781738\n",
      "Ep 29: Batch #155 - Loss: 0.6942521929740906\n",
      "Ep 29: Batch #156 - Loss: 0.8023142218589783\n",
      "Ep 29: Batch #157 - Loss: 0.6189863085746765\n",
      "Ep 29: Batch #158 - Loss: 0.7192125916481018\n",
      "Ep 29: Batch #159 - Loss: 0.6114087700843811\n",
      "Ep 29: Batch #160 - Loss: 0.7071982026100159\n",
      "Ep 29: Batch #161 - Loss: 0.6725913286209106\n",
      "Ep 29: Batch #162 - Loss: 0.7205594778060913\n",
      "Ep 29: Batch #163 - Loss: 0.7632977366447449\n",
      "Ep 29: Batch #164 - Loss: 0.6510921120643616\n",
      "Ep 29: Batch #165 - Loss: 1.3450261354446411\n",
      "Ep 29: Batch #166 - Loss: 0.5359368920326233\n",
      "Ep 29: Batch #167 - Loss: 0.7633323073387146\n",
      "Ep 29: Batch #168 - Loss: 0.6939858794212341\n",
      "Ep 29: Batch #169 - Loss: 0.6723346710205078\n",
      "Ep 29: Batch #170 - Loss: 0.6334932446479797\n",
      "Ep 29: Batch #171 - Loss: 0.6425499320030212\n",
      "Ep 29: Batch #172 - Loss: 0.535640299320221\n",
      "Ep 29: Batch #173 - Loss: 0.9346896409988403\n",
      "Ep 29: Batch #174 - Loss: 0.4974440932273865\n",
      "Ep 29: Batch #175 - Loss: 0.6435330510139465\n",
      "Ep 29: Batch #176 - Loss: 0.8999031186103821\n",
      "Ep 29: Batch #177 - Loss: 0.6588795781135559\n",
      "Ep 29: Batch #178 - Loss: 0.6286090016365051\n",
      "Ep 29: Batch #179 - Loss: 0.752747654914856\n",
      "Ep 29: Batch #180 - Loss: 0.6566154360771179\n",
      "Ep 29: Batch #181 - Loss: 0.8053541779518127\n",
      "Ep 29: Batch #182 - Loss: 0.628261148929596\n",
      "Ep 29: Batch #183 - Loss: 0.6104449033737183\n",
      "Ep 29: Batch #184 - Loss: 0.9238158464431763\n",
      "Ep 29: Batch #185 - Loss: 0.6347819566726685\n",
      "Ep 29: Batch #186 - Loss: 0.7650783658027649\n",
      "Ep 29: Batch #187 - Loss: 0.8775584101676941\n",
      "Ep 29: Batch #188 - Loss: 0.9981385469436646\n",
      "Ep 29: Batch #189 - Loss: 0.5902849435806274\n",
      "Ep 29: Batch #190 - Loss: 0.6262388229370117\n",
      "Ep 29: Batch #191 - Loss: 0.8159462213516235\n",
      "Ep 29: Batch #192 - Loss: 0.5725088715553284\n",
      "Ep 29: Batch #193 - Loss: 0.6298795938491821\n",
      "Ep 29: Batch #194 - Loss: 0.550463855266571\n",
      "Ep 29: Batch #195 - Loss: 0.7970911264419556\n",
      "Ep 29: Batch #196 - Loss: 0.6948274970054626\n",
      "Ep 29: Batch #197 - Loss: 0.7036451101303101\n",
      "Ep 29: Batch #198 - Loss: 0.5355885624885559\n",
      "Ep 29: Batch #199 - Loss: 0.6491568684577942\n",
      "Ep 30: Batch #0 - Loss: 0.6513421535491943\n",
      "Ep 30: Batch #1 - Loss: 0.7162631750106812\n",
      "Ep 30: Batch #2 - Loss: 0.861638605594635\n",
      "Ep 30: Batch #3 - Loss: 0.7234510183334351\n",
      "Ep 30: Batch #4 - Loss: 0.6589987874031067\n",
      "Ep 30: Batch #5 - Loss: 0.5648614764213562\n",
      "Ep 30: Batch #6 - Loss: 0.7460265159606934\n",
      "Ep 30: Batch #7 - Loss: 0.5795710682868958\n",
      "Ep 30: Batch #8 - Loss: 0.5909786820411682\n",
      "Ep 30: Batch #9 - Loss: 1.0983906984329224\n",
      "Ep 30: Batch #10 - Loss: 0.8226785659790039\n",
      "Ep 30: Batch #11 - Loss: 0.5454034805297852\n",
      "Ep 30: Batch #12 - Loss: 1.2245676517486572\n",
      "Ep 30: Batch #13 - Loss: 0.573112428188324\n",
      "Ep 30: Batch #14 - Loss: 0.603653073310852\n",
      "Ep 30: Batch #15 - Loss: 0.880243182182312\n",
      "Ep 30: Batch #16 - Loss: 0.9562125205993652\n",
      "Ep 30: Batch #17 - Loss: 0.7310487627983093\n",
      "Ep 30: Batch #18 - Loss: 0.8079528212547302\n",
      "Ep 30: Batch #19 - Loss: 0.5655947923660278\n",
      "Ep 30: Batch #20 - Loss: 0.5483911037445068\n",
      "Ep 30: Batch #21 - Loss: 0.8709648847579956\n",
      "Ep 30: Batch #22 - Loss: 0.6149839162826538\n",
      "Ep 30: Batch #23 - Loss: 0.603757381439209\n",
      "Ep 30: Batch #24 - Loss: 0.6427209973335266\n",
      "Ep 30: Batch #25 - Loss: 0.6113163828849792\n",
      "Ep 30: Batch #26 - Loss: 0.5677977204322815\n",
      "Ep 30: Batch #27 - Loss: 1.1459583044052124\n",
      "Ep 30: Batch #28 - Loss: 0.6944792866706848\n",
      "Ep 30: Batch #29 - Loss: 0.7600050568580627\n",
      "Ep 30: Batch #30 - Loss: 0.8748935461044312\n",
      "Ep 30: Batch #31 - Loss: 0.5636157393455505\n",
      "Ep 30: Batch #32 - Loss: 0.5847213864326477\n",
      "Ep 30: Batch #33 - Loss: 0.6712481379508972\n",
      "Ep 30: Batch #34 - Loss: 0.6478292942047119\n",
      "Ep 30: Batch #35 - Loss: 0.7289245128631592\n",
      "Ep 30: Batch #36 - Loss: 0.5840769410133362\n",
      "Ep 30: Batch #37 - Loss: 0.9246118664741516\n",
      "Ep 30: Batch #38 - Loss: 0.575198769569397\n",
      "Ep 30: Batch #39 - Loss: 0.6870230436325073\n",
      "Ep 30: Batch #40 - Loss: 0.6069852113723755\n",
      "Ep 30: Batch #41 - Loss: 0.6223578453063965\n",
      "Ep 30: Batch #42 - Loss: 0.5723271369934082\n",
      "Ep 30: Batch #43 - Loss: 0.6356421113014221\n",
      "Ep 30: Batch #44 - Loss: 0.6185866594314575\n",
      "Ep 30: Batch #45 - Loss: 0.53023362159729\n",
      "Ep 30: Batch #46 - Loss: 0.69817054271698\n",
      "Ep 30: Batch #47 - Loss: 0.806470513343811\n",
      "Ep 30: Batch #48 - Loss: 1.0432279109954834\n",
      "Ep 30: Batch #49 - Loss: 0.8141960501670837\n",
      "Ep 30: Batch #50 - Loss: 0.5737826228141785\n",
      "Ep 30: Batch #51 - Loss: 0.8190702199935913\n",
      "Ep 30: Batch #52 - Loss: 0.6792504787445068\n",
      "Ep 30: Batch #53 - Loss: 0.7175661325454712\n",
      "Ep 30: Batch #54 - Loss: 0.5829369425773621\n",
      "Ep 30: Batch #55 - Loss: 0.6117571592330933\n",
      "Ep 30: Batch #56 - Loss: 0.8699821829795837\n",
      "Ep 30: Batch #57 - Loss: 0.6856346726417542\n",
      "Ep 30: Batch #58 - Loss: 0.8319748640060425\n",
      "Ep 30: Batch #59 - Loss: 0.565885603427887\n",
      "Ep 30: Batch #60 - Loss: 1.0164673328399658\n",
      "Ep 30: Batch #61 - Loss: 0.5355211496353149\n",
      "Ep 30: Batch #62 - Loss: 0.5774307250976562\n",
      "Ep 30: Batch #63 - Loss: 0.7921955585479736\n",
      "Ep 30: Batch #64 - Loss: 8.652743339538574\n",
      "Ep 30: Batch #65 - Loss: 0.5264310240745544\n",
      "Ep 30: Batch #66 - Loss: 0.6687481999397278\n",
      "Ep 30: Batch #67 - Loss: 0.7794806957244873\n",
      "Ep 30: Batch #68 - Loss: 0.7218350172042847\n",
      "Ep 30: Batch #69 - Loss: 0.5950807332992554\n",
      "Ep 30: Batch #70 - Loss: 0.62026447057724\n",
      "Ep 30: Batch #71 - Loss: 0.5392751097679138\n",
      "Ep 30: Batch #72 - Loss: 0.6688786745071411\n",
      "Ep 30: Batch #73 - Loss: 0.7329081296920776\n",
      "Ep 30: Batch #74 - Loss: 0.5839564204216003\n",
      "Ep 30: Batch #75 - Loss: 0.6716648936271667\n",
      "Ep 30: Batch #76 - Loss: 0.936879575252533\n",
      "Ep 30: Batch #77 - Loss: 0.5798344612121582\n",
      "Ep 30: Batch #78 - Loss: 0.9301074743270874\n",
      "Ep 30: Batch #79 - Loss: 0.5292985439300537\n",
      "Ep 30: Batch #80 - Loss: 0.6974318623542786\n",
      "Ep 30: Batch #81 - Loss: 1.5298759937286377\n",
      "Ep 30: Batch #82 - Loss: 0.7538623809814453\n",
      "Ep 30: Batch #83 - Loss: 1.348468542098999\n",
      "Ep 30: Batch #84 - Loss: 0.5810656547546387\n",
      "Ep 30: Batch #85 - Loss: 0.7985274195671082\n",
      "Ep 30: Batch #86 - Loss: 0.551899254322052\n",
      "Ep 30: Batch #87 - Loss: 0.5745354890823364\n",
      "Ep 30: Batch #88 - Loss: 0.6577795743942261\n",
      "Ep 30: Batch #89 - Loss: 0.7378963828086853\n",
      "Ep 30: Batch #90 - Loss: 0.9005946516990662\n",
      "Ep 30: Batch #91 - Loss: 0.6492104530334473\n",
      "Ep 30: Batch #92 - Loss: 0.7473545670509338\n",
      "Ep 30: Batch #93 - Loss: 0.7880640625953674\n",
      "Ep 30: Batch #94 - Loss: 0.7684129476547241\n",
      "Ep 30: Batch #95 - Loss: 0.7631340026855469\n",
      "Ep 30: Batch #96 - Loss: 0.7621574401855469\n",
      "Ep 30: Batch #97 - Loss: 0.5863916277885437\n",
      "Ep 30: Batch #98 - Loss: 0.5821855068206787\n",
      "Ep 30: Batch #99 - Loss: 0.8027170300483704\n",
      "Ep 30: Batch #100 - Loss: 0.5608904361724854\n",
      "Ep 30: Batch #101 - Loss: 0.8644387722015381\n",
      "Ep 30: Batch #102 - Loss: 0.6173422336578369\n",
      "Ep 30: Batch #103 - Loss: 0.6412144899368286\n",
      "Ep 30: Batch #104 - Loss: 0.6628457307815552\n",
      "Ep 30: Batch #105 - Loss: 0.817739725112915\n",
      "Ep 30: Batch #106 - Loss: 0.6271747946739197\n",
      "Ep 30: Batch #107 - Loss: 0.6138305068016052\n",
      "Ep 30: Batch #108 - Loss: 0.9039000868797302\n",
      "Ep 30: Batch #109 - Loss: 0.63100266456604\n",
      "Ep 30: Batch #110 - Loss: 0.7308878302574158\n",
      "Ep 30: Batch #111 - Loss: 1.0465216636657715\n",
      "Ep 30: Batch #112 - Loss: 0.8116439580917358\n",
      "Ep 30: Batch #113 - Loss: 0.6614353656768799\n",
      "Ep 30: Batch #114 - Loss: 0.7311607003211975\n",
      "Ep 30: Batch #115 - Loss: 0.9073574542999268\n",
      "Ep 30: Batch #116 - Loss: 0.5269471406936646\n",
      "Ep 30: Batch #117 - Loss: 0.6853427290916443\n",
      "Ep 30: Batch #118 - Loss: 0.4587605893611908\n",
      "Model saved in file: ./weights_autoencoder_sigmoid/model_e30b118_1516648795.6734138.ckpt\n",
      "Ep 30: Batch #119 - Loss: 0.8053650856018066\n",
      "Ep 30: Batch #120 - Loss: 0.6628645658493042\n",
      "Ep 30: Batch #121 - Loss: 0.5665176510810852\n",
      "Ep 30: Batch #122 - Loss: 0.7139865756034851\n",
      "Ep 30: Batch #123 - Loss: 0.7225662469863892\n",
      "Ep 30: Batch #124 - Loss: 0.5576798915863037\n",
      "Ep 30: Batch #125 - Loss: 2.468289852142334\n",
      "Ep 30: Batch #126 - Loss: 0.9996089935302734\n",
      "Ep 30: Batch #127 - Loss: 0.58442223072052\n",
      "Ep 30: Batch #128 - Loss: 0.8846569657325745\n",
      "Ep 30: Batch #129 - Loss: 0.6817231774330139\n",
      "Ep 30: Batch #130 - Loss: 0.5995445847511292\n",
      "Ep 30: Batch #131 - Loss: 0.8068236708641052\n",
      "Ep 30: Batch #132 - Loss: 0.6863868832588196\n",
      "Ep 30: Batch #133 - Loss: 0.6699792146682739\n",
      "Ep 30: Batch #134 - Loss: 0.6404842734336853\n",
      "Ep 30: Batch #135 - Loss: 0.827698826789856\n",
      "Ep 30: Batch #136 - Loss: 1.042109727859497\n",
      "Ep 30: Batch #137 - Loss: 0.7552983164787292\n",
      "Ep 30: Batch #138 - Loss: 0.9008213877677917\n",
      "Ep 30: Batch #139 - Loss: 0.6892776489257812\n",
      "Ep 30: Batch #140 - Loss: 0.8498628735542297\n",
      "Ep 30: Batch #141 - Loss: 1.1344846487045288\n",
      "Ep 30: Batch #142 - Loss: 0.6733457446098328\n",
      "Ep 30: Batch #143 - Loss: 0.7721762657165527\n",
      "Ep 30: Batch #144 - Loss: 0.6125496029853821\n",
      "Ep 30: Batch #145 - Loss: 0.6007498502731323\n",
      "Ep 30: Batch #146 - Loss: 0.7080459594726562\n",
      "Ep 30: Batch #147 - Loss: 0.6738424301147461\n",
      "Ep 30: Batch #148 - Loss: 0.7621046304702759\n",
      "Ep 30: Batch #149 - Loss: 0.6399810314178467\n",
      "Ep 30: Batch #150 - Loss: 0.7236610054969788\n",
      "Ep 30: Batch #151 - Loss: 0.6330015063285828\n",
      "Ep 30: Batch #152 - Loss: 0.6105406880378723\n",
      "Ep 30: Batch #153 - Loss: 0.835307240486145\n",
      "Ep 30: Batch #154 - Loss: 0.6356753706932068\n",
      "Ep 30: Batch #155 - Loss: 0.6975768804550171\n",
      "Ep 30: Batch #156 - Loss: 0.800834596157074\n",
      "Ep 30: Batch #157 - Loss: 0.6195271611213684\n",
      "Ep 30: Batch #158 - Loss: 0.7188672423362732\n",
      "Ep 30: Batch #159 - Loss: 0.6102677583694458\n",
      "Ep 30: Batch #160 - Loss: 0.7063307762145996\n",
      "Ep 30: Batch #161 - Loss: 0.6723368167877197\n",
      "Ep 30: Batch #162 - Loss: 0.7208442687988281\n",
      "Ep 30: Batch #163 - Loss: 0.7634735703468323\n",
      "Ep 30: Batch #164 - Loss: 0.6512721180915833\n",
      "Ep 30: Batch #165 - Loss: 1.3459055423736572\n",
      "Ep 30: Batch #166 - Loss: 0.5359099507331848\n",
      "Ep 30: Batch #167 - Loss: 0.7609235048294067\n",
      "Ep 30: Batch #168 - Loss: 0.6943053603172302\n",
      "Ep 30: Batch #169 - Loss: 0.6722925305366516\n",
      "Ep 30: Batch #170 - Loss: 0.632950484752655\n",
      "Ep 30: Batch #171 - Loss: 0.6423538327217102\n",
      "Ep 30: Batch #172 - Loss: 0.5353548526763916\n",
      "Ep 30: Batch #173 - Loss: 0.9339751601219177\n",
      "Ep 30: Batch #174 - Loss: 0.49727556109428406\n",
      "Ep 30: Batch #175 - Loss: 0.643180787563324\n",
      "Ep 30: Batch #176 - Loss: 0.9009097218513489\n",
      "Ep 30: Batch #177 - Loss: 0.658120334148407\n",
      "Ep 30: Batch #178 - Loss: 0.6283559203147888\n",
      "Ep 30: Batch #179 - Loss: 0.7536378502845764\n",
      "Ep 30: Batch #180 - Loss: 0.6566058993339539\n",
      "Ep 30: Batch #181 - Loss: 0.8050227761268616\n",
      "Ep 30: Batch #182 - Loss: 0.6285368204116821\n",
      "Ep 30: Batch #183 - Loss: 0.609916627407074\n",
      "Ep 30: Batch #184 - Loss: 0.9234808087348938\n",
      "Ep 30: Batch #185 - Loss: 0.6348667144775391\n",
      "Ep 30: Batch #186 - Loss: 0.7648239135742188\n",
      "Ep 30: Batch #187 - Loss: 0.8765615820884705\n",
      "Ep 30: Batch #188 - Loss: 0.9951480031013489\n",
      "Ep 30: Batch #189 - Loss: 0.5900898575782776\n",
      "Ep 30: Batch #190 - Loss: 0.6263120770454407\n",
      "Ep 30: Batch #191 - Loss: 0.8168577551841736\n",
      "Ep 30: Batch #192 - Loss: 0.5722651481628418\n",
      "Ep 30: Batch #193 - Loss: 0.6298013925552368\n",
      "Ep 30: Batch #194 - Loss: 0.549900472164154\n",
      "Ep 30: Batch #195 - Loss: 0.796478807926178\n",
      "Ep 30: Batch #196 - Loss: 0.6946324706077576\n",
      "Ep 30: Batch #197 - Loss: 0.7035187482833862\n",
      "Ep 30: Batch #198 - Loss: 0.5352833271026611\n",
      "Ep 30: Batch #199 - Loss: 0.6486560702323914\n",
      "Ep 31: Batch #0 - Loss: 0.6509215235710144\n",
      "Ep 31: Batch #1 - Loss: 0.716253936290741\n",
      "Ep 31: Batch #2 - Loss: 0.8618281483650208\n",
      "Ep 31: Batch #3 - Loss: 0.723461925983429\n",
      "Ep 31: Batch #4 - Loss: 0.6591157913208008\n",
      "Ep 31: Batch #5 - Loss: 0.5642833709716797\n",
      "Ep 31: Batch #6 - Loss: 0.7452110052108765\n",
      "Ep 31: Batch #7 - Loss: 0.5791559815406799\n",
      "Ep 31: Batch #8 - Loss: 0.5909125804901123\n",
      "Ep 31: Batch #9 - Loss: 1.0984551906585693\n",
      "Ep 31: Batch #10 - Loss: 0.8214008212089539\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 31: Batch #11 - Loss: 0.5453764200210571\n",
      "Ep 31: Batch #12 - Loss: 1.2243202924728394\n",
      "Ep 31: Batch #13 - Loss: 0.5730024576187134\n",
      "Ep 31: Batch #14 - Loss: 0.6031852960586548\n",
      "Ep 31: Batch #15 - Loss: 0.8785767555236816\n",
      "Ep 31: Batch #16 - Loss: 0.9556149244308472\n",
      "Ep 31: Batch #17 - Loss: 0.7310155630111694\n",
      "Ep 31: Batch #18 - Loss: 0.808118462562561\n",
      "Ep 31: Batch #19 - Loss: 0.5655911564826965\n",
      "Ep 31: Batch #20 - Loss: 0.5481839776039124\n",
      "Ep 31: Batch #21 - Loss: 0.8672546744346619\n",
      "Ep 31: Batch #22 - Loss: 0.614764392375946\n",
      "Ep 31: Batch #23 - Loss: 0.6042645573616028\n",
      "Ep 31: Batch #24 - Loss: 0.6421436071395874\n",
      "Ep 31: Batch #25 - Loss: 0.6111802458763123\n",
      "Ep 31: Batch #26 - Loss: 0.5669129490852356\n",
      "Ep 31: Batch #27 - Loss: 1.1459459066390991\n",
      "Ep 31: Batch #28 - Loss: 0.6941193342208862\n",
      "Ep 31: Batch #29 - Loss: 0.7597026228904724\n",
      "Ep 31: Batch #30 - Loss: 0.8723475337028503\n",
      "Ep 31: Batch #31 - Loss: 0.5634675621986389\n",
      "Ep 31: Batch #32 - Loss: 0.5843213796615601\n",
      "Ep 31: Batch #33 - Loss: 0.6710559725761414\n",
      "Ep 31: Batch #34 - Loss: 0.6474948525428772\n",
      "Ep 31: Batch #35 - Loss: 0.7286347150802612\n",
      "Ep 31: Batch #36 - Loss: 0.584163248538971\n",
      "Ep 31: Batch #37 - Loss: 0.9248612523078918\n",
      "Ep 31: Batch #38 - Loss: 0.5749117732048035\n",
      "Ep 31: Batch #39 - Loss: 0.6870216131210327\n",
      "Ep 31: Batch #40 - Loss: 0.6068306565284729\n",
      "Ep 31: Batch #41 - Loss: 0.6223692893981934\n",
      "Ep 31: Batch #42 - Loss: 0.5722378492355347\n",
      "Ep 31: Batch #43 - Loss: 0.6354564428329468\n",
      "Ep 31: Batch #44 - Loss: 0.6183149814605713\n",
      "Ep 31: Batch #45 - Loss: 0.5299394130706787\n",
      "Ep 31: Batch #46 - Loss: 0.6981314420700073\n",
      "Ep 31: Batch #47 - Loss: 0.8063273429870605\n",
      "Ep 31: Batch #48 - Loss: 1.043442726135254\n",
      "Ep 31: Batch #49 - Loss: 0.8142525553703308\n",
      "Ep 31: Batch #50 - Loss: 0.573499858379364\n",
      "Ep 31: Batch #51 - Loss: 0.8192833065986633\n",
      "Ep 31: Batch #52 - Loss: 0.6790379285812378\n",
      "Ep 31: Batch #53 - Loss: 0.71747225522995\n",
      "Ep 31: Batch #54 - Loss: 0.5826317667961121\n",
      "Ep 31: Batch #55 - Loss: 0.6113249063491821\n",
      "Ep 31: Batch #56 - Loss: 0.869645893573761\n",
      "Ep 31: Batch #57 - Loss: 0.6853282451629639\n",
      "Ep 31: Batch #58 - Loss: 0.8319488763809204\n",
      "Ep 31: Batch #59 - Loss: 0.5655390620231628\n",
      "Ep 31: Batch #60 - Loss: 1.0168325901031494\n",
      "Ep 31: Batch #61 - Loss: 0.5354199409484863\n",
      "Ep 31: Batch #62 - Loss: 0.5774532556533813\n",
      "Ep 31: Batch #63 - Loss: 0.7918088436126709\n",
      "Ep 31: Batch #64 - Loss: 8.651103019714355\n",
      "Ep 31: Batch #65 - Loss: 0.5264910459518433\n",
      "Ep 31: Batch #66 - Loss: 0.6681430339813232\n",
      "Ep 31: Batch #67 - Loss: 0.7788581848144531\n",
      "Ep 31: Batch #68 - Loss: 0.7205579280853271\n",
      "Ep 31: Batch #69 - Loss: 0.5938347578048706\n",
      "Ep 31: Batch #70 - Loss: 0.620221734046936\n",
      "Ep 31: Batch #71 - Loss: 0.5393645763397217\n",
      "Ep 31: Batch #72 - Loss: 0.6655753254890442\n",
      "Ep 31: Batch #73 - Loss: 0.7313090562820435\n",
      "Ep 31: Batch #74 - Loss: 0.5820090770721436\n",
      "Ep 31: Batch #75 - Loss: 0.6707928776741028\n",
      "Ep 31: Batch #76 - Loss: 0.9339523315429688\n",
      "Ep 31: Batch #77 - Loss: 0.5789978504180908\n",
      "Ep 31: Batch #78 - Loss: 0.9287867546081543\n",
      "Ep 31: Batch #79 - Loss: 0.5289345383644104\n",
      "Ep 31: Batch #80 - Loss: 0.6963046789169312\n",
      "Ep 31: Batch #81 - Loss: 1.5309373140335083\n",
      "Ep 31: Batch #82 - Loss: 0.7525249719619751\n",
      "Ep 31: Batch #83 - Loss: 1.3445602655410767\n",
      "Ep 31: Batch #84 - Loss: 0.5800430178642273\n",
      "Ep 31: Batch #85 - Loss: 0.7945743799209595\n",
      "Ep 31: Batch #86 - Loss: 0.5510998368263245\n",
      "Ep 31: Batch #87 - Loss: 0.574905276298523\n",
      "Ep 31: Batch #88 - Loss: 0.6584902405738831\n",
      "Ep 31: Batch #89 - Loss: 0.736852765083313\n",
      "Ep 31: Batch #90 - Loss: 0.9001665115356445\n",
      "Ep 31: Batch #91 - Loss: 0.6493304371833801\n",
      "Ep 31: Batch #92 - Loss: 0.7450247406959534\n",
      "Ep 31: Batch #93 - Loss: 0.7875428199768066\n",
      "Ep 31: Batch #94 - Loss: 0.7667815685272217\n",
      "Ep 31: Batch #95 - Loss: 0.7619381546974182\n",
      "Ep 31: Batch #96 - Loss: 0.7617611885070801\n",
      "Ep 31: Batch #97 - Loss: 0.5864763259887695\n",
      "Ep 31: Batch #98 - Loss: 0.5818422436714172\n",
      "Ep 31: Batch #99 - Loss: 0.8029410243034363\n",
      "Ep 31: Batch #100 - Loss: 0.5603786706924438\n",
      "Ep 31: Batch #101 - Loss: 0.8621043562889099\n",
      "Ep 31: Batch #102 - Loss: 0.6167592406272888\n",
      "Ep 31: Batch #103 - Loss: 0.6409786343574524\n",
      "Ep 31: Batch #104 - Loss: 0.6625665426254272\n",
      "Ep 31: Batch #105 - Loss: 0.8178845643997192\n",
      "Ep 31: Batch #106 - Loss: 0.6270180940628052\n",
      "Ep 31: Batch #107 - Loss: 0.6139253377914429\n",
      "Ep 31: Batch #108 - Loss: 0.903509259223938\n",
      "Ep 31: Batch #109 - Loss: 0.6296754479408264\n",
      "Ep 31: Batch #110 - Loss: 0.7304304838180542\n",
      "Ep 31: Batch #111 - Loss: 1.0459909439086914\n",
      "Ep 31: Batch #112 - Loss: 0.8101148009300232\n",
      "Ep 31: Batch #113 - Loss: 0.660724401473999\n",
      "Ep 31: Batch #114 - Loss: 0.73093181848526\n",
      "Ep 31: Batch #115 - Loss: 0.9061112403869629\n",
      "Ep 31: Batch #116 - Loss: 0.5262424945831299\n",
      "Ep 31: Batch #117 - Loss: 0.6847315430641174\n",
      "Ep 31: Batch #118 - Loss: 0.4587991535663605\n",
      "Ep 31: Batch #119 - Loss: 0.8060309290885925\n",
      "Ep 31: Batch #120 - Loss: 0.6625861525535583\n",
      "Ep 31: Batch #121 - Loss: 0.5661653280258179\n",
      "Ep 31: Batch #122 - Loss: 0.7137352228164673\n",
      "Ep 31: Batch #123 - Loss: 0.7219319939613342\n",
      "Ep 31: Batch #124 - Loss: 0.5575682520866394\n",
      "Ep 31: Batch #125 - Loss: 2.468043565750122\n",
      "Ep 31: Batch #126 - Loss: 1.0000972747802734\n",
      "Ep 31: Batch #127 - Loss: 0.5844025611877441\n",
      "Ep 31: Batch #128 - Loss: 0.8838043212890625\n",
      "Ep 31: Batch #129 - Loss: 0.6813555955886841\n",
      "Ep 31: Batch #130 - Loss: 0.5988515615463257\n",
      "Ep 31: Batch #131 - Loss: 0.8069067597389221\n",
      "Ep 31: Batch #132 - Loss: 0.6862173676490784\n",
      "Ep 31: Batch #133 - Loss: 0.6695798635482788\n",
      "Ep 31: Batch #134 - Loss: 0.6397690176963806\n",
      "Ep 31: Batch #135 - Loss: 0.8253019452095032\n",
      "Ep 31: Batch #136 - Loss: 1.0418442487716675\n",
      "Ep 31: Batch #137 - Loss: 0.7553092837333679\n",
      "Ep 31: Batch #138 - Loss: 0.9006602168083191\n",
      "Ep 31: Batch #139 - Loss: 0.6875097751617432\n",
      "Ep 31: Batch #140 - Loss: 0.8490743041038513\n",
      "Ep 31: Batch #141 - Loss: 1.1338109970092773\n",
      "Ep 31: Batch #142 - Loss: 0.6730338931083679\n",
      "Ep 31: Batch #143 - Loss: 0.7717675566673279\n",
      "Ep 31: Batch #144 - Loss: 0.6124856472015381\n",
      "Ep 31: Batch #145 - Loss: 0.599950909614563\n",
      "Ep 31: Batch #146 - Loss: 0.7074324488639832\n",
      "Ep 31: Batch #147 - Loss: 0.6730312705039978\n",
      "Ep 31: Batch #148 - Loss: 0.7612093091011047\n",
      "Ep 31: Batch #149 - Loss: 0.6382818222045898\n",
      "Ep 31: Batch #150 - Loss: 0.7229745984077454\n",
      "Ep 31: Batch #151 - Loss: 0.6323647499084473\n",
      "Ep 31: Batch #152 - Loss: 0.6104142665863037\n",
      "Ep 31: Batch #153 - Loss: 0.8346986770629883\n",
      "Ep 31: Batch #154 - Loss: 0.6352850794792175\n",
      "Ep 31: Batch #155 - Loss: 0.69438636302948\n",
      "Ep 31: Batch #156 - Loss: 0.7991198301315308\n",
      "Ep 31: Batch #157 - Loss: 0.6187205910682678\n",
      "Ep 31: Batch #158 - Loss: 0.7187818288803101\n",
      "Ep 31: Batch #159 - Loss: 0.6093463897705078\n",
      "Ep 31: Batch #160 - Loss: 0.7056974768638611\n",
      "Ep 31: Batch #161 - Loss: 0.6717231869697571\n",
      "Ep 31: Batch #162 - Loss: 0.7205658555030823\n",
      "Ep 31: Batch #163 - Loss: 0.762431263923645\n",
      "Ep 31: Batch #164 - Loss: 0.6509385704994202\n",
      "Ep 31: Batch #165 - Loss: 1.34529709815979\n",
      "Ep 31: Batch #166 - Loss: 0.5356577038764954\n",
      "Ep 31: Batch #167 - Loss: 0.7584463357925415\n",
      "Ep 31: Batch #168 - Loss: 0.6937081217765808\n",
      "Ep 31: Batch #169 - Loss: 0.6715205907821655\n",
      "Ep 31: Batch #170 - Loss: 0.6323740482330322\n",
      "Ep 31: Batch #171 - Loss: 0.6424908638000488\n",
      "Ep 31: Batch #172 - Loss: 0.5351321697235107\n",
      "Ep 31: Batch #173 - Loss: 0.9341187477111816\n",
      "Ep 31: Batch #174 - Loss: 0.49699240922927856\n",
      "Ep 31: Batch #175 - Loss: 0.6428609490394592\n",
      "Ep 31: Batch #176 - Loss: 0.9002480506896973\n",
      "Ep 31: Batch #177 - Loss: 0.6574062705039978\n",
      "Ep 31: Batch #178 - Loss: 0.627687931060791\n",
      "Ep 31: Batch #179 - Loss: 0.7524737119674683\n",
      "Ep 31: Batch #180 - Loss: 0.6560850143432617\n",
      "Ep 31: Batch #181 - Loss: 0.8045409321784973\n",
      "Ep 31: Batch #182 - Loss: 0.627975344657898\n",
      "Ep 31: Batch #183 - Loss: 0.6098272800445557\n",
      "Ep 31: Batch #184 - Loss: 0.9231048226356506\n",
      "Ep 31: Batch #185 - Loss: 0.6346551775932312\n",
      "Ep 31: Batch #186 - Loss: 0.763748288154602\n",
      "Ep 31: Batch #187 - Loss: 0.8755137920379639\n",
      "Ep 31: Batch #188 - Loss: 0.9932420253753662\n",
      "Ep 31: Batch #189 - Loss: 0.5898773670196533\n",
      "Ep 31: Batch #190 - Loss: 0.6258808374404907\n",
      "Ep 31: Batch #191 - Loss: 0.8153413534164429\n",
      "Ep 31: Batch #192 - Loss: 0.5723139643669128\n",
      "Ep 31: Batch #193 - Loss: 0.6297370195388794\n",
      "Ep 31: Batch #194 - Loss: 0.5493252277374268\n",
      "Ep 31: Batch #195 - Loss: 0.7958412766456604\n",
      "Ep 31: Batch #196 - Loss: 0.6945193409919739\n",
      "Ep 31: Batch #197 - Loss: 0.7034026980400085\n",
      "Ep 31: Batch #198 - Loss: 0.535045325756073\n",
      "Ep 31: Batch #199 - Loss: 0.648254930973053\n",
      "Ep 32: Batch #0 - Loss: 0.6506825089454651\n",
      "Ep 32: Batch #1 - Loss: 0.7160347104072571\n",
      "Ep 32: Batch #2 - Loss: 0.861638605594635\n",
      "Ep 32: Batch #3 - Loss: 0.7232406735420227\n",
      "Ep 32: Batch #4 - Loss: 0.6591543555259705\n",
      "Ep 32: Batch #5 - Loss: 0.5641453266143799\n",
      "Ep 32: Batch #6 - Loss: 0.7450318336486816\n",
      "Ep 32: Batch #7 - Loss: 0.5788249969482422\n",
      "Ep 32: Batch #8 - Loss: 0.5905949473381042\n",
      "Ep 32: Batch #9 - Loss: 1.0985058546066284\n",
      "Ep 32: Batch #10 - Loss: 0.8204829096794128\n",
      "Ep 32: Batch #11 - Loss: 0.5451369285583496\n",
      "Ep 32: Batch #12 - Loss: 1.223215937614441\n",
      "Ep 32: Batch #13 - Loss: 0.5728885531425476\n",
      "Ep 32: Batch #14 - Loss: 0.6030430793762207\n",
      "Ep 32: Batch #15 - Loss: 0.8765743374824524\n",
      "Ep 32: Batch #16 - Loss: 0.9554082751274109\n",
      "Ep 32: Batch #17 - Loss: 0.7310299873352051\n",
      "Ep 32: Batch #18 - Loss: 0.8081552386283875\n",
      "Ep 32: Batch #19 - Loss: 0.5656102895736694\n",
      "Ep 32: Batch #20 - Loss: 0.5481106042861938\n",
      "Ep 32: Batch #21 - Loss: 0.8650699257850647\n",
      "Ep 32: Batch #22 - Loss: 0.61443692445755\n",
      "Ep 32: Batch #23 - Loss: 0.603632926940918\n",
      "Ep 32: Batch #24 - Loss: 0.6418509483337402\n",
      "Ep 32: Batch #25 - Loss: 0.6109712719917297\n",
      "Ep 32: Batch #26 - Loss: 0.5665168762207031\n",
      "Ep 32: Batch #27 - Loss: 1.1456414461135864\n",
      "Ep 32: Batch #28 - Loss: 0.6937717199325562\n",
      "Ep 32: Batch #29 - Loss: 0.7595415115356445\n",
      "Ep 32: Batch #30 - Loss: 0.8703243136405945\n",
      "Ep 32: Batch #31 - Loss: 0.5631767511367798\n",
      "Ep 32: Batch #32 - Loss: 0.5839850902557373\n",
      "Ep 32: Batch #33 - Loss: 0.6705668568611145\n",
      "Ep 32: Batch #34 - Loss: 0.6467717289924622\n",
      "Ep 32: Batch #35 - Loss: 0.7279840111732483\n",
      "Ep 32: Batch #36 - Loss: 0.5839497447013855\n",
      "Ep 32: Batch #37 - Loss: 0.9248088002204895\n",
      "Ep 32: Batch #38 - Loss: 0.5745809674263\n",
      "Ep 32: Batch #39 - Loss: 0.6869373917579651\n",
      "Ep 32: Batch #40 - Loss: 0.6064388751983643\n",
      "Ep 32: Batch #41 - Loss: 0.6223651170730591\n",
      "Ep 32: Batch #42 - Loss: 0.5720500946044922\n",
      "Ep 32: Batch #43 - Loss: 0.635244607925415\n",
      "Ep 32: Batch #44 - Loss: 0.6180426478385925\n",
      "Ep 32: Batch #45 - Loss: 0.5297836661338806\n",
      "Ep 32: Batch #46 - Loss: 0.6979625225067139\n",
      "Ep 32: Batch #47 - Loss: 0.806364893913269\n",
      "Ep 32: Batch #48 - Loss: 1.0425790548324585\n",
      "Ep 32: Batch #49 - Loss: 0.8144913911819458\n",
      "Ep 32: Batch #50 - Loss: 0.5735223293304443\n",
      "Ep 32: Batch #51 - Loss: 0.8196425437927246\n",
      "Ep 32: Batch #52 - Loss: 0.6787052750587463\n",
      "Ep 32: Batch #53 - Loss: 0.717507541179657\n",
      "Ep 32: Batch #54 - Loss: 0.5822888016700745\n",
      "Ep 32: Batch #55 - Loss: 0.6108865737915039\n",
      "Ep 32: Batch #56 - Loss: 0.8690102100372314\n",
      "Ep 32: Batch #57 - Loss: 0.6849197745323181\n",
      "Ep 32: Batch #58 - Loss: 0.8316150307655334\n",
      "Ep 32: Batch #59 - Loss: 0.5651947855949402\n",
      "Ep 32: Batch #60 - Loss: 1.0153460502624512\n",
      "Ep 32: Batch #61 - Loss: 0.5353455543518066\n",
      "Ep 32: Batch #62 - Loss: 0.5774257183074951\n",
      "Ep 32: Batch #63 - Loss: 0.7914873957633972\n",
      "Ep 32: Batch #64 - Loss: 8.636009216308594\n",
      "Ep 32: Batch #65 - Loss: 0.5262523889541626\n",
      "Ep 32: Batch #66 - Loss: 0.6675434708595276\n",
      "Ep 32: Batch #67 - Loss: 0.7781758904457092\n",
      "Ep 32: Batch #68 - Loss: 0.7200771570205688\n",
      "Ep 32: Batch #69 - Loss: 0.5934832692146301\n",
      "Ep 32: Batch #70 - Loss: 0.6201800107955933\n",
      "Ep 32: Batch #71 - Loss: 0.5391619205474854\n",
      "Ep 32: Batch #72 - Loss: 0.6648194193840027\n",
      "Ep 32: Batch #73 - Loss: 0.7307519316673279\n",
      "Ep 32: Batch #74 - Loss: 0.5820303559303284\n",
      "Ep 32: Batch #75 - Loss: 0.670746922492981\n",
      "Ep 32: Batch #76 - Loss: 0.9334952235221863\n",
      "Ep 32: Batch #77 - Loss: 0.5792887806892395\n",
      "Ep 32: Batch #78 - Loss: 0.9280712604522705\n",
      "Ep 32: Batch #79 - Loss: 0.5287392139434814\n",
      "Ep 32: Batch #80 - Loss: 0.6959949731826782\n",
      "Ep 32: Batch #81 - Loss: 1.528931736946106\n",
      "Ep 32: Batch #82 - Loss: 0.752337634563446\n",
      "Ep 32: Batch #83 - Loss: 1.3406742811203003\n",
      "Ep 32: Batch #84 - Loss: 0.5798786282539368\n",
      "Ep 32: Batch #85 - Loss: 0.7944563031196594\n",
      "Ep 32: Batch #86 - Loss: 0.5506095886230469\n",
      "Ep 32: Batch #87 - Loss: 0.5748417973518372\n",
      "Ep 32: Batch #88 - Loss: 0.6584472060203552\n",
      "Ep 32: Batch #89 - Loss: 0.7364290356636047\n",
      "Ep 32: Batch #90 - Loss: 0.9000577926635742\n",
      "Ep 32: Batch #91 - Loss: 0.6493701338768005\n",
      "Ep 32: Batch #92 - Loss: 0.7433285117149353\n",
      "Ep 32: Batch #93 - Loss: 0.787482500076294\n",
      "Ep 32: Batch #94 - Loss: 0.765216588973999\n",
      "Ep 32: Batch #95 - Loss: 0.7614907026290894\n",
      "Ep 32: Batch #96 - Loss: 0.7614768147468567\n",
      "Ep 32: Batch #97 - Loss: 0.5864753723144531\n",
      "Ep 32: Batch #98 - Loss: 0.5814562439918518\n",
      "Ep 32: Batch #99 - Loss: 0.8026490211486816\n",
      "Ep 32: Batch #100 - Loss: 0.5600841641426086\n",
      "Ep 32: Batch #101 - Loss: 0.862031102180481\n",
      "Ep 32: Batch #102 - Loss: 0.615562915802002\n",
      "Ep 32: Batch #103 - Loss: 0.6404741406440735\n",
      "Ep 32: Batch #104 - Loss: 0.6625173091888428\n",
      "Ep 32: Batch #105 - Loss: 0.8173370361328125\n",
      "Ep 32: Batch #106 - Loss: 0.6271525025367737\n",
      "Ep 32: Batch #107 - Loss: 0.6138966679573059\n",
      "Ep 32: Batch #108 - Loss: 0.9029335975646973\n",
      "Ep 32: Batch #109 - Loss: 0.6292340159416199\n",
      "Ep 32: Batch #110 - Loss: 0.7299511432647705\n",
      "Ep 32: Batch #111 - Loss: 1.0456831455230713\n",
      "Ep 32: Batch #112 - Loss: 0.8085662722587585\n",
      "Ep 32: Batch #113 - Loss: 0.6604849100112915\n",
      "Ep 32: Batch #114 - Loss: 0.7305386662483215\n",
      "Ep 32: Batch #115 - Loss: 0.9061156511306763\n",
      "Ep 32: Batch #116 - Loss: 0.5257511138916016\n",
      "Ep 32: Batch #117 - Loss: 0.6840217113494873\n",
      "Ep 32: Batch #118 - Loss: 0.4587843418121338\n",
      "Ep 32: Batch #119 - Loss: 0.8068580031394958\n",
      "Ep 32: Batch #120 - Loss: 0.6623259782791138\n",
      "Ep 32: Batch #121 - Loss: 0.565686821937561\n",
      "Ep 32: Batch #122 - Loss: 0.7134394645690918\n",
      "Ep 32: Batch #123 - Loss: 0.7218800187110901\n",
      "Ep 32: Batch #124 - Loss: 0.5575398206710815\n",
      "Ep 32: Batch #125 - Loss: 2.467500925064087\n",
      "Ep 32: Batch #126 - Loss: 0.9993536472320557\n",
      "Ep 32: Batch #127 - Loss: 0.5843359231948853\n",
      "Ep 32: Batch #128 - Loss: 0.8839846849441528\n",
      "Ep 32: Batch #129 - Loss: 0.6810236573219299\n",
      "Ep 32: Batch #130 - Loss: 0.5985380411148071\n",
      "Ep 32: Batch #131 - Loss: 0.8069257140159607\n",
      "Ep 32: Batch #132 - Loss: 0.6859601736068726\n",
      "Ep 32: Batch #133 - Loss: 0.6695588231086731\n",
      "Ep 32: Batch #134 - Loss: 0.6394975185394287\n",
      "Ep 32: Batch #135 - Loss: 0.8252241611480713\n",
      "Ep 32: Batch #136 - Loss: 1.0418108701705933\n",
      "Ep 32: Batch #137 - Loss: 0.7555711269378662\n",
      "Ep 32: Batch #138 - Loss: 0.9004435539245605\n",
      "Ep 32: Batch #139 - Loss: 0.6850230097770691\n",
      "Ep 32: Batch #140 - Loss: 0.8485110402107239\n",
      "Ep 32: Batch #141 - Loss: 1.1338119506835938\n",
      "Ep 32: Batch #142 - Loss: 0.6726945042610168\n",
      "Ep 32: Batch #143 - Loss: 0.7718468308448792\n",
      "Ep 32: Batch #144 - Loss: 0.6124963164329529\n",
      "Ep 32: Batch #145 - Loss: 0.5996761918067932\n",
      "Ep 32: Batch #146 - Loss: 0.7070181965827942\n",
      "Ep 32: Batch #147 - Loss: 0.6724166870117188\n",
      "Ep 32: Batch #148 - Loss: 0.7607593536376953\n",
      "Ep 32: Batch #149 - Loss: 0.6370862126350403\n",
      "Ep 32: Batch #150 - Loss: 0.7227956652641296\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 32: Batch #151 - Loss: 0.6319659352302551\n",
      "Ep 32: Batch #152 - Loss: 0.6101319789886475\n",
      "Ep 32: Batch #153 - Loss: 0.8338276743888855\n",
      "Ep 32: Batch #154 - Loss: 0.6350555419921875\n",
      "Ep 32: Batch #155 - Loss: 0.6932392120361328\n",
      "Ep 32: Batch #156 - Loss: 0.7982560992240906\n",
      "Ep 32: Batch #157 - Loss: 0.6183828711509705\n",
      "Ep 32: Batch #158 - Loss: 0.7185745239257812\n",
      "Ep 32: Batch #159 - Loss: 0.6084374785423279\n",
      "Ep 32: Batch #160 - Loss: 0.704918384552002\n",
      "Ep 32: Batch #161 - Loss: 0.671437680721283\n",
      "Ep 32: Batch #162 - Loss: 0.7200822830200195\n",
      "Ep 32: Batch #163 - Loss: 0.762174129486084\n",
      "Ep 32: Batch #164 - Loss: 0.6505148410797119\n",
      "Ep 32: Batch #165 - Loss: 1.3452720642089844\n",
      "Ep 32: Batch #166 - Loss: 0.5353728532791138\n",
      "Ep 32: Batch #167 - Loss: 0.7560989260673523\n",
      "Ep 32: Batch #168 - Loss: 0.6936150193214417\n",
      "Ep 32: Batch #169 - Loss: 0.6714512705802917\n",
      "Ep 32: Batch #170 - Loss: 0.6319389939308167\n",
      "Ep 32: Batch #171 - Loss: 0.6424727439880371\n",
      "Ep 32: Batch #172 - Loss: 0.5349678993225098\n",
      "Ep 32: Batch #173 - Loss: 0.9337887763977051\n",
      "Ep 32: Batch #174 - Loss: 0.4970395863056183\n",
      "Ep 32: Batch #175 - Loss: 0.6424022316932678\n",
      "Ep 32: Batch #176 - Loss: 0.8997202515602112\n",
      "Ep 32: Batch #177 - Loss: 0.6570011377334595\n",
      "Ep 32: Batch #178 - Loss: 0.6273720264434814\n",
      "Ep 32: Batch #179 - Loss: 0.7521218061447144\n",
      "Ep 32: Batch #180 - Loss: 0.6557284593582153\n",
      "Ep 32: Batch #181 - Loss: 0.8044188618659973\n",
      "Ep 32: Batch #182 - Loss: 0.6277855634689331\n",
      "Ep 32: Batch #183 - Loss: 0.6097409725189209\n",
      "Ep 32: Batch #184 - Loss: 0.9230201244354248\n",
      "Ep 32: Batch #185 - Loss: 0.6345102787017822\n",
      "Ep 32: Batch #186 - Loss: 0.7631494402885437\n",
      "Ep 32: Batch #187 - Loss: 0.874447762966156\n",
      "Ep 32: Batch #188 - Loss: 0.9912296533584595\n",
      "Ep 32: Batch #189 - Loss: 0.5894905924797058\n",
      "Ep 32: Batch #190 - Loss: 0.6255528926849365\n",
      "Ep 32: Batch #191 - Loss: 0.814613401889801\n",
      "Ep 32: Batch #192 - Loss: 0.5721901655197144\n",
      "Ep 32: Batch #193 - Loss: 0.6297252178192139\n",
      "Ep 32: Batch #194 - Loss: 0.5487179756164551\n",
      "Ep 32: Batch #195 - Loss: 0.7949653267860413\n",
      "Ep 32: Batch #196 - Loss: 0.694187581539154\n",
      "Ep 32: Batch #197 - Loss: 0.7031041979789734\n",
      "Ep 32: Batch #198 - Loss: 0.5349141359329224\n",
      "Ep 32: Batch #199 - Loss: 0.647860050201416\n",
      "Ep 33: Batch #0 - Loss: 0.6505430340766907\n",
      "Ep 33: Batch #1 - Loss: 0.7157576084136963\n",
      "Ep 33: Batch #2 - Loss: 0.8613054156303406\n",
      "Ep 33: Batch #3 - Loss: 0.7232023477554321\n",
      "Ep 33: Batch #4 - Loss: 0.6591195464134216\n",
      "Ep 33: Batch #5 - Loss: 0.5636850595474243\n",
      "Ep 33: Batch #6 - Loss: 0.7445458769798279\n",
      "Ep 33: Batch #7 - Loss: 0.5785470008850098\n",
      "Ep 33: Batch #8 - Loss: 0.5903896689414978\n",
      "Ep 33: Batch #9 - Loss: 1.098333477973938\n",
      "Ep 33: Batch #10 - Loss: 0.8195394277572632\n",
      "Ep 33: Batch #11 - Loss: 0.5447903275489807\n",
      "Ep 33: Batch #12 - Loss: 1.2219288349151611\n",
      "Ep 33: Batch #13 - Loss: 0.5727708339691162\n",
      "Ep 33: Batch #14 - Loss: 0.6027678847312927\n",
      "Ep 33: Batch #15 - Loss: 0.8745470643043518\n",
      "Ep 33: Batch #16 - Loss: 0.9549511075019836\n",
      "Ep 33: Batch #17 - Loss: 0.7310276627540588\n",
      "Ep 33: Batch #18 - Loss: 0.8084659576416016\n",
      "Ep 33: Batch #19 - Loss: 0.5655108690261841\n",
      "Ep 33: Batch #20 - Loss: 0.5481042265892029\n",
      "Ep 33: Batch #21 - Loss: 0.8625279068946838\n",
      "Ep 33: Batch #22 - Loss: 0.6140715479850769\n",
      "Ep 33: Batch #23 - Loss: 0.6033096313476562\n",
      "Ep 33: Batch #24 - Loss: 0.641523003578186\n",
      "Ep 33: Batch #25 - Loss: 0.6107412576675415\n",
      "Ep 33: Batch #26 - Loss: 0.5657731890678406\n",
      "Ep 33: Batch #27 - Loss: 1.1454870700836182\n",
      "Ep 33: Batch #28 - Loss: 0.693496823310852\n",
      "Ep 33: Batch #29 - Loss: 0.7593905925750732\n",
      "Ep 33: Batch #30 - Loss: 0.8685061931610107\n",
      "Ep 33: Batch #31 - Loss: 0.563030481338501\n",
      "Ep 33: Batch #32 - Loss: 0.5837921500205994\n",
      "Ep 33: Batch #33 - Loss: 0.6702396273612976\n",
      "Ep 33: Batch #34 - Loss: 0.6462046504020691\n",
      "Ep 33: Batch #35 - Loss: 0.7277567386627197\n",
      "Ep 33: Batch #36 - Loss: 0.5840660929679871\n",
      "Ep 33: Batch #37 - Loss: 0.9248250126838684\n",
      "Ep 33: Batch #38 - Loss: 0.5742427110671997\n",
      "Ep 33: Batch #39 - Loss: 0.686682939529419\n",
      "Ep 33: Batch #40 - Loss: 0.6063439249992371\n",
      "Ep 33: Batch #41 - Loss: 0.6222451329231262\n",
      "Ep 33: Batch #42 - Loss: 0.5718424916267395\n",
      "Ep 33: Batch #43 - Loss: 0.6350692510604858\n",
      "Ep 33: Batch #44 - Loss: 0.6177929639816284\n",
      "Ep 33: Batch #45 - Loss: 0.5295488238334656\n",
      "Ep 33: Batch #46 - Loss: 0.6977806091308594\n",
      "Ep 33: Batch #47 - Loss: 0.8063415288925171\n",
      "Ep 33: Batch #48 - Loss: 1.042173981666565\n",
      "Ep 33: Batch #49 - Loss: 0.8144004940986633\n",
      "Ep 33: Batch #50 - Loss: 0.5735341906547546\n",
      "Ep 33: Batch #51 - Loss: 0.8195671439170837\n",
      "Ep 33: Batch #52 - Loss: 0.6786211729049683\n",
      "Ep 33: Batch #53 - Loss: 0.7174798250198364\n",
      "Ep 33: Batch #54 - Loss: 0.5820797085762024\n",
      "Ep 33: Batch #55 - Loss: 0.6109596490859985\n",
      "Ep 33: Batch #56 - Loss: 0.8681739568710327\n",
      "Ep 33: Batch #57 - Loss: 0.6846349835395813\n",
      "Ep 33: Batch #58 - Loss: 0.831244170665741\n",
      "Ep 33: Batch #59 - Loss: 0.5648075342178345\n",
      "Ep 33: Batch #60 - Loss: 1.014769434928894\n",
      "Ep 33: Batch #61 - Loss: 0.5351868867874146\n",
      "Ep 33: Batch #62 - Loss: 0.5772568583488464\n",
      "Ep 33: Batch #63 - Loss: 0.7909671068191528\n",
      "Ep 33: Batch #64 - Loss: 8.623783111572266\n",
      "Ep 33: Batch #65 - Loss: 0.5261409282684326\n",
      "Ep 33: Batch #66 - Loss: 0.6671826243400574\n",
      "Ep 33: Batch #67 - Loss: 0.7779260873794556\n",
      "Ep 33: Batch #68 - Loss: 0.719614565372467\n",
      "Ep 33: Batch #69 - Loss: 0.5932230353355408\n",
      "Ep 33: Batch #70 - Loss: 0.620276689529419\n",
      "Ep 33: Batch #71 - Loss: 0.5389875173568726\n",
      "Ep 33: Batch #72 - Loss: 0.6646782159805298\n",
      "Ep 33: Batch #73 - Loss: 0.7302277684211731\n",
      "Ep 33: Batch #74 - Loss: 0.5817117094993591\n",
      "Ep 33: Batch #75 - Loss: 0.6707314848899841\n",
      "Ep 33: Batch #76 - Loss: 0.9327020645141602\n",
      "Ep 33: Batch #77 - Loss: 0.5791571140289307\n",
      "Ep 33: Batch #78 - Loss: 0.927419900894165\n",
      "Ep 33: Batch #79 - Loss: 0.5285112261772156\n",
      "Ep 33: Batch #80 - Loss: 0.6957355737686157\n",
      "Ep 33: Batch #81 - Loss: 1.5279781818389893\n",
      "Ep 33: Batch #82 - Loss: 0.7524168491363525\n",
      "Ep 33: Batch #83 - Loss: 1.3365708589553833\n",
      "Ep 33: Batch #84 - Loss: 0.5798004865646362\n",
      "Ep 33: Batch #85 - Loss: 0.7940042018890381\n",
      "Ep 33: Batch #86 - Loss: 0.5504626631736755\n",
      "Ep 33: Batch #87 - Loss: 0.5747747421264648\n",
      "Ep 33: Batch #88 - Loss: 0.6585127711296082\n",
      "Ep 33: Batch #89 - Loss: 0.7359597682952881\n",
      "Ep 33: Batch #90 - Loss: 0.8999120593070984\n",
      "Ep 33: Batch #91 - Loss: 0.6492672562599182\n",
      "Ep 33: Batch #92 - Loss: 0.7424026727676392\n",
      "Ep 33: Batch #93 - Loss: 0.7872243523597717\n",
      "Ep 33: Batch #94 - Loss: 0.7643088698387146\n",
      "Ep 33: Batch #95 - Loss: 0.7611646056175232\n",
      "Ep 33: Batch #96 - Loss: 0.7613207101821899\n",
      "Ep 33: Batch #97 - Loss: 0.5864204168319702\n",
      "Ep 33: Batch #98 - Loss: 0.5811265707015991\n",
      "Ep 33: Batch #99 - Loss: 0.8023081421852112\n",
      "Ep 33: Batch #100 - Loss: 0.5597633123397827\n",
      "Ep 33: Batch #101 - Loss: 0.8621184229850769\n",
      "Ep 33: Batch #102 - Loss: 0.6152135729789734\n",
      "Ep 33: Batch #103 - Loss: 0.6402550935745239\n",
      "Ep 33: Batch #104 - Loss: 0.662533164024353\n",
      "Ep 33: Batch #105 - Loss: 0.8172200918197632\n",
      "Ep 33: Batch #106 - Loss: 0.6273742318153381\n",
      "Ep 33: Batch #107 - Loss: 0.6141014695167542\n",
      "Ep 33: Batch #108 - Loss: 0.9026408195495605\n",
      "Ep 33: Batch #109 - Loss: 0.6287142634391785\n",
      "Ep 33: Batch #110 - Loss: 0.7295408844947815\n",
      "Ep 33: Batch #111 - Loss: 1.0456146001815796\n",
      "Ep 33: Batch #112 - Loss: 0.8073257207870483\n",
      "Ep 33: Batch #113 - Loss: 0.6602063775062561\n",
      "Ep 33: Batch #114 - Loss: 0.7304084300994873\n",
      "Ep 33: Batch #115 - Loss: 0.9060181379318237\n",
      "Ep 33: Batch #116 - Loss: 0.5251938104629517\n",
      "Ep 33: Batch #117 - Loss: 0.683479368686676\n",
      "Ep 33: Batch #118 - Loss: 0.45856815576553345\n",
      "Model saved in file: ./weights_autoencoder_sigmoid/model_e33b118_1516648796.0525496.ckpt\n",
      "Ep 33: Batch #119 - Loss: 0.8073374629020691\n",
      "Ep 33: Batch #120 - Loss: 0.662238597869873\n",
      "Ep 33: Batch #121 - Loss: 0.5652860403060913\n",
      "Ep 33: Batch #122 - Loss: 0.7135917544364929\n",
      "Ep 33: Batch #123 - Loss: 0.7214604616165161\n",
      "Ep 33: Batch #124 - Loss: 0.5575133562088013\n",
      "Ep 33: Batch #125 - Loss: 2.467405080795288\n",
      "Ep 33: Batch #126 - Loss: 0.9997005462646484\n",
      "Ep 33: Batch #127 - Loss: 0.5844776034355164\n",
      "Ep 33: Batch #128 - Loss: 0.8838793039321899\n",
      "Ep 33: Batch #129 - Loss: 0.680609941482544\n",
      "Ep 33: Batch #130 - Loss: 0.5982661247253418\n",
      "Ep 33: Batch #131 - Loss: 0.8065543174743652\n",
      "Ep 33: Batch #132 - Loss: 0.6858505606651306\n",
      "Ep 33: Batch #133 - Loss: 0.6693118214607239\n",
      "Ep 33: Batch #134 - Loss: 0.6390909552574158\n",
      "Ep 33: Batch #135 - Loss: 0.8253687024116516\n",
      "Ep 33: Batch #136 - Loss: 1.041824460029602\n",
      "Ep 33: Batch #137 - Loss: 0.7553534507751465\n",
      "Ep 33: Batch #138 - Loss: 0.9004325866699219\n",
      "Ep 33: Batch #139 - Loss: 0.6836908459663391\n",
      "Ep 33: Batch #140 - Loss: 0.8479307889938354\n",
      "Ep 33: Batch #141 - Loss: 1.1334984302520752\n",
      "Ep 33: Batch #142 - Loss: 0.6724265813827515\n",
      "Ep 33: Batch #143 - Loss: 0.7714574337005615\n",
      "Ep 33: Batch #144 - Loss: 0.6124323010444641\n",
      "Ep 33: Batch #145 - Loss: 0.5994162559509277\n",
      "Ep 33: Batch #146 - Loss: 0.7068579792976379\n",
      "Ep 33: Batch #147 - Loss: 0.671657145023346\n",
      "Ep 33: Batch #148 - Loss: 0.7602369785308838\n",
      "Ep 33: Batch #149 - Loss: 0.635926365852356\n",
      "Ep 33: Batch #150 - Loss: 0.7225077152252197\n",
      "Ep 33: Batch #151 - Loss: 0.6316736340522766\n",
      "Ep 33: Batch #152 - Loss: 0.6100704669952393\n",
      "Ep 33: Batch #153 - Loss: 0.8332571387290955\n",
      "Ep 33: Batch #154 - Loss: 0.6349115371704102\n",
      "Ep 33: Batch #155 - Loss: 0.6929651498794556\n",
      "Ep 33: Batch #156 - Loss: 0.7972946166992188\n",
      "Ep 33: Batch #157 - Loss: 0.6176824569702148\n",
      "Ep 33: Batch #158 - Loss: 0.7184934020042419\n",
      "Ep 33: Batch #159 - Loss: 0.6077216267585754\n",
      "Ep 33: Batch #160 - Loss: 0.7044249176979065\n",
      "Ep 33: Batch #161 - Loss: 0.6711124777793884\n",
      "Ep 33: Batch #162 - Loss: 0.7198883295059204\n",
      "Ep 33: Batch #163 - Loss: 0.761715292930603\n",
      "Ep 33: Batch #164 - Loss: 0.6501755714416504\n",
      "Ep 33: Batch #165 - Loss: 1.3448765277862549\n",
      "Ep 33: Batch #166 - Loss: 0.5352615714073181\n",
      "Ep 33: Batch #167 - Loss: 0.7542325854301453\n",
      "Ep 33: Batch #168 - Loss: 0.693581759929657\n",
      "Ep 33: Batch #169 - Loss: 0.6712960004806519\n",
      "Ep 33: Batch #170 - Loss: 0.6316163539886475\n",
      "Ep 33: Batch #171 - Loss: 0.6424100995063782\n",
      "Ep 33: Batch #172 - Loss: 0.534923255443573\n",
      "Ep 33: Batch #173 - Loss: 0.9336155652999878\n",
      "Ep 33: Batch #174 - Loss: 0.4970223605632782\n",
      "Ep 33: Batch #175 - Loss: 0.6423220038414001\n",
      "Ep 33: Batch #176 - Loss: 0.8992946743965149\n",
      "Ep 33: Batch #177 - Loss: 0.6565138101577759\n",
      "Ep 33: Batch #178 - Loss: 0.6269981861114502\n",
      "Ep 33: Batch #179 - Loss: 0.7518101334571838\n",
      "Ep 33: Batch #180 - Loss: 0.6556339859962463\n",
      "Ep 33: Batch #181 - Loss: 0.8040906190872192\n",
      "Ep 33: Batch #182 - Loss: 0.6276463866233826\n",
      "Ep 33: Batch #183 - Loss: 0.6095784902572632\n",
      "Ep 33: Batch #184 - Loss: 0.9228392839431763\n",
      "Ep 33: Batch #185 - Loss: 0.6341603398323059\n",
      "Ep 33: Batch #186 - Loss: 0.7621865272521973\n",
      "Ep 33: Batch #187 - Loss: 0.8744859099388123\n",
      "Ep 33: Batch #188 - Loss: 0.9895563125610352\n",
      "Ep 33: Batch #189 - Loss: 0.5893456935882568\n",
      "Ep 33: Batch #190 - Loss: 0.6253383159637451\n",
      "Ep 33: Batch #191 - Loss: 0.8138876557350159\n",
      "Ep 33: Batch #192 - Loss: 0.5722100138664246\n",
      "Ep 33: Batch #193 - Loss: 0.6297840476036072\n",
      "Ep 33: Batch #194 - Loss: 0.5483918190002441\n",
      "Ep 33: Batch #195 - Loss: 0.7945874929428101\n",
      "Ep 33: Batch #196 - Loss: 0.693966805934906\n",
      "Ep 33: Batch #197 - Loss: 0.7030132412910461\n",
      "Ep 33: Batch #198 - Loss: 0.5347711443901062\n",
      "Ep 33: Batch #199 - Loss: 0.6476433277130127\n",
      "Ep 34: Batch #0 - Loss: 0.6504815220832825\n",
      "Ep 34: Batch #1 - Loss: 0.7154266834259033\n",
      "Ep 34: Batch #2 - Loss: 0.8611540794372559\n",
      "Ep 34: Batch #3 - Loss: 0.723230242729187\n",
      "Ep 34: Batch #4 - Loss: 0.6591247916221619\n",
      "Ep 34: Batch #5 - Loss: 0.5634239315986633\n",
      "Ep 34: Batch #6 - Loss: 0.7441682815551758\n",
      "Ep 34: Batch #7 - Loss: 0.5781757235527039\n",
      "Ep 34: Batch #8 - Loss: 0.590285062789917\n",
      "Ep 34: Batch #9 - Loss: 1.0981831550598145\n",
      "Ep 34: Batch #10 - Loss: 0.8186689615249634\n",
      "Ep 34: Batch #11 - Loss: 0.5445724129676819\n",
      "Ep 34: Batch #12 - Loss: 1.2208967208862305\n",
      "Ep 34: Batch #13 - Loss: 0.572655439376831\n",
      "Ep 34: Batch #14 - Loss: 0.6025500297546387\n",
      "Ep 34: Batch #15 - Loss: 0.8726282119750977\n",
      "Ep 34: Batch #16 - Loss: 0.9546807408332825\n",
      "Ep 34: Batch #17 - Loss: 0.7310439944267273\n",
      "Ep 34: Batch #18 - Loss: 0.8085780143737793\n",
      "Ep 34: Batch #19 - Loss: 0.565317690372467\n",
      "Ep 34: Batch #20 - Loss: 0.5479574799537659\n",
      "Ep 34: Batch #21 - Loss: 0.859836995601654\n",
      "Ep 34: Batch #22 - Loss: 0.6136285066604614\n",
      "Ep 34: Batch #23 - Loss: 0.602817714214325\n",
      "Ep 34: Batch #24 - Loss: 0.6414534449577332\n",
      "Ep 34: Batch #25 - Loss: 0.6102845668792725\n",
      "Ep 34: Batch #26 - Loss: 0.5649780631065369\n",
      "Ep 34: Batch #27 - Loss: 1.1451860666275024\n",
      "Ep 34: Batch #28 - Loss: 0.6930796504020691\n",
      "Ep 34: Batch #29 - Loss: 0.7594379782676697\n",
      "Ep 34: Batch #30 - Loss: 0.865976095199585\n",
      "Ep 34: Batch #31 - Loss: 0.5628830790519714\n",
      "Ep 34: Batch #32 - Loss: 0.5835819244384766\n",
      "Ep 34: Batch #33 - Loss: 0.6699304580688477\n",
      "Ep 34: Batch #34 - Loss: 0.6456993222236633\n",
      "Ep 34: Batch #35 - Loss: 0.7276715040206909\n",
      "Ep 34: Batch #36 - Loss: 0.5841996669769287\n",
      "Ep 34: Batch #37 - Loss: 0.9247556924819946\n",
      "Ep 34: Batch #38 - Loss: 0.5738810300827026\n",
      "Ep 34: Batch #39 - Loss: 0.6864166259765625\n",
      "Ep 34: Batch #40 - Loss: 0.6060121655464172\n",
      "Ep 34: Batch #41 - Loss: 0.6221477389335632\n",
      "Ep 34: Batch #42 - Loss: 0.5716199278831482\n",
      "Ep 34: Batch #43 - Loss: 0.6348326802253723\n",
      "Ep 34: Batch #44 - Loss: 0.6174200773239136\n",
      "Ep 34: Batch #45 - Loss: 0.5293515920639038\n",
      "Ep 34: Batch #46 - Loss: 0.6977176666259766\n",
      "Ep 34: Batch #47 - Loss: 0.8062508702278137\n",
      "Ep 34: Batch #48 - Loss: 1.041898488998413\n",
      "Ep 34: Batch #49 - Loss: 0.8146108984947205\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 34: Batch #50 - Loss: 0.5736244916915894\n",
      "Ep 34: Batch #51 - Loss: 0.8196475505828857\n",
      "Ep 34: Batch #52 - Loss: 0.6785956621170044\n",
      "Ep 34: Batch #53 - Loss: 0.7175001502037048\n",
      "Ep 34: Batch #54 - Loss: 0.5817022323608398\n",
      "Ep 34: Batch #55 - Loss: 0.6106444597244263\n",
      "Ep 34: Batch #56 - Loss: 0.8677186965942383\n",
      "Ep 34: Batch #57 - Loss: 0.6842479109764099\n",
      "Ep 34: Batch #58 - Loss: 0.8308454155921936\n",
      "Ep 34: Batch #59 - Loss: 0.564704179763794\n",
      "Ep 34: Batch #60 - Loss: 1.0149612426757812\n",
      "Ep 34: Batch #61 - Loss: 0.535193145275116\n",
      "Ep 34: Batch #62 - Loss: 0.5771156549453735\n",
      "Ep 34: Batch #63 - Loss: 0.7907288074493408\n",
      "Ep 34: Batch #64 - Loss: 8.604825019836426\n",
      "Ep 34: Batch #65 - Loss: 0.526138186454773\n",
      "Ep 34: Batch #66 - Loss: 0.6669389605522156\n",
      "Ep 34: Batch #67 - Loss: 0.7776234149932861\n",
      "Ep 34: Batch #68 - Loss: 0.7194526791572571\n",
      "Ep 34: Batch #69 - Loss: 0.593053936958313\n",
      "Ep 34: Batch #70 - Loss: 0.6202734112739563\n",
      "Ep 34: Batch #71 - Loss: 0.5389402508735657\n",
      "Ep 34: Batch #72 - Loss: 0.6651251912117004\n",
      "Ep 34: Batch #73 - Loss: 0.7299201488494873\n",
      "Ep 34: Batch #74 - Loss: 0.5815463662147522\n",
      "Ep 34: Batch #75 - Loss: 0.6707702279090881\n",
      "Ep 34: Batch #76 - Loss: 0.9323911666870117\n",
      "Ep 34: Batch #77 - Loss: 0.5793151259422302\n",
      "Ep 34: Batch #78 - Loss: 0.9267274141311646\n",
      "Ep 34: Batch #79 - Loss: 0.528378427028656\n",
      "Ep 34: Batch #80 - Loss: 0.6956047415733337\n",
      "Ep 34: Batch #81 - Loss: 1.5277866125106812\n",
      "Ep 34: Batch #82 - Loss: 0.752477765083313\n",
      "Ep 34: Batch #83 - Loss: 1.3325749635696411\n",
      "Ep 34: Batch #84 - Loss: 0.5799176096916199\n",
      "Ep 34: Batch #85 - Loss: 0.7936940789222717\n",
      "Ep 34: Batch #86 - Loss: 0.550326943397522\n",
      "Ep 34: Batch #87 - Loss: 0.5748670697212219\n",
      "Ep 34: Batch #88 - Loss: 0.6584985852241516\n",
      "Ep 34: Batch #89 - Loss: 0.7355408668518066\n",
      "Ep 34: Batch #90 - Loss: 0.9000999331474304\n",
      "Ep 34: Batch #91 - Loss: 0.6493469476699829\n",
      "Ep 34: Batch #92 - Loss: 0.7420213222503662\n",
      "Ep 34: Batch #93 - Loss: 0.787002444267273\n",
      "Ep 34: Batch #94 - Loss: 0.7636156678199768\n",
      "Ep 34: Batch #95 - Loss: 0.7610870003700256\n",
      "Ep 34: Batch #96 - Loss: 0.7613232135772705\n",
      "Ep 34: Batch #97 - Loss: 0.5867665410041809\n",
      "Ep 34: Batch #98 - Loss: 0.581023097038269\n",
      "Ep 34: Batch #99 - Loss: 0.8024821281433105\n",
      "Ep 34: Batch #100 - Loss: 0.559563398361206\n",
      "Ep 34: Batch #101 - Loss: 0.8624317049980164\n",
      "Ep 34: Batch #102 - Loss: 0.6151605844497681\n",
      "Ep 34: Batch #103 - Loss: 0.6401176452636719\n",
      "Ep 34: Batch #104 - Loss: 0.6627253293991089\n",
      "Ep 34: Batch #105 - Loss: 0.8174727559089661\n",
      "Ep 34: Batch #106 - Loss: 0.6274784803390503\n",
      "Ep 34: Batch #107 - Loss: 0.6142793893814087\n",
      "Ep 34: Batch #108 - Loss: 0.9026620984077454\n",
      "Ep 34: Batch #109 - Loss: 0.6282783150672913\n",
      "Ep 34: Batch #110 - Loss: 0.7292559146881104\n",
      "Ep 34: Batch #111 - Loss: 1.0456355810165405\n",
      "Ep 34: Batch #112 - Loss: 0.8066624402999878\n",
      "Ep 34: Batch #113 - Loss: 0.6601688265800476\n",
      "Ep 34: Batch #114 - Loss: 0.7304570078849792\n",
      "Ep 34: Batch #115 - Loss: 0.906230628490448\n",
      "Ep 34: Batch #116 - Loss: 0.5249601006507874\n",
      "Ep 34: Batch #117 - Loss: 0.6831177473068237\n",
      "Ep 34: Batch #118 - Loss: 0.4583355188369751\n",
      "Model saved in file: ./weights_autoencoder_sigmoid/model_e34b118_1516648796.1917255.ckpt\n",
      "Ep 34: Batch #119 - Loss: 0.8071826100349426\n",
      "Ep 34: Batch #120 - Loss: 0.6618502736091614\n",
      "Ep 34: Batch #121 - Loss: 0.565056324005127\n",
      "Ep 34: Batch #122 - Loss: 0.7134560942649841\n",
      "Ep 34: Batch #123 - Loss: 0.7212384939193726\n",
      "Ep 34: Batch #124 - Loss: 0.5575303435325623\n",
      "Ep 34: Batch #125 - Loss: 2.467534065246582\n",
      "Ep 34: Batch #126 - Loss: 0.9992073178291321\n",
      "Ep 34: Batch #127 - Loss: 0.5846714973449707\n",
      "Ep 34: Batch #128 - Loss: 0.8839285373687744\n",
      "Ep 34: Batch #129 - Loss: 0.680316150188446\n",
      "Ep 34: Batch #130 - Loss: 0.5978004336357117\n",
      "Ep 34: Batch #131 - Loss: 0.8064159154891968\n",
      "Ep 34: Batch #132 - Loss: 0.6857436299324036\n",
      "Ep 34: Batch #133 - Loss: 0.6692048907279968\n",
      "Ep 34: Batch #134 - Loss: 0.6387203931808472\n",
      "Ep 34: Batch #135 - Loss: 0.8245671391487122\n",
      "Ep 34: Batch #136 - Loss: 1.0420079231262207\n",
      "Ep 34: Batch #137 - Loss: 0.755448579788208\n",
      "Ep 34: Batch #138 - Loss: 0.9004785418510437\n",
      "Ep 34: Batch #139 - Loss: 0.681630551815033\n",
      "Ep 34: Batch #140 - Loss: 0.8475954532623291\n",
      "Ep 34: Batch #141 - Loss: 1.1334247589111328\n",
      "Ep 34: Batch #142 - Loss: 0.6722500324249268\n",
      "Ep 34: Batch #143 - Loss: 0.7717896103858948\n",
      "Ep 34: Batch #144 - Loss: 0.6125868558883667\n",
      "Ep 34: Batch #145 - Loss: 0.5992826819419861\n",
      "Ep 34: Batch #146 - Loss: 0.706903338432312\n",
      "Ep 34: Batch #147 - Loss: 0.6714139580726624\n",
      "Ep 34: Batch #148 - Loss: 0.7592371702194214\n",
      "Ep 34: Batch #149 - Loss: 0.6347125172615051\n",
      "Ep 34: Batch #150 - Loss: 0.7223213315010071\n",
      "Ep 34: Batch #151 - Loss: 0.6312287449836731\n",
      "Ep 34: Batch #152 - Loss: 0.6100072264671326\n",
      "Ep 34: Batch #153 - Loss: 0.8327183723449707\n",
      "Ep 34: Batch #154 - Loss: 0.6347801685333252\n",
      "Ep 34: Batch #155 - Loss: 0.693134605884552\n",
      "Ep 34: Batch #156 - Loss: 0.7962002158164978\n",
      "Ep 34: Batch #157 - Loss: 0.6172714233398438\n",
      "Ep 34: Batch #158 - Loss: 0.7183921933174133\n",
      "Ep 34: Batch #159 - Loss: 0.6070972084999084\n",
      "Ep 34: Batch #160 - Loss: 0.7036054730415344\n",
      "Ep 34: Batch #161 - Loss: 0.6709575057029724\n",
      "Ep 34: Batch #162 - Loss: 0.7198903560638428\n",
      "Ep 34: Batch #163 - Loss: 0.7614805698394775\n",
      "Ep 34: Batch #164 - Loss: 0.6500247120857239\n",
      "Ep 34: Batch #165 - Loss: 1.3447422981262207\n",
      "Ep 34: Batch #166 - Loss: 0.5350788235664368\n",
      "Ep 34: Batch #167 - Loss: 0.7518330216407776\n",
      "Ep 34: Batch #168 - Loss: 0.6933177709579468\n",
      "Ep 34: Batch #169 - Loss: 0.6708555817604065\n",
      "Ep 34: Batch #170 - Loss: 0.6311314105987549\n",
      "Ep 34: Batch #171 - Loss: 0.642400324344635\n",
      "Ep 34: Batch #172 - Loss: 0.5351012945175171\n",
      "Ep 34: Batch #173 - Loss: 0.9332570433616638\n",
      "Ep 34: Batch #174 - Loss: 0.4970437288284302\n",
      "Ep 34: Batch #175 - Loss: 0.6415479183197021\n",
      "Ep 34: Batch #176 - Loss: 0.8991230130195618\n",
      "Ep 34: Batch #177 - Loss: 0.6560710668563843\n",
      "Ep 34: Batch #178 - Loss: 0.6265445947647095\n",
      "Ep 34: Batch #179 - Loss: 0.7518898844718933\n",
      "Ep 34: Batch #180 - Loss: 0.6554401516914368\n",
      "Ep 34: Batch #181 - Loss: 0.8041418790817261\n",
      "Ep 34: Batch #182 - Loss: 0.6271922588348389\n",
      "Ep 34: Batch #183 - Loss: 0.6093827486038208\n",
      "Ep 34: Batch #184 - Loss: 0.922736406326294\n",
      "Ep 34: Batch #185 - Loss: 0.6343661546707153\n",
      "Ep 34: Batch #186 - Loss: 0.7619856595993042\n",
      "Ep 34: Batch #187 - Loss: 0.8737057447433472\n",
      "Ep 34: Batch #188 - Loss: 0.9876373410224915\n",
      "Ep 34: Batch #189 - Loss: 0.5892087817192078\n",
      "Ep 34: Batch #190 - Loss: 0.6252817511558533\n",
      "Ep 34: Batch #191 - Loss: 0.813287079334259\n",
      "Ep 34: Batch #192 - Loss: 0.572053074836731\n",
      "Ep 34: Batch #193 - Loss: 0.629777193069458\n",
      "Ep 34: Batch #194 - Loss: 0.5481199622154236\n",
      "Ep 34: Batch #195 - Loss: 0.7948586940765381\n",
      "Ep 34: Batch #196 - Loss: 0.6939234137535095\n",
      "Ep 34: Batch #197 - Loss: 0.7029577493667603\n",
      "Ep 34: Batch #198 - Loss: 0.5348565578460693\n",
      "Ep 34: Batch #199 - Loss: 0.6474356651306152\n",
      "Ep 35: Batch #0 - Loss: 0.6504882574081421\n",
      "Ep 35: Batch #1 - Loss: 0.7152361273765564\n",
      "Ep 35: Batch #2 - Loss: 0.8609020709991455\n",
      "Ep 35: Batch #3 - Loss: 0.7236894965171814\n",
      "Ep 35: Batch #4 - Loss: 0.6589232087135315\n",
      "Ep 35: Batch #5 - Loss: 0.5630162954330444\n",
      "Ep 35: Batch #6 - Loss: 0.7437043190002441\n",
      "Ep 35: Batch #7 - Loss: 0.5778558850288391\n",
      "Ep 35: Batch #8 - Loss: 0.5901965498924255\n",
      "Ep 35: Batch #9 - Loss: 1.0981789827346802\n",
      "Ep 35: Batch #10 - Loss: 0.8177212476730347\n",
      "Ep 35: Batch #11 - Loss: 0.5445147752761841\n",
      "Ep 35: Batch #12 - Loss: 1.2198741436004639\n",
      "Ep 35: Batch #13 - Loss: 0.5725277066230774\n",
      "Ep 35: Batch #14 - Loss: 0.6024070978164673\n",
      "Ep 35: Batch #15 - Loss: 0.8708505630493164\n",
      "Ep 35: Batch #16 - Loss: 0.9547972679138184\n",
      "Ep 35: Batch #17 - Loss: 0.7311006188392639\n",
      "Ep 35: Batch #18 - Loss: 0.8086778521537781\n",
      "Ep 35: Batch #19 - Loss: 0.5650839805603027\n",
      "Ep 35: Batch #20 - Loss: 0.547770619392395\n",
      "Ep 35: Batch #21 - Loss: 0.8572500348091125\n",
      "Ep 35: Batch #22 - Loss: 0.6132535934448242\n",
      "Ep 35: Batch #23 - Loss: 0.6021978855133057\n",
      "Ep 35: Batch #24 - Loss: 0.6412352919578552\n",
      "Ep 35: Batch #25 - Loss: 0.6098163723945618\n",
      "Ep 35: Batch #26 - Loss: 0.5642052292823792\n",
      "Ep 35: Batch #27 - Loss: 1.144982099533081\n",
      "Ep 35: Batch #28 - Loss: 0.6926296949386597\n",
      "Ep 35: Batch #29 - Loss: 0.759405255317688\n",
      "Ep 35: Batch #30 - Loss: 0.8630805015563965\n",
      "Ep 35: Batch #31 - Loss: 0.5628156661987305\n",
      "Ep 35: Batch #32 - Loss: 0.5833179354667664\n",
      "Ep 35: Batch #33 - Loss: 0.6696354150772095\n",
      "Ep 35: Batch #34 - Loss: 0.6452838182449341\n",
      "Ep 35: Batch #35 - Loss: 0.7271859049797058\n",
      "Ep 35: Batch #36 - Loss: 0.5839298963546753\n",
      "Ep 35: Batch #37 - Loss: 0.9245873093605042\n",
      "Ep 35: Batch #38 - Loss: 0.5738137364387512\n",
      "Ep 35: Batch #39 - Loss: 0.6865492463111877\n",
      "Ep 35: Batch #40 - Loss: 0.6057661175727844\n",
      "Ep 35: Batch #41 - Loss: 0.6218428611755371\n",
      "Ep 35: Batch #42 - Loss: 0.5715693831443787\n",
      "Ep 35: Batch #43 - Loss: 0.6344946622848511\n",
      "Ep 35: Batch #44 - Loss: 0.6171056032180786\n",
      "Ep 35: Batch #45 - Loss: 0.5290793776512146\n",
      "Ep 35: Batch #46 - Loss: 0.697715163230896\n",
      "Ep 35: Batch #47 - Loss: 0.8062494993209839\n",
      "Ep 35: Batch #48 - Loss: 1.0416792631149292\n",
      "Ep 35: Batch #49 - Loss: 0.8144015669822693\n",
      "Ep 35: Batch #50 - Loss: 0.5736562013626099\n",
      "Ep 35: Batch #51 - Loss: 0.8195796012878418\n",
      "Ep 35: Batch #52 - Loss: 0.6785711646080017\n",
      "Ep 35: Batch #53 - Loss: 0.7175280451774597\n",
      "Ep 35: Batch #54 - Loss: 0.5815054774284363\n",
      "Ep 35: Batch #55 - Loss: 0.6104460954666138\n",
      "Ep 35: Batch #56 - Loss: 0.8668827414512634\n",
      "Ep 35: Batch #57 - Loss: 0.6840275526046753\n",
      "Ep 35: Batch #58 - Loss: 0.8306804299354553\n",
      "Ep 35: Batch #59 - Loss: 0.564353346824646\n",
      "Ep 35: Batch #60 - Loss: 1.0146249532699585\n",
      "Ep 35: Batch #61 - Loss: 0.5353312492370605\n",
      "Ep 35: Batch #62 - Loss: 0.5770319700241089\n",
      "Ep 35: Batch #63 - Loss: 0.790309488773346\n",
      "Ep 35: Batch #64 - Loss: 8.628405570983887\n",
      "Ep 35: Batch #65 - Loss: 0.5259455442428589\n",
      "Ep 35: Batch #66 - Loss: 0.6667196750640869\n",
      "Ep 35: Batch #67 - Loss: 0.7777823209762573\n",
      "Ep 35: Batch #68 - Loss: 0.7186880707740784\n",
      "Ep 35: Batch #69 - Loss: 0.5930128693580627\n",
      "Ep 35: Batch #70 - Loss: 0.618999719619751\n",
      "Ep 35: Batch #71 - Loss: 0.538824737071991\n",
      "Ep 35: Batch #72 - Loss: 0.6657842397689819\n",
      "Ep 35: Batch #73 - Loss: 0.7299637794494629\n",
      "Ep 35: Batch #74 - Loss: 0.583419680595398\n",
      "Ep 35: Batch #75 - Loss: 0.6708363890647888\n",
      "Ep 35: Batch #76 - Loss: 0.9341810941696167\n",
      "Ep 35: Batch #77 - Loss: 0.5792520642280579\n",
      "Ep 35: Batch #78 - Loss: 0.9264293909072876\n",
      "Ep 35: Batch #79 - Loss: 0.5283429622650146\n",
      "Ep 35: Batch #80 - Loss: 0.695899248123169\n",
      "Ep 35: Batch #81 - Loss: 1.5275686979293823\n",
      "Ep 35: Batch #82 - Loss: 0.753145158290863\n",
      "Ep 35: Batch #83 - Loss: 1.3272068500518799\n",
      "Ep 35: Batch #84 - Loss: 0.5795921087265015\n",
      "Ep 35: Batch #85 - Loss: 0.7952134013175964\n",
      "Ep 35: Batch #86 - Loss: 0.5502819418907166\n",
      "Ep 35: Batch #87 - Loss: 0.5741714239120483\n",
      "Ep 35: Batch #88 - Loss: 0.6581359505653381\n",
      "Ep 35: Batch #89 - Loss: 0.7349458336830139\n",
      "Ep 35: Batch #90 - Loss: 0.9003969430923462\n",
      "Ep 35: Batch #91 - Loss: 0.6492164731025696\n",
      "Ep 35: Batch #92 - Loss: 0.7407677173614502\n",
      "Ep 35: Batch #93 - Loss: 0.7868337035179138\n",
      "Ep 35: Batch #94 - Loss: 0.7627518773078918\n",
      "Ep 35: Batch #95 - Loss: 0.7614731192588806\n",
      "Ep 35: Batch #96 - Loss: 0.761154055595398\n",
      "Ep 35: Batch #97 - Loss: 0.5860974788665771\n",
      "Ep 35: Batch #98 - Loss: 0.5803683996200562\n",
      "Ep 35: Batch #99 - Loss: 0.8022470474243164\n",
      "Ep 35: Batch #100 - Loss: 0.5596192479133606\n",
      "Ep 35: Batch #101 - Loss: 0.8639442324638367\n",
      "Ep 35: Batch #102 - Loss: 0.6148476600646973\n",
      "Ep 35: Batch #103 - Loss: 0.6400117874145508\n",
      "Ep 35: Batch #104 - Loss: 0.662581205368042\n",
      "Ep 35: Batch #105 - Loss: 0.8167308568954468\n",
      "Ep 35: Batch #106 - Loss: 0.6276692748069763\n",
      "Ep 35: Batch #107 - Loss: 0.6141055226325989\n",
      "Ep 35: Batch #108 - Loss: 0.9024853706359863\n",
      "Ep 35: Batch #109 - Loss: 0.6285106539726257\n",
      "Ep 35: Batch #110 - Loss: 0.7286348342895508\n",
      "Ep 35: Batch #111 - Loss: 1.0451266765594482\n",
      "Ep 35: Batch #112 - Loss: 0.8053799271583557\n",
      "Ep 35: Batch #113 - Loss: 0.6604951620101929\n",
      "Ep 35: Batch #114 - Loss: 0.7306191921234131\n",
      "Ep 35: Batch #115 - Loss: 0.9064881801605225\n",
      "Ep 35: Batch #116 - Loss: 0.5247455835342407\n",
      "Ep 35: Batch #117 - Loss: 0.6826453804969788\n",
      "Ep 35: Batch #118 - Loss: 0.45801371335983276\n",
      "Model saved in file: ./weights_autoencoder_sigmoid/model_e35b118_1516648796.331018.ckpt\n",
      "Ep 35: Batch #119 - Loss: 0.8075286746025085\n",
      "Ep 35: Batch #120 - Loss: 0.6620951890945435\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 35: Batch #121 - Loss: 0.5648951530456543\n",
      "Ep 35: Batch #122 - Loss: 0.7129188776016235\n",
      "Ep 35: Batch #123 - Loss: 0.7209600806236267\n",
      "Ep 35: Batch #124 - Loss: 0.5574951767921448\n",
      "Ep 35: Batch #125 - Loss: 2.467907428741455\n",
      "Ep 35: Batch #126 - Loss: 0.9997725486755371\n",
      "Ep 35: Batch #127 - Loss: 0.5838828682899475\n",
      "Ep 35: Batch #128 - Loss: 0.8843713998794556\n",
      "Ep 35: Batch #129 - Loss: 0.679953932762146\n",
      "Ep 35: Batch #130 - Loss: 0.5978386998176575\n",
      "Ep 35: Batch #131 - Loss: 0.8067067265510559\n",
      "Ep 35: Batch #132 - Loss: 0.6856966018676758\n",
      "Ep 35: Batch #133 - Loss: 0.6695387363433838\n",
      "Ep 35: Batch #134 - Loss: 0.6388195157051086\n",
      "Ep 35: Batch #135 - Loss: 0.8245042562484741\n",
      "Ep 35: Batch #136 - Loss: 1.0414084196090698\n",
      "Ep 35: Batch #137 - Loss: 0.7549102306365967\n",
      "Ep 35: Batch #138 - Loss: 0.9009351134300232\n",
      "Ep 35: Batch #139 - Loss: 0.6814901828765869\n",
      "Ep 35: Batch #140 - Loss: 0.847485363483429\n",
      "Ep 35: Batch #141 - Loss: 1.1335176229476929\n",
      "Ep 35: Batch #142 - Loss: 0.6722122430801392\n",
      "Ep 35: Batch #143 - Loss: 0.7716355919837952\n",
      "Ep 35: Batch #144 - Loss: 0.6124935150146484\n",
      "Ep 35: Batch #145 - Loss: 0.5995230078697205\n",
      "Ep 35: Batch #146 - Loss: 0.7064473032951355\n",
      "Ep 35: Batch #147 - Loss: 0.6710255742073059\n",
      "Ep 35: Batch #148 - Loss: 0.7601615786552429\n",
      "Ep 35: Batch #149 - Loss: 0.6338058114051819\n",
      "Ep 35: Batch #150 - Loss: 0.722695529460907\n",
      "Ep 35: Batch #151 - Loss: 0.631208062171936\n",
      "Ep 35: Batch #152 - Loss: 0.6097552180290222\n",
      "Ep 35: Batch #153 - Loss: 0.8321533799171448\n",
      "Ep 35: Batch #154 - Loss: 0.6347477436065674\n",
      "Ep 35: Batch #155 - Loss: 0.6936441659927368\n",
      "Ep 35: Batch #156 - Loss: 0.7955015897750854\n",
      "Ep 35: Batch #157 - Loss: 0.6175966262817383\n",
      "Ep 35: Batch #158 - Loss: 0.7181292772293091\n",
      "Ep 35: Batch #159 - Loss: 0.6064953207969666\n",
      "Ep 35: Batch #160 - Loss: 0.7029577493667603\n",
      "Ep 35: Batch #161 - Loss: 0.6709920167922974\n",
      "Ep 35: Batch #162 - Loss: 0.7197150588035583\n",
      "Ep 35: Batch #163 - Loss: 0.7617442011833191\n",
      "Ep 35: Batch #164 - Loss: 0.6500312685966492\n",
      "Ep 35: Batch #165 - Loss: 1.344044804573059\n",
      "Ep 35: Batch #166 - Loss: 0.5350675582885742\n",
      "Ep 35: Batch #167 - Loss: 0.7495553493499756\n",
      "Ep 35: Batch #168 - Loss: 0.6933358311653137\n",
      "Ep 35: Batch #169 - Loss: 0.6711177825927734\n",
      "Ep 35: Batch #170 - Loss: 0.6308761239051819\n",
      "Ep 35: Batch #171 - Loss: 0.642219066619873\n",
      "Ep 35: Batch #172 - Loss: 0.5348693132400513\n",
      "Ep 35: Batch #173 - Loss: 0.932556688785553\n",
      "Ep 35: Batch #174 - Loss: 0.4969139099121094\n",
      "Ep 35: Batch #175 - Loss: 0.6410367488861084\n",
      "Ep 35: Batch #176 - Loss: 0.8987228870391846\n",
      "Ep 35: Batch #177 - Loss: 0.6554903388023376\n",
      "Ep 35: Batch #178 - Loss: 0.6263466477394104\n",
      "Ep 35: Batch #179 - Loss: 0.7515714764595032\n",
      "Ep 35: Batch #180 - Loss: 0.6548389196395874\n",
      "Ep 35: Batch #181 - Loss: 0.8040111660957336\n",
      "Ep 35: Batch #182 - Loss: 0.626679003238678\n",
      "Ep 35: Batch #183 - Loss: 0.6086819767951965\n",
      "Ep 35: Batch #184 - Loss: 0.9222351312637329\n",
      "Ep 35: Batch #185 - Loss: 0.634125292301178\n",
      "Ep 35: Batch #186 - Loss: 0.7619197368621826\n",
      "Ep 35: Batch #187 - Loss: 0.873518705368042\n",
      "Ep 35: Batch #188 - Loss: 0.9849127531051636\n",
      "Ep 35: Batch #189 - Loss: 0.5890445709228516\n",
      "Ep 35: Batch #190 - Loss: 0.6255461573600769\n",
      "Ep 35: Batch #191 - Loss: 0.8135405778884888\n",
      "Ep 35: Batch #192 - Loss: 0.5719485282897949\n",
      "Ep 35: Batch #193 - Loss: 0.6299877762794495\n",
      "Ep 35: Batch #194 - Loss: 0.5477904677391052\n",
      "Ep 35: Batch #195 - Loss: 0.7944429516792297\n",
      "Ep 35: Batch #196 - Loss: 0.6936972141265869\n",
      "Ep 35: Batch #197 - Loss: 0.7028357982635498\n",
      "Ep 35: Batch #198 - Loss: 0.5347365736961365\n",
      "Ep 35: Batch #199 - Loss: 0.6471949815750122\n",
      "Ep 36: Batch #0 - Loss: 0.650509238243103\n",
      "Ep 36: Batch #1 - Loss: 0.7154900431632996\n",
      "Ep 36: Batch #2 - Loss: 0.8612265586853027\n",
      "Ep 36: Batch #3 - Loss: 0.7236467003822327\n",
      "Ep 36: Batch #4 - Loss: 0.6589320302009583\n",
      "Ep 36: Batch #5 - Loss: 0.5626372694969177\n",
      "Ep 36: Batch #6 - Loss: 0.7431853413581848\n",
      "Ep 36: Batch #7 - Loss: 0.5778710842132568\n",
      "Ep 36: Batch #8 - Loss: 0.5902242660522461\n",
      "Ep 36: Batch #9 - Loss: 1.0979492664337158\n",
      "Ep 36: Batch #10 - Loss: 0.8169381618499756\n",
      "Ep 36: Batch #11 - Loss: 0.5445786714553833\n",
      "Ep 36: Batch #12 - Loss: 1.2190788984298706\n",
      "Ep 36: Batch #13 - Loss: 0.5724573135375977\n",
      "Ep 36: Batch #14 - Loss: 0.6022600531578064\n",
      "Ep 36: Batch #15 - Loss: 0.8699091076850891\n",
      "Ep 36: Batch #16 - Loss: 0.954599916934967\n",
      "Ep 36: Batch #17 - Loss: 0.7310493588447571\n",
      "Ep 36: Batch #18 - Loss: 0.8084545135498047\n",
      "Ep 36: Batch #19 - Loss: 0.5650711059570312\n",
      "Ep 36: Batch #20 - Loss: 0.5476169586181641\n",
      "Ep 36: Batch #21 - Loss: 0.8542605638504028\n",
      "Ep 36: Batch #22 - Loss: 0.613034188747406\n",
      "Ep 36: Batch #23 - Loss: 0.6024253368377686\n",
      "Ep 36: Batch #24 - Loss: 0.6409502029418945\n",
      "Ep 36: Batch #25 - Loss: 0.6097519397735596\n",
      "Ep 36: Batch #26 - Loss: 0.563677966594696\n",
      "Ep 36: Batch #27 - Loss: 1.1446999311447144\n",
      "Ep 36: Batch #28 - Loss: 0.6925502419471741\n",
      "Ep 36: Batch #29 - Loss: 0.7589247822761536\n",
      "Ep 36: Batch #30 - Loss: 0.8611672520637512\n",
      "Ep 36: Batch #31 - Loss: 0.5626108646392822\n",
      "Ep 36: Batch #32 - Loss: 0.5828933715820312\n",
      "Ep 36: Batch #33 - Loss: 0.6696797013282776\n",
      "Ep 36: Batch #34 - Loss: 0.6452447175979614\n",
      "Ep 36: Batch #35 - Loss: 0.7270730137825012\n",
      "Ep 36: Batch #36 - Loss: 0.5839096903800964\n",
      "Ep 36: Batch #37 - Loss: 0.9242995381355286\n",
      "Ep 36: Batch #38 - Loss: 0.5734882950782776\n",
      "Ep 36: Batch #39 - Loss: 0.6865200400352478\n",
      "Ep 36: Batch #40 - Loss: 0.6057981848716736\n",
      "Ep 36: Batch #41 - Loss: 0.622146487236023\n",
      "Ep 36: Batch #42 - Loss: 0.5712803602218628\n",
      "Ep 36: Batch #43 - Loss: 0.6342360377311707\n",
      "Ep 36: Batch #44 - Loss: 0.6168424487113953\n",
      "Ep 36: Batch #45 - Loss: 0.5290839076042175\n",
      "Ep 36: Batch #46 - Loss: 0.6977491974830627\n",
      "Ep 36: Batch #47 - Loss: 0.8060458898544312\n",
      "Ep 36: Batch #48 - Loss: 1.0417182445526123\n",
      "Ep 36: Batch #49 - Loss: 0.814460813999176\n",
      "Ep 36: Batch #50 - Loss: 0.5735070109367371\n",
      "Ep 36: Batch #51 - Loss: 0.819557249546051\n",
      "Ep 36: Batch #52 - Loss: 0.6783956289291382\n",
      "Ep 36: Batch #53 - Loss: 0.7175313234329224\n",
      "Ep 36: Batch #54 - Loss: 0.5813932418823242\n",
      "Ep 36: Batch #55 - Loss: 0.6099949479103088\n",
      "Ep 36: Batch #56 - Loss: 0.8666791319847107\n",
      "Ep 36: Batch #57 - Loss: 0.6839308142662048\n",
      "Ep 36: Batch #58 - Loss: 0.8303523659706116\n",
      "Ep 36: Batch #59 - Loss: 0.5637523531913757\n",
      "Ep 36: Batch #60 - Loss: 1.0141057968139648\n",
      "Ep 36: Batch #61 - Loss: 0.5352513790130615\n",
      "Ep 36: Batch #62 - Loss: 0.5768113136291504\n",
      "Ep 36: Batch #63 - Loss: 0.7895764708518982\n",
      "Ep 36: Batch #64 - Loss: 8.6000394821167\n",
      "Ep 36: Batch #65 - Loss: 0.5258862376213074\n",
      "Ep 36: Batch #66 - Loss: 0.6664668917655945\n",
      "Ep 36: Batch #67 - Loss: 0.7773354053497314\n",
      "Ep 36: Batch #68 - Loss: 0.7183215022087097\n",
      "Ep 36: Batch #69 - Loss: 0.5923712849617004\n",
      "Ep 36: Batch #70 - Loss: 0.6194874048233032\n",
      "Ep 36: Batch #71 - Loss: 0.5389004349708557\n",
      "Ep 36: Batch #72 - Loss: 0.6643775105476379\n",
      "Ep 36: Batch #73 - Loss: 0.7287760972976685\n",
      "Ep 36: Batch #74 - Loss: 0.5815074443817139\n",
      "Ep 36: Batch #75 - Loss: 0.6704755425453186\n",
      "Ep 36: Batch #76 - Loss: 0.9319137334823608\n",
      "Ep 36: Batch #77 - Loss: 0.5793744921684265\n",
      "Ep 36: Batch #78 - Loss: 0.9255988001823425\n",
      "Ep 36: Batch #79 - Loss: 0.5279785990715027\n",
      "Ep 36: Batch #80 - Loss: 0.6950313448905945\n",
      "Ep 36: Batch #81 - Loss: 1.5291330814361572\n",
      "Ep 36: Batch #82 - Loss: 0.7520421147346497\n",
      "Ep 36: Batch #83 - Loss: 1.3234302997589111\n",
      "Ep 36: Batch #84 - Loss: 0.5796841979026794\n",
      "Ep 36: Batch #85 - Loss: 0.7926620841026306\n",
      "Ep 36: Batch #86 - Loss: 0.5498331189155579\n",
      "Ep 36: Batch #87 - Loss: 0.574120044708252\n",
      "Ep 36: Batch #88 - Loss: 0.6583150029182434\n",
      "Ep 36: Batch #89 - Loss: 0.7344014048576355\n",
      "Ep 36: Batch #90 - Loss: 0.9000939726829529\n",
      "Ep 36: Batch #91 - Loss: 0.6492856740951538\n",
      "Ep 36: Batch #92 - Loss: 0.7401677370071411\n",
      "Ep 36: Batch #93 - Loss: 0.7867200374603271\n",
      "Ep 36: Batch #94 - Loss: 0.7615349888801575\n",
      "Ep 36: Batch #95 - Loss: 0.7610301971435547\n",
      "Ep 36: Batch #96 - Loss: 0.7601394057273865\n",
      "Ep 36: Batch #97 - Loss: 0.586725115776062\n",
      "Ep 36: Batch #98 - Loss: 0.5805590748786926\n",
      "Ep 36: Batch #99 - Loss: 0.8029013276100159\n",
      "Ep 36: Batch #100 - Loss: 0.5594868063926697\n",
      "Ep 36: Batch #101 - Loss: 0.8626723289489746\n",
      "Ep 36: Batch #102 - Loss: 0.6148027777671814\n",
      "Ep 36: Batch #103 - Loss: 0.6397464275360107\n",
      "Ep 36: Batch #104 - Loss: 0.6621618270874023\n",
      "Ep 36: Batch #105 - Loss: 0.816473126411438\n",
      "Ep 36: Batch #106 - Loss: 0.6275793313980103\n",
      "Ep 36: Batch #107 - Loss: 0.6143070459365845\n",
      "Ep 36: Batch #108 - Loss: 0.9024630784988403\n",
      "Ep 36: Batch #109 - Loss: 0.627334475517273\n",
      "Ep 36: Batch #110 - Loss: 0.7283197641372681\n",
      "Ep 36: Batch #111 - Loss: 1.0450960397720337\n",
      "Ep 36: Batch #112 - Loss: 0.8049841523170471\n",
      "Ep 36: Batch #113 - Loss: 0.65989750623703\n",
      "Ep 36: Batch #114 - Loss: 0.7301359176635742\n",
      "Ep 36: Batch #115 - Loss: 0.9060742259025574\n",
      "Ep 36: Batch #116 - Loss: 0.5242590308189392\n",
      "Ep 36: Batch #117 - Loss: 0.6821740865707397\n",
      "Ep 36: Batch #118 - Loss: 0.45807379484176636\n",
      "Ep 36: Batch #119 - Loss: 0.8078437447547913\n",
      "Ep 36: Batch #120 - Loss: 0.661797285079956\n",
      "Ep 36: Batch #121 - Loss: 0.5646205544471741\n",
      "Ep 36: Batch #122 - Loss: 0.7131525874137878\n",
      "Ep 36: Batch #123 - Loss: 0.7206075191497803\n",
      "Ep 36: Batch #124 - Loss: 0.5573365688323975\n",
      "Ep 36: Batch #125 - Loss: 2.4679629802703857\n",
      "Ep 36: Batch #126 - Loss: 0.9994300603866577\n",
      "Ep 36: Batch #127 - Loss: 0.5838702321052551\n",
      "Ep 36: Batch #128 - Loss: 0.8841277360916138\n",
      "Ep 36: Batch #129 - Loss: 0.6797593235969543\n",
      "Ep 36: Batch #130 - Loss: 0.5972006320953369\n",
      "Ep 36: Batch #131 - Loss: 0.8060067892074585\n",
      "Ep 36: Batch #132 - Loss: 0.6855846047401428\n",
      "Ep 36: Batch #133 - Loss: 0.6685094833374023\n",
      "Ep 36: Batch #134 - Loss: 0.6380239725112915\n",
      "Ep 36: Batch #135 - Loss: 0.8237197399139404\n",
      "Ep 36: Batch #136 - Loss: 1.0414179563522339\n",
      "Ep 36: Batch #137 - Loss: 0.7549322843551636\n",
      "Ep 36: Batch #138 - Loss: 0.9008294343948364\n",
      "Ep 36: Batch #139 - Loss: 0.6795207262039185\n",
      "Ep 36: Batch #140 - Loss: 0.8468917012214661\n",
      "Ep 36: Batch #141 - Loss: 1.1327544450759888\n",
      "Ep 36: Batch #142 - Loss: 0.671885073184967\n",
      "Ep 36: Batch #143 - Loss: 0.771732747554779\n",
      "Ep 36: Batch #144 - Loss: 0.6123541593551636\n",
      "Ep 36: Batch #145 - Loss: 0.5992043614387512\n",
      "Ep 36: Batch #146 - Loss: 0.706200361251831\n",
      "Ep 36: Batch #147 - Loss: 0.6707226634025574\n",
      "Ep 36: Batch #148 - Loss: 0.7586373686790466\n",
      "Ep 36: Batch #149 - Loss: 0.6324422955513\n",
      "Ep 36: Batch #150 - Loss: 0.7220037579536438\n",
      "Ep 36: Batch #151 - Loss: 0.6306223273277283\n",
      "Ep 36: Batch #152 - Loss: 0.6095662117004395\n",
      "Ep 36: Batch #153 - Loss: 0.8315378427505493\n",
      "Ep 36: Batch #154 - Loss: 0.6345610022544861\n",
      "Ep 36: Batch #155 - Loss: 0.6922152042388916\n",
      "Ep 36: Batch #156 - Loss: 0.7950162291526794\n",
      "Ep 36: Batch #157 - Loss: 0.6167314052581787\n",
      "Ep 36: Batch #158 - Loss: 0.7181352972984314\n",
      "Ep 36: Batch #159 - Loss: 0.6055443286895752\n",
      "Ep 36: Batch #160 - Loss: 0.7024196982383728\n",
      "Ep 36: Batch #161 - Loss: 0.6705557107925415\n",
      "Ep 36: Batch #162 - Loss: 0.7192516922950745\n",
      "Ep 36: Batch #163 - Loss: 0.7611473798751831\n",
      "Ep 36: Batch #164 - Loss: 0.6497140526771545\n",
      "Ep 36: Batch #165 - Loss: 1.343808650970459\n",
      "Ep 36: Batch #166 - Loss: 0.5346787571907043\n",
      "Ep 36: Batch #167 - Loss: 0.7476891875267029\n",
      "Ep 36: Batch #168 - Loss: 0.6930709481239319\n",
      "Ep 36: Batch #169 - Loss: 0.6706457138061523\n",
      "Ep 36: Batch #170 - Loss: 0.6304389238357544\n",
      "Ep 36: Batch #171 - Loss: 0.6420937776565552\n",
      "Ep 36: Batch #172 - Loss: 0.5349811911582947\n",
      "Ep 36: Batch #173 - Loss: 0.9328063726425171\n",
      "Ep 36: Batch #174 - Loss: 0.49713945388793945\n",
      "Ep 36: Batch #175 - Loss: 0.6407319903373718\n",
      "Ep 36: Batch #176 - Loss: 0.8987876176834106\n",
      "Ep 36: Batch #177 - Loss: 0.6551239490509033\n",
      "Ep 36: Batch #178 - Loss: 0.6262096762657166\n",
      "Ep 36: Batch #179 - Loss: 0.7515212297439575\n",
      "Ep 36: Batch #180 - Loss: 0.6549901962280273\n",
      "Ep 36: Batch #181 - Loss: 0.8039670586585999\n",
      "Ep 36: Batch #182 - Loss: 0.6267340183258057\n",
      "Ep 36: Batch #183 - Loss: 0.6087734699249268\n",
      "Ep 36: Batch #184 - Loss: 0.922408938407898\n",
      "Ep 36: Batch #185 - Loss: 0.6341879963874817\n",
      "Ep 36: Batch #186 - Loss: 0.761297345161438\n",
      "Ep 36: Batch #187 - Loss: 0.8730818629264832\n",
      "Ep 36: Batch #188 - Loss: 0.9838308691978455\n",
      "Ep 36: Batch #189 - Loss: 0.5888299942016602\n",
      "Ep 36: Batch #190 - Loss: 0.6252211332321167\n",
      "Ep 36: Batch #191 - Loss: 0.8125512003898621\n",
      "Ep 36: Batch #192 - Loss: 0.5718410611152649\n",
      "Ep 36: Batch #193 - Loss: 0.6299707293510437\n",
      "Ep 36: Batch #194 - Loss: 0.5473527908325195\n",
      "Ep 36: Batch #195 - Loss: 0.7944532036781311\n",
      "Ep 36: Batch #196 - Loss: 0.6935444474220276\n",
      "Ep 36: Batch #197 - Loss: 0.7026616930961609\n",
      "Ep 36: Batch #198 - Loss: 0.5346386432647705\n",
      "Ep 36: Batch #199 - Loss: 0.64698326587677\n",
      "Ep 37: Batch #0 - Loss: 0.6504047513008118\n",
      "Ep 37: Batch #1 - Loss: 0.715324342250824\n",
      "Ep 37: Batch #2 - Loss: 0.8609568476676941\n",
      "Ep 37: Batch #3 - Loss: 0.7237265110015869\n",
      "Ep 37: Batch #4 - Loss: 0.6589263081550598\n",
      "Ep 37: Batch #5 - Loss: 0.5626327991485596\n",
      "Ep 37: Batch #6 - Loss: 0.7428991198539734\n",
      "Ep 37: Batch #7 - Loss: 0.5775541663169861\n",
      "Ep 37: Batch #8 - Loss: 0.5900982022285461\n",
      "Ep 37: Batch #9 - Loss: 1.0975745916366577\n",
      "Ep 37: Batch #10 - Loss: 0.8161800503730774\n",
      "Ep 37: Batch #11 - Loss: 0.5444840788841248\n",
      "Ep 37: Batch #12 - Loss: 1.2182601690292358\n",
      "Ep 37: Batch #13 - Loss: 0.5723403692245483\n",
      "Ep 37: Batch #14 - Loss: 0.602040708065033\n",
      "Ep 37: Batch #15 - Loss: 0.8686147928237915\n",
      "Ep 37: Batch #16 - Loss: 0.9546334743499756\n",
      "Ep 37: Batch #17 - Loss: 0.7310822010040283\n",
      "Ep 37: Batch #18 - Loss: 0.8084383010864258\n",
      "Ep 37: Batch #19 - Loss: 0.5648020505905151\n",
      "Ep 37: Batch #20 - Loss: 0.5474624037742615\n",
      "Ep 37: Batch #21 - Loss: 0.8519383072853088\n",
      "Ep 37: Batch #22 - Loss: 0.6126812696456909\n",
      "Ep 37: Batch #23 - Loss: 0.6019220948219299\n",
      "Ep 37: Batch #24 - Loss: 0.6407690644264221\n",
      "Ep 37: Batch #25 - Loss: 0.6097072958946228\n",
      "Ep 37: Batch #26 - Loss: 0.5630490183830261\n",
      "Ep 37: Batch #27 - Loss: 1.1444098949432373\n",
      "Ep 37: Batch #28 - Loss: 0.6921367049217224\n",
      "Ep 37: Batch #29 - Loss: 0.759035587310791\n",
      "Ep 37: Batch #30 - Loss: 0.8593874573707581\n",
      "Ep 37: Batch #31 - Loss: 0.5625696778297424\n",
      "Ep 37: Batch #32 - Loss: 0.5827482342720032\n",
      "Ep 37: Batch #33 - Loss: 0.6694036722183228\n",
      "Ep 37: Batch #34 - Loss: 0.6448168754577637\n",
      "Ep 37: Batch #35 - Loss: 0.7267110347747803\n",
      "Ep 37: Batch #36 - Loss: 0.5838000774383545\n",
      "Ep 37: Batch #37 - Loss: 0.9241835474967957\n",
      "Ep 37: Batch #38 - Loss: 0.5731168985366821\n",
      "Ep 37: Batch #39 - Loss: 0.6863141059875488\n",
      "Ep 37: Batch #40 - Loss: 0.6056320071220398\n",
      "Ep 37: Batch #41 - Loss: 0.6221393942832947\n",
      "Ep 37: Batch #42 - Loss: 0.5713574886322021\n",
      "Ep 37: Batch #43 - Loss: 0.6341082453727722\n",
      "Ep 37: Batch #44 - Loss: 0.6166553497314453\n",
      "Ep 37: Batch #45 - Loss: 0.5286699533462524\n",
      "Ep 37: Batch #46 - Loss: 0.6977673172950745\n",
      "Ep 37: Batch #47 - Loss: 0.8062454462051392\n",
      "Ep 37: Batch #48 - Loss: 1.0417189598083496\n",
      "Ep 37: Batch #49 - Loss: 0.814424991607666\n",
      "Ep 37: Batch #50 - Loss: 0.5736493468284607\n",
      "Ep 37: Batch #51 - Loss: 0.8195063471794128\n",
      "Ep 37: Batch #52 - Loss: 0.6781944632530212\n",
      "Ep 37: Batch #53 - Loss: 0.7175697684288025\n",
      "Ep 37: Batch #54 - Loss: 0.5810744762420654\n",
      "Ep 37: Batch #55 - Loss: 0.6099354028701782\n",
      "Ep 37: Batch #56 - Loss: 0.8664840459823608\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 37: Batch #57 - Loss: 0.6836665868759155\n",
      "Ep 37: Batch #58 - Loss: 0.8299732208251953\n",
      "Ep 37: Batch #59 - Loss: 0.5637118220329285\n",
      "Ep 37: Batch #60 - Loss: 1.0141551494598389\n",
      "Ep 37: Batch #61 - Loss: 0.535490870475769\n",
      "Ep 37: Batch #62 - Loss: 0.5764760971069336\n",
      "Ep 37: Batch #63 - Loss: 0.7894441485404968\n",
      "Ep 37: Batch #64 - Loss: 8.57939624786377\n",
      "Ep 37: Batch #65 - Loss: 0.525822103023529\n",
      "Ep 37: Batch #66 - Loss: 0.6667526364326477\n",
      "Ep 37: Batch #67 - Loss: 0.7772021293640137\n",
      "Ep 37: Batch #68 - Loss: 0.7187445759773254\n",
      "Ep 37: Batch #69 - Loss: 0.5924261808395386\n",
      "Ep 37: Batch #70 - Loss: 0.6199625134468079\n",
      "Ep 37: Batch #71 - Loss: 0.5388430953025818\n",
      "Ep 37: Batch #72 - Loss: 0.6650104522705078\n",
      "Ep 37: Batch #73 - Loss: 0.7284885048866272\n",
      "Ep 37: Batch #74 - Loss: 0.5818223357200623\n",
      "Ep 37: Batch #75 - Loss: 0.6705119013786316\n",
      "Ep 37: Batch #76 - Loss: 0.9317325949668884\n",
      "Ep 37: Batch #77 - Loss: 0.5792483687400818\n",
      "Ep 37: Batch #78 - Loss: 0.9252585768699646\n",
      "Ep 37: Batch #79 - Loss: 0.5277596712112427\n",
      "Ep 37: Batch #80 - Loss: 0.6950083374977112\n",
      "Ep 37: Batch #81 - Loss: 1.528049111366272\n",
      "Ep 37: Batch #82 - Loss: 0.7518041729927063\n",
      "Ep 37: Batch #83 - Loss: 1.319675087928772\n",
      "Ep 37: Batch #84 - Loss: 0.5804330110549927\n",
      "Ep 37: Batch #85 - Loss: 0.792449414730072\n",
      "Ep 37: Batch #86 - Loss: 0.5499393939971924\n",
      "Ep 37: Batch #87 - Loss: 0.5741032361984253\n",
      "Ep 37: Batch #88 - Loss: 0.6582241654396057\n",
      "Ep 37: Batch #89 - Loss: 0.7340355515480042\n",
      "Ep 37: Batch #90 - Loss: 0.9002167582511902\n",
      "Ep 37: Batch #91 - Loss: 0.6496756672859192\n",
      "Ep 37: Batch #92 - Loss: 0.7404076457023621\n",
      "Ep 37: Batch #93 - Loss: 0.7866089940071106\n",
      "Ep 37: Batch #94 - Loss: 0.7607387900352478\n",
      "Ep 37: Batch #95 - Loss: 0.7611446380615234\n",
      "Ep 37: Batch #96 - Loss: 0.7610139846801758\n",
      "Ep 37: Batch #97 - Loss: 0.5875704288482666\n",
      "Ep 37: Batch #98 - Loss: 0.5806306004524231\n",
      "Ep 37: Batch #99 - Loss: 0.8030360341072083\n",
      "Ep 37: Batch #100 - Loss: 0.5593743324279785\n",
      "Ep 37: Batch #101 - Loss: 0.8628473281860352\n",
      "Ep 37: Batch #102 - Loss: 0.6146725416183472\n",
      "Ep 37: Batch #103 - Loss: 0.6397252082824707\n",
      "Ep 37: Batch #104 - Loss: 0.6623125672340393\n",
      "Ep 37: Batch #105 - Loss: 0.8163827657699585\n",
      "Ep 37: Batch #106 - Loss: 0.6274939179420471\n",
      "Ep 37: Batch #107 - Loss: 0.6145429611206055\n",
      "Ep 37: Batch #108 - Loss: 0.902570903301239\n",
      "Ep 37: Batch #109 - Loss: 0.6272132396697998\n",
      "Ep 37: Batch #110 - Loss: 0.7281864881515503\n",
      "Ep 37: Batch #111 - Loss: 1.0452288389205933\n",
      "Ep 37: Batch #112 - Loss: 0.8046181201934814\n",
      "Ep 37: Batch #113 - Loss: 0.6597613096237183\n",
      "Ep 37: Batch #114 - Loss: 0.7299851775169373\n",
      "Ep 37: Batch #115 - Loss: 0.9061335921287537\n",
      "Ep 37: Batch #116 - Loss: 0.5240105986595154\n",
      "Ep 37: Batch #117 - Loss: 0.6819181442260742\n",
      "Ep 37: Batch #118 - Loss: 0.4580497145652771\n",
      "Ep 37: Batch #119 - Loss: 0.8083508014678955\n",
      "Ep 37: Batch #120 - Loss: 0.6613884568214417\n",
      "Ep 37: Batch #121 - Loss: 0.5644155740737915\n",
      "Ep 37: Batch #122 - Loss: 0.7131675481796265\n",
      "Ep 37: Batch #123 - Loss: 0.7206278443336487\n",
      "Ep 37: Batch #124 - Loss: 0.5574382543563843\n",
      "Ep 37: Batch #125 - Loss: 2.467841625213623\n",
      "Ep 37: Batch #126 - Loss: 0.9998815655708313\n",
      "Ep 37: Batch #127 - Loss: 0.5840333104133606\n",
      "Ep 37: Batch #128 - Loss: 0.8841322660446167\n",
      "Ep 37: Batch #129 - Loss: 0.6799514889717102\n",
      "Ep 37: Batch #130 - Loss: 0.5969724059104919\n",
      "Ep 37: Batch #131 - Loss: 0.8062297105789185\n",
      "Ep 37: Batch #132 - Loss: 0.6853799223899841\n",
      "Ep 37: Batch #133 - Loss: 0.6684591770172119\n",
      "Ep 37: Batch #134 - Loss: 0.6377777457237244\n",
      "Ep 37: Batch #135 - Loss: 0.8236798048019409\n",
      "Ep 37: Batch #136 - Loss: 1.0416053533554077\n",
      "Ep 37: Batch #137 - Loss: 0.7548955678939819\n",
      "Ep 37: Batch #138 - Loss: 0.9007790684700012\n",
      "Ep 37: Batch #139 - Loss: 0.6789862513542175\n",
      "Ep 37: Batch #140 - Loss: 0.8464917540550232\n",
      "Ep 37: Batch #141 - Loss: 1.1325111389160156\n",
      "Ep 37: Batch #142 - Loss: 0.6717861890792847\n",
      "Ep 37: Batch #143 - Loss: 0.7722355127334595\n",
      "Ep 37: Batch #144 - Loss: 0.6122938394546509\n",
      "Ep 37: Batch #145 - Loss: 0.5991373062133789\n",
      "Ep 37: Batch #146 - Loss: 0.7065268754959106\n",
      "Ep 37: Batch #147 - Loss: 0.6704145669937134\n",
      "Ep 37: Batch #148 - Loss: 0.7583147287368774\n",
      "Ep 37: Batch #149 - Loss: 0.6315789818763733\n",
      "Ep 37: Batch #150 - Loss: 0.7221571207046509\n",
      "Ep 37: Batch #151 - Loss: 0.6305236220359802\n",
      "Ep 37: Batch #152 - Loss: 0.6093435883522034\n",
      "Ep 37: Batch #153 - Loss: 0.8310714364051819\n",
      "Ep 37: Batch #154 - Loss: 0.6345115900039673\n",
      "Ep 37: Batch #155 - Loss: 0.6925681829452515\n",
      "Ep 37: Batch #156 - Loss: 0.794135332107544\n",
      "Ep 37: Batch #157 - Loss: 0.6165536642074585\n",
      "Ep 37: Batch #158 - Loss: 0.718177855014801\n",
      "Ep 37: Batch #159 - Loss: 0.6052070260047913\n",
      "Ep 37: Batch #160 - Loss: 0.7019714117050171\n",
      "Ep 37: Batch #161 - Loss: 0.6704961657524109\n",
      "Ep 37: Batch #162 - Loss: 0.7193686962127686\n",
      "Ep 37: Batch #163 - Loss: 0.7609809041023254\n",
      "Ep 37: Batch #164 - Loss: 0.649580717086792\n",
      "Ep 37: Batch #165 - Loss: 1.3431352376937866\n",
      "Ep 37: Batch #166 - Loss: 0.5343979001045227\n",
      "Ep 37: Batch #167 - Loss: 0.745515763759613\n",
      "Ep 37: Batch #168 - Loss: 0.6929840445518494\n",
      "Ep 37: Batch #169 - Loss: 0.6704013347625732\n",
      "Ep 37: Batch #170 - Loss: 0.6304059028625488\n",
      "Ep 37: Batch #171 - Loss: 0.6420839428901672\n",
      "Ep 37: Batch #172 - Loss: 0.5350380539894104\n",
      "Ep 37: Batch #173 - Loss: 0.9322412014007568\n",
      "Ep 37: Batch #174 - Loss: 0.49711722135543823\n",
      "Ep 37: Batch #175 - Loss: 0.640448808670044\n",
      "Ep 37: Batch #176 - Loss: 0.898500919342041\n",
      "Ep 37: Batch #177 - Loss: 0.6548447608947754\n",
      "Ep 37: Batch #178 - Loss: 0.6257780194282532\n",
      "Ep 37: Batch #179 - Loss: 0.751706600189209\n",
      "Ep 37: Batch #180 - Loss: 0.6547053456306458\n",
      "Ep 37: Batch #181 - Loss: 0.8039528727531433\n",
      "Ep 37: Batch #182 - Loss: 0.6267620921134949\n",
      "Ep 37: Batch #183 - Loss: 0.608643651008606\n",
      "Ep 37: Batch #184 - Loss: 0.9225410223007202\n",
      "Ep 37: Batch #185 - Loss: 0.6338768601417542\n",
      "Ep 37: Batch #186 - Loss: 0.7610198855400085\n",
      "Ep 37: Batch #187 - Loss: 0.8715947866439819\n",
      "Ep 37: Batch #188 - Loss: 0.9825226664543152\n",
      "Ep 37: Batch #189 - Loss: 0.5887011885643005\n",
      "Ep 37: Batch #190 - Loss: 0.6248575448989868\n",
      "Ep 37: Batch #191 - Loss: 0.8118796348571777\n",
      "Ep 37: Batch #192 - Loss: 0.5717227458953857\n",
      "Ep 37: Batch #193 - Loss: 0.6300642490386963\n",
      "Ep 37: Batch #194 - Loss: 0.5471357703208923\n",
      "Ep 37: Batch #195 - Loss: 0.7944836616516113\n",
      "Ep 37: Batch #196 - Loss: 0.6933436393737793\n",
      "Ep 37: Batch #197 - Loss: 0.7024969458580017\n",
      "Ep 37: Batch #198 - Loss: 0.5346278548240662\n",
      "Ep 37: Batch #199 - Loss: 0.646920382976532\n",
      "Ep 38: Batch #0 - Loss: 0.6504619121551514\n",
      "Ep 38: Batch #1 - Loss: 0.7151457667350769\n",
      "Ep 38: Batch #2 - Loss: 0.8606488108634949\n",
      "Ep 38: Batch #3 - Loss: 0.7236849665641785\n",
      "Ep 38: Batch #4 - Loss: 0.65864098072052\n",
      "Ep 38: Batch #5 - Loss: 0.5623140335083008\n",
      "Ep 38: Batch #6 - Loss: 0.7424045205116272\n",
      "Ep 38: Batch #7 - Loss: 0.5772155523300171\n",
      "Ep 38: Batch #8 - Loss: 0.5898671746253967\n",
      "Ep 38: Batch #9 - Loss: 1.097543478012085\n",
      "Ep 38: Batch #10 - Loss: 0.8156563639640808\n",
      "Ep 38: Batch #11 - Loss: 0.5444113612174988\n",
      "Ep 38: Batch #12 - Loss: 1.217093825340271\n",
      "Ep 38: Batch #13 - Loss: 0.5722859501838684\n",
      "Ep 38: Batch #14 - Loss: 0.6019635200500488\n",
      "Ep 38: Batch #15 - Loss: 0.8671669960021973\n",
      "Ep 38: Batch #16 - Loss: 0.9543030858039856\n",
      "Ep 38: Batch #17 - Loss: 0.7307493686676025\n",
      "Ep 38: Batch #18 - Loss: 0.8084344863891602\n",
      "Ep 38: Batch #19 - Loss: 0.564565896987915\n",
      "Ep 38: Batch #20 - Loss: 0.5474421977996826\n",
      "Ep 38: Batch #21 - Loss: 0.8496924042701721\n",
      "Ep 38: Batch #22 - Loss: 0.6124650835990906\n",
      "Ep 38: Batch #23 - Loss: 0.6015770435333252\n",
      "Ep 38: Batch #24 - Loss: 0.6404239535331726\n",
      "Ep 38: Batch #25 - Loss: 0.6096173524856567\n",
      "Ep 38: Batch #26 - Loss: 0.5627076029777527\n",
      "Ep 38: Batch #27 - Loss: 1.1442484855651855\n",
      "Ep 38: Batch #28 - Loss: 0.6920284032821655\n",
      "Ep 38: Batch #29 - Loss: 0.7591373920440674\n",
      "Ep 38: Batch #30 - Loss: 0.8574075698852539\n",
      "Ep 38: Batch #31 - Loss: 0.5624827742576599\n",
      "Ep 38: Batch #32 - Loss: 0.5826171636581421\n",
      "Ep 38: Batch #33 - Loss: 0.6691397428512573\n",
      "Ep 38: Batch #34 - Loss: 0.6442336440086365\n",
      "Ep 38: Batch #35 - Loss: 0.7263695597648621\n",
      "Ep 38: Batch #36 - Loss: 0.5838764905929565\n",
      "Ep 38: Batch #37 - Loss: 0.9239883422851562\n",
      "Ep 38: Batch #38 - Loss: 0.572912335395813\n",
      "Ep 38: Batch #39 - Loss: 0.6861618161201477\n",
      "Ep 38: Batch #40 - Loss: 0.6056796312332153\n",
      "Ep 38: Batch #41 - Loss: 0.6218367218971252\n",
      "Ep 38: Batch #42 - Loss: 0.5712218284606934\n",
      "Ep 38: Batch #43 - Loss: 0.6341782212257385\n",
      "Ep 38: Batch #44 - Loss: 0.61637943983078\n",
      "Ep 38: Batch #45 - Loss: 0.5285164713859558\n",
      "Ep 38: Batch #46 - Loss: 0.697698712348938\n",
      "Ep 38: Batch #47 - Loss: 0.806164026260376\n",
      "Ep 38: Batch #48 - Loss: 1.0414490699768066\n",
      "Ep 38: Batch #49 - Loss: 0.8140763640403748\n",
      "Ep 38: Batch #50 - Loss: 0.5739392638206482\n",
      "Ep 38: Batch #51 - Loss: 0.8195207715034485\n",
      "Ep 38: Batch #52 - Loss: 0.6781395077705383\n",
      "Ep 38: Batch #53 - Loss: 0.7175050377845764\n",
      "Ep 38: Batch #54 - Loss: 0.5809059143066406\n",
      "Ep 38: Batch #55 - Loss: 0.6097083687782288\n",
      "Ep 38: Batch #56 - Loss: 0.8653320074081421\n",
      "Ep 38: Batch #57 - Loss: 0.683499813079834\n",
      "Ep 38: Batch #58 - Loss: 0.8297516107559204\n",
      "Ep 38: Batch #59 - Loss: 0.5634775757789612\n",
      "Ep 38: Batch #60 - Loss: 1.0143414735794067\n",
      "Ep 38: Batch #61 - Loss: 0.5355114936828613\n",
      "Ep 38: Batch #62 - Loss: 0.5762532353401184\n",
      "Ep 38: Batch #63 - Loss: 0.7890887260437012\n",
      "Ep 38: Batch #64 - Loss: 8.601800918579102\n",
      "Ep 38: Batch #65 - Loss: 0.5257337093353271\n",
      "Ep 38: Batch #66 - Loss: 0.666497528553009\n",
      "Ep 38: Batch #67 - Loss: 0.7770726084709167\n",
      "Ep 38: Batch #68 - Loss: 0.7174444198608398\n",
      "Ep 38: Batch #69 - Loss: 0.5919779539108276\n",
      "Ep 38: Batch #70 - Loss: 0.6180316209793091\n",
      "Ep 38: Batch #71 - Loss: 0.5385530591011047\n",
      "Ep 38: Batch #72 - Loss: 0.6643947958946228\n",
      "Ep 38: Batch #73 - Loss: 0.7280829548835754\n",
      "Ep 38: Batch #74 - Loss: 0.5828868746757507\n",
      "Ep 38: Batch #75 - Loss: 0.6703550815582275\n",
      "Ep 38: Batch #76 - Loss: 0.932857096195221\n",
      "Ep 38: Batch #77 - Loss: 0.5789245367050171\n",
      "Ep 38: Batch #78 - Loss: 0.925644040107727\n",
      "Ep 38: Batch #79 - Loss: 0.5278117656707764\n",
      "Ep 38: Batch #80 - Loss: 0.6952946186065674\n",
      "Ep 38: Batch #81 - Loss: 1.526863932609558\n",
      "Ep 38: Batch #82 - Loss: 0.7525880336761475\n",
      "Ep 38: Batch #83 - Loss: 1.3158228397369385\n",
      "Ep 38: Batch #84 - Loss: 0.5793783068656921\n",
      "Ep 38: Batch #85 - Loss: 0.7937695384025574\n",
      "Ep 38: Batch #86 - Loss: 0.5499157905578613\n",
      "Ep 38: Batch #87 - Loss: 0.5741672515869141\n",
      "Ep 38: Batch #88 - Loss: 0.6583425998687744\n",
      "Ep 38: Batch #89 - Loss: 0.7340247631072998\n",
      "Ep 38: Batch #90 - Loss: 0.9004229307174683\n",
      "Ep 38: Batch #91 - Loss: 0.649097204208374\n",
      "Ep 38: Batch #92 - Loss: 0.73833167552948\n",
      "Ep 38: Batch #93 - Loss: 0.7859759330749512\n",
      "Ep 38: Batch #94 - Loss: 0.7600196599960327\n",
      "Ep 38: Batch #95 - Loss: 0.761573851108551\n",
      "Ep 38: Batch #96 - Loss: 0.7613707184791565\n",
      "Ep 38: Batch #97 - Loss: 0.5865240693092346\n",
      "Ep 38: Batch #98 - Loss: 0.5794480443000793\n",
      "Ep 38: Batch #99 - Loss: 0.8021559715270996\n",
      "Ep 38: Batch #100 - Loss: 0.559088945388794\n",
      "Ep 38: Batch #101 - Loss: 0.8646150231361389\n",
      "Ep 38: Batch #102 - Loss: 0.6146515607833862\n",
      "Ep 38: Batch #103 - Loss: 0.6393436789512634\n",
      "Ep 38: Batch #104 - Loss: 0.6622076630592346\n",
      "Ep 38: Batch #105 - Loss: 0.8155960440635681\n",
      "Ep 38: Batch #106 - Loss: 0.6277828812599182\n",
      "Ep 38: Batch #107 - Loss: 0.6142852902412415\n",
      "Ep 38: Batch #108 - Loss: 0.9023550748825073\n",
      "Ep 38: Batch #109 - Loss: 0.6272500157356262\n",
      "Ep 38: Batch #110 - Loss: 0.7281336784362793\n",
      "Ep 38: Batch #111 - Loss: 1.0449707508087158\n",
      "Ep 38: Batch #112 - Loss: 0.8036022782325745\n",
      "Ep 38: Batch #113 - Loss: 0.6599138975143433\n",
      "Ep 38: Batch #114 - Loss: 0.730407178401947\n",
      "Ep 38: Batch #115 - Loss: 0.9063517451286316\n",
      "Ep 38: Batch #116 - Loss: 0.5239899754524231\n",
      "Ep 38: Batch #117 - Loss: 0.6814773678779602\n",
      "Ep 38: Batch #118 - Loss: 0.4575066864490509\n",
      "Model saved in file: ./weights_autoencoder_sigmoid/model_e38b118_1516648796.706912.ckpt\n",
      "Ep 38: Batch #119 - Loss: 0.8076741099357605\n",
      "Ep 38: Batch #120 - Loss: 0.6616111993789673\n",
      "Ep 38: Batch #121 - Loss: 0.5637161135673523\n",
      "Ep 38: Batch #122 - Loss: 0.712631106376648\n",
      "Ep 38: Batch #123 - Loss: 0.7203948497772217\n",
      "Ep 38: Batch #124 - Loss: 0.5575355291366577\n",
      "Ep 38: Batch #125 - Loss: 2.468204975128174\n",
      "Ep 38: Batch #126 - Loss: 0.9994769096374512\n",
      "Ep 38: Batch #127 - Loss: 0.5835796594619751\n",
      "Ep 38: Batch #128 - Loss: 0.8842670917510986\n",
      "Ep 38: Batch #129 - Loss: 0.6795416474342346\n",
      "Ep 38: Batch #130 - Loss: 0.5970045328140259\n",
      "Ep 38: Batch #131 - Loss: 0.8058311939239502\n",
      "Ep 38: Batch #132 - Loss: 0.6852104067802429\n",
      "Ep 38: Batch #133 - Loss: 0.6684038043022156\n",
      "Ep 38: Batch #134 - Loss: 0.638034999370575\n",
      "Ep 38: Batch #135 - Loss: 0.8234814405441284\n",
      "Ep 38: Batch #136 - Loss: 1.0411309003829956\n",
      "Ep 38: Batch #137 - Loss: 0.7542388439178467\n",
      "Ep 38: Batch #138 - Loss: 0.9008964896202087\n",
      "Ep 38: Batch #139 - Loss: 0.6794663667678833\n",
      "Ep 38: Batch #140 - Loss: 0.8463541269302368\n",
      "Ep 38: Batch #141 - Loss: 1.1320929527282715\n",
      "Ep 38: Batch #142 - Loss: 0.671944797039032\n",
      "Ep 38: Batch #143 - Loss: 0.7715169787406921\n",
      "Ep 38: Batch #144 - Loss: 0.6124822497367859\n",
      "Ep 38: Batch #145 - Loss: 0.5992411375045776\n",
      "Ep 38: Batch #146 - Loss: 0.7058404088020325\n",
      "Ep 38: Batch #147 - Loss: 0.6697598695755005\n",
      "Ep 38: Batch #148 - Loss: 0.7581454515457153\n",
      "Ep 38: Batch #149 - Loss: 0.6305177211761475\n",
      "Ep 38: Batch #150 - Loss: 0.7221201062202454\n",
      "Ep 38: Batch #151 - Loss: 0.6306139230728149\n",
      "Ep 38: Batch #152 - Loss: 0.6093649864196777\n",
      "Ep 38: Batch #153 - Loss: 0.8307883143424988\n",
      "Ep 38: Batch #154 - Loss: 0.6345043778419495\n",
      "Ep 38: Batch #155 - Loss: 0.692132830619812\n",
      "Ep 38: Batch #156 - Loss: 0.7933462858200073\n",
      "Ep 38: Batch #157 - Loss: 0.6165437698364258\n",
      "Ep 38: Batch #158 - Loss: 0.7180771827697754\n",
      "Ep 38: Batch #159 - Loss: 0.6047128438949585\n",
      "Ep 38: Batch #160 - Loss: 0.7015822529792786\n",
      "Ep 38: Batch #161 - Loss: 0.6706194281578064\n",
      "Ep 38: Batch #162 - Loss: 0.7194128036499023\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 38: Batch #163 - Loss: 0.760912299156189\n",
      "Ep 38: Batch #164 - Loss: 0.6495362520217896\n",
      "Ep 38: Batch #165 - Loss: 1.3432074785232544\n",
      "Ep 38: Batch #166 - Loss: 0.5344401597976685\n",
      "Ep 38: Batch #167 - Loss: 0.7432460188865662\n",
      "Ep 38: Batch #168 - Loss: 0.6931450963020325\n",
      "Ep 38: Batch #169 - Loss: 0.6698951125144958\n",
      "Ep 38: Batch #170 - Loss: 0.630169689655304\n",
      "Ep 38: Batch #171 - Loss: 0.6419776082038879\n",
      "Ep 38: Batch #172 - Loss: 0.5348562598228455\n",
      "Ep 38: Batch #173 - Loss: 0.9318404197692871\n",
      "Ep 38: Batch #174 - Loss: 0.4970526695251465\n",
      "Ep 38: Batch #175 - Loss: 0.6396514177322388\n",
      "Ep 38: Batch #176 - Loss: 0.8984737396240234\n",
      "Ep 38: Batch #177 - Loss: 0.6542761921882629\n",
      "Ep 38: Batch #178 - Loss: 0.6254832148551941\n",
      "Ep 38: Batch #179 - Loss: 0.7512214183807373\n",
      "Ep 38: Batch #180 - Loss: 0.654456615447998\n",
      "Ep 38: Batch #181 - Loss: 0.8039257526397705\n",
      "Ep 38: Batch #182 - Loss: 0.626428484916687\n",
      "Ep 38: Batch #183 - Loss: 0.6081075072288513\n",
      "Ep 38: Batch #184 - Loss: 0.9223796725273132\n",
      "Ep 38: Batch #185 - Loss: 0.6338253021240234\n",
      "Ep 38: Batch #186 - Loss: 0.7610985040664673\n",
      "Ep 38: Batch #187 - Loss: 0.8718035817146301\n",
      "Ep 38: Batch #188 - Loss: 0.9803191423416138\n",
      "Ep 38: Batch #189 - Loss: 0.5887960195541382\n",
      "Ep 38: Batch #190 - Loss: 0.6250335574150085\n",
      "Ep 38: Batch #191 - Loss: 0.8115322589874268\n",
      "Ep 38: Batch #192 - Loss: 0.5716213583946228\n",
      "Ep 38: Batch #193 - Loss: 0.6301723122596741\n",
      "Ep 38: Batch #194 - Loss: 0.5468161106109619\n",
      "Ep 38: Batch #195 - Loss: 0.7937756776809692\n",
      "Ep 38: Batch #196 - Loss: 0.6932741403579712\n",
      "Ep 38: Batch #197 - Loss: 0.7024659514427185\n",
      "Ep 38: Batch #198 - Loss: 0.5346550941467285\n",
      "Ep 38: Batch #199 - Loss: 0.6467853784561157\n",
      "Ep 39: Batch #0 - Loss: 0.6506115198135376\n",
      "Ep 39: Batch #1 - Loss: 0.7150548100471497\n",
      "Ep 39: Batch #2 - Loss: 0.8605793118476868\n",
      "Ep 39: Batch #3 - Loss: 0.723964512348175\n",
      "Ep 39: Batch #4 - Loss: 0.6584071516990662\n",
      "Ep 39: Batch #5 - Loss: 0.5621602535247803\n",
      "Ep 39: Batch #6 - Loss: 0.7419916987419128\n",
      "Ep 39: Batch #7 - Loss: 0.5771169662475586\n",
      "Ep 39: Batch #8 - Loss: 0.5898016691207886\n",
      "Ep 39: Batch #9 - Loss: 1.0968939065933228\n",
      "Ep 39: Batch #10 - Loss: 0.8145025968551636\n",
      "Ep 39: Batch #11 - Loss: 0.5445110201835632\n",
      "Ep 39: Batch #12 - Loss: 1.2160738706588745\n",
      "Ep 39: Batch #13 - Loss: 0.5722224116325378\n",
      "Ep 39: Batch #14 - Loss: 0.6018438339233398\n",
      "Ep 39: Batch #15 - Loss: 0.8661484122276306\n",
      "Ep 39: Batch #16 - Loss: 0.9543402194976807\n",
      "Ep 39: Batch #17 - Loss: 0.7306690812110901\n",
      "Ep 39: Batch #18 - Loss: 0.808372974395752\n",
      "Ep 39: Batch #19 - Loss: 0.5644227266311646\n",
      "Ep 39: Batch #20 - Loss: 0.5473806262016296\n",
      "Ep 39: Batch #21 - Loss: 0.8477191925048828\n",
      "Ep 39: Batch #22 - Loss: 0.6122227311134338\n",
      "Ep 39: Batch #23 - Loss: 0.6014070510864258\n",
      "Ep 39: Batch #24 - Loss: 0.6402337551116943\n",
      "Ep 39: Batch #25 - Loss: 0.6093905568122864\n",
      "Ep 39: Batch #26 - Loss: 0.5621457099914551\n",
      "Ep 39: Batch #27 - Loss: 1.1444244384765625\n",
      "Ep 39: Batch #28 - Loss: 0.6918603777885437\n",
      "Ep 39: Batch #29 - Loss: 0.7589886784553528\n",
      "Ep 39: Batch #30 - Loss: 0.8550921678543091\n",
      "Ep 39: Batch #31 - Loss: 0.5623522996902466\n",
      "Ep 39: Batch #32 - Loss: 0.5823858976364136\n",
      "Ep 39: Batch #33 - Loss: 0.6689876914024353\n",
      "Ep 39: Batch #34 - Loss: 0.6442696452140808\n",
      "Ep 39: Batch #35 - Loss: 0.7260320782661438\n",
      "Ep 39: Batch #36 - Loss: 0.5841008424758911\n",
      "Ep 39: Batch #37 - Loss: 0.9233956933021545\n",
      "Ep 39: Batch #38 - Loss: 0.572745144367218\n",
      "Ep 39: Batch #39 - Loss: 0.6868455410003662\n",
      "Ep 39: Batch #40 - Loss: 0.6053559184074402\n",
      "Ep 39: Batch #41 - Loss: 0.6218332648277283\n",
      "Ep 39: Batch #42 - Loss: 0.5711472034454346\n",
      "Ep 39: Batch #43 - Loss: 0.6339545249938965\n",
      "Ep 39: Batch #44 - Loss: 0.6160709857940674\n",
      "Ep 39: Batch #45 - Loss: 0.5283636450767517\n",
      "Ep 39: Batch #46 - Loss: 0.6978031396865845\n",
      "Ep 39: Batch #47 - Loss: 0.8058952689170837\n",
      "Ep 39: Batch #48 - Loss: 1.0414888858795166\n",
      "Ep 39: Batch #49 - Loss: 0.8140614032745361\n",
      "Ep 39: Batch #50 - Loss: 0.5738391280174255\n",
      "Ep 39: Batch #51 - Loss: 0.8193922638893127\n",
      "Ep 39: Batch #52 - Loss: 0.6780328750610352\n",
      "Ep 39: Batch #53 - Loss: 0.7173724174499512\n",
      "Ep 39: Batch #54 - Loss: 0.5807914137840271\n",
      "Ep 39: Batch #55 - Loss: 0.6093735694885254\n",
      "Ep 39: Batch #56 - Loss: 0.8650403022766113\n",
      "Ep 39: Batch #57 - Loss: 0.6836000680923462\n",
      "Ep 39: Batch #58 - Loss: 0.8293555974960327\n",
      "Ep 39: Batch #59 - Loss: 0.5631699562072754\n",
      "Ep 39: Batch #60 - Loss: 1.0139224529266357\n",
      "Ep 39: Batch #61 - Loss: 0.5353291630744934\n",
      "Ep 39: Batch #62 - Loss: 0.5760862231254578\n",
      "Ep 39: Batch #63 - Loss: 0.7883445024490356\n",
      "Ep 39: Batch #64 - Loss: 8.553892135620117\n",
      "Ep 39: Batch #65 - Loss: 0.5256690382957458\n",
      "Ep 39: Batch #66 - Loss: 0.6663172841072083\n",
      "Ep 39: Batch #67 - Loss: 0.7768787741661072\n",
      "Ep 39: Batch #68 - Loss: 0.7170789837837219\n",
      "Ep 39: Batch #69 - Loss: 0.5918582081794739\n",
      "Ep 39: Batch #70 - Loss: 0.6176634430885315\n",
      "Ep 39: Batch #71 - Loss: 0.5380053520202637\n",
      "Ep 39: Batch #72 - Loss: 0.6654852628707886\n",
      "Ep 39: Batch #73 - Loss: 0.7278455495834351\n",
      "Ep 39: Batch #74 - Loss: 0.5828892588615417\n",
      "Ep 39: Batch #75 - Loss: 0.6701915264129639\n",
      "Ep 39: Batch #76 - Loss: 0.9332577586174011\n",
      "Ep 39: Batch #77 - Loss: 0.5785742402076721\n",
      "Ep 39: Batch #78 - Loss: 0.925444483757019\n",
      "Ep 39: Batch #79 - Loss: 0.5272412300109863\n",
      "Ep 39: Batch #80 - Loss: 0.6950867772102356\n",
      "Ep 39: Batch #81 - Loss: 1.5270922183990479\n",
      "Ep 39: Batch #82 - Loss: 0.7524712681770325\n",
      "Ep 39: Batch #83 - Loss: 1.3107103109359741\n",
      "Ep 39: Batch #84 - Loss: 0.5804786682128906\n",
      "Ep 39: Batch #85 - Loss: 0.7952123284339905\n",
      "Ep 39: Batch #86 - Loss: 0.5496141314506531\n",
      "Ep 39: Batch #87 - Loss: 0.5739062428474426\n",
      "Ep 39: Batch #88 - Loss: 0.6584701538085938\n",
      "Ep 39: Batch #89 - Loss: 0.7333714962005615\n",
      "Ep 39: Batch #90 - Loss: 0.9002447724342346\n",
      "Ep 39: Batch #91 - Loss: 0.6494976282119751\n",
      "Ep 39: Batch #92 - Loss: 0.7403258681297302\n",
      "Ep 39: Batch #93 - Loss: 0.7863359451293945\n",
      "Ep 39: Batch #94 - Loss: 0.7592572569847107\n",
      "Ep 39: Batch #95 - Loss: 0.7617790699005127\n",
      "Ep 39: Batch #96 - Loss: 0.7620000839233398\n",
      "Ep 39: Batch #97 - Loss: 0.5873082876205444\n",
      "Ep 39: Batch #98 - Loss: 0.579504668712616\n",
      "Ep 39: Batch #99 - Loss: 0.8028034567832947\n",
      "Ep 39: Batch #100 - Loss: 0.5594395399093628\n",
      "Ep 39: Batch #101 - Loss: 0.86455899477005\n",
      "Ep 39: Batch #102 - Loss: 0.614617645740509\n",
      "Ep 39: Batch #103 - Loss: 0.6393778324127197\n",
      "Ep 39: Batch #104 - Loss: 0.6621996164321899\n",
      "Ep 39: Batch #105 - Loss: 0.815458357334137\n",
      "Ep 39: Batch #106 - Loss: 0.6277570724487305\n",
      "Ep 39: Batch #107 - Loss: 0.6141649484634399\n",
      "Ep 39: Batch #108 - Loss: 0.902213990688324\n",
      "Ep 39: Batch #109 - Loss: 0.6270710825920105\n",
      "Ep 39: Batch #110 - Loss: 0.7280263304710388\n",
      "Ep 39: Batch #111 - Loss: 1.0451351404190063\n",
      "Ep 39: Batch #112 - Loss: 0.8028101325035095\n",
      "Ep 39: Batch #113 - Loss: 0.6598656177520752\n",
      "Ep 39: Batch #114 - Loss: 0.7297952175140381\n",
      "Ep 39: Batch #115 - Loss: 0.9064862728118896\n",
      "Ep 39: Batch #116 - Loss: 0.5235255360603333\n",
      "Ep 39: Batch #117 - Loss: 0.6813291311264038\n",
      "Ep 39: Batch #118 - Loss: 0.4575059413909912\n",
      "Model saved in file: ./weights_autoencoder_sigmoid/model_e39b118_1516648796.8445117.ckpt\n",
      "Ep 39: Batch #119 - Loss: 0.8086389303207397\n",
      "Ep 39: Batch #120 - Loss: 0.6620373129844666\n",
      "Ep 39: Batch #121 - Loss: 0.5633518099784851\n",
      "Ep 39: Batch #122 - Loss: 0.7130624651908875\n",
      "Ep 39: Batch #123 - Loss: 0.7201246619224548\n",
      "Ep 39: Batch #124 - Loss: 0.5574854016304016\n",
      "Ep 39: Batch #125 - Loss: 2.467848300933838\n",
      "Ep 39: Batch #126 - Loss: 0.9999398589134216\n",
      "Ep 39: Batch #127 - Loss: 0.5835334658622742\n",
      "Ep 39: Batch #128 - Loss: 0.884861946105957\n",
      "Ep 39: Batch #129 - Loss: 0.6791766285896301\n",
      "Ep 39: Batch #130 - Loss: 0.5969123840332031\n",
      "Ep 39: Batch #131 - Loss: 0.8061174750328064\n",
      "Ep 39: Batch #132 - Loss: 0.6855398416519165\n",
      "Ep 39: Batch #133 - Loss: 0.6684935688972473\n",
      "Ep 39: Batch #134 - Loss: 0.6382133364677429\n",
      "Ep 39: Batch #135 - Loss: 0.8243411183357239\n",
      "Ep 39: Batch #136 - Loss: 1.0410999059677124\n",
      "Ep 39: Batch #137 - Loss: 0.754806399345398\n",
      "Ep 39: Batch #138 - Loss: 0.9009954929351807\n",
      "Ep 39: Batch #139 - Loss: 0.6786584258079529\n",
      "Ep 39: Batch #140 - Loss: 0.846077024936676\n",
      "Ep 39: Batch #141 - Loss: 1.1317418813705444\n",
      "Ep 39: Batch #142 - Loss: 0.6720432043075562\n",
      "Ep 39: Batch #143 - Loss: 0.7717667818069458\n",
      "Ep 39: Batch #144 - Loss: 0.6123703122138977\n",
      "Ep 39: Batch #145 - Loss: 0.5995990037918091\n",
      "Ep 39: Batch #146 - Loss: 0.7059597373008728\n",
      "Ep 39: Batch #147 - Loss: 0.6696444153785706\n",
      "Ep 39: Batch #148 - Loss: 0.7585701942443848\n",
      "Ep 39: Batch #149 - Loss: 0.630317211151123\n",
      "Ep 39: Batch #150 - Loss: 0.7224625945091248\n",
      "Ep 39: Batch #151 - Loss: 0.630803644657135\n",
      "Ep 39: Batch #152 - Loss: 0.6094847321510315\n",
      "Ep 39: Batch #153 - Loss: 0.8303487300872803\n",
      "Ep 39: Batch #154 - Loss: 0.6344488859176636\n",
      "Ep 39: Batch #155 - Loss: 0.6939763426780701\n",
      "Ep 39: Batch #156 - Loss: 0.7932381629943848\n",
      "Ep 39: Batch #157 - Loss: 0.616183340549469\n",
      "Ep 39: Batch #158 - Loss: 0.7181175947189331\n",
      "Ep 39: Batch #159 - Loss: 0.6039662957191467\n",
      "Ep 39: Batch #160 - Loss: 0.7009701132774353\n",
      "Ep 39: Batch #161 - Loss: 0.6705388426780701\n",
      "Ep 39: Batch #162 - Loss: 0.7193951606750488\n",
      "Ep 39: Batch #163 - Loss: 0.760888934135437\n",
      "Ep 39: Batch #164 - Loss: 0.6496712565422058\n",
      "Ep 39: Batch #165 - Loss: 1.3427693843841553\n",
      "Ep 39: Batch #166 - Loss: 0.534454345703125\n",
      "Ep 39: Batch #167 - Loss: 0.741560697555542\n",
      "Ep 39: Batch #168 - Loss: 0.6935160160064697\n",
      "Ep 39: Batch #169 - Loss: 0.6695730686187744\n",
      "Ep 39: Batch #170 - Loss: 0.6298426985740662\n",
      "Ep 39: Batch #171 - Loss: 0.6419193148612976\n",
      "Ep 39: Batch #172 - Loss: 0.5347386598587036\n",
      "Ep 39: Batch #173 - Loss: 0.9311119318008423\n",
      "Ep 39: Batch #174 - Loss: 0.49725526571273804\n",
      "Ep 39: Batch #175 - Loss: 0.6393407583236694\n",
      "Ep 39: Batch #176 - Loss: 0.899036169052124\n",
      "Ep 39: Batch #177 - Loss: 0.6539487242698669\n",
      "Ep 39: Batch #178 - Loss: 0.6252536177635193\n",
      "Ep 39: Batch #179 - Loss: 0.7523232102394104\n",
      "Ep 39: Batch #180 - Loss: 0.6546057462692261\n",
      "Ep 39: Batch #181 - Loss: 0.8039999604225159\n",
      "Ep 39: Batch #182 - Loss: 0.6264791488647461\n",
      "Ep 39: Batch #183 - Loss: 0.6079781651496887\n",
      "Ep 39: Batch #184 - Loss: 0.9220177531242371\n",
      "Ep 39: Batch #185 - Loss: 0.6333558559417725\n",
      "Ep 39: Batch #186 - Loss: 0.7606093883514404\n",
      "Ep 39: Batch #187 - Loss: 0.8706668019294739\n",
      "Ep 39: Batch #188 - Loss: 0.9777315258979797\n",
      "Ep 39: Batch #189 - Loss: 0.588685154914856\n",
      "Ep 39: Batch #190 - Loss: 0.6249338388442993\n",
      "Ep 39: Batch #191 - Loss: 0.8112024068832397\n",
      "Ep 39: Batch #192 - Loss: 0.5712698698043823\n",
      "Ep 39: Batch #193 - Loss: 0.6301583051681519\n",
      "Ep 39: Batch #194 - Loss: 0.5465354323387146\n",
      "Ep 39: Batch #195 - Loss: 0.7931130528450012\n",
      "Ep 39: Batch #196 - Loss: 0.6929590702056885\n",
      "Ep 39: Batch #197 - Loss: 0.7020109295845032\n",
      "Ep 39: Batch #198 - Loss: 0.5346938967704773\n",
      "Ep 39: Batch #199 - Loss: 0.6463860273361206\n",
      "Ep 40: Batch #0 - Loss: 0.6507343053817749\n",
      "Ep 40: Batch #1 - Loss: 0.7150170803070068\n",
      "Ep 40: Batch #2 - Loss: 0.8608770370483398\n",
      "Ep 40: Batch #3 - Loss: 0.7237288951873779\n",
      "Ep 40: Batch #4 - Loss: 0.6583074927330017\n",
      "Ep 40: Batch #5 - Loss: 0.5618066191673279\n",
      "Ep 40: Batch #6 - Loss: 0.741447389125824\n",
      "Ep 40: Batch #7 - Loss: 0.5770010352134705\n",
      "Ep 40: Batch #8 - Loss: 0.5899676084518433\n",
      "Ep 40: Batch #9 - Loss: 1.0968986749649048\n",
      "Ep 40: Batch #10 - Loss: 0.8136648535728455\n",
      "Ep 40: Batch #11 - Loss: 0.5444901585578918\n",
      "Ep 40: Batch #12 - Loss: 1.2152044773101807\n",
      "Ep 40: Batch #13 - Loss: 0.572186291217804\n",
      "Ep 40: Batch #14 - Loss: 0.6018465161323547\n",
      "Ep 40: Batch #15 - Loss: 0.8652610182762146\n",
      "Ep 40: Batch #16 - Loss: 0.9542461037635803\n",
      "Ep 40: Batch #17 - Loss: 0.7304961681365967\n",
      "Ep 40: Batch #18 - Loss: 0.8081027269363403\n",
      "Ep 40: Batch #19 - Loss: 0.5643360018730164\n",
      "Ep 40: Batch #20 - Loss: 0.5474002957344055\n",
      "Ep 40: Batch #21 - Loss: 0.8449045419692993\n",
      "Ep 40: Batch #22 - Loss: 0.6120220422744751\n",
      "Ep 40: Batch #23 - Loss: 0.6014072895050049\n",
      "Ep 40: Batch #24 - Loss: 0.6396642923355103\n",
      "Ep 40: Batch #25 - Loss: 0.6092559099197388\n",
      "Ep 40: Batch #26 - Loss: 0.5618628263473511\n",
      "Ep 40: Batch #27 - Loss: 1.1439741849899292\n",
      "Ep 40: Batch #28 - Loss: 0.691710889339447\n",
      "Ep 40: Batch #29 - Loss: 0.7588339447975159\n",
      "Ep 40: Batch #30 - Loss: 0.8534510731697083\n",
      "Ep 40: Batch #31 - Loss: 0.562210738658905\n",
      "Ep 40: Batch #32 - Loss: 0.5822372436523438\n",
      "Ep 40: Batch #33 - Loss: 0.668848991394043\n",
      "Ep 40: Batch #34 - Loss: 0.6438196897506714\n",
      "Ep 40: Batch #35 - Loss: 0.7257410883903503\n",
      "Ep 40: Batch #36 - Loss: 0.5839508175849915\n",
      "Ep 40: Batch #37 - Loss: 0.9235053062438965\n",
      "Ep 40: Batch #38 - Loss: 0.5724577903747559\n",
      "Ep 40: Batch #39 - Loss: 0.6867642998695374\n",
      "Ep 40: Batch #40 - Loss: 0.6053555607795715\n",
      "Ep 40: Batch #41 - Loss: 0.6217641234397888\n",
      "Ep 40: Batch #42 - Loss: 0.5709505081176758\n",
      "Ep 40: Batch #43 - Loss: 0.6338469982147217\n",
      "Ep 40: Batch #44 - Loss: 0.6159493923187256\n",
      "Ep 40: Batch #45 - Loss: 0.5280147194862366\n",
      "Ep 40: Batch #46 - Loss: 0.6977893710136414\n",
      "Ep 40: Batch #47 - Loss: 0.8058067560195923\n",
      "Ep 40: Batch #48 - Loss: 1.0413577556610107\n",
      "Ep 40: Batch #49 - Loss: 0.8138574361801147\n",
      "Ep 40: Batch #50 - Loss: 0.5739138126373291\n",
      "Ep 40: Batch #51 - Loss: 0.8193592429161072\n",
      "Ep 40: Batch #52 - Loss: 0.6778531670570374\n",
      "Ep 40: Batch #53 - Loss: 0.7172165513038635\n",
      "Ep 40: Batch #54 - Loss: 0.5806704163551331\n",
      "Ep 40: Batch #55 - Loss: 0.6092770099639893\n",
      "Ep 40: Batch #56 - Loss: 0.8649255633354187\n",
      "Ep 40: Batch #57 - Loss: 0.6832929253578186\n",
      "Ep 40: Batch #58 - Loss: 0.8292170763015747\n",
      "Ep 40: Batch #59 - Loss: 0.5627485513687134\n",
      "Ep 40: Batch #60 - Loss: 1.0139362812042236\n",
      "Ep 40: Batch #61 - Loss: 0.5352842211723328\n",
      "Ep 40: Batch #62 - Loss: 0.5759940147399902\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 40: Batch #63 - Loss: 0.7878427505493164\n",
      "Ep 40: Batch #64 - Loss: 8.568543434143066\n",
      "Ep 40: Batch #65 - Loss: 0.5256023406982422\n",
      "Ep 40: Batch #66 - Loss: 0.6662692427635193\n",
      "Ep 40: Batch #67 - Loss: 0.7764861583709717\n",
      "Ep 40: Batch #68 - Loss: 0.7169826626777649\n",
      "Ep 40: Batch #69 - Loss: 0.5914955735206604\n",
      "Ep 40: Batch #70 - Loss: 0.6183879971504211\n",
      "Ep 40: Batch #71 - Loss: 0.5380591750144958\n",
      "Ep 40: Batch #72 - Loss: 0.6638184189796448\n",
      "Ep 40: Batch #73 - Loss: 0.7269534468650818\n",
      "Ep 40: Batch #74 - Loss: 0.5824573636054993\n",
      "Ep 40: Batch #75 - Loss: 0.6699031591415405\n",
      "Ep 40: Batch #76 - Loss: 0.9306280612945557\n",
      "Ep 40: Batch #77 - Loss: 0.5786424875259399\n",
      "Ep 40: Batch #78 - Loss: 0.9247485399246216\n",
      "Ep 40: Batch #79 - Loss: 0.5271337032318115\n",
      "Ep 40: Batch #80 - Loss: 0.6946990489959717\n",
      "Ep 40: Batch #81 - Loss: 1.5275261402130127\n",
      "Ep 40: Batch #82 - Loss: 0.7515831589698792\n",
      "Ep 40: Batch #83 - Loss: 1.3060991764068604\n",
      "Ep 40: Batch #84 - Loss: 0.5797746181488037\n",
      "Ep 40: Batch #85 - Loss: 0.7911859154701233\n",
      "Ep 40: Batch #86 - Loss: 0.5493319034576416\n",
      "Ep 40: Batch #87 - Loss: 0.573762059211731\n",
      "Ep 40: Batch #88 - Loss: 0.6583113074302673\n",
      "Ep 40: Batch #89 - Loss: 0.7324678897857666\n",
      "Ep 40: Batch #90 - Loss: 0.9001526236534119\n",
      "Ep 40: Batch #91 - Loss: 0.6494777202606201\n",
      "Ep 40: Batch #92 - Loss: 0.7379196882247925\n",
      "Ep 40: Batch #93 - Loss: 0.7860743999481201\n",
      "Ep 40: Batch #94 - Loss: 0.7581235766410828\n",
      "Ep 40: Batch #95 - Loss: 0.7611421346664429\n",
      "Ep 40: Batch #96 - Loss: 0.7603476047515869\n",
      "Ep 40: Batch #97 - Loss: 0.5877675414085388\n",
      "Ep 40: Batch #98 - Loss: 0.5797447562217712\n",
      "Ep 40: Batch #99 - Loss: 0.8027927875518799\n",
      "Ep 40: Batch #100 - Loss: 0.5591893792152405\n",
      "Ep 40: Batch #101 - Loss: 0.8639920949935913\n",
      "Ep 40: Batch #102 - Loss: 0.6144862174987793\n",
      "Ep 40: Batch #103 - Loss: 0.6390469670295715\n",
      "Ep 40: Batch #104 - Loss: 0.661906898021698\n",
      "Ep 40: Batch #105 - Loss: 0.8154887557029724\n",
      "Ep 40: Batch #106 - Loss: 0.6273678541183472\n",
      "Ep 40: Batch #107 - Loss: 0.6144795417785645\n",
      "Ep 40: Batch #108 - Loss: 0.9025481939315796\n",
      "Ep 40: Batch #109 - Loss: 0.626516580581665\n",
      "Ep 40: Batch #110 - Loss: 0.7275957465171814\n",
      "Ep 40: Batch #111 - Loss: 1.0448006391525269\n",
      "Ep 40: Batch #112 - Loss: 0.8021646738052368\n",
      "Ep 40: Batch #113 - Loss: 0.6593424081802368\n",
      "Ep 40: Batch #114 - Loss: 0.729671835899353\n",
      "Ep 40: Batch #115 - Loss: 0.906501054763794\n",
      "Ep 40: Batch #116 - Loss: 0.5231263637542725\n",
      "Ep 40: Batch #117 - Loss: 0.6812695264816284\n",
      "Ep 40: Batch #118 - Loss: 0.45762428641319275\n",
      "Ep 40: Batch #119 - Loss: 0.8091827630996704\n",
      "Ep 40: Batch #120 - Loss: 0.6613960266113281\n",
      "Ep 40: Batch #121 - Loss: 0.5632416009902954\n",
      "Ep 40: Batch #122 - Loss: 0.7133987545967102\n",
      "Ep 40: Batch #123 - Loss: 0.7199739813804626\n",
      "Ep 40: Batch #124 - Loss: 0.5573821663856506\n",
      "Ep 40: Batch #125 - Loss: 2.4680075645446777\n",
      "Ep 40: Batch #126 - Loss: 0.9997289776802063\n",
      "Ep 40: Batch #127 - Loss: 0.5835762619972229\n",
      "Ep 40: Batch #128 - Loss: 0.8849033713340759\n",
      "Ep 40: Batch #129 - Loss: 0.6788835525512695\n",
      "Ep 40: Batch #130 - Loss: 0.5966892242431641\n",
      "Ep 40: Batch #131 - Loss: 0.8063589930534363\n",
      "Ep 40: Batch #132 - Loss: 0.685661792755127\n",
      "Ep 40: Batch #133 - Loss: 0.6683154106140137\n",
      "Ep 40: Batch #134 - Loss: 0.6377032399177551\n",
      "Ep 40: Batch #135 - Loss: 0.8233978152275085\n",
      "Ep 40: Batch #136 - Loss: 1.0413589477539062\n",
      "Ep 40: Batch #137 - Loss: 0.7548605799674988\n",
      "Ep 40: Batch #138 - Loss: 0.9009121656417847\n",
      "Ep 40: Batch #139 - Loss: 0.6781423091888428\n",
      "Ep 40: Batch #140 - Loss: 0.8459850549697876\n",
      "Ep 40: Batch #141 - Loss: 1.1316115856170654\n",
      "Ep 40: Batch #142 - Loss: 0.6718540787696838\n",
      "Ep 40: Batch #143 - Loss: 0.7715283036231995\n",
      "Ep 40: Batch #144 - Loss: 0.6122956275939941\n",
      "Ep 40: Batch #145 - Loss: 0.5995391011238098\n",
      "Ep 40: Batch #146 - Loss: 0.7057496905326843\n",
      "Ep 40: Batch #147 - Loss: 0.6695622205734253\n",
      "Ep 40: Batch #148 - Loss: 0.7584023475646973\n",
      "Ep 40: Batch #149 - Loss: 0.6293756365776062\n",
      "Ep 40: Batch #150 - Loss: 0.7222253084182739\n",
      "Ep 40: Batch #151 - Loss: 0.630350649356842\n",
      "Ep 40: Batch #152 - Loss: 0.6090266108512878\n",
      "Ep 40: Batch #153 - Loss: 0.8301113843917847\n",
      "Ep 40: Batch #154 - Loss: 0.6341795921325684\n",
      "Ep 40: Batch #155 - Loss: 0.6919800639152527\n",
      "Ep 40: Batch #156 - Loss: 0.792518675327301\n",
      "Ep 40: Batch #157 - Loss: 0.6158005595207214\n",
      "Ep 40: Batch #158 - Loss: 0.718098521232605\n",
      "Ep 40: Batch #159 - Loss: 0.6035454869270325\n",
      "Ep 40: Batch #160 - Loss: 0.7005293965339661\n",
      "Ep 40: Batch #161 - Loss: 0.6702188849449158\n",
      "Ep 40: Batch #162 - Loss: 0.7194230556488037\n",
      "Ep 40: Batch #163 - Loss: 0.7607613801956177\n",
      "Ep 40: Batch #164 - Loss: 0.649437665939331\n",
      "Ep 40: Batch #165 - Loss: 1.342586636543274\n",
      "Ep 40: Batch #166 - Loss: 0.5343564748764038\n",
      "Ep 40: Batch #167 - Loss: 0.7405704855918884\n",
      "Ep 40: Batch #168 - Loss: 0.6929588317871094\n",
      "Ep 40: Batch #169 - Loss: 0.6690899133682251\n",
      "Ep 40: Batch #170 - Loss: 0.6299494504928589\n",
      "Ep 40: Batch #171 - Loss: 0.6418384909629822\n",
      "Ep 40: Batch #172 - Loss: 0.534672737121582\n",
      "Ep 40: Batch #173 - Loss: 0.9312450885772705\n",
      "Ep 40: Batch #174 - Loss: 0.49690043926239014\n",
      "Ep 40: Batch #175 - Loss: 0.6391826868057251\n",
      "Ep 40: Batch #176 - Loss: 0.898478627204895\n",
      "Ep 40: Batch #177 - Loss: 0.653639018535614\n",
      "Ep 40: Batch #178 - Loss: 0.6250306367874146\n",
      "Ep 40: Batch #179 - Loss: 0.7510470747947693\n",
      "Ep 40: Batch #180 - Loss: 0.6542260050773621\n",
      "Ep 40: Batch #181 - Loss: 0.8039645552635193\n",
      "Ep 40: Batch #182 - Loss: 0.6264966726303101\n",
      "Ep 40: Batch #183 - Loss: 0.6077051758766174\n",
      "Ep 40: Batch #184 - Loss: 0.9220380187034607\n",
      "Ep 40: Batch #185 - Loss: 0.6332746148109436\n",
      "Ep 40: Batch #186 - Loss: 0.7603898644447327\n",
      "Ep 40: Batch #187 - Loss: 0.8701385855674744\n",
      "Ep 40: Batch #188 - Loss: 0.9763840436935425\n",
      "Ep 40: Batch #189 - Loss: 0.5884875655174255\n",
      "Ep 40: Batch #190 - Loss: 0.6244826316833496\n",
      "Ep 40: Batch #191 - Loss: 0.8109300136566162\n",
      "Ep 40: Batch #192 - Loss: 0.5713002681732178\n",
      "Ep 40: Batch #193 - Loss: 0.6301256418228149\n",
      "Ep 40: Batch #194 - Loss: 0.5463890433311462\n",
      "Ep 40: Batch #195 - Loss: 0.7928580045700073\n",
      "Ep 40: Batch #196 - Loss: 0.6929429769515991\n",
      "Ep 40: Batch #197 - Loss: 0.7021644115447998\n",
      "Ep 40: Batch #198 - Loss: 0.5345402956008911\n",
      "Ep 40: Batch #199 - Loss: 0.6463253498077393\n",
      "Ep 41: Batch #0 - Loss: 0.6504824757575989\n",
      "Ep 41: Batch #1 - Loss: 0.7150431871414185\n",
      "Ep 41: Batch #2 - Loss: 0.8606142401695251\n",
      "Ep 41: Batch #3 - Loss: 0.7236783504486084\n",
      "Ep 41: Batch #4 - Loss: 0.6581680178642273\n",
      "Ep 41: Batch #5 - Loss: 0.5617503523826599\n",
      "Ep 41: Batch #6 - Loss: 0.74116051197052\n",
      "Ep 41: Batch #7 - Loss: 0.5769625306129456\n",
      "Ep 41: Batch #8 - Loss: 0.589760422706604\n",
      "Ep 41: Batch #9 - Loss: 1.0970624685287476\n",
      "Ep 41: Batch #10 - Loss: 0.8135078549385071\n",
      "Ep 41: Batch #11 - Loss: 0.5444072484970093\n",
      "Ep 41: Batch #12 - Loss: 1.2142573595046997\n",
      "Ep 41: Batch #13 - Loss: 0.572162926197052\n",
      "Ep 41: Batch #14 - Loss: 0.6017538905143738\n",
      "Ep 41: Batch #15 - Loss: 0.8638535737991333\n",
      "Ep 41: Batch #16 - Loss: 0.9541505575180054\n",
      "Ep 41: Batch #17 - Loss: 0.7303750514984131\n",
      "Ep 41: Batch #18 - Loss: 0.8080816864967346\n",
      "Ep 41: Batch #19 - Loss: 0.5641194581985474\n",
      "Ep 41: Batch #20 - Loss: 0.5474226474761963\n",
      "Ep 41: Batch #21 - Loss: 0.8424849510192871\n",
      "Ep 41: Batch #22 - Loss: 0.6118189096450806\n",
      "Ep 41: Batch #23 - Loss: 0.6011060476303101\n",
      "Ep 41: Batch #24 - Loss: 0.6393383145332336\n",
      "Ep 41: Batch #25 - Loss: 0.6091693043708801\n",
      "Ep 41: Batch #26 - Loss: 0.5616216659545898\n",
      "Ep 41: Batch #27 - Loss: 1.1437246799468994\n",
      "Ep 41: Batch #28 - Loss: 0.6915319561958313\n",
      "Ep 41: Batch #29 - Loss: 0.7585216164588928\n",
      "Ep 41: Batch #30 - Loss: 0.8519055843353271\n",
      "Ep 41: Batch #31 - Loss: 0.5621116757392883\n",
      "Ep 41: Batch #32 - Loss: 0.5821825861930847\n",
      "Ep 41: Batch #33 - Loss: 0.668588399887085\n",
      "Ep 41: Batch #34 - Loss: 0.6431010365486145\n",
      "Ep 41: Batch #35 - Loss: 0.7255298495292664\n",
      "Ep 41: Batch #36 - Loss: 0.5835973620414734\n",
      "Ep 41: Batch #37 - Loss: 0.9235976934432983\n",
      "Ep 41: Batch #38 - Loss: 0.5722277760505676\n",
      "Ep 41: Batch #39 - Loss: 0.6866235136985779\n",
      "Ep 41: Batch #40 - Loss: 0.6053473353385925\n",
      "Ep 41: Batch #41 - Loss: 0.6216059923171997\n",
      "Ep 41: Batch #42 - Loss: 0.5707924365997314\n",
      "Ep 41: Batch #43 - Loss: 0.633720338344574\n",
      "Ep 41: Batch #44 - Loss: 0.6158581972122192\n",
      "Ep 41: Batch #45 - Loss: 0.5280634164810181\n",
      "Ep 41: Batch #46 - Loss: 0.6977767944335938\n",
      "Ep 41: Batch #47 - Loss: 0.8058302402496338\n",
      "Ep 41: Batch #48 - Loss: 1.0414838790893555\n",
      "Ep 41: Batch #49 - Loss: 0.8137471675872803\n",
      "Ep 41: Batch #50 - Loss: 0.5739003419876099\n",
      "Ep 41: Batch #51 - Loss: 0.8195211887359619\n",
      "Ep 41: Batch #52 - Loss: 0.6777334809303284\n",
      "Ep 41: Batch #53 - Loss: 0.7172239422798157\n",
      "Ep 41: Batch #54 - Loss: 0.5805376768112183\n",
      "Ep 41: Batch #55 - Loss: 0.6093999147415161\n",
      "Ep 41: Batch #56 - Loss: 0.8647730350494385\n",
      "Ep 41: Batch #57 - Loss: 0.6831453442573547\n",
      "Ep 41: Batch #58 - Loss: 0.8288825154304504\n",
      "Ep 41: Batch #59 - Loss: 0.5624383091926575\n",
      "Ep 41: Batch #60 - Loss: 1.013552188873291\n",
      "Ep 41: Batch #61 - Loss: 0.5353856086730957\n",
      "Ep 41: Batch #62 - Loss: 0.5758784413337708\n",
      "Ep 41: Batch #63 - Loss: 0.7876620888710022\n",
      "Ep 41: Batch #64 - Loss: 8.547934532165527\n",
      "Ep 41: Batch #65 - Loss: 0.5256503820419312\n",
      "Ep 41: Batch #66 - Loss: 0.6664019227027893\n",
      "Ep 41: Batch #67 - Loss: 0.7765021920204163\n",
      "Ep 41: Batch #68 - Loss: 0.7175471186637878\n",
      "Ep 41: Batch #69 - Loss: 0.5916815996170044\n",
      "Ep 41: Batch #70 - Loss: 0.6192642450332642\n",
      "Ep 41: Batch #71 - Loss: 0.5382972955703735\n",
      "Ep 41: Batch #72 - Loss: 0.6646100282669067\n",
      "Ep 41: Batch #73 - Loss: 0.7269759774208069\n",
      "Ep 41: Batch #74 - Loss: 0.5822108387947083\n",
      "Ep 41: Batch #75 - Loss: 0.6701011061668396\n",
      "Ep 41: Batch #76 - Loss: 0.9302189946174622\n",
      "Ep 41: Batch #77 - Loss: 0.5784600377082825\n",
      "Ep 41: Batch #78 - Loss: 0.9240995645523071\n",
      "Ep 41: Batch #79 - Loss: 0.5272551774978638\n",
      "Ep 41: Batch #80 - Loss: 0.6946335434913635\n",
      "Ep 41: Batch #81 - Loss: 1.5265480279922485\n",
      "Ep 41: Batch #82 - Loss: 0.7514879703521729\n",
      "Ep 41: Batch #83 - Loss: 1.3029247522354126\n",
      "Ep 41: Batch #84 - Loss: 0.5808602571487427\n",
      "Ep 41: Batch #85 - Loss: 0.7912339568138123\n",
      "Ep 41: Batch #86 - Loss: 0.5494595170021057\n",
      "Ep 41: Batch #87 - Loss: 0.5740809440612793\n",
      "Ep 41: Batch #88 - Loss: 0.6586441993713379\n",
      "Ep 41: Batch #89 - Loss: 0.7325388789176941\n",
      "Ep 41: Batch #90 - Loss: 0.9003170132637024\n",
      "Ep 41: Batch #91 - Loss: 0.6496264934539795\n",
      "Ep 41: Batch #92 - Loss: 0.7378721833229065\n",
      "Ep 41: Batch #93 - Loss: 0.7861416339874268\n",
      "Ep 41: Batch #94 - Loss: 0.7571761608123779\n",
      "Ep 41: Batch #95 - Loss: 0.7613790035247803\n",
      "Ep 41: Batch #96 - Loss: 0.7609713673591614\n",
      "Ep 41: Batch #97 - Loss: 0.5881538391113281\n",
      "Ep 41: Batch #98 - Loss: 0.5796216130256653\n",
      "Ep 41: Batch #99 - Loss: 0.8025469183921814\n",
      "Ep 41: Batch #100 - Loss: 0.5591402053833008\n",
      "Ep 41: Batch #101 - Loss: 0.8637381792068481\n",
      "Ep 41: Batch #102 - Loss: 0.6143706440925598\n",
      "Ep 41: Batch #103 - Loss: 0.6388753652572632\n",
      "Ep 41: Batch #104 - Loss: 0.6620150208473206\n",
      "Ep 41: Batch #105 - Loss: 0.8160988092422485\n",
      "Ep 41: Batch #106 - Loss: 0.6278721690177917\n",
      "Ep 41: Batch #107 - Loss: 0.6145755052566528\n",
      "Ep 41: Batch #108 - Loss: 0.902313768863678\n",
      "Ep 41: Batch #109 - Loss: 0.6265450716018677\n",
      "Ep 41: Batch #110 - Loss: 0.7274670004844666\n",
      "Ep 41: Batch #111 - Loss: 1.0446771383285522\n",
      "Ep 41: Batch #112 - Loss: 0.8020022511482239\n",
      "Ep 41: Batch #113 - Loss: 0.6591683030128479\n",
      "Ep 41: Batch #114 - Loss: 0.7299346327781677\n",
      "Ep 41: Batch #115 - Loss: 0.906851589679718\n",
      "Ep 41: Batch #116 - Loss: 0.523120641708374\n",
      "Ep 41: Batch #117 - Loss: 0.6812810301780701\n",
      "Ep 41: Batch #118 - Loss: 0.45767703652381897\n",
      "Ep 41: Batch #119 - Loss: 0.8091173768043518\n",
      "Ep 41: Batch #120 - Loss: 0.6611683368682861\n",
      "Ep 41: Batch #121 - Loss: 0.5631301403045654\n",
      "Ep 41: Batch #122 - Loss: 0.7135006785392761\n",
      "Ep 41: Batch #123 - Loss: 0.7201217412948608\n",
      "Ep 41: Batch #124 - Loss: 0.5575195550918579\n",
      "Ep 41: Batch #125 - Loss: 2.4679811000823975\n",
      "Ep 41: Batch #126 - Loss: 0.9992232918739319\n",
      "Ep 41: Batch #127 - Loss: 0.5838367938995361\n",
      "Ep 41: Batch #128 - Loss: 0.8846452832221985\n",
      "Ep 41: Batch #129 - Loss: 0.6787712574005127\n",
      "Ep 41: Batch #130 - Loss: 0.5965051651000977\n",
      "Ep 41: Batch #131 - Loss: 0.806213915348053\n",
      "Ep 41: Batch #132 - Loss: 0.6854535341262817\n",
      "Ep 41: Batch #133 - Loss: 0.66801917552948\n",
      "Ep 41: Batch #134 - Loss: 0.6374270915985107\n",
      "Ep 41: Batch #135 - Loss: 0.8229043483734131\n",
      "Ep 41: Batch #136 - Loss: 1.0417537689208984\n",
      "Ep 41: Batch #137 - Loss: 0.7549861669540405\n",
      "Ep 41: Batch #138 - Loss: 0.900605320930481\n",
      "Ep 41: Batch #139 - Loss: 0.6783006191253662\n",
      "Ep 41: Batch #140 - Loss: 0.8458095192909241\n",
      "Ep 41: Batch #141 - Loss: 1.1316475868225098\n",
      "Ep 41: Batch #142 - Loss: 0.6717075109481812\n",
      "Ep 41: Batch #143 - Loss: 0.7718549370765686\n",
      "Ep 41: Batch #144 - Loss: 0.6123414039611816\n",
      "Ep 41: Batch #145 - Loss: 0.5997606515884399\n",
      "Ep 41: Batch #146 - Loss: 0.7057798504829407\n",
      "Ep 41: Batch #147 - Loss: 0.6696091890335083\n",
      "Ep 41: Batch #148 - Loss: 0.7577387690544128\n",
      "Ep 41: Batch #149 - Loss: 0.6289542317390442\n",
      "Ep 41: Batch #150 - Loss: 0.7215578556060791\n",
      "Ep 41: Batch #151 - Loss: 0.6300095915794373\n",
      "Ep 41: Batch #152 - Loss: 0.6086385250091553\n",
      "Ep 41: Batch #153 - Loss: 0.8299439549446106\n",
      "Ep 41: Batch #154 - Loss: 0.6339631080627441\n",
      "Ep 41: Batch #155 - Loss: 0.692359209060669\n",
      "Ep 41: Batch #156 - Loss: 0.7920471429824829\n",
      "Ep 41: Batch #157 - Loss: 0.6154952049255371\n",
      "Ep 41: Batch #158 - Loss: 0.7180852890014648\n",
      "Ep 41: Batch #159 - Loss: 0.6033607721328735\n",
      "Ep 41: Batch #160 - Loss: 0.7002317905426025\n",
      "Ep 41: Batch #161 - Loss: 0.6701498031616211\n",
      "Ep 41: Batch #162 - Loss: 0.7196449041366577\n",
      "Ep 41: Batch #163 - Loss: 0.7605277895927429\n",
      "Ep 41: Batch #164 - Loss: 0.649371325969696\n",
      "Ep 41: Batch #165 - Loss: 1.3428049087524414\n",
      "Ep 41: Batch #166 - Loss: 0.5342238545417786\n",
      "Ep 41: Batch #167 - Loss: 0.7394343614578247\n",
      "Ep 41: Batch #168 - Loss: 0.6929798722267151\n",
      "Ep 41: Batch #169 - Loss: 0.6687152981758118\n",
      "Ep 41: Batch #170 - Loss: 0.6298854351043701\n",
      "Ep 41: Batch #171 - Loss: 0.6419231295585632\n",
      "Ep 41: Batch #172 - Loss: 0.5348318815231323\n",
      "Ep 41: Batch #173 - Loss: 0.9310523271560669\n",
      "Ep 41: Batch #174 - Loss: 0.4973641037940979\n",
      "Ep 41: Batch #175 - Loss: 0.6389222145080566\n",
      "Ep 41: Batch #176 - Loss: 0.8978302478790283\n",
      "Ep 41: Batch #177 - Loss: 0.6535294055938721\n",
      "Ep 41: Batch #178 - Loss: 0.6250306963920593\n",
      "Ep 41: Batch #179 - Loss: 0.7511528134346008\n",
      "Ep 41: Batch #180 - Loss: 0.6541597843170166\n",
      "Ep 41: Batch #181 - Loss: 0.8039678335189819\n",
      "Ep 41: Batch #182 - Loss: 0.6265449523925781\n",
      "Ep 41: Batch #183 - Loss: 0.6074099540710449\n",
      "Ep 41: Batch #184 - Loss: 0.922172486782074\n",
      "Ep 41: Batch #185 - Loss: 0.6333296895027161\n",
      "Ep 41: Batch #186 - Loss: 0.7601606845855713\n",
      "Ep 41: Batch #187 - Loss: 0.8702414631843567\n",
      "Ep 41: Batch #188 - Loss: 0.9754005670547485\n",
      "Ep 41: Batch #189 - Loss: 0.5884536504745483\n",
      "Ep 41: Batch #190 - Loss: 0.6244087815284729\n",
      "Ep 41: Batch #191 - Loss: 0.8109103441238403\n",
      "Ep 41: Batch #192 - Loss: 0.5715158581733704\n",
      "Ep 41: Batch #193 - Loss: 0.6302981376647949\n",
      "Ep 41: Batch #194 - Loss: 0.5464156270027161\n",
      "Ep 41: Batch #195 - Loss: 0.7927271127700806\n",
      "Ep 41: Batch #196 - Loss: 0.6931191682815552\n",
      "Ep 41: Batch #197 - Loss: 0.7023590207099915\n",
      "Ep 41: Batch #198 - Loss: 0.5346162915229797\n",
      "Ep 41: Batch #199 - Loss: 0.6463181376457214\n",
      "Ep 42: Batch #0 - Loss: 0.6505230665206909\n",
      "Ep 42: Batch #1 - Loss: 0.714995801448822\n",
      "Ep 42: Batch #2 - Loss: 0.8605452179908752\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 42: Batch #3 - Loss: 0.7238887548446655\n",
      "Ep 42: Batch #4 - Loss: 0.6580182313919067\n",
      "Ep 42: Batch #5 - Loss: 0.5616685152053833\n",
      "Ep 42: Batch #6 - Loss: 0.7408538460731506\n",
      "Ep 42: Batch #7 - Loss: 0.576978325843811\n",
      "Ep 42: Batch #8 - Loss: 0.5895454287528992\n",
      "Ep 42: Batch #9 - Loss: 1.0970474481582642\n",
      "Ep 42: Batch #10 - Loss: 0.8131605982780457\n",
      "Ep 42: Batch #11 - Loss: 0.5443337559700012\n",
      "Ep 42: Batch #12 - Loss: 1.2135454416275024\n",
      "Ep 42: Batch #13 - Loss: 0.5721918344497681\n",
      "Ep 42: Batch #14 - Loss: 0.6017071604728699\n",
      "Ep 42: Batch #15 - Loss: 0.8623716235160828\n",
      "Ep 42: Batch #16 - Loss: 0.95452880859375\n",
      "Ep 42: Batch #17 - Loss: 0.7303835153579712\n",
      "Ep 42: Batch #18 - Loss: 0.8082481026649475\n",
      "Ep 42: Batch #19 - Loss: 0.5642688274383545\n",
      "Ep 42: Batch #20 - Loss: 0.5475460290908813\n",
      "Ep 42: Batch #21 - Loss: 0.8409105539321899\n",
      "Ep 42: Batch #22 - Loss: 0.6117326021194458\n",
      "Ep 42: Batch #23 - Loss: 0.6011239886283875\n",
      "Ep 42: Batch #24 - Loss: 0.639294445514679\n",
      "Ep 42: Batch #25 - Loss: 0.6090691089630127\n",
      "Ep 42: Batch #26 - Loss: 0.561866044998169\n",
      "Ep 42: Batch #27 - Loss: 1.143853783607483\n",
      "Ep 42: Batch #28 - Loss: 0.6914680004119873\n",
      "Ep 42: Batch #29 - Loss: 0.7584006190299988\n",
      "Ep 42: Batch #30 - Loss: 0.8501155972480774\n",
      "Ep 42: Batch #31 - Loss: 0.5621709823608398\n",
      "Ep 42: Batch #32 - Loss: 0.5821572542190552\n",
      "Ep 42: Batch #33 - Loss: 0.6684896349906921\n",
      "Ep 42: Batch #34 - Loss: 0.6427649855613708\n",
      "Ep 42: Batch #35 - Loss: 0.7255116105079651\n",
      "Ep 42: Batch #36 - Loss: 0.5834521651268005\n",
      "Ep 42: Batch #37 - Loss: 0.9238621592521667\n",
      "Ep 42: Batch #38 - Loss: 0.5720487833023071\n",
      "Ep 42: Batch #39 - Loss: 0.6866183876991272\n",
      "Ep 42: Batch #40 - Loss: 0.605411946773529\n",
      "Ep 42: Batch #41 - Loss: 0.6215522885322571\n",
      "Ep 42: Batch #42 - Loss: 0.5707305669784546\n",
      "Ep 42: Batch #43 - Loss: 0.6337617635726929\n",
      "Ep 42: Batch #44 - Loss: 0.6156134009361267\n",
      "Ep 42: Batch #45 - Loss: 0.5280045866966248\n",
      "Ep 42: Batch #46 - Loss: 0.6978644728660583\n",
      "Ep 42: Batch #47 - Loss: 0.8059370517730713\n",
      "Ep 42: Batch #48 - Loss: 1.041380763053894\n",
      "Ep 42: Batch #49 - Loss: 0.8135905861854553\n",
      "Ep 42: Batch #50 - Loss: 0.5739825367927551\n",
      "Ep 42: Batch #51 - Loss: 0.8193422555923462\n",
      "Ep 42: Batch #52 - Loss: 0.6776715517044067\n",
      "Ep 42: Batch #53 - Loss: 0.7172013521194458\n",
      "Ep 42: Batch #54 - Loss: 0.5803425312042236\n",
      "Ep 42: Batch #55 - Loss: 0.609150230884552\n",
      "Ep 42: Batch #56 - Loss: 0.8641376495361328\n",
      "Ep 42: Batch #57 - Loss: 0.682862401008606\n",
      "Ep 42: Batch #58 - Loss: 0.8287925124168396\n",
      "Ep 42: Batch #59 - Loss: 0.5619407296180725\n",
      "Ep 42: Batch #60 - Loss: 1.013551115989685\n",
      "Ep 42: Batch #61 - Loss: 0.5354706645011902\n",
      "Ep 42: Batch #62 - Loss: 0.5754631161689758\n",
      "Ep 42: Batch #63 - Loss: 0.7873386144638062\n",
      "Ep 42: Batch #64 - Loss: 8.553703308105469\n",
      "Ep 42: Batch #65 - Loss: 0.5257641077041626\n",
      "Ep 42: Batch #66 - Loss: 0.666045606136322\n",
      "Ep 42: Batch #67 - Loss: 0.7766221761703491\n",
      "Ep 42: Batch #68 - Loss: 0.7162691354751587\n",
      "Ep 42: Batch #69 - Loss: 0.591079831123352\n",
      "Ep 42: Batch #70 - Loss: 0.6173126101493835\n",
      "Ep 42: Batch #71 - Loss: 0.5376038551330566\n",
      "Ep 42: Batch #72 - Loss: 0.6646655797958374\n",
      "Ep 42: Batch #73 - Loss: 0.7270491123199463\n",
      "Ep 42: Batch #74 - Loss: 0.5826032757759094\n",
      "Ep 42: Batch #75 - Loss: 0.6700711846351624\n",
      "Ep 42: Batch #76 - Loss: 0.9323634505271912\n",
      "Ep 42: Batch #77 - Loss: 0.5783997178077698\n",
      "Ep 42: Batch #78 - Loss: 0.9251305460929871\n",
      "Ep 42: Batch #79 - Loss: 0.5270460844039917\n",
      "Ep 42: Batch #80 - Loss: 0.6953580379486084\n",
      "Ep 42: Batch #81 - Loss: 1.527919888496399\n",
      "Ep 42: Batch #82 - Loss: 0.7536386251449585\n",
      "Ep 42: Batch #83 - Loss: 1.298855185508728\n",
      "Ep 42: Batch #84 - Loss: 0.5805758237838745\n",
      "Ep 42: Batch #85 - Loss: 0.7951049208641052\n",
      "Ep 42: Batch #86 - Loss: 0.549450695514679\n",
      "Ep 42: Batch #87 - Loss: 0.5740470886230469\n",
      "Ep 42: Batch #88 - Loss: 0.6593130230903625\n",
      "Ep 42: Batch #89 - Loss: 0.7333335280418396\n",
      "Ep 42: Batch #90 - Loss: 0.9007164835929871\n",
      "Ep 42: Batch #91 - Loss: 0.6497950553894043\n",
      "Ep 42: Batch #92 - Loss: 0.7375757098197937\n",
      "Ep 42: Batch #93 - Loss: 0.7863468527793884\n",
      "Ep 42: Batch #94 - Loss: 0.7576245069503784\n",
      "Ep 42: Batch #95 - Loss: 0.7628320455551147\n",
      "Ep 42: Batch #96 - Loss: 0.7629594802856445\n",
      "Ep 42: Batch #97 - Loss: 0.5885782837867737\n",
      "Ep 42: Batch #98 - Loss: 0.5805720090866089\n",
      "Ep 42: Batch #99 - Loss: 0.8040990233421326\n",
      "Ep 42: Batch #100 - Loss: 0.5594386458396912\n",
      "Ep 42: Batch #101 - Loss: 0.8656186461448669\n",
      "Ep 42: Batch #102 - Loss: 0.614120364189148\n",
      "Ep 42: Batch #103 - Loss: 0.63898104429245\n",
      "Ep 42: Batch #104 - Loss: 0.6620924472808838\n",
      "Ep 42: Batch #105 - Loss: 0.8154827952384949\n",
      "Ep 42: Batch #106 - Loss: 0.6283084750175476\n",
      "Ep 42: Batch #107 - Loss: 0.6146568059921265\n",
      "Ep 42: Batch #108 - Loss: 0.9023199677467346\n",
      "Ep 42: Batch #109 - Loss: 0.6276142597198486\n",
      "Ep 42: Batch #110 - Loss: 0.7273935079574585\n",
      "Ep 42: Batch #111 - Loss: 1.0445631742477417\n",
      "Ep 42: Batch #112 - Loss: 0.8012091517448425\n",
      "Ep 42: Batch #113 - Loss: 0.6600454449653625\n",
      "Ep 42: Batch #114 - Loss: 0.7301680445671082\n",
      "Ep 42: Batch #115 - Loss: 0.9069873094558716\n",
      "Ep 42: Batch #116 - Loss: 0.5232032537460327\n",
      "Ep 42: Batch #117 - Loss: 0.680904746055603\n",
      "Ep 42: Batch #118 - Loss: 0.45725011825561523\n",
      "Model saved in file: ./weights_autoencoder_sigmoid/model_e42b118_1516648797.2234125.ckpt\n",
      "Ep 42: Batch #119 - Loss: 0.8088460564613342\n",
      "Ep 42: Batch #120 - Loss: 0.6619230508804321\n",
      "Ep 42: Batch #121 - Loss: 0.5622534155845642\n",
      "Ep 42: Batch #122 - Loss: 0.7129872441291809\n",
      "Ep 42: Batch #123 - Loss: 0.7200343608856201\n",
      "Ep 42: Batch #124 - Loss: 0.5577735304832458\n",
      "Ep 42: Batch #125 - Loss: 2.4686105251312256\n",
      "Ep 42: Batch #126 - Loss: 0.9994605183601379\n",
      "Ep 42: Batch #127 - Loss: 0.5833203792572021\n",
      "Ep 42: Batch #128 - Loss: 0.8849259614944458\n",
      "Ep 42: Batch #129 - Loss: 0.6792967319488525\n",
      "Ep 42: Batch #130 - Loss: 0.5966755747795105\n",
      "Ep 42: Batch #131 - Loss: 0.8056890964508057\n",
      "Ep 42: Batch #132 - Loss: 0.6854049563407898\n",
      "Ep 42: Batch #133 - Loss: 0.66769939661026\n",
      "Ep 42: Batch #134 - Loss: 0.6380599737167358\n",
      "Ep 42: Batch #135 - Loss: 0.8229338526725769\n",
      "Ep 42: Batch #136 - Loss: 1.041537880897522\n",
      "Ep 42: Batch #137 - Loss: 0.7544652819633484\n",
      "Ep 42: Batch #138 - Loss: 0.9010263085365295\n",
      "Ep 42: Batch #139 - Loss: 0.6781876087188721\n",
      "Ep 42: Batch #140 - Loss: 0.8451734185218811\n",
      "Ep 42: Batch #141 - Loss: 1.1309765577316284\n",
      "Ep 42: Batch #142 - Loss: 0.6722170114517212\n",
      "Ep 42: Batch #143 - Loss: 0.7711681127548218\n",
      "Ep 42: Batch #144 - Loss: 0.6123828887939453\n",
      "Ep 42: Batch #145 - Loss: 0.5996189117431641\n",
      "Ep 42: Batch #146 - Loss: 0.705858588218689\n",
      "Ep 42: Batch #147 - Loss: 0.6689147353172302\n",
      "Ep 42: Batch #148 - Loss: 0.7570469975471497\n",
      "Ep 42: Batch #149 - Loss: 0.627769410610199\n",
      "Ep 42: Batch #150 - Loss: 0.7217587828636169\n",
      "Ep 42: Batch #151 - Loss: 0.6300793290138245\n",
      "Ep 42: Batch #152 - Loss: 0.6089293360710144\n",
      "Ep 42: Batch #153 - Loss: 0.8293780088424683\n",
      "Ep 42: Batch #154 - Loss: 0.6339830756187439\n",
      "Ep 42: Batch #155 - Loss: 0.6927884221076965\n",
      "Ep 42: Batch #156 - Loss: 0.7913832664489746\n",
      "Ep 42: Batch #157 - Loss: 0.6155112981796265\n",
      "Ep 42: Batch #158 - Loss: 0.7182403802871704\n",
      "Ep 42: Batch #159 - Loss: 0.6027339100837708\n",
      "Ep 42: Batch #160 - Loss: 0.7001162171363831\n",
      "Ep 42: Batch #161 - Loss: 0.6702035069465637\n",
      "Ep 42: Batch #162 - Loss: 0.7196109294891357\n",
      "Ep 42: Batch #163 - Loss: 0.7606135010719299\n",
      "Ep 42: Batch #164 - Loss: 0.6491864323616028\n",
      "Ep 42: Batch #165 - Loss: 1.3429381847381592\n",
      "Ep 42: Batch #166 - Loss: 0.5345798134803772\n",
      "Ep 42: Batch #167 - Loss: 0.7373301982879639\n",
      "Ep 42: Batch #168 - Loss: 0.693589985370636\n",
      "Ep 42: Batch #169 - Loss: 0.668732225894928\n",
      "Ep 42: Batch #170 - Loss: 0.6294439435005188\n",
      "Ep 42: Batch #171 - Loss: 0.6417197585105896\n",
      "Ep 42: Batch #172 - Loss: 0.534873902797699\n",
      "Ep 42: Batch #173 - Loss: 0.930949866771698\n",
      "Ep 42: Batch #174 - Loss: 0.49751442670822144\n",
      "Ep 42: Batch #175 - Loss: 0.6383075714111328\n",
      "Ep 42: Batch #176 - Loss: 0.8989905118942261\n",
      "Ep 42: Batch #177 - Loss: 0.6531771421432495\n",
      "Ep 42: Batch #178 - Loss: 0.6249362230300903\n",
      "Ep 42: Batch #179 - Loss: 0.7507201433181763\n",
      "Ep 42: Batch #180 - Loss: 0.6542053818702698\n",
      "Ep 42: Batch #181 - Loss: 0.8040269613265991\n",
      "Ep 42: Batch #182 - Loss: 0.6266636252403259\n",
      "Ep 42: Batch #183 - Loss: 0.6074710488319397\n",
      "Ep 42: Batch #184 - Loss: 0.9218937158584595\n",
      "Ep 42: Batch #185 - Loss: 0.6328710317611694\n",
      "Ep 42: Batch #186 - Loss: 0.7599992156028748\n",
      "Ep 42: Batch #187 - Loss: 0.8688878417015076\n",
      "Ep 42: Batch #188 - Loss: 0.9724854826927185\n",
      "Ep 42: Batch #189 - Loss: 0.5882982015609741\n",
      "Ep 42: Batch #190 - Loss: 0.6244379878044128\n",
      "Ep 42: Batch #191 - Loss: 0.810347855091095\n",
      "Ep 42: Batch #192 - Loss: 0.5710957050323486\n",
      "Ep 42: Batch #193 - Loss: 0.6301705241203308\n",
      "Ep 42: Batch #194 - Loss: 0.5459932088851929\n",
      "Ep 42: Batch #195 - Loss: 0.792361319065094\n",
      "Ep 42: Batch #196 - Loss: 0.6928243637084961\n",
      "Ep 42: Batch #197 - Loss: 0.7019643783569336\n",
      "Ep 42: Batch #198 - Loss: 0.5345589518547058\n",
      "Ep 42: Batch #199 - Loss: 0.6463244557380676\n",
      "Ep 43: Batch #0 - Loss: 0.6507788896560669\n",
      "Ep 43: Batch #1 - Loss: 0.7148381471633911\n",
      "Ep 43: Batch #2 - Loss: 0.8606990575790405\n",
      "Ep 43: Batch #3 - Loss: 0.7234187722206116\n",
      "Ep 43: Batch #4 - Loss: 0.6579155325889587\n",
      "Ep 43: Batch #5 - Loss: 0.5617828369140625\n",
      "Ep 43: Batch #6 - Loss: 0.7406761646270752\n",
      "Ep 43: Batch #7 - Loss: 0.5767253041267395\n",
      "Ep 43: Batch #8 - Loss: 0.5895248651504517\n",
      "Ep 43: Batch #9 - Loss: 1.0966700315475464\n",
      "Ep 43: Batch #10 - Loss: 0.812379002571106\n",
      "Ep 43: Batch #11 - Loss: 0.544370174407959\n",
      "Ep 43: Batch #12 - Loss: 1.2129929065704346\n",
      "Ep 43: Batch #13 - Loss: 0.5720965266227722\n",
      "Ep 43: Batch #14 - Loss: 0.6016526818275452\n",
      "Ep 43: Batch #15 - Loss: 0.8611094951629639\n",
      "Ep 43: Batch #16 - Loss: 0.9545186758041382\n",
      "Ep 43: Batch #17 - Loss: 0.7303889989852905\n",
      "Ep 43: Batch #18 - Loss: 0.8078127503395081\n",
      "Ep 43: Batch #19 - Loss: 0.5643622279167175\n",
      "Ep 43: Batch #20 - Loss: 0.5475447177886963\n",
      "Ep 43: Batch #21 - Loss: 0.8387840390205383\n",
      "Ep 43: Batch #22 - Loss: 0.6116655468940735\n",
      "Ep 43: Batch #23 - Loss: 0.6009937524795532\n",
      "Ep 43: Batch #24 - Loss: 0.6390056610107422\n",
      "Ep 43: Batch #25 - Loss: 0.6087478399276733\n",
      "Ep 43: Batch #26 - Loss: 0.561003565788269\n",
      "Ep 43: Batch #27 - Loss: 1.1441173553466797\n",
      "Ep 43: Batch #28 - Loss: 0.6914430260658264\n",
      "Ep 43: Batch #29 - Loss: 0.7583258152008057\n",
      "Ep 43: Batch #30 - Loss: 0.8487786650657654\n",
      "Ep 43: Batch #31 - Loss: 0.5621026158332825\n",
      "Ep 43: Batch #32 - Loss: 0.5821802616119385\n",
      "Ep 43: Batch #33 - Loss: 0.6684842109680176\n",
      "Ep 43: Batch #34 - Loss: 0.6426360607147217\n",
      "Ep 43: Batch #35 - Loss: 0.7254525423049927\n",
      "Ep 43: Batch #36 - Loss: 0.5834951400756836\n",
      "Ep 43: Batch #37 - Loss: 0.923498272895813\n",
      "Ep 43: Batch #38 - Loss: 0.571834146976471\n",
      "Ep 43: Batch #39 - Loss: 0.6865469217300415\n",
      "Ep 43: Batch #40 - Loss: 0.6052895784378052\n",
      "Ep 43: Batch #41 - Loss: 0.6214323043823242\n",
      "Ep 43: Batch #42 - Loss: 0.5708127021789551\n",
      "Ep 43: Batch #43 - Loss: 0.633675754070282\n",
      "Ep 43: Batch #44 - Loss: 0.6153959035873413\n",
      "Ep 43: Batch #45 - Loss: 0.5277813673019409\n",
      "Ep 43: Batch #46 - Loss: 0.6978107690811157\n",
      "Ep 43: Batch #47 - Loss: 0.8058081269264221\n",
      "Ep 43: Batch #48 - Loss: 1.0413386821746826\n",
      "Ep 43: Batch #49 - Loss: 0.8135015964508057\n",
      "Ep 43: Batch #50 - Loss: 0.5740673542022705\n",
      "Ep 43: Batch #51 - Loss: 0.819388210773468\n",
      "Ep 43: Batch #52 - Loss: 0.6777529716491699\n",
      "Ep 43: Batch #53 - Loss: 0.7171225547790527\n",
      "Ep 43: Batch #54 - Loss: 0.5803799033164978\n",
      "Ep 43: Batch #55 - Loss: 0.6091488003730774\n",
      "Ep 43: Batch #56 - Loss: 0.8635427355766296\n",
      "Ep 43: Batch #57 - Loss: 0.6827372312545776\n",
      "Ep 43: Batch #58 - Loss: 0.8287383317947388\n",
      "Ep 43: Batch #59 - Loss: 0.561581015586853\n",
      "Ep 43: Batch #60 - Loss: 1.01334547996521\n",
      "Ep 43: Batch #61 - Loss: 0.5353716015815735\n",
      "Ep 43: Batch #62 - Loss: 0.5755239725112915\n",
      "Ep 43: Batch #63 - Loss: 0.7867727875709534\n",
      "Ep 43: Batch #64 - Loss: 8.516657829284668\n",
      "Ep 43: Batch #65 - Loss: 0.5255980491638184\n",
      "Ep 43: Batch #66 - Loss: 0.6662698984146118\n",
      "Ep 43: Batch #67 - Loss: 0.7764807343482971\n",
      "Ep 43: Batch #68 - Loss: 0.7169561386108398\n",
      "Ep 43: Batch #69 - Loss: 0.5914171934127808\n",
      "Ep 43: Batch #70 - Loss: 0.6188952922821045\n",
      "Ep 43: Batch #71 - Loss: 0.5379886627197266\n",
      "Ep 43: Batch #72 - Loss: 0.6647611260414124\n",
      "Ep 43: Batch #73 - Loss: 0.7264145016670227\n",
      "Ep 43: Batch #74 - Loss: 0.5820143222808838\n",
      "Ep 43: Batch #75 - Loss: 0.6701850891113281\n",
      "Ep 43: Batch #76 - Loss: 0.9292872548103333\n",
      "Ep 43: Batch #77 - Loss: 0.5782175660133362\n",
      "Ep 43: Batch #78 - Loss: 0.9235551357269287\n",
      "Ep 43: Batch #79 - Loss: 0.5272888541221619\n",
      "Ep 43: Batch #80 - Loss: 0.6951912045478821\n",
      "Ep 43: Batch #81 - Loss: 1.5262525081634521\n",
      "Ep 43: Batch #82 - Loss: 0.7518854737281799\n",
      "Ep 43: Batch #83 - Loss: 1.2957494258880615\n",
      "Ep 43: Batch #84 - Loss: 0.5811752676963806\n",
      "Ep 43: Batch #85 - Loss: 0.7914717793464661\n",
      "Ep 43: Batch #86 - Loss: 0.549800455570221\n",
      "Ep 43: Batch #87 - Loss: 0.5739647150039673\n",
      "Ep 43: Batch #88 - Loss: 0.6589977741241455\n",
      "Ep 43: Batch #89 - Loss: 0.7323417067527771\n",
      "Ep 43: Batch #90 - Loss: 0.9008194208145142\n",
      "Ep 43: Batch #91 - Loss: 0.6496179103851318\n",
      "Ep 43: Batch #92 - Loss: 0.737429141998291\n",
      "Ep 43: Batch #93 - Loss: 0.785767138004303\n",
      "Ep 43: Batch #94 - Loss: 0.7560944557189941\n",
      "Ep 43: Batch #95 - Loss: 0.7615498900413513\n",
      "Ep 43: Batch #96 - Loss: 0.7610805034637451\n",
      "Ep 43: Batch #97 - Loss: 0.588179886341095\n",
      "Ep 43: Batch #98 - Loss: 0.5797435641288757\n",
      "Ep 43: Batch #99 - Loss: 0.8021916747093201\n",
      "Ep 43: Batch #100 - Loss: 0.5589100122451782\n",
      "Ep 43: Batch #101 - Loss: 0.8646473288536072\n",
      "Ep 43: Batch #102 - Loss: 0.6140411496162415\n",
      "Ep 43: Batch #103 - Loss: 0.6387493014335632\n",
      "Ep 43: Batch #104 - Loss: 0.6622046828269958\n",
      "Ep 43: Batch #105 - Loss: 0.8165594935417175\n",
      "Ep 43: Batch #106 - Loss: 0.6277160048484802\n",
      "Ep 43: Batch #107 - Loss: 0.6153305172920227\n",
      "Ep 43: Batch #108 - Loss: 0.9022331833839417\n",
      "Ep 43: Batch #109 - Loss: 0.626530110836029\n",
      "Ep 43: Batch #110 - Loss: 0.7273778319358826\n",
      "Ep 43: Batch #111 - Loss: 1.044434905052185\n",
      "Ep 43: Batch #112 - Loss: 0.8009606599807739\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 43: Batch #113 - Loss: 0.6591817140579224\n",
      "Ep 43: Batch #114 - Loss: 0.7298117876052856\n",
      "Ep 43: Batch #115 - Loss: 0.9074484705924988\n",
      "Ep 43: Batch #116 - Loss: 0.5232796669006348\n",
      "Ep 43: Batch #117 - Loss: 0.6810594201087952\n",
      "Ep 43: Batch #118 - Loss: 0.45723986625671387\n",
      "Model saved in file: ./weights_autoencoder_sigmoid/model_e43b118_1516648797.3599637.ckpt\n",
      "Ep 43: Batch #119 - Loss: 0.8094170689582825\n",
      "Ep 43: Batch #120 - Loss: 0.6608092188835144\n",
      "Ep 43: Batch #121 - Loss: 0.5628763437271118\n",
      "Ep 43: Batch #122 - Loss: 0.7130445241928101\n",
      "Ep 43: Batch #123 - Loss: 0.719678521156311\n",
      "Ep 43: Batch #124 - Loss: 0.5574955344200134\n",
      "Ep 43: Batch #125 - Loss: 2.469351053237915\n",
      "Ep 43: Batch #126 - Loss: 0.9992857575416565\n",
      "Ep 43: Batch #127 - Loss: 0.5837896466255188\n",
      "Ep 43: Batch #128 - Loss: 0.8848980665206909\n",
      "Ep 43: Batch #129 - Loss: 0.6788635849952698\n",
      "Ep 43: Batch #130 - Loss: 0.5966613292694092\n",
      "Ep 43: Batch #131 - Loss: 0.806260883808136\n",
      "Ep 43: Batch #132 - Loss: 0.6854380369186401\n",
      "Ep 43: Batch #133 - Loss: 0.6683766841888428\n",
      "Ep 43: Batch #134 - Loss: 0.6373093724250793\n",
      "Ep 43: Batch #135 - Loss: 0.8227872848510742\n",
      "Ep 43: Batch #136 - Loss: 1.0420366525650024\n",
      "Ep 43: Batch #137 - Loss: 0.7544435262680054\n",
      "Ep 43: Batch #138 - Loss: 0.9005982279777527\n",
      "Ep 43: Batch #139 - Loss: 0.6771933436393738\n",
      "Ep 43: Batch #140 - Loss: 0.8455498814582825\n",
      "Ep 43: Batch #141 - Loss: 1.130871295928955\n",
      "Ep 43: Batch #142 - Loss: 0.671617329120636\n",
      "Ep 43: Batch #143 - Loss: 0.771959662437439\n",
      "Ep 43: Batch #144 - Loss: 0.6124430894851685\n",
      "Ep 43: Batch #145 - Loss: 0.5997865200042725\n",
      "Ep 43: Batch #146 - Loss: 0.7048478722572327\n",
      "Ep 43: Batch #147 - Loss: 0.6693716645240784\n",
      "Ep 43: Batch #148 - Loss: 0.757776141166687\n",
      "Ep 43: Batch #149 - Loss: 0.6274356842041016\n",
      "Ep 43: Batch #150 - Loss: 0.7216036319732666\n",
      "Ep 43: Batch #151 - Loss: 0.6293991804122925\n",
      "Ep 43: Batch #152 - Loss: 0.6084387898445129\n",
      "Ep 43: Batch #153 - Loss: 0.8291929364204407\n",
      "Ep 43: Batch #154 - Loss: 0.6341785192489624\n",
      "Ep 43: Batch #155 - Loss: 0.6931661367416382\n",
      "Ep 43: Batch #156 - Loss: 0.7907574772834778\n",
      "Ep 43: Batch #157 - Loss: 0.615462601184845\n",
      "Ep 43: Batch #158 - Loss: 0.7181445360183716\n",
      "Ep 43: Batch #159 - Loss: 0.6025568246841431\n",
      "Ep 43: Batch #160 - Loss: 0.6998243927955627\n",
      "Ep 43: Batch #161 - Loss: 0.670036256313324\n",
      "Ep 43: Batch #162 - Loss: 0.7193878293037415\n",
      "Ep 43: Batch #163 - Loss: 0.7602918148040771\n",
      "Ep 43: Batch #164 - Loss: 0.6493949890136719\n",
      "Ep 43: Batch #165 - Loss: 1.342852234840393\n",
      "Ep 43: Batch #166 - Loss: 0.5342047214508057\n",
      "Ep 43: Batch #167 - Loss: 0.735820472240448\n",
      "Ep 43: Batch #168 - Loss: 0.6930851340293884\n",
      "Ep 43: Batch #169 - Loss: 0.668164074420929\n",
      "Ep 43: Batch #170 - Loss: 0.6298719048500061\n",
      "Ep 43: Batch #171 - Loss: 0.641600489616394\n",
      "Ep 43: Batch #172 - Loss: 0.5347962379455566\n",
      "Ep 43: Batch #173 - Loss: 0.9309201836585999\n",
      "Ep 43: Batch #174 - Loss: 0.497138112783432\n",
      "Ep 43: Batch #175 - Loss: 0.6384392976760864\n",
      "Ep 43: Batch #176 - Loss: 0.8975475430488586\n",
      "Ep 43: Batch #177 - Loss: 0.6531810164451599\n",
      "Ep 43: Batch #178 - Loss: 0.6248981952667236\n",
      "Ep 43: Batch #179 - Loss: 0.7502962946891785\n",
      "Ep 43: Batch #180 - Loss: 0.6537211537361145\n",
      "Ep 43: Batch #181 - Loss: 0.8037336468696594\n",
      "Ep 43: Batch #182 - Loss: 0.6268458366394043\n",
      "Ep 43: Batch #183 - Loss: 0.6071156859397888\n",
      "Ep 43: Batch #184 - Loss: 0.9218483567237854\n",
      "Ep 43: Batch #185 - Loss: 0.6331215500831604\n",
      "Ep 43: Batch #186 - Loss: 0.7596794962882996\n",
      "Ep 43: Batch #187 - Loss: 0.8694633841514587\n",
      "Ep 43: Batch #188 - Loss: 0.9719000458717346\n",
      "Ep 43: Batch #189 - Loss: 0.5882716774940491\n",
      "Ep 43: Batch #190 - Loss: 0.6245271563529968\n",
      "Ep 43: Batch #191 - Loss: 0.810308039188385\n",
      "Ep 43: Batch #192 - Loss: 0.5712570548057556\n",
      "Ep 43: Batch #193 - Loss: 0.6303710341453552\n",
      "Ep 43: Batch #194 - Loss: 0.5458605289459229\n",
      "Ep 43: Batch #195 - Loss: 0.7919586896896362\n",
      "Ep 43: Batch #196 - Loss: 0.6929360032081604\n",
      "Ep 43: Batch #197 - Loss: 0.7021013498306274\n",
      "Ep 43: Batch #198 - Loss: 0.5343063473701477\n",
      "Ep 43: Batch #199 - Loss: 0.6461329460144043\n",
      "Ep 44: Batch #0 - Loss: 0.6507483124732971\n",
      "Ep 44: Batch #1 - Loss: 0.7149837613105774\n",
      "Ep 44: Batch #2 - Loss: 0.8603976964950562\n",
      "Ep 44: Batch #3 - Loss: 0.7236891388893127\n",
      "Ep 44: Batch #4 - Loss: 0.6576427221298218\n",
      "Ep 44: Batch #5 - Loss: 0.5609932541847229\n",
      "Ep 44: Batch #6 - Loss: 0.7400980591773987\n",
      "Ep 44: Batch #7 - Loss: 0.5767660140991211\n",
      "Ep 44: Batch #8 - Loss: 0.5895050764083862\n",
      "Ep 44: Batch #9 - Loss: 1.0962767601013184\n",
      "Ep 44: Batch #10 - Loss: 0.8118110299110413\n",
      "Ep 44: Batch #11 - Loss: 0.5442588329315186\n",
      "Ep 44: Batch #12 - Loss: 1.2125980854034424\n",
      "Ep 44: Batch #13 - Loss: 0.572036623954773\n",
      "Ep 44: Batch #14 - Loss: 0.6014379262924194\n",
      "Ep 44: Batch #15 - Loss: 0.8604663610458374\n",
      "Ep 44: Batch #16 - Loss: 0.9547927379608154\n",
      "Ep 44: Batch #17 - Loss: 0.7302601933479309\n",
      "Ep 44: Batch #18 - Loss: 0.8079817295074463\n",
      "Ep 44: Batch #19 - Loss: 0.5642481446266174\n",
      "Ep 44: Batch #20 - Loss: 0.547581136226654\n",
      "Ep 44: Batch #21 - Loss: 0.8368495106697083\n",
      "Ep 44: Batch #22 - Loss: 0.6113436222076416\n",
      "Ep 44: Batch #23 - Loss: 0.6010764837265015\n",
      "Ep 44: Batch #24 - Loss: 0.638984739780426\n",
      "Ep 44: Batch #25 - Loss: 0.6085193157196045\n",
      "Ep 44: Batch #26 - Loss: 0.5608078837394714\n",
      "Ep 44: Batch #27 - Loss: 1.1437727212905884\n",
      "Ep 44: Batch #28 - Loss: 0.6915339827537537\n",
      "Ep 44: Batch #29 - Loss: 0.758003294467926\n",
      "Ep 44: Batch #30 - Loss: 0.8468905091285706\n",
      "Ep 44: Batch #31 - Loss: 0.5619886517524719\n",
      "Ep 44: Batch #32 - Loss: 0.582091748714447\n",
      "Ep 44: Batch #33 - Loss: 0.6683188676834106\n",
      "Ep 44: Batch #34 - Loss: 0.6422021389007568\n",
      "Ep 44: Batch #35 - Loss: 0.7251198887825012\n",
      "Ep 44: Batch #36 - Loss: 0.5837296843528748\n",
      "Ep 44: Batch #37 - Loss: 0.923570454120636\n",
      "Ep 44: Batch #38 - Loss: 0.5717324614524841\n",
      "Ep 44: Batch #39 - Loss: 0.686302900314331\n",
      "Ep 44: Batch #40 - Loss: 0.6053004264831543\n",
      "Ep 44: Batch #41 - Loss: 0.6213557124137878\n",
      "Ep 44: Batch #42 - Loss: 0.5706869959831238\n",
      "Ep 44: Batch #43 - Loss: 0.6336902379989624\n",
      "Ep 44: Batch #44 - Loss: 0.6152666807174683\n",
      "Ep 44: Batch #45 - Loss: 0.5276823043823242\n",
      "Ep 44: Batch #46 - Loss: 0.6977893710136414\n",
      "Ep 44: Batch #47 - Loss: 0.8057687878608704\n",
      "Ep 44: Batch #48 - Loss: 1.041140079498291\n",
      "Ep 44: Batch #49 - Loss: 0.8134738206863403\n",
      "Ep 44: Batch #50 - Loss: 0.57399582862854\n",
      "Ep 44: Batch #51 - Loss: 0.8192871809005737\n",
      "Ep 44: Batch #52 - Loss: 0.6774966716766357\n",
      "Ep 44: Batch #53 - Loss: 0.7169932723045349\n",
      "Ep 44: Batch #54 - Loss: 0.5801588296890259\n",
      "Ep 44: Batch #55 - Loss: 0.609411358833313\n",
      "Ep 44: Batch #56 - Loss: 0.8628299832344055\n",
      "Ep 44: Batch #57 - Loss: 0.6827561259269714\n",
      "Ep 44: Batch #58 - Loss: 0.8284905552864075\n",
      "Ep 44: Batch #59 - Loss: 0.5613132119178772\n",
      "Ep 44: Batch #60 - Loss: 1.0131293535232544\n",
      "Ep 44: Batch #61 - Loss: 0.5354560017585754\n",
      "Ep 44: Batch #62 - Loss: 0.5751411318778992\n",
      "Ep 44: Batch #63 - Loss: 0.7865638136863708\n",
      "Ep 44: Batch #64 - Loss: 8.533533096313477\n",
      "Ep 44: Batch #65 - Loss: 0.5256443619728088\n",
      "Ep 44: Batch #66 - Loss: 0.6659678816795349\n",
      "Ep 44: Batch #67 - Loss: 0.7761341333389282\n",
      "Ep 44: Batch #68 - Loss: 0.7157249450683594\n",
      "Ep 44: Batch #69 - Loss: 0.5903649926185608\n",
      "Ep 44: Batch #70 - Loss: 0.6171659827232361\n",
      "Ep 44: Batch #71 - Loss: 0.5375507473945618\n",
      "Ep 44: Batch #72 - Loss: 0.663596510887146\n",
      "Ep 44: Batch #73 - Loss: 0.725662350654602\n",
      "Ep 44: Batch #74 - Loss: 0.5819105505943298\n",
      "Ep 44: Batch #75 - Loss: 0.6697150468826294\n",
      "Ep 44: Batch #76 - Loss: 0.9302645921707153\n",
      "Ep 44: Batch #77 - Loss: 0.5778878331184387\n",
      "Ep 44: Batch #78 - Loss: 0.9237589240074158\n",
      "Ep 44: Batch #79 - Loss: 0.5271555781364441\n",
      "Ep 44: Batch #80 - Loss: 0.6946772336959839\n",
      "Ep 44: Batch #81 - Loss: 1.5270421504974365\n",
      "Ep 44: Batch #82 - Loss: 0.7523680329322815\n",
      "Ep 44: Batch #83 - Loss: 1.2927480936050415\n",
      "Ep 44: Batch #84 - Loss: 0.5788812041282654\n",
      "Ep 44: Batch #85 - Loss: 0.7907940149307251\n",
      "Ep 44: Batch #86 - Loss: 0.549414873123169\n",
      "Ep 44: Batch #87 - Loss: 0.5737459659576416\n",
      "Ep 44: Batch #88 - Loss: 0.6589038372039795\n",
      "Ep 44: Batch #89 - Loss: 0.7322169542312622\n",
      "Ep 44: Batch #90 - Loss: 0.9009877443313599\n",
      "Ep 44: Batch #91 - Loss: 0.6493821740150452\n",
      "Ep 44: Batch #92 - Loss: 0.7349736094474792\n",
      "Ep 44: Batch #93 - Loss: 0.7855494618415833\n",
      "Ep 44: Batch #94 - Loss: 0.7555922269821167\n",
      "Ep 44: Batch #95 - Loss: 0.7618386745452881\n",
      "Ep 44: Batch #96 - Loss: 0.7630936503410339\n",
      "Ep 44: Batch #97 - Loss: 0.5882493257522583\n",
      "Ep 44: Batch #98 - Loss: 0.5797919034957886\n",
      "Ep 44: Batch #99 - Loss: 0.8028939962387085\n",
      "Ep 44: Batch #100 - Loss: 0.5590510964393616\n",
      "Ep 44: Batch #101 - Loss: 0.8650839328765869\n",
      "Ep 44: Batch #102 - Loss: 0.6133601665496826\n",
      "Ep 44: Batch #103 - Loss: 0.6388708353042603\n",
      "Ep 44: Batch #104 - Loss: 0.6620279550552368\n",
      "Ep 44: Batch #105 - Loss: 0.8157147169113159\n",
      "Ep 44: Batch #106 - Loss: 0.6278721690177917\n",
      "Ep 44: Batch #107 - Loss: 0.6154459714889526\n",
      "Ep 44: Batch #108 - Loss: 0.9017157554626465\n",
      "Ep 44: Batch #109 - Loss: 0.6265431046485901\n",
      "Ep 44: Batch #110 - Loss: 0.727548360824585\n",
      "Ep 44: Batch #111 - Loss: 1.044382929801941\n",
      "Ep 44: Batch #112 - Loss: 0.800178587436676\n",
      "Ep 44: Batch #113 - Loss: 0.6594759821891785\n",
      "Ep 44: Batch #114 - Loss: 0.7306354641914368\n",
      "Ep 44: Batch #115 - Loss: 0.9075560569763184\n",
      "Ep 44: Batch #116 - Loss: 0.5228587985038757\n",
      "Ep 44: Batch #117 - Loss: 0.6805390119552612\n",
      "Ep 44: Batch #118 - Loss: 0.45681899785995483\n",
      "Model saved in file: ./weights_autoencoder_sigmoid/model_e44b118_1516648797.4962378.ckpt\n",
      "Ep 44: Batch #119 - Loss: 0.8090709447860718\n",
      "Ep 44: Batch #120 - Loss: 0.660887598991394\n",
      "Ep 44: Batch #121 - Loss: 0.562237560749054\n",
      "Ep 44: Batch #122 - Loss: 0.7127573490142822\n",
      "Ep 44: Batch #123 - Loss: 0.7197520732879639\n",
      "Ep 44: Batch #124 - Loss: 0.5574787855148315\n",
      "Ep 44: Batch #125 - Loss: 2.4687724113464355\n",
      "Ep 44: Batch #126 - Loss: 0.9995652437210083\n",
      "Ep 44: Batch #127 - Loss: 0.5831462144851685\n",
      "Ep 44: Batch #128 - Loss: 0.884813666343689\n",
      "Ep 44: Batch #129 - Loss: 0.6789662837982178\n",
      "Ep 44: Batch #130 - Loss: 0.5967028141021729\n",
      "Ep 44: Batch #131 - Loss: 0.8057015538215637\n",
      "Ep 44: Batch #132 - Loss: 0.6850825548171997\n",
      "Ep 44: Batch #133 - Loss: 0.6676432490348816\n",
      "Ep 44: Batch #134 - Loss: 0.6375232934951782\n",
      "Ep 44: Batch #135 - Loss: 0.8229097127914429\n",
      "Ep 44: Batch #136 - Loss: 1.0415798425674438\n",
      "Ep 44: Batch #137 - Loss: 0.7544901371002197\n",
      "Ep 44: Batch #138 - Loss: 0.9011101126670837\n",
      "Ep 44: Batch #139 - Loss: 0.6778855323791504\n",
      "Ep 44: Batch #140 - Loss: 0.8453113436698914\n",
      "Ep 44: Batch #141 - Loss: 1.130351185798645\n",
      "Ep 44: Batch #142 - Loss: 0.6723065972328186\n",
      "Ep 44: Batch #143 - Loss: 0.7714188694953918\n",
      "Ep 44: Batch #144 - Loss: 0.6124573349952698\n",
      "Ep 44: Batch #145 - Loss: 0.5994398593902588\n",
      "Ep 44: Batch #146 - Loss: 0.7049243450164795\n",
      "Ep 44: Batch #147 - Loss: 0.6683686971664429\n",
      "Ep 44: Batch #148 - Loss: 0.7562950253486633\n",
      "Ep 44: Batch #149 - Loss: 0.6258540749549866\n",
      "Ep 44: Batch #150 - Loss: 0.7215749621391296\n",
      "Ep 44: Batch #151 - Loss: 0.6294575333595276\n",
      "Ep 44: Batch #152 - Loss: 0.6085406541824341\n",
      "Ep 44: Batch #153 - Loss: 0.8287540674209595\n",
      "Ep 44: Batch #154 - Loss: 0.633465588092804\n",
      "Ep 44: Batch #155 - Loss: 0.6914575695991516\n",
      "Ep 44: Batch #156 - Loss: 0.7898116111755371\n",
      "Ep 44: Batch #157 - Loss: 0.6150990128517151\n",
      "Ep 44: Batch #158 - Loss: 0.718257486820221\n",
      "Ep 44: Batch #159 - Loss: 0.6019713282585144\n",
      "Ep 44: Batch #160 - Loss: 0.6993438005447388\n",
      "Ep 44: Batch #161 - Loss: 0.6700662970542908\n",
      "Ep 44: Batch #162 - Loss: 0.7196086645126343\n",
      "Ep 44: Batch #163 - Loss: 0.7603041529655457\n",
      "Ep 44: Batch #164 - Loss: 0.6490517854690552\n",
      "Ep 44: Batch #165 - Loss: 1.3433622121810913\n",
      "Ep 44: Batch #166 - Loss: 0.53448885679245\n",
      "Ep 44: Batch #167 - Loss: 0.7336307764053345\n",
      "Ep 44: Batch #168 - Loss: 0.6931383609771729\n",
      "Ep 44: Batch #169 - Loss: 0.6681663990020752\n",
      "Ep 44: Batch #170 - Loss: 0.6292563676834106\n",
      "Ep 44: Batch #171 - Loss: 0.6415854692459106\n",
      "Ep 44: Batch #172 - Loss: 0.5349687933921814\n",
      "Ep 44: Batch #173 - Loss: 0.9308434724807739\n",
      "Ep 44: Batch #174 - Loss: 0.49704644083976746\n",
      "Ep 44: Batch #175 - Loss: 0.6383222937583923\n",
      "Ep 44: Batch #176 - Loss: 0.8979859352111816\n",
      "Ep 44: Batch #177 - Loss: 0.6528344750404358\n",
      "Ep 44: Batch #178 - Loss: 0.6248666048049927\n",
      "Ep 44: Batch #179 - Loss: 0.7502354979515076\n",
      "Ep 44: Batch #180 - Loss: 0.6536819934844971\n",
      "Ep 44: Batch #181 - Loss: 0.8038550019264221\n",
      "Ep 44: Batch #182 - Loss: 0.626713216304779\n",
      "Ep 44: Batch #183 - Loss: 0.6071900725364685\n",
      "Ep 44: Batch #184 - Loss: 0.921751856803894\n",
      "Ep 44: Batch #185 - Loss: 0.6331892013549805\n",
      "Ep 44: Batch #186 - Loss: 0.7592450380325317\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 44: Batch #187 - Loss: 0.8690070509910583\n",
      "Ep 44: Batch #188 - Loss: 0.9697579741477966\n",
      "Ep 44: Batch #189 - Loss: 0.5880023837089539\n",
      "Ep 44: Batch #190 - Loss: 0.624359667301178\n",
      "Ep 44: Batch #191 - Loss: 0.8099992275238037\n",
      "Ep 44: Batch #192 - Loss: 0.5711562633514404\n",
      "Ep 44: Batch #193 - Loss: 0.6303635835647583\n",
      "Ep 44: Batch #194 - Loss: 0.5456967353820801\n",
      "Ep 44: Batch #195 - Loss: 0.7915236949920654\n",
      "Ep 44: Batch #196 - Loss: 0.6927364468574524\n",
      "Ep 44: Batch #197 - Loss: 0.7016710042953491\n",
      "Ep 44: Batch #198 - Loss: 0.5341483354568481\n",
      "Ep 44: Batch #199 - Loss: 0.6458964943885803\n",
      "Ep 45: Batch #0 - Loss: 0.6507620215415955\n",
      "Ep 45: Batch #1 - Loss: 0.7150111198425293\n",
      "Ep 45: Batch #2 - Loss: 0.8603551983833313\n",
      "Ep 45: Batch #3 - Loss: 0.723818838596344\n",
      "Ep 45: Batch #4 - Loss: 0.6576420664787292\n",
      "Ep 45: Batch #5 - Loss: 0.5611308217048645\n",
      "Ep 45: Batch #6 - Loss: 0.7402348518371582\n",
      "Ep 45: Batch #7 - Loss: 0.5766807794570923\n",
      "Ep 45: Batch #8 - Loss: 0.5884647369384766\n",
      "Ep 45: Batch #9 - Loss: 1.096335768699646\n",
      "Ep 45: Batch #10 - Loss: 0.8112257719039917\n",
      "Ep 45: Batch #11 - Loss: 0.5444873571395874\n",
      "Ep 45: Batch #12 - Loss: 1.211552619934082\n",
      "Ep 45: Batch #13 - Loss: 0.5721249580383301\n",
      "Ep 45: Batch #14 - Loss: 0.6013818979263306\n",
      "Ep 45: Batch #15 - Loss: 0.8593120574951172\n",
      "Ep 45: Batch #16 - Loss: 0.954316258430481\n",
      "Ep 45: Batch #17 - Loss: 0.7301383018493652\n",
      "Ep 45: Batch #18 - Loss: 0.8079819679260254\n",
      "Ep 45: Batch #19 - Loss: 0.5642268657684326\n",
      "Ep 45: Batch #20 - Loss: 0.547569751739502\n",
      "Ep 45: Batch #21 - Loss: 0.8346386551856995\n",
      "Ep 45: Batch #22 - Loss: 0.611461877822876\n",
      "Ep 45: Batch #23 - Loss: 0.6008838415145874\n",
      "Ep 45: Batch #24 - Loss: 0.6390666365623474\n",
      "Ep 45: Batch #25 - Loss: 0.6083736419677734\n",
      "Ep 45: Batch #26 - Loss: 0.5614643096923828\n",
      "Ep 45: Batch #27 - Loss: 1.1439353227615356\n",
      "Ep 45: Batch #28 - Loss: 0.6914477348327637\n",
      "Ep 45: Batch #29 - Loss: 0.7576526403427124\n",
      "Ep 45: Batch #30 - Loss: 0.8450853824615479\n",
      "Ep 45: Batch #31 - Loss: 0.5619328022003174\n",
      "Ep 45: Batch #32 - Loss: 0.5820412635803223\n",
      "Ep 45: Batch #33 - Loss: 0.6682217121124268\n",
      "Ep 45: Batch #34 - Loss: 0.6420732140541077\n",
      "Ep 45: Batch #35 - Loss: 0.7252756357192993\n",
      "Ep 45: Batch #36 - Loss: 0.58360755443573\n",
      "Ep 45: Batch #37 - Loss: 0.9232335090637207\n",
      "Ep 45: Batch #38 - Loss: 0.571541965007782\n",
      "Ep 45: Batch #39 - Loss: 0.6876814365386963\n",
      "Ep 45: Batch #40 - Loss: 0.6054432988166809\n",
      "Ep 45: Batch #41 - Loss: 0.6213387250900269\n",
      "Ep 45: Batch #42 - Loss: 0.5704747438430786\n",
      "Ep 45: Batch #43 - Loss: 0.6334857940673828\n",
      "Ep 45: Batch #44 - Loss: 0.6151444315910339\n",
      "Ep 45: Batch #45 - Loss: 0.5276188850402832\n",
      "Ep 45: Batch #46 - Loss: 0.697747528553009\n",
      "Ep 45: Batch #47 - Loss: 0.8056268692016602\n",
      "Ep 45: Batch #48 - Loss: 1.0410983562469482\n",
      "Ep 45: Batch #49 - Loss: 0.8134167790412903\n",
      "Ep 45: Batch #50 - Loss: 0.5741689205169678\n",
      "Ep 45: Batch #51 - Loss: 0.8190418481826782\n",
      "Ep 45: Batch #52 - Loss: 0.67755526304245\n",
      "Ep 45: Batch #53 - Loss: 0.7170299887657166\n",
      "Ep 45: Batch #54 - Loss: 0.5800336003303528\n",
      "Ep 45: Batch #55 - Loss: 0.6087971925735474\n",
      "Ep 45: Batch #56 - Loss: 0.8627786636352539\n",
      "Ep 45: Batch #57 - Loss: 0.6828269958496094\n",
      "Ep 45: Batch #58 - Loss: 0.828292191028595\n",
      "Ep 45: Batch #59 - Loss: 0.5610752701759338\n",
      "Ep 45: Batch #60 - Loss: 1.012365460395813\n",
      "Ep 45: Batch #61 - Loss: 0.5355352759361267\n",
      "Ep 45: Batch #62 - Loss: 0.5752318501472473\n",
      "Ep 45: Batch #63 - Loss: 0.7859582901000977\n",
      "Ep 45: Batch #64 - Loss: 8.506545066833496\n",
      "Ep 45: Batch #65 - Loss: 0.5256472826004028\n",
      "Ep 45: Batch #66 - Loss: 0.6658381223678589\n",
      "Ep 45: Batch #67 - Loss: 0.7761713862419128\n",
      "Ep 45: Batch #68 - Loss: 0.7155702114105225\n",
      "Ep 45: Batch #69 - Loss: 0.5901452302932739\n",
      "Ep 45: Batch #70 - Loss: 0.6164935827255249\n",
      "Ep 45: Batch #71 - Loss: 0.5373080372810364\n",
      "Ep 45: Batch #72 - Loss: 0.6635030508041382\n",
      "Ep 45: Batch #73 - Loss: 0.7252882719039917\n",
      "Ep 45: Batch #74 - Loss: 0.5817693471908569\n",
      "Ep 45: Batch #75 - Loss: 0.6695003509521484\n",
      "Ep 45: Batch #76 - Loss: 0.9298834204673767\n",
      "Ep 45: Batch #77 - Loss: 0.5776062607765198\n",
      "Ep 45: Batch #78 - Loss: 0.923679769039154\n",
      "Ep 45: Batch #79 - Loss: 0.526904821395874\n",
      "Ep 45: Batch #80 - Loss: 0.6947349905967712\n",
      "Ep 45: Batch #81 - Loss: 1.5261932611465454\n",
      "Ep 45: Batch #82 - Loss: 0.7518357634544373\n",
      "Ep 45: Batch #83 - Loss: 1.2883083820343018\n",
      "Ep 45: Batch #84 - Loss: 0.5788185000419617\n",
      "Ep 45: Batch #85 - Loss: 0.79041588306427\n",
      "Ep 45: Batch #86 - Loss: 0.5492416024208069\n",
      "Ep 45: Batch #87 - Loss: 0.5737053751945496\n",
      "Ep 45: Batch #88 - Loss: 0.6592404246330261\n",
      "Ep 45: Batch #89 - Loss: 0.732081949710846\n",
      "Ep 45: Batch #90 - Loss: 0.9009590744972229\n",
      "Ep 45: Batch #91 - Loss: 0.649543046951294\n",
      "Ep 45: Batch #92 - Loss: 0.7343910932540894\n",
      "Ep 45: Batch #93 - Loss: 0.785537600517273\n",
      "Ep 45: Batch #94 - Loss: 0.7553885579109192\n",
      "Ep 45: Batch #95 - Loss: 0.7619518637657166\n",
      "Ep 45: Batch #96 - Loss: 0.7632777094841003\n",
      "Ep 45: Batch #97 - Loss: 0.5878676176071167\n",
      "Ep 45: Batch #98 - Loss: 0.5794010758399963\n",
      "Ep 45: Batch #99 - Loss: 0.8008609414100647\n",
      "Ep 45: Batch #100 - Loss: 0.5591556429862976\n",
      "Ep 45: Batch #101 - Loss: 0.865289032459259\n",
      "Ep 45: Batch #102 - Loss: 0.6135374307632446\n",
      "Ep 45: Batch #103 - Loss: 0.6385995745658875\n",
      "Ep 45: Batch #104 - Loss: 0.6618872880935669\n",
      "Ep 45: Batch #105 - Loss: 0.8157593607902527\n",
      "Ep 45: Batch #106 - Loss: 0.6277384161949158\n",
      "Ep 45: Batch #107 - Loss: 0.6152501106262207\n",
      "Ep 45: Batch #108 - Loss: 0.901767909526825\n",
      "Ep 45: Batch #109 - Loss: 0.6266695261001587\n",
      "Ep 45: Batch #110 - Loss: 0.7272380590438843\n",
      "Ep 45: Batch #111 - Loss: 1.0442019701004028\n",
      "Ep 45: Batch #112 - Loss: 0.7997300028800964\n",
      "Ep 45: Batch #113 - Loss: 0.659469485282898\n",
      "Ep 45: Batch #114 - Loss: 0.7301046848297119\n",
      "Ep 45: Batch #115 - Loss: 0.9074687957763672\n",
      "Ep 45: Batch #116 - Loss: 0.5227712392807007\n",
      "Ep 45: Batch #117 - Loss: 0.6804786920547485\n",
      "Ep 45: Batch #118 - Loss: 0.4568679928779602\n",
      "Ep 45: Batch #119 - Loss: 0.809326171875\n",
      "Ep 45: Batch #120 - Loss: 0.6610321402549744\n",
      "Ep 45: Batch #121 - Loss: 0.5617396831512451\n",
      "Ep 45: Batch #122 - Loss: 0.7124765515327454\n",
      "Ep 45: Batch #123 - Loss: 0.7195407152175903\n",
      "Ep 45: Batch #124 - Loss: 0.5575007200241089\n",
      "Ep 45: Batch #125 - Loss: 2.468773603439331\n",
      "Ep 45: Batch #126 - Loss: 0.9997127652168274\n",
      "Ep 45: Batch #127 - Loss: 0.5830780267715454\n",
      "Ep 45: Batch #128 - Loss: 0.8845276832580566\n",
      "Ep 45: Batch #129 - Loss: 0.6790293455123901\n",
      "Ep 45: Batch #130 - Loss: 0.5966082811355591\n",
      "Ep 45: Batch #131 - Loss: 0.8058935403823853\n",
      "Ep 45: Batch #132 - Loss: 0.6849854588508606\n",
      "Ep 45: Batch #133 - Loss: 0.6680603623390198\n",
      "Ep 45: Batch #134 - Loss: 0.6377545595169067\n",
      "Ep 45: Batch #135 - Loss: 0.8225193619728088\n",
      "Ep 45: Batch #136 - Loss: 1.04139244556427\n",
      "Ep 45: Batch #137 - Loss: 0.7543502449989319\n",
      "Ep 45: Batch #138 - Loss: 0.9009038209915161\n",
      "Ep 45: Batch #139 - Loss: 0.6774088144302368\n",
      "Ep 45: Batch #140 - Loss: 0.8450390696525574\n",
      "Ep 45: Batch #141 - Loss: 1.1301229000091553\n",
      "Ep 45: Batch #142 - Loss: 0.671848475933075\n",
      "Ep 45: Batch #143 - Loss: 0.7714908123016357\n",
      "Ep 45: Batch #144 - Loss: 0.6123830676078796\n",
      "Ep 45: Batch #145 - Loss: 0.5993958115577698\n",
      "Ep 45: Batch #146 - Loss: 0.704406201839447\n",
      "Ep 45: Batch #147 - Loss: 0.6678979992866516\n",
      "Ep 45: Batch #148 - Loss: 0.7564101815223694\n",
      "Ep 45: Batch #149 - Loss: 0.6250442266464233\n",
      "Ep 45: Batch #150 - Loss: 0.7215083241462708\n",
      "Ep 45: Batch #151 - Loss: 0.6292708516120911\n",
      "Ep 45: Batch #152 - Loss: 0.6085793972015381\n",
      "Ep 45: Batch #153 - Loss: 0.8283157348632812\n",
      "Ep 45: Batch #154 - Loss: 0.6335608959197998\n",
      "Ep 45: Batch #155 - Loss: 0.6917036175727844\n",
      "Ep 45: Batch #156 - Loss: 0.7890812158584595\n",
      "Ep 45: Batch #157 - Loss: 0.615009069442749\n",
      "Ep 45: Batch #158 - Loss: 0.718290388584137\n",
      "Ep 45: Batch #159 - Loss: 0.6014628410339355\n",
      "Ep 45: Batch #160 - Loss: 0.6990788578987122\n",
      "Ep 45: Batch #161 - Loss: 0.6701285243034363\n",
      "Ep 45: Batch #162 - Loss: 0.7195582389831543\n",
      "Ep 45: Batch #163 - Loss: 0.7600463032722473\n",
      "Ep 45: Batch #164 - Loss: 0.649046003818512\n",
      "Ep 45: Batch #165 - Loss: 1.3430180549621582\n",
      "Ep 45: Batch #166 - Loss: 0.5344720482826233\n",
      "Ep 45: Batch #167 - Loss: 0.7315423488616943\n",
      "Ep 45: Batch #168 - Loss: 0.693066418170929\n",
      "Ep 45: Batch #169 - Loss: 0.6681292653083801\n",
      "Ep 45: Batch #170 - Loss: 0.6287354826927185\n",
      "Ep 45: Batch #171 - Loss: 0.6414034962654114\n",
      "Ep 45: Batch #172 - Loss: 0.5348156094551086\n",
      "Ep 45: Batch #173 - Loss: 0.9305525422096252\n",
      "Ep 45: Batch #174 - Loss: 0.496768981218338\n",
      "Ep 45: Batch #175 - Loss: 0.6380230784416199\n",
      "Ep 45: Batch #176 - Loss: 0.8982585072517395\n",
      "Ep 45: Batch #177 - Loss: 0.6526721715927124\n",
      "Ep 45: Batch #178 - Loss: 0.6246988773345947\n",
      "Ep 45: Batch #179 - Loss: 0.7498774528503418\n",
      "Ep 45: Batch #180 - Loss: 0.6533408164978027\n",
      "Ep 45: Batch #181 - Loss: 0.8037351965904236\n",
      "Ep 45: Batch #182 - Loss: 0.6267642378807068\n",
      "Ep 45: Batch #183 - Loss: 0.6071535348892212\n",
      "Ep 45: Batch #184 - Loss: 0.9215566515922546\n",
      "Ep 45: Batch #185 - Loss: 0.633176863193512\n",
      "Ep 45: Batch #186 - Loss: 0.7591264247894287\n",
      "Ep 45: Batch #187 - Loss: 0.8689092397689819\n",
      "Ep 45: Batch #188 - Loss: 0.9680112600326538\n",
      "Ep 45: Batch #189 - Loss: 0.5876715183258057\n",
      "Ep 45: Batch #190 - Loss: 0.6243124008178711\n",
      "Ep 45: Batch #191 - Loss: 0.8093856573104858\n",
      "Ep 45: Batch #192 - Loss: 0.5711170434951782\n",
      "Ep 45: Batch #193 - Loss: 0.6303789019584656\n",
      "Ep 45: Batch #194 - Loss: 0.5455398559570312\n",
      "Ep 45: Batch #195 - Loss: 0.7904707193374634\n",
      "Ep 45: Batch #196 - Loss: 0.6928470134735107\n",
      "Ep 45: Batch #197 - Loss: 0.7015298008918762\n",
      "Ep 45: Batch #198 - Loss: 0.5341254472732544\n",
      "Ep 45: Batch #199 - Loss: 0.6458621621131897\n",
      "Ep 46: Batch #0 - Loss: 0.6508775353431702\n",
      "Ep 46: Batch #1 - Loss: 0.7150020599365234\n",
      "Ep 46: Batch #2 - Loss: 0.8603852987289429\n",
      "Ep 46: Batch #3 - Loss: 0.7238078713417053\n",
      "Ep 46: Batch #4 - Loss: 0.6575945615768433\n",
      "Ep 46: Batch #5 - Loss: 0.5605341792106628\n",
      "Ep 46: Batch #6 - Loss: 0.7399247288703918\n",
      "Ep 46: Batch #7 - Loss: 0.5765266418457031\n",
      "Ep 46: Batch #8 - Loss: 0.58856201171875\n",
      "Ep 46: Batch #9 - Loss: 1.0961195230484009\n",
      "Ep 46: Batch #10 - Loss: 0.8108314871788025\n",
      "Ep 46: Batch #11 - Loss: 0.5445343852043152\n",
      "Ep 46: Batch #12 - Loss: 1.2107731103897095\n",
      "Ep 46: Batch #13 - Loss: 0.5721547603607178\n",
      "Ep 46: Batch #14 - Loss: 0.601319432258606\n",
      "Ep 46: Batch #15 - Loss: 0.8586205840110779\n",
      "Ep 46: Batch #16 - Loss: 0.9543081521987915\n",
      "Ep 46: Batch #17 - Loss: 0.7300926446914673\n",
      "Ep 46: Batch #18 - Loss: 0.8079829216003418\n",
      "Ep 46: Batch #19 - Loss: 0.5642114877700806\n",
      "Ep 46: Batch #20 - Loss: 0.5475120544433594\n",
      "Ep 46: Batch #21 - Loss: 0.8326432704925537\n",
      "Ep 46: Batch #22 - Loss: 0.6111719608306885\n",
      "Ep 46: Batch #23 - Loss: 0.6007251143455505\n",
      "Ep 46: Batch #24 - Loss: 0.638969898223877\n",
      "Ep 46: Batch #25 - Loss: 0.6080771684646606\n",
      "Ep 46: Batch #26 - Loss: 0.5609574913978577\n",
      "Ep 46: Batch #27 - Loss: 1.1436450481414795\n",
      "Ep 46: Batch #28 - Loss: 0.6914297342300415\n",
      "Ep 46: Batch #29 - Loss: 0.7576423287391663\n",
      "Ep 46: Batch #30 - Loss: 0.8437031507492065\n",
      "Ep 46: Batch #31 - Loss: 0.5618575811386108\n",
      "Ep 46: Batch #32 - Loss: 0.5819440484046936\n",
      "Ep 46: Batch #33 - Loss: 0.6680996417999268\n",
      "Ep 46: Batch #34 - Loss: 0.6418893933296204\n",
      "Ep 46: Batch #35 - Loss: 0.7251942157745361\n",
      "Ep 46: Batch #36 - Loss: 0.5837762355804443\n",
      "Ep 46: Batch #37 - Loss: 0.9231262803077698\n",
      "Ep 46: Batch #38 - Loss: 0.571260392665863\n",
      "Ep 46: Batch #39 - Loss: 0.6869199872016907\n",
      "Ep 46: Batch #40 - Loss: 0.6052650809288025\n",
      "Ep 46: Batch #41 - Loss: 0.6213049292564392\n",
      "Ep 46: Batch #42 - Loss: 0.5703924298286438\n",
      "Ep 46: Batch #43 - Loss: 0.6334144473075867\n",
      "Ep 46: Batch #44 - Loss: 0.6150478720664978\n",
      "Ep 46: Batch #45 - Loss: 0.5270827412605286\n",
      "Ep 46: Batch #46 - Loss: 0.6976889967918396\n",
      "Ep 46: Batch #47 - Loss: 0.8056774735450745\n",
      "Ep 46: Batch #48 - Loss: 1.0411608219146729\n",
      "Ep 46: Batch #49 - Loss: 0.8133177757263184\n",
      "Ep 46: Batch #50 - Loss: 0.5742358565330505\n",
      "Ep 46: Batch #51 - Loss: 0.8191241025924683\n",
      "Ep 46: Batch #52 - Loss: 0.6774806380271912\n",
      "Ep 46: Batch #53 - Loss: 0.7169100642204285\n",
      "Ep 46: Batch #54 - Loss: 0.579902172088623\n",
      "Ep 46: Batch #55 - Loss: 0.6091387867927551\n",
      "Ep 46: Batch #56 - Loss: 0.8620796203613281\n",
      "Ep 46: Batch #57 - Loss: 0.6827639937400818\n",
      "Ep 46: Batch #58 - Loss: 0.8283759355545044\n",
      "Ep 46: Batch #59 - Loss: 0.5608670711517334\n",
      "Ep 46: Batch #60 - Loss: 1.0117981433868408\n",
      "Ep 46: Batch #61 - Loss: 0.5355507135391235\n",
      "Ep 46: Batch #62 - Loss: 0.5751917362213135\n",
      "Ep 46: Batch #63 - Loss: 0.7855396270751953\n",
      "Ep 46: Batch #64 - Loss: 8.483813285827637\n",
      "Ep 46: Batch #65 - Loss: 0.5257386565208435\n",
      "Ep 46: Batch #66 - Loss: 0.6663569211959839\n",
      "Ep 46: Batch #67 - Loss: 0.7768028378486633\n",
      "Ep 46: Batch #68 - Loss: 0.7169632315635681\n",
      "Ep 46: Batch #69 - Loss: 0.591485857963562\n",
      "Ep 46: Batch #70 - Loss: 0.6191661953926086\n",
      "Ep 46: Batch #71 - Loss: 0.5380690097808838\n",
      "Ep 46: Batch #72 - Loss: 0.6657717823982239\n",
      "Ep 46: Batch #73 - Loss: 0.7261784076690674\n",
      "Ep 46: Batch #74 - Loss: 0.5803442597389221\n",
      "Ep 46: Batch #75 - Loss: 0.6700459718704224\n",
      "Ep 46: Batch #76 - Loss: 0.9288327097892761\n",
      "Ep 46: Batch #77 - Loss: 0.5778477787971497\n",
      "Ep 46: Batch #78 - Loss: 0.924033522605896\n",
      "Ep 46: Batch #79 - Loss: 0.5278574228286743\n",
      "Ep 46: Batch #80 - Loss: 0.6960650682449341\n",
      "Ep 46: Batch #81 - Loss: 1.5297945737838745\n",
      "Ep 46: Batch #82 - Loss: 0.7525363564491272\n",
      "Ep 46: Batch #83 - Loss: 1.2872658967971802\n",
      "Ep 46: Batch #84 - Loss: 0.5828955173492432\n",
      "Ep 46: Batch #85 - Loss: 0.7919749617576599\n",
      "Ep 46: Batch #86 - Loss: 0.5510130524635315\n",
      "Ep 46: Batch #87 - Loss: 0.5742207169532776\n",
      "Ep 46: Batch #88 - Loss: 0.6597360372543335\n",
      "Ep 46: Batch #89 - Loss: 0.733192503452301\n",
      "Ep 46: Batch #90 - Loss: 0.9014586210250854\n",
      "Ep 46: Batch #91 - Loss: 0.6495122909545898\n",
      "Ep 46: Batch #92 - Loss: 0.7389217019081116\n",
      "Ep 46: Batch #93 - Loss: 0.7851905226707458\n",
      "Ep 46: Batch #94 - Loss: 0.7544947266578674\n",
      "Ep 46: Batch #95 - Loss: 0.7625987529754639\n",
      "Ep 46: Batch #96 - Loss: 0.7636767625808716\n",
      "Ep 46: Batch #97 - Loss: 0.5884556174278259\n",
      "Ep 46: Batch #98 - Loss: 0.5805736780166626\n",
      "Ep 46: Batch #99 - Loss: 0.7992918491363525\n",
      "Ep 46: Batch #100 - Loss: 0.5589844584465027\n",
      "Ep 46: Batch #101 - Loss: 0.8658286333084106\n",
      "Ep 46: Batch #102 - Loss: 0.6141597032546997\n",
      "Ep 46: Batch #103 - Loss: 0.6386808753013611\n",
      "Ep 46: Batch #104 - Loss: 0.6631050109863281\n",
      "Ep 46: Batch #105 - Loss: 0.8180839419364929\n",
      "Ep 46: Batch #106 - Loss: 0.628014087677002\n",
      "Ep 46: Batch #107 - Loss: 0.6156502962112427\n",
      "Ep 46: Batch #108 - Loss: 0.9026214480400085\n",
      "Ep 46: Batch #109 - Loss: 0.6260427832603455\n",
      "Ep 46: Batch #110 - Loss: 0.7265859842300415\n",
      "Ep 46: Batch #111 - Loss: 1.0442053079605103\n",
      "Ep 46: Batch #112 - Loss: 0.8000867962837219\n",
      "Ep 46: Batch #113 - Loss: 0.6588603258132935\n",
      "Ep 46: Batch #114 - Loss: 0.7294603586196899\n",
      "Ep 46: Batch #115 - Loss: 0.9081547856330872\n",
      "Ep 46: Batch #116 - Loss: 0.5233125686645508\n",
      "Ep 46: Batch #117 - Loss: 0.6806625127792358\n",
      "Ep 46: Batch #118 - Loss: 0.4570225775241852\n",
      "Ep 46: Batch #119 - Loss: 0.810265302658081\n",
      "Ep 46: Batch #120 - Loss: 0.6605890393257141\n",
      "Ep 46: Batch #121 - Loss: 0.5622848868370056\n",
      "Ep 46: Batch #122 - Loss: 0.7125410437583923\n",
      "Ep 46: Batch #123 - Loss: 0.7193910479545593\n",
      "Ep 46: Batch #124 - Loss: 0.5574169754981995\n",
      "Ep 46: Batch #125 - Loss: 2.469764471054077\n",
      "Ep 46: Batch #126 - Loss: 0.9995997548103333\n",
      "Ep 46: Batch #127 - Loss: 0.5834320783615112\n",
      "Ep 46: Batch #128 - Loss: 0.8853982090950012\n",
      "Ep 46: Batch #129 - Loss: 0.6789074540138245\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 46: Batch #130 - Loss: 0.5965728163719177\n",
      "Ep 46: Batch #131 - Loss: 0.8060920834541321\n",
      "Ep 46: Batch #132 - Loss: 0.6852399110794067\n",
      "Ep 46: Batch #133 - Loss: 0.6686542630195618\n",
      "Ep 46: Batch #134 - Loss: 0.6372948288917542\n",
      "Ep 46: Batch #135 - Loss: 0.8221501708030701\n",
      "Ep 46: Batch #136 - Loss: 1.0422029495239258\n",
      "Ep 46: Batch #137 - Loss: 0.7545217871665955\n",
      "Ep 46: Batch #138 - Loss: 0.900687038898468\n",
      "Ep 46: Batch #139 - Loss: 0.6770671010017395\n",
      "Ep 46: Batch #140 - Loss: 0.8453618288040161\n",
      "Ep 46: Batch #141 - Loss: 1.1301493644714355\n",
      "Ep 46: Batch #142 - Loss: 0.6712948679924011\n",
      "Ep 46: Batch #143 - Loss: 0.7718759179115295\n",
      "Ep 46: Batch #144 - Loss: 0.6126636266708374\n",
      "Ep 46: Batch #145 - Loss: 0.6001384258270264\n",
      "Ep 46: Batch #146 - Loss: 0.7038815021514893\n",
      "Ep 46: Batch #147 - Loss: 0.6682812571525574\n",
      "Ep 46: Batch #148 - Loss: 0.7570440173149109\n",
      "Ep 46: Batch #149 - Loss: 0.6244068145751953\n",
      "Ep 46: Batch #150 - Loss: 0.7211080193519592\n",
      "Ep 46: Batch #151 - Loss: 0.6285891532897949\n",
      "Ep 46: Batch #152 - Loss: 0.6081287264823914\n",
      "Ep 46: Batch #153 - Loss: 0.8283935785293579\n",
      "Ep 46: Batch #154 - Loss: 0.6334682106971741\n",
      "Ep 46: Batch #155 - Loss: 0.6943410038948059\n",
      "Ep 46: Batch #156 - Loss: 0.7888999581336975\n",
      "Ep 46: Batch #157 - Loss: 0.6149404048919678\n",
      "Ep 46: Batch #158 - Loss: 0.7181060910224915\n",
      "Ep 46: Batch #159 - Loss: 0.6013751029968262\n",
      "Ep 46: Batch #160 - Loss: 0.698952853679657\n",
      "Ep 46: Batch #161 - Loss: 0.6700819730758667\n",
      "Ep 46: Batch #162 - Loss: 0.7190654277801514\n",
      "Ep 46: Batch #163 - Loss: 0.7598931789398193\n",
      "Ep 46: Batch #164 - Loss: 0.6491615772247314\n",
      "Ep 46: Batch #165 - Loss: 1.3419852256774902\n",
      "Ep 46: Batch #166 - Loss: 0.5343786478042603\n",
      "Ep 46: Batch #167 - Loss: 0.7301663160324097\n",
      "Ep 46: Batch #168 - Loss: 0.6933149695396423\n",
      "Ep 46: Batch #169 - Loss: 0.6679090261459351\n",
      "Ep 46: Batch #170 - Loss: 0.6289948225021362\n",
      "Ep 46: Batch #171 - Loss: 0.6412761211395264\n",
      "Ep 46: Batch #172 - Loss: 0.5348659157752991\n",
      "Ep 46: Batch #173 - Loss: 0.9306007623672485\n",
      "Ep 46: Batch #174 - Loss: 0.4967096149921417\n",
      "Ep 46: Batch #175 - Loss: 0.6378200054168701\n",
      "Ep 46: Batch #176 - Loss: 0.8974480032920837\n",
      "Ep 46: Batch #177 - Loss: 0.652584433555603\n",
      "Ep 46: Batch #178 - Loss: 0.6245596408843994\n",
      "Ep 46: Batch #179 - Loss: 0.7501676678657532\n",
      "Ep 46: Batch #180 - Loss: 0.6536214351654053\n",
      "Ep 46: Batch #181 - Loss: 0.8034946918487549\n",
      "Ep 46: Batch #182 - Loss: 0.6272073984146118\n",
      "Ep 46: Batch #183 - Loss: 0.6070221066474915\n",
      "Ep 46: Batch #184 - Loss: 0.9218554496765137\n",
      "Ep 46: Batch #185 - Loss: 0.633194088935852\n",
      "Ep 46: Batch #186 - Loss: 0.7586591839790344\n",
      "Ep 46: Batch #187 - Loss: 0.8699849843978882\n",
      "Ep 46: Batch #188 - Loss: 0.968656599521637\n",
      "Ep 46: Batch #189 - Loss: 0.5878332257270813\n",
      "Ep 46: Batch #190 - Loss: 0.624279797077179\n",
      "Ep 46: Batch #191 - Loss: 0.8094791173934937\n",
      "Ep 46: Batch #192 - Loss: 0.5713964700698853\n",
      "Ep 46: Batch #193 - Loss: 0.6304193735122681\n",
      "Ep 46: Batch #194 - Loss: 0.5454307794570923\n",
      "Ep 46: Batch #195 - Loss: 0.7902677059173584\n",
      "Ep 46: Batch #196 - Loss: 0.693183183670044\n",
      "Ep 46: Batch #197 - Loss: 0.7021172642707825\n",
      "Ep 46: Batch #198 - Loss: 0.5341559052467346\n",
      "Ep 46: Batch #199 - Loss: 0.6456521153450012\n",
      "Ep 47: Batch #0 - Loss: 0.6511809229850769\n",
      "Ep 47: Batch #1 - Loss: 0.7151716947555542\n",
      "Ep 47: Batch #2 - Loss: 0.8604471683502197\n",
      "Ep 47: Batch #3 - Loss: 0.7240455746650696\n",
      "Ep 47: Batch #4 - Loss: 0.6577466726303101\n",
      "Ep 47: Batch #5 - Loss: 0.5592400431632996\n",
      "Ep 47: Batch #6 - Loss: 0.7391180992126465\n",
      "Ep 47: Batch #7 - Loss: 0.576630711555481\n",
      "Ep 47: Batch #8 - Loss: 0.5882720947265625\n",
      "Ep 47: Batch #9 - Loss: 1.0962694883346558\n",
      "Ep 47: Batch #10 - Loss: 0.8104900121688843\n",
      "Ep 47: Batch #11 - Loss: 0.5445042848587036\n",
      "Ep 47: Batch #12 - Loss: 1.2100801467895508\n",
      "Ep 47: Batch #13 - Loss: 0.5721749663352966\n",
      "Ep 47: Batch #14 - Loss: 0.6011683940887451\n",
      "Ep 47: Batch #15 - Loss: 0.8578832745552063\n",
      "Ep 47: Batch #16 - Loss: 0.9550616145133972\n",
      "Ep 47: Batch #17 - Loss: 0.7302998304367065\n",
      "Ep 47: Batch #18 - Loss: 0.8081437349319458\n",
      "Ep 47: Batch #19 - Loss: 0.5641952157020569\n",
      "Ep 47: Batch #20 - Loss: 0.5476081371307373\n",
      "Ep 47: Batch #21 - Loss: 0.8316450119018555\n",
      "Ep 47: Batch #22 - Loss: 0.6109235882759094\n",
      "Ep 47: Batch #23 - Loss: 0.6008215546607971\n",
      "Ep 47: Batch #24 - Loss: 0.6391541957855225\n",
      "Ep 47: Batch #25 - Loss: 0.6077542901039124\n",
      "Ep 47: Batch #26 - Loss: 0.5608343482017517\n",
      "Ep 47: Batch #27 - Loss: 1.1438217163085938\n",
      "Ep 47: Batch #28 - Loss: 0.6916692852973938\n",
      "Ep 47: Batch #29 - Loss: 0.7573914527893066\n",
      "Ep 47: Batch #30 - Loss: 0.8423162698745728\n",
      "Ep 47: Batch #31 - Loss: 0.5617170333862305\n",
      "Ep 47: Batch #32 - Loss: 0.5818252563476562\n",
      "Ep 47: Batch #33 - Loss: 0.667974054813385\n",
      "Ep 47: Batch #34 - Loss: 0.6412899494171143\n",
      "Ep 47: Batch #35 - Loss: 0.7248897552490234\n",
      "Ep 47: Batch #36 - Loss: 0.5838044285774231\n",
      "Ep 47: Batch #37 - Loss: 0.9234579801559448\n",
      "Ep 47: Batch #38 - Loss: 0.5710558891296387\n",
      "Ep 47: Batch #39 - Loss: 0.6865285634994507\n",
      "Ep 47: Batch #40 - Loss: 0.6058100461959839\n",
      "Ep 47: Batch #41 - Loss: 0.6208460330963135\n",
      "Ep 47: Batch #42 - Loss: 0.5702705979347229\n",
      "Ep 47: Batch #43 - Loss: 0.6334092020988464\n",
      "Ep 47: Batch #44 - Loss: 0.6149135231971741\n",
      "Ep 47: Batch #45 - Loss: 0.5268434882164001\n",
      "Ep 47: Batch #46 - Loss: 0.6975342035293579\n",
      "Ep 47: Batch #47 - Loss: 0.8054983615875244\n",
      "Ep 47: Batch #48 - Loss: 1.040670394897461\n",
      "Ep 47: Batch #49 - Loss: 0.8133497834205627\n",
      "Ep 47: Batch #50 - Loss: 0.5741627812385559\n",
      "Ep 47: Batch #51 - Loss: 0.8191717863082886\n",
      "Ep 47: Batch #52 - Loss: 0.6772637963294983\n",
      "Ep 47: Batch #53 - Loss: 0.7168814539909363\n",
      "Ep 47: Batch #54 - Loss: 0.579588770866394\n",
      "Ep 47: Batch #55 - Loss: 0.6091282963752747\n",
      "Ep 47: Batch #56 - Loss: 0.8615971803665161\n",
      "Ep 47: Batch #57 - Loss: 0.6828227639198303\n",
      "Ep 47: Batch #58 - Loss: 0.828156054019928\n",
      "Ep 47: Batch #59 - Loss: 0.560711145401001\n",
      "Ep 47: Batch #60 - Loss: 1.011385202407837\n",
      "Ep 47: Batch #61 - Loss: 0.5356639623641968\n",
      "Ep 47: Batch #62 - Loss: 0.5751011371612549\n",
      "Ep 47: Batch #63 - Loss: 0.7854634523391724\n",
      "Ep 47: Batch #64 - Loss: 8.490565299987793\n",
      "Ep 47: Batch #65 - Loss: 0.5257803201675415\n",
      "Ep 47: Batch #66 - Loss: 0.6656721234321594\n",
      "Ep 47: Batch #67 - Loss: 0.7762385606765747\n",
      "Ep 47: Batch #68 - Loss: 0.7152323126792908\n",
      "Ep 47: Batch #69 - Loss: 0.589594304561615\n",
      "Ep 47: Batch #70 - Loss: 0.6163749098777771\n",
      "Ep 47: Batch #71 - Loss: 0.5371019840240479\n",
      "Ep 47: Batch #72 - Loss: 0.663525402545929\n",
      "Ep 47: Batch #73 - Loss: 0.724342942237854\n",
      "Ep 47: Batch #74 - Loss: 0.5797901749610901\n",
      "Ep 47: Batch #75 - Loss: 0.6690624356269836\n",
      "Ep 47: Batch #76 - Loss: 0.9286257028579712\n",
      "Ep 47: Batch #77 - Loss: 0.5771604180335999\n",
      "Ep 47: Batch #78 - Loss: 0.9234944581985474\n",
      "Ep 47: Batch #79 - Loss: 0.5270702838897705\n",
      "Ep 47: Batch #80 - Loss: 0.6945844888687134\n",
      "Ep 47: Batch #81 - Loss: 1.5267070531845093\n",
      "Ep 47: Batch #82 - Loss: 0.751373827457428\n",
      "Ep 47: Batch #83 - Loss: 1.2852531671524048\n",
      "Ep 47: Batch #84 - Loss: 0.578262209892273\n",
      "Ep 47: Batch #85 - Loss: 0.7885304093360901\n",
      "Ep 47: Batch #86 - Loss: 0.5493571758270264\n",
      "Ep 47: Batch #87 - Loss: 0.5738935470581055\n",
      "Ep 47: Batch #88 - Loss: 0.6587180495262146\n",
      "Ep 47: Batch #89 - Loss: 0.731902539730072\n",
      "Ep 47: Batch #90 - Loss: 0.9015373587608337\n",
      "Ep 47: Batch #91 - Loss: 0.6492473483085632\n",
      "Ep 47: Batch #92 - Loss: 0.7336943745613098\n",
      "Ep 47: Batch #93 - Loss: 0.7848061323165894\n",
      "Ep 47: Batch #94 - Loss: 0.7530100345611572\n",
      "Ep 47: Batch #95 - Loss: 0.7618347406387329\n",
      "Ep 47: Batch #96 - Loss: 0.7636348605155945\n",
      "Ep 47: Batch #97 - Loss: 0.5869215726852417\n",
      "Ep 47: Batch #98 - Loss: 0.5789331197738647\n",
      "Ep 47: Batch #99 - Loss: 0.798445999622345\n",
      "Ep 47: Batch #100 - Loss: 0.5587712526321411\n",
      "Ep 47: Batch #101 - Loss: 0.8657440543174744\n",
      "Ep 47: Batch #102 - Loss: 0.6138192415237427\n",
      "Ep 47: Batch #103 - Loss: 0.6383016705513\n",
      "Ep 47: Batch #104 - Loss: 0.6620643138885498\n",
      "Ep 47: Batch #105 - Loss: 0.8159240484237671\n",
      "Ep 47: Batch #106 - Loss: 0.6274125576019287\n",
      "Ep 47: Batch #107 - Loss: 0.6155697703361511\n",
      "Ep 47: Batch #108 - Loss: 0.9013174176216125\n",
      "Ep 47: Batch #109 - Loss: 0.6267667412757874\n",
      "Ep 47: Batch #110 - Loss: 0.7268795967102051\n",
      "Ep 47: Batch #111 - Loss: 1.044025182723999\n",
      "Ep 47: Batch #112 - Loss: 0.7993558049201965\n",
      "Ep 47: Batch #113 - Loss: 0.658943235874176\n",
      "Ep 47: Batch #114 - Loss: 0.7291625142097473\n",
      "Ep 47: Batch #115 - Loss: 0.907799243927002\n",
      "Ep 47: Batch #116 - Loss: 0.5227572321891785\n",
      "Ep 47: Batch #117 - Loss: 0.6800417900085449\n",
      "Ep 47: Batch #118 - Loss: 0.4565165042877197\n",
      "Model saved in file: ./weights_autoencoder_sigmoid/model_e47b118_1516648797.870655.ckpt\n",
      "Ep 47: Batch #119 - Loss: 0.8094277381896973\n",
      "Ep 47: Batch #120 - Loss: 0.6602286100387573\n",
      "Ep 47: Batch #121 - Loss: 0.5619949698448181\n",
      "Ep 47: Batch #122 - Loss: 0.7119890451431274\n",
      "Ep 47: Batch #123 - Loss: 0.7191970348358154\n",
      "Ep 47: Batch #124 - Loss: 0.5572956204414368\n",
      "Ep 47: Batch #125 - Loss: 2.469308614730835\n",
      "Ep 47: Batch #126 - Loss: 0.9998159408569336\n",
      "Ep 47: Batch #127 - Loss: 0.5828053951263428\n",
      "Ep 47: Batch #128 - Loss: 0.8843790888786316\n",
      "Ep 47: Batch #129 - Loss: 0.6781055331230164\n",
      "Ep 47: Batch #130 - Loss: 0.5965713858604431\n",
      "Ep 47: Batch #131 - Loss: 0.8056989312171936\n",
      "Ep 47: Batch #132 - Loss: 0.684948205947876\n",
      "Ep 47: Batch #133 - Loss: 0.6681280136108398\n",
      "Ep 47: Batch #134 - Loss: 0.6372325420379639\n",
      "Ep 47: Batch #135 - Loss: 0.8225443959236145\n",
      "Ep 47: Batch #136 - Loss: 1.0413116216659546\n",
      "Ep 47: Batch #137 - Loss: 0.753864049911499\n",
      "Ep 47: Batch #138 - Loss: 0.9009370803833008\n",
      "Ep 47: Batch #139 - Loss: 0.6772077679634094\n",
      "Ep 47: Batch #140 - Loss: 0.8452597856521606\n",
      "Ep 47: Batch #141 - Loss: 1.1298023462295532\n",
      "Ep 47: Batch #142 - Loss: 0.671698272228241\n",
      "Ep 47: Batch #143 - Loss: 0.7714911699295044\n",
      "Ep 47: Batch #144 - Loss: 0.6127678751945496\n",
      "Ep 47: Batch #145 - Loss: 0.6000009179115295\n",
      "Ep 47: Batch #146 - Loss: 0.703513503074646\n",
      "Ep 47: Batch #147 - Loss: 0.6675834655761719\n",
      "Ep 47: Batch #148 - Loss: 0.7560329437255859\n",
      "Ep 47: Batch #149 - Loss: 0.6228165626525879\n",
      "Ep 47: Batch #150 - Loss: 0.7211788296699524\n",
      "Ep 47: Batch #151 - Loss: 0.6286852359771729\n",
      "Ep 47: Batch #152 - Loss: 0.6081801652908325\n",
      "Ep 47: Batch #153 - Loss: 0.8280752897262573\n",
      "Ep 47: Batch #154 - Loss: 0.6330664753913879\n",
      "Ep 47: Batch #155 - Loss: 0.6916837692260742\n",
      "Ep 47: Batch #156 - Loss: 0.7878991365432739\n",
      "Ep 47: Batch #157 - Loss: 0.6146059632301331\n",
      "Ep 47: Batch #158 - Loss: 0.7181705832481384\n",
      "Ep 47: Batch #159 - Loss: 0.6007311940193176\n",
      "Ep 47: Batch #160 - Loss: 0.6982713937759399\n",
      "Ep 47: Batch #161 - Loss: 0.6701319813728333\n",
      "Ep 47: Batch #162 - Loss: 0.718883752822876\n",
      "Ep 47: Batch #163 - Loss: 0.7599883675575256\n",
      "Ep 47: Batch #164 - Loss: 0.6487623453140259\n",
      "Ep 47: Batch #165 - Loss: 1.3425028324127197\n",
      "Ep 47: Batch #166 - Loss: 0.5342826843261719\n",
      "Ep 47: Batch #167 - Loss: 0.7280997037887573\n",
      "Ep 47: Batch #168 - Loss: 0.6928355693817139\n",
      "Ep 47: Batch #169 - Loss: 0.6677983999252319\n",
      "Ep 47: Batch #170 - Loss: 0.6286084651947021\n",
      "Ep 47: Batch #171 - Loss: 0.6412952542304993\n",
      "Ep 47: Batch #172 - Loss: 0.5349804162979126\n",
      "Ep 47: Batch #173 - Loss: 0.9307000041007996\n",
      "Ep 47: Batch #174 - Loss: 0.49689778685569763\n",
      "Ep 47: Batch #175 - Loss: 0.63727867603302\n",
      "Ep 47: Batch #176 - Loss: 0.897412896156311\n",
      "Ep 47: Batch #177 - Loss: 0.6523093581199646\n",
      "Ep 47: Batch #178 - Loss: 0.6245108246803284\n",
      "Ep 47: Batch #179 - Loss: 0.7497690916061401\n",
      "Ep 47: Batch #180 - Loss: 0.6529428958892822\n",
      "Ep 47: Batch #181 - Loss: 0.803219199180603\n",
      "Ep 47: Batch #182 - Loss: 0.6271499991416931\n",
      "Ep 47: Batch #183 - Loss: 0.6069575548171997\n",
      "Ep 47: Batch #184 - Loss: 0.9216180443763733\n",
      "Ep 47: Batch #185 - Loss: 0.6333338618278503\n",
      "Ep 47: Batch #186 - Loss: 0.7576474547386169\n",
      "Ep 47: Batch #187 - Loss: 0.8687180876731873\n",
      "Ep 47: Batch #188 - Loss: 0.965899646282196\n",
      "Ep 47: Batch #189 - Loss: 0.5874923467636108\n",
      "Ep 47: Batch #190 - Loss: 0.6242468953132629\n",
      "Ep 47: Batch #191 - Loss: 0.8089567422866821\n",
      "Ep 47: Batch #192 - Loss: 0.5709468722343445\n",
      "Ep 47: Batch #193 - Loss: 0.6304000616073608\n",
      "Ep 47: Batch #194 - Loss: 0.5450748205184937\n",
      "Ep 47: Batch #195 - Loss: 0.7898039221763611\n",
      "Ep 47: Batch #196 - Loss: 0.6927955150604248\n",
      "Ep 47: Batch #197 - Loss: 0.7017102241516113\n",
      "Ep 47: Batch #198 - Loss: 0.5339798927307129\n",
      "Ep 47: Batch #199 - Loss: 0.6452630162239075\n",
      "Ep 48: Batch #0 - Loss: 0.6509976387023926\n",
      "Ep 48: Batch #1 - Loss: 0.7150136828422546\n",
      "Ep 48: Batch #2 - Loss: 0.860312819480896\n",
      "Ep 48: Batch #3 - Loss: 0.7233965396881104\n",
      "Ep 48: Batch #4 - Loss: 0.6575748324394226\n",
      "Ep 48: Batch #5 - Loss: 0.5566943883895874\n",
      "Ep 48: Batch #6 - Loss: 0.7389953136444092\n",
      "Ep 48: Batch #7 - Loss: 0.5764864087104797\n",
      "Ep 48: Batch #8 - Loss: 0.5876526236534119\n",
      "Ep 48: Batch #9 - Loss: 1.0955415964126587\n",
      "Ep 48: Batch #10 - Loss: 0.8096480965614319\n",
      "Ep 48: Batch #11 - Loss: 0.5444885492324829\n",
      "Ep 48: Batch #12 - Loss: 1.2091954946517944\n",
      "Ep 48: Batch #13 - Loss: 0.572043240070343\n",
      "Ep 48: Batch #14 - Loss: 0.6010262370109558\n",
      "Ep 48: Batch #15 - Loss: 0.8567185997962952\n",
      "Ep 48: Batch #16 - Loss: 0.9548588991165161\n",
      "Ep 48: Batch #17 - Loss: 0.7302704453468323\n",
      "Ep 48: Batch #18 - Loss: 0.8081142902374268\n",
      "Ep 48: Batch #19 - Loss: 0.564220666885376\n",
      "Ep 48: Batch #20 - Loss: 0.5474902391433716\n",
      "Ep 48: Batch #21 - Loss: 0.8304299116134644\n",
      "Ep 48: Batch #22 - Loss: 0.6102306246757507\n",
      "Ep 48: Batch #23 - Loss: 0.6005796790122986\n",
      "Ep 48: Batch #24 - Loss: 0.6388770937919617\n",
      "Ep 48: Batch #25 - Loss: 0.6074728965759277\n",
      "Ep 48: Batch #26 - Loss: 0.5603151917457581\n",
      "Ep 48: Batch #27 - Loss: 1.1437143087387085\n",
      "Ep 48: Batch #28 - Loss: 0.6916173100471497\n",
      "Ep 48: Batch #29 - Loss: 0.7568954825401306\n",
      "Ep 48: Batch #30 - Loss: 0.8406484723091125\n",
      "Ep 48: Batch #31 - Loss: 0.5616778135299683\n",
      "Ep 48: Batch #32 - Loss: 0.5817604064941406\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 48: Batch #33 - Loss: 0.6677762866020203\n",
      "Ep 48: Batch #34 - Loss: 0.6411441564559937\n",
      "Ep 48: Batch #35 - Loss: 0.7247652411460876\n",
      "Ep 48: Batch #36 - Loss: 0.5840653777122498\n",
      "Ep 48: Batch #37 - Loss: 0.9226606488227844\n",
      "Ep 48: Batch #38 - Loss: 0.570795476436615\n",
      "Ep 48: Batch #39 - Loss: 0.6866731643676758\n",
      "Ep 48: Batch #40 - Loss: 0.605243444442749\n",
      "Ep 48: Batch #41 - Loss: 0.6209183931350708\n",
      "Ep 48: Batch #42 - Loss: 0.570513129234314\n",
      "Ep 48: Batch #43 - Loss: 0.6331621408462524\n",
      "Ep 48: Batch #44 - Loss: 0.6147676110267639\n",
      "Ep 48: Batch #45 - Loss: 0.5264973640441895\n",
      "Ep 48: Batch #46 - Loss: 0.697613000869751\n",
      "Ep 48: Batch #47 - Loss: 0.8054948449134827\n",
      "Ep 48: Batch #48 - Loss: 1.0408765077590942\n",
      "Ep 48: Batch #49 - Loss: 0.8134907484054565\n",
      "Ep 48: Batch #50 - Loss: 0.5742031335830688\n",
      "Ep 48: Batch #51 - Loss: 0.8193236589431763\n",
      "Ep 48: Batch #52 - Loss: 0.6772401332855225\n",
      "Ep 48: Batch #53 - Loss: 0.7168294191360474\n",
      "Ep 48: Batch #54 - Loss: 0.5795207619667053\n",
      "Ep 48: Batch #55 - Loss: 0.6096435785293579\n",
      "Ep 48: Batch #56 - Loss: 0.8608746528625488\n",
      "Ep 48: Batch #57 - Loss: 0.6828208565711975\n",
      "Ep 48: Batch #58 - Loss: 0.8286343812942505\n",
      "Ep 48: Batch #59 - Loss: 0.5604969263076782\n",
      "Ep 48: Batch #60 - Loss: 1.0109621286392212\n",
      "Ep 48: Batch #61 - Loss: 0.5356107354164124\n",
      "Ep 48: Batch #62 - Loss: 0.5751877427101135\n",
      "Ep 48: Batch #63 - Loss: 0.7850187420845032\n",
      "Ep 48: Batch #64 - Loss: 8.471013069152832\n",
      "Ep 48: Batch #65 - Loss: 0.525719404220581\n",
      "Ep 48: Batch #66 - Loss: 0.6655744314193726\n",
      "Ep 48: Batch #67 - Loss: 0.7761875987052917\n",
      "Ep 48: Batch #68 - Loss: 0.7148506045341492\n",
      "Ep 48: Batch #69 - Loss: 0.5893770456314087\n",
      "Ep 48: Batch #70 - Loss: 0.6159592866897583\n",
      "Ep 48: Batch #71 - Loss: 0.5369624495506287\n",
      "Ep 48: Batch #72 - Loss: 0.6633549928665161\n",
      "Ep 48: Batch #73 - Loss: 0.7242429256439209\n",
      "Ep 48: Batch #74 - Loss: 0.5794677734375\n",
      "Ep 48: Batch #75 - Loss: 0.6689655780792236\n",
      "Ep 48: Batch #76 - Loss: 0.9284829497337341\n",
      "Ep 48: Batch #77 - Loss: 0.5768147110939026\n",
      "Ep 48: Batch #78 - Loss: 0.9232885837554932\n",
      "Ep 48: Batch #79 - Loss: 0.5268189907073975\n",
      "Ep 48: Batch #80 - Loss: 0.6945691108703613\n",
      "Ep 48: Batch #81 - Loss: 1.5256940126419067\n",
      "Ep 48: Batch #82 - Loss: 0.7519317269325256\n",
      "Ep 48: Batch #83 - Loss: 1.2820839881896973\n",
      "Ep 48: Batch #84 - Loss: 0.5778661966323853\n",
      "Ep 48: Batch #85 - Loss: 0.7883315682411194\n",
      "Ep 48: Batch #86 - Loss: 0.5491011738777161\n",
      "Ep 48: Batch #87 - Loss: 0.5735029578208923\n",
      "Ep 48: Batch #88 - Loss: 0.6588588356971741\n",
      "Ep 48: Batch #89 - Loss: 0.7312474846839905\n",
      "Ep 48: Batch #90 - Loss: 0.9014593362808228\n",
      "Ep 48: Batch #91 - Loss: 0.649323046207428\n",
      "Ep 48: Batch #92 - Loss: 0.7333737015724182\n",
      "Ep 48: Batch #93 - Loss: 0.7844910621643066\n",
      "Ep 48: Batch #94 - Loss: 0.7522239089012146\n",
      "Ep 48: Batch #95 - Loss: 0.7612316608428955\n",
      "Ep 48: Batch #96 - Loss: 0.7630090117454529\n",
      "Ep 48: Batch #97 - Loss: 0.5866743922233582\n",
      "Ep 48: Batch #98 - Loss: 0.5785076022148132\n",
      "Ep 48: Batch #99 - Loss: 0.797472357749939\n",
      "Ep 48: Batch #100 - Loss: 0.5585560202598572\n",
      "Ep 48: Batch #101 - Loss: 0.8659329414367676\n",
      "Ep 48: Batch #102 - Loss: 0.6136982440948486\n",
      "Ep 48: Batch #103 - Loss: 0.6379731893539429\n",
      "Ep 48: Batch #104 - Loss: 0.6619192361831665\n",
      "Ep 48: Batch #105 - Loss: 0.8158454298973083\n",
      "Ep 48: Batch #106 - Loss: 0.6276117563247681\n",
      "Ep 48: Batch #107 - Loss: 0.6152047514915466\n",
      "Ep 48: Batch #108 - Loss: 0.9018983840942383\n",
      "Ep 48: Batch #109 - Loss: 0.6265397667884827\n",
      "Ep 48: Batch #110 - Loss: 0.7261903285980225\n",
      "Ep 48: Batch #111 - Loss: 1.043853759765625\n",
      "Ep 48: Batch #112 - Loss: 0.799045979976654\n",
      "Ep 48: Batch #113 - Loss: 0.6591865420341492\n",
      "Ep 48: Batch #114 - Loss: 0.7289609313011169\n",
      "Ep 48: Batch #115 - Loss: 0.9078484177589417\n",
      "Ep 48: Batch #116 - Loss: 0.522705614566803\n",
      "Ep 48: Batch #117 - Loss: 0.6797835826873779\n",
      "Ep 48: Batch #118 - Loss: 0.4563884139060974\n",
      "Model saved in file: ./weights_autoencoder_sigmoid/model_e48b118_1516648798.0077846.ckpt\n",
      "Ep 48: Batch #119 - Loss: 0.8100989460945129\n",
      "Ep 48: Batch #120 - Loss: 0.6604793071746826\n",
      "Ep 48: Batch #121 - Loss: 0.5614696741104126\n",
      "Ep 48: Batch #122 - Loss: 0.7116422057151794\n",
      "Ep 48: Batch #123 - Loss: 0.7190090417861938\n",
      "Ep 48: Batch #124 - Loss: 0.5571994185447693\n",
      "Ep 48: Batch #125 - Loss: 2.46968412399292\n",
      "Ep 48: Batch #126 - Loss: 1.000057339668274\n",
      "Ep 48: Batch #127 - Loss: 0.5825987458229065\n",
      "Ep 48: Batch #128 - Loss: 0.8845679759979248\n",
      "Ep 48: Batch #129 - Loss: 0.6787369847297668\n",
      "Ep 48: Batch #130 - Loss: 0.5963926911354065\n",
      "Ep 48: Batch #131 - Loss: 0.8054248094558716\n",
      "Ep 48: Batch #132 - Loss: 0.6847904324531555\n",
      "Ep 48: Batch #133 - Loss: 0.6682253479957581\n",
      "Ep 48: Batch #134 - Loss: 0.637383222579956\n",
      "Ep 48: Batch #135 - Loss: 0.822746992111206\n",
      "Ep 48: Batch #136 - Loss: 1.0414363145828247\n",
      "Ep 48: Batch #137 - Loss: 0.7535409331321716\n",
      "Ep 48: Batch #138 - Loss: 0.9009730815887451\n",
      "Ep 48: Batch #139 - Loss: 0.6769117116928101\n",
      "Ep 48: Batch #140 - Loss: 0.8450064659118652\n",
      "Ep 48: Batch #141 - Loss: 1.129170298576355\n",
      "Ep 48: Batch #142 - Loss: 0.6715224981307983\n",
      "Ep 48: Batch #143 - Loss: 0.7715818881988525\n",
      "Ep 48: Batch #144 - Loss: 0.6127296686172485\n",
      "Ep 48: Batch #145 - Loss: 0.600011944770813\n",
      "Ep 48: Batch #146 - Loss: 0.7035162448883057\n",
      "Ep 48: Batch #147 - Loss: 0.6671051979064941\n",
      "Ep 48: Batch #148 - Loss: 0.7558739185333252\n",
      "Ep 48: Batch #149 - Loss: 0.6219261288642883\n",
      "Ep 48: Batch #150 - Loss: 0.7211422920227051\n",
      "Ep 48: Batch #151 - Loss: 0.6286811828613281\n",
      "Ep 48: Batch #152 - Loss: 0.6081103682518005\n",
      "Ep 48: Batch #153 - Loss: 0.8278995752334595\n",
      "Ep 48: Batch #154 - Loss: 0.6333932280540466\n",
      "Ep 48: Batch #155 - Loss: 0.6913921236991882\n",
      "Ep 48: Batch #156 - Loss: 0.7876089811325073\n",
      "Ep 48: Batch #157 - Loss: 0.6146832704544067\n",
      "Ep 48: Batch #158 - Loss: 0.7181934118270874\n",
      "Ep 48: Batch #159 - Loss: 0.600382924079895\n",
      "Ep 48: Batch #160 - Loss: 0.6980667114257812\n",
      "Ep 48: Batch #161 - Loss: 0.6701361536979675\n",
      "Ep 48: Batch #162 - Loss: 0.7187859416007996\n",
      "Ep 48: Batch #163 - Loss: 0.7598252296447754\n",
      "Ep 48: Batch #164 - Loss: 0.6487073302268982\n",
      "Ep 48: Batch #165 - Loss: 1.342098355293274\n",
      "Ep 48: Batch #166 - Loss: 0.5342578887939453\n",
      "Ep 48: Batch #167 - Loss: 0.7262306213378906\n",
      "Ep 48: Batch #168 - Loss: 0.6927070617675781\n",
      "Ep 48: Batch #169 - Loss: 0.6679229140281677\n",
      "Ep 48: Batch #170 - Loss: 0.6283756494522095\n",
      "Ep 48: Batch #171 - Loss: 0.641097903251648\n",
      "Ep 48: Batch #172 - Loss: 0.5347838997840881\n",
      "Ep 48: Batch #173 - Loss: 0.9303512573242188\n",
      "Ep 48: Batch #174 - Loss: 0.4965137541294098\n",
      "Ep 48: Batch #175 - Loss: 0.6374027729034424\n",
      "Ep 48: Batch #176 - Loss: 0.8973092436790466\n",
      "Ep 48: Batch #177 - Loss: 0.6521627306938171\n",
      "Ep 48: Batch #178 - Loss: 0.6243022084236145\n",
      "Ep 48: Batch #179 - Loss: 0.7495312690734863\n",
      "Ep 48: Batch #180 - Loss: 0.6528684496879578\n",
      "Ep 48: Batch #181 - Loss: 0.8030073642730713\n",
      "Ep 48: Batch #182 - Loss: 0.6270624399185181\n",
      "Ep 48: Batch #183 - Loss: 0.6069555878639221\n",
      "Ep 48: Batch #184 - Loss: 0.9214016199111938\n",
      "Ep 48: Batch #185 - Loss: 0.6330965161323547\n",
      "Ep 48: Batch #186 - Loss: 0.7571985125541687\n",
      "Ep 48: Batch #187 - Loss: 0.8681939840316772\n",
      "Ep 48: Batch #188 - Loss: 0.9638738632202148\n",
      "Ep 48: Batch #189 - Loss: 0.5872787833213806\n",
      "Ep 48: Batch #190 - Loss: 0.6240557432174683\n",
      "Ep 48: Batch #191 - Loss: 0.808427095413208\n",
      "Ep 48: Batch #192 - Loss: 0.5708385109901428\n",
      "Ep 48: Batch #193 - Loss: 0.6305069327354431\n",
      "Ep 48: Batch #194 - Loss: 0.544874906539917\n",
      "Ep 48: Batch #195 - Loss: 0.7897192239761353\n",
      "Ep 48: Batch #196 - Loss: 0.6929160356521606\n",
      "Ep 48: Batch #197 - Loss: 0.7016261219978333\n",
      "Ep 48: Batch #198 - Loss: 0.5340073108673096\n",
      "Ep 48: Batch #199 - Loss: 0.6452489495277405\n",
      "Ep 49: Batch #0 - Loss: 0.6511066555976868\n",
      "Ep 49: Batch #1 - Loss: 0.7150846719741821\n",
      "Ep 49: Batch #2 - Loss: 0.8603773713111877\n",
      "Ep 49: Batch #3 - Loss: 0.7232403755187988\n",
      "Ep 49: Batch #4 - Loss: 0.6573958992958069\n",
      "Ep 49: Batch #5 - Loss: 0.5561249256134033\n",
      "Ep 49: Batch #6 - Loss: 0.7387279272079468\n",
      "Ep 49: Batch #7 - Loss: 0.5766053795814514\n",
      "Ep 49: Batch #8 - Loss: 0.5876035690307617\n",
      "Ep 49: Batch #9 - Loss: 1.0954960584640503\n",
      "Ep 49: Batch #10 - Loss: 0.8089399337768555\n",
      "Ep 49: Batch #11 - Loss: 0.5444176197052002\n",
      "Ep 49: Batch #12 - Loss: 1.2085742950439453\n",
      "Ep 49: Batch #13 - Loss: 0.5719790458679199\n",
      "Ep 49: Batch #14 - Loss: 0.6009200215339661\n",
      "Ep 49: Batch #15 - Loss: 0.8561710715293884\n",
      "Ep 49: Batch #16 - Loss: 0.9549636840820312\n",
      "Ep 49: Batch #17 - Loss: 0.73029625415802\n",
      "Ep 49: Batch #18 - Loss: 0.8079827427864075\n",
      "Ep 49: Batch #19 - Loss: 0.5642659068107605\n",
      "Ep 49: Batch #20 - Loss: 0.5474626421928406\n",
      "Ep 49: Batch #21 - Loss: 0.8287299275398254\n",
      "Ep 49: Batch #22 - Loss: 0.6100704073905945\n",
      "Ep 49: Batch #23 - Loss: 0.6006243228912354\n",
      "Ep 49: Batch #24 - Loss: 0.6390206813812256\n",
      "Ep 49: Batch #25 - Loss: 0.6073052883148193\n",
      "Ep 49: Batch #26 - Loss: 0.5601122379302979\n",
      "Ep 49: Batch #27 - Loss: 1.143640160560608\n",
      "Ep 49: Batch #28 - Loss: 0.6916511654853821\n",
      "Ep 49: Batch #29 - Loss: 0.7563945055007935\n",
      "Ep 49: Batch #30 - Loss: 0.839388370513916\n",
      "Ep 49: Batch #31 - Loss: 0.5615660548210144\n",
      "Ep 49: Batch #32 - Loss: 0.5816782116889954\n",
      "Ep 49: Batch #33 - Loss: 0.6677321791648865\n",
      "Ep 49: Batch #34 - Loss: 0.6407124996185303\n",
      "Ep 49: Batch #35 - Loss: 0.7246542572975159\n",
      "Ep 49: Batch #36 - Loss: 0.5847192406654358\n",
      "Ep 49: Batch #37 - Loss: 0.922578752040863\n",
      "Ep 49: Batch #38 - Loss: 0.570649266242981\n",
      "Ep 49: Batch #39 - Loss: 0.6864412426948547\n",
      "Ep 49: Batch #40 - Loss: 0.6049706935882568\n",
      "Ep 49: Batch #41 - Loss: 0.6209052205085754\n",
      "Ep 49: Batch #42 - Loss: 0.5703935623168945\n",
      "Ep 49: Batch #43 - Loss: 0.6330392360687256\n",
      "Ep 49: Batch #44 - Loss: 0.6146993637084961\n",
      "Ep 49: Batch #45 - Loss: 0.5265058875083923\n",
      "Ep 49: Batch #46 - Loss: 0.6977431774139404\n",
      "Ep 49: Batch #47 - Loss: 0.8054832220077515\n",
      "Ep 49: Batch #48 - Loss: 1.0408059358596802\n",
      "Ep 49: Batch #49 - Loss: 0.8135504126548767\n",
      "Ep 49: Batch #50 - Loss: 0.5742709040641785\n",
      "Ep 49: Batch #51 - Loss: 0.8193325400352478\n",
      "Ep 49: Batch #52 - Loss: 0.6772032380104065\n",
      "Ep 49: Batch #53 - Loss: 0.7167264819145203\n",
      "Ep 49: Batch #54 - Loss: 0.579534649848938\n",
      "Ep 49: Batch #55 - Loss: 0.6092795133590698\n",
      "Ep 49: Batch #56 - Loss: 0.8601433634757996\n",
      "Ep 49: Batch #57 - Loss: 0.6829366087913513\n",
      "Ep 49: Batch #58 - Loss: 0.8284612894058228\n",
      "Ep 49: Batch #59 - Loss: 0.5603064298629761\n",
      "Ep 49: Batch #60 - Loss: 1.0105106830596924\n",
      "Ep 49: Batch #61 - Loss: 0.535592257976532\n",
      "Ep 49: Batch #62 - Loss: 0.5751938819885254\n",
      "Ep 49: Batch #63 - Loss: 0.7843797206878662\n",
      "Ep 49: Batch #64 - Loss: 8.454107284545898\n",
      "Ep 49: Batch #65 - Loss: 0.5256741642951965\n",
      "Ep 49: Batch #66 - Loss: 0.6655635833740234\n",
      "Ep 49: Batch #67 - Loss: 0.7760702967643738\n",
      "Ep 49: Batch #68 - Loss: 0.7146707773208618\n",
      "Ep 49: Batch #69 - Loss: 0.5891415476799011\n",
      "Ep 49: Batch #70 - Loss: 0.6158974766731262\n",
      "Ep 49: Batch #71 - Loss: 0.5369141101837158\n",
      "Ep 49: Batch #72 - Loss: 0.6633046269416809\n",
      "Ep 49: Batch #73 - Loss: 0.7239566445350647\n",
      "Ep 49: Batch #74 - Loss: 0.5792528986930847\n",
      "Ep 49: Batch #75 - Loss: 0.6688097715377808\n",
      "Ep 49: Batch #76 - Loss: 0.9281806945800781\n",
      "Ep 49: Batch #77 - Loss: 0.5768234133720398\n",
      "Ep 49: Batch #78 - Loss: 0.9230241775512695\n",
      "Ep 49: Batch #79 - Loss: 0.5268437266349792\n",
      "Ep 49: Batch #80 - Loss: 0.6944617629051208\n",
      "Ep 49: Batch #81 - Loss: 1.5255277156829834\n",
      "Ep 49: Batch #82 - Loss: 0.7520227432250977\n",
      "Ep 49: Batch #83 - Loss: 1.2789331674575806\n",
      "Ep 49: Batch #84 - Loss: 0.5779756903648376\n",
      "Ep 49: Batch #85 - Loss: 0.7878187894821167\n",
      "Ep 49: Batch #86 - Loss: 0.5489943027496338\n",
      "Ep 49: Batch #87 - Loss: 0.5733890533447266\n",
      "Ep 49: Batch #88 - Loss: 0.6590084433555603\n",
      "Ep 49: Batch #89 - Loss: 0.7310526371002197\n",
      "Ep 49: Batch #90 - Loss: 0.9015053510665894\n",
      "Ep 49: Batch #91 - Loss: 0.6493507623672485\n",
      "Ep 49: Batch #92 - Loss: 0.7332077622413635\n",
      "Ep 49: Batch #93 - Loss: 0.7843403220176697\n",
      "Ep 49: Batch #94 - Loss: 0.7514752149581909\n",
      "Ep 49: Batch #95 - Loss: 0.7613800764083862\n",
      "Ep 49: Batch #96 - Loss: 0.7606176137924194\n",
      "Ep 49: Batch #97 - Loss: 0.5864703059196472\n",
      "Ep 49: Batch #98 - Loss: 0.5782502889633179\n",
      "Ep 49: Batch #99 - Loss: 0.7975899577140808\n",
      "Ep 49: Batch #100 - Loss: 0.5584341287612915\n",
      "Ep 49: Batch #101 - Loss: 0.866155207157135\n",
      "Ep 49: Batch #102 - Loss: 0.613501787185669\n",
      "Ep 49: Batch #103 - Loss: 0.6376833915710449\n",
      "Ep 49: Batch #104 - Loss: 0.6618208289146423\n",
      "Ep 49: Batch #105 - Loss: 0.8158776164054871\n",
      "Ep 49: Batch #106 - Loss: 0.62725830078125\n",
      "Ep 49: Batch #107 - Loss: 0.6151533722877502\n",
      "Ep 49: Batch #108 - Loss: 0.9012404680252075\n",
      "Ep 49: Batch #109 - Loss: 0.6263836622238159\n",
      "Ep 49: Batch #110 - Loss: 0.7260056734085083\n",
      "Ep 49: Batch #111 - Loss: 1.0436975955963135\n",
      "Ep 49: Batch #112 - Loss: 0.7985277771949768\n",
      "Ep 49: Batch #113 - Loss: 0.6591700911521912\n",
      "Ep 49: Batch #114 - Loss: 0.7288423776626587\n",
      "Ep 49: Batch #115 - Loss: 0.9078366160392761\n",
      "Ep 49: Batch #116 - Loss: 0.5225858688354492\n",
      "Ep 49: Batch #117 - Loss: 0.6796826124191284\n",
      "Ep 49: Batch #118 - Loss: 0.4562777280807495\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved in file: ./weights_autoencoder_sigmoid/model_e49b118_1516648798.1453526.ckpt\n",
      "Ep 49: Batch #119 - Loss: 0.8100923299789429\n",
      "Ep 49: Batch #120 - Loss: 0.6604240536689758\n",
      "Ep 49: Batch #121 - Loss: 0.5613304972648621\n",
      "Ep 49: Batch #122 - Loss: 0.7114184498786926\n",
      "Ep 49: Batch #123 - Loss: 0.7187419533729553\n",
      "Ep 49: Batch #124 - Loss: 0.5571594834327698\n",
      "Ep 49: Batch #125 - Loss: 2.4704537391662598\n",
      "Ep 49: Batch #126 - Loss: 1.0005300045013428\n",
      "Ep 49: Batch #127 - Loss: 0.5829036831855774\n",
      "Ep 49: Batch #128 - Loss: 0.8845680952072144\n",
      "Ep 49: Batch #129 - Loss: 0.6785913705825806\n",
      "Ep 49: Batch #130 - Loss: 0.5963738560676575\n",
      "Ep 49: Batch #131 - Loss: 0.8054775595664978\n",
      "Ep 49: Batch #132 - Loss: 0.6849478483200073\n",
      "Ep 49: Batch #133 - Loss: 0.6686455607414246\n",
      "Ep 49: Batch #134 - Loss: 0.637212872505188\n",
      "Ep 49: Batch #135 - Loss: 0.8225440979003906\n",
      "Ep 49: Batch #136 - Loss: 1.0415207147598267\n",
      "Ep 49: Batch #137 - Loss: 0.7537400722503662\n",
      "Ep 49: Batch #138 - Loss: 0.9011027216911316\n",
      "Ep 49: Batch #139 - Loss: 0.6772885918617249\n",
      "Ep 49: Batch #140 - Loss: 0.8450268507003784\n",
      "Ep 49: Batch #141 - Loss: 1.1281489133834839\n",
      "Ep 49: Batch #142 - Loss: 0.6713414192199707\n",
      "Ep 49: Batch #143 - Loss: 0.771586537361145\n",
      "Ep 49: Batch #144 - Loss: 0.6126782894134521\n",
      "Ep 49: Batch #145 - Loss: 0.6004118919372559\n",
      "Ep 49: Batch #146 - Loss: 0.7027230262756348\n",
      "Ep 49: Batch #147 - Loss: 0.6669637560844421\n",
      "Ep 49: Batch #148 - Loss: 0.7559226751327515\n",
      "Ep 49: Batch #149 - Loss: 0.6211792230606079\n",
      "Ep 49: Batch #150 - Loss: 0.7210447788238525\n",
      "Ep 49: Batch #151 - Loss: 0.628499448299408\n",
      "Ep 49: Batch #152 - Loss: 0.6079244613647461\n",
      "Ep 49: Batch #153 - Loss: 0.8278703093528748\n",
      "Ep 49: Batch #154 - Loss: 0.6332995891571045\n",
      "Ep 49: Batch #155 - Loss: 0.6913575530052185\n",
      "Ep 49: Batch #156 - Loss: 0.787386417388916\n",
      "Ep 49: Batch #157 - Loss: 0.614109992980957\n",
      "Ep 49: Batch #158 - Loss: 0.7181130051612854\n",
      "Ep 49: Batch #159 - Loss: 0.6000545620918274\n",
      "Ep 49: Batch #160 - Loss: 0.6975998878479004\n",
      "Ep 49: Batch #161 - Loss: 0.6702062487602234\n",
      "Ep 49: Batch #162 - Loss: 0.7186229825019836\n",
      "Ep 49: Batch #163 - Loss: 0.7598420977592468\n",
      "Ep 49: Batch #164 - Loss: 0.64857017993927\n",
      "Ep 49: Batch #165 - Loss: 1.3417096138000488\n",
      "Ep 49: Batch #166 - Loss: 0.5343115329742432\n",
      "Ep 49: Batch #167 - Loss: 0.7245985865592957\n",
      "Ep 49: Batch #168 - Loss: 0.692770779132843\n",
      "Ep 49: Batch #169 - Loss: 0.6676591634750366\n",
      "Ep 49: Batch #170 - Loss: 0.6283481121063232\n",
      "Ep 49: Batch #171 - Loss: 0.6410990953445435\n",
      "Ep 49: Batch #172 - Loss: 0.5347177386283875\n",
      "Ep 49: Batch #173 - Loss: 0.9300497174263\n",
      "Ep 49: Batch #174 - Loss: 0.4963788390159607\n",
      "Ep 49: Batch #175 - Loss: 0.6373867392539978\n",
      "Ep 49: Batch #176 - Loss: 0.8971018195152283\n",
      "Ep 49: Batch #177 - Loss: 0.6520154476165771\n",
      "Ep 49: Batch #178 - Loss: 0.6242043972015381\n",
      "Ep 49: Batch #179 - Loss: 0.7492778301239014\n",
      "Ep 49: Batch #180 - Loss: 0.6524160504341125\n",
      "Ep 49: Batch #181 - Loss: 0.8031147122383118\n",
      "Ep 49: Batch #182 - Loss: 0.6270543336868286\n",
      "Ep 49: Batch #183 - Loss: 0.6069024801254272\n",
      "Ep 49: Batch #184 - Loss: 0.9213816523551941\n",
      "Ep 49: Batch #185 - Loss: 0.6333696246147156\n",
      "Ep 49: Batch #186 - Loss: 0.7569195032119751\n",
      "Ep 49: Batch #187 - Loss: 0.8683574199676514\n",
      "Ep 49: Batch #188 - Loss: 0.9622922539710999\n",
      "Ep 49: Batch #189 - Loss: 0.5871493816375732\n",
      "Ep 49: Batch #190 - Loss: 0.6240571737289429\n",
      "Ep 49: Batch #191 - Loss: 0.8082000017166138\n",
      "Ep 49: Batch #192 - Loss: 0.5708559155464172\n",
      "Ep 49: Batch #193 - Loss: 0.6305934190750122\n",
      "Ep 49: Batch #194 - Loss: 0.5447793006896973\n",
      "Ep 49: Batch #195 - Loss: 0.7892504334449768\n",
      "Ep 49: Batch #196 - Loss: 0.6930983662605286\n",
      "Ep 49: Batch #197 - Loss: 0.7016381025314331\n",
      "Ep 49: Batch #198 - Loss: 0.5338842272758484\n",
      "Ep 49: Batch #199 - Loss: 0.6450807452201843\n",
      "Ep 50: Batch #0 - Loss: 0.6513059735298157\n",
      "Ep 50: Batch #1 - Loss: 0.7152077555656433\n",
      "Ep 50: Batch #2 - Loss: 0.8602674603462219\n",
      "Ep 50: Batch #3 - Loss: 0.7232239842414856\n",
      "Ep 50: Batch #4 - Loss: 0.6573578715324402\n",
      "Ep 50: Batch #5 - Loss: 0.5562935471534729\n",
      "Ep 50: Batch #6 - Loss: 0.7386307716369629\n",
      "Ep 50: Batch #7 - Loss: 0.5766515135765076\n",
      "Ep 50: Batch #8 - Loss: 0.5873457193374634\n",
      "Ep 50: Batch #9 - Loss: 1.095461368560791\n",
      "Ep 50: Batch #10 - Loss: 0.8085111975669861\n",
      "Ep 50: Batch #11 - Loss: 0.5445983409881592\n",
      "Ep 50: Batch #12 - Loss: 1.2080130577087402\n",
      "Ep 50: Batch #13 - Loss: 0.571925938129425\n",
      "Ep 50: Batch #14 - Loss: 0.600857675075531\n",
      "Ep 50: Batch #15 - Loss: 0.8554513454437256\n",
      "Ep 50: Batch #16 - Loss: 0.954932451248169\n",
      "Ep 50: Batch #17 - Loss: 0.7302255630493164\n",
      "Ep 50: Batch #18 - Loss: 0.808144211769104\n",
      "Ep 50: Batch #19 - Loss: 0.564231812953949\n",
      "Ep 50: Batch #20 - Loss: 0.5475097894668579\n",
      "Ep 50: Batch #21 - Loss: 0.8271118998527527\n",
      "Ep 50: Batch #22 - Loss: 0.6100682616233826\n",
      "Ep 50: Batch #23 - Loss: 0.6006909012794495\n",
      "Ep 50: Batch #24 - Loss: 0.6390450596809387\n",
      "Ep 50: Batch #25 - Loss: 0.6072052121162415\n",
      "Ep 50: Batch #26 - Loss: 0.5597771406173706\n",
      "Ep 50: Batch #27 - Loss: 1.1435483694076538\n",
      "Ep 50: Batch #28 - Loss: 0.6915872097015381\n",
      "Ep 50: Batch #29 - Loss: 0.7564101219177246\n",
      "Ep 50: Batch #30 - Loss: 0.8382989168167114\n",
      "Ep 50: Batch #31 - Loss: 0.5614016652107239\n",
      "Ep 50: Batch #32 - Loss: 0.5815710425376892\n",
      "Ep 50: Batch #33 - Loss: 0.6675561666488647\n",
      "Ep 50: Batch #34 - Loss: 0.6405879259109497\n",
      "Ep 50: Batch #35 - Loss: 0.7248163223266602\n",
      "Ep 50: Batch #36 - Loss: 0.5850591063499451\n",
      "Ep 50: Batch #37 - Loss: 0.9226148128509521\n",
      "Ep 50: Batch #38 - Loss: 0.57049959897995\n",
      "Ep 50: Batch #39 - Loss: 0.6867856979370117\n",
      "Ep 50: Batch #40 - Loss: 0.6050590872764587\n",
      "Ep 50: Batch #41 - Loss: 0.620968759059906\n",
      "Ep 50: Batch #42 - Loss: 0.5704593658447266\n",
      "Ep 50: Batch #43 - Loss: 0.6329305768013\n",
      "Ep 50: Batch #44 - Loss: 0.6146489381790161\n",
      "Ep 50: Batch #45 - Loss: 0.5263639688491821\n",
      "Ep 50: Batch #46 - Loss: 0.6977691054344177\n",
      "Ep 50: Batch #47 - Loss: 0.8053769469261169\n",
      "Ep 50: Batch #48 - Loss: 1.040637493133545\n",
      "Ep 50: Batch #49 - Loss: 0.813482940196991\n",
      "Ep 50: Batch #50 - Loss: 0.5742344260215759\n",
      "Ep 50: Batch #51 - Loss: 0.8188914656639099\n",
      "Ep 50: Batch #52 - Loss: 0.6770187020301819\n",
      "Ep 50: Batch #53 - Loss: 0.7169250249862671\n",
      "Ep 50: Batch #54 - Loss: 0.5794532299041748\n",
      "Ep 50: Batch #55 - Loss: 0.6092955470085144\n",
      "Ep 50: Batch #56 - Loss: 0.8600953817367554\n",
      "Ep 50: Batch #57 - Loss: 0.6830012202262878\n",
      "Ep 50: Batch #58 - Loss: 0.8278907537460327\n",
      "Ep 50: Batch #59 - Loss: 0.5600124597549438\n",
      "Ep 50: Batch #60 - Loss: 1.010543942451477\n",
      "Ep 50: Batch #61 - Loss: 0.5356835126876831\n",
      "Ep 50: Batch #62 - Loss: 0.575104832649231\n",
      "Ep 50: Batch #63 - Loss: 0.7840744853019714\n",
      "Ep 50: Batch #64 - Loss: 8.440385818481445\n",
      "Ep 50: Batch #65 - Loss: 0.5256785154342651\n",
      "Ep 50: Batch #66 - Loss: 0.6656227707862854\n",
      "Ep 50: Batch #67 - Loss: 0.7758998274803162\n",
      "Ep 50: Batch #68 - Loss: 0.7145097255706787\n",
      "Ep 50: Batch #69 - Loss: 0.5889937281608582\n",
      "Ep 50: Batch #70 - Loss: 0.6156852841377258\n",
      "Ep 50: Batch #71 - Loss: 0.5368971228599548\n",
      "Ep 50: Batch #72 - Loss: 0.6632363796234131\n",
      "Ep 50: Batch #73 - Loss: 0.7235268354415894\n",
      "Ep 50: Batch #74 - Loss: 0.5789368152618408\n",
      "Ep 50: Batch #75 - Loss: 0.6685441136360168\n",
      "Ep 50: Batch #76 - Loss: 0.9278222918510437\n",
      "Ep 50: Batch #77 - Loss: 0.5766603350639343\n",
      "Ep 50: Batch #78 - Loss: 0.9226149320602417\n",
      "Ep 50: Batch #79 - Loss: 0.5268334150314331\n",
      "Ep 50: Batch #80 - Loss: 0.6944695115089417\n",
      "Ep 50: Batch #81 - Loss: 1.5258290767669678\n",
      "Ep 50: Batch #82 - Loss: 0.7516934871673584\n",
      "Ep 50: Batch #83 - Loss: 1.2760461568832397\n",
      "Ep 50: Batch #84 - Loss: 0.5778409242630005\n",
      "Ep 50: Batch #85 - Loss: 0.787670910358429\n",
      "Ep 50: Batch #86 - Loss: 0.5489403009414673\n",
      "Ep 50: Batch #87 - Loss: 0.5733362436294556\n",
      "Ep 50: Batch #88 - Loss: 0.658600389957428\n",
      "Ep 50: Batch #89 - Loss: 0.7307707667350769\n",
      "Ep 50: Batch #90 - Loss: 0.901643693447113\n",
      "Ep 50: Batch #91 - Loss: 0.6494866609573364\n",
      "Ep 50: Batch #92 - Loss: 0.7327499389648438\n",
      "Ep 50: Batch #93 - Loss: 0.7842521667480469\n",
      "Ep 50: Batch #94 - Loss: 0.7508973479270935\n",
      "Ep 50: Batch #95 - Loss: 0.7617133855819702\n",
      "Ep 50: Batch #96 - Loss: 0.761717677116394\n",
      "Ep 50: Batch #97 - Loss: 0.58657306432724\n",
      "Ep 50: Batch #98 - Loss: 0.578209638595581\n",
      "Ep 50: Batch #99 - Loss: 0.796825647354126\n",
      "Ep 50: Batch #100 - Loss: 0.5585930943489075\n",
      "Ep 50: Batch #101 - Loss: 0.8662309646606445\n",
      "Ep 50: Batch #102 - Loss: 0.6134977340698242\n",
      "Ep 50: Batch #103 - Loss: 0.6376532316207886\n",
      "Ep 50: Batch #104 - Loss: 0.6620143055915833\n",
      "Ep 50: Batch #105 - Loss: 0.8161091804504395\n",
      "Ep 50: Batch #106 - Loss: 0.6270002126693726\n",
      "Ep 50: Batch #107 - Loss: 0.6154664754867554\n",
      "Ep 50: Batch #108 - Loss: 0.901196300983429\n",
      "Ep 50: Batch #109 - Loss: 0.6267237663269043\n",
      "Ep 50: Batch #110 - Loss: 0.7264894247055054\n",
      "Ep 50: Batch #111 - Loss: 1.0439094305038452\n",
      "Ep 50: Batch #112 - Loss: 0.7982497215270996\n",
      "Ep 50: Batch #113 - Loss: 0.6591429710388184\n",
      "Ep 50: Batch #114 - Loss: 0.728431761264801\n",
      "Ep 50: Batch #115 - Loss: 0.9080007076263428\n",
      "Ep 50: Batch #116 - Loss: 0.5224393010139465\n",
      "Ep 50: Batch #117 - Loss: 0.6796410083770752\n",
      "Ep 50: Batch #118 - Loss: 0.4560217261314392\n",
      "Model saved in file: ./weights_autoencoder_sigmoid/model_e50b118_1516648798.2837348.ckpt\n",
      "Ep 50: Batch #119 - Loss: 0.8101987242698669\n",
      "Ep 50: Batch #120 - Loss: 0.6602596044540405\n",
      "Ep 50: Batch #121 - Loss: 0.5613681077957153\n",
      "Ep 50: Batch #122 - Loss: 0.7113407254219055\n",
      "Ep 50: Batch #123 - Loss: 0.7185479998588562\n",
      "Ep 50: Batch #124 - Loss: 0.557118833065033\n",
      "Ep 50: Batch #125 - Loss: 2.4701061248779297\n",
      "Ep 50: Batch #126 - Loss: 1.0005210638046265\n",
      "Ep 50: Batch #127 - Loss: 0.5825648903846741\n",
      "Ep 50: Batch #128 - Loss: 0.8845585584640503\n",
      "Ep 50: Batch #129 - Loss: 0.6786303520202637\n",
      "Ep 50: Batch #130 - Loss: 0.5963144898414612\n",
      "Ep 50: Batch #131 - Loss: 0.8051244616508484\n",
      "Ep 50: Batch #132 - Loss: 0.684647798538208\n",
      "Ep 50: Batch #133 - Loss: 0.6683395504951477\n",
      "Ep 50: Batch #134 - Loss: 0.6373666524887085\n",
      "Ep 50: Batch #135 - Loss: 0.822596549987793\n",
      "Ep 50: Batch #136 - Loss: 1.04155695438385\n",
      "Ep 50: Batch #137 - Loss: 0.7536836862564087\n",
      "Ep 50: Batch #138 - Loss: 0.9011596441268921\n",
      "Ep 50: Batch #139 - Loss: 0.6768762469291687\n",
      "Ep 50: Batch #140 - Loss: 0.8448609113693237\n",
      "Ep 50: Batch #141 - Loss: 1.1280393600463867\n",
      "Ep 50: Batch #142 - Loss: 0.671295702457428\n",
      "Ep 50: Batch #143 - Loss: 0.7714796662330627\n",
      "Ep 50: Batch #144 - Loss: 0.612850546836853\n",
      "Ep 50: Batch #145 - Loss: 0.6003353595733643\n",
      "Ep 50: Batch #146 - Loss: 0.7027131915092468\n",
      "Ep 50: Batch #147 - Loss: 0.6664872765541077\n",
      "Ep 50: Batch #148 - Loss: 0.7550806403160095\n",
      "Ep 50: Batch #149 - Loss: 0.6203712224960327\n",
      "Ep 50: Batch #150 - Loss: 0.7210029363632202\n",
      "Ep 50: Batch #151 - Loss: 0.6283986568450928\n",
      "Ep 50: Batch #152 - Loss: 0.6077179312705994\n",
      "Ep 50: Batch #153 - Loss: 0.8277503848075867\n",
      "Ep 50: Batch #154 - Loss: 0.6334387063980103\n",
      "Ep 50: Batch #155 - Loss: 0.69161456823349\n",
      "Ep 50: Batch #156 - Loss: 0.7873263955116272\n",
      "Ep 50: Batch #157 - Loss: 0.6142311096191406\n",
      "Ep 50: Batch #158 - Loss: 0.7182425260543823\n",
      "Ep 50: Batch #159 - Loss: 0.5996735692024231\n",
      "Ep 50: Batch #160 - Loss: 0.6972213387489319\n",
      "Ep 50: Batch #161 - Loss: 0.6699821949005127\n",
      "Ep 50: Batch #162 - Loss: 0.7184560894966125\n",
      "Ep 50: Batch #163 - Loss: 0.7598323822021484\n",
      "Ep 50: Batch #164 - Loss: 0.6482700109481812\n",
      "Ep 50: Batch #165 - Loss: 1.3413572311401367\n",
      "Ep 50: Batch #166 - Loss: 0.534122884273529\n",
      "Ep 50: Batch #167 - Loss: 0.7234995365142822\n",
      "Ep 50: Batch #168 - Loss: 0.6927230954170227\n",
      "Ep 50: Batch #169 - Loss: 0.6675654649734497\n",
      "Ep 50: Batch #170 - Loss: 0.6282458305358887\n",
      "Ep 50: Batch #171 - Loss: 0.6409767866134644\n",
      "Ep 50: Batch #172 - Loss: 0.5348767638206482\n",
      "Ep 50: Batch #173 - Loss: 0.9301601052284241\n",
      "Ep 50: Batch #174 - Loss: 0.49622783064842224\n",
      "Ep 50: Batch #175 - Loss: 0.6369127035140991\n",
      "Ep 50: Batch #176 - Loss: 0.8972972631454468\n",
      "Ep 50: Batch #177 - Loss: 0.6519879102706909\n",
      "Ep 50: Batch #178 - Loss: 0.6241464614868164\n",
      "Ep 50: Batch #179 - Loss: 0.7492671608924866\n",
      "Ep 50: Batch #180 - Loss: 0.6522642374038696\n",
      "Ep 50: Batch #181 - Loss: 0.8027464747428894\n",
      "Ep 50: Batch #182 - Loss: 0.6271032094955444\n",
      "Ep 50: Batch #183 - Loss: 0.6069265604019165\n",
      "Ep 50: Batch #184 - Loss: 0.9212902188301086\n",
      "Ep 50: Batch #185 - Loss: 0.6333861351013184\n",
      "Ep 50: Batch #186 - Loss: 0.7561848759651184\n",
      "Ep 50: Batch #187 - Loss: 0.8675141930580139\n",
      "Ep 50: Batch #188 - Loss: 0.9614588618278503\n",
      "Ep 50: Batch #189 - Loss: 0.5869905352592468\n",
      "Ep 50: Batch #190 - Loss: 0.6237477660179138\n",
      "Ep 50: Batch #191 - Loss: 0.8078336119651794\n",
      "Ep 50: Batch #192 - Loss: 0.5707519054412842\n",
      "Ep 50: Batch #193 - Loss: 0.6309189200401306\n",
      "Ep 50: Batch #194 - Loss: 0.5445829629898071\n",
      "Ep 50: Batch #195 - Loss: 0.7887169122695923\n",
      "Ep 50: Batch #196 - Loss: 0.6929230093955994\n",
      "Ep 50: Batch #197 - Loss: 0.7014066576957703\n",
      "Ep 50: Batch #198 - Loss: 0.533894419670105\n",
      "Ep 50: Batch #199 - Loss: 0.6447521448135376\n",
      "Ep 51: Batch #0 - Loss: 0.6515883207321167\n",
      "Ep 51: Batch #1 - Loss: 0.7152441143989563\n",
      "Ep 51: Batch #2 - Loss: 0.8602302670478821\n",
      "Ep 51: Batch #3 - Loss: 0.7233296036720276\n",
      "Ep 51: Batch #4 - Loss: 0.657444179058075\n",
      "Ep 51: Batch #5 - Loss: 0.5555246472358704\n",
      "Ep 51: Batch #6 - Loss: 0.7382535338401794\n",
      "Ep 51: Batch #7 - Loss: 0.5765401124954224\n",
      "Ep 51: Batch #8 - Loss: 0.5870741009712219\n",
      "Ep 51: Batch #9 - Loss: 1.0955859422683716\n",
      "Ep 51: Batch #10 - Loss: 0.8078565001487732\n",
      "Ep 51: Batch #11 - Loss: 0.5445271730422974\n",
      "Ep 51: Batch #12 - Loss: 1.2074707746505737\n",
      "Ep 51: Batch #13 - Loss: 0.5717772841453552\n",
      "Ep 51: Batch #14 - Loss: 0.6007156372070312\n",
      "Ep 51: Batch #15 - Loss: 0.8546459078788757\n",
      "Ep 51: Batch #16 - Loss: 0.9552413821220398\n",
      "Ep 51: Batch #17 - Loss: 0.7304418087005615\n",
      "Ep 51: Batch #18 - Loss: 0.8082338571548462\n",
      "Ep 51: Batch #19 - Loss: 0.5642757415771484\n",
      "Ep 51: Batch #20 - Loss: 0.5475534200668335\n",
      "Ep 51: Batch #21 - Loss: 0.8258723616600037\n",
      "Ep 51: Batch #22 - Loss: 0.609807550907135\n",
      "Ep 51: Batch #23 - Loss: 0.6006551384925842\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 51: Batch #24 - Loss: 0.6390348076820374\n",
      "Ep 51: Batch #25 - Loss: 0.6069471836090088\n",
      "Ep 51: Batch #26 - Loss: 0.5593040585517883\n",
      "Ep 51: Batch #27 - Loss: 1.1433522701263428\n",
      "Ep 51: Batch #28 - Loss: 0.6917107701301575\n",
      "Ep 51: Batch #29 - Loss: 0.7558367848396301\n",
      "Ep 51: Batch #30 - Loss: 0.8369762897491455\n",
      "Ep 51: Batch #31 - Loss: 0.5613762736320496\n",
      "Ep 51: Batch #32 - Loss: 0.5816322565078735\n",
      "Ep 51: Batch #33 - Loss: 0.6674643754959106\n",
      "Ep 51: Batch #34 - Loss: 0.6401263475418091\n",
      "Ep 51: Batch #35 - Loss: 0.7247487902641296\n",
      "Ep 51: Batch #36 - Loss: 0.5851847529411316\n",
      "Ep 51: Batch #37 - Loss: 0.9223611354827881\n",
      "Ep 51: Batch #38 - Loss: 0.5703085660934448\n",
      "Ep 51: Batch #39 - Loss: 0.686628520488739\n",
      "Ep 51: Batch #40 - Loss: 0.6050407290458679\n",
      "Ep 51: Batch #41 - Loss: 0.6206971406936646\n",
      "Ep 51: Batch #42 - Loss: 0.5705077052116394\n",
      "Ep 51: Batch #43 - Loss: 0.6328140497207642\n",
      "Ep 51: Batch #44 - Loss: 0.6146288514137268\n",
      "Ep 51: Batch #45 - Loss: 0.5263116359710693\n",
      "Ep 51: Batch #46 - Loss: 0.6977159380912781\n",
      "Ep 51: Batch #47 - Loss: 0.8053253889083862\n",
      "Ep 51: Batch #48 - Loss: 1.0405443906784058\n",
      "Ep 51: Batch #49 - Loss: 0.8135437369346619\n",
      "Ep 51: Batch #50 - Loss: 0.5742694139480591\n",
      "Ep 51: Batch #51 - Loss: 0.8188018202781677\n",
      "Ep 51: Batch #52 - Loss: 0.6770698428153992\n",
      "Ep 51: Batch #53 - Loss: 0.7166270613670349\n",
      "Ep 51: Batch #54 - Loss: 0.5793572664260864\n",
      "Ep 51: Batch #55 - Loss: 0.6093860268592834\n",
      "Ep 51: Batch #56 - Loss: 0.8597937226295471\n",
      "Ep 51: Batch #57 - Loss: 0.683185875415802\n",
      "Ep 51: Batch #58 - Loss: 0.8281028866767883\n",
      "Ep 51: Batch #59 - Loss: 0.5600340366363525\n",
      "Ep 51: Batch #60 - Loss: 1.0102334022521973\n",
      "Ep 51: Batch #61 - Loss: 0.5357932448387146\n",
      "Ep 51: Batch #62 - Loss: 0.5750710964202881\n",
      "Ep 51: Batch #63 - Loss: 0.7836608290672302\n",
      "Ep 51: Batch #64 - Loss: 8.426260948181152\n",
      "Ep 51: Batch #65 - Loss: 0.5257039666175842\n",
      "Ep 51: Batch #66 - Loss: 0.6654822826385498\n",
      "Ep 51: Batch #67 - Loss: 0.7758923172950745\n",
      "Ep 51: Batch #68 - Loss: 0.7144415378570557\n",
      "Ep 51: Batch #69 - Loss: 0.5888162851333618\n",
      "Ep 51: Batch #70 - Loss: 0.6155955195426941\n",
      "Ep 51: Batch #71 - Loss: 0.5368559956550598\n",
      "Ep 51: Batch #72 - Loss: 0.6632368564605713\n",
      "Ep 51: Batch #73 - Loss: 0.7234370112419128\n",
      "Ep 51: Batch #74 - Loss: 0.5787917971611023\n",
      "Ep 51: Batch #75 - Loss: 0.6684431433677673\n",
      "Ep 51: Batch #76 - Loss: 0.9275851845741272\n",
      "Ep 51: Batch #77 - Loss: 0.5764500498771667\n",
      "Ep 51: Batch #78 - Loss: 0.922453761100769\n",
      "Ep 51: Batch #79 - Loss: 0.526717483997345\n",
      "Ep 51: Batch #80 - Loss: 0.6943680644035339\n",
      "Ep 51: Batch #81 - Loss: 1.5259677171707153\n",
      "Ep 51: Batch #82 - Loss: 0.7518322467803955\n",
      "Ep 51: Batch #83 - Loss: 1.2730294466018677\n",
      "Ep 51: Batch #84 - Loss: 0.577642560005188\n",
      "Ep 51: Batch #85 - Loss: 0.7870711088180542\n",
      "Ep 51: Batch #86 - Loss: 0.548956036567688\n",
      "Ep 51: Batch #87 - Loss: 0.5732205510139465\n",
      "Ep 51: Batch #88 - Loss: 0.6581858992576599\n",
      "Ep 51: Batch #89 - Loss: 0.7303120493888855\n",
      "Ep 51: Batch #90 - Loss: 0.9018258452415466\n",
      "Ep 51: Batch #91 - Loss: 0.6495717763900757\n",
      "Ep 51: Batch #92 - Loss: 0.7327653765678406\n",
      "Ep 51: Batch #93 - Loss: 0.7841078639030457\n",
      "Ep 51: Batch #94 - Loss: 0.750732421875\n",
      "Ep 51: Batch #95 - Loss: 0.7615613341331482\n",
      "Ep 51: Batch #96 - Loss: 0.7604489326477051\n",
      "Ep 51: Batch #97 - Loss: 0.5866214632987976\n",
      "Ep 51: Batch #98 - Loss: 0.5784804821014404\n",
      "Ep 51: Batch #99 - Loss: 0.7970522046089172\n",
      "Ep 51: Batch #100 - Loss: 0.5585739016532898\n",
      "Ep 51: Batch #101 - Loss: 0.8664675354957581\n",
      "Ep 51: Batch #102 - Loss: 0.6134862303733826\n",
      "Ep 51: Batch #103 - Loss: 0.6376757025718689\n",
      "Ep 51: Batch #104 - Loss: 0.6621134877204895\n",
      "Ep 51: Batch #105 - Loss: 0.8163711428642273\n",
      "Ep 51: Batch #106 - Loss: 0.6268825531005859\n",
      "Ep 51: Batch #107 - Loss: 0.6155100464820862\n",
      "Ep 51: Batch #108 - Loss: 0.9016616344451904\n",
      "Ep 51: Batch #109 - Loss: 0.6266584396362305\n",
      "Ep 51: Batch #110 - Loss: 0.7262494564056396\n",
      "Ep 51: Batch #111 - Loss: 1.0437037944793701\n",
      "Ep 51: Batch #112 - Loss: 0.7981858849525452\n",
      "Ep 51: Batch #113 - Loss: 0.659197986125946\n",
      "Ep 51: Batch #114 - Loss: 0.7283034324645996\n",
      "Ep 51: Batch #115 - Loss: 0.9082579612731934\n",
      "Ep 51: Batch #116 - Loss: 0.5225395560264587\n",
      "Ep 51: Batch #117 - Loss: 0.6797265410423279\n",
      "Ep 51: Batch #118 - Loss: 0.45596039295196533\n",
      "Model saved in file: ./weights_autoencoder_sigmoid/model_e51b118_1516648798.4243188.ckpt\n",
      "Ep 51: Batch #119 - Loss: 0.8104161620140076\n",
      "Ep 51: Batch #120 - Loss: 0.6603787541389465\n",
      "Ep 51: Batch #121 - Loss: 0.5612251162528992\n",
      "Ep 51: Batch #122 - Loss: 0.7111314535140991\n",
      "Ep 51: Batch #123 - Loss: 0.718329906463623\n",
      "Ep 51: Batch #124 - Loss: 0.5570269823074341\n",
      "Ep 51: Batch #125 - Loss: 2.470176935195923\n",
      "Ep 51: Batch #126 - Loss: 1.0010548830032349\n",
      "Ep 51: Batch #127 - Loss: 0.5823920369148254\n",
      "Ep 51: Batch #128 - Loss: 0.8849935531616211\n",
      "Ep 51: Batch #129 - Loss: 0.6786197423934937\n",
      "Ep 51: Batch #130 - Loss: 0.5962613821029663\n",
      "Ep 51: Batch #131 - Loss: 0.8048205971717834\n",
      "Ep 51: Batch #132 - Loss: 0.6844509243965149\n",
      "Ep 51: Batch #133 - Loss: 0.6682431101799011\n",
      "Ep 51: Batch #134 - Loss: 0.6371654868125916\n",
      "Ep 51: Batch #135 - Loss: 0.8222432732582092\n",
      "Ep 51: Batch #136 - Loss: 1.042068362236023\n",
      "Ep 51: Batch #137 - Loss: 0.7539748549461365\n",
      "Ep 51: Batch #138 - Loss: 0.9011543989181519\n",
      "Ep 51: Batch #139 - Loss: 0.6774559617042542\n",
      "Ep 51: Batch #140 - Loss: 0.8448062539100647\n",
      "Ep 51: Batch #141 - Loss: 1.1273692846298218\n",
      "Ep 51: Batch #142 - Loss: 0.6714276671409607\n",
      "Ep 51: Batch #143 - Loss: 0.7717321515083313\n",
      "Ep 51: Batch #144 - Loss: 0.6129331588745117\n",
      "Ep 51: Batch #145 - Loss: 0.6003543734550476\n",
      "Ep 51: Batch #146 - Loss: 0.7025963068008423\n",
      "Ep 51: Batch #147 - Loss: 0.6663278341293335\n",
      "Ep 51: Batch #148 - Loss: 0.7548825740814209\n",
      "Ep 51: Batch #149 - Loss: 0.6203216314315796\n",
      "Ep 51: Batch #150 - Loss: 0.720959484577179\n",
      "Ep 51: Batch #151 - Loss: 0.6284719705581665\n",
      "Ep 51: Batch #152 - Loss: 0.6076207756996155\n",
      "Ep 51: Batch #153 - Loss: 0.8276078701019287\n",
      "Ep 51: Batch #154 - Loss: 0.6331188678741455\n",
      "Ep 51: Batch #155 - Loss: 0.691887617111206\n",
      "Ep 51: Batch #156 - Loss: 0.7872534990310669\n",
      "Ep 51: Batch #157 - Loss: 0.6141842007637024\n",
      "Ep 51: Batch #158 - Loss: 0.7183210253715515\n",
      "Ep 51: Batch #159 - Loss: 0.5997433662414551\n",
      "Ep 51: Batch #160 - Loss: 0.6970584988594055\n",
      "Ep 51: Batch #161 - Loss: 0.6700524687767029\n",
      "Ep 51: Batch #162 - Loss: 0.7183966040611267\n",
      "Ep 51: Batch #163 - Loss: 0.7596352100372314\n",
      "Ep 51: Batch #164 - Loss: 0.6484876275062561\n",
      "Ep 51: Batch #165 - Loss: 1.3414572477340698\n",
      "Ep 51: Batch #166 - Loss: 0.5343313217163086\n",
      "Ep 51: Batch #167 - Loss: 0.7225913405418396\n",
      "Ep 51: Batch #168 - Loss: 0.6928115487098694\n",
      "Ep 51: Batch #169 - Loss: 0.6676537394523621\n",
      "Ep 51: Batch #170 - Loss: 0.628242015838623\n",
      "Ep 51: Batch #171 - Loss: 0.6409668922424316\n",
      "Ep 51: Batch #172 - Loss: 0.5347652435302734\n",
      "Ep 51: Batch #173 - Loss: 0.9301414489746094\n",
      "Ep 51: Batch #174 - Loss: 0.49639588594436646\n",
      "Ep 51: Batch #175 - Loss: 0.6365844011306763\n",
      "Ep 51: Batch #176 - Loss: 0.8972417712211609\n",
      "Ep 51: Batch #177 - Loss: 0.6517874598503113\n",
      "Ep 51: Batch #178 - Loss: 0.6240955591201782\n",
      "Ep 51: Batch #179 - Loss: 0.7490969896316528\n",
      "Ep 51: Batch #180 - Loss: 0.6522045731544495\n",
      "Ep 51: Batch #181 - Loss: 0.8030368089675903\n",
      "Ep 51: Batch #182 - Loss: 0.6271890997886658\n",
      "Ep 51: Batch #183 - Loss: 0.606718122959137\n",
      "Ep 51: Batch #184 - Loss: 0.921225905418396\n",
      "Ep 51: Batch #185 - Loss: 0.6332822442054749\n",
      "Ep 51: Batch #186 - Loss: 0.7561192512512207\n",
      "Ep 51: Batch #187 - Loss: 0.8672015070915222\n",
      "Ep 51: Batch #188 - Loss: 0.9601409435272217\n",
      "Ep 51: Batch #189 - Loss: 0.5870997905731201\n",
      "Ep 51: Batch #190 - Loss: 0.6236143708229065\n",
      "Ep 51: Batch #191 - Loss: 0.8075913786888123\n",
      "Ep 51: Batch #192 - Loss: 0.5707775354385376\n",
      "Ep 51: Batch #193 - Loss: 0.6309058666229248\n",
      "Ep 51: Batch #194 - Loss: 0.5443591475486755\n",
      "Ep 51: Batch #195 - Loss: 0.7883212566375732\n",
      "Ep 51: Batch #196 - Loss: 0.6929903030395508\n",
      "Ep 51: Batch #197 - Loss: 0.7013643383979797\n",
      "Ep 51: Batch #198 - Loss: 0.5338847041130066\n",
      "Ep 51: Batch #199 - Loss: 0.6446737051010132\n",
      "Ep 52: Batch #0 - Loss: 0.6514926552772522\n",
      "Ep 52: Batch #1 - Loss: 0.7153172492980957\n",
      "Ep 52: Batch #2 - Loss: 0.8602463603019714\n",
      "Ep 52: Batch #3 - Loss: 0.7231152057647705\n",
      "Ep 52: Batch #4 - Loss: 0.6574041843414307\n",
      "Ep 52: Batch #5 - Loss: 0.5553960800170898\n",
      "Ep 52: Batch #6 - Loss: 0.7380189299583435\n",
      "Ep 52: Batch #7 - Loss: 0.5764893889427185\n",
      "Ep 52: Batch #8 - Loss: 0.5869019031524658\n",
      "Ep 52: Batch #9 - Loss: 1.095313310623169\n",
      "Ep 52: Batch #10 - Loss: 0.8072040677070618\n",
      "Ep 52: Batch #11 - Loss: 0.5445392727851868\n",
      "Ep 52: Batch #12 - Loss: 1.2064547538757324\n",
      "Ep 52: Batch #13 - Loss: 0.571787416934967\n",
      "Ep 52: Batch #14 - Loss: 0.600540816783905\n",
      "Ep 52: Batch #15 - Loss: 0.8541578054428101\n",
      "Ep 52: Batch #16 - Loss: 0.9554092884063721\n",
      "Ep 52: Batch #17 - Loss: 0.7304074764251709\n",
      "Ep 52: Batch #18 - Loss: 0.8082654476165771\n",
      "Ep 52: Batch #19 - Loss: 0.5641903281211853\n",
      "Ep 52: Batch #20 - Loss: 0.5474444627761841\n",
      "Ep 52: Batch #21 - Loss: 0.8245931267738342\n",
      "Ep 52: Batch #22 - Loss: 0.6096673607826233\n",
      "Ep 52: Batch #23 - Loss: 0.6006284356117249\n",
      "Ep 52: Batch #24 - Loss: 0.6390402913093567\n",
      "Ep 52: Batch #25 - Loss: 0.6069682836532593\n",
      "Ep 52: Batch #26 - Loss: 0.558908224105835\n",
      "Ep 52: Batch #27 - Loss: 1.1430355310440063\n",
      "Ep 52: Batch #28 - Loss: 0.6917308568954468\n",
      "Ep 52: Batch #29 - Loss: 0.7558279633522034\n",
      "Ep 52: Batch #30 - Loss: 0.8358093500137329\n",
      "Ep 52: Batch #31 - Loss: 0.5613872408866882\n",
      "Ep 52: Batch #32 - Loss: 0.5816040635108948\n",
      "Ep 52: Batch #33 - Loss: 0.6674535274505615\n",
      "Ep 52: Batch #34 - Loss: 0.6399438381195068\n",
      "Ep 52: Batch #35 - Loss: 0.7246909141540527\n",
      "Ep 52: Batch #36 - Loss: 0.5848357081413269\n",
      "Ep 52: Batch #37 - Loss: 0.9225680232048035\n",
      "Ep 52: Batch #38 - Loss: 0.570201575756073\n",
      "Ep 52: Batch #39 - Loss: 0.6865143775939941\n",
      "Ep 52: Batch #40 - Loss: 0.6051105856895447\n",
      "Ep 52: Batch #41 - Loss: 0.6206497550010681\n",
      "Ep 52: Batch #42 - Loss: 0.5705699920654297\n",
      "Ep 52: Batch #43 - Loss: 0.6327124834060669\n",
      "Ep 52: Batch #44 - Loss: 0.6144546866416931\n",
      "Ep 52: Batch #45 - Loss: 0.5259708762168884\n",
      "Ep 52: Batch #46 - Loss: 0.6976820826530457\n",
      "Ep 52: Batch #47 - Loss: 0.8053252696990967\n",
      "Ep 52: Batch #48 - Loss: 1.040501356124878\n",
      "Ep 52: Batch #49 - Loss: 0.8135116696357727\n",
      "Ep 52: Batch #50 - Loss: 0.5742189884185791\n",
      "Ep 52: Batch #51 - Loss: 0.8185054659843445\n",
      "Ep 52: Batch #52 - Loss: 0.6768543124198914\n",
      "Ep 52: Batch #53 - Loss: 0.7165201306343079\n",
      "Ep 52: Batch #54 - Loss: 0.5793073773384094\n",
      "Ep 52: Batch #55 - Loss: 0.6094909906387329\n",
      "Ep 52: Batch #56 - Loss: 0.8592576384544373\n",
      "Ep 52: Batch #57 - Loss: 0.6831125617027283\n",
      "Ep 52: Batch #58 - Loss: 0.8278526663780212\n",
      "Ep 52: Batch #59 - Loss: 0.5597729682922363\n",
      "Ep 52: Batch #60 - Loss: 1.0098458528518677\n",
      "Ep 52: Batch #61 - Loss: 0.5358450412750244\n",
      "Ep 52: Batch #62 - Loss: 0.5751029849052429\n",
      "Ep 52: Batch #63 - Loss: 0.7833379507064819\n",
      "Ep 52: Batch #64 - Loss: 8.413102149963379\n",
      "Ep 52: Batch #65 - Loss: 0.5256476998329163\n",
      "Ep 52: Batch #66 - Loss: 0.6653993129730225\n",
      "Ep 52: Batch #67 - Loss: 0.7760685682296753\n",
      "Ep 52: Batch #68 - Loss: 0.7142893075942993\n",
      "Ep 52: Batch #69 - Loss: 0.5887004137039185\n",
      "Ep 52: Batch #70 - Loss: 0.6157189011573792\n",
      "Ep 52: Batch #71 - Loss: 0.5368033051490784\n",
      "Ep 52: Batch #72 - Loss: 0.6632911562919617\n",
      "Ep 52: Batch #73 - Loss: 0.7233394384384155\n",
      "Ep 52: Batch #74 - Loss: 0.5785539150238037\n",
      "Ep 52: Batch #75 - Loss: 0.6683084964752197\n",
      "Ep 52: Batch #76 - Loss: 0.9272270202636719\n",
      "Ep 52: Batch #77 - Loss: 0.5764113068580627\n",
      "Ep 52: Batch #78 - Loss: 0.9221936464309692\n",
      "Ep 52: Batch #79 - Loss: 0.5267685651779175\n",
      "Ep 52: Batch #80 - Loss: 0.6943116784095764\n",
      "Ep 52: Batch #81 - Loss: 1.5273723602294922\n",
      "Ep 52: Batch #82 - Loss: 0.7519170045852661\n",
      "Ep 52: Batch #83 - Loss: 1.2702770233154297\n",
      "Ep 52: Batch #84 - Loss: 0.5779304504394531\n",
      "Ep 52: Batch #85 - Loss: 0.7873127460479736\n",
      "Ep 52: Batch #86 - Loss: 0.5491714477539062\n",
      "Ep 52: Batch #87 - Loss: 0.5735562443733215\n",
      "Ep 52: Batch #88 - Loss: 0.6583330035209656\n",
      "Ep 52: Batch #89 - Loss: 0.7307329177856445\n",
      "Ep 52: Batch #90 - Loss: 0.9019866585731506\n",
      "Ep 52: Batch #91 - Loss: 0.6497624516487122\n",
      "Ep 52: Batch #92 - Loss: 0.7326101660728455\n",
      "Ep 52: Batch #93 - Loss: 0.784404456615448\n",
      "Ep 52: Batch #94 - Loss: 0.7510234713554382\n",
      "Ep 52: Batch #95 - Loss: 0.762129545211792\n",
      "Ep 52: Batch #96 - Loss: 0.7626048922538757\n",
      "Ep 52: Batch #97 - Loss: 0.5888896584510803\n",
      "Ep 52: Batch #98 - Loss: 0.5787890553474426\n",
      "Ep 52: Batch #99 - Loss: 0.7984910011291504\n",
      "Ep 52: Batch #100 - Loss: 0.5588242411613464\n",
      "Ep 52: Batch #101 - Loss: 0.8667997121810913\n",
      "Ep 52: Batch #102 - Loss: 0.6137130856513977\n",
      "Ep 52: Batch #103 - Loss: 0.6380207538604736\n",
      "Ep 52: Batch #104 - Loss: 0.6626302599906921\n",
      "Ep 52: Batch #105 - Loss: 0.8167458176612854\n",
      "Ep 52: Batch #106 - Loss: 0.6273884177207947\n",
      "Ep 52: Batch #107 - Loss: 0.6160284876823425\n",
      "Ep 52: Batch #108 - Loss: 0.9009765386581421\n",
      "Ep 52: Batch #109 - Loss: 0.6273507475852966\n",
      "Ep 52: Batch #110 - Loss: 0.727300763130188\n",
      "Ep 52: Batch #111 - Loss: 1.044045329093933\n",
      "Ep 52: Batch #112 - Loss: 0.7975501418113708\n",
      "Ep 52: Batch #113 - Loss: 0.65935218334198\n",
      "Ep 52: Batch #114 - Loss: 0.7285803556442261\n",
      "Ep 52: Batch #115 - Loss: 0.9084310531616211\n",
      "Ep 52: Batch #116 - Loss: 0.5225352644920349\n",
      "Ep 52: Batch #117 - Loss: 0.6798902750015259\n",
      "Ep 52: Batch #118 - Loss: 0.45598655939102173\n",
      "Ep 52: Batch #119 - Loss: 0.8095577359199524\n",
      "Ep 52: Batch #120 - Loss: 0.6601735353469849\n",
      "Ep 52: Batch #121 - Loss: 0.5616291761398315\n",
      "Ep 52: Batch #122 - Loss: 0.7111811637878418\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 52: Batch #123 - Loss: 0.7183921337127686\n",
      "Ep 52: Batch #124 - Loss: 0.557183563709259\n",
      "Ep 52: Batch #125 - Loss: 2.4704012870788574\n",
      "Ep 52: Batch #126 - Loss: 1.0011845827102661\n",
      "Ep 52: Batch #127 - Loss: 0.5824201703071594\n",
      "Ep 52: Batch #128 - Loss: 0.88477623462677\n",
      "Ep 52: Batch #129 - Loss: 0.6786824464797974\n",
      "Ep 52: Batch #130 - Loss: 0.5964741110801697\n",
      "Ep 52: Batch #131 - Loss: 0.8049291372299194\n",
      "Ep 52: Batch #132 - Loss: 0.6843986511230469\n",
      "Ep 52: Batch #133 - Loss: 0.6679564714431763\n",
      "Ep 52: Batch #134 - Loss: 0.637093722820282\n",
      "Ep 52: Batch #135 - Loss: 0.8224290609359741\n",
      "Ep 52: Batch #136 - Loss: 1.0418126583099365\n",
      "Ep 52: Batch #137 - Loss: 0.7544648051261902\n",
      "Ep 52: Batch #138 - Loss: 0.9014465808868408\n",
      "Ep 52: Batch #139 - Loss: 0.6767960786819458\n",
      "Ep 52: Batch #140 - Loss: 0.8447054028511047\n",
      "Ep 52: Batch #141 - Loss: 1.127233624458313\n",
      "Ep 52: Batch #142 - Loss: 0.6719778776168823\n",
      "Ep 52: Batch #143 - Loss: 0.7720991373062134\n",
      "Ep 52: Batch #144 - Loss: 0.6131541132926941\n",
      "Ep 52: Batch #145 - Loss: 0.600328803062439\n",
      "Ep 52: Batch #146 - Loss: 0.7017373442649841\n",
      "Ep 52: Batch #147 - Loss: 0.6652685403823853\n",
      "Ep 52: Batch #148 - Loss: 0.7544357776641846\n",
      "Ep 52: Batch #149 - Loss: 0.6194935441017151\n",
      "Ep 52: Batch #150 - Loss: 0.7208577990531921\n",
      "Ep 52: Batch #151 - Loss: 0.6282057762145996\n",
      "Ep 52: Batch #152 - Loss: 0.6076663136482239\n",
      "Ep 52: Batch #153 - Loss: 0.8275736570358276\n",
      "Ep 52: Batch #154 - Loss: 0.6336618065834045\n",
      "Ep 52: Batch #155 - Loss: 0.6921396255493164\n",
      "Ep 52: Batch #156 - Loss: 0.7864587903022766\n",
      "Ep 52: Batch #157 - Loss: 0.6142245531082153\n",
      "Ep 52: Batch #158 - Loss: 0.7183031439781189\n",
      "Ep 52: Batch #159 - Loss: 0.599120020866394\n",
      "Ep 52: Batch #160 - Loss: 0.696444034576416\n",
      "Ep 52: Batch #161 - Loss: 0.6699069738388062\n",
      "Ep 52: Batch #162 - Loss: 0.7184269428253174\n",
      "Ep 52: Batch #163 - Loss: 0.7598434090614319\n",
      "Ep 52: Batch #164 - Loss: 0.6482985019683838\n",
      "Ep 52: Batch #165 - Loss: 1.3413962125778198\n",
      "Ep 52: Batch #166 - Loss: 0.534209132194519\n",
      "Ep 52: Batch #167 - Loss: 0.7208960652351379\n",
      "Ep 52: Batch #168 - Loss: 0.6927575469017029\n",
      "Ep 52: Batch #169 - Loss: 0.667503297328949\n",
      "Ep 52: Batch #170 - Loss: 0.6284347772598267\n",
      "Ep 52: Batch #171 - Loss: 0.6409032940864563\n",
      "Ep 52: Batch #172 - Loss: 0.5348057746887207\n",
      "Ep 52: Batch #173 - Loss: 0.9297404885292053\n",
      "Ep 52: Batch #174 - Loss: 0.4960046112537384\n",
      "Ep 52: Batch #175 - Loss: 0.6366865634918213\n",
      "Ep 52: Batch #176 - Loss: 0.8973831534385681\n",
      "Ep 52: Batch #177 - Loss: 0.65156090259552\n",
      "Ep 52: Batch #178 - Loss: 0.6241329908370972\n",
      "Ep 52: Batch #179 - Loss: 0.7489920854568481\n",
      "Ep 52: Batch #180 - Loss: 0.6517693996429443\n",
      "Ep 52: Batch #181 - Loss: 0.8026206493377686\n",
      "Ep 52: Batch #182 - Loss: 0.6271474361419678\n",
      "Ep 52: Batch #183 - Loss: 0.6067516803741455\n",
      "Ep 52: Batch #184 - Loss: 0.9210835099220276\n",
      "Ep 52: Batch #185 - Loss: 0.6334449052810669\n",
      "Ep 52: Batch #186 - Loss: 0.7556585669517517\n",
      "Ep 52: Batch #187 - Loss: 0.866998016834259\n",
      "Ep 52: Batch #188 - Loss: 0.9586811661720276\n",
      "Ep 52: Batch #189 - Loss: 0.587019681930542\n",
      "Ep 52: Batch #190 - Loss: 0.623907208442688\n",
      "Ep 52: Batch #191 - Loss: 0.8072364330291748\n",
      "Ep 52: Batch #192 - Loss: 0.5707201361656189\n",
      "Ep 52: Batch #193 - Loss: 0.6310388445854187\n",
      "Ep 52: Batch #194 - Loss: 0.5441564321517944\n",
      "Ep 52: Batch #195 - Loss: 0.7881119847297668\n",
      "Ep 52: Batch #196 - Loss: 0.6929545998573303\n",
      "Ep 52: Batch #197 - Loss: 0.7011650800704956\n",
      "Ep 52: Batch #198 - Loss: 0.5336999297142029\n",
      "Ep 52: Batch #199 - Loss: 0.6444640159606934\n",
      "Ep 53: Batch #0 - Loss: 0.6515253186225891\n",
      "Ep 53: Batch #1 - Loss: 0.7153956890106201\n",
      "Ep 53: Batch #2 - Loss: 0.860389232635498\n",
      "Ep 53: Batch #3 - Loss: 0.7228935956954956\n",
      "Ep 53: Batch #4 - Loss: 0.6574188470840454\n",
      "Ep 53: Batch #5 - Loss: 0.5550139546394348\n",
      "Ep 53: Batch #6 - Loss: 0.7376428842544556\n",
      "Ep 53: Batch #7 - Loss: 0.5764440298080444\n",
      "Ep 53: Batch #8 - Loss: 0.5865492820739746\n",
      "Ep 53: Batch #9 - Loss: 1.0952411890029907\n",
      "Ep 53: Batch #10 - Loss: 0.8065440058708191\n",
      "Ep 53: Batch #11 - Loss: 0.5445560812950134\n",
      "Ep 53: Batch #12 - Loss: 1.205675482749939\n",
      "Ep 53: Batch #13 - Loss: 0.5718957185745239\n",
      "Ep 53: Batch #14 - Loss: 0.6003703474998474\n",
      "Ep 53: Batch #15 - Loss: 0.8537394404411316\n",
      "Ep 53: Batch #16 - Loss: 0.955112636089325\n",
      "Ep 53: Batch #17 - Loss: 0.7305604815483093\n",
      "Ep 53: Batch #18 - Loss: 0.8082636594772339\n",
      "Ep 53: Batch #19 - Loss: 0.5641992092132568\n",
      "Ep 53: Batch #20 - Loss: 0.54729825258255\n",
      "Ep 53: Batch #21 - Loss: 0.823354184627533\n",
      "Ep 53: Batch #22 - Loss: 0.6093993186950684\n",
      "Ep 53: Batch #23 - Loss: 0.6004393100738525\n",
      "Ep 53: Batch #24 - Loss: 0.6391516327857971\n",
      "Ep 53: Batch #25 - Loss: 0.6067543625831604\n",
      "Ep 53: Batch #26 - Loss: 0.5585567951202393\n",
      "Ep 53: Batch #27 - Loss: 1.1429003477096558\n",
      "Ep 53: Batch #28 - Loss: 0.6916455626487732\n",
      "Ep 53: Batch #29 - Loss: 0.7554667592048645\n",
      "Ep 53: Batch #30 - Loss: 0.834726095199585\n",
      "Ep 53: Batch #31 - Loss: 0.5613332390785217\n",
      "Ep 53: Batch #32 - Loss: 0.5816229581832886\n",
      "Ep 53: Batch #33 - Loss: 0.6672380566596985\n",
      "Ep 53: Batch #34 - Loss: 0.6396265625953674\n",
      "Ep 53: Batch #35 - Loss: 0.7245254516601562\n",
      "Ep 53: Batch #36 - Loss: 0.5848106145858765\n",
      "Ep 53: Batch #37 - Loss: 0.9222300052642822\n",
      "Ep 53: Batch #38 - Loss: 0.5699483156204224\n",
      "Ep 53: Batch #39 - Loss: 0.6870853304862976\n",
      "Ep 53: Batch #40 - Loss: 0.6050797700881958\n",
      "Ep 53: Batch #41 - Loss: 0.6205589175224304\n",
      "Ep 53: Batch #42 - Loss: 0.5706104040145874\n",
      "Ep 53: Batch #43 - Loss: 0.6326146721839905\n",
      "Ep 53: Batch #44 - Loss: 0.6144442558288574\n",
      "Ep 53: Batch #45 - Loss: 0.5261826515197754\n",
      "Ep 53: Batch #46 - Loss: 0.6976293325424194\n",
      "Ep 53: Batch #47 - Loss: 0.805243968963623\n",
      "Ep 53: Batch #48 - Loss: 1.0411344766616821\n",
      "Ep 53: Batch #49 - Loss: 0.8132795095443726\n",
      "Ep 53: Batch #50 - Loss: 0.5742382407188416\n",
      "Ep 53: Batch #51 - Loss: 0.8186800479888916\n",
      "Ep 53: Batch #52 - Loss: 0.6768769025802612\n",
      "Ep 53: Batch #53 - Loss: 0.7162789106369019\n",
      "Ep 53: Batch #54 - Loss: 0.5791758298873901\n",
      "Ep 53: Batch #55 - Loss: 0.6100000143051147\n",
      "Ep 53: Batch #56 - Loss: 0.8591054081916809\n",
      "Ep 53: Batch #57 - Loss: 0.6829441785812378\n",
      "Ep 53: Batch #58 - Loss: 0.8282392024993896\n",
      "Ep 53: Batch #59 - Loss: 0.5597237944602966\n",
      "Ep 53: Batch #60 - Loss: 1.0098228454589844\n",
      "Ep 53: Batch #61 - Loss: 0.5357342958450317\n",
      "Ep 53: Batch #62 - Loss: 0.5751309990882874\n",
      "Ep 53: Batch #63 - Loss: 0.7830535173416138\n",
      "Ep 53: Batch #64 - Loss: 8.399918556213379\n",
      "Ep 53: Batch #65 - Loss: 0.5256276726722717\n",
      "Ep 53: Batch #66 - Loss: 0.6652819514274597\n",
      "Ep 53: Batch #67 - Loss: 0.7760953307151794\n",
      "Ep 53: Batch #68 - Loss: 0.714246928691864\n",
      "Ep 53: Batch #69 - Loss: 0.5885459184646606\n",
      "Ep 53: Batch #70 - Loss: 0.6153308153152466\n",
      "Ep 53: Batch #71 - Loss: 0.5367037057876587\n",
      "Ep 53: Batch #72 - Loss: 0.6632897257804871\n",
      "Ep 53: Batch #73 - Loss: 0.7231758236885071\n",
      "Ep 53: Batch #74 - Loss: 0.5786194205284119\n",
      "Ep 53: Batch #75 - Loss: 0.668313205242157\n",
      "Ep 53: Batch #76 - Loss: 0.9270160794258118\n",
      "Ep 53: Batch #77 - Loss: 0.5764104127883911\n",
      "Ep 53: Batch #78 - Loss: 0.921952486038208\n",
      "Ep 53: Batch #79 - Loss: 0.5266271829605103\n",
      "Ep 53: Batch #80 - Loss: 0.6943119168281555\n",
      "Ep 53: Batch #81 - Loss: 1.52949059009552\n",
      "Ep 53: Batch #82 - Loss: 0.7516867518424988\n",
      "Ep 53: Batch #83 - Loss: 1.2681927680969238\n",
      "Ep 53: Batch #84 - Loss: 0.5775994062423706\n",
      "Ep 53: Batch #85 - Loss: 0.7874004244804382\n",
      "Ep 53: Batch #86 - Loss: 0.5490279197692871\n",
      "Ep 53: Batch #87 - Loss: 0.5727712512016296\n",
      "Ep 53: Batch #88 - Loss: 0.6576752066612244\n",
      "Ep 53: Batch #89 - Loss: 0.7300906181335449\n",
      "Ep 53: Batch #90 - Loss: 0.9018397331237793\n",
      "Ep 53: Batch #91 - Loss: 0.6496289968490601\n",
      "Ep 53: Batch #92 - Loss: 0.7325875163078308\n",
      "Ep 53: Batch #93 - Loss: 0.7841505408287048\n",
      "Ep 53: Batch #94 - Loss: 0.7497333884239197\n",
      "Ep 53: Batch #95 - Loss: 0.7615370750427246\n",
      "Ep 53: Batch #96 - Loss: 0.7621013522148132\n",
      "Ep 53: Batch #97 - Loss: 0.5870212316513062\n",
      "Ep 53: Batch #98 - Loss: 0.5788400173187256\n",
      "Ep 53: Batch #99 - Loss: 0.796607255935669\n",
      "Ep 53: Batch #100 - Loss: 0.5584750771522522\n",
      "Ep 53: Batch #101 - Loss: 0.8668025732040405\n",
      "Ep 53: Batch #102 - Loss: 0.6136149764060974\n",
      "Ep 53: Batch #103 - Loss: 0.6372692584991455\n",
      "Ep 53: Batch #104 - Loss: 0.6618396639823914\n",
      "Ep 53: Batch #105 - Loss: 0.8162528276443481\n",
      "Ep 53: Batch #106 - Loss: 0.6267001032829285\n",
      "Ep 53: Batch #107 - Loss: 0.6160027980804443\n",
      "Ep 53: Batch #108 - Loss: 0.901900053024292\n",
      "Ep 53: Batch #109 - Loss: 0.6267005801200867\n",
      "Ep 53: Batch #110 - Loss: 0.725618302822113\n",
      "Ep 53: Batch #111 - Loss: 1.0430588722229004\n",
      "Ep 53: Batch #112 - Loss: 0.7974933981895447\n",
      "Ep 53: Batch #113 - Loss: 0.6588246822357178\n",
      "Ep 53: Batch #114 - Loss: 0.7280824780464172\n",
      "Ep 53: Batch #115 - Loss: 0.908229410648346\n",
      "Ep 53: Batch #116 - Loss: 0.5222891569137573\n",
      "Ep 53: Batch #117 - Loss: 0.6795451641082764\n",
      "Ep 53: Batch #118 - Loss: 0.4557291269302368\n",
      "Model saved in file: ./weights_autoencoder_sigmoid/model_e53b118_1516648798.6804936.ckpt\n",
      "Ep 53: Batch #119 - Loss: 0.8105589747428894\n",
      "Ep 53: Batch #120 - Loss: 0.6604869961738586\n",
      "Ep 53: Batch #121 - Loss: 0.5612893104553223\n",
      "Ep 53: Batch #122 - Loss: 0.7109168171882629\n",
      "Ep 53: Batch #123 - Loss: 0.7179840803146362\n",
      "Ep 53: Batch #124 - Loss: 0.556977391242981\n",
      "Ep 53: Batch #125 - Loss: 2.4705636501312256\n",
      "Ep 53: Batch #126 - Loss: 1.0012328624725342\n",
      "Ep 53: Batch #127 - Loss: 0.5823912024497986\n",
      "Ep 53: Batch #128 - Loss: 0.8849108219146729\n",
      "Ep 53: Batch #129 - Loss: 0.6782097220420837\n",
      "Ep 53: Batch #130 - Loss: 0.5961151123046875\n",
      "Ep 53: Batch #131 - Loss: 0.8040928840637207\n",
      "Ep 53: Batch #132 - Loss: 0.6843698620796204\n",
      "Ep 53: Batch #133 - Loss: 0.668097734451294\n",
      "Ep 53: Batch #134 - Loss: 0.6371372938156128\n",
      "Ep 53: Batch #135 - Loss: 0.8220372200012207\n",
      "Ep 53: Batch #136 - Loss: 1.0416239500045776\n",
      "Ep 53: Batch #137 - Loss: 0.7540133595466614\n",
      "Ep 53: Batch #138 - Loss: 0.9011238217353821\n",
      "Ep 53: Batch #139 - Loss: 0.679424524307251\n",
      "Ep 53: Batch #140 - Loss: 0.8445931673049927\n",
      "Ep 53: Batch #141 - Loss: 1.126514196395874\n",
      "Ep 53: Batch #142 - Loss: 0.6712896227836609\n",
      "Ep 53: Batch #143 - Loss: 0.771743655204773\n",
      "Ep 53: Batch #144 - Loss: 0.6128174662590027\n",
      "Ep 53: Batch #145 - Loss: 0.6004349589347839\n",
      "Ep 53: Batch #146 - Loss: 0.7018313407897949\n",
      "Ep 53: Batch #147 - Loss: 0.665608286857605\n",
      "Ep 53: Batch #148 - Loss: 0.7541484236717224\n",
      "Ep 53: Batch #149 - Loss: 0.6191766262054443\n",
      "Ep 53: Batch #150 - Loss: 0.7207644581794739\n",
      "Ep 53: Batch #151 - Loss: 0.6281744837760925\n",
      "Ep 53: Batch #152 - Loss: 0.607504665851593\n",
      "Ep 53: Batch #153 - Loss: 0.8274533748626709\n",
      "Ep 53: Batch #154 - Loss: 0.6327213644981384\n",
      "Ep 53: Batch #155 - Loss: 0.6922264099121094\n",
      "Ep 53: Batch #156 - Loss: 0.7866415977478027\n",
      "Ep 53: Batch #157 - Loss: 0.6137952208518982\n",
      "Ep 53: Batch #158 - Loss: 0.7181279063224792\n",
      "Ep 53: Batch #159 - Loss: 0.5993005633354187\n",
      "Ep 53: Batch #160 - Loss: 0.6964817047119141\n",
      "Ep 53: Batch #161 - Loss: 0.6699012517929077\n",
      "Ep 53: Batch #162 - Loss: 0.718172013759613\n",
      "Ep 53: Batch #163 - Loss: 0.7598478198051453\n",
      "Ep 53: Batch #164 - Loss: 0.6483520865440369\n",
      "Ep 53: Batch #165 - Loss: 1.3410452604293823\n",
      "Ep 53: Batch #166 - Loss: 0.5343354940414429\n",
      "Ep 53: Batch #167 - Loss: 0.720098614692688\n",
      "Ep 53: Batch #168 - Loss: 0.6928914189338684\n",
      "Ep 53: Batch #169 - Loss: 0.6679588556289673\n",
      "Ep 53: Batch #170 - Loss: 0.6280659437179565\n",
      "Ep 53: Batch #171 - Loss: 0.6405735611915588\n",
      "Ep 53: Batch #172 - Loss: 0.5347527265548706\n",
      "Ep 53: Batch #173 - Loss: 0.9293393492698669\n",
      "Ep 53: Batch #174 - Loss: 0.49589842557907104\n",
      "Ep 53: Batch #175 - Loss: 0.6371534466743469\n",
      "Ep 53: Batch #176 - Loss: 0.8971047401428223\n",
      "Ep 53: Batch #177 - Loss: 0.6512991786003113\n",
      "Ep 53: Batch #178 - Loss: 0.6238612532615662\n",
      "Ep 53: Batch #179 - Loss: 0.7487418055534363\n",
      "Ep 53: Batch #180 - Loss: 0.6518217921257019\n",
      "Ep 53: Batch #181 - Loss: 0.8026066422462463\n",
      "Ep 53: Batch #182 - Loss: 0.6273791790008545\n",
      "Ep 53: Batch #183 - Loss: 0.6065012216567993\n",
      "Ep 53: Batch #184 - Loss: 0.9210847020149231\n",
      "Ep 53: Batch #185 - Loss: 0.6330679655075073\n",
      "Ep 53: Batch #186 - Loss: 0.7553386688232422\n",
      "Ep 53: Batch #187 - Loss: 0.8666289448738098\n",
      "Ep 53: Batch #188 - Loss: 0.9583462476730347\n",
      "Ep 53: Batch #189 - Loss: 0.5869601964950562\n",
      "Ep 53: Batch #190 - Loss: 0.6234990358352661\n",
      "Ep 53: Batch #191 - Loss: 0.807062029838562\n",
      "Ep 53: Batch #192 - Loss: 0.5708741545677185\n",
      "Ep 53: Batch #193 - Loss: 0.6310853958129883\n",
      "Ep 53: Batch #194 - Loss: 0.5440386533737183\n",
      "Ep 53: Batch #195 - Loss: 0.7876123189926147\n",
      "Ep 53: Batch #196 - Loss: 0.6932193636894226\n",
      "Ep 53: Batch #197 - Loss: 0.7012373805046082\n",
      "Ep 53: Batch #198 - Loss: 0.5337348580360413\n",
      "Ep 53: Batch #199 - Loss: 0.6443362236022949\n",
      "Ep 54: Batch #0 - Loss: 0.6517037749290466\n",
      "Ep 54: Batch #1 - Loss: 0.7156898975372314\n",
      "Ep 54: Batch #2 - Loss: 0.8602738976478577\n",
      "Ep 54: Batch #3 - Loss: 0.72293621301651\n",
      "Ep 54: Batch #4 - Loss: 0.657524824142456\n",
      "Ep 54: Batch #5 - Loss: 0.5545298457145691\n",
      "Ep 54: Batch #6 - Loss: 0.7373711466789246\n",
      "Ep 54: Batch #7 - Loss: 0.5764437317848206\n",
      "Ep 54: Batch #8 - Loss: 0.5864129662513733\n",
      "Ep 54: Batch #9 - Loss: 1.0955003499984741\n",
      "Ep 54: Batch #10 - Loss: 0.8063599467277527\n",
      "Ep 54: Batch #11 - Loss: 0.5445680618286133\n",
      "Ep 54: Batch #12 - Loss: 1.2053879499435425\n",
      "Ep 54: Batch #13 - Loss: 0.5718857049942017\n",
      "Ep 54: Batch #14 - Loss: 0.6002113819122314\n",
      "Ep 54: Batch #15 - Loss: 0.8532295823097229\n",
      "Ep 54: Batch #16 - Loss: 0.9555569291114807\n",
      "Ep 54: Batch #17 - Loss: 0.7306190133094788\n",
      "Ep 54: Batch #18 - Loss: 0.808474063873291\n",
      "Ep 54: Batch #19 - Loss: 0.5643941164016724\n",
      "Ep 54: Batch #20 - Loss: 0.547524631023407\n",
      "Ep 54: Batch #21 - Loss: 0.8218352794647217\n",
      "Ep 54: Batch #22 - Loss: 0.6095507144927979\n",
      "Ep 54: Batch #23 - Loss: 0.6007142663002014\n",
      "Ep 54: Batch #24 - Loss: 0.6393545269966125\n",
      "Ep 54: Batch #25 - Loss: 0.6067467331886292\n",
      "Ep 54: Batch #26 - Loss: 0.5582606792449951\n",
      "Ep 54: Batch #27 - Loss: 1.1428579092025757\n",
      "Ep 54: Batch #28 - Loss: 0.6916677355766296\n",
      "Ep 54: Batch #29 - Loss: 0.755315363407135\n",
      "Ep 54: Batch #30 - Loss: 0.8337682485580444\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 54: Batch #31 - Loss: 0.5613515377044678\n",
      "Ep 54: Batch #32 - Loss: 0.5815941095352173\n",
      "Ep 54: Batch #33 - Loss: 0.6674209237098694\n",
      "Ep 54: Batch #34 - Loss: 0.6396200656890869\n",
      "Ep 54: Batch #35 - Loss: 0.724686324596405\n",
      "Ep 54: Batch #36 - Loss: 0.5845696330070496\n",
      "Ep 54: Batch #37 - Loss: 0.9224641919136047\n",
      "Ep 54: Batch #38 - Loss: 0.569881796836853\n",
      "Ep 54: Batch #39 - Loss: 0.6871190071105957\n",
      "Ep 54: Batch #40 - Loss: 0.6050938963890076\n",
      "Ep 54: Batch #41 - Loss: 0.6206228137016296\n",
      "Ep 54: Batch #42 - Loss: 0.5707600116729736\n",
      "Ep 54: Batch #43 - Loss: 0.6327013969421387\n",
      "Ep 54: Batch #44 - Loss: 0.6144258975982666\n",
      "Ep 54: Batch #45 - Loss: 0.5258725881576538\n",
      "Ep 54: Batch #46 - Loss: 0.6976831555366516\n",
      "Ep 54: Batch #47 - Loss: 0.8050975203514099\n",
      "Ep 54: Batch #48 - Loss: 1.0406855344772339\n",
      "Ep 54: Batch #49 - Loss: 0.8134756684303284\n",
      "Ep 54: Batch #50 - Loss: 0.5742106437683105\n",
      "Ep 54: Batch #51 - Loss: 0.8183420300483704\n",
      "Ep 54: Batch #52 - Loss: 0.6766884922981262\n",
      "Ep 54: Batch #53 - Loss: 0.7162894010543823\n",
      "Ep 54: Batch #54 - Loss: 0.579082727432251\n",
      "Ep 54: Batch #55 - Loss: 0.6089200973510742\n",
      "Ep 54: Batch #56 - Loss: 0.858741819858551\n",
      "Ep 54: Batch #57 - Loss: 0.682912290096283\n",
      "Ep 54: Batch #58 - Loss: 0.8279657363891602\n",
      "Ep 54: Batch #59 - Loss: 0.5596656203269958\n",
      "Ep 54: Batch #60 - Loss: 1.0091787576675415\n",
      "Ep 54: Batch #61 - Loss: 0.535735011100769\n",
      "Ep 54: Batch #62 - Loss: 0.575122058391571\n",
      "Ep 54: Batch #63 - Loss: 0.7826569080352783\n",
      "Ep 54: Batch #64 - Loss: 8.385921478271484\n",
      "Ep 54: Batch #65 - Loss: 0.5255512595176697\n",
      "Ep 54: Batch #66 - Loss: 0.6651885509490967\n",
      "Ep 54: Batch #67 - Loss: 0.776250958442688\n",
      "Ep 54: Batch #68 - Loss: 0.7140714526176453\n",
      "Ep 54: Batch #69 - Loss: 0.5883945822715759\n",
      "Ep 54: Batch #70 - Loss: 0.615487277507782\n",
      "Ep 54: Batch #71 - Loss: 0.5366743206977844\n",
      "Ep 54: Batch #72 - Loss: 0.66329425573349\n",
      "Ep 54: Batch #73 - Loss: 0.7229359745979309\n",
      "Ep 54: Batch #74 - Loss: 0.5784921646118164\n",
      "Ep 54: Batch #75 - Loss: 0.6681875586509705\n",
      "Ep 54: Batch #76 - Loss: 0.92656409740448\n",
      "Ep 54: Batch #77 - Loss: 0.5763559937477112\n",
      "Ep 54: Batch #78 - Loss: 0.9218266606330872\n",
      "Ep 54: Batch #79 - Loss: 0.5266243815422058\n",
      "Ep 54: Batch #80 - Loss: 0.6941275596618652\n",
      "Ep 54: Batch #81 - Loss: 1.5252577066421509\n",
      "Ep 54: Batch #82 - Loss: 0.7516448497772217\n",
      "Ep 54: Batch #83 - Loss: 1.265648365020752\n",
      "Ep 54: Batch #84 - Loss: 0.57785564661026\n",
      "Ep 54: Batch #85 - Loss: 0.7869421243667603\n",
      "Ep 54: Batch #86 - Loss: 0.5489856600761414\n",
      "Ep 54: Batch #87 - Loss: 0.5730780959129333\n",
      "Ep 54: Batch #88 - Loss: 0.6578377485275269\n",
      "Ep 54: Batch #89 - Loss: 0.7300505638122559\n",
      "Ep 54: Batch #90 - Loss: 0.9019371867179871\n",
      "Ep 54: Batch #91 - Loss: 0.6498278379440308\n",
      "Ep 54: Batch #92 - Loss: 0.7319644689559937\n",
      "Ep 54: Batch #93 - Loss: 0.7840021848678589\n",
      "Ep 54: Batch #94 - Loss: 0.7497265338897705\n",
      "Ep 54: Batch #95 - Loss: 0.7617009282112122\n",
      "Ep 54: Batch #96 - Loss: 0.7606087923049927\n",
      "Ep 54: Batch #97 - Loss: 0.5874316096305847\n",
      "Ep 54: Batch #98 - Loss: 0.5782835483551025\n",
      "Ep 54: Batch #99 - Loss: 0.7967002391815186\n",
      "Ep 54: Batch #100 - Loss: 0.5585702061653137\n",
      "Ep 54: Batch #101 - Loss: 0.8672668933868408\n",
      "Ep 54: Batch #102 - Loss: 0.6136467456817627\n",
      "Ep 54: Batch #103 - Loss: 0.6374493837356567\n",
      "Ep 54: Batch #104 - Loss: 0.6623155474662781\n",
      "Ep 54: Batch #105 - Loss: 0.816859781742096\n",
      "Ep 54: Batch #106 - Loss: 0.6266904473304749\n",
      "Ep 54: Batch #107 - Loss: 0.6157373189926147\n",
      "Ep 54: Batch #108 - Loss: 0.9008929133415222\n",
      "Ep 54: Batch #109 - Loss: 0.6274208426475525\n",
      "Ep 54: Batch #110 - Loss: 0.7268020510673523\n",
      "Ep 54: Batch #111 - Loss: 1.0438575744628906\n",
      "Ep 54: Batch #112 - Loss: 0.7968428730964661\n",
      "Ep 54: Batch #113 - Loss: 0.6590047478675842\n",
      "Ep 54: Batch #114 - Loss: 0.7276022434234619\n",
      "Ep 54: Batch #115 - Loss: 0.9084700345993042\n",
      "Ep 54: Batch #116 - Loss: 0.5222564339637756\n",
      "Ep 54: Batch #117 - Loss: 0.6796983480453491\n",
      "Ep 54: Batch #118 - Loss: 0.45564004778862\n",
      "Model saved in file: ./weights_autoencoder_sigmoid/model_e54b118_1516648798.8183968.ckpt\n",
      "Ep 54: Batch #119 - Loss: 0.8092246055603027\n",
      "Ep 54: Batch #120 - Loss: 0.6601482629776001\n",
      "Ep 54: Batch #121 - Loss: 0.561471164226532\n",
      "Ep 54: Batch #122 - Loss: 0.7112306356430054\n",
      "Ep 54: Batch #123 - Loss: 0.718015193939209\n",
      "Ep 54: Batch #124 - Loss: 0.5570921897888184\n",
      "Ep 54: Batch #125 - Loss: 2.4708282947540283\n",
      "Ep 54: Batch #126 - Loss: 1.0015450716018677\n",
      "Ep 54: Batch #127 - Loss: 0.582503616809845\n",
      "Ep 54: Batch #128 - Loss: 0.8846876621246338\n",
      "Ep 54: Batch #129 - Loss: 0.6778309941291809\n",
      "Ep 54: Batch #130 - Loss: 0.596224844455719\n",
      "Ep 54: Batch #131 - Loss: 0.804365336894989\n",
      "Ep 54: Batch #132 - Loss: 0.6841642260551453\n",
      "Ep 54: Batch #133 - Loss: 0.667869508266449\n",
      "Ep 54: Batch #134 - Loss: 0.6369173526763916\n",
      "Ep 54: Batch #135 - Loss: 0.821982741355896\n",
      "Ep 54: Batch #136 - Loss: 1.0421693325042725\n",
      "Ep 54: Batch #137 - Loss: 0.7545531392097473\n",
      "Ep 54: Batch #138 - Loss: 0.9015127420425415\n",
      "Ep 54: Batch #139 - Loss: 0.6766884922981262\n",
      "Ep 54: Batch #140 - Loss: 0.8442828059196472\n",
      "Ep 54: Batch #141 - Loss: 1.1263535022735596\n",
      "Ep 54: Batch #142 - Loss: 0.6718345284461975\n",
      "Ep 54: Batch #143 - Loss: 0.7720962762832642\n",
      "Ep 54: Batch #144 - Loss: 0.6132011413574219\n",
      "Ep 54: Batch #145 - Loss: 0.6005655527114868\n",
      "Ep 54: Batch #146 - Loss: 0.7010762691497803\n",
      "Ep 54: Batch #147 - Loss: 0.6649535894393921\n",
      "Ep 54: Batch #148 - Loss: 0.7541327476501465\n",
      "Ep 54: Batch #149 - Loss: 0.618420422077179\n",
      "Ep 54: Batch #150 - Loss: 0.7207275629043579\n",
      "Ep 54: Batch #151 - Loss: 0.6278898119926453\n",
      "Ep 54: Batch #152 - Loss: 0.6073617935180664\n",
      "Ep 54: Batch #153 - Loss: 0.8272526860237122\n",
      "Ep 54: Batch #154 - Loss: 0.6337842345237732\n",
      "Ep 54: Batch #155 - Loss: 0.6921964883804321\n",
      "Ep 54: Batch #156 - Loss: 0.7861083745956421\n",
      "Ep 54: Batch #157 - Loss: 0.6140620112419128\n",
      "Ep 54: Batch #158 - Loss: 0.7181957364082336\n",
      "Ep 54: Batch #159 - Loss: 0.598529040813446\n",
      "Ep 54: Batch #160 - Loss: 0.6957842707633972\n",
      "Ep 54: Batch #161 - Loss: 0.6698578596115112\n",
      "Ep 54: Batch #162 - Loss: 0.7182345986366272\n",
      "Ep 54: Batch #163 - Loss: 0.7597604393959045\n",
      "Ep 54: Batch #164 - Loss: 0.648113489151001\n",
      "Ep 54: Batch #165 - Loss: 1.3415846824645996\n",
      "Ep 54: Batch #166 - Loss: 0.5342692136764526\n",
      "Ep 54: Batch #167 - Loss: 0.718413233757019\n",
      "Ep 54: Batch #168 - Loss: 0.6928627490997314\n",
      "Ep 54: Batch #169 - Loss: 0.6674845814704895\n",
      "Ep 54: Batch #170 - Loss: 0.6284019351005554\n",
      "Ep 54: Batch #171 - Loss: 0.6408818960189819\n",
      "Ep 54: Batch #172 - Loss: 0.5347416996955872\n",
      "Ep 54: Batch #173 - Loss: 0.9297054409980774\n",
      "Ep 54: Batch #174 - Loss: 0.49586960673332214\n",
      "Ep 54: Batch #175 - Loss: 0.6363797783851624\n",
      "Ep 54: Batch #176 - Loss: 0.897249698638916\n",
      "Ep 54: Batch #177 - Loss: 0.6511651873588562\n",
      "Ep 54: Batch #178 - Loss: 0.6238129138946533\n",
      "Ep 54: Batch #179 - Loss: 0.7484972476959229\n",
      "Ep 54: Batch #180 - Loss: 0.6514049172401428\n",
      "Ep 54: Batch #181 - Loss: 0.8025817275047302\n",
      "Ep 54: Batch #182 - Loss: 0.627309262752533\n",
      "Ep 54: Batch #183 - Loss: 0.6066310405731201\n",
      "Ep 54: Batch #184 - Loss: 0.9211844205856323\n",
      "Ep 54: Batch #185 - Loss: 0.633574366569519\n",
      "Ep 54: Batch #186 - Loss: 0.7554758191108704\n",
      "Ep 54: Batch #187 - Loss: 0.8672348856925964\n",
      "Ep 54: Batch #188 - Loss: 0.9570143222808838\n",
      "Ep 54: Batch #189 - Loss: 0.5871396660804749\n",
      "Ep 54: Batch #190 - Loss: 0.623831570148468\n",
      "Ep 54: Batch #191 - Loss: 0.8067541718482971\n",
      "Ep 54: Batch #192 - Loss: 0.5708286762237549\n",
      "Ep 54: Batch #193 - Loss: 0.6311032772064209\n",
      "Ep 54: Batch #194 - Loss: 0.5438695549964905\n",
      "Ep 54: Batch #195 - Loss: 0.7872243523597717\n",
      "Ep 54: Batch #196 - Loss: 0.6931443214416504\n",
      "Ep 54: Batch #197 - Loss: 0.7011319398880005\n",
      "Ep 54: Batch #198 - Loss: 0.5337508916854858\n",
      "Ep 54: Batch #199 - Loss: 0.6441406011581421\n",
      "Ep 55: Batch #0 - Loss: 0.6518171429634094\n",
      "Ep 55: Batch #1 - Loss: 0.7156156897544861\n",
      "Ep 55: Batch #2 - Loss: 0.8605453968048096\n",
      "Ep 55: Batch #3 - Loss: 0.7227298021316528\n",
      "Ep 55: Batch #4 - Loss: 0.6574320197105408\n",
      "Ep 55: Batch #5 - Loss: 0.5543760061264038\n",
      "Ep 55: Batch #6 - Loss: 0.7371551990509033\n",
      "Ep 55: Batch #7 - Loss: 0.5762457251548767\n",
      "Ep 55: Batch #8 - Loss: 0.5862423181533813\n",
      "Ep 55: Batch #9 - Loss: 1.0948967933654785\n",
      "Ep 55: Batch #10 - Loss: 0.8056542873382568\n",
      "Ep 55: Batch #11 - Loss: 0.544604480266571\n",
      "Ep 55: Batch #12 - Loss: 1.2049856185913086\n",
      "Ep 55: Batch #13 - Loss: 0.5718650221824646\n",
      "Ep 55: Batch #14 - Loss: 0.6001327037811279\n",
      "Ep 55: Batch #15 - Loss: 0.8528733253479004\n",
      "Ep 55: Batch #16 - Loss: 0.9548178911209106\n",
      "Ep 55: Batch #17 - Loss: 0.7306673526763916\n",
      "Ep 55: Batch #18 - Loss: 0.8083515763282776\n",
      "Ep 55: Batch #19 - Loss: 0.564329981803894\n",
      "Ep 55: Batch #20 - Loss: 0.5472732782363892\n",
      "Ep 55: Batch #21 - Loss: 0.820932924747467\n",
      "Ep 55: Batch #22 - Loss: 0.608932614326477\n",
      "Ep 55: Batch #23 - Loss: 0.6005698442459106\n",
      "Ep 55: Batch #24 - Loss: 0.6392039656639099\n",
      "Ep 55: Batch #25 - Loss: 0.6065701246261597\n",
      "Ep 55: Batch #26 - Loss: 0.5582213401794434\n",
      "Ep 55: Batch #27 - Loss: 1.1429399251937866\n",
      "Ep 55: Batch #28 - Loss: 0.6918803453445435\n",
      "Ep 55: Batch #29 - Loss: 0.7551956176757812\n",
      "Ep 55: Batch #30 - Loss: 0.8327661752700806\n",
      "Ep 55: Batch #31 - Loss: 0.5613062381744385\n",
      "Ep 55: Batch #32 - Loss: 0.5816025733947754\n",
      "Ep 55: Batch #33 - Loss: 0.6672242283821106\n",
      "Ep 55: Batch #34 - Loss: 0.6392660737037659\n",
      "Ep 55: Batch #35 - Loss: 0.7244921922683716\n",
      "Ep 55: Batch #36 - Loss: 0.5848355889320374\n",
      "Ep 55: Batch #37 - Loss: 0.9222460985183716\n",
      "Ep 55: Batch #38 - Loss: 0.5697045922279358\n",
      "Ep 55: Batch #39 - Loss: 0.6862559914588928\n",
      "Ep 55: Batch #40 - Loss: 0.605029284954071\n",
      "Ep 55: Batch #41 - Loss: 0.6205740571022034\n",
      "Ep 55: Batch #42 - Loss: 0.5707466006278992\n",
      "Ep 55: Batch #43 - Loss: 0.632615327835083\n",
      "Ep 55: Batch #44 - Loss: 0.6143218278884888\n",
      "Ep 55: Batch #45 - Loss: 0.525750458240509\n",
      "Ep 55: Batch #46 - Loss: 0.6976514458656311\n",
      "Ep 55: Batch #47 - Loss: 0.8051488995552063\n",
      "Ep 55: Batch #48 - Loss: 1.0409247875213623\n",
      "Ep 55: Batch #49 - Loss: 0.8132132291793823\n",
      "Ep 55: Batch #50 - Loss: 0.574086606502533\n",
      "Ep 55: Batch #51 - Loss: 0.8187368512153625\n",
      "Ep 55: Batch #52 - Loss: 0.6767858266830444\n",
      "Ep 55: Batch #53 - Loss: 0.7162348628044128\n",
      "Ep 55: Batch #54 - Loss: 0.5788393616676331\n",
      "Ep 55: Batch #55 - Loss: 0.6090179085731506\n",
      "Ep 55: Batch #56 - Loss: 0.858609676361084\n",
      "Ep 55: Batch #57 - Loss: 0.6830446720123291\n",
      "Ep 55: Batch #58 - Loss: 0.827921986579895\n",
      "Ep 55: Batch #59 - Loss: 0.5594214200973511\n",
      "Ep 55: Batch #60 - Loss: 1.0095598697662354\n",
      "Ep 55: Batch #61 - Loss: 0.535927951335907\n",
      "Ep 55: Batch #62 - Loss: 0.5749768614768982\n",
      "Ep 55: Batch #63 - Loss: 0.7825459241867065\n",
      "Ep 55: Batch #64 - Loss: 8.372344017028809\n",
      "Ep 55: Batch #65 - Loss: 0.5255377292633057\n",
      "Ep 55: Batch #66 - Loss: 0.6651268005371094\n",
      "Ep 55: Batch #67 - Loss: 0.7761703133583069\n",
      "Ep 55: Batch #68 - Loss: 0.7138380408287048\n",
      "Ep 55: Batch #69 - Loss: 0.5881673097610474\n",
      "Ep 55: Batch #70 - Loss: 0.6155163049697876\n",
      "Ep 55: Batch #71 - Loss: 0.5364888906478882\n",
      "Ep 55: Batch #72 - Loss: 0.6631546020507812\n",
      "Ep 55: Batch #73 - Loss: 0.7228099703788757\n",
      "Ep 55: Batch #74 - Loss: 0.5782392621040344\n",
      "Ep 55: Batch #75 - Loss: 0.6681368947029114\n",
      "Ep 55: Batch #76 - Loss: 0.9266598224639893\n",
      "Ep 55: Batch #77 - Loss: 0.5761280655860901\n",
      "Ep 55: Batch #78 - Loss: 0.9214705228805542\n",
      "Ep 55: Batch #79 - Loss: 0.5266004800796509\n",
      "Ep 55: Batch #80 - Loss: 0.6940719485282898\n",
      "Ep 55: Batch #81 - Loss: 1.5297173261642456\n",
      "Ep 55: Batch #82 - Loss: 0.7521330118179321\n",
      "Ep 55: Batch #83 - Loss: 1.2632743120193481\n",
      "Ep 55: Batch #84 - Loss: 0.5777648687362671\n",
      "Ep 55: Batch #85 - Loss: 0.7868818640708923\n",
      "Ep 55: Batch #86 - Loss: 0.5490274429321289\n",
      "Ep 55: Batch #87 - Loss: 0.5725628733634949\n",
      "Ep 55: Batch #88 - Loss: 0.6574410796165466\n",
      "Ep 55: Batch #89 - Loss: 0.7295299768447876\n",
      "Ep 55: Batch #90 - Loss: 0.9017398357391357\n",
      "Ep 55: Batch #91 - Loss: 0.6498489379882812\n",
      "Ep 55: Batch #92 - Loss: 0.731824517250061\n",
      "Ep 55: Batch #93 - Loss: 0.7838664054870605\n",
      "Ep 55: Batch #94 - Loss: 0.7486203908920288\n",
      "Ep 55: Batch #95 - Loss: 0.7614056468009949\n",
      "Ep 55: Batch #96 - Loss: 0.7610679268836975\n",
      "Ep 55: Batch #97 - Loss: 0.5868015885353088\n",
      "Ep 55: Batch #98 - Loss: 0.5785807967185974\n",
      "Ep 55: Batch #99 - Loss: 0.795768678188324\n",
      "Ep 55: Batch #100 - Loss: 0.5584076642990112\n",
      "Ep 55: Batch #101 - Loss: 0.8672839999198914\n",
      "Ep 55: Batch #102 - Loss: 0.6133154034614563\n",
      "Ep 55: Batch #103 - Loss: 0.6372133493423462\n",
      "Ep 55: Batch #104 - Loss: 0.6617598533630371\n",
      "Ep 55: Batch #105 - Loss: 0.8163361549377441\n",
      "Ep 55: Batch #106 - Loss: 0.6267176270484924\n",
      "Ep 55: Batch #107 - Loss: 0.6156810522079468\n",
      "Ep 55: Batch #108 - Loss: 0.9016637802124023\n",
      "Ep 55: Batch #109 - Loss: 0.6268399953842163\n",
      "Ep 55: Batch #110 - Loss: 0.7256051301956177\n",
      "Ep 55: Batch #111 - Loss: 1.0431575775146484\n",
      "Ep 55: Batch #112 - Loss: 0.7970466613769531\n",
      "Ep 55: Batch #113 - Loss: 0.6587821841239929\n",
      "Ep 55: Batch #114 - Loss: 0.7276521325111389\n",
      "Ep 55: Batch #115 - Loss: 0.9084699749946594\n",
      "Ep 55: Batch #116 - Loss: 0.5223357677459717\n",
      "Ep 55: Batch #117 - Loss: 0.6795840859413147\n",
      "Ep 55: Batch #118 - Loss: 0.4556594491004944\n",
      "Ep 55: Batch #119 - Loss: 0.8104610443115234\n",
      "Ep 55: Batch #120 - Loss: 0.6605427265167236\n",
      "Ep 55: Batch #121 - Loss: 0.5609198808670044\n",
      "Ep 55: Batch #122 - Loss: 0.7107609510421753\n",
      "Ep 55: Batch #123 - Loss: 0.7177397012710571\n",
      "Ep 55: Batch #124 - Loss: 0.5570188760757446\n",
      "Ep 55: Batch #125 - Loss: 2.470855951309204\n",
      "Ep 55: Batch #126 - Loss: 1.0018759965896606\n",
      "Ep 55: Batch #127 - Loss: 0.5824001431465149\n",
      "Ep 55: Batch #128 - Loss: 0.8852208256721497\n",
      "Ep 55: Batch #129 - Loss: 0.6785168051719666\n",
      "Ep 55: Batch #130 - Loss: 0.5960314273834229\n",
      "Ep 55: Batch #131 - Loss: 0.8039960265159607\n",
      "Ep 55: Batch #132 - Loss: 0.6843224167823792\n",
      "Ep 55: Batch #133 - Loss: 0.6678192019462585\n",
      "Ep 55: Batch #134 - Loss: 0.6370430588722229\n",
      "Ep 55: Batch #135 - Loss: 0.8218148350715637\n",
      "Ep 55: Batch #136 - Loss: 1.0421438217163086\n",
      "Ep 55: Batch #137 - Loss: 0.7540296316146851\n",
      "Ep 55: Batch #138 - Loss: 0.901540219783783\n",
      "Ep 55: Batch #139 - Loss: 0.6773081421852112\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 55: Batch #140 - Loss: 0.8440858125686646\n",
      "Ep 55: Batch #141 - Loss: 1.1259115934371948\n",
      "Ep 55: Batch #142 - Loss: 0.6715012192726135\n",
      "Ep 55: Batch #143 - Loss: 0.77193683385849\n",
      "Ep 55: Batch #144 - Loss: 0.6130754351615906\n",
      "Ep 55: Batch #145 - Loss: 0.6005149483680725\n",
      "Ep 55: Batch #146 - Loss: 0.7014591693878174\n",
      "Ep 55: Batch #147 - Loss: 0.6651505827903748\n",
      "Ep 55: Batch #148 - Loss: 0.753568708896637\n",
      "Ep 55: Batch #149 - Loss: 0.6183914542198181\n",
      "Ep 55: Batch #150 - Loss: 0.7207651734352112\n",
      "Ep 55: Batch #151 - Loss: 0.628021776676178\n",
      "Ep 55: Batch #152 - Loss: 0.6073616147041321\n",
      "Ep 55: Batch #153 - Loss: 0.8271393775939941\n",
      "Ep 55: Batch #154 - Loss: 0.6326546669006348\n",
      "Ep 55: Batch #155 - Loss: 0.6918936371803284\n",
      "Ep 55: Batch #156 - Loss: 0.7862091064453125\n",
      "Ep 55: Batch #157 - Loss: 0.6138781309127808\n",
      "Ep 55: Batch #158 - Loss: 0.7180724143981934\n",
      "Ep 55: Batch #159 - Loss: 0.5986660718917847\n",
      "Ep 55: Batch #160 - Loss: 0.6957154273986816\n",
      "Ep 55: Batch #161 - Loss: 0.6698209047317505\n",
      "Ep 55: Batch #162 - Loss: 0.7178646922111511\n",
      "Ep 55: Batch #163 - Loss: 0.7597147226333618\n",
      "Ep 55: Batch #164 - Loss: 0.648155689239502\n",
      "Ep 55: Batch #165 - Loss: 1.3405311107635498\n",
      "Ep 55: Batch #166 - Loss: 0.5343802571296692\n",
      "Ep 55: Batch #167 - Loss: 0.7177827954292297\n",
      "Ep 55: Batch #168 - Loss: 0.6929175853729248\n",
      "Ep 55: Batch #169 - Loss: 0.6678222417831421\n",
      "Ep 55: Batch #170 - Loss: 0.6280727386474609\n",
      "Ep 55: Batch #171 - Loss: 0.6403601765632629\n",
      "Ep 55: Batch #172 - Loss: 0.5344914197921753\n",
      "Ep 55: Batch #173 - Loss: 0.9293909072875977\n",
      "Ep 55: Batch #174 - Loss: 0.4959036409854889\n",
      "Ep 55: Batch #175 - Loss: 0.6359723210334778\n",
      "Ep 55: Batch #176 - Loss: 0.8971297144889832\n",
      "Ep 55: Batch #177 - Loss: 0.6511099934577942\n",
      "Ep 55: Batch #178 - Loss: 0.6236150860786438\n",
      "Ep 55: Batch #179 - Loss: 0.7484943866729736\n",
      "Ep 55: Batch #180 - Loss: 0.651429295539856\n",
      "Ep 55: Batch #181 - Loss: 0.8022129535675049\n",
      "Ep 55: Batch #182 - Loss: 0.6275511980056763\n",
      "Ep 55: Batch #183 - Loss: 0.6062991619110107\n",
      "Ep 55: Batch #184 - Loss: 0.9210553169250488\n",
      "Ep 55: Batch #185 - Loss: 0.6331639289855957\n",
      "Ep 55: Batch #186 - Loss: 0.7552104592323303\n",
      "Ep 55: Batch #187 - Loss: 0.8664224147796631\n",
      "Ep 55: Batch #188 - Loss: 0.956505537033081\n",
      "Ep 55: Batch #189 - Loss: 0.5869603157043457\n",
      "Ep 55: Batch #190 - Loss: 0.623344361782074\n",
      "Ep 55: Batch #191 - Loss: 0.8064716458320618\n",
      "Ep 55: Batch #192 - Loss: 0.5708507299423218\n",
      "Ep 55: Batch #193 - Loss: 0.6311333775520325\n",
      "Ep 55: Batch #194 - Loss: 0.5437431335449219\n",
      "Ep 55: Batch #195 - Loss: 0.7873231768608093\n",
      "Ep 55: Batch #196 - Loss: 0.693355143070221\n",
      "Ep 55: Batch #197 - Loss: 0.7011131048202515\n",
      "Ep 55: Batch #198 - Loss: 0.5338122844696045\n",
      "Ep 55: Batch #199 - Loss: 0.6439678072929382\n",
      "Ep 56: Batch #0 - Loss: 0.6515837907791138\n",
      "Ep 56: Batch #1 - Loss: 0.7157516479492188\n",
      "Ep 56: Batch #2 - Loss: 0.86046302318573\n",
      "Ep 56: Batch #3 - Loss: 0.7225986123085022\n",
      "Ep 56: Batch #4 - Loss: 0.6573957800865173\n",
      "Ep 56: Batch #5 - Loss: 0.5540693998336792\n",
      "Ep 56: Batch #6 - Loss: 0.7367778420448303\n",
      "Ep 56: Batch #7 - Loss: 0.5762824416160583\n",
      "Ep 56: Batch #8 - Loss: 0.586370587348938\n",
      "Ep 56: Batch #9 - Loss: 1.095171570777893\n",
      "Ep 56: Batch #10 - Loss: 0.805332362651825\n",
      "Ep 56: Batch #11 - Loss: 0.544570803642273\n",
      "Ep 56: Batch #12 - Loss: 1.204293131828308\n",
      "Ep 56: Batch #13 - Loss: 0.5718239545822144\n",
      "Ep 56: Batch #14 - Loss: 0.6000199913978577\n",
      "Ep 56: Batch #15 - Loss: 0.8521856069564819\n",
      "Ep 56: Batch #16 - Loss: 0.9558217525482178\n",
      "Ep 56: Batch #17 - Loss: 0.7308415770530701\n",
      "Ep 56: Batch #18 - Loss: 0.8085050582885742\n",
      "Ep 56: Batch #19 - Loss: 0.5644418001174927\n",
      "Ep 56: Batch #20 - Loss: 0.5474892854690552\n",
      "Ep 56: Batch #21 - Loss: 0.8196986317634583\n",
      "Ep 56: Batch #22 - Loss: 0.6091370582580566\n",
      "Ep 56: Batch #23 - Loss: 0.6007593274116516\n",
      "Ep 56: Batch #24 - Loss: 0.639458179473877\n",
      "Ep 56: Batch #25 - Loss: 0.6065795421600342\n",
      "Ep 56: Batch #26 - Loss: 0.5579343438148499\n",
      "Ep 56: Batch #27 - Loss: 1.142768383026123\n",
      "Ep 56: Batch #28 - Loss: 0.6920076012611389\n",
      "Ep 56: Batch #29 - Loss: 0.7550549507141113\n",
      "Ep 56: Batch #30 - Loss: 0.8321231007575989\n",
      "Ep 56: Batch #31 - Loss: 0.5613983869552612\n",
      "Ep 56: Batch #32 - Loss: 0.5815160274505615\n",
      "Ep 56: Batch #33 - Loss: 0.6673272848129272\n",
      "Ep 56: Batch #34 - Loss: 0.6389979124069214\n",
      "Ep 56: Batch #35 - Loss: 0.7245877981185913\n",
      "Ep 56: Batch #36 - Loss: 0.5844827890396118\n",
      "Ep 56: Batch #37 - Loss: 0.921594500541687\n",
      "Ep 56: Batch #38 - Loss: 0.5696585774421692\n",
      "Ep 56: Batch #39 - Loss: 0.6863921284675598\n",
      "Ep 56: Batch #40 - Loss: 0.6047821640968323\n",
      "Ep 56: Batch #41 - Loss: 0.6205150485038757\n",
      "Ep 56: Batch #42 - Loss: 0.5709202289581299\n",
      "Ep 56: Batch #43 - Loss: 0.632644534111023\n",
      "Ep 56: Batch #44 - Loss: 0.6144180297851562\n",
      "Ep 56: Batch #45 - Loss: 0.5254254341125488\n",
      "Ep 56: Batch #46 - Loss: 0.6976299285888672\n",
      "Ep 56: Batch #47 - Loss: 0.8051698207855225\n",
      "Ep 56: Batch #48 - Loss: 1.0409806966781616\n",
      "Ep 56: Batch #49 - Loss: 0.8134534955024719\n",
      "Ep 56: Batch #50 - Loss: 0.5740373730659485\n",
      "Ep 56: Batch #51 - Loss: 0.8183434009552002\n",
      "Ep 56: Batch #52 - Loss: 0.6766132712364197\n",
      "Ep 56: Batch #53 - Loss: 0.7161944508552551\n",
      "Ep 56: Batch #54 - Loss: 0.5788363218307495\n",
      "Ep 56: Batch #55 - Loss: 0.6094896793365479\n",
      "Ep 56: Batch #56 - Loss: 0.8582342863082886\n",
      "Ep 56: Batch #57 - Loss: 0.6828669905662537\n",
      "Ep 56: Batch #58 - Loss: 0.8279832601547241\n",
      "Ep 56: Batch #59 - Loss: 0.559290885925293\n",
      "Ep 56: Batch #60 - Loss: 1.0089919567108154\n",
      "Ep 56: Batch #61 - Loss: 0.5355554819107056\n",
      "Ep 56: Batch #62 - Loss: 0.5749676823616028\n",
      "Ep 56: Batch #63 - Loss: 0.7821366190910339\n",
      "Ep 56: Batch #64 - Loss: 8.358695983886719\n",
      "Ep 56: Batch #65 - Loss: 0.525298535823822\n",
      "Ep 56: Batch #66 - Loss: 0.6649518609046936\n",
      "Ep 56: Batch #67 - Loss: 0.7761049270629883\n",
      "Ep 56: Batch #68 - Loss: 0.7138620615005493\n",
      "Ep 56: Batch #69 - Loss: 0.588514506816864\n",
      "Ep 56: Batch #70 - Loss: 0.6154857277870178\n",
      "Ep 56: Batch #71 - Loss: 0.5365279316902161\n",
      "Ep 56: Batch #72 - Loss: 0.6632388830184937\n",
      "Ep 56: Batch #73 - Loss: 0.722592294216156\n",
      "Ep 56: Batch #74 - Loss: 0.5779955387115479\n",
      "Ep 56: Batch #75 - Loss: 0.6679583787918091\n",
      "Ep 56: Batch #76 - Loss: 0.9261999130249023\n",
      "Ep 56: Batch #77 - Loss: 0.5761019587516785\n",
      "Ep 56: Batch #78 - Loss: 0.9212855100631714\n",
      "Ep 56: Batch #79 - Loss: 0.5264425277709961\n",
      "Ep 56: Batch #80 - Loss: 0.6938078999519348\n",
      "Ep 56: Batch #81 - Loss: 1.5253090858459473\n",
      "Ep 56: Batch #82 - Loss: 0.7522174119949341\n",
      "Ep 56: Batch #83 - Loss: 1.260874629020691\n",
      "Ep 56: Batch #84 - Loss: 0.5779148936271667\n",
      "Ep 56: Batch #85 - Loss: 0.7869743704795837\n",
      "Ep 56: Batch #86 - Loss: 0.5489524602890015\n",
      "Ep 56: Batch #87 - Loss: 0.5726227164268494\n",
      "Ep 56: Batch #88 - Loss: 0.6573562026023865\n",
      "Ep 56: Batch #89 - Loss: 0.7292017340660095\n",
      "Ep 56: Batch #90 - Loss: 0.9015578031539917\n",
      "Ep 56: Batch #91 - Loss: 0.6497166156768799\n",
      "Ep 56: Batch #92 - Loss: 0.7313156723976135\n",
      "Ep 56: Batch #93 - Loss: 0.7835408449172974\n",
      "Ep 56: Batch #94 - Loss: 0.7481905221939087\n",
      "Ep 56: Batch #95 - Loss: 0.7612298130989075\n",
      "Ep 56: Batch #96 - Loss: 0.759998083114624\n",
      "Ep 56: Batch #97 - Loss: 0.5867399573326111\n",
      "Ep 56: Batch #98 - Loss: 0.5778801441192627\n",
      "Ep 56: Batch #99 - Loss: 0.795388400554657\n",
      "Ep 56: Batch #100 - Loss: 0.5582385659217834\n",
      "Ep 56: Batch #101 - Loss: 0.8674502372741699\n",
      "Ep 56: Batch #102 - Loss: 0.6131413578987122\n",
      "Ep 56: Batch #103 - Loss: 0.636795163154602\n",
      "Ep 56: Batch #104 - Loss: 0.6617244482040405\n",
      "Ep 56: Batch #105 - Loss: 0.8164739012718201\n",
      "Ep 56: Batch #106 - Loss: 0.6266573071479797\n",
      "Ep 56: Batch #107 - Loss: 0.6154767274856567\n",
      "Ep 56: Batch #108 - Loss: 0.9008099436759949\n",
      "Ep 56: Batch #109 - Loss: 0.6273947358131409\n",
      "Ep 56: Batch #110 - Loss: 0.7259505987167358\n",
      "Ep 56: Batch #111 - Loss: 1.0430632829666138\n",
      "Ep 56: Batch #112 - Loss: 0.7961614727973938\n",
      "Ep 56: Batch #113 - Loss: 0.658320963382721\n",
      "Ep 56: Batch #114 - Loss: 0.7271838784217834\n",
      "Ep 56: Batch #115 - Loss: 0.9083617329597473\n",
      "Ep 56: Batch #116 - Loss: 0.5221055746078491\n",
      "Ep 56: Batch #117 - Loss: 0.6794232130050659\n",
      "Ep 56: Batch #118 - Loss: 0.45547276735305786\n",
      "Model saved in file: ./weights_autoencoder_sigmoid/model_e56b118_1516648799.0718482.ckpt\n",
      "Ep 56: Batch #119 - Loss: 0.8095732927322388\n",
      "Ep 56: Batch #120 - Loss: 0.6602559089660645\n",
      "Ep 56: Batch #121 - Loss: 0.5612270832061768\n",
      "Ep 56: Batch #122 - Loss: 0.7108590602874756\n",
      "Ep 56: Batch #123 - Loss: 0.7176114320755005\n",
      "Ep 56: Batch #124 - Loss: 0.5568385720252991\n",
      "Ep 56: Batch #125 - Loss: 2.470972776412964\n",
      "Ep 56: Batch #126 - Loss: 1.0019869804382324\n",
      "Ep 56: Batch #127 - Loss: 0.582425594329834\n",
      "Ep 56: Batch #128 - Loss: 0.885003924369812\n",
      "Ep 56: Batch #129 - Loss: 0.6779229044914246\n",
      "Ep 56: Batch #130 - Loss: 0.5959174036979675\n",
      "Ep 56: Batch #131 - Loss: 0.8038070201873779\n",
      "Ep 56: Batch #132 - Loss: 0.6840725541114807\n",
      "Ep 56: Batch #133 - Loss: 0.6675942540168762\n",
      "Ep 56: Batch #134 - Loss: 0.6367811560630798\n",
      "Ep 56: Batch #135 - Loss: 0.8216460347175598\n",
      "Ep 56: Batch #136 - Loss: 1.0419504642486572\n",
      "Ep 56: Batch #137 - Loss: 0.7544093132019043\n",
      "Ep 56: Batch #138 - Loss: 0.9014456272125244\n",
      "Ep 56: Batch #139 - Loss: 0.6765154600143433\n",
      "Ep 56: Batch #140 - Loss: 0.843833863735199\n",
      "Ep 56: Batch #141 - Loss: 1.1254085302352905\n",
      "Ep 56: Batch #142 - Loss: 0.6716998219490051\n",
      "Ep 56: Batch #143 - Loss: 0.7718576788902283\n",
      "Ep 56: Batch #144 - Loss: 0.6129947304725647\n",
      "Ep 56: Batch #145 - Loss: 0.600715160369873\n",
      "Ep 56: Batch #146 - Loss: 0.7005941271781921\n",
      "Ep 56: Batch #147 - Loss: 0.6643624901771545\n",
      "Ep 56: Batch #148 - Loss: 0.7536115646362305\n",
      "Ep 56: Batch #149 - Loss: 0.6176834106445312\n",
      "Ep 56: Batch #150 - Loss: 0.7204701900482178\n",
      "Ep 56: Batch #151 - Loss: 0.6276198625564575\n",
      "Ep 56: Batch #152 - Loss: 0.6073463559150696\n",
      "Ep 56: Batch #153 - Loss: 0.8269562721252441\n",
      "Ep 56: Batch #154 - Loss: 0.6332287788391113\n",
      "Ep 56: Batch #155 - Loss: 0.691826343536377\n",
      "Ep 56: Batch #156 - Loss: 0.7855548858642578\n",
      "Ep 56: Batch #157 - Loss: 0.6136480569839478\n",
      "Ep 56: Batch #158 - Loss: 0.7180290818214417\n",
      "Ep 56: Batch #159 - Loss: 0.5982571840286255\n",
      "Ep 56: Batch #160 - Loss: 0.6952916979789734\n",
      "Ep 56: Batch #161 - Loss: 0.6697587966918945\n",
      "Ep 56: Batch #162 - Loss: 0.717802882194519\n",
      "Ep 56: Batch #163 - Loss: 0.7596690654754639\n",
      "Ep 56: Batch #164 - Loss: 0.6480622887611389\n",
      "Ep 56: Batch #165 - Loss: 1.3400242328643799\n",
      "Ep 56: Batch #166 - Loss: 0.5343427658081055\n",
      "Ep 56: Batch #167 - Loss: 0.7165568470954895\n",
      "Ep 56: Batch #168 - Loss: 0.6928128004074097\n",
      "Ep 56: Batch #169 - Loss: 0.6674972176551819\n",
      "Ep 56: Batch #170 - Loss: 0.6279973387718201\n",
      "Ep 56: Batch #171 - Loss: 0.6404328942298889\n",
      "Ep 56: Batch #172 - Loss: 0.5344753861427307\n",
      "Ep 56: Batch #173 - Loss: 0.9291656017303467\n",
      "Ep 56: Batch #174 - Loss: 0.49546653032302856\n",
      "Ep 56: Batch #175 - Loss: 0.6358694434165955\n",
      "Ep 56: Batch #176 - Loss: 0.8971662521362305\n",
      "Ep 56: Batch #177 - Loss: 0.6505677700042725\n",
      "Ep 56: Batch #178 - Loss: 0.6233647465705872\n",
      "Ep 56: Batch #179 - Loss: 0.7479899525642395\n",
      "Ep 56: Batch #180 - Loss: 0.6511545181274414\n",
      "Ep 56: Batch #181 - Loss: 0.8020238280296326\n",
      "Ep 56: Batch #182 - Loss: 0.627403974533081\n",
      "Ep 56: Batch #183 - Loss: 0.6062713861465454\n",
      "Ep 56: Batch #184 - Loss: 0.9209967255592346\n",
      "Ep 56: Batch #185 - Loss: 0.6332664489746094\n",
      "Ep 56: Batch #186 - Loss: 0.7550411820411682\n",
      "Ep 56: Batch #187 - Loss: 0.8665596842765808\n",
      "Ep 56: Batch #188 - Loss: 0.9551205635070801\n",
      "Ep 56: Batch #189 - Loss: 0.5868993401527405\n",
      "Ep 56: Batch #190 - Loss: 0.6232669949531555\n",
      "Ep 56: Batch #191 - Loss: 0.8061425685882568\n",
      "Ep 56: Batch #192 - Loss: 0.5709669589996338\n",
      "Ep 56: Batch #193 - Loss: 0.6311814785003662\n",
      "Ep 56: Batch #194 - Loss: 0.5436939597129822\n",
      "Ep 56: Batch #195 - Loss: 0.7866181135177612\n",
      "Ep 56: Batch #196 - Loss: 0.6934059858322144\n",
      "Ep 56: Batch #197 - Loss: 0.7011892199516296\n",
      "Ep 56: Batch #198 - Loss: 0.5338242053985596\n",
      "Ep 56: Batch #199 - Loss: 0.643975555896759\n",
      "Ep 57: Batch #0 - Loss: 0.6517878770828247\n",
      "Ep 57: Batch #1 - Loss: 0.7158669233322144\n",
      "Ep 57: Batch #2 - Loss: 0.8603619337081909\n",
      "Ep 57: Batch #3 - Loss: 0.7225924730300903\n",
      "Ep 57: Batch #4 - Loss: 0.6574170589447021\n",
      "Ep 57: Batch #5 - Loss: 0.5543190240859985\n",
      "Ep 57: Batch #6 - Loss: 0.736521303653717\n",
      "Ep 57: Batch #7 - Loss: 0.5761861801147461\n",
      "Ep 57: Batch #8 - Loss: 0.5862243175506592\n",
      "Ep 57: Batch #9 - Loss: 1.0947810411453247\n",
      "Ep 57: Batch #10 - Loss: 0.8048686385154724\n",
      "Ep 57: Batch #11 - Loss: 0.5445638298988342\n",
      "Ep 57: Batch #12 - Loss: 1.2040770053863525\n",
      "Ep 57: Batch #13 - Loss: 0.5718252062797546\n",
      "Ep 57: Batch #14 - Loss: 0.5998477339744568\n",
      "Ep 57: Batch #15 - Loss: 0.851506769657135\n",
      "Ep 57: Batch #16 - Loss: 0.9550068378448486\n",
      "Ep 57: Batch #17 - Loss: 0.7307989001274109\n",
      "Ep 57: Batch #18 - Loss: 0.8084123134613037\n",
      "Ep 57: Batch #19 - Loss: 0.5643300414085388\n",
      "Ep 57: Batch #20 - Loss: 0.547164797782898\n",
      "Ep 57: Batch #21 - Loss: 0.8180013298988342\n",
      "Ep 57: Batch #22 - Loss: 0.6086938381195068\n",
      "Ep 57: Batch #23 - Loss: 0.6006609201431274\n",
      "Ep 57: Batch #24 - Loss: 0.6393222212791443\n",
      "Ep 57: Batch #25 - Loss: 0.6063748002052307\n",
      "Ep 57: Batch #26 - Loss: 0.5576805472373962\n",
      "Ep 57: Batch #27 - Loss: 1.1424758434295654\n",
      "Ep 57: Batch #28 - Loss: 0.692015528678894\n",
      "Ep 57: Batch #29 - Loss: 0.7549721002578735\n",
      "Ep 57: Batch #30 - Loss: 0.8309487104415894\n",
      "Ep 57: Batch #31 - Loss: 0.5614557266235352\n",
      "Ep 57: Batch #32 - Loss: 0.581533670425415\n",
      "Ep 57: Batch #33 - Loss: 0.6671395897865295\n",
      "Ep 57: Batch #34 - Loss: 0.6387966275215149\n",
      "Ep 57: Batch #35 - Loss: 0.7244623899459839\n",
      "Ep 57: Batch #36 - Loss: 0.5844724774360657\n",
      "Ep 57: Batch #37 - Loss: 0.9214995503425598\n",
      "Ep 57: Batch #38 - Loss: 0.5693735480308533\n",
      "Ep 57: Batch #39 - Loss: 0.6864286065101624\n",
      "Ep 57: Batch #40 - Loss: 0.6047473549842834\n",
      "Ep 57: Batch #41 - Loss: 0.6203747391700745\n",
      "Ep 57: Batch #42 - Loss: 0.5709067583084106\n",
      "Ep 57: Batch #43 - Loss: 0.6325103044509888\n",
      "Ep 57: Batch #44 - Loss: 0.6142873167991638\n",
      "Ep 57: Batch #45 - Loss: 0.5251786112785339\n",
      "Ep 57: Batch #46 - Loss: 0.6974420547485352\n",
      "Ep 57: Batch #47 - Loss: 0.8048843145370483\n",
      "Ep 57: Batch #48 - Loss: 1.0408620834350586\n",
      "Ep 57: Batch #49 - Loss: 0.813208818435669\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 57: Batch #50 - Loss: 0.573948860168457\n",
      "Ep 57: Batch #51 - Loss: 0.8183167576789856\n",
      "Ep 57: Batch #52 - Loss: 0.676490843296051\n",
      "Ep 57: Batch #53 - Loss: 0.7159993052482605\n",
      "Ep 57: Batch #54 - Loss: 0.5786362290382385\n",
      "Ep 57: Batch #55 - Loss: 0.6093589067459106\n",
      "Ep 57: Batch #56 - Loss: 0.8582029938697815\n",
      "Ep 57: Batch #57 - Loss: 0.6827977895736694\n",
      "Ep 57: Batch #58 - Loss: 0.8273802995681763\n",
      "Ep 57: Batch #59 - Loss: 0.5590156316757202\n",
      "Ep 57: Batch #60 - Loss: 1.0096043348312378\n",
      "Ep 57: Batch #61 - Loss: 0.5356988906860352\n",
      "Ep 57: Batch #62 - Loss: 0.5747898817062378\n",
      "Ep 57: Batch #63 - Loss: 0.7819175124168396\n",
      "Ep 57: Batch #64 - Loss: 8.34454345703125\n",
      "Ep 57: Batch #65 - Loss: 0.5252339243888855\n",
      "Ep 57: Batch #66 - Loss: 0.6648839712142944\n",
      "Ep 57: Batch #67 - Loss: 0.7760743498802185\n",
      "Ep 57: Batch #68 - Loss: 0.7136348485946655\n",
      "Ep 57: Batch #69 - Loss: 0.5883166790008545\n",
      "Ep 57: Batch #70 - Loss: 0.6157654523849487\n",
      "Ep 57: Batch #71 - Loss: 0.5364013910293579\n",
      "Ep 57: Batch #72 - Loss: 0.663091242313385\n",
      "Ep 57: Batch #73 - Loss: 0.7222209572792053\n",
      "Ep 57: Batch #74 - Loss: 0.5777182579040527\n",
      "Ep 57: Batch #75 - Loss: 0.6678931713104248\n",
      "Ep 57: Batch #76 - Loss: 0.9260898232460022\n",
      "Ep 57: Batch #77 - Loss: 0.575934112071991\n",
      "Ep 57: Batch #78 - Loss: 0.920972466468811\n",
      "Ep 57: Batch #79 - Loss: 0.5263767242431641\n",
      "Ep 57: Batch #80 - Loss: 0.6936108469963074\n",
      "Ep 57: Batch #81 - Loss: 1.5257645845413208\n",
      "Ep 57: Batch #82 - Loss: 0.7519596815109253\n",
      "Ep 57: Batch #83 - Loss: 1.258018136024475\n",
      "Ep 57: Batch #84 - Loss: 0.5780166387557983\n",
      "Ep 57: Batch #85 - Loss: 0.7866941094398499\n",
      "Ep 57: Batch #86 - Loss: 0.5488230586051941\n",
      "Ep 57: Batch #87 - Loss: 0.5727595686912537\n",
      "Ep 57: Batch #88 - Loss: 0.6577702164649963\n",
      "Ep 57: Batch #89 - Loss: 0.7295394539833069\n",
      "Ep 57: Batch #90 - Loss: 0.9014886021614075\n",
      "Ep 57: Batch #91 - Loss: 0.6498536467552185\n",
      "Ep 57: Batch #92 - Loss: 0.7312750220298767\n",
      "Ep 57: Batch #93 - Loss: 0.7837185263633728\n",
      "Ep 57: Batch #94 - Loss: 0.7485076189041138\n",
      "Ep 57: Batch #95 - Loss: 0.7613712549209595\n",
      "Ep 57: Batch #96 - Loss: 0.7617819309234619\n",
      "Ep 57: Batch #97 - Loss: 0.5873317718505859\n",
      "Ep 57: Batch #98 - Loss: 0.5783088207244873\n",
      "Ep 57: Batch #99 - Loss: 0.7964533567428589\n",
      "Ep 57: Batch #100 - Loss: 0.5583506226539612\n",
      "Ep 57: Batch #101 - Loss: 0.8677544593811035\n",
      "Ep 57: Batch #102 - Loss: 0.6131657361984253\n",
      "Ep 57: Batch #103 - Loss: 0.6369415521621704\n",
      "Ep 57: Batch #104 - Loss: 0.6621052026748657\n",
      "Ep 57: Batch #105 - Loss: 0.8167356848716736\n",
      "Ep 57: Batch #106 - Loss: 0.6266441941261292\n",
      "Ep 57: Batch #107 - Loss: 0.6154400706291199\n",
      "Ep 57: Batch #108 - Loss: 0.9003668427467346\n",
      "Ep 57: Batch #109 - Loss: 0.6272754669189453\n",
      "Ep 57: Batch #110 - Loss: 0.7262348532676697\n",
      "Ep 57: Batch #111 - Loss: 1.0433990955352783\n",
      "Ep 57: Batch #112 - Loss: 0.7960062623023987\n",
      "Ep 57: Batch #113 - Loss: 0.6582124829292297\n",
      "Ep 57: Batch #114 - Loss: 0.7274605631828308\n",
      "Ep 57: Batch #115 - Loss: 0.9086191058158875\n",
      "Ep 57: Batch #116 - Loss: 0.5220812559127808\n",
      "Ep 57: Batch #117 - Loss: 0.6793200373649597\n",
      "Ep 57: Batch #118 - Loss: 0.4554935097694397\n",
      "Ep 57: Batch #119 - Loss: 0.807992696762085\n",
      "Ep 57: Batch #120 - Loss: 0.6599934697151184\n",
      "Ep 57: Batch #121 - Loss: 0.561310350894928\n",
      "Ep 57: Batch #122 - Loss: 0.7104536294937134\n",
      "Ep 57: Batch #123 - Loss: 0.7175207734107971\n",
      "Ep 57: Batch #124 - Loss: 0.5569069385528564\n",
      "Ep 57: Batch #125 - Loss: 2.4717423915863037\n",
      "Ep 57: Batch #126 - Loss: 1.0024482011795044\n",
      "Ep 57: Batch #127 - Loss: 0.5824825763702393\n",
      "Ep 57: Batch #128 - Loss: 0.8849982023239136\n",
      "Ep 57: Batch #129 - Loss: 0.6786520481109619\n",
      "Ep 57: Batch #130 - Loss: 0.596168041229248\n",
      "Ep 57: Batch #131 - Loss: 0.8041587471961975\n",
      "Ep 57: Batch #132 - Loss: 0.6840361952781677\n",
      "Ep 57: Batch #133 - Loss: 0.6676918268203735\n",
      "Ep 57: Batch #134 - Loss: 0.6368575692176819\n",
      "Ep 57: Batch #135 - Loss: 0.8216432929039001\n",
      "Ep 57: Batch #136 - Loss: 1.0423023700714111\n",
      "Ep 57: Batch #137 - Loss: 0.7550020217895508\n",
      "Ep 57: Batch #138 - Loss: 0.9016914367675781\n",
      "Ep 57: Batch #139 - Loss: 0.6766818165779114\n",
      "Ep 57: Batch #140 - Loss: 0.8437385559082031\n",
      "Ep 57: Batch #141 - Loss: 1.1251164674758911\n",
      "Ep 57: Batch #142 - Loss: 0.6720526218414307\n",
      "Ep 57: Batch #143 - Loss: 0.7718893885612488\n",
      "Ep 57: Batch #144 - Loss: 0.6128368973731995\n",
      "Ep 57: Batch #145 - Loss: 0.6007477641105652\n",
      "Ep 57: Batch #146 - Loss: 0.7001774311065674\n",
      "Ep 57: Batch #147 - Loss: 0.6640840768814087\n",
      "Ep 57: Batch #148 - Loss: 0.7537649869918823\n",
      "Ep 57: Batch #149 - Loss: 0.6173220276832581\n",
      "Ep 57: Batch #150 - Loss: 0.7204259037971497\n",
      "Ep 57: Batch #151 - Loss: 0.6275495886802673\n",
      "Ep 57: Batch #152 - Loss: 0.6073455810546875\n",
      "Ep 57: Batch #153 - Loss: 0.8269268274307251\n",
      "Ep 57: Batch #154 - Loss: 0.632790207862854\n",
      "Ep 57: Batch #155 - Loss: 0.6917800307273865\n",
      "Ep 57: Batch #156 - Loss: 0.7852672934532166\n",
      "Ep 57: Batch #157 - Loss: 0.6133910417556763\n",
      "Ep 57: Batch #158 - Loss: 0.7180581092834473\n",
      "Ep 57: Batch #159 - Loss: 0.598127007484436\n",
      "Ep 57: Batch #160 - Loss: 0.6948195099830627\n",
      "Ep 57: Batch #161 - Loss: 0.6697130799293518\n",
      "Ep 57: Batch #162 - Loss: 0.7179170846939087\n",
      "Ep 57: Batch #163 - Loss: 0.7596099376678467\n",
      "Ep 57: Batch #164 - Loss: 0.6479476094245911\n",
      "Ep 57: Batch #165 - Loss: 1.3404382467269897\n",
      "Ep 57: Batch #166 - Loss: 0.5344451665878296\n",
      "Ep 57: Batch #167 - Loss: 0.7154673337936401\n",
      "Ep 57: Batch #168 - Loss: 0.6928359866142273\n",
      "Ep 57: Batch #169 - Loss: 0.6675027012825012\n",
      "Ep 57: Batch #170 - Loss: 0.6281904578208923\n",
      "Ep 57: Batch #171 - Loss: 0.6405431628227234\n",
      "Ep 57: Batch #172 - Loss: 0.5344244241714478\n",
      "Ep 57: Batch #173 - Loss: 0.929601788520813\n",
      "Ep 57: Batch #174 - Loss: 0.4954909682273865\n",
      "Ep 57: Batch #175 - Loss: 0.6358252167701721\n",
      "Ep 57: Batch #176 - Loss: 0.8972278237342834\n",
      "Ep 57: Batch #177 - Loss: 0.6506558656692505\n",
      "Ep 57: Batch #178 - Loss: 0.6232670545578003\n",
      "Ep 57: Batch #179 - Loss: 0.7476333975791931\n",
      "Ep 57: Batch #180 - Loss: 0.6509138941764832\n",
      "Ep 57: Batch #181 - Loss: 0.8021261692047119\n",
      "Ep 57: Batch #182 - Loss: 0.6276313066482544\n",
      "Ep 57: Batch #183 - Loss: 0.6062160730361938\n",
      "Ep 57: Batch #184 - Loss: 0.9210587739944458\n",
      "Ep 57: Batch #185 - Loss: 0.6334912776947021\n",
      "Ep 57: Batch #186 - Loss: 0.7548975944519043\n",
      "Ep 57: Batch #187 - Loss: 0.8672569394111633\n",
      "Ep 57: Batch #188 - Loss: 0.9536471366882324\n",
      "Ep 57: Batch #189 - Loss: 0.5869805812835693\n",
      "Ep 57: Batch #190 - Loss: 0.6234238147735596\n",
      "Ep 57: Batch #191 - Loss: 0.805666983127594\n",
      "Ep 57: Batch #192 - Loss: 0.570900022983551\n",
      "Ep 57: Batch #193 - Loss: 0.6311402320861816\n",
      "Ep 57: Batch #194 - Loss: 0.5435784459114075\n",
      "Ep 57: Batch #195 - Loss: 0.7865080237388611\n",
      "Ep 57: Batch #196 - Loss: 0.6932328939437866\n",
      "Ep 57: Batch #197 - Loss: 0.7014018297195435\n",
      "Ep 57: Batch #198 - Loss: 0.5338104963302612\n",
      "Ep 57: Batch #199 - Loss: 0.6440074443817139\n",
      "Ep 58: Batch #0 - Loss: 0.6518530249595642\n",
      "Ep 58: Batch #1 - Loss: 0.7159176468849182\n",
      "Ep 58: Batch #2 - Loss: 0.8604768514633179\n",
      "Ep 58: Batch #3 - Loss: 0.7222673296928406\n",
      "Ep 58: Batch #4 - Loss: 0.6574323773384094\n",
      "Ep 58: Batch #5 - Loss: 0.553871750831604\n",
      "Ep 58: Batch #6 - Loss: 0.7366155982017517\n",
      "Ep 58: Batch #7 - Loss: 0.576210081577301\n",
      "Ep 58: Batch #8 - Loss: 0.5862041115760803\n",
      "Ep 58: Batch #9 - Loss: 1.094459056854248\n",
      "Ep 58: Batch #10 - Loss: 0.8040950894355774\n",
      "Ep 58: Batch #11 - Loss: 0.5445048809051514\n",
      "Ep 58: Batch #12 - Loss: 1.2034114599227905\n",
      "Ep 58: Batch #13 - Loss: 0.5718183517456055\n",
      "Ep 58: Batch #14 - Loss: 0.5997392535209656\n",
      "Ep 58: Batch #15 - Loss: 0.850466251373291\n",
      "Ep 58: Batch #16 - Loss: 0.9549007415771484\n",
      "Ep 58: Batch #17 - Loss: 0.7309157848358154\n",
      "Ep 58: Batch #18 - Loss: 0.8083378076553345\n",
      "Ep 58: Batch #19 - Loss: 0.564212441444397\n",
      "Ep 58: Batch #20 - Loss: 0.5469167828559875\n",
      "Ep 58: Batch #21 - Loss: 0.8163567185401917\n",
      "Ep 58: Batch #22 - Loss: 0.6084862351417542\n",
      "Ep 58: Batch #23 - Loss: 0.6005499362945557\n",
      "Ep 58: Batch #24 - Loss: 0.6389420032501221\n",
      "Ep 58: Batch #25 - Loss: 0.6064170002937317\n",
      "Ep 58: Batch #26 - Loss: 0.557560384273529\n",
      "Ep 58: Batch #27 - Loss: 1.1423132419586182\n",
      "Ep 58: Batch #28 - Loss: 0.6919031739234924\n",
      "Ep 58: Batch #29 - Loss: 0.75458163022995\n",
      "Ep 58: Batch #30 - Loss: 0.8302885293960571\n",
      "Ep 58: Batch #31 - Loss: 0.5613961219787598\n",
      "Ep 58: Batch #32 - Loss: 0.5814938545227051\n",
      "Ep 58: Batch #33 - Loss: 0.6669871211051941\n",
      "Ep 58: Batch #34 - Loss: 0.6385060548782349\n",
      "Ep 58: Batch #35 - Loss: 0.7243762612342834\n",
      "Ep 58: Batch #36 - Loss: 0.58480304479599\n",
      "Ep 58: Batch #37 - Loss: 0.921450138092041\n",
      "Ep 58: Batch #38 - Loss: 0.5693562626838684\n",
      "Ep 58: Batch #39 - Loss: 0.6861975789070129\n",
      "Ep 58: Batch #40 - Loss: 0.604574978351593\n",
      "Ep 58: Batch #41 - Loss: 0.620330274105072\n",
      "Ep 58: Batch #42 - Loss: 0.570758581161499\n",
      "Ep 58: Batch #43 - Loss: 0.6325013041496277\n",
      "Ep 58: Batch #44 - Loss: 0.6141246557235718\n",
      "Ep 58: Batch #45 - Loss: 0.5249922275543213\n",
      "Ep 58: Batch #46 - Loss: 0.6974066495895386\n",
      "Ep 58: Batch #47 - Loss: 0.8047732710838318\n",
      "Ep 58: Batch #48 - Loss: 1.0415098667144775\n",
      "Ep 58: Batch #49 - Loss: 0.8129213452339172\n",
      "Ep 58: Batch #50 - Loss: 0.5739255547523499\n",
      "Ep 58: Batch #51 - Loss: 0.8184077143669128\n",
      "Ep 58: Batch #52 - Loss: 0.6766654849052429\n",
      "Ep 58: Batch #53 - Loss: 0.7157806158065796\n",
      "Ep 58: Batch #54 - Loss: 0.578536331653595\n",
      "Ep 58: Batch #55 - Loss: 0.6100051403045654\n",
      "Ep 58: Batch #56 - Loss: 0.8579258918762207\n",
      "Ep 58: Batch #57 - Loss: 0.6827121376991272\n",
      "Ep 58: Batch #58 - Loss: 0.8280982971191406\n",
      "Ep 58: Batch #59 - Loss: 0.5589319467544556\n",
      "Ep 58: Batch #60 - Loss: 1.0091297626495361\n",
      "Ep 58: Batch #61 - Loss: 0.5355120897293091\n",
      "Ep 58: Batch #62 - Loss: 0.5746698379516602\n",
      "Ep 58: Batch #63 - Loss: 0.7817367315292358\n",
      "Ep 58: Batch #64 - Loss: 8.33086109161377\n",
      "Ep 58: Batch #65 - Loss: 0.5250259637832642\n",
      "Ep 58: Batch #66 - Loss: 0.6647229194641113\n",
      "Ep 58: Batch #67 - Loss: 0.7760474681854248\n",
      "Ep 58: Batch #68 - Loss: 0.7135896682739258\n",
      "Ep 58: Batch #69 - Loss: 0.5882234573364258\n",
      "Ep 58: Batch #70 - Loss: 0.6153463125228882\n",
      "Ep 58: Batch #71 - Loss: 0.5363447666168213\n",
      "Ep 58: Batch #72 - Loss: 0.6629928350448608\n",
      "Ep 58: Batch #73 - Loss: 0.7218981385231018\n",
      "Ep 58: Batch #74 - Loss: 0.5775855779647827\n",
      "Ep 58: Batch #75 - Loss: 0.6677999496459961\n",
      "Ep 58: Batch #76 - Loss: 0.9261279106140137\n",
      "Ep 58: Batch #77 - Loss: 0.5760691165924072\n",
      "Ep 58: Batch #78 - Loss: 0.920534610748291\n",
      "Ep 58: Batch #79 - Loss: 0.526250422000885\n",
      "Ep 58: Batch #80 - Loss: 0.693324089050293\n",
      "Ep 58: Batch #81 - Loss: 1.5291210412979126\n",
      "Ep 58: Batch #82 - Loss: 0.7520434856414795\n",
      "Ep 58: Batch #83 - Loss: 1.2557097673416138\n",
      "Ep 58: Batch #84 - Loss: 0.5777654051780701\n",
      "Ep 58: Batch #85 - Loss: 0.7865637540817261\n",
      "Ep 58: Batch #86 - Loss: 0.5487523078918457\n",
      "Ep 58: Batch #87 - Loss: 0.5724846720695496\n",
      "Ep 58: Batch #88 - Loss: 0.6573870778083801\n",
      "Ep 58: Batch #89 - Loss: 0.7289472222328186\n",
      "Ep 58: Batch #90 - Loss: 0.9014279842376709\n",
      "Ep 58: Batch #91 - Loss: 0.6495709419250488\n",
      "Ep 58: Batch #92 - Loss: 0.7316228151321411\n",
      "Ep 58: Batch #93 - Loss: 0.7833768725395203\n",
      "Ep 58: Batch #94 - Loss: 0.7474777698516846\n",
      "Ep 58: Batch #95 - Loss: 0.7611015439033508\n",
      "Ep 58: Batch #96 - Loss: 0.7594422698020935\n",
      "Ep 58: Batch #97 - Loss: 0.5866773128509521\n",
      "Ep 58: Batch #98 - Loss: 0.5786288380622864\n",
      "Ep 58: Batch #99 - Loss: 0.7957716584205627\n",
      "Ep 58: Batch #100 - Loss: 0.5580716133117676\n",
      "Ep 58: Batch #101 - Loss: 0.8676872849464417\n",
      "Ep 58: Batch #102 - Loss: 0.6128885746002197\n",
      "Ep 58: Batch #103 - Loss: 0.6366327404975891\n",
      "Ep 58: Batch #104 - Loss: 0.6615229845046997\n",
      "Ep 58: Batch #105 - Loss: 0.8164928555488586\n",
      "Ep 58: Batch #106 - Loss: 0.6265738010406494\n",
      "Ep 58: Batch #107 - Loss: 0.6153119206428528\n",
      "Ep 58: Batch #108 - Loss: 0.901190459728241\n",
      "Ep 58: Batch #109 - Loss: 0.6274973750114441\n",
      "Ep 58: Batch #110 - Loss: 0.7256208062171936\n",
      "Ep 58: Batch #111 - Loss: 1.0427215099334717\n",
      "Ep 58: Batch #112 - Loss: 0.7956304550170898\n",
      "Ep 58: Batch #113 - Loss: 0.6579329371452332\n",
      "Ep 58: Batch #114 - Loss: 0.7274140119552612\n",
      "Ep 58: Batch #115 - Loss: 0.9086771011352539\n",
      "Ep 58: Batch #116 - Loss: 0.5218473672866821\n",
      "Ep 58: Batch #117 - Loss: 0.6793535947799683\n",
      "Ep 58: Batch #118 - Loss: 0.4551955461502075\n",
      "Model saved in file: ./weights_autoencoder_sigmoid/model_e58b118_1516648799.3244808.ckpt\n",
      "Ep 58: Batch #119 - Loss: 0.8097353577613831\n",
      "Ep 58: Batch #120 - Loss: 0.6603505611419678\n",
      "Ep 58: Batch #121 - Loss: 0.5612964034080505\n",
      "Ep 58: Batch #122 - Loss: 0.7104588150978088\n",
      "Ep 58: Batch #123 - Loss: 0.7172980904579163\n",
      "Ep 58: Batch #124 - Loss: 0.5567616820335388\n",
      "Ep 58: Batch #125 - Loss: 2.4712367057800293\n",
      "Ep 58: Batch #126 - Loss: 1.0023456811904907\n",
      "Ep 58: Batch #127 - Loss: 0.582246720790863\n",
      "Ep 58: Batch #128 - Loss: 0.8850796818733215\n",
      "Ep 58: Batch #129 - Loss: 0.6788206696510315\n",
      "Ep 58: Batch #130 - Loss: 0.5958681106567383\n",
      "Ep 58: Batch #131 - Loss: 0.8033803105354309\n",
      "Ep 58: Batch #132 - Loss: 0.6840133666992188\n",
      "Ep 58: Batch #133 - Loss: 0.6674007773399353\n",
      "Ep 58: Batch #134 - Loss: 0.6365807056427002\n",
      "Ep 58: Batch #135 - Loss: 0.8216334581375122\n",
      "Ep 58: Batch #136 - Loss: 1.0418422222137451\n",
      "Ep 58: Batch #137 - Loss: 0.7543236613273621\n",
      "Ep 58: Batch #138 - Loss: 0.90127032995224\n",
      "Ep 58: Batch #139 - Loss: 0.6761870980262756\n",
      "Ep 58: Batch #140 - Loss: 0.8435394763946533\n",
      "Ep 58: Batch #141 - Loss: 1.1243655681610107\n",
      "Ep 58: Batch #142 - Loss: 0.6716244220733643\n",
      "Ep 58: Batch #143 - Loss: 0.7716654539108276\n",
      "Ep 58: Batch #144 - Loss: 0.6126974821090698\n",
      "Ep 58: Batch #145 - Loss: 0.6004765629768372\n",
      "Ep 58: Batch #146 - Loss: 0.6999599933624268\n",
      "Ep 58: Batch #147 - Loss: 0.663391649723053\n",
      "Ep 58: Batch #148 - Loss: 0.7532824873924255\n",
      "Ep 58: Batch #149 - Loss: 0.6166587471961975\n",
      "Ep 58: Batch #150 - Loss: 0.7203912734985352\n",
      "Ep 58: Batch #151 - Loss: 0.6273694038391113\n",
      "Ep 58: Batch #152 - Loss: 0.6072418689727783\n",
      "Ep 58: Batch #153 - Loss: 0.8266424536705017\n",
      "Ep 58: Batch #154 - Loss: 0.6332716345787048\n",
      "Ep 58: Batch #155 - Loss: 0.6916003823280334\n",
      "Ep 58: Batch #156 - Loss: 0.7843900918960571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 58: Batch #157 - Loss: 0.6133787631988525\n",
      "Ep 58: Batch #158 - Loss: 0.7181960940361023\n",
      "Ep 58: Batch #159 - Loss: 0.5979501008987427\n",
      "Ep 58: Batch #160 - Loss: 0.6947303414344788\n",
      "Ep 58: Batch #161 - Loss: 0.6695695519447327\n",
      "Ep 58: Batch #162 - Loss: 0.717756450176239\n",
      "Ep 58: Batch #163 - Loss: 0.7594138979911804\n",
      "Ep 58: Batch #164 - Loss: 0.6479011178016663\n",
      "Ep 58: Batch #165 - Loss: 1.339991807937622\n",
      "Ep 58: Batch #166 - Loss: 0.5344855189323425\n",
      "Ep 58: Batch #167 - Loss: 0.7147165536880493\n",
      "Ep 58: Batch #168 - Loss: 0.692897379398346\n",
      "Ep 58: Batch #169 - Loss: 0.6676827073097229\n",
      "Ep 58: Batch #170 - Loss: 0.628479540348053\n",
      "Ep 58: Batch #171 - Loss: 0.6402038335800171\n",
      "Ep 58: Batch #172 - Loss: 0.5345895886421204\n",
      "Ep 58: Batch #173 - Loss: 0.9291778802871704\n",
      "Ep 58: Batch #174 - Loss: 0.49546700716018677\n",
      "Ep 58: Batch #175 - Loss: 0.6361637711524963\n",
      "Ep 58: Batch #176 - Loss: 0.8969894051551819\n",
      "Ep 58: Batch #177 - Loss: 0.6505901217460632\n",
      "Ep 58: Batch #178 - Loss: 0.6232540607452393\n",
      "Ep 58: Batch #179 - Loss: 0.7474367022514343\n",
      "Ep 58: Batch #180 - Loss: 0.6509907245635986\n",
      "Ep 58: Batch #181 - Loss: 0.801703155040741\n",
      "Ep 58: Batch #182 - Loss: 0.6274943947792053\n",
      "Ep 58: Batch #183 - Loss: 0.6060367822647095\n",
      "Ep 58: Batch #184 - Loss: 0.9207514524459839\n",
      "Ep 58: Batch #185 - Loss: 0.6330385804176331\n",
      "Ep 58: Batch #186 - Loss: 0.754368245601654\n",
      "Ep 58: Batch #187 - Loss: 0.8662320375442505\n",
      "Ep 58: Batch #188 - Loss: 0.9533616304397583\n",
      "Ep 58: Batch #189 - Loss: 0.5868767499923706\n",
      "Ep 58: Batch #190 - Loss: 0.623132050037384\n",
      "Ep 58: Batch #191 - Loss: 0.8058688044548035\n",
      "Ep 58: Batch #192 - Loss: 0.5710802674293518\n",
      "Ep 58: Batch #193 - Loss: 0.6312106847763062\n",
      "Ep 58: Batch #194 - Loss: 0.5434740781784058\n",
      "Ep 58: Batch #195 - Loss: 0.7864407300949097\n",
      "Ep 58: Batch #196 - Loss: 0.6932487487792969\n",
      "Ep 58: Batch #197 - Loss: 0.7012360692024231\n",
      "Ep 58: Batch #198 - Loss: 0.5339052081108093\n",
      "Ep 58: Batch #199 - Loss: 0.6439551711082458\n",
      "Ep 59: Batch #0 - Loss: 0.651660680770874\n",
      "Ep 59: Batch #1 - Loss: 0.7161345481872559\n",
      "Ep 59: Batch #2 - Loss: 0.860343873500824\n",
      "Ep 59: Batch #3 - Loss: 0.7222172021865845\n",
      "Ep 59: Batch #4 - Loss: 0.657373309135437\n",
      "Ep 59: Batch #5 - Loss: 0.5537893772125244\n",
      "Ep 59: Batch #6 - Loss: 0.7361855506896973\n",
      "Ep 59: Batch #7 - Loss: 0.5762872695922852\n",
      "Ep 59: Batch #8 - Loss: 0.5861472487449646\n",
      "Ep 59: Batch #9 - Loss: 1.095253825187683\n",
      "Ep 59: Batch #10 - Loss: 0.8038671612739563\n",
      "Ep 59: Batch #11 - Loss: 0.5446946024894714\n",
      "Ep 59: Batch #12 - Loss: 1.2029575109481812\n",
      "Ep 59: Batch #13 - Loss: 0.571841299533844\n",
      "Ep 59: Batch #14 - Loss: 0.5997197031974792\n",
      "Ep 59: Batch #15 - Loss: 0.8498321175575256\n",
      "Ep 59: Batch #16 - Loss: 0.9556068181991577\n",
      "Ep 59: Batch #17 - Loss: 0.731083333492279\n",
      "Ep 59: Batch #18 - Loss: 0.8085663318634033\n",
      "Ep 59: Batch #19 - Loss: 0.5642561316490173\n",
      "Ep 59: Batch #20 - Loss: 0.547319769859314\n",
      "Ep 59: Batch #21 - Loss: 0.8147085309028625\n",
      "Ep 59: Batch #22 - Loss: 0.6090673208236694\n",
      "Ep 59: Batch #23 - Loss: 0.6009173393249512\n",
      "Ep 59: Batch #24 - Loss: 0.6390185952186584\n",
      "Ep 59: Batch #25 - Loss: 0.6065350770950317\n",
      "Ep 59: Batch #26 - Loss: 0.5573853850364685\n",
      "Ep 59: Batch #27 - Loss: 1.142194390296936\n",
      "Ep 59: Batch #28 - Loss: 0.6920230388641357\n",
      "Ep 59: Batch #29 - Loss: 0.7548806071281433\n",
      "Ep 59: Batch #30 - Loss: 0.8297703266143799\n",
      "Ep 59: Batch #31 - Loss: 0.5614414811134338\n",
      "Ep 59: Batch #32 - Loss: 0.5814568996429443\n",
      "Ep 59: Batch #33 - Loss: 0.6672322154045105\n",
      "Ep 59: Batch #34 - Loss: 0.6383390426635742\n",
      "Ep 59: Batch #35 - Loss: 0.724748432636261\n",
      "Ep 59: Batch #36 - Loss: 0.5842599272727966\n",
      "Ep 59: Batch #37 - Loss: 0.9214147329330444\n",
      "Ep 59: Batch #38 - Loss: 0.5692254304885864\n",
      "Ep 59: Batch #39 - Loss: 0.6870717406272888\n",
      "Ep 59: Batch #40 - Loss: 0.6046763062477112\n",
      "Ep 59: Batch #41 - Loss: 0.6205243468284607\n",
      "Ep 59: Batch #42 - Loss: 0.5710848569869995\n",
      "Ep 59: Batch #43 - Loss: 0.6323813796043396\n",
      "Ep 59: Batch #44 - Loss: 0.6141232848167419\n",
      "Ep 59: Batch #45 - Loss: 0.5251136422157288\n",
      "Ep 59: Batch #46 - Loss: 0.6974440217018127\n",
      "Ep 59: Batch #47 - Loss: 0.8047630190849304\n",
      "Ep 59: Batch #48 - Loss: 1.0416761636734009\n",
      "Ep 59: Batch #49 - Loss: 0.8133814334869385\n",
      "Ep 59: Batch #50 - Loss: 0.5738670825958252\n",
      "Ep 59: Batch #51 - Loss: 0.8178678750991821\n",
      "Ep 59: Batch #52 - Loss: 0.6764268279075623\n",
      "Ep 59: Batch #53 - Loss: 0.7159634828567505\n",
      "Ep 59: Batch #54 - Loss: 0.5784524083137512\n",
      "Ep 59: Batch #55 - Loss: 0.6097586750984192\n",
      "Ep 59: Batch #56 - Loss: 0.8579375743865967\n",
      "Ep 59: Batch #57 - Loss: 0.682578444480896\n",
      "Ep 59: Batch #58 - Loss: 0.8275049328804016\n",
      "Ep 59: Batch #59 - Loss: 0.5586966872215271\n",
      "Ep 59: Batch #60 - Loss: 1.0090628862380981\n",
      "Ep 59: Batch #61 - Loss: 0.5355207324028015\n",
      "Ep 59: Batch #62 - Loss: 0.5746395587921143\n",
      "Ep 59: Batch #63 - Loss: 0.7814352512359619\n",
      "Ep 59: Batch #64 - Loss: 8.318241119384766\n",
      "Ep 59: Batch #65 - Loss: 0.5247867703437805\n",
      "Ep 59: Batch #66 - Loss: 0.6647829413414001\n",
      "Ep 59: Batch #67 - Loss: 0.7759546637535095\n",
      "Ep 59: Batch #68 - Loss: 0.7135518789291382\n",
      "Ep 59: Batch #69 - Loss: 0.5880202054977417\n",
      "Ep 59: Batch #70 - Loss: 0.6154000759124756\n",
      "Ep 59: Batch #71 - Loss: 0.5363794565200806\n",
      "Ep 59: Batch #72 - Loss: 0.662941038608551\n",
      "Ep 59: Batch #73 - Loss: 0.7216414213180542\n",
      "Ep 59: Batch #74 - Loss: 0.5773608684539795\n",
      "Ep 59: Batch #75 - Loss: 0.6676601767539978\n",
      "Ep 59: Batch #76 - Loss: 0.9259012937545776\n",
      "Ep 59: Batch #77 - Loss: 0.5759229063987732\n",
      "Ep 59: Batch #78 - Loss: 0.9200557470321655\n",
      "Ep 59: Batch #79 - Loss: 0.5262811183929443\n",
      "Ep 59: Batch #80 - Loss: 0.693107545375824\n",
      "Ep 59: Batch #81 - Loss: 1.5252799987792969\n",
      "Ep 59: Batch #82 - Loss: 0.7522767186164856\n",
      "Ep 59: Batch #83 - Loss: 1.2529046535491943\n",
      "Ep 59: Batch #84 - Loss: 0.5778312683105469\n",
      "Ep 59: Batch #85 - Loss: 0.7864139676094055\n",
      "Ep 59: Batch #86 - Loss: 0.5484023690223694\n",
      "Ep 59: Batch #87 - Loss: 0.5727171301841736\n",
      "Ep 59: Batch #88 - Loss: 0.6574175953865051\n",
      "Ep 59: Batch #89 - Loss: 0.7287158370018005\n",
      "Ep 59: Batch #90 - Loss: 0.9012588858604431\n",
      "Ep 59: Batch #91 - Loss: 0.649512767791748\n",
      "Ep 59: Batch #92 - Loss: 0.7310947179794312\n",
      "Ep 59: Batch #93 - Loss: 0.7833130955696106\n",
      "Ep 59: Batch #94 - Loss: 0.7474919557571411\n",
      "Ep 59: Batch #95 - Loss: 0.7612280249595642\n",
      "Ep 59: Batch #96 - Loss: 0.7595282793045044\n",
      "Ep 59: Batch #97 - Loss: 0.5866584181785583\n",
      "Ep 59: Batch #98 - Loss: 0.578143835067749\n",
      "Ep 59: Batch #99 - Loss: 0.7952723503112793\n",
      "Ep 59: Batch #100 - Loss: 0.5579395890235901\n",
      "Ep 59: Batch #101 - Loss: 0.8678657412528992\n",
      "Ep 59: Batch #102 - Loss: 0.6128430366516113\n",
      "Ep 59: Batch #103 - Loss: 0.6366044878959656\n",
      "Ep 59: Batch #104 - Loss: 0.6617643237113953\n",
      "Ep 59: Batch #105 - Loss: 0.8169116973876953\n",
      "Ep 59: Batch #106 - Loss: 0.6263949871063232\n",
      "Ep 59: Batch #107 - Loss: 0.6153925061225891\n",
      "Ep 59: Batch #108 - Loss: 0.9006437659263611\n",
      "Ep 59: Batch #109 - Loss: 0.6273524165153503\n",
      "Ep 59: Batch #110 - Loss: 0.725762665271759\n",
      "Ep 59: Batch #111 - Loss: 1.0430712699890137\n",
      "Ep 59: Batch #112 - Loss: 0.7958974242210388\n",
      "Ep 59: Batch #113 - Loss: 0.6577732563018799\n",
      "Ep 59: Batch #114 - Loss: 0.726983904838562\n",
      "Ep 59: Batch #115 - Loss: 0.9087918996810913\n",
      "Ep 59: Batch #116 - Loss: 0.5220000743865967\n",
      "Ep 59: Batch #117 - Loss: 0.6790284514427185\n",
      "Ep 59: Batch #118 - Loss: 0.45511671900749207\n",
      "Model saved in file: ./weights_autoencoder_sigmoid/model_e59b118_1516648799.4643793.ckpt\n",
      "Ep 59: Batch #119 - Loss: 0.8092778921127319\n",
      "Ep 59: Batch #120 - Loss: 0.6600289940834045\n",
      "Ep 59: Batch #121 - Loss: 0.5613287687301636\n",
      "Ep 59: Batch #122 - Loss: 0.7100322842597961\n",
      "Ep 59: Batch #123 - Loss: 0.7172445058822632\n",
      "Ep 59: Batch #124 - Loss: 0.5567408204078674\n",
      "Ep 59: Batch #125 - Loss: 2.4718551635742188\n",
      "Ep 59: Batch #126 - Loss: 1.0030708312988281\n",
      "Ep 59: Batch #127 - Loss: 0.5823491215705872\n",
      "Ep 59: Batch #128 - Loss: 0.8855541348457336\n",
      "Ep 59: Batch #129 - Loss: 0.6779049634933472\n",
      "Ep 59: Batch #130 - Loss: 0.5959582328796387\n",
      "Ep 59: Batch #131 - Loss: 0.8037183284759521\n",
      "Ep 59: Batch #132 - Loss: 0.683966875076294\n",
      "Ep 59: Batch #133 - Loss: 0.6674789190292358\n",
      "Ep 59: Batch #134 - Loss: 0.6365795731544495\n",
      "Ep 59: Batch #135 - Loss: 0.8213892579078674\n",
      "Ep 59: Batch #136 - Loss: 1.0431199073791504\n",
      "Ep 59: Batch #137 - Loss: 0.7549935579299927\n",
      "Ep 59: Batch #138 - Loss: 0.9013761878013611\n",
      "Ep 59: Batch #139 - Loss: 0.6767981648445129\n",
      "Ep 59: Batch #140 - Loss: 0.8434149026870728\n",
      "Ep 59: Batch #141 - Loss: 1.124463438987732\n",
      "Ep 59: Batch #142 - Loss: 0.6721267700195312\n",
      "Ep 59: Batch #143 - Loss: 0.7721166014671326\n",
      "Ep 59: Batch #144 - Loss: 0.612838625907898\n",
      "Ep 59: Batch #145 - Loss: 0.6004639267921448\n",
      "Ep 59: Batch #146 - Loss: 0.699937641620636\n",
      "Ep 59: Batch #147 - Loss: 0.6634185314178467\n",
      "Ep 59: Batch #148 - Loss: 0.75375896692276\n",
      "Ep 59: Batch #149 - Loss: 0.6170933842658997\n",
      "Ep 59: Batch #150 - Loss: 0.720454752445221\n",
      "Ep 59: Batch #151 - Loss: 0.6274953484535217\n",
      "Ep 59: Batch #152 - Loss: 0.6074724197387695\n",
      "Ep 59: Batch #153 - Loss: 0.82664954662323\n",
      "Ep 59: Batch #154 - Loss: 0.6323261260986328\n",
      "Ep 59: Batch #155 - Loss: 0.6915547847747803\n",
      "Ep 59: Batch #156 - Loss: 0.7835570573806763\n",
      "Ep 59: Batch #157 - Loss: 0.6132346987724304\n",
      "Ep 59: Batch #158 - Loss: 0.7184531688690186\n",
      "Ep 59: Batch #159 - Loss: 0.5981746315956116\n",
      "Ep 59: Batch #160 - Loss: 0.6944824457168579\n",
      "Ep 59: Batch #161 - Loss: 0.6696046590805054\n",
      "Ep 59: Batch #162 - Loss: 0.7181681394577026\n",
      "Ep 59: Batch #163 - Loss: 0.7595646381378174\n",
      "Ep 59: Batch #164 - Loss: 0.6480037569999695\n",
      "Ep 59: Batch #165 - Loss: 1.3397159576416016\n",
      "Ep 59: Batch #166 - Loss: 0.5343491435050964\n",
      "Ep 59: Batch #167 - Loss: 0.7141003012657166\n",
      "Ep 59: Batch #168 - Loss: 0.6928920149803162\n",
      "Ep 59: Batch #169 - Loss: 0.6675696969032288\n",
      "Ep 59: Batch #170 - Loss: 0.6279456615447998\n",
      "Ep 59: Batch #171 - Loss: 0.6401951313018799\n",
      "Ep 59: Batch #172 - Loss: 0.5342914462089539\n",
      "Ep 59: Batch #173 - Loss: 0.9297634363174438\n",
      "Ep 59: Batch #174 - Loss: 0.49543216824531555\n",
      "Ep 59: Batch #175 - Loss: 0.6353191137313843\n",
      "Ep 59: Batch #176 - Loss: 0.897595226764679\n",
      "Ep 59: Batch #177 - Loss: 0.650779128074646\n",
      "Ep 59: Batch #178 - Loss: 0.6229718327522278\n",
      "Ep 59: Batch #179 - Loss: 0.7468442916870117\n",
      "Ep 59: Batch #180 - Loss: 0.6508035659790039\n",
      "Ep 59: Batch #181 - Loss: 0.8020987510681152\n",
      "Ep 59: Batch #182 - Loss: 0.6278049945831299\n",
      "Ep 59: Batch #183 - Loss: 0.6061688661575317\n",
      "Ep 59: Batch #184 - Loss: 0.9206108450889587\n",
      "Ep 59: Batch #185 - Loss: 0.6331723928451538\n",
      "Ep 59: Batch #186 - Loss: 0.7546199560165405\n",
      "Ep 59: Batch #187 - Loss: 0.8662710785865784\n",
      "Ep 59: Batch #188 - Loss: 0.9518117308616638\n",
      "Ep 59: Batch #189 - Loss: 0.5869607925415039\n",
      "Ep 59: Batch #190 - Loss: 0.6228253245353699\n",
      "Ep 59: Batch #191 - Loss: 0.805406928062439\n",
      "Ep 59: Batch #192 - Loss: 0.5709877610206604\n",
      "Ep 59: Batch #193 - Loss: 0.6311067938804626\n",
      "Ep 59: Batch #194 - Loss: 0.5432702302932739\n",
      "Ep 59: Batch #195 - Loss: 0.786421537399292\n",
      "Ep 59: Batch #196 - Loss: 0.693122923374176\n",
      "Ep 59: Batch #197 - Loss: 0.7012614011764526\n",
      "Ep 59: Batch #198 - Loss: 0.5338735580444336\n",
      "Ep 59: Batch #199 - Loss: 0.6437168121337891\n",
      "Ep 60: Batch #0 - Loss: 0.6515846848487854\n",
      "Ep 60: Batch #1 - Loss: 0.7161288857460022\n",
      "Ep 60: Batch #2 - Loss: 0.8604152202606201\n",
      "Ep 60: Batch #3 - Loss: 0.7219848036766052\n",
      "Ep 60: Batch #4 - Loss: 0.6575060486793518\n",
      "Ep 60: Batch #5 - Loss: 0.5542086362838745\n",
      "Ep 60: Batch #6 - Loss: 0.7362989783287048\n",
      "Ep 60: Batch #7 - Loss: 0.5763996243476868\n",
      "Ep 60: Batch #8 - Loss: 0.5862501859664917\n",
      "Ep 60: Batch #9 - Loss: 1.095154047012329\n",
      "Ep 60: Batch #10 - Loss: 0.8028970956802368\n",
      "Ep 60: Batch #11 - Loss: 0.5446199178695679\n",
      "Ep 60: Batch #12 - Loss: 1.2022674083709717\n",
      "Ep 60: Batch #13 - Loss: 0.5718144178390503\n",
      "Ep 60: Batch #14 - Loss: 0.5995230078697205\n",
      "Ep 60: Batch #15 - Loss: 0.8488818407058716\n",
      "Ep 60: Batch #16 - Loss: 0.9556136727333069\n",
      "Ep 60: Batch #17 - Loss: 0.7309690117835999\n",
      "Ep 60: Batch #18 - Loss: 0.8087190389633179\n",
      "Ep 60: Batch #19 - Loss: 0.5642775297164917\n",
      "Ep 60: Batch #20 - Loss: 0.547119677066803\n",
      "Ep 60: Batch #21 - Loss: 0.8142096400260925\n",
      "Ep 60: Batch #22 - Loss: 0.6089599132537842\n",
      "Ep 60: Batch #23 - Loss: 0.6006137132644653\n",
      "Ep 60: Batch #24 - Loss: 0.6388309001922607\n",
      "Ep 60: Batch #25 - Loss: 0.6066737174987793\n",
      "Ep 60: Batch #26 - Loss: 0.5572880506515503\n",
      "Ep 60: Batch #27 - Loss: 1.1420021057128906\n",
      "Ep 60: Batch #28 - Loss: 0.6919379830360413\n",
      "Ep 60: Batch #29 - Loss: 0.7546695470809937\n",
      "Ep 60: Batch #30 - Loss: 0.8296358585357666\n",
      "Ep 60: Batch #31 - Loss: 0.561507523059845\n",
      "Ep 60: Batch #32 - Loss: 0.5814660787582397\n",
      "Ep 60: Batch #33 - Loss: 0.6673079133033752\n",
      "Ep 60: Batch #34 - Loss: 0.6382427215576172\n",
      "Ep 60: Batch #35 - Loss: 0.7246873378753662\n",
      "Ep 60: Batch #36 - Loss: 0.5844433307647705\n",
      "Ep 60: Batch #37 - Loss: 0.9214614033699036\n",
      "Ep 60: Batch #38 - Loss: 0.569111704826355\n",
      "Ep 60: Batch #39 - Loss: 0.6865097880363464\n",
      "Ep 60: Batch #40 - Loss: 0.6046504974365234\n",
      "Ep 60: Batch #41 - Loss: 0.6202702522277832\n",
      "Ep 60: Batch #42 - Loss: 0.5707985162734985\n",
      "Ep 60: Batch #43 - Loss: 0.632483959197998\n",
      "Ep 60: Batch #44 - Loss: 0.613865315914154\n",
      "Ep 60: Batch #45 - Loss: 0.5248723030090332\n",
      "Ep 60: Batch #46 - Loss: 0.6974513530731201\n",
      "Ep 60: Batch #47 - Loss: 0.8046347498893738\n",
      "Ep 60: Batch #48 - Loss: 1.0423741340637207\n",
      "Ep 60: Batch #49 - Loss: 0.813077986240387\n",
      "Ep 60: Batch #50 - Loss: 0.573974609375\n",
      "Ep 60: Batch #51 - Loss: 0.8179200887680054\n",
      "Ep 60: Batch #52 - Loss: 0.6762657761573792\n",
      "Ep 60: Batch #53 - Loss: 0.7158570289611816\n",
      "Ep 60: Batch #54 - Loss: 0.5784019231796265\n",
      "Ep 60: Batch #55 - Loss: 0.609981119632721\n",
      "Ep 60: Batch #56 - Loss: 0.8576390743255615\n",
      "Ep 60: Batch #57 - Loss: 0.6825541853904724\n",
      "Ep 60: Batch #58 - Loss: 0.8277769088745117\n",
      "Ep 60: Batch #59 - Loss: 0.558641791343689\n",
      "Ep 60: Batch #60 - Loss: 1.0087908506393433\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 60: Batch #61 - Loss: 0.5353866219520569\n",
      "Ep 60: Batch #62 - Loss: 0.5744971036911011\n",
      "Ep 60: Batch #63 - Loss: 0.781292200088501\n",
      "Ep 60: Batch #64 - Loss: 8.30422592163086\n",
      "Ep 60: Batch #65 - Loss: 0.5246446132659912\n",
      "Ep 60: Batch #66 - Loss: 0.6646811366081238\n",
      "Ep 60: Batch #67 - Loss: 0.7759113311767578\n",
      "Ep 60: Batch #68 - Loss: 0.7136098742485046\n",
      "Ep 60: Batch #69 - Loss: 0.588012158870697\n",
      "Ep 60: Batch #70 - Loss: 0.6152787804603577\n",
      "Ep 60: Batch #71 - Loss: 0.5362212061882019\n",
      "Ep 60: Batch #72 - Loss: 0.6628741025924683\n",
      "Ep 60: Batch #73 - Loss: 0.7215225100517273\n",
      "Ep 60: Batch #74 - Loss: 0.5773075819015503\n",
      "Ep 60: Batch #75 - Loss: 0.6674089431762695\n",
      "Ep 60: Batch #76 - Loss: 0.9256221055984497\n",
      "Ep 60: Batch #77 - Loss: 0.5757639408111572\n",
      "Ep 60: Batch #78 - Loss: 0.9201900959014893\n",
      "Ep 60: Batch #79 - Loss: 0.525860071182251\n",
      "Ep 60: Batch #80 - Loss: 0.6928456425666809\n",
      "Ep 60: Batch #81 - Loss: 1.5272800922393799\n",
      "Ep 60: Batch #82 - Loss: 0.7518933415412903\n",
      "Ep 60: Batch #83 - Loss: 1.2504346370697021\n",
      "Ep 60: Batch #84 - Loss: 0.578341007232666\n",
      "Ep 60: Batch #85 - Loss: 0.786138653755188\n",
      "Ep 60: Batch #86 - Loss: 0.5486518144607544\n",
      "Ep 60: Batch #87 - Loss: 0.5729212760925293\n",
      "Ep 60: Batch #88 - Loss: 0.6576327085494995\n",
      "Ep 60: Batch #89 - Loss: 0.7292429804801941\n",
      "Ep 60: Batch #90 - Loss: 0.9015108346939087\n",
      "Ep 60: Batch #91 - Loss: 0.6498494744300842\n",
      "Ep 60: Batch #92 - Loss: 0.7311843037605286\n",
      "Ep 60: Batch #93 - Loss: 0.7838051319122314\n",
      "Ep 60: Batch #94 - Loss: 0.7479784488677979\n",
      "Ep 60: Batch #95 - Loss: 0.7615153789520264\n",
      "Ep 60: Batch #96 - Loss: 0.7595945596694946\n",
      "Ep 60: Batch #97 - Loss: 0.5876124501228333\n",
      "Ep 60: Batch #98 - Loss: 0.5786898136138916\n",
      "Ep 60: Batch #99 - Loss: 0.7973448634147644\n",
      "Ep 60: Batch #100 - Loss: 0.5581045746803284\n",
      "Ep 60: Batch #101 - Loss: 0.8682061433792114\n",
      "Ep 60: Batch #102 - Loss: 0.613081157207489\n",
      "Ep 60: Batch #103 - Loss: 0.6366687417030334\n",
      "Ep 60: Batch #104 - Loss: 0.6621963381767273\n",
      "Ep 60: Batch #105 - Loss: 0.8171977996826172\n",
      "Ep 60: Batch #106 - Loss: 0.626706600189209\n",
      "Ep 60: Batch #107 - Loss: 0.6156975626945496\n",
      "Ep 60: Batch #108 - Loss: 0.9007718563079834\n",
      "Ep 60: Batch #109 - Loss: 0.6278083920478821\n",
      "Ep 60: Batch #110 - Loss: 0.7267211079597473\n",
      "Ep 60: Batch #111 - Loss: 1.0428215265274048\n",
      "Ep 60: Batch #112 - Loss: 0.7947390079498291\n",
      "Ep 60: Batch #113 - Loss: 0.657753586769104\n",
      "Ep 60: Batch #114 - Loss: 0.7272756099700928\n",
      "Ep 60: Batch #115 - Loss: 0.908778727054596\n",
      "Ep 60: Batch #116 - Loss: 0.5219488143920898\n",
      "Ep 60: Batch #117 - Loss: 0.6790106892585754\n",
      "Ep 60: Batch #118 - Loss: 0.4551135003566742\n",
      "Model saved in file: ./weights_autoencoder_sigmoid/model_e60b118_1516648799.604834.ckpt\n",
      "Ep 60: Batch #119 - Loss: 0.8081588745117188\n",
      "Ep 60: Batch #120 - Loss: 0.6600576639175415\n",
      "Ep 60: Batch #121 - Loss: 0.5618109107017517\n",
      "Ep 60: Batch #122 - Loss: 0.7106065154075623\n",
      "Ep 60: Batch #123 - Loss: 0.7173629403114319\n",
      "Ep 60: Batch #124 - Loss: 0.557022213935852\n",
      "Ep 60: Batch #125 - Loss: 2.4723384380340576\n",
      "Ep 60: Batch #126 - Loss: 1.0030163526535034\n",
      "Ep 60: Batch #127 - Loss: 0.5827036499977112\n",
      "Ep 60: Batch #128 - Loss: 0.8852453827857971\n",
      "Ep 60: Batch #129 - Loss: 0.6775495409965515\n",
      "Ep 60: Batch #130 - Loss: 0.5961374640464783\n",
      "Ep 60: Batch #131 - Loss: 0.8040474653244019\n",
      "Ep 60: Batch #132 - Loss: 0.6839132308959961\n",
      "Ep 60: Batch #133 - Loss: 0.6672205924987793\n",
      "Ep 60: Batch #134 - Loss: 0.636718213558197\n",
      "Ep 60: Batch #135 - Loss: 0.821902871131897\n",
      "Ep 60: Batch #136 - Loss: 1.0426887273788452\n",
      "Ep 60: Batch #137 - Loss: 0.7554832696914673\n",
      "Ep 60: Batch #138 - Loss: 0.9015390872955322\n",
      "Ep 60: Batch #139 - Loss: 0.6764143109321594\n",
      "Ep 60: Batch #140 - Loss: 0.8433157205581665\n",
      "Ep 60: Batch #141 - Loss: 1.1239805221557617\n",
      "Ep 60: Batch #142 - Loss: 0.6724029779434204\n",
      "Ep 60: Batch #143 - Loss: 0.7720606923103333\n",
      "Ep 60: Batch #144 - Loss: 0.6128109693527222\n",
      "Ep 60: Batch #145 - Loss: 0.6001051664352417\n",
      "Ep 60: Batch #146 - Loss: 0.6998140811920166\n",
      "Ep 60: Batch #147 - Loss: 0.6633884906768799\n",
      "Ep 60: Batch #148 - Loss: 0.7538114190101624\n",
      "Ep 60: Batch #149 - Loss: 0.6167458295822144\n",
      "Ep 60: Batch #150 - Loss: 0.7204985022544861\n",
      "Ep 60: Batch #151 - Loss: 0.6272666454315186\n",
      "Ep 60: Batch #152 - Loss: 0.6073935031890869\n",
      "Ep 60: Batch #153 - Loss: 0.8263441920280457\n",
      "Ep 60: Batch #154 - Loss: 0.6328514218330383\n",
      "Ep 60: Batch #155 - Loss: 0.6916484832763672\n",
      "Ep 60: Batch #156 - Loss: 0.7823709845542908\n",
      "Ep 60: Batch #157 - Loss: 0.6130852103233337\n",
      "Ep 60: Batch #158 - Loss: 0.7182333469390869\n",
      "Ep 60: Batch #159 - Loss: 0.5978705286979675\n",
      "Ep 60: Batch #160 - Loss: 0.6940319538116455\n",
      "Ep 60: Batch #161 - Loss: 0.6696293950080872\n",
      "Ep 60: Batch #162 - Loss: 0.7182029485702515\n",
      "Ep 60: Batch #163 - Loss: 0.7595638632774353\n",
      "Ep 60: Batch #164 - Loss: 0.6478034853935242\n",
      "Ep 60: Batch #165 - Loss: 1.3400468826293945\n",
      "Ep 60: Batch #166 - Loss: 0.534437358379364\n",
      "Ep 60: Batch #167 - Loss: 0.7134127616882324\n",
      "Ep 60: Batch #168 - Loss: 0.6929841637611389\n",
      "Ep 60: Batch #169 - Loss: 0.6673497557640076\n",
      "Ep 60: Batch #170 - Loss: 0.6284865140914917\n",
      "Ep 60: Batch #171 - Loss: 0.6405149698257446\n",
      "Ep 60: Batch #172 - Loss: 0.534289538860321\n",
      "Ep 60: Batch #173 - Loss: 0.9301251173019409\n",
      "Ep 60: Batch #174 - Loss: 0.4954453706741333\n",
      "Ep 60: Batch #175 - Loss: 0.6354304552078247\n",
      "Ep 60: Batch #176 - Loss: 0.8975554704666138\n",
      "Ep 60: Batch #177 - Loss: 0.6504833698272705\n",
      "Ep 60: Batch #178 - Loss: 0.6233417987823486\n",
      "Ep 60: Batch #179 - Loss: 0.7467050552368164\n",
      "Ep 60: Batch #180 - Loss: 0.6503824591636658\n",
      "Ep 60: Batch #181 - Loss: 0.8021247982978821\n",
      "Ep 60: Batch #182 - Loss: 0.6277941465377808\n",
      "Ep 60: Batch #183 - Loss: 0.6061440706253052\n",
      "Ep 60: Batch #184 - Loss: 0.9205257892608643\n",
      "Ep 60: Batch #185 - Loss: 0.6335002183914185\n",
      "Ep 60: Batch #186 - Loss: 0.7545172572135925\n",
      "Ep 60: Batch #187 - Loss: 0.8669673800468445\n",
      "Ep 60: Batch #188 - Loss: 0.9503217935562134\n",
      "Ep 60: Batch #189 - Loss: 0.5870413184165955\n",
      "Ep 60: Batch #190 - Loss: 0.6232245564460754\n",
      "Ep 60: Batch #191 - Loss: 0.8049647212028503\n",
      "Ep 60: Batch #192 - Loss: 0.571263313293457\n",
      "Ep 60: Batch #193 - Loss: 0.6313138604164124\n",
      "Ep 60: Batch #194 - Loss: 0.5432596206665039\n",
      "Ep 60: Batch #195 - Loss: 0.7863227128982544\n",
      "Ep 60: Batch #196 - Loss: 0.6931418776512146\n",
      "Ep 60: Batch #197 - Loss: 0.7010267376899719\n",
      "Ep 60: Batch #198 - Loss: 0.5338450074195862\n",
      "Ep 60: Batch #199 - Loss: 0.643654465675354\n",
      "Ep 61: Batch #0 - Loss: 0.6517314910888672\n",
      "Ep 61: Batch #1 - Loss: 0.715981125831604\n",
      "Ep 61: Batch #2 - Loss: 0.8603790998458862\n",
      "Ep 61: Batch #3 - Loss: 0.7217195630073547\n",
      "Ep 61: Batch #4 - Loss: 0.6575213670730591\n",
      "Ep 61: Batch #5 - Loss: 0.5541432499885559\n",
      "Ep 61: Batch #6 - Loss: 0.7360488772392273\n",
      "Ep 61: Batch #7 - Loss: 0.5761522054672241\n",
      "Ep 61: Batch #8 - Loss: 0.5860737562179565\n",
      "Ep 61: Batch #9 - Loss: 1.0939795970916748\n",
      "Ep 61: Batch #10 - Loss: 0.8019009828567505\n",
      "Ep 61: Batch #11 - Loss: 0.5445564389228821\n",
      "Ep 61: Batch #12 - Loss: 1.2018582820892334\n",
      "Ep 61: Batch #13 - Loss: 0.5717660188674927\n",
      "Ep 61: Batch #14 - Loss: 0.5994413495063782\n",
      "Ep 61: Batch #15 - Loss: 0.8489155173301697\n",
      "Ep 61: Batch #16 - Loss: 0.9549332857131958\n",
      "Ep 61: Batch #17 - Loss: 0.7309080362319946\n",
      "Ep 61: Batch #18 - Loss: 0.8084929585456848\n",
      "Ep 61: Batch #19 - Loss: 0.5641911625862122\n",
      "Ep 61: Batch #20 - Loss: 0.5470275282859802\n",
      "Ep 61: Batch #21 - Loss: 0.8129503726959229\n",
      "Ep 61: Batch #22 - Loss: 0.6085090041160583\n",
      "Ep 61: Batch #23 - Loss: 0.6003884077072144\n",
      "Ep 61: Batch #24 - Loss: 0.6388444900512695\n",
      "Ep 61: Batch #25 - Loss: 0.6066247820854187\n",
      "Ep 61: Batch #26 - Loss: 0.5571913719177246\n",
      "Ep 61: Batch #27 - Loss: 1.1418122053146362\n",
      "Ep 61: Batch #28 - Loss: 0.6920332908630371\n",
      "Ep 61: Batch #29 - Loss: 0.7540091872215271\n",
      "Ep 61: Batch #30 - Loss: 0.8288248181343079\n",
      "Ep 61: Batch #31 - Loss: 0.5615877509117126\n",
      "Ep 61: Batch #32 - Loss: 0.5813482403755188\n",
      "Ep 61: Batch #33 - Loss: 0.6669666767120361\n",
      "Ep 61: Batch #34 - Loss: 0.6379057168960571\n",
      "Ep 61: Batch #35 - Loss: 0.7241984605789185\n",
      "Ep 61: Batch #36 - Loss: 0.5846729874610901\n",
      "Ep 61: Batch #37 - Loss: 0.9213347434997559\n",
      "Ep 61: Batch #38 - Loss: 0.5690175294876099\n",
      "Ep 61: Batch #39 - Loss: 0.6868074536323547\n",
      "Ep 61: Batch #40 - Loss: 0.604448139667511\n",
      "Ep 61: Batch #41 - Loss: 0.6200377941131592\n",
      "Ep 61: Batch #42 - Loss: 0.5705751776695251\n",
      "Ep 61: Batch #43 - Loss: 0.6326521635055542\n",
      "Ep 61: Batch #44 - Loss: 0.6137964129447937\n",
      "Ep 61: Batch #45 - Loss: 0.5249583125114441\n",
      "Ep 61: Batch #46 - Loss: 0.697304368019104\n",
      "Ep 61: Batch #47 - Loss: 0.8044072985649109\n",
      "Ep 61: Batch #48 - Loss: 1.0415153503417969\n",
      "Ep 61: Batch #49 - Loss: 0.8126157522201538\n",
      "Ep 61: Batch #50 - Loss: 0.5737996101379395\n",
      "Ep 61: Batch #51 - Loss: 0.8176836371421814\n",
      "Ep 61: Batch #52 - Loss: 0.676281213760376\n",
      "Ep 61: Batch #53 - Loss: 0.7156541347503662\n",
      "Ep 61: Batch #54 - Loss: 0.5781935453414917\n",
      "Ep 61: Batch #55 - Loss: 0.6099714040756226\n",
      "Ep 61: Batch #56 - Loss: 0.8578616976737976\n",
      "Ep 61: Batch #57 - Loss: 0.6825398206710815\n",
      "Ep 61: Batch #58 - Loss: 0.8270934820175171\n",
      "Ep 61: Batch #59 - Loss: 0.5585830211639404\n",
      "Ep 61: Batch #60 - Loss: 1.0086137056350708\n",
      "Ep 61: Batch #61 - Loss: 0.5353904366493225\n",
      "Ep 61: Batch #62 - Loss: 0.5744557976722717\n",
      "Ep 61: Batch #63 - Loss: 0.7810840010643005\n",
      "Ep 61: Batch #64 - Loss: 8.28996467590332\n",
      "Ep 61: Batch #65 - Loss: 0.524613618850708\n",
      "Ep 61: Batch #66 - Loss: 0.6646530032157898\n",
      "Ep 61: Batch #67 - Loss: 0.7758359313011169\n",
      "Ep 61: Batch #68 - Loss: 0.7133139967918396\n",
      "Ep 61: Batch #69 - Loss: 0.5876337289810181\n",
      "Ep 61: Batch #70 - Loss: 0.6155522465705872\n",
      "Ep 61: Batch #71 - Loss: 0.5360608100891113\n",
      "Ep 61: Batch #72 - Loss: 0.6628050804138184\n",
      "Ep 61: Batch #73 - Loss: 0.7213752269744873\n",
      "Ep 61: Batch #74 - Loss: 0.5771996974945068\n",
      "Ep 61: Batch #75 - Loss: 0.6673282980918884\n",
      "Ep 61: Batch #76 - Loss: 0.9253054857254028\n",
      "Ep 61: Batch #77 - Loss: 0.5754626989364624\n",
      "Ep 61: Batch #78 - Loss: 0.9198002815246582\n",
      "Ep 61: Batch #79 - Loss: 0.525811493396759\n",
      "Ep 61: Batch #80 - Loss: 0.6926485300064087\n",
      "Ep 61: Batch #81 - Loss: 1.5294585227966309\n",
      "Ep 61: Batch #82 - Loss: 0.7519151568412781\n",
      "Ep 61: Batch #83 - Loss: 1.2481160163879395\n",
      "Ep 61: Batch #84 - Loss: 0.5779284238815308\n",
      "Ep 61: Batch #85 - Loss: 0.78602135181427\n",
      "Ep 61: Batch #86 - Loss: 0.5482400059700012\n",
      "Ep 61: Batch #87 - Loss: 0.5723406672477722\n",
      "Ep 61: Batch #88 - Loss: 0.6570147275924683\n",
      "Ep 61: Batch #89 - Loss: 0.7284983992576599\n",
      "Ep 61: Batch #90 - Loss: 0.9012598991394043\n",
      "Ep 61: Batch #91 - Loss: 0.6497973799705505\n",
      "Ep 61: Batch #92 - Loss: 0.7310672998428345\n",
      "Ep 61: Batch #93 - Loss: 0.7834531664848328\n",
      "Ep 61: Batch #94 - Loss: 0.746576189994812\n",
      "Ep 61: Batch #95 - Loss: 0.7611138820648193\n",
      "Ep 61: Batch #96 - Loss: 0.7612888813018799\n",
      "Ep 61: Batch #97 - Loss: 0.5871017575263977\n",
      "Ep 61: Batch #98 - Loss: 0.5783721208572388\n",
      "Ep 61: Batch #99 - Loss: 0.7950976490974426\n",
      "Ep 61: Batch #100 - Loss: 0.5579003095626831\n",
      "Ep 61: Batch #101 - Loss: 0.8679255247116089\n",
      "Ep 61: Batch #102 - Loss: 0.6129134893417358\n",
      "Ep 61: Batch #103 - Loss: 0.636267900466919\n",
      "Ep 61: Batch #104 - Loss: 0.6611999273300171\n",
      "Ep 61: Batch #105 - Loss: 0.816811203956604\n",
      "Ep 61: Batch #106 - Loss: 0.6260802745819092\n",
      "Ep 61: Batch #107 - Loss: 0.6153976321220398\n",
      "Ep 61: Batch #108 - Loss: 0.9013375639915466\n",
      "Ep 61: Batch #109 - Loss: 0.6271807551383972\n",
      "Ep 61: Batch #110 - Loss: 0.7256404161453247\n",
      "Ep 61: Batch #111 - Loss: 1.042220950126648\n",
      "Ep 61: Batch #112 - Loss: 0.794776201248169\n",
      "Ep 61: Batch #113 - Loss: 0.6575237512588501\n",
      "Ep 61: Batch #114 - Loss: 0.7267401814460754\n",
      "Ep 61: Batch #115 - Loss: 0.9090964198112488\n",
      "Ep 61: Batch #116 - Loss: 0.5217230916023254\n",
      "Ep 61: Batch #117 - Loss: 0.6788605451583862\n",
      "Ep 61: Batch #118 - Loss: 0.4549565613269806\n",
      "Model saved in file: ./weights_autoencoder_sigmoid/model_e61b118_1516648799.7432923.ckpt\n",
      "Ep 61: Batch #119 - Loss: 0.809027373790741\n",
      "Ep 61: Batch #120 - Loss: 0.6604259610176086\n",
      "Ep 61: Batch #121 - Loss: 0.561401903629303\n",
      "Ep 61: Batch #122 - Loss: 0.7101570963859558\n",
      "Ep 61: Batch #123 - Loss: 0.7168765068054199\n",
      "Ep 61: Batch #124 - Loss: 0.5568394064903259\n",
      "Ep 61: Batch #125 - Loss: 2.4716176986694336\n",
      "Ep 61: Batch #126 - Loss: 1.0033189058303833\n",
      "Ep 61: Batch #127 - Loss: 0.5824592113494873\n",
      "Ep 61: Batch #128 - Loss: 0.885630190372467\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 61: Batch #129 - Loss: 0.6779572367668152\n",
      "Ep 61: Batch #130 - Loss: 0.5955798625946045\n",
      "Ep 61: Batch #131 - Loss: 0.802961528301239\n",
      "Ep 61: Batch #132 - Loss: 0.6839427947998047\n",
      "Ep 61: Batch #133 - Loss: 0.667069673538208\n",
      "Ep 61: Batch #134 - Loss: 0.6367930769920349\n",
      "Ep 61: Batch #135 - Loss: 0.8215776085853577\n",
      "Ep 61: Batch #136 - Loss: 1.0423002243041992\n",
      "Ep 61: Batch #137 - Loss: 0.7543132305145264\n",
      "Ep 61: Batch #138 - Loss: 0.901178240776062\n",
      "Ep 61: Batch #139 - Loss: 0.6770117282867432\n",
      "Ep 61: Batch #140 - Loss: 0.8430977463722229\n",
      "Ep 61: Batch #141 - Loss: 1.1229358911514282\n",
      "Ep 61: Batch #142 - Loss: 0.6712994575500488\n",
      "Ep 61: Batch #143 - Loss: 0.7715436220169067\n",
      "Ep 61: Batch #144 - Loss: 0.6124841570854187\n",
      "Ep 61: Batch #145 - Loss: 0.5995587110519409\n",
      "Ep 61: Batch #146 - Loss: 0.6994934678077698\n",
      "Ep 61: Batch #147 - Loss: 0.6628753542900085\n",
      "Ep 61: Batch #148 - Loss: 0.753132164478302\n",
      "Ep 61: Batch #149 - Loss: 0.6163728833198547\n",
      "Ep 61: Batch #150 - Loss: 0.7204700112342834\n",
      "Ep 61: Batch #151 - Loss: 0.6271973252296448\n",
      "Ep 61: Batch #152 - Loss: 0.6073792576789856\n",
      "Ep 61: Batch #153 - Loss: 0.8261445760726929\n",
      "Ep 61: Batch #154 - Loss: 0.632268488407135\n",
      "Ep 61: Batch #155 - Loss: 0.691236138343811\n",
      "Ep 61: Batch #156 - Loss: 0.7817311882972717\n",
      "Ep 61: Batch #157 - Loss: 0.613145649433136\n",
      "Ep 61: Batch #158 - Loss: 0.7184056639671326\n",
      "Ep 61: Batch #159 - Loss: 0.597829282283783\n",
      "Ep 61: Batch #160 - Loss: 0.6941109895706177\n",
      "Ep 61: Batch #161 - Loss: 0.6694019436836243\n",
      "Ep 61: Batch #162 - Loss: 0.7180864214897156\n",
      "Ep 61: Batch #163 - Loss: 0.7598205804824829\n",
      "Ep 61: Batch #164 - Loss: 0.6477394700050354\n",
      "Ep 61: Batch #165 - Loss: 1.3392212390899658\n",
      "Ep 61: Batch #166 - Loss: 0.5343101620674133\n",
      "Ep 61: Batch #167 - Loss: 0.7128685712814331\n",
      "Ep 61: Batch #168 - Loss: 0.6928252577781677\n",
      "Ep 61: Batch #169 - Loss: 0.6673871278762817\n",
      "Ep 61: Batch #170 - Loss: 0.6278976202011108\n",
      "Ep 61: Batch #171 - Loss: 0.6401883959770203\n",
      "Ep 61: Batch #172 - Loss: 0.5341079235076904\n",
      "Ep 61: Batch #173 - Loss: 0.9294140338897705\n",
      "Ep 61: Batch #174 - Loss: 0.49523988366127014\n",
      "Ep 61: Batch #175 - Loss: 0.6352176666259766\n",
      "Ep 61: Batch #176 - Loss: 0.8973858952522278\n",
      "Ep 61: Batch #177 - Loss: 0.6502920985221863\n",
      "Ep 61: Batch #178 - Loss: 0.6230351328849792\n",
      "Ep 61: Batch #179 - Loss: 0.7468247413635254\n",
      "Ep 61: Batch #180 - Loss: 0.6502641439437866\n",
      "Ep 61: Batch #181 - Loss: 0.8016878962516785\n",
      "Ep 61: Batch #182 - Loss: 0.6278911232948303\n",
      "Ep 61: Batch #183 - Loss: 0.6058215498924255\n",
      "Ep 61: Batch #184 - Loss: 0.9202063679695129\n",
      "Ep 61: Batch #185 - Loss: 0.632941722869873\n",
      "Ep 61: Batch #186 - Loss: 0.7540091276168823\n",
      "Ep 61: Batch #187 - Loss: 0.8663344383239746\n",
      "Ep 61: Batch #188 - Loss: 0.9497585892677307\n",
      "Ep 61: Batch #189 - Loss: 0.5868202447891235\n",
      "Ep 61: Batch #190 - Loss: 0.6224811673164368\n",
      "Ep 61: Batch #191 - Loss: 0.8048144578933716\n",
      "Ep 61: Batch #192 - Loss: 0.5711690187454224\n",
      "Ep 61: Batch #193 - Loss: 0.6311237812042236\n",
      "Ep 61: Batch #194 - Loss: 0.543053388595581\n",
      "Ep 61: Batch #195 - Loss: 0.7859863042831421\n",
      "Ep 61: Batch #196 - Loss: 0.6929221153259277\n",
      "Ep 61: Batch #197 - Loss: 0.7006850242614746\n",
      "Ep 61: Batch #198 - Loss: 0.5339139699935913\n",
      "Ep 61: Batch #199 - Loss: 0.6438767313957214\n",
      "Ep 62: Batch #0 - Loss: 0.6514202952384949\n",
      "Ep 62: Batch #1 - Loss: 0.7162230014801025\n",
      "Ep 62: Batch #2 - Loss: 0.8602586984634399\n",
      "Ep 62: Batch #3 - Loss: 0.7217162251472473\n",
      "Ep 62: Batch #4 - Loss: 0.6573920845985413\n",
      "Ep 62: Batch #5 - Loss: 0.5539180040359497\n",
      "Ep 62: Batch #6 - Loss: 0.7356678247451782\n",
      "Ep 62: Batch #7 - Loss: 0.5760570764541626\n",
      "Ep 62: Batch #8 - Loss: 0.5857936143875122\n",
      "Ep 62: Batch #9 - Loss: 1.0941998958587646\n",
      "Ep 62: Batch #10 - Loss: 0.8016178607940674\n",
      "Ep 62: Batch #11 - Loss: 0.544520914554596\n",
      "Ep 62: Batch #12 - Loss: 1.2015658617019653\n",
      "Ep 62: Batch #13 - Loss: 0.5717940926551819\n",
      "Ep 62: Batch #14 - Loss: 0.5993502736091614\n",
      "Ep 62: Batch #15 - Loss: 0.8482368588447571\n",
      "Ep 62: Batch #16 - Loss: 0.9551510810852051\n",
      "Ep 62: Batch #17 - Loss: 0.7310015559196472\n",
      "Ep 62: Batch #18 - Loss: 0.808628261089325\n",
      "Ep 62: Batch #19 - Loss: 0.5641618967056274\n",
      "Ep 62: Batch #20 - Loss: 0.5468682050704956\n",
      "Ep 62: Batch #21 - Loss: 0.8118541836738586\n",
      "Ep 62: Batch #22 - Loss: 0.608462929725647\n",
      "Ep 62: Batch #23 - Loss: 0.6003428101539612\n",
      "Ep 62: Batch #24 - Loss: 0.6388826370239258\n",
      "Ep 62: Batch #25 - Loss: 0.606631875038147\n",
      "Ep 62: Batch #26 - Loss: 0.5569210052490234\n",
      "Ep 62: Batch #27 - Loss: 1.1416857242584229\n",
      "Ep 62: Batch #28 - Loss: 0.6922164559364319\n",
      "Ep 62: Batch #29 - Loss: 0.7540562152862549\n",
      "Ep 62: Batch #30 - Loss: 0.8280914425849915\n",
      "Ep 62: Batch #31 - Loss: 0.5616167783737183\n",
      "Ep 62: Batch #32 - Loss: 0.5814281702041626\n",
      "Ep 62: Batch #33 - Loss: 0.666995644569397\n",
      "Ep 62: Batch #34 - Loss: 0.6377368569374084\n",
      "Ep 62: Batch #35 - Loss: 0.7242156267166138\n",
      "Ep 62: Batch #36 - Loss: 0.584865927696228\n",
      "Ep 62: Batch #37 - Loss: 0.9212701320648193\n",
      "Ep 62: Batch #38 - Loss: 0.5688651204109192\n",
      "Ep 62: Batch #39 - Loss: 0.6869701147079468\n",
      "Ep 62: Batch #40 - Loss: 0.6044874787330627\n",
      "Ep 62: Batch #41 - Loss: 0.6200088262557983\n",
      "Ep 62: Batch #42 - Loss: 0.5704655051231384\n",
      "Ep 62: Batch #43 - Loss: 0.6323689818382263\n",
      "Ep 62: Batch #44 - Loss: 0.6137091517448425\n",
      "Ep 62: Batch #45 - Loss: 0.5248229503631592\n",
      "Ep 62: Batch #46 - Loss: 0.6973492503166199\n",
      "Ep 62: Batch #47 - Loss: 0.8044321537017822\n",
      "Ep 62: Batch #48 - Loss: 1.042074203491211\n",
      "Ep 62: Batch #49 - Loss: 0.8124663829803467\n",
      "Ep 62: Batch #50 - Loss: 0.5739583969116211\n",
      "Ep 62: Batch #51 - Loss: 0.8175147175788879\n",
      "Ep 62: Batch #52 - Loss: 0.6763737797737122\n",
      "Ep 62: Batch #53 - Loss: 0.715587854385376\n",
      "Ep 62: Batch #54 - Loss: 0.5783397555351257\n",
      "Ep 62: Batch #55 - Loss: 0.6094494462013245\n",
      "Ep 62: Batch #56 - Loss: 0.8579211235046387\n",
      "Ep 62: Batch #57 - Loss: 0.6827055215835571\n",
      "Ep 62: Batch #58 - Loss: 0.8275421857833862\n",
      "Ep 62: Batch #59 - Loss: 0.5584307312965393\n",
      "Ep 62: Batch #60 - Loss: 1.008401870727539\n",
      "Ep 62: Batch #61 - Loss: 0.5354838967323303\n",
      "Ep 62: Batch #62 - Loss: 0.5744303464889526\n",
      "Ep 62: Batch #63 - Loss: 0.7808697819709778\n",
      "Ep 62: Batch #64 - Loss: 8.27763557434082\n",
      "Ep 62: Batch #65 - Loss: 0.5243960022926331\n",
      "Ep 62: Batch #66 - Loss: 0.6645811200141907\n",
      "Ep 62: Batch #67 - Loss: 0.7758073210716248\n",
      "Ep 62: Batch #68 - Loss: 0.7133357524871826\n",
      "Ep 62: Batch #69 - Loss: 0.5876845121383667\n",
      "Ep 62: Batch #70 - Loss: 0.6158952713012695\n",
      "Ep 62: Batch #71 - Loss: 0.5359090566635132\n",
      "Ep 62: Batch #72 - Loss: 0.6628841757774353\n",
      "Ep 62: Batch #73 - Loss: 0.7212021946907043\n",
      "Ep 62: Batch #74 - Loss: 0.577177882194519\n",
      "Ep 62: Batch #75 - Loss: 0.6672811508178711\n",
      "Ep 62: Batch #76 - Loss: 0.9252786636352539\n",
      "Ep 62: Batch #77 - Loss: 0.5757163763046265\n",
      "Ep 62: Batch #78 - Loss: 0.9194498062133789\n",
      "Ep 62: Batch #79 - Loss: 0.525814950466156\n",
      "Ep 62: Batch #80 - Loss: 0.69247967004776\n",
      "Ep 62: Batch #81 - Loss: 1.523558497428894\n",
      "Ep 62: Batch #82 - Loss: 0.7520931363105774\n",
      "Ep 62: Batch #83 - Loss: 1.2453147172927856\n",
      "Ep 62: Batch #84 - Loss: 0.5781158804893494\n",
      "Ep 62: Batch #85 - Loss: 0.7860817909240723\n",
      "Ep 62: Batch #86 - Loss: 0.5482296943664551\n",
      "Ep 62: Batch #87 - Loss: 0.5723447203636169\n",
      "Ep 62: Batch #88 - Loss: 0.6569329500198364\n",
      "Ep 62: Batch #89 - Loss: 0.7282033562660217\n",
      "Ep 62: Batch #90 - Loss: 0.9012526273727417\n",
      "Ep 62: Batch #91 - Loss: 0.6496924757957458\n",
      "Ep 62: Batch #92 - Loss: 0.7310082316398621\n",
      "Ep 62: Batch #93 - Loss: 0.7831010818481445\n",
      "Ep 62: Batch #94 - Loss: 0.7467294335365295\n",
      "Ep 62: Batch #95 - Loss: 0.7610616087913513\n",
      "Ep 62: Batch #96 - Loss: 0.7611297965049744\n",
      "Ep 62: Batch #97 - Loss: 0.5865833163261414\n",
      "Ep 62: Batch #98 - Loss: 0.5777449011802673\n",
      "Ep 62: Batch #99 - Loss: 0.7940737009048462\n",
      "Ep 62: Batch #100 - Loss: 0.5576526522636414\n",
      "Ep 62: Batch #101 - Loss: 0.8680005669593811\n",
      "Ep 62: Batch #102 - Loss: 0.6129031181335449\n",
      "Ep 62: Batch #103 - Loss: 0.6361626386642456\n",
      "Ep 62: Batch #104 - Loss: 0.6615135073661804\n",
      "Ep 62: Batch #105 - Loss: 0.817113995552063\n",
      "Ep 62: Batch #106 - Loss: 0.626221776008606\n",
      "Ep 62: Batch #107 - Loss: 0.6154916286468506\n",
      "Ep 62: Batch #108 - Loss: 0.9007902145385742\n",
      "Ep 62: Batch #109 - Loss: 0.6273736953735352\n",
      "Ep 62: Batch #110 - Loss: 0.7260200381278992\n",
      "Ep 62: Batch #111 - Loss: 1.0423516035079956\n",
      "Ep 62: Batch #112 - Loss: 0.7942012548446655\n",
      "Ep 62: Batch #113 - Loss: 0.6575111150741577\n",
      "Ep 62: Batch #114 - Loss: 0.726459264755249\n",
      "Ep 62: Batch #115 - Loss: 0.9089363217353821\n",
      "Ep 62: Batch #116 - Loss: 0.5218969583511353\n",
      "Ep 62: Batch #117 - Loss: 0.6788235306739807\n",
      "Ep 62: Batch #118 - Loss: 0.4548024833202362\n",
      "Model saved in file: ./weights_autoencoder_sigmoid/model_e62b118_1516648799.8811343.ckpt\n",
      "Ep 62: Batch #119 - Loss: 0.8084094524383545\n",
      "Ep 62: Batch #120 - Loss: 0.6598033308982849\n",
      "Ep 62: Batch #121 - Loss: 0.5615394115447998\n",
      "Ep 62: Batch #122 - Loss: 0.7100098729133606\n",
      "Ep 62: Batch #123 - Loss: 0.7166270613670349\n",
      "Ep 62: Batch #124 - Loss: 0.5566533207893372\n",
      "Ep 62: Batch #125 - Loss: 2.4723126888275146\n",
      "Ep 62: Batch #126 - Loss: 1.00343918800354\n",
      "Ep 62: Batch #127 - Loss: 0.5825462341308594\n",
      "Ep 62: Batch #128 - Loss: 0.8854578733444214\n",
      "Ep 62: Batch #129 - Loss: 0.6779822111129761\n",
      "Ep 62: Batch #130 - Loss: 0.5955839157104492\n",
      "Ep 62: Batch #131 - Loss: 0.8030577301979065\n",
      "Ep 62: Batch #132 - Loss: 0.6838899254798889\n",
      "Ep 62: Batch #133 - Loss: 0.6668879985809326\n",
      "Ep 62: Batch #134 - Loss: 0.6367892026901245\n",
      "Ep 62: Batch #135 - Loss: 0.8215822577476501\n",
      "Ep 62: Batch #136 - Loss: 1.0427430868148804\n",
      "Ep 62: Batch #137 - Loss: 0.7547764182090759\n",
      "Ep 62: Batch #138 - Loss: 0.9014122486114502\n",
      "Ep 62: Batch #139 - Loss: 0.6757809519767761\n",
      "Ep 62: Batch #140 - Loss: 0.843007504940033\n",
      "Ep 62: Batch #141 - Loss: 1.122632384300232\n",
      "Ep 62: Batch #142 - Loss: 0.671675443649292\n",
      "Ep 62: Batch #143 - Loss: 0.7716116309165955\n",
      "Ep 62: Batch #144 - Loss: 0.612581729888916\n",
      "Ep 62: Batch #145 - Loss: 0.5996353626251221\n",
      "Ep 62: Batch #146 - Loss: 0.6992464065551758\n",
      "Ep 62: Batch #147 - Loss: 0.6627041101455688\n",
      "Ep 62: Batch #148 - Loss: 0.7533475756645203\n",
      "Ep 62: Batch #149 - Loss: 0.6159009337425232\n",
      "Ep 62: Batch #150 - Loss: 0.720363438129425\n",
      "Ep 62: Batch #151 - Loss: 0.6269609332084656\n",
      "Ep 62: Batch #152 - Loss: 0.6072590947151184\n",
      "Ep 62: Batch #153 - Loss: 0.8261967897415161\n",
      "Ep 62: Batch #154 - Loss: 0.6327990889549255\n",
      "Ep 62: Batch #155 - Loss: 0.6911704540252686\n",
      "Ep 62: Batch #156 - Loss: 0.7812493443489075\n",
      "Ep 62: Batch #157 - Loss: 0.6130797863006592\n",
      "Ep 62: Batch #158 - Loss: 0.7183769345283508\n",
      "Ep 62: Batch #159 - Loss: 0.5974916815757751\n",
      "Ep 62: Batch #160 - Loss: 0.693869948387146\n",
      "Ep 62: Batch #161 - Loss: 0.6692118048667908\n",
      "Ep 62: Batch #162 - Loss: 0.7180479764938354\n",
      "Ep 62: Batch #163 - Loss: 0.7597243785858154\n",
      "Ep 62: Batch #164 - Loss: 0.6476888656616211\n",
      "Ep 62: Batch #165 - Loss: 1.3388293981552124\n",
      "Ep 62: Batch #166 - Loss: 0.5343138575553894\n",
      "Ep 62: Batch #167 - Loss: 0.711679220199585\n",
      "Ep 62: Batch #168 - Loss: 0.6928632259368896\n",
      "Ep 62: Batch #169 - Loss: 0.6670860648155212\n",
      "Ep 62: Batch #170 - Loss: 0.6277280449867249\n",
      "Ep 62: Batch #171 - Loss: 0.6401442289352417\n",
      "Ep 62: Batch #172 - Loss: 0.5342639684677124\n",
      "Ep 62: Batch #173 - Loss: 0.9287126660346985\n",
      "Ep 62: Batch #174 - Loss: 0.4953363239765167\n",
      "Ep 62: Batch #175 - Loss: 0.6356241106987\n",
      "Ep 62: Batch #176 - Loss: 0.8971065282821655\n",
      "Ep 62: Batch #177 - Loss: 0.6498546600341797\n",
      "Ep 62: Batch #178 - Loss: 0.6230801939964294\n",
      "Ep 62: Batch #179 - Loss: 0.7464302182197571\n",
      "Ep 62: Batch #180 - Loss: 0.6503192186355591\n",
      "Ep 62: Batch #181 - Loss: 0.8017546534538269\n",
      "Ep 62: Batch #182 - Loss: 0.6278422474861145\n",
      "Ep 62: Batch #183 - Loss: 0.6058680415153503\n",
      "Ep 62: Batch #184 - Loss: 0.9202802181243896\n",
      "Ep 62: Batch #185 - Loss: 0.6329872012138367\n",
      "Ep 62: Batch #186 - Loss: 0.7533934116363525\n",
      "Ep 62: Batch #187 - Loss: 0.8662293553352356\n",
      "Ep 62: Batch #188 - Loss: 0.9488223195075989\n",
      "Ep 62: Batch #189 - Loss: 0.5868861675262451\n",
      "Ep 62: Batch #190 - Loss: 0.6224081516265869\n",
      "Ep 62: Batch #191 - Loss: 0.8050519227981567\n",
      "Ep 62: Batch #192 - Loss: 0.5713993310928345\n",
      "Ep 62: Batch #193 - Loss: 0.6311636567115784\n",
      "Ep 62: Batch #194 - Loss: 0.5430523157119751\n",
      "Ep 62: Batch #195 - Loss: 0.7855109572410583\n",
      "Ep 62: Batch #196 - Loss: 0.6930676698684692\n",
      "Ep 62: Batch #197 - Loss: 0.7006585597991943\n",
      "Ep 62: Batch #198 - Loss: 0.5338701009750366\n",
      "Ep 62: Batch #199 - Loss: 0.6439176797866821\n",
      "Ep 63: Batch #0 - Loss: 0.6515325903892517\n",
      "Ep 63: Batch #1 - Loss: 0.7165234088897705\n",
      "Ep 63: Batch #2 - Loss: 0.8602089285850525\n",
      "Ep 63: Batch #3 - Loss: 0.7221434116363525\n",
      "Ep 63: Batch #4 - Loss: 0.6573805809020996\n",
      "Ep 63: Batch #5 - Loss: 0.5536916851997375\n",
      "Ep 63: Batch #6 - Loss: 0.7353966236114502\n",
      "Ep 63: Batch #7 - Loss: 0.5761398077011108\n",
      "Ep 63: Batch #8 - Loss: 0.585719108581543\n",
      "Ep 63: Batch #9 - Loss: 1.0947456359863281\n",
      "Ep 63: Batch #10 - Loss: 0.8008490800857544\n",
      "Ep 63: Batch #11 - Loss: 0.5445640683174133\n",
      "Ep 63: Batch #12 - Loss: 1.20096755027771\n",
      "Ep 63: Batch #13 - Loss: 0.5717900991439819\n",
      "Ep 63: Batch #14 - Loss: 0.5993640422821045\n",
      "Ep 63: Batch #15 - Loss: 0.8475337028503418\n",
      "Ep 63: Batch #16 - Loss: 0.9555181860923767\n",
      "Ep 63: Batch #17 - Loss: 0.7309601902961731\n",
      "Ep 63: Batch #18 - Loss: 0.8088207840919495\n",
      "Ep 63: Batch #19 - Loss: 0.5640693306922913\n",
      "Ep 63: Batch #20 - Loss: 0.5469479560852051\n",
      "Ep 63: Batch #21 - Loss: 0.8103640675544739\n",
      "Ep 63: Batch #22 - Loss: 0.6086742281913757\n",
      "Ep 63: Batch #23 - Loss: 0.6006189584732056\n",
      "Ep 63: Batch #24 - Loss: 0.6389817595481873\n",
      "Ep 63: Batch #25 - Loss: 0.6066957712173462\n",
      "Ep 63: Batch #26 - Loss: 0.5567442774772644\n",
      "Ep 63: Batch #27 - Loss: 1.1413062810897827\n",
      "Ep 63: Batch #28 - Loss: 0.692434549331665\n",
      "Ep 63: Batch #29 - Loss: 0.7542721629142761\n",
      "Ep 63: Batch #30 - Loss: 0.8272621035575867\n",
      "Ep 63: Batch #31 - Loss: 0.5618387460708618\n",
      "Ep 63: Batch #32 - Loss: 0.5813725590705872\n",
      "Ep 63: Batch #33 - Loss: 0.6671491265296936\n",
      "Ep 63: Batch #34 - Loss: 0.6376041769981384\n",
      "Ep 63: Batch #35 - Loss: 0.7243196964263916\n",
      "Ep 63: Batch #36 - Loss: 0.5850366950035095\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 63: Batch #37 - Loss: 0.9213678240776062\n",
      "Ep 63: Batch #38 - Loss: 0.5688146352767944\n",
      "Ep 63: Batch #39 - Loss: 0.6869013905525208\n",
      "Ep 63: Batch #40 - Loss: 0.6045383214950562\n",
      "Ep 63: Batch #41 - Loss: 0.6201449632644653\n",
      "Ep 63: Batch #42 - Loss: 0.5705767273902893\n",
      "Ep 63: Batch #43 - Loss: 0.6325737833976746\n",
      "Ep 63: Batch #44 - Loss: 0.613613486289978\n",
      "Ep 63: Batch #45 - Loss: 0.5248217582702637\n",
      "Ep 63: Batch #46 - Loss: 0.6973713636398315\n",
      "Ep 63: Batch #47 - Loss: 0.804267942905426\n",
      "Ep 63: Batch #48 - Loss: 1.0416374206542969\n",
      "Ep 63: Batch #49 - Loss: 0.8123818635940552\n",
      "Ep 63: Batch #50 - Loss: 0.5739020109176636\n",
      "Ep 63: Batch #51 - Loss: 0.8173286318778992\n",
      "Ep 63: Batch #52 - Loss: 0.6761743426322937\n",
      "Ep 63: Batch #53 - Loss: 0.7154703140258789\n",
      "Ep 63: Batch #54 - Loss: 0.5782848596572876\n",
      "Ep 63: Batch #55 - Loss: 0.6102876663208008\n",
      "Ep 63: Batch #56 - Loss: 0.857884407043457\n",
      "Ep 63: Batch #57 - Loss: 0.6825450658798218\n",
      "Ep 63: Batch #58 - Loss: 0.827049970626831\n",
      "Ep 63: Batch #59 - Loss: 0.5583434104919434\n",
      "Ep 63: Batch #60 - Loss: 1.0084540843963623\n",
      "Ep 63: Batch #61 - Loss: 0.5353241562843323\n",
      "Ep 63: Batch #62 - Loss: 0.5744933485984802\n",
      "Ep 63: Batch #63 - Loss: 0.7807420492172241\n",
      "Ep 63: Batch #64 - Loss: 8.26232624053955\n",
      "Ep 63: Batch #65 - Loss: 0.5243043899536133\n",
      "Ep 63: Batch #66 - Loss: 0.6647794842720032\n",
      "Ep 63: Batch #67 - Loss: 0.7758833765983582\n",
      "Ep 63: Batch #68 - Loss: 0.7133151292800903\n",
      "Ep 63: Batch #69 - Loss: 0.5875092148780823\n",
      "Ep 63: Batch #70 - Loss: 0.615236759185791\n",
      "Ep 63: Batch #71 - Loss: 0.5359565615653992\n",
      "Ep 63: Batch #72 - Loss: 0.6626466512680054\n",
      "Ep 63: Batch #73 - Loss: 0.7211015224456787\n",
      "Ep 63: Batch #74 - Loss: 0.5770032405853271\n",
      "Ep 63: Batch #75 - Loss: 0.6671686172485352\n",
      "Ep 63: Batch #76 - Loss: 0.9250692129135132\n",
      "Ep 63: Batch #77 - Loss: 0.575589120388031\n",
      "Ep 63: Batch #78 - Loss: 0.9191977977752686\n",
      "Ep 63: Batch #79 - Loss: 0.5255067944526672\n",
      "Ep 63: Batch #80 - Loss: 0.6922990679740906\n",
      "Ep 63: Batch #81 - Loss: 1.5233429670333862\n",
      "Ep 63: Batch #82 - Loss: 0.7524625062942505\n",
      "Ep 63: Batch #83 - Loss: 1.2424709796905518\n",
      "Ep 63: Batch #84 - Loss: 0.5777998566627502\n",
      "Ep 63: Batch #85 - Loss: 0.7853822708129883\n",
      "Ep 63: Batch #86 - Loss: 0.5478809475898743\n",
      "Ep 63: Batch #87 - Loss: 0.5721638798713684\n",
      "Ep 63: Batch #88 - Loss: 0.657007098197937\n",
      "Ep 63: Batch #89 - Loss: 0.7281079888343811\n",
      "Ep 63: Batch #90 - Loss: 0.9013578295707703\n",
      "Ep 63: Batch #91 - Loss: 0.6496743559837341\n",
      "Ep 63: Batch #92 - Loss: 0.7306786179542542\n",
      "Ep 63: Batch #93 - Loss: 0.783064603805542\n",
      "Ep 63: Batch #94 - Loss: 0.7464065551757812\n",
      "Ep 63: Batch #95 - Loss: 0.7608598470687866\n",
      "Ep 63: Batch #96 - Loss: 0.7584042549133301\n",
      "Ep 63: Batch #97 - Loss: 0.5867613554000854\n",
      "Ep 63: Batch #98 - Loss: 0.5776825547218323\n",
      "Ep 63: Batch #99 - Loss: 0.7942162156105042\n",
      "Ep 63: Batch #100 - Loss: 0.5576579570770264\n",
      "Ep 63: Batch #101 - Loss: 0.8683943152427673\n",
      "Ep 63: Batch #102 - Loss: 0.6123816967010498\n",
      "Ep 63: Batch #103 - Loss: 0.635996401309967\n",
      "Ep 63: Batch #104 - Loss: 0.6612347364425659\n",
      "Ep 63: Batch #105 - Loss: 0.8172178864479065\n",
      "Ep 63: Batch #106 - Loss: 0.626068651676178\n",
      "Ep 63: Batch #107 - Loss: 0.6153258085250854\n",
      "Ep 63: Batch #108 - Loss: 0.9006909728050232\n",
      "Ep 63: Batch #109 - Loss: 0.6270526051521301\n",
      "Ep 63: Batch #110 - Loss: 0.7254302501678467\n",
      "Ep 63: Batch #111 - Loss: 1.0420066118240356\n",
      "Ep 63: Batch #112 - Loss: 0.7944759726524353\n",
      "Ep 63: Batch #113 - Loss: 0.6574646830558777\n",
      "Ep 63: Batch #114 - Loss: 0.7262791395187378\n",
      "Ep 63: Batch #115 - Loss: 0.9089771509170532\n",
      "Ep 63: Batch #116 - Loss: 0.5218453407287598\n",
      "Ep 63: Batch #117 - Loss: 0.6786688566207886\n",
      "Ep 63: Batch #118 - Loss: 0.4547724425792694\n",
      "Model saved in file: ./weights_autoencoder_sigmoid/model_e63b118_1516648800.0185537.ckpt\n",
      "Ep 63: Batch #119 - Loss: 0.8079988360404968\n",
      "Ep 63: Batch #120 - Loss: 0.6600290536880493\n",
      "Ep 63: Batch #121 - Loss: 0.5612843632698059\n",
      "Ep 63: Batch #122 - Loss: 0.7098110914230347\n",
      "Ep 63: Batch #123 - Loss: 0.7165018320083618\n",
      "Ep 63: Batch #124 - Loss: 0.5567319989204407\n",
      "Ep 63: Batch #125 - Loss: 2.4727542400360107\n",
      "Ep 63: Batch #126 - Loss: 1.0038161277770996\n",
      "Ep 63: Batch #127 - Loss: 0.5824804902076721\n",
      "Ep 63: Batch #128 - Loss: 0.8857921361923218\n",
      "Ep 63: Batch #129 - Loss: 0.6774321794509888\n",
      "Ep 63: Batch #130 - Loss: 0.595684289932251\n",
      "Ep 63: Batch #131 - Loss: 0.8031429648399353\n",
      "Ep 63: Batch #132 - Loss: 0.6839563250541687\n",
      "Ep 63: Batch #133 - Loss: 0.6668158769607544\n",
      "Ep 63: Batch #134 - Loss: 0.6367205381393433\n",
      "Ep 63: Batch #135 - Loss: 0.8218187689781189\n",
      "Ep 63: Batch #136 - Loss: 1.0426284074783325\n",
      "Ep 63: Batch #137 - Loss: 0.7550700306892395\n",
      "Ep 63: Batch #138 - Loss: 0.9014289379119873\n",
      "Ep 63: Batch #139 - Loss: 0.6764242053031921\n",
      "Ep 63: Batch #140 - Loss: 0.84261554479599\n",
      "Ep 63: Batch #141 - Loss: 1.122422456741333\n",
      "Ep 63: Batch #142 - Loss: 0.6718259453773499\n",
      "Ep 63: Batch #143 - Loss: 0.7716137170791626\n",
      "Ep 63: Batch #144 - Loss: 0.6124250888824463\n",
      "Ep 63: Batch #145 - Loss: 0.5994491577148438\n",
      "Ep 63: Batch #146 - Loss: 0.6991053223609924\n",
      "Ep 63: Batch #147 - Loss: 0.6626406311988831\n",
      "Ep 63: Batch #148 - Loss: 0.7533398270606995\n",
      "Ep 63: Batch #149 - Loss: 0.61611407995224\n",
      "Ep 63: Batch #150 - Loss: 0.7204641699790955\n",
      "Ep 63: Batch #151 - Loss: 0.6269208192825317\n",
      "Ep 63: Batch #152 - Loss: 0.6072388887405396\n",
      "Ep 63: Batch #153 - Loss: 0.8259418606758118\n",
      "Ep 63: Batch #154 - Loss: 0.6320282816886902\n",
      "Ep 63: Batch #155 - Loss: 0.6908804774284363\n",
      "Ep 63: Batch #156 - Loss: 0.7812733054161072\n",
      "Ep 63: Batch #157 - Loss: 0.6129052639007568\n",
      "Ep 63: Batch #158 - Loss: 0.7182852029800415\n",
      "Ep 63: Batch #159 - Loss: 0.5974850654602051\n",
      "Ep 63: Batch #160 - Loss: 0.6935551762580872\n",
      "Ep 63: Batch #161 - Loss: 0.6690992116928101\n",
      "Ep 63: Batch #162 - Loss: 0.7182173132896423\n",
      "Ep 63: Batch #163 - Loss: 0.7598305344581604\n",
      "Ep 63: Batch #164 - Loss: 0.6477380394935608\n",
      "Ep 63: Batch #165 - Loss: 1.3391352891921997\n",
      "Ep 63: Batch #166 - Loss: 0.534270703792572\n",
      "Ep 63: Batch #167 - Loss: 0.7112948894500732\n",
      "Ep 63: Batch #168 - Loss: 0.6928017735481262\n",
      "Ep 63: Batch #169 - Loss: 0.6668006777763367\n",
      "Ep 63: Batch #170 - Loss: 0.6277302503585815\n",
      "Ep 63: Batch #171 - Loss: 0.6405267119407654\n",
      "Ep 63: Batch #172 - Loss: 0.5340288877487183\n",
      "Ep 63: Batch #173 - Loss: 0.9294426441192627\n",
      "Ep 63: Batch #174 - Loss: 0.494954913854599\n",
      "Ep 63: Batch #175 - Loss: 0.6349638104438782\n",
      "Ep 63: Batch #176 - Loss: 0.897487223148346\n",
      "Ep 63: Batch #177 - Loss: 0.649757444858551\n",
      "Ep 63: Batch #178 - Loss: 0.622812807559967\n",
      "Ep 63: Batch #179 - Loss: 0.7458882927894592\n",
      "Ep 63: Batch #180 - Loss: 0.6500380635261536\n",
      "Ep 63: Batch #181 - Loss: 0.8017598390579224\n",
      "Ep 63: Batch #182 - Loss: 0.6282179951667786\n",
      "Ep 63: Batch #183 - Loss: 0.6059848070144653\n",
      "Ep 63: Batch #184 - Loss: 0.920150101184845\n",
      "Ep 63: Batch #185 - Loss: 0.6331764459609985\n",
      "Ep 63: Batch #186 - Loss: 0.7532666921615601\n",
      "Ep 63: Batch #187 - Loss: 0.866547703742981\n",
      "Ep 63: Batch #188 - Loss: 0.9472526907920837\n",
      "Ep 63: Batch #189 - Loss: 0.5870052576065063\n",
      "Ep 63: Batch #190 - Loss: 0.6220313906669617\n",
      "Ep 63: Batch #191 - Loss: 0.8040563464164734\n",
      "Ep 63: Batch #192 - Loss: 0.5710675120353699\n",
      "Ep 63: Batch #193 - Loss: 0.6311298608779907\n",
      "Ep 63: Batch #194 - Loss: 0.5428125858306885\n",
      "Ep 63: Batch #195 - Loss: 0.78515625\n",
      "Ep 63: Batch #196 - Loss: 0.6928550004959106\n",
      "Ep 63: Batch #197 - Loss: 0.7004485726356506\n",
      "Ep 63: Batch #198 - Loss: 0.5338770151138306\n",
      "Ep 63: Batch #199 - Loss: 0.6436915397644043\n",
      "Ep 64: Batch #0 - Loss: 0.651462733745575\n",
      "Ep 64: Batch #1 - Loss: 0.7162835597991943\n",
      "Ep 64: Batch #2 - Loss: 0.8606000542640686\n",
      "Ep 64: Batch #3 - Loss: 0.7216611504554749\n",
      "Ep 64: Batch #4 - Loss: 0.6573918461799622\n",
      "Ep 64: Batch #5 - Loss: 0.5537323951721191\n",
      "Ep 64: Batch #6 - Loss: 0.7352778315544128\n",
      "Ep 64: Batch #7 - Loss: 0.5761183500289917\n",
      "Ep 64: Batch #8 - Loss: 0.5855515003204346\n",
      "Ep 64: Batch #9 - Loss: 1.093544840812683\n",
      "Ep 64: Batch #10 - Loss: 0.8000884652137756\n",
      "Ep 64: Batch #11 - Loss: 0.5444189310073853\n",
      "Ep 64: Batch #12 - Loss: 1.2005375623703003\n",
      "Ep 64: Batch #13 - Loss: 0.5717466473579407\n",
      "Ep 64: Batch #14 - Loss: 0.59911048412323\n",
      "Ep 64: Batch #15 - Loss: 0.8472810387611389\n",
      "Ep 64: Batch #16 - Loss: 0.9550968408584595\n",
      "Ep 64: Batch #17 - Loss: 0.7311614155769348\n",
      "Ep 64: Batch #18 - Loss: 0.8088433742523193\n",
      "Ep 64: Batch #19 - Loss: 0.5641600489616394\n",
      "Ep 64: Batch #20 - Loss: 0.5466997027397156\n",
      "Ep 64: Batch #21 - Loss: 0.8098463416099548\n",
      "Ep 64: Batch #22 - Loss: 0.6082433462142944\n",
      "Ep 64: Batch #23 - Loss: 0.6003133058547974\n",
      "Ep 64: Batch #24 - Loss: 0.6389638781547546\n",
      "Ep 64: Batch #25 - Loss: 0.6066448092460632\n",
      "Ep 64: Batch #26 - Loss: 0.5566974878311157\n",
      "Ep 64: Batch #27 - Loss: 1.1411018371582031\n",
      "Ep 64: Batch #28 - Loss: 0.6925311088562012\n",
      "Ep 64: Batch #29 - Loss: 0.7538608908653259\n",
      "Ep 64: Batch #30 - Loss: 0.8267771601676941\n",
      "Ep 64: Batch #31 - Loss: 0.5616891980171204\n",
      "Ep 64: Batch #32 - Loss: 0.5813784003257751\n",
      "Ep 64: Batch #33 - Loss: 0.6670737862586975\n",
      "Ep 64: Batch #34 - Loss: 0.6374781131744385\n",
      "Ep 64: Batch #35 - Loss: 0.7241105437278748\n",
      "Ep 64: Batch #36 - Loss: 0.5847446322441101\n",
      "Ep 64: Batch #37 - Loss: 0.9212371110916138\n",
      "Ep 64: Batch #38 - Loss: 0.5687961578369141\n",
      "Ep 64: Batch #39 - Loss: 0.686800479888916\n",
      "Ep 64: Batch #40 - Loss: 0.6045866012573242\n",
      "Ep 64: Batch #41 - Loss: 0.6198914051055908\n",
      "Ep 64: Batch #42 - Loss: 0.5704348683357239\n",
      "Ep 64: Batch #43 - Loss: 0.6326126456260681\n",
      "Ep 64: Batch #44 - Loss: 0.6135059595108032\n",
      "Ep 64: Batch #45 - Loss: 0.5247246026992798\n",
      "Ep 64: Batch #46 - Loss: 0.6973960399627686\n",
      "Ep 64: Batch #47 - Loss: 0.8042678833007812\n",
      "Ep 64: Batch #48 - Loss: 1.0424875020980835\n",
      "Ep 64: Batch #49 - Loss: 0.8120355010032654\n",
      "Ep 64: Batch #50 - Loss: 0.574105441570282\n",
      "Ep 64: Batch #51 - Loss: 0.8175492286682129\n",
      "Ep 64: Batch #52 - Loss: 0.676304280757904\n",
      "Ep 64: Batch #53 - Loss: 0.7152420878410339\n",
      "Ep 64: Batch #54 - Loss: 0.578325629234314\n",
      "Ep 64: Batch #55 - Loss: 0.6103636622428894\n",
      "Ep 64: Batch #56 - Loss: 0.8578717112541199\n",
      "Ep 64: Batch #57 - Loss: 0.6825805902481079\n",
      "Ep 64: Batch #58 - Loss: 0.8275600671768188\n",
      "Ep 64: Batch #59 - Loss: 0.5582506656646729\n",
      "Ep 64: Batch #60 - Loss: 1.0082746744155884\n",
      "Ep 64: Batch #61 - Loss: 0.535323977470398\n",
      "Ep 64: Batch #62 - Loss: 0.5745651125907898\n",
      "Ep 64: Batch #63 - Loss: 0.7805742025375366\n",
      "Ep 64: Batch #64 - Loss: 8.250038146972656\n",
      "Ep 64: Batch #65 - Loss: 0.524183452129364\n",
      "Ep 64: Batch #66 - Loss: 0.6648097038269043\n",
      "Ep 64: Batch #67 - Loss: 0.7758947610855103\n",
      "Ep 64: Batch #68 - Loss: 0.7132465243339539\n",
      "Ep 64: Batch #69 - Loss: 0.5874987244606018\n",
      "Ep 64: Batch #70 - Loss: 0.6153656840324402\n",
      "Ep 64: Batch #71 - Loss: 0.5358783602714539\n",
      "Ep 64: Batch #72 - Loss: 0.6627574563026428\n",
      "Ep 64: Batch #73 - Loss: 0.7209463119506836\n",
      "Ep 64: Batch #74 - Loss: 0.5769187211990356\n",
      "Ep 64: Batch #75 - Loss: 0.6670235395431519\n",
      "Ep 64: Batch #76 - Loss: 0.9248262643814087\n",
      "Ep 64: Batch #77 - Loss: 0.5756847858428955\n",
      "Ep 64: Batch #78 - Loss: 0.9189172983169556\n",
      "Ep 64: Batch #79 - Loss: 0.5254719257354736\n",
      "Ep 64: Batch #80 - Loss: 0.6922242045402527\n",
      "Ep 64: Batch #81 - Loss: 1.5233978033065796\n",
      "Ep 64: Batch #82 - Loss: 0.7524716258049011\n",
      "Ep 64: Batch #83 - Loss: 1.239946961402893\n",
      "Ep 64: Batch #84 - Loss: 0.5781418085098267\n",
      "Ep 64: Batch #85 - Loss: 0.7856184840202332\n",
      "Ep 64: Batch #86 - Loss: 0.5483453273773193\n",
      "Ep 64: Batch #87 - Loss: 0.5724261403083801\n",
      "Ep 64: Batch #88 - Loss: 0.6574366688728333\n",
      "Ep 64: Batch #89 - Loss: 0.7283501625061035\n",
      "Ep 64: Batch #90 - Loss: 0.9015133380889893\n",
      "Ep 64: Batch #91 - Loss: 0.6497646570205688\n",
      "Ep 64: Batch #92 - Loss: 0.7308682203292847\n",
      "Ep 64: Batch #93 - Loss: 0.7831641435623169\n",
      "Ep 64: Batch #94 - Loss: 0.7470908164978027\n",
      "Ep 64: Batch #95 - Loss: 0.7612123489379883\n",
      "Ep 64: Batch #96 - Loss: 0.7599389553070068\n",
      "Ep 64: Batch #97 - Loss: 0.5869638323783875\n",
      "Ep 64: Batch #98 - Loss: 0.5782228112220764\n",
      "Ep 64: Batch #99 - Loss: 0.7952781915664673\n",
      "Ep 64: Batch #100 - Loss: 0.5575605630874634\n",
      "Ep 64: Batch #101 - Loss: 0.868478000164032\n",
      "Ep 64: Batch #102 - Loss: 0.6125807166099548\n",
      "Ep 64: Batch #103 - Loss: 0.6361840963363647\n",
      "Ep 64: Batch #104 - Loss: 0.6617506742477417\n",
      "Ep 64: Batch #105 - Loss: 0.8177151083946228\n",
      "Ep 64: Batch #106 - Loss: 0.6263413429260254\n",
      "Ep 64: Batch #107 - Loss: 0.6155109405517578\n",
      "Ep 64: Batch #108 - Loss: 0.900625467300415\n",
      "Ep 64: Batch #109 - Loss: 0.6275293231010437\n",
      "Ep 64: Batch #110 - Loss: 0.7262639403343201\n",
      "Ep 64: Batch #111 - Loss: 1.0421966314315796\n",
      "Ep 64: Batch #112 - Loss: 0.7936638593673706\n",
      "Ep 64: Batch #113 - Loss: 0.6575956344604492\n",
      "Ep 64: Batch #114 - Loss: 0.7263271808624268\n",
      "Ep 64: Batch #115 - Loss: 0.9089884757995605\n",
      "Ep 64: Batch #116 - Loss: 0.5219765305519104\n",
      "Ep 64: Batch #117 - Loss: 0.6788217425346375\n",
      "Ep 64: Batch #118 - Loss: 0.45478203892707825\n",
      "Ep 64: Batch #119 - Loss: 0.8080747723579407\n",
      "Ep 64: Batch #120 - Loss: 0.6596364378929138\n",
      "Ep 64: Batch #121 - Loss: 0.5616003274917603\n",
      "Ep 64: Batch #122 - Loss: 0.7100505828857422\n",
      "Ep 64: Batch #123 - Loss: 0.7165921330451965\n",
      "Ep 64: Batch #124 - Loss: 0.5570107102394104\n",
      "Ep 64: Batch #125 - Loss: 2.4736289978027344\n",
      "Ep 64: Batch #126 - Loss: 1.004628300666809\n",
      "Ep 64: Batch #127 - Loss: 0.5825698971748352\n",
      "Ep 64: Batch #128 - Loss: 0.8855049014091492\n",
      "Ep 64: Batch #129 - Loss: 0.6783028244972229\n",
      "Ep 64: Batch #130 - Loss: 0.595808207988739\n",
      "Ep 64: Batch #131 - Loss: 0.8035393953323364\n",
      "Ep 64: Batch #132 - Loss: 0.6837878823280334\n",
      "Ep 64: Batch #133 - Loss: 0.6668417453765869\n",
      "Ep 64: Batch #134 - Loss: 0.6368889212608337\n",
      "Ep 64: Batch #135 - Loss: 0.8220852613449097\n",
      "Ep 64: Batch #136 - Loss: 1.043610692024231\n",
      "Ep 64: Batch #137 - Loss: 0.7559682130813599\n",
      "Ep 64: Batch #138 - Loss: 0.9015532732009888\n",
      "Ep 64: Batch #139 - Loss: 0.6754295825958252\n",
      "Ep 64: Batch #140 - Loss: 0.8427820801734924\n",
      "Ep 64: Batch #141 - Loss: 1.1220207214355469\n",
      "Ep 64: Batch #142 - Loss: 0.6722255945205688\n",
      "Ep 64: Batch #143 - Loss: 0.7716661691665649\n",
      "Ep 64: Batch #144 - Loss: 0.6125074028968811\n",
      "Ep 64: Batch #145 - Loss: 0.5994552373886108\n",
      "Ep 64: Batch #146 - Loss: 0.6988852024078369\n",
      "Ep 64: Batch #147 - Loss: 0.6626572012901306\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 64: Batch #148 - Loss: 0.7535258531570435\n",
      "Ep 64: Batch #149 - Loss: 0.6152633428573608\n",
      "Ep 64: Batch #150 - Loss: 0.7204168438911438\n",
      "Ep 64: Batch #151 - Loss: 0.6268259286880493\n",
      "Ep 64: Batch #152 - Loss: 0.6072584390640259\n",
      "Ep 64: Batch #153 - Loss: 0.8260238170623779\n",
      "Ep 64: Batch #154 - Loss: 0.6323827505111694\n",
      "Ep 64: Batch #155 - Loss: 0.6910130977630615\n",
      "Ep 64: Batch #156 - Loss: 0.7804040908813477\n",
      "Ep 64: Batch #157 - Loss: 0.6129417419433594\n",
      "Ep 64: Batch #158 - Loss: 0.7182286381721497\n",
      "Ep 64: Batch #159 - Loss: 0.5972751379013062\n",
      "Ep 64: Batch #160 - Loss: 0.6932868957519531\n",
      "Ep 64: Batch #161 - Loss: 0.6691587567329407\n",
      "Ep 64: Batch #162 - Loss: 0.7182914018630981\n",
      "Ep 64: Batch #163 - Loss: 0.7596295475959778\n",
      "Ep 64: Batch #164 - Loss: 0.6476057171821594\n",
      "Ep 64: Batch #165 - Loss: 1.3387030363082886\n",
      "Ep 64: Batch #166 - Loss: 0.534361720085144\n",
      "Ep 64: Batch #167 - Loss: 0.7103301286697388\n",
      "Ep 64: Batch #168 - Loss: 0.6927323341369629\n",
      "Ep 64: Batch #169 - Loss: 0.6664102673530579\n",
      "Ep 64: Batch #170 - Loss: 0.6274349689483643\n",
      "Ep 64: Batch #171 - Loss: 0.6405999660491943\n",
      "Ep 64: Batch #172 - Loss: 0.5339749455451965\n",
      "Ep 64: Batch #173 - Loss: 0.9289621710777283\n",
      "Ep 64: Batch #174 - Loss: 0.4948505163192749\n",
      "Ep 64: Batch #175 - Loss: 0.6351161599159241\n",
      "Ep 64: Batch #176 - Loss: 0.8971917033195496\n",
      "Ep 64: Batch #177 - Loss: 0.6493049263954163\n",
      "Ep 64: Batch #178 - Loss: 0.6225072741508484\n",
      "Ep 64: Batch #179 - Loss: 0.7458758354187012\n",
      "Ep 64: Batch #180 - Loss: 0.6497806310653687\n",
      "Ep 64: Batch #181 - Loss: 0.8014634251594543\n",
      "Ep 64: Batch #182 - Loss: 0.628222644329071\n",
      "Ep 64: Batch #183 - Loss: 0.6058489084243774\n",
      "Ep 64: Batch #184 - Loss: 0.9201014637947083\n",
      "Ep 64: Batch #185 - Loss: 0.6331919431686401\n",
      "Ep 64: Batch #186 - Loss: 0.7525399923324585\n",
      "Ep 64: Batch #187 - Loss: 0.8663837313652039\n",
      "Ep 64: Batch #188 - Loss: 0.9461588859558105\n",
      "Ep 64: Batch #189 - Loss: 0.5869773626327515\n",
      "Ep 64: Batch #190 - Loss: 0.6220427751541138\n",
      "Ep 64: Batch #191 - Loss: 0.8038087487220764\n",
      "Ep 64: Batch #192 - Loss: 0.5713569521903992\n",
      "Ep 64: Batch #193 - Loss: 0.6311704516410828\n",
      "Ep 64: Batch #194 - Loss: 0.5427419543266296\n",
      "Ep 64: Batch #195 - Loss: 0.7852888703346252\n",
      "Ep 64: Batch #196 - Loss: 0.6928519010543823\n",
      "Ep 64: Batch #197 - Loss: 0.7003446221351624\n",
      "Ep 64: Batch #198 - Loss: 0.5338580012321472\n",
      "Ep 64: Batch #199 - Loss: 0.6437980532646179\n",
      "Ep 65: Batch #0 - Loss: 0.6514588594436646\n",
      "Ep 65: Batch #1 - Loss: 0.7162302136421204\n",
      "Ep 65: Batch #2 - Loss: 0.8607430458068848\n",
      "Ep 65: Batch #3 - Loss: 0.7219041585922241\n",
      "Ep 65: Batch #4 - Loss: 0.657397985458374\n",
      "Ep 65: Batch #5 - Loss: 0.5538655519485474\n",
      "Ep 65: Batch #6 - Loss: 0.7351636290550232\n",
      "Ep 65: Batch #7 - Loss: 0.5761178731918335\n",
      "Ep 65: Batch #8 - Loss: 0.5855041146278381\n",
      "Ep 65: Batch #9 - Loss: 1.0935888290405273\n",
      "Ep 65: Batch #10 - Loss: 0.7993890047073364\n",
      "Ep 65: Batch #11 - Loss: 0.5443400144577026\n",
      "Ep 65: Batch #12 - Loss: 1.1997461318969727\n",
      "Ep 65: Batch #13 - Loss: 0.5716412663459778\n",
      "Ep 65: Batch #14 - Loss: 0.5990121960639954\n",
      "Ep 65: Batch #15 - Loss: 0.8465629816055298\n",
      "Ep 65: Batch #16 - Loss: 0.9549105167388916\n",
      "Ep 65: Batch #17 - Loss: 0.7312893271446228\n",
      "Ep 65: Batch #18 - Loss: 0.8087137937545776\n",
      "Ep 65: Batch #19 - Loss: 0.5640040636062622\n",
      "Ep 65: Batch #20 - Loss: 0.546466052532196\n",
      "Ep 65: Batch #21 - Loss: 0.8081010580062866\n",
      "Ep 65: Batch #22 - Loss: 0.6078585386276245\n",
      "Ep 65: Batch #23 - Loss: 0.6003462672233582\n",
      "Ep 65: Batch #24 - Loss: 0.6390382647514343\n",
      "Ep 65: Batch #25 - Loss: 0.6066759824752808\n",
      "Ep 65: Batch #26 - Loss: 0.5563719272613525\n",
      "Ep 65: Batch #27 - Loss: 1.1407803297042847\n",
      "Ep 65: Batch #28 - Loss: 0.6928191184997559\n",
      "Ep 65: Batch #29 - Loss: 0.75403892993927\n",
      "Ep 65: Batch #30 - Loss: 0.8260471224784851\n",
      "Ep 65: Batch #31 - Loss: 0.5617417693138123\n",
      "Ep 65: Batch #32 - Loss: 0.5814334750175476\n",
      "Ep 65: Batch #33 - Loss: 0.6668954491615295\n",
      "Ep 65: Batch #34 - Loss: 0.6371902823448181\n",
      "Ep 65: Batch #35 - Loss: 0.7239245772361755\n",
      "Ep 65: Batch #36 - Loss: 0.5852302312850952\n",
      "Ep 65: Batch #37 - Loss: 0.9214352369308472\n",
      "Ep 65: Batch #38 - Loss: 0.5687767863273621\n",
      "Ep 65: Batch #39 - Loss: 0.686767578125\n",
      "Ep 65: Batch #40 - Loss: 0.6045154929161072\n",
      "Ep 65: Batch #41 - Loss: 0.6199612021446228\n",
      "Ep 65: Batch #42 - Loss: 0.5703743696212769\n",
      "Ep 65: Batch #43 - Loss: 0.6327741742134094\n",
      "Ep 65: Batch #44 - Loss: 0.6133624315261841\n",
      "Ep 65: Batch #45 - Loss: 0.5246831774711609\n",
      "Ep 65: Batch #46 - Loss: 0.6973391175270081\n",
      "Ep 65: Batch #47 - Loss: 0.8040240406990051\n",
      "Ep 65: Batch #48 - Loss: 1.0424293279647827\n",
      "Ep 65: Batch #49 - Loss: 0.8114731907844543\n",
      "Ep 65: Batch #50 - Loss: 0.5739315152168274\n",
      "Ep 65: Batch #51 - Loss: 0.8171690702438354\n",
      "Ep 65: Batch #52 - Loss: 0.6760714054107666\n",
      "Ep 65: Batch #53 - Loss: 0.7151989340782166\n",
      "Ep 65: Batch #54 - Loss: 0.5783321261405945\n",
      "Ep 65: Batch #55 - Loss: 0.610779881477356\n",
      "Ep 65: Batch #56 - Loss: 0.8579769134521484\n",
      "Ep 65: Batch #57 - Loss: 0.6823164820671082\n",
      "Ep 65: Batch #58 - Loss: 0.8267195224761963\n",
      "Ep 65: Batch #59 - Loss: 0.558090329170227\n",
      "Ep 65: Batch #60 - Loss: 1.008594036102295\n",
      "Ep 65: Batch #61 - Loss: 0.5353863835334778\n",
      "Ep 65: Batch #62 - Loss: 0.5744865536689758\n",
      "Ep 65: Batch #63 - Loss: 0.780456006526947\n",
      "Ep 65: Batch #64 - Loss: 8.236165046691895\n",
      "Ep 65: Batch #65 - Loss: 0.5241279602050781\n",
      "Ep 65: Batch #66 - Loss: 0.6646861433982849\n",
      "Ep 65: Batch #67 - Loss: 0.7758041024208069\n",
      "Ep 65: Batch #68 - Loss: 0.7128810882568359\n",
      "Ep 65: Batch #69 - Loss: 0.5872705578804016\n",
      "Ep 65: Batch #70 - Loss: 0.6152148246765137\n",
      "Ep 65: Batch #71 - Loss: 0.5358211994171143\n",
      "Ep 65: Batch #72 - Loss: 0.6623859405517578\n",
      "Ep 65: Batch #73 - Loss: 0.720676839351654\n",
      "Ep 65: Batch #74 - Loss: 0.5766980648040771\n",
      "Ep 65: Batch #75 - Loss: 0.6669880151748657\n",
      "Ep 65: Batch #76 - Loss: 0.9245499968528748\n",
      "Ep 65: Batch #77 - Loss: 0.5755106210708618\n",
      "Ep 65: Batch #78 - Loss: 0.9188045263290405\n",
      "Ep 65: Batch #79 - Loss: 0.5254126787185669\n",
      "Ep 65: Batch #80 - Loss: 0.6920763850212097\n",
      "Ep 65: Batch #81 - Loss: 1.5245479345321655\n",
      "Ep 65: Batch #82 - Loss: 0.7528075575828552\n",
      "Ep 65: Batch #83 - Loss: 1.2375497817993164\n",
      "Ep 65: Batch #84 - Loss: 0.5776393413543701\n",
      "Ep 65: Batch #85 - Loss: 0.78549724817276\n",
      "Ep 65: Batch #86 - Loss: 0.5477878451347351\n",
      "Ep 65: Batch #87 - Loss: 0.5724573135375977\n",
      "Ep 65: Batch #88 - Loss: 0.6573147773742676\n",
      "Ep 65: Batch #89 - Loss: 0.7277405858039856\n",
      "Ep 65: Batch #90 - Loss: 0.9012267589569092\n",
      "Ep 65: Batch #91 - Loss: 0.6497934460639954\n",
      "Ep 65: Batch #92 - Loss: 0.7307173013687134\n",
      "Ep 65: Batch #93 - Loss: 0.7830303907394409\n",
      "Ep 65: Batch #94 - Loss: 0.746442973613739\n",
      "Ep 65: Batch #95 - Loss: 0.7612841129302979\n",
      "Ep 65: Batch #96 - Loss: 0.7581812143325806\n",
      "Ep 65: Batch #97 - Loss: 0.5866738557815552\n",
      "Ep 65: Batch #98 - Loss: 0.5779784917831421\n",
      "Ep 65: Batch #99 - Loss: 0.794542133808136\n",
      "Ep 65: Batch #100 - Loss: 0.5576099157333374\n",
      "Ep 65: Batch #101 - Loss: 0.8681864142417908\n",
      "Ep 65: Batch #102 - Loss: 0.6124054789543152\n",
      "Ep 65: Batch #103 - Loss: 0.635922372341156\n",
      "Ep 65: Batch #104 - Loss: 0.6610310077667236\n",
      "Ep 65: Batch #105 - Loss: 0.8175535798072815\n",
      "Ep 65: Batch #106 - Loss: 0.6261621713638306\n",
      "Ep 65: Batch #107 - Loss: 0.615418016910553\n",
      "Ep 65: Batch #108 - Loss: 0.901112973690033\n",
      "Ep 65: Batch #109 - Loss: 0.6271450519561768\n",
      "Ep 65: Batch #110 - Loss: 0.7253388166427612\n",
      "Ep 65: Batch #111 - Loss: 1.0416921377182007\n",
      "Ep 65: Batch #112 - Loss: 0.7937893867492676\n",
      "Ep 65: Batch #113 - Loss: 0.6573950052261353\n",
      "Ep 65: Batch #114 - Loss: 0.7261627912521362\n",
      "Ep 65: Batch #115 - Loss: 0.9090927243232727\n",
      "Ep 65: Batch #116 - Loss: 0.521766722202301\n",
      "Ep 65: Batch #117 - Loss: 0.6786373853683472\n",
      "Ep 65: Batch #118 - Loss: 0.4545457363128662\n",
      "Model saved in file: ./weights_autoencoder_sigmoid/model_e65b118_1516648800.2753317.ckpt\n",
      "Ep 65: Batch #119 - Loss: 0.8092281818389893\n",
      "Ep 65: Batch #120 - Loss: 0.659735381603241\n",
      "Ep 65: Batch #121 - Loss: 0.561297595500946\n",
      "Ep 65: Batch #122 - Loss: 0.7096336483955383\n",
      "Ep 65: Batch #123 - Loss: 0.7161603569984436\n",
      "Ep 65: Batch #124 - Loss: 0.557000994682312\n",
      "Ep 65: Batch #125 - Loss: 2.473219871520996\n",
      "Ep 65: Batch #126 - Loss: 1.0048067569732666\n",
      "Ep 65: Batch #127 - Loss: 0.5822374820709229\n",
      "Ep 65: Batch #128 - Loss: 0.8854551911354065\n",
      "Ep 65: Batch #129 - Loss: 0.6778466701507568\n",
      "Ep 65: Batch #130 - Loss: 0.595496416091919\n",
      "Ep 65: Batch #131 - Loss: 0.8032790422439575\n",
      "Ep 65: Batch #132 - Loss: 0.6839536428451538\n",
      "Ep 65: Batch #133 - Loss: 0.6666991114616394\n",
      "Ep 65: Batch #134 - Loss: 0.6369228959083557\n",
      "Ep 65: Batch #135 - Loss: 0.8220928311347961\n",
      "Ep 65: Batch #136 - Loss: 1.042992115020752\n",
      "Ep 65: Batch #137 - Loss: 0.7559948563575745\n",
      "Ep 65: Batch #138 - Loss: 0.9014900326728821\n",
      "Ep 65: Batch #139 - Loss: 0.675133228302002\n",
      "Ep 65: Batch #140 - Loss: 0.8425800204277039\n",
      "Ep 65: Batch #141 - Loss: 1.121368169784546\n",
      "Ep 65: Batch #142 - Loss: 0.672018826007843\n",
      "Ep 65: Batch #143 - Loss: 0.7713169455528259\n",
      "Ep 65: Batch #144 - Loss: 0.6122515201568604\n",
      "Ep 65: Batch #145 - Loss: 0.5992306470870972\n",
      "Ep 65: Batch #146 - Loss: 0.6987431645393372\n",
      "Ep 65: Batch #147 - Loss: 0.6624658107757568\n",
      "Ep 65: Batch #148 - Loss: 0.7529706358909607\n",
      "Ep 65: Batch #149 - Loss: 0.6151739358901978\n",
      "Ep 65: Batch #150 - Loss: 0.7204161286354065\n",
      "Ep 65: Batch #151 - Loss: 0.6267051696777344\n",
      "Ep 65: Batch #152 - Loss: 0.6073657870292664\n",
      "Ep 65: Batch #153 - Loss: 0.8258301019668579\n",
      "Ep 65: Batch #154 - Loss: 0.6317954659461975\n",
      "Ep 65: Batch #155 - Loss: 0.6905498504638672\n",
      "Ep 65: Batch #156 - Loss: 0.7802516222000122\n",
      "Ep 65: Batch #157 - Loss: 0.6128728985786438\n",
      "Ep 65: Batch #158 - Loss: 0.7180721759796143\n",
      "Ep 65: Batch #159 - Loss: 0.5972533226013184\n",
      "Ep 65: Batch #160 - Loss: 0.6930659413337708\n",
      "Ep 65: Batch #161 - Loss: 0.6690521240234375\n",
      "Ep 65: Batch #162 - Loss: 0.7185679078102112\n",
      "Ep 65: Batch #163 - Loss: 0.7599450349807739\n",
      "Ep 65: Batch #164 - Loss: 0.6475757956504822\n",
      "Ep 65: Batch #165 - Loss: 1.3403465747833252\n",
      "Ep 65: Batch #166 - Loss: 0.5345137715339661\n",
      "Ep 65: Batch #167 - Loss: 0.7103822827339172\n",
      "Ep 65: Batch #168 - Loss: 0.6930843591690063\n",
      "Ep 65: Batch #169 - Loss: 0.6669732332229614\n",
      "Ep 65: Batch #170 - Loss: 0.6276241540908813\n",
      "Ep 65: Batch #171 - Loss: 0.6404106020927429\n",
      "Ep 65: Batch #172 - Loss: 0.534400224685669\n",
      "Ep 65: Batch #173 - Loss: 0.9290860295295715\n",
      "Ep 65: Batch #174 - Loss: 0.4953306019306183\n",
      "Ep 65: Batch #175 - Loss: 0.6356274485588074\n",
      "Ep 65: Batch #176 - Loss: 0.8968261480331421\n",
      "Ep 65: Batch #177 - Loss: 0.649483859539032\n",
      "Ep 65: Batch #178 - Loss: 0.6231300830841064\n",
      "Ep 65: Batch #179 - Loss: 0.7463725209236145\n",
      "Ep 65: Batch #180 - Loss: 0.6498510241508484\n",
      "Ep 65: Batch #181 - Loss: 0.8017417192459106\n",
      "Ep 65: Batch #182 - Loss: 0.6284161806106567\n",
      "Ep 65: Batch #183 - Loss: 0.6058950424194336\n",
      "Ep 65: Batch #184 - Loss: 0.9201030135154724\n",
      "Ep 65: Batch #185 - Loss: 0.6331984996795654\n",
      "Ep 65: Batch #186 - Loss: 0.7518048882484436\n",
      "Ep 65: Batch #187 - Loss: 0.8662773966789246\n",
      "Ep 65: Batch #188 - Loss: 0.9457363486289978\n",
      "Ep 65: Batch #189 - Loss: 0.5870645642280579\n",
      "Ep 65: Batch #190 - Loss: 0.621954619884491\n",
      "Ep 65: Batch #191 - Loss: 0.8040524125099182\n",
      "Ep 65: Batch #192 - Loss: 0.5716213583946228\n",
      "Ep 65: Batch #193 - Loss: 0.6311352252960205\n",
      "Ep 65: Batch #194 - Loss: 0.5426745414733887\n",
      "Ep 65: Batch #195 - Loss: 0.784842312335968\n",
      "Ep 65: Batch #196 - Loss: 0.6931465268135071\n",
      "Ep 65: Batch #197 - Loss: 0.7005144953727722\n",
      "Ep 65: Batch #198 - Loss: 0.5337997078895569\n",
      "Ep 65: Batch #199 - Loss: 0.6438324451446533\n",
      "Ep 66: Batch #0 - Loss: 0.651362955570221\n",
      "Ep 66: Batch #1 - Loss: 0.7165423631668091\n",
      "Ep 66: Batch #2 - Loss: 0.8605377674102783\n",
      "Ep 66: Batch #3 - Loss: 0.721470832824707\n",
      "Ep 66: Batch #4 - Loss: 0.6574010252952576\n",
      "Ep 66: Batch #5 - Loss: 0.5535928606987\n",
      "Ep 66: Batch #6 - Loss: 0.7352006435394287\n",
      "Ep 66: Batch #7 - Loss: 0.5762796998023987\n",
      "Ep 66: Batch #8 - Loss: 0.585480272769928\n",
      "Ep 66: Batch #9 - Loss: 1.0941582918167114\n",
      "Ep 66: Batch #10 - Loss: 0.7990990281105042\n",
      "Ep 66: Batch #11 - Loss: 0.5444331169128418\n",
      "Ep 66: Batch #12 - Loss: 1.1993069648742676\n",
      "Ep 66: Batch #13 - Loss: 0.5716150999069214\n",
      "Ep 66: Batch #14 - Loss: 0.598953366279602\n",
      "Ep 66: Batch #15 - Loss: 0.8461384177207947\n",
      "Ep 66: Batch #16 - Loss: 0.9556095600128174\n",
      "Ep 66: Batch #17 - Loss: 0.7312411665916443\n",
      "Ep 66: Batch #18 - Loss: 0.8088796138763428\n",
      "Ep 66: Batch #19 - Loss: 0.5638829469680786\n",
      "Ep 66: Batch #20 - Loss: 0.5466121435165405\n",
      "Ep 66: Batch #21 - Loss: 0.8069272637367249\n",
      "Ep 66: Batch #22 - Loss: 0.6083508133888245\n",
      "Ep 66: Batch #23 - Loss: 0.6002770066261292\n",
      "Ep 66: Batch #24 - Loss: 0.6391100287437439\n",
      "Ep 66: Batch #25 - Loss: 0.6066580414772034\n",
      "Ep 66: Batch #26 - Loss: 0.5563299655914307\n",
      "Ep 66: Batch #27 - Loss: 1.1406095027923584\n",
      "Ep 66: Batch #28 - Loss: 0.6926526427268982\n",
      "Ep 66: Batch #29 - Loss: 0.7536278367042542\n",
      "Ep 66: Batch #30 - Loss: 0.8256661891937256\n",
      "Ep 66: Batch #31 - Loss: 0.5618442893028259\n",
      "Ep 66: Batch #32 - Loss: 0.5811771750450134\n",
      "Ep 66: Batch #33 - Loss: 0.6671284437179565\n",
      "Ep 66: Batch #34 - Loss: 0.6371501088142395\n",
      "Ep 66: Batch #35 - Loss: 0.7240992784500122\n",
      "Ep 66: Batch #36 - Loss: 0.5851394534111023\n",
      "Ep 66: Batch #37 - Loss: 0.921035885810852\n",
      "Ep 66: Batch #38 - Loss: 0.5685740113258362\n",
      "Ep 66: Batch #39 - Loss: 0.6869616508483887\n",
      "Ep 66: Batch #40 - Loss: 0.6045851707458496\n",
      "Ep 66: Batch #41 - Loss: 0.6198942065238953\n",
      "Ep 66: Batch #42 - Loss: 0.5704091191291809\n",
      "Ep 66: Batch #43 - Loss: 0.6327756643295288\n",
      "Ep 66: Batch #44 - Loss: 0.6132522225379944\n",
      "Ep 66: Batch #45 - Loss: 0.5247271656990051\n",
      "Ep 66: Batch #46 - Loss: 0.6972607374191284\n",
      "Ep 66: Batch #47 - Loss: 0.8040310144424438\n",
      "Ep 66: Batch #48 - Loss: 1.0424933433532715\n",
      "Ep 66: Batch #49 - Loss: 0.8114271759986877\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 66: Batch #50 - Loss: 0.5738792419433594\n",
      "Ep 66: Batch #51 - Loss: 0.8170911073684692\n",
      "Ep 66: Batch #52 - Loss: 0.6759361028671265\n",
      "Ep 66: Batch #53 - Loss: 0.7150740027427673\n",
      "Ep 66: Batch #54 - Loss: 0.5782247185707092\n",
      "Ep 66: Batch #55 - Loss: 0.6108905673027039\n",
      "Ep 66: Batch #56 - Loss: 0.8581529855728149\n",
      "Ep 66: Batch #57 - Loss: 0.6822572946548462\n",
      "Ep 66: Batch #58 - Loss: 0.8266839385032654\n",
      "Ep 66: Batch #59 - Loss: 0.55799400806427\n",
      "Ep 66: Batch #60 - Loss: 1.0080211162567139\n",
      "Ep 66: Batch #61 - Loss: 0.5351437926292419\n",
      "Ep 66: Batch #62 - Loss: 0.5746205449104309\n",
      "Ep 66: Batch #63 - Loss: 0.7802380919456482\n",
      "Ep 66: Batch #64 - Loss: 8.222762107849121\n",
      "Ep 66: Batch #65 - Loss: 0.5240421295166016\n",
      "Ep 66: Batch #66 - Loss: 0.6645933985710144\n",
      "Ep 66: Batch #67 - Loss: 0.7759705185890198\n",
      "Ep 66: Batch #68 - Loss: 0.7130815982818604\n",
      "Ep 66: Batch #69 - Loss: 0.587270975112915\n",
      "Ep 66: Batch #70 - Loss: 0.6154282689094543\n",
      "Ep 66: Batch #71 - Loss: 0.5358829498291016\n",
      "Ep 66: Batch #72 - Loss: 0.6626749038696289\n",
      "Ep 66: Batch #73 - Loss: 0.7206701040267944\n",
      "Ep 66: Batch #74 - Loss: 0.5768270492553711\n",
      "Ep 66: Batch #75 - Loss: 0.666959822177887\n",
      "Ep 66: Batch #76 - Loss: 0.9243967533111572\n",
      "Ep 66: Batch #77 - Loss: 0.575581431388855\n",
      "Ep 66: Batch #78 - Loss: 0.9183462858200073\n",
      "Ep 66: Batch #79 - Loss: 0.5254019498825073\n",
      "Ep 66: Batch #80 - Loss: 0.6917606592178345\n",
      "Ep 66: Batch #81 - Loss: 1.5229939222335815\n",
      "Ep 66: Batch #82 - Loss: 0.7523509860038757\n",
      "Ep 66: Batch #83 - Loss: 1.2347445487976074\n",
      "Ep 66: Batch #84 - Loss: 0.577774703502655\n",
      "Ep 66: Batch #85 - Loss: 0.7851836681365967\n",
      "Ep 66: Batch #86 - Loss: 0.5479168891906738\n",
      "Ep 66: Batch #87 - Loss: 0.5720502138137817\n",
      "Ep 66: Batch #88 - Loss: 0.6571023464202881\n",
      "Ep 66: Batch #89 - Loss: 0.7276037931442261\n",
      "Ep 66: Batch #90 - Loss: 0.9014630913734436\n",
      "Ep 66: Batch #91 - Loss: 0.6495150327682495\n",
      "Ep 66: Batch #92 - Loss: 0.7303799986839294\n",
      "Ep 66: Batch #93 - Loss: 0.7829292416572571\n",
      "Ep 66: Batch #94 - Loss: 0.7459707856178284\n",
      "Ep 66: Batch #95 - Loss: 0.7608787417411804\n",
      "Ep 66: Batch #96 - Loss: 0.7576448917388916\n",
      "Ep 66: Batch #97 - Loss: 0.5868299007415771\n",
      "Ep 66: Batch #98 - Loss: 0.5775185823440552\n",
      "Ep 66: Batch #99 - Loss: 0.7937267422676086\n",
      "Ep 66: Batch #100 - Loss: 0.5575208067893982\n",
      "Ep 66: Batch #101 - Loss: 0.8687260746955872\n",
      "Ep 66: Batch #102 - Loss: 0.6122220158576965\n",
      "Ep 66: Batch #103 - Loss: 0.635718584060669\n",
      "Ep 66: Batch #104 - Loss: 0.6609727740287781\n",
      "Ep 66: Batch #105 - Loss: 0.817298412322998\n",
      "Ep 66: Batch #106 - Loss: 0.6259256601333618\n",
      "Ep 66: Batch #107 - Loss: 0.6153238415718079\n",
      "Ep 66: Batch #108 - Loss: 0.9006966948509216\n",
      "Ep 66: Batch #109 - Loss: 0.626767635345459\n",
      "Ep 66: Batch #110 - Loss: 0.7249952554702759\n",
      "Ep 66: Batch #111 - Loss: 1.0411564111709595\n",
      "Ep 66: Batch #112 - Loss: 0.7932433485984802\n",
      "Ep 66: Batch #113 - Loss: 0.6573986411094666\n",
      "Ep 66: Batch #114 - Loss: 0.725763738155365\n",
      "Ep 66: Batch #115 - Loss: 0.9091390371322632\n",
      "Ep 66: Batch #116 - Loss: 0.5216760635375977\n",
      "Ep 66: Batch #117 - Loss: 0.6784340143203735\n",
      "Ep 66: Batch #118 - Loss: 0.4545285999774933\n",
      "Model saved in file: ./weights_autoencoder_sigmoid/model_e66b118_1516648800.4109464.ckpt\n",
      "Ep 66: Batch #119 - Loss: 0.8084148168563843\n",
      "Ep 66: Batch #120 - Loss: 0.659267783164978\n",
      "Ep 66: Batch #121 - Loss: 0.5610189437866211\n",
      "Ep 66: Batch #122 - Loss: 0.7094427347183228\n",
      "Ep 66: Batch #123 - Loss: 0.7160717844963074\n",
      "Ep 66: Batch #124 - Loss: 0.556750476360321\n",
      "Ep 66: Batch #125 - Loss: 2.47353458404541\n",
      "Ep 66: Batch #126 - Loss: 1.0050078630447388\n",
      "Ep 66: Batch #127 - Loss: 0.5823444128036499\n",
      "Ep 66: Batch #128 - Loss: 0.8856478333473206\n",
      "Ep 66: Batch #129 - Loss: 0.6775299906730652\n",
      "Ep 66: Batch #130 - Loss: 0.5955013036727905\n",
      "Ep 66: Batch #131 - Loss: 0.8030238747596741\n",
      "Ep 66: Batch #132 - Loss: 0.6837581396102905\n",
      "Ep 66: Batch #133 - Loss: 0.6668994426727295\n",
      "Ep 66: Batch #134 - Loss: 0.6366912722587585\n",
      "Ep 66: Batch #135 - Loss: 0.8216211199760437\n",
      "Ep 66: Batch #136 - Loss: 1.0426082611083984\n",
      "Ep 66: Batch #137 - Loss: 0.7550427913665771\n",
      "Ep 66: Batch #138 - Loss: 0.9014750719070435\n",
      "Ep 66: Batch #139 - Loss: 0.6753727197647095\n",
      "Ep 66: Batch #140 - Loss: 0.8422574400901794\n",
      "Ep 66: Batch #141 - Loss: 1.1205470561981201\n",
      "Ep 66: Batch #142 - Loss: 0.6713511347770691\n",
      "Ep 66: Batch #143 - Loss: 0.7710959315299988\n",
      "Ep 66: Batch #144 - Loss: 0.6120882630348206\n",
      "Ep 66: Batch #145 - Loss: 0.5989357233047485\n",
      "Ep 66: Batch #146 - Loss: 0.698309600353241\n",
      "Ep 66: Batch #147 - Loss: 0.6620093584060669\n",
      "Ep 66: Batch #148 - Loss: 0.7534565329551697\n",
      "Ep 66: Batch #149 - Loss: 0.6149407625198364\n",
      "Ep 66: Batch #150 - Loss: 0.7202891707420349\n",
      "Ep 66: Batch #151 - Loss: 0.626763105392456\n",
      "Ep 66: Batch #152 - Loss: 0.6072608232498169\n",
      "Ep 66: Batch #153 - Loss: 0.8260822296142578\n",
      "Ep 66: Batch #154 - Loss: 0.6318681240081787\n",
      "Ep 66: Batch #155 - Loss: 0.6904017925262451\n",
      "Ep 66: Batch #156 - Loss: 0.7797877788543701\n",
      "Ep 66: Batch #157 - Loss: 0.612747848033905\n",
      "Ep 66: Batch #158 - Loss: 0.7179428339004517\n",
      "Ep 66: Batch #159 - Loss: 0.5971283316612244\n",
      "Ep 66: Batch #160 - Loss: 0.6931394934654236\n",
      "Ep 66: Batch #161 - Loss: 0.6691256761550903\n",
      "Ep 66: Batch #162 - Loss: 0.7188331484794617\n",
      "Ep 66: Batch #163 - Loss: 0.759945809841156\n",
      "Ep 66: Batch #164 - Loss: 0.6477060317993164\n",
      "Ep 66: Batch #165 - Loss: 1.3377879858016968\n",
      "Ep 66: Batch #166 - Loss: 0.534318208694458\n",
      "Ep 66: Batch #167 - Loss: 0.7091578841209412\n",
      "Ep 66: Batch #168 - Loss: 0.6925566792488098\n",
      "Ep 66: Batch #169 - Loss: 0.6665048003196716\n",
      "Ep 66: Batch #170 - Loss: 0.6270865797996521\n",
      "Ep 66: Batch #171 - Loss: 0.6405967473983765\n",
      "Ep 66: Batch #172 - Loss: 0.533936619758606\n",
      "Ep 66: Batch #173 - Loss: 0.929039478302002\n",
      "Ep 66: Batch #174 - Loss: 0.4945938289165497\n",
      "Ep 66: Batch #175 - Loss: 0.6347404718399048\n",
      "Ep 66: Batch #176 - Loss: 0.8966978192329407\n",
      "Ep 66: Batch #177 - Loss: 0.6492084860801697\n",
      "Ep 66: Batch #178 - Loss: 0.6223877668380737\n",
      "Ep 66: Batch #179 - Loss: 0.7458338737487793\n",
      "Ep 66: Batch #180 - Loss: 0.6496396064758301\n",
      "Ep 66: Batch #181 - Loss: 0.8014384508132935\n",
      "Ep 66: Batch #182 - Loss: 0.6285077333450317\n",
      "Ep 66: Batch #183 - Loss: 0.6056991219520569\n",
      "Ep 66: Batch #184 - Loss: 0.919795572757721\n",
      "Ep 66: Batch #185 - Loss: 0.6329975128173828\n",
      "Ep 66: Batch #186 - Loss: 0.752248227596283\n",
      "Ep 66: Batch #187 - Loss: 0.8666234612464905\n",
      "Ep 66: Batch #188 - Loss: 0.9444933533668518\n",
      "Ep 66: Batch #189 - Loss: 0.5869876742362976\n",
      "Ep 66: Batch #190 - Loss: 0.6215782165527344\n",
      "Ep 66: Batch #191 - Loss: 0.8032045364379883\n",
      "Ep 66: Batch #192 - Loss: 0.5711804032325745\n",
      "Ep 66: Batch #193 - Loss: 0.6310964822769165\n",
      "Ep 66: Batch #194 - Loss: 0.5425084233283997\n",
      "Ep 66: Batch #195 - Loss: 0.7842546105384827\n",
      "Ep 66: Batch #196 - Loss: 0.6929028034210205\n",
      "Ep 66: Batch #197 - Loss: 0.7002570033073425\n",
      "Ep 66: Batch #198 - Loss: 0.5336578488349915\n",
      "Ep 66: Batch #199 - Loss: 0.6435959339141846\n",
      "Ep 67: Batch #0 - Loss: 0.6513317227363586\n",
      "Ep 67: Batch #1 - Loss: 0.7164481282234192\n",
      "Ep 67: Batch #2 - Loss: 0.8608627319335938\n",
      "Ep 67: Batch #3 - Loss: 0.7213409543037415\n",
      "Ep 67: Batch #4 - Loss: 0.657326877117157\n",
      "Ep 67: Batch #5 - Loss: 0.5535141229629517\n",
      "Ep 67: Batch #6 - Loss: 0.7351451516151428\n",
      "Ep 67: Batch #7 - Loss: 0.5761030316352844\n",
      "Ep 67: Batch #8 - Loss: 0.5852586030960083\n",
      "Ep 67: Batch #9 - Loss: 1.0934759378433228\n",
      "Ep 67: Batch #10 - Loss: 0.7985827326774597\n",
      "Ep 67: Batch #11 - Loss: 0.544353723526001\n",
      "Ep 67: Batch #12 - Loss: 1.1988273859024048\n",
      "Ep 67: Batch #13 - Loss: 0.5715773701667786\n",
      "Ep 67: Batch #14 - Loss: 0.5988700985908508\n",
      "Ep 67: Batch #15 - Loss: 0.8449415564537048\n",
      "Ep 67: Batch #16 - Loss: 0.9548024535179138\n",
      "Ep 67: Batch #17 - Loss: 0.7313199639320374\n",
      "Ep 67: Batch #18 - Loss: 0.8088597059249878\n",
      "Ep 67: Batch #19 - Loss: 0.5638929605484009\n",
      "Ep 67: Batch #20 - Loss: 0.546283483505249\n",
      "Ep 67: Batch #21 - Loss: 0.8058419823646545\n",
      "Ep 67: Batch #22 - Loss: 0.6077417135238647\n",
      "Ep 67: Batch #23 - Loss: 0.6000353097915649\n",
      "Ep 67: Batch #24 - Loss: 0.6391726136207581\n",
      "Ep 67: Batch #25 - Loss: 0.606455385684967\n",
      "Ep 67: Batch #26 - Loss: 0.5561114549636841\n",
      "Ep 67: Batch #27 - Loss: 1.1403027772903442\n",
      "Ep 67: Batch #28 - Loss: 0.6930566430091858\n",
      "Ep 67: Batch #29 - Loss: 0.7534959316253662\n",
      "Ep 67: Batch #30 - Loss: 0.824950098991394\n",
      "Ep 67: Batch #31 - Loss: 0.5618000030517578\n",
      "Ep 67: Batch #32 - Loss: 0.5814419388771057\n",
      "Ep 67: Batch #33 - Loss: 0.6667931079864502\n",
      "Ep 67: Batch #34 - Loss: 0.6369692087173462\n",
      "Ep 67: Batch #35 - Loss: 0.7241069674491882\n",
      "Ep 67: Batch #36 - Loss: 0.585037112236023\n",
      "Ep 67: Batch #37 - Loss: 0.9210891723632812\n",
      "Ep 67: Batch #38 - Loss: 0.5684845447540283\n",
      "Ep 67: Batch #39 - Loss: 0.6868822574615479\n",
      "Ep 67: Batch #40 - Loss: 0.6046364903450012\n",
      "Ep 67: Batch #41 - Loss: 0.6198325157165527\n",
      "Ep 67: Batch #42 - Loss: 0.5703631043434143\n",
      "Ep 67: Batch #43 - Loss: 0.6327823996543884\n",
      "Ep 67: Batch #44 - Loss: 0.613124430179596\n",
      "Ep 67: Batch #45 - Loss: 0.5245490074157715\n",
      "Ep 67: Batch #46 - Loss: 0.6973240375518799\n",
      "Ep 67: Batch #47 - Loss: 0.803939700126648\n",
      "Ep 67: Batch #48 - Loss: 1.0430573225021362\n",
      "Ep 67: Batch #49 - Loss: 0.8110135197639465\n",
      "Ep 67: Batch #50 - Loss: 0.5740752816200256\n",
      "Ep 67: Batch #51 - Loss: 0.8171462416648865\n",
      "Ep 67: Batch #52 - Loss: 0.6761091351509094\n",
      "Ep 67: Batch #53 - Loss: 0.7150145173072815\n",
      "Ep 67: Batch #54 - Loss: 0.5782776474952698\n",
      "Ep 67: Batch #55 - Loss: 0.6105935573577881\n",
      "Ep 67: Batch #56 - Loss: 0.8583027720451355\n",
      "Ep 67: Batch #57 - Loss: 0.6822267174720764\n",
      "Ep 67: Batch #58 - Loss: 0.826763927936554\n",
      "Ep 67: Batch #59 - Loss: 0.5577816963195801\n",
      "Ep 67: Batch #60 - Loss: 1.0085147619247437\n",
      "Ep 67: Batch #61 - Loss: 0.5352856516838074\n",
      "Ep 67: Batch #62 - Loss: 0.5744965076446533\n",
      "Ep 67: Batch #63 - Loss: 0.7801523208618164\n",
      "Ep 67: Batch #64 - Loss: 8.210634231567383\n",
      "Ep 67: Batch #65 - Loss: 0.523949146270752\n",
      "Ep 67: Batch #66 - Loss: 0.664483368396759\n",
      "Ep 67: Batch #67 - Loss: 0.7760588526725769\n",
      "Ep 67: Batch #68 - Loss: 0.7129252552986145\n",
      "Ep 67: Batch #69 - Loss: 0.5873475074768066\n",
      "Ep 67: Batch #70 - Loss: 0.615696132183075\n",
      "Ep 67: Batch #71 - Loss: 0.5355258584022522\n",
      "Ep 67: Batch #72 - Loss: 0.6627403497695923\n",
      "Ep 67: Batch #73 - Loss: 0.7204560041427612\n",
      "Ep 67: Batch #74 - Loss: 0.5765936970710754\n",
      "Ep 67: Batch #75 - Loss: 0.6669127345085144\n",
      "Ep 67: Batch #76 - Loss: 0.9242729544639587\n",
      "Ep 67: Batch #77 - Loss: 0.5754684805870056\n",
      "Ep 67: Batch #78 - Loss: 0.9183141589164734\n",
      "Ep 67: Batch #79 - Loss: 0.5253943800926208\n",
      "Ep 67: Batch #80 - Loss: 0.6918252110481262\n",
      "Ep 67: Batch #81 - Loss: 1.5255497694015503\n",
      "Ep 67: Batch #82 - Loss: 0.7524883151054382\n",
      "Ep 67: Batch #83 - Loss: 1.2321629524230957\n",
      "Ep 67: Batch #84 - Loss: 0.5784602761268616\n",
      "Ep 67: Batch #85 - Loss: 0.7851962447166443\n",
      "Ep 67: Batch #86 - Loss: 0.5479653477668762\n",
      "Ep 67: Batch #87 - Loss: 0.5724478363990784\n",
      "Ep 67: Batch #88 - Loss: 0.6578444242477417\n",
      "Ep 67: Batch #89 - Loss: 0.7281270623207092\n",
      "Ep 67: Batch #90 - Loss: 0.9018120169639587\n",
      "Ep 67: Batch #91 - Loss: 0.6499460339546204\n",
      "Ep 67: Batch #92 - Loss: 0.7309759855270386\n",
      "Ep 67: Batch #93 - Loss: 0.7832938432693481\n",
      "Ep 67: Batch #94 - Loss: 0.7468356490135193\n",
      "Ep 67: Batch #95 - Loss: 0.7613487839698792\n",
      "Ep 67: Batch #96 - Loss: 0.7594234943389893\n",
      "Ep 67: Batch #97 - Loss: 0.5875309705734253\n",
      "Ep 67: Batch #98 - Loss: 0.5784731507301331\n",
      "Ep 67: Batch #99 - Loss: 0.7960584759712219\n",
      "Ep 67: Batch #100 - Loss: 0.5577250719070435\n",
      "Ep 67: Batch #101 - Loss: 0.8689848184585571\n",
      "Ep 67: Batch #102 - Loss: 0.6123887300491333\n",
      "Ep 67: Batch #103 - Loss: 0.6359511017799377\n",
      "Ep 67: Batch #104 - Loss: 0.6614394783973694\n",
      "Ep 67: Batch #105 - Loss: 0.8179706335067749\n",
      "Ep 67: Batch #106 - Loss: 0.6261862516403198\n",
      "Ep 67: Batch #107 - Loss: 0.6154495477676392\n",
      "Ep 67: Batch #108 - Loss: 0.9006299376487732\n",
      "Ep 67: Batch #109 - Loss: 0.6270400881767273\n",
      "Ep 67: Batch #110 - Loss: 0.7260291576385498\n",
      "Ep 67: Batch #111 - Loss: 1.0418533086776733\n",
      "Ep 67: Batch #112 - Loss: 0.7930006980895996\n",
      "Ep 67: Batch #113 - Loss: 0.6577410697937012\n",
      "Ep 67: Batch #114 - Loss: 0.7264872789382935\n",
      "Ep 67: Batch #115 - Loss: 0.909468948841095\n",
      "Ep 67: Batch #116 - Loss: 0.5220558643341064\n",
      "Ep 67: Batch #117 - Loss: 0.6787039041519165\n",
      "Ep 67: Batch #118 - Loss: 0.4547394812107086\n",
      "Ep 67: Batch #119 - Loss: 0.8078118562698364\n",
      "Ep 67: Batch #120 - Loss: 0.6589438319206238\n",
      "Ep 67: Batch #121 - Loss: 0.5612319111824036\n",
      "Ep 67: Batch #122 - Loss: 0.7096529006958008\n",
      "Ep 67: Batch #123 - Loss: 0.7160214781761169\n",
      "Ep 67: Batch #124 - Loss: 0.556969404220581\n",
      "Ep 67: Batch #125 - Loss: 2.4744842052459717\n",
      "Ep 67: Batch #126 - Loss: 1.0056617259979248\n",
      "Ep 67: Batch #127 - Loss: 0.5826148390769958\n",
      "Ep 67: Batch #128 - Loss: 0.8857988119125366\n",
      "Ep 67: Batch #129 - Loss: 0.6781162023544312\n",
      "Ep 67: Batch #130 - Loss: 0.5956804752349854\n",
      "Ep 67: Batch #131 - Loss: 0.8040379285812378\n",
      "Ep 67: Batch #132 - Loss: 0.6838574409484863\n",
      "Ep 67: Batch #133 - Loss: 0.6667419075965881\n",
      "Ep 67: Batch #134 - Loss: 0.6370857357978821\n",
      "Ep 67: Batch #135 - Loss: 0.821946918964386\n",
      "Ep 67: Batch #136 - Loss: 1.0433951616287231\n",
      "Ep 67: Batch #137 - Loss: 0.7558922171592712\n",
      "Ep 67: Batch #138 - Loss: 0.9016586542129517\n",
      "Ep 67: Batch #139 - Loss: 0.6752868294715881\n",
      "Ep 67: Batch #140 - Loss: 0.8422802686691284\n",
      "Ep 67: Batch #141 - Loss: 1.120714783668518\n",
      "Ep 67: Batch #142 - Loss: 0.6720218062400818\n",
      "Ep 67: Batch #143 - Loss: 0.7713157534599304\n",
      "Ep 67: Batch #144 - Loss: 0.6121792197227478\n",
      "Ep 67: Batch #145 - Loss: 0.5987862348556519\n",
      "Ep 67: Batch #146 - Loss: 0.6983116269111633\n",
      "Ep 67: Batch #147 - Loss: 0.6621625423431396\n",
      "Ep 67: Batch #148 - Loss: 0.7533861398696899\n",
      "Ep 67: Batch #149 - Loss: 0.6149029731750488\n",
      "Ep 67: Batch #150 - Loss: 0.7202621102333069\n",
      "Ep 67: Batch #151 - Loss: 0.6265796422958374\n",
      "Ep 67: Batch #152 - Loss: 0.6072202324867249\n",
      "Ep 67: Batch #153 - Loss: 0.8262800574302673\n",
      "Ep 67: Batch #154 - Loss: 0.6321052312850952\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 67: Batch #155 - Loss: 0.6904297471046448\n",
      "Ep 67: Batch #156 - Loss: 0.779615581035614\n",
      "Ep 67: Batch #157 - Loss: 0.6126567125320435\n",
      "Ep 67: Batch #158 - Loss: 0.7178967595100403\n",
      "Ep 67: Batch #159 - Loss: 0.5971601605415344\n",
      "Ep 67: Batch #160 - Loss: 0.6927787661552429\n",
      "Ep 67: Batch #161 - Loss: 0.6693759560585022\n",
      "Ep 67: Batch #162 - Loss: 0.7188740968704224\n",
      "Ep 67: Batch #163 - Loss: 0.7595028281211853\n",
      "Ep 67: Batch #164 - Loss: 0.6476999521255493\n",
      "Ep 67: Batch #165 - Loss: 1.3399078845977783\n",
      "Ep 67: Batch #166 - Loss: 0.534288227558136\n",
      "Ep 67: Batch #167 - Loss: 0.7090069055557251\n",
      "Ep 67: Batch #168 - Loss: 0.692823052406311\n",
      "Ep 67: Batch #169 - Loss: 0.6663259267807007\n",
      "Ep 67: Batch #170 - Loss: 0.627899706363678\n",
      "Ep 67: Batch #171 - Loss: 0.6411284804344177\n",
      "Ep 67: Batch #172 - Loss: 0.5339903831481934\n",
      "Ep 67: Batch #173 - Loss: 0.9300395250320435\n",
      "Ep 67: Batch #174 - Loss: 0.49468135833740234\n",
      "Ep 67: Batch #175 - Loss: 0.6350741386413574\n",
      "Ep 67: Batch #176 - Loss: 0.8970740437507629\n",
      "Ep 67: Batch #177 - Loss: 0.6491402983665466\n",
      "Ep 67: Batch #178 - Loss: 0.6225736141204834\n",
      "Ep 67: Batch #179 - Loss: 0.7460271120071411\n",
      "Ep 67: Batch #180 - Loss: 0.6493480801582336\n",
      "Ep 67: Batch #181 - Loss: 0.802015483379364\n",
      "Ep 67: Batch #182 - Loss: 0.6288074254989624\n",
      "Ep 67: Batch #183 - Loss: 0.6059213280677795\n",
      "Ep 67: Batch #184 - Loss: 0.920168399810791\n",
      "Ep 67: Batch #185 - Loss: 0.6341334581375122\n",
      "Ep 67: Batch #186 - Loss: 0.7526042461395264\n",
      "Ep 67: Batch #187 - Loss: 0.8677225708961487\n",
      "Ep 67: Batch #188 - Loss: 0.9426975846290588\n",
      "Ep 67: Batch #189 - Loss: 0.5870764851570129\n",
      "Ep 67: Batch #190 - Loss: 0.6223658919334412\n",
      "Ep 67: Batch #191 - Loss: 0.8033252954483032\n",
      "Ep 67: Batch #192 - Loss: 0.5715455412864685\n",
      "Ep 67: Batch #193 - Loss: 0.631200909614563\n",
      "Ep 67: Batch #194 - Loss: 0.5426800847053528\n",
      "Ep 67: Batch #195 - Loss: 0.7842914462089539\n",
      "Ep 67: Batch #196 - Loss: 0.693092405796051\n",
      "Ep 67: Batch #197 - Loss: 0.7002849578857422\n",
      "Ep 67: Batch #198 - Loss: 0.5337769389152527\n",
      "Ep 67: Batch #199 - Loss: 0.6434842944145203\n",
      "Ep 68: Batch #0 - Loss: 0.6516804099082947\n",
      "Ep 68: Batch #1 - Loss: 0.7165299654006958\n",
      "Ep 68: Batch #2 - Loss: 0.8612207174301147\n",
      "Ep 68: Batch #3 - Loss: 0.7216426730155945\n",
      "Ep 68: Batch #4 - Loss: 0.6575342416763306\n",
      "Ep 68: Batch #5 - Loss: 0.5534946918487549\n",
      "Ep 68: Batch #6 - Loss: 0.7352616190910339\n",
      "Ep 68: Batch #7 - Loss: 0.5761380195617676\n",
      "Ep 68: Batch #8 - Loss: 0.5852499008178711\n",
      "Ep 68: Batch #9 - Loss: 1.093281865119934\n",
      "Ep 68: Batch #10 - Loss: 0.7974284887313843\n",
      "Ep 68: Batch #11 - Loss: 0.5443188548088074\n",
      "Ep 68: Batch #12 - Loss: 1.198456048965454\n",
      "Ep 68: Batch #13 - Loss: 0.5715370774269104\n",
      "Ep 68: Batch #14 - Loss: 0.5987271666526794\n",
      "Ep 68: Batch #15 - Loss: 0.8454682230949402\n",
      "Ep 68: Batch #16 - Loss: 0.9547204375267029\n",
      "Ep 68: Batch #17 - Loss: 0.7313919067382812\n",
      "Ep 68: Batch #18 - Loss: 0.8089519143104553\n",
      "Ep 68: Batch #19 - Loss: 0.5639516115188599\n",
      "Ep 68: Batch #20 - Loss: 0.5462449789047241\n",
      "Ep 68: Batch #21 - Loss: 0.8049841523170471\n",
      "Ep 68: Batch #22 - Loss: 0.6073049902915955\n",
      "Ep 68: Batch #23 - Loss: 0.6001513004302979\n",
      "Ep 68: Batch #24 - Loss: 0.6393681764602661\n",
      "Ep 68: Batch #25 - Loss: 0.6064333319664001\n",
      "Ep 68: Batch #26 - Loss: 0.556087851524353\n",
      "Ep 68: Batch #27 - Loss: 1.140392780303955\n",
      "Ep 68: Batch #28 - Loss: 0.6933237910270691\n",
      "Ep 68: Batch #29 - Loss: 0.7537712454795837\n",
      "Ep 68: Batch #30 - Loss: 0.8243224620819092\n",
      "Ep 68: Batch #31 - Loss: 0.561836302280426\n",
      "Ep 68: Batch #32 - Loss: 0.581355094909668\n",
      "Ep 68: Batch #33 - Loss: 0.6666622161865234\n",
      "Ep 68: Batch #34 - Loss: 0.6367993354797363\n",
      "Ep 68: Batch #35 - Loss: 0.724144458770752\n",
      "Ep 68: Batch #36 - Loss: 0.5850953459739685\n",
      "Ep 68: Batch #37 - Loss: 0.921218991279602\n",
      "Ep 68: Batch #38 - Loss: 0.5685898065567017\n",
      "Ep 68: Batch #39 - Loss: 0.6867297887802124\n",
      "Ep 68: Batch #40 - Loss: 0.6047921776771545\n",
      "Ep 68: Batch #41 - Loss: 0.6202566623687744\n",
      "Ep 68: Batch #42 - Loss: 0.5704500079154968\n",
      "Ep 68: Batch #43 - Loss: 0.6329631805419922\n",
      "Ep 68: Batch #44 - Loss: 0.6130129098892212\n",
      "Ep 68: Batch #45 - Loss: 0.5246240496635437\n",
      "Ep 68: Batch #46 - Loss: 0.6974544525146484\n",
      "Ep 68: Batch #47 - Loss: 0.8039317727088928\n",
      "Ep 68: Batch #48 - Loss: 1.0434880256652832\n",
      "Ep 68: Batch #49 - Loss: 0.8104051947593689\n",
      "Ep 68: Batch #50 - Loss: 0.5738784670829773\n",
      "Ep 68: Batch #51 - Loss: 0.8173169493675232\n",
      "Ep 68: Batch #52 - Loss: 0.6762555837631226\n",
      "Ep 68: Batch #53 - Loss: 0.7149880528450012\n",
      "Ep 68: Batch #54 - Loss: 0.5782142877578735\n",
      "Ep 68: Batch #55 - Loss: 0.6112201809883118\n",
      "Ep 68: Batch #56 - Loss: 0.8585036396980286\n",
      "Ep 68: Batch #57 - Loss: 0.682254433631897\n",
      "Ep 68: Batch #58 - Loss: 0.8267714381217957\n",
      "Ep 68: Batch #59 - Loss: 0.5575066208839417\n",
      "Ep 68: Batch #60 - Loss: 1.008510708808899\n",
      "Ep 68: Batch #61 - Loss: 0.5354112982749939\n",
      "Ep 68: Batch #62 - Loss: 0.5745251774787903\n",
      "Ep 68: Batch #63 - Loss: 0.7802280187606812\n",
      "Ep 68: Batch #64 - Loss: 8.196884155273438\n",
      "Ep 68: Batch #65 - Loss: 0.524064302444458\n",
      "Ep 68: Batch #66 - Loss: 0.6644223928451538\n",
      "Ep 68: Batch #67 - Loss: 0.7759958505630493\n",
      "Ep 68: Batch #68 - Loss: 0.712769627571106\n",
      "Ep 68: Batch #69 - Loss: 0.5868902802467346\n",
      "Ep 68: Batch #70 - Loss: 0.6152819991111755\n",
      "Ep 68: Batch #71 - Loss: 0.5357338786125183\n",
      "Ep 68: Batch #72 - Loss: 0.6623904705047607\n",
      "Ep 68: Batch #73 - Loss: 0.7202371954917908\n",
      "Ep 68: Batch #74 - Loss: 0.576538622379303\n",
      "Ep 68: Batch #75 - Loss: 0.6668409705162048\n",
      "Ep 68: Batch #76 - Loss: 0.9241800308227539\n",
      "Ep 68: Batch #77 - Loss: 0.5753791928291321\n",
      "Ep 68: Batch #78 - Loss: 0.9181069135665894\n",
      "Ep 68: Batch #79 - Loss: 0.5253521203994751\n",
      "Ep 68: Batch #80 - Loss: 0.6916582584381104\n",
      "Ep 68: Batch #81 - Loss: 1.5284340381622314\n",
      "Ep 68: Batch #82 - Loss: 0.7528977394104004\n",
      "Ep 68: Batch #83 - Loss: 1.229975938796997\n",
      "Ep 68: Batch #84 - Loss: 0.5777440071105957\n",
      "Ep 68: Batch #85 - Loss: 0.7847861647605896\n",
      "Ep 68: Batch #86 - Loss: 0.5476270914077759\n",
      "Ep 68: Batch #87 - Loss: 0.5720109343528748\n",
      "Ep 68: Batch #88 - Loss: 0.65705806016922\n",
      "Ep 68: Batch #89 - Loss: 0.7272018194198608\n",
      "Ep 68: Batch #90 - Loss: 0.9011255502700806\n",
      "Ep 68: Batch #91 - Loss: 0.6498485803604126\n",
      "Ep 68: Batch #92 - Loss: 0.7303783297538757\n",
      "Ep 68: Batch #93 - Loss: 0.7829118371009827\n",
      "Ep 68: Batch #94 - Loss: 0.7455912232398987\n",
      "Ep 68: Batch #95 - Loss: 0.7608569264411926\n",
      "Ep 68: Batch #96 - Loss: 0.7569447159767151\n",
      "Ep 68: Batch #97 - Loss: 0.5874307155609131\n",
      "Ep 68: Batch #98 - Loss: 0.5779992938041687\n",
      "Ep 68: Batch #99 - Loss: 0.7941259145736694\n",
      "Ep 68: Batch #100 - Loss: 0.5577199459075928\n",
      "Ep 68: Batch #101 - Loss: 0.8689451813697815\n",
      "Ep 68: Batch #102 - Loss: 0.6121035218238831\n",
      "Ep 68: Batch #103 - Loss: 0.6355611681938171\n",
      "Ep 68: Batch #104 - Loss: 0.6606019139289856\n",
      "Ep 68: Batch #105 - Loss: 0.8176788687705994\n",
      "Ep 68: Batch #106 - Loss: 0.6259480714797974\n",
      "Ep 68: Batch #107 - Loss: 0.6152544021606445\n",
      "Ep 68: Batch #108 - Loss: 0.9009007215499878\n",
      "Ep 68: Batch #109 - Loss: 0.6265386343002319\n",
      "Ep 68: Batch #110 - Loss: 0.7242643237113953\n",
      "Ep 68: Batch #111 - Loss: 1.0402239561080933\n",
      "Ep 68: Batch #112 - Loss: 0.7929709553718567\n",
      "Ep 68: Batch #113 - Loss: 0.657271146774292\n",
      "Ep 68: Batch #114 - Loss: 0.7255637049674988\n",
      "Ep 68: Batch #115 - Loss: 0.9094228148460388\n",
      "Ep 68: Batch #116 - Loss: 0.521511971950531\n",
      "Ep 68: Batch #117 - Loss: 0.6783157587051392\n",
      "Ep 68: Batch #118 - Loss: 0.4543318450450897\n",
      "Model saved in file: ./weights_autoencoder_sigmoid/model_e68b118_1516648800.6671493.ckpt\n",
      "Ep 68: Batch #119 - Loss: 0.8092864155769348\n",
      "Ep 68: Batch #120 - Loss: 0.6591045260429382\n",
      "Ep 68: Batch #121 - Loss: 0.5607812404632568\n",
      "Ep 68: Batch #122 - Loss: 0.7094016075134277\n",
      "Ep 68: Batch #123 - Loss: 0.7156369686126709\n",
      "Ep 68: Batch #124 - Loss: 0.5566182732582092\n",
      "Ep 68: Batch #125 - Loss: 2.4736757278442383\n",
      "Ep 68: Batch #126 - Loss: 1.005538821220398\n",
      "Ep 68: Batch #127 - Loss: 0.5823200941085815\n",
      "Ep 68: Batch #128 - Loss: 0.8858790397644043\n",
      "Ep 68: Batch #129 - Loss: 0.6776387691497803\n",
      "Ep 68: Batch #130 - Loss: 0.5953502058982849\n",
      "Ep 68: Batch #131 - Loss: 0.8026034832000732\n",
      "Ep 68: Batch #132 - Loss: 0.6836532950401306\n",
      "Ep 68: Batch #133 - Loss: 0.666648805141449\n",
      "Ep 68: Batch #134 - Loss: 0.6368593573570251\n",
      "Ep 68: Batch #135 - Loss: 0.8217267990112305\n",
      "Ep 68: Batch #136 - Loss: 1.0427968502044678\n",
      "Ep 68: Batch #137 - Loss: 0.7552329301834106\n",
      "Ep 68: Batch #138 - Loss: 0.9014140963554382\n",
      "Ep 68: Batch #139 - Loss: 0.6746764779090881\n",
      "Ep 68: Batch #140 - Loss: 0.8419967293739319\n",
      "Ep 68: Batch #141 - Loss: 1.119632363319397\n",
      "Ep 68: Batch #142 - Loss: 0.671396017074585\n",
      "Ep 68: Batch #143 - Loss: 0.770828902721405\n",
      "Ep 68: Batch #144 - Loss: 0.6119370460510254\n",
      "Ep 68: Batch #145 - Loss: 0.5984840393066406\n",
      "Ep 68: Batch #146 - Loss: 0.6980546712875366\n",
      "Ep 68: Batch #147 - Loss: 0.6619241237640381\n",
      "Ep 68: Batch #148 - Loss: 0.7526937127113342\n",
      "Ep 68: Batch #149 - Loss: 0.614388644695282\n",
      "Ep 68: Batch #150 - Loss: 0.7200621366500854\n",
      "Ep 68: Batch #151 - Loss: 0.6263929009437561\n",
      "Ep 68: Batch #152 - Loss: 0.6071492433547974\n",
      "Ep 68: Batch #153 - Loss: 0.8259784579277039\n",
      "Ep 68: Batch #154 - Loss: 0.6316677331924438\n",
      "Ep 68: Batch #155 - Loss: 0.6901313662528992\n",
      "Ep 68: Batch #156 - Loss: 0.779293417930603\n",
      "Ep 68: Batch #157 - Loss: 0.6125108599662781\n",
      "Ep 68: Batch #158 - Loss: 0.7180219888687134\n",
      "Ep 68: Batch #159 - Loss: 0.5969579815864563\n",
      "Ep 68: Batch #160 - Loss: 0.692451000213623\n",
      "Ep 68: Batch #161 - Loss: 0.6690475940704346\n",
      "Ep 68: Batch #162 - Loss: 0.7188892364501953\n",
      "Ep 68: Batch #163 - Loss: 0.7596690654754639\n",
      "Ep 68: Batch #164 - Loss: 0.6477322578430176\n",
      "Ep 68: Batch #165 - Loss: 1.3375215530395508\n",
      "Ep 68: Batch #166 - Loss: 0.5344922542572021\n",
      "Ep 68: Batch #167 - Loss: 0.7086756825447083\n",
      "Ep 68: Batch #168 - Loss: 0.6928387880325317\n",
      "Ep 68: Batch #169 - Loss: 0.6667073965072632\n",
      "Ep 68: Batch #170 - Loss: 0.6273249387741089\n",
      "Ep 68: Batch #171 - Loss: 0.6406125426292419\n",
      "Ep 68: Batch #172 - Loss: 0.5342018008232117\n",
      "Ep 68: Batch #173 - Loss: 0.9288249015808105\n",
      "Ep 68: Batch #174 - Loss: 0.4950196146965027\n",
      "Ep 68: Batch #175 - Loss: 0.6348850727081299\n",
      "Ep 68: Batch #176 - Loss: 0.8965292572975159\n",
      "Ep 68: Batch #177 - Loss: 0.6488739848136902\n",
      "Ep 68: Batch #178 - Loss: 0.6224725246429443\n",
      "Ep 68: Batch #179 - Loss: 0.7456809282302856\n",
      "Ep 68: Batch #180 - Loss: 0.6493673920631409\n",
      "Ep 68: Batch #181 - Loss: 0.8013173937797546\n",
      "Ep 68: Batch #182 - Loss: 0.6287645101547241\n",
      "Ep 68: Batch #183 - Loss: 0.6056953072547913\n",
      "Ep 68: Batch #184 - Loss: 0.919554591178894\n",
      "Ep 68: Batch #185 - Loss: 0.6330721378326416\n",
      "Ep 68: Batch #186 - Loss: 0.7513456344604492\n",
      "Ep 68: Batch #187 - Loss: 0.8661721348762512\n",
      "Ep 68: Batch #188 - Loss: 0.9422029256820679\n",
      "Ep 68: Batch #189 - Loss: 0.5867559313774109\n",
      "Ep 68: Batch #190 - Loss: 0.6217058897018433\n",
      "Ep 68: Batch #191 - Loss: 0.8029096722602844\n",
      "Ep 68: Batch #192 - Loss: 0.5713455677032471\n",
      "Ep 68: Batch #193 - Loss: 0.6311311721801758\n",
      "Ep 68: Batch #194 - Loss: 0.5425789952278137\n",
      "Ep 68: Batch #195 - Loss: 0.7840453386306763\n",
      "Ep 68: Batch #196 - Loss: 0.693121075630188\n",
      "Ep 68: Batch #197 - Loss: 0.7000589370727539\n",
      "Ep 68: Batch #198 - Loss: 0.5336127281188965\n",
      "Ep 68: Batch #199 - Loss: 0.6435155272483826\n",
      "Ep 69: Batch #0 - Loss: 0.6513015031814575\n",
      "Ep 69: Batch #1 - Loss: 0.7166560888290405\n",
      "Ep 69: Batch #2 - Loss: 0.860752284526825\n",
      "Ep 69: Batch #3 - Loss: 0.7210012674331665\n",
      "Ep 69: Batch #4 - Loss: 0.6573772430419922\n",
      "Ep 69: Batch #5 - Loss: 0.5534257888793945\n",
      "Ep 69: Batch #6 - Loss: 0.7347534894943237\n",
      "Ep 69: Batch #7 - Loss: 0.5760822296142578\n",
      "Ep 69: Batch #8 - Loss: 0.5850634574890137\n",
      "Ep 69: Batch #9 - Loss: 1.0939337015151978\n",
      "Ep 69: Batch #10 - Loss: 0.7979767918586731\n",
      "Ep 69: Batch #11 - Loss: 0.5443941950798035\n",
      "Ep 69: Batch #12 - Loss: 1.1978274583816528\n",
      "Ep 69: Batch #13 - Loss: 0.5714065432548523\n",
      "Ep 69: Batch #14 - Loss: 0.5987491607666016\n",
      "Ep 69: Batch #15 - Loss: 0.844308078289032\n",
      "Ep 69: Batch #16 - Loss: 0.955298662185669\n",
      "Ep 69: Batch #17 - Loss: 0.7313867211341858\n",
      "Ep 69: Batch #18 - Loss: 0.8090357184410095\n",
      "Ep 69: Batch #19 - Loss: 0.5637772679328918\n",
      "Ep 69: Batch #20 - Loss: 0.5462108254432678\n",
      "Ep 69: Batch #21 - Loss: 0.8039078116416931\n",
      "Ep 69: Batch #22 - Loss: 0.6077090501785278\n",
      "Ep 69: Batch #23 - Loss: 0.599967896938324\n",
      "Ep 69: Batch #24 - Loss: 0.6393646597862244\n",
      "Ep 69: Batch #25 - Loss: 0.6064356565475464\n",
      "Ep 69: Batch #26 - Loss: 0.5559785962104797\n",
      "Ep 69: Batch #27 - Loss: 1.1400926113128662\n",
      "Ep 69: Batch #28 - Loss: 0.6929807066917419\n",
      "Ep 69: Batch #29 - Loss: 0.7533296346664429\n",
      "Ep 69: Batch #30 - Loss: 0.8239500522613525\n",
      "Ep 69: Batch #31 - Loss: 0.5618411898612976\n",
      "Ep 69: Batch #32 - Loss: 0.581124484539032\n",
      "Ep 69: Batch #33 - Loss: 0.6667707562446594\n",
      "Ep 69: Batch #34 - Loss: 0.636607825756073\n",
      "Ep 69: Batch #35 - Loss: 0.7241206765174866\n",
      "Ep 69: Batch #36 - Loss: 0.5850673913955688\n",
      "Ep 69: Batch #37 - Loss: 0.921021044254303\n",
      "Ep 69: Batch #38 - Loss: 0.5682993531227112\n",
      "Ep 69: Batch #39 - Loss: 0.6869943141937256\n",
      "Ep 69: Batch #40 - Loss: 0.6046567559242249\n",
      "Ep 69: Batch #41 - Loss: 0.6196901202201843\n",
      "Ep 69: Batch #42 - Loss: 0.5703169107437134\n",
      "Ep 69: Batch #43 - Loss: 0.6327124238014221\n",
      "Ep 69: Batch #44 - Loss: 0.613061785697937\n",
      "Ep 69: Batch #45 - Loss: 0.524472713470459\n",
      "Ep 69: Batch #46 - Loss: 0.6972262263298035\n",
      "Ep 69: Batch #47 - Loss: 0.8037569522857666\n",
      "Ep 69: Batch #48 - Loss: 1.043230652809143\n",
      "Ep 69: Batch #49 - Loss: 0.810460090637207\n",
      "Ep 69: Batch #50 - Loss: 0.5738053917884827\n",
      "Ep 69: Batch #51 - Loss: 0.8169001340866089\n",
      "Ep 69: Batch #52 - Loss: 0.6758920550346375\n",
      "Ep 69: Batch #53 - Loss: 0.7148965001106262\n",
      "Ep 69: Batch #54 - Loss: 0.5780988335609436\n",
      "Ep 69: Batch #55 - Loss: 0.6114028096199036\n",
      "Ep 69: Batch #56 - Loss: 0.8585798740386963\n",
      "Ep 69: Batch #57 - Loss: 0.6822141408920288\n",
      "Ep 69: Batch #58 - Loss: 0.8265045285224915\n",
      "Ep 69: Batch #59 - Loss: 0.5574902892112732\n",
      "Ep 69: Batch #60 - Loss: 1.0077711343765259\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 69: Batch #61 - Loss: 0.5352917909622192\n",
      "Ep 69: Batch #62 - Loss: 0.5744991302490234\n",
      "Ep 69: Batch #63 - Loss: 0.7799217104911804\n",
      "Ep 69: Batch #64 - Loss: 8.182291030883789\n",
      "Ep 69: Batch #65 - Loss: 0.523955225944519\n",
      "Ep 69: Batch #66 - Loss: 0.6643796563148499\n",
      "Ep 69: Batch #67 - Loss: 0.7760281562805176\n",
      "Ep 69: Batch #68 - Loss: 0.7129058837890625\n",
      "Ep 69: Batch #69 - Loss: 0.586830735206604\n",
      "Ep 69: Batch #70 - Loss: 0.6154378652572632\n",
      "Ep 69: Batch #71 - Loss: 0.5355357527732849\n",
      "Ep 69: Batch #72 - Loss: 0.662549614906311\n",
      "Ep 69: Batch #73 - Loss: 0.7202665209770203\n",
      "Ep 69: Batch #74 - Loss: 0.576511561870575\n",
      "Ep 69: Batch #75 - Loss: 0.6667157411575317\n",
      "Ep 69: Batch #76 - Loss: 0.9239484667778015\n",
      "Ep 69: Batch #77 - Loss: 0.5754354596138\n",
      "Ep 69: Batch #78 - Loss: 0.9180644154548645\n",
      "Ep 69: Batch #79 - Loss: 0.5252323150634766\n",
      "Ep 69: Batch #80 - Loss: 0.6914101839065552\n",
      "Ep 69: Batch #81 - Loss: 1.5225824117660522\n",
      "Ep 69: Batch #82 - Loss: 0.752830982208252\n",
      "Ep 69: Batch #83 - Loss: 1.2273662090301514\n",
      "Ep 69: Batch #84 - Loss: 0.5778100490570068\n",
      "Ep 69: Batch #85 - Loss: 0.7847130298614502\n",
      "Ep 69: Batch #86 - Loss: 0.5477030873298645\n",
      "Ep 69: Batch #87 - Loss: 0.5717741250991821\n",
      "Ep 69: Batch #88 - Loss: 0.6567612886428833\n",
      "Ep 69: Batch #89 - Loss: 0.726982593536377\n",
      "Ep 69: Batch #90 - Loss: 0.9009254574775696\n",
      "Ep 69: Batch #91 - Loss: 0.6496825218200684\n",
      "Ep 69: Batch #92 - Loss: 0.7302500605583191\n",
      "Ep 69: Batch #93 - Loss: 0.7827444672584534\n",
      "Ep 69: Batch #94 - Loss: 0.7455061078071594\n",
      "Ep 69: Batch #95 - Loss: 0.7607598900794983\n",
      "Ep 69: Batch #96 - Loss: 0.7573487758636475\n",
      "Ep 69: Batch #97 - Loss: 0.587161123752594\n",
      "Ep 69: Batch #98 - Loss: 0.5773778557777405\n",
      "Ep 69: Batch #99 - Loss: 0.7930129170417786\n",
      "Ep 69: Batch #100 - Loss: 0.5576041340827942\n",
      "Ep 69: Batch #101 - Loss: 0.8689764738082886\n",
      "Ep 69: Batch #102 - Loss: 0.6118813157081604\n",
      "Ep 69: Batch #103 - Loss: 0.6354619264602661\n",
      "Ep 69: Batch #104 - Loss: 0.6606001257896423\n",
      "Ep 69: Batch #105 - Loss: 0.8177554607391357\n",
      "Ep 69: Batch #106 - Loss: 0.6258366107940674\n",
      "Ep 69: Batch #107 - Loss: 0.6151589155197144\n",
      "Ep 69: Batch #108 - Loss: 0.9007354378700256\n",
      "Ep 69: Batch #109 - Loss: 0.626429557800293\n",
      "Ep 69: Batch #110 - Loss: 0.7245649695396423\n",
      "Ep 69: Batch #111 - Loss: 1.04048752784729\n",
      "Ep 69: Batch #112 - Loss: 0.7922635674476624\n",
      "Ep 69: Batch #113 - Loss: 0.6573679447174072\n",
      "Ep 69: Batch #114 - Loss: 0.7255390286445618\n",
      "Ep 69: Batch #115 - Loss: 0.9094476699829102\n",
      "Ep 69: Batch #116 - Loss: 0.521706759929657\n",
      "Ep 69: Batch #117 - Loss: 0.6783841252326965\n",
      "Ep 69: Batch #118 - Loss: 0.4543920159339905\n",
      "Ep 69: Batch #119 - Loss: 0.8088340163230896\n",
      "Ep 69: Batch #120 - Loss: 0.658849835395813\n",
      "Ep 69: Batch #121 - Loss: 0.5606986880302429\n",
      "Ep 69: Batch #122 - Loss: 0.7094966173171997\n",
      "Ep 69: Batch #123 - Loss: 0.7155370116233826\n",
      "Ep 69: Batch #124 - Loss: 0.5566610097885132\n",
      "Ep 69: Batch #125 - Loss: 2.474114418029785\n",
      "Ep 69: Batch #126 - Loss: 1.005943775177002\n",
      "Ep 69: Batch #127 - Loss: 0.5823376774787903\n",
      "Ep 69: Batch #128 - Loss: 0.8859564065933228\n",
      "Ep 69: Batch #129 - Loss: 0.6780523657798767\n",
      "Ep 69: Batch #130 - Loss: 0.5953294038772583\n",
      "Ep 69: Batch #131 - Loss: 0.8027637004852295\n",
      "Ep 69: Batch #132 - Loss: 0.6835644245147705\n",
      "Ep 69: Batch #133 - Loss: 0.666700541973114\n",
      "Ep 69: Batch #134 - Loss: 0.6368569135665894\n",
      "Ep 69: Batch #135 - Loss: 0.8218003511428833\n",
      "Ep 69: Batch #136 - Loss: 1.0434314012527466\n",
      "Ep 69: Batch #137 - Loss: 0.755149781703949\n",
      "Ep 69: Batch #138 - Loss: 0.9016618132591248\n",
      "Ep 69: Batch #139 - Loss: 0.6745926737785339\n",
      "Ep 69: Batch #140 - Loss: 0.8419179320335388\n",
      "Ep 69: Batch #141 - Loss: 1.1193196773529053\n",
      "Ep 69: Batch #142 - Loss: 0.6713197231292725\n",
      "Ep 69: Batch #143 - Loss: 0.7710552215576172\n",
      "Ep 69: Batch #144 - Loss: 0.6119220852851868\n",
      "Ep 69: Batch #145 - Loss: 0.5981530547142029\n",
      "Ep 69: Batch #146 - Loss: 0.698006808757782\n",
      "Ep 69: Batch #147 - Loss: 0.661899745464325\n",
      "Ep 69: Batch #148 - Loss: 0.7527681589126587\n",
      "Ep 69: Batch #149 - Loss: 0.6142231225967407\n",
      "Ep 69: Batch #150 - Loss: 0.7199669480323792\n",
      "Ep 69: Batch #151 - Loss: 0.6263224482536316\n",
      "Ep 69: Batch #152 - Loss: 0.6071513891220093\n",
      "Ep 69: Batch #153 - Loss: 0.826170802116394\n",
      "Ep 69: Batch #154 - Loss: 0.6318379640579224\n",
      "Ep 69: Batch #155 - Loss: 0.6902274489402771\n",
      "Ep 69: Batch #156 - Loss: 0.779019832611084\n",
      "Ep 69: Batch #157 - Loss: 0.6125569939613342\n",
      "Ep 69: Batch #158 - Loss: 0.7177674770355225\n",
      "Ep 69: Batch #159 - Loss: 0.5969331860542297\n",
      "Ep 69: Batch #160 - Loss: 0.6922823190689087\n",
      "Ep 69: Batch #161 - Loss: 0.6691526770591736\n",
      "Ep 69: Batch #162 - Loss: 0.7193132638931274\n",
      "Ep 69: Batch #163 - Loss: 0.7596461772918701\n",
      "Ep 69: Batch #164 - Loss: 0.6475662589073181\n",
      "Ep 69: Batch #165 - Loss: 1.3377183675765991\n",
      "Ep 69: Batch #166 - Loss: 0.5343325734138489\n",
      "Ep 69: Batch #167 - Loss: 0.7078339457511902\n",
      "Ep 69: Batch #168 - Loss: 0.6926971077919006\n",
      "Ep 69: Batch #169 - Loss: 0.6664510369300842\n",
      "Ep 69: Batch #170 - Loss: 0.6272428035736084\n",
      "Ep 69: Batch #171 - Loss: 0.6408199667930603\n",
      "Ep 69: Batch #172 - Loss: 0.5339382290840149\n",
      "Ep 69: Batch #173 - Loss: 0.9285835027694702\n",
      "Ep 69: Batch #174 - Loss: 0.4946993887424469\n",
      "Ep 69: Batch #175 - Loss: 0.6345438957214355\n",
      "Ep 69: Batch #176 - Loss: 0.8964769840240479\n",
      "Ep 69: Batch #177 - Loss: 0.6486048698425293\n",
      "Ep 69: Batch #178 - Loss: 0.6220909357070923\n",
      "Ep 69: Batch #179 - Loss: 0.7454861402511597\n",
      "Ep 69: Batch #180 - Loss: 0.6490350365638733\n",
      "Ep 69: Batch #181 - Loss: 0.8012974262237549\n",
      "Ep 69: Batch #182 - Loss: 0.6287829875946045\n",
      "Ep 69: Batch #183 - Loss: 0.6056183576583862\n",
      "Ep 69: Batch #184 - Loss: 0.9196128249168396\n",
      "Ep 69: Batch #185 - Loss: 0.6331417560577393\n",
      "Ep 69: Batch #186 - Loss: 0.7516388893127441\n",
      "Ep 69: Batch #187 - Loss: 0.8667044043540955\n",
      "Ep 69: Batch #188 - Loss: 0.941184937953949\n",
      "Ep 69: Batch #189 - Loss: 0.586763858795166\n",
      "Ep 69: Batch #190 - Loss: 0.6214526891708374\n",
      "Ep 69: Batch #191 - Loss: 0.8023046255111694\n",
      "Ep 69: Batch #192 - Loss: 0.5712621808052063\n",
      "Ep 69: Batch #193 - Loss: 0.6309628486633301\n",
      "Ep 69: Batch #194 - Loss: 0.5424748063087463\n",
      "Ep 69: Batch #195 - Loss: 0.783568799495697\n",
      "Ep 69: Batch #196 - Loss: 0.6931103467941284\n",
      "Ep 69: Batch #197 - Loss: 0.6999333500862122\n",
      "Ep 69: Batch #198 - Loss: 0.5336147546768188\n",
      "Ep 69: Batch #199 - Loss: 0.6433292627334595\n",
      "Ep 70: Batch #0 - Loss: 0.651409924030304\n",
      "Ep 70: Batch #1 - Loss: 0.7167614102363586\n",
      "Ep 70: Batch #2 - Loss: 0.8609131574630737\n",
      "Ep 70: Batch #3 - Loss: 0.721129298210144\n",
      "Ep 70: Batch #4 - Loss: 0.6574025750160217\n",
      "Ep 70: Batch #5 - Loss: 0.553395688533783\n",
      "Ep 70: Batch #6 - Loss: 0.7344340085983276\n",
      "Ep 70: Batch #7 - Loss: 0.5759461522102356\n",
      "Ep 70: Batch #8 - Loss: 0.5849477648735046\n",
      "Ep 70: Batch #9 - Loss: 1.0936615467071533\n",
      "Ep 70: Batch #10 - Loss: 0.7972917556762695\n",
      "Ep 70: Batch #11 - Loss: 0.5442434549331665\n",
      "Ep 70: Batch #12 - Loss: 1.1975390911102295\n",
      "Ep 70: Batch #13 - Loss: 0.571493923664093\n",
      "Ep 70: Batch #14 - Loss: 0.5985074639320374\n",
      "Ep 70: Batch #15 - Loss: 0.8440188765525818\n",
      "Ep 70: Batch #16 - Loss: 0.9549105167388916\n",
      "Ep 70: Batch #17 - Loss: 0.7315842509269714\n",
      "Ep 70: Batch #18 - Loss: 0.8090298771858215\n",
      "Ep 70: Batch #19 - Loss: 0.5638084411621094\n",
      "Ep 70: Batch #20 - Loss: 0.546065628528595\n",
      "Ep 70: Batch #21 - Loss: 0.8027625679969788\n",
      "Ep 70: Batch #22 - Loss: 0.6073211431503296\n",
      "Ep 70: Batch #23 - Loss: 0.6000813245773315\n",
      "Ep 70: Batch #24 - Loss: 0.6395229697227478\n",
      "Ep 70: Batch #25 - Loss: 0.6062737703323364\n",
      "Ep 70: Batch #26 - Loss: 0.5558544993400574\n",
      "Ep 70: Batch #27 - Loss: 1.1397308111190796\n",
      "Ep 70: Batch #28 - Loss: 0.6930378675460815\n",
      "Ep 70: Batch #29 - Loss: 0.7533856630325317\n",
      "Ep 70: Batch #30 - Loss: 0.8233550190925598\n",
      "Ep 70: Batch #31 - Loss: 0.5617537498474121\n",
      "Ep 70: Batch #32 - Loss: 0.581122636795044\n",
      "Ep 70: Batch #33 - Loss: 0.6667112112045288\n",
      "Ep 70: Batch #34 - Loss: 0.6365266442298889\n",
      "Ep 70: Batch #35 - Loss: 0.7242345213890076\n",
      "Ep 70: Batch #36 - Loss: 0.5849839448928833\n",
      "Ep 70: Batch #37 - Loss: 0.9209033846855164\n",
      "Ep 70: Batch #38 - Loss: 0.5681585669517517\n",
      "Ep 70: Batch #39 - Loss: 0.6869644522666931\n",
      "Ep 70: Batch #40 - Loss: 0.6045722961425781\n",
      "Ep 70: Batch #41 - Loss: 0.61966472864151\n",
      "Ep 70: Batch #42 - Loss: 0.5702493190765381\n",
      "Ep 70: Batch #43 - Loss: 0.632763683795929\n",
      "Ep 70: Batch #44 - Loss: 0.6129551529884338\n",
      "Ep 70: Batch #45 - Loss: 0.5243294835090637\n",
      "Ep 70: Batch #46 - Loss: 0.6971918940544128\n",
      "Ep 70: Batch #47 - Loss: 0.8036283254623413\n",
      "Ep 70: Batch #48 - Loss: 1.0439882278442383\n",
      "Ep 70: Batch #49 - Loss: 0.8099478483200073\n",
      "Ep 70: Batch #50 - Loss: 0.5738885998725891\n",
      "Ep 70: Batch #51 - Loss: 0.816974401473999\n",
      "Ep 70: Batch #52 - Loss: 0.6759968996047974\n",
      "Ep 70: Batch #53 - Loss: 0.7148792147636414\n",
      "Ep 70: Batch #54 - Loss: 0.5781230926513672\n",
      "Ep 70: Batch #55 - Loss: 0.6109890341758728\n",
      "Ep 70: Batch #56 - Loss: 0.8584862351417542\n",
      "Ep 70: Batch #57 - Loss: 0.6821476221084595\n",
      "Ep 70: Batch #58 - Loss: 0.8266873359680176\n",
      "Ep 70: Batch #59 - Loss: 0.5574135184288025\n",
      "Ep 70: Batch #60 - Loss: 1.0080820322036743\n",
      "Ep 70: Batch #61 - Loss: 0.5354411602020264\n",
      "Ep 70: Batch #62 - Loss: 0.5744531750679016\n",
      "Ep 70: Batch #63 - Loss: 0.7799072265625\n",
      "Ep 70: Batch #64 - Loss: 8.169589042663574\n",
      "Ep 70: Batch #65 - Loss: 0.5239372253417969\n",
      "Ep 70: Batch #66 - Loss: 0.6641920804977417\n",
      "Ep 70: Batch #67 - Loss: 0.7760879397392273\n",
      "Ep 70: Batch #68 - Loss: 0.712791919708252\n",
      "Ep 70: Batch #69 - Loss: 0.5868998169898987\n",
      "Ep 70: Batch #70 - Loss: 0.6155338287353516\n",
      "Ep 70: Batch #71 - Loss: 0.5355321764945984\n",
      "Ep 70: Batch #72 - Loss: 0.6626378893852234\n",
      "Ep 70: Batch #73 - Loss: 0.7201647758483887\n",
      "Ep 70: Batch #74 - Loss: 0.5765570402145386\n",
      "Ep 70: Batch #75 - Loss: 0.666615903377533\n",
      "Ep 70: Batch #76 - Loss: 0.9238874912261963\n",
      "Ep 70: Batch #77 - Loss: 0.5754952430725098\n",
      "Ep 70: Batch #78 - Loss: 0.9178045392036438\n",
      "Ep 70: Batch #79 - Loss: 0.5252932906150818\n",
      "Ep 70: Batch #80 - Loss: 0.6913023591041565\n",
      "Ep 70: Batch #81 - Loss: 1.5251628160476685\n",
      "Ep 70: Batch #82 - Loss: 0.7529687285423279\n",
      "Ep 70: Batch #83 - Loss: 1.225042700767517\n",
      "Ep 70: Batch #84 - Loss: 0.5782451629638672\n",
      "Ep 70: Batch #85 - Loss: 0.7843801975250244\n",
      "Ep 70: Batch #86 - Loss: 0.5475506782531738\n",
      "Ep 70: Batch #87 - Loss: 0.572066605091095\n",
      "Ep 70: Batch #88 - Loss: 0.6573826670646667\n",
      "Ep 70: Batch #89 - Loss: 0.7274025678634644\n",
      "Ep 70: Batch #90 - Loss: 0.9015674591064453\n",
      "Ep 70: Batch #91 - Loss: 0.649956464767456\n",
      "Ep 70: Batch #92 - Loss: 0.7310348153114319\n",
      "Ep 70: Batch #93 - Loss: 0.7830221652984619\n",
      "Ep 70: Batch #94 - Loss: 0.7459577918052673\n",
      "Ep 70: Batch #95 - Loss: 0.7609120011329651\n",
      "Ep 70: Batch #96 - Loss: 0.7590605020523071\n",
      "Ep 70: Batch #97 - Loss: 0.5875857472419739\n",
      "Ep 70: Batch #98 - Loss: 0.578170895576477\n",
      "Ep 70: Batch #99 - Loss: 0.7943825721740723\n",
      "Ep 70: Batch #100 - Loss: 0.5577033758163452\n",
      "Ep 70: Batch #101 - Loss: 0.8690553903579712\n",
      "Ep 70: Batch #102 - Loss: 0.6125844120979309\n",
      "Ep 70: Batch #103 - Loss: 0.635745644569397\n",
      "Ep 70: Batch #104 - Loss: 0.6613169312477112\n",
      "Ep 70: Batch #105 - Loss: 0.8183371424674988\n",
      "Ep 70: Batch #106 - Loss: 0.6262932419776917\n",
      "Ep 70: Batch #107 - Loss: 0.6153929233551025\n",
      "Ep 70: Batch #108 - Loss: 0.9007067680358887\n",
      "Ep 70: Batch #109 - Loss: 0.6267786622047424\n",
      "Ep 70: Batch #110 - Loss: 0.7257034182548523\n",
      "Ep 70: Batch #111 - Loss: 1.0407902002334595\n",
      "Ep 70: Batch #112 - Loss: 0.7919357419013977\n",
      "Ep 70: Batch #113 - Loss: 0.6578580737113953\n",
      "Ep 70: Batch #114 - Loss: 0.7262855768203735\n",
      "Ep 70: Batch #115 - Loss: 0.9098082184791565\n",
      "Ep 70: Batch #116 - Loss: 0.5219770073890686\n",
      "Ep 70: Batch #117 - Loss: 0.6786765456199646\n",
      "Ep 70: Batch #118 - Loss: 0.45460274815559387\n",
      "Ep 70: Batch #119 - Loss: 0.8080160617828369\n",
      "Ep 70: Batch #120 - Loss: 0.6586101055145264\n",
      "Ep 70: Batch #121 - Loss: 0.5612297654151917\n",
      "Ep 70: Batch #122 - Loss: 0.7097927331924438\n",
      "Ep 70: Batch #123 - Loss: 0.7156754732131958\n",
      "Ep 70: Batch #124 - Loss: 0.556888222694397\n",
      "Ep 70: Batch #125 - Loss: 2.4756455421447754\n",
      "Ep 70: Batch #126 - Loss: 1.0058062076568604\n",
      "Ep 70: Batch #127 - Loss: 0.58256995677948\n",
      "Ep 70: Batch #128 - Loss: 0.8863329291343689\n",
      "Ep 70: Batch #129 - Loss: 0.6788631081581116\n",
      "Ep 70: Batch #130 - Loss: 0.5956323742866516\n",
      "Ep 70: Batch #131 - Loss: 0.8035485148429871\n",
      "Ep 70: Batch #132 - Loss: 0.6839805841445923\n",
      "Ep 70: Batch #133 - Loss: 0.6666973233222961\n",
      "Ep 70: Batch #134 - Loss: 0.6371802687644958\n",
      "Ep 70: Batch #135 - Loss: 0.822298526763916\n",
      "Ep 70: Batch #136 - Loss: 1.0432618856430054\n",
      "Ep 70: Batch #137 - Loss: 0.7558757662773132\n",
      "Ep 70: Batch #138 - Loss: 0.901762843132019\n",
      "Ep 70: Batch #139 - Loss: 0.6746149063110352\n",
      "Ep 70: Batch #140 - Loss: 0.8419625759124756\n",
      "Ep 70: Batch #141 - Loss: 1.1193331480026245\n",
      "Ep 70: Batch #142 - Loss: 0.6718063950538635\n",
      "Ep 70: Batch #143 - Loss: 0.7711498141288757\n",
      "Ep 70: Batch #144 - Loss: 0.6118075847625732\n",
      "Ep 70: Batch #145 - Loss: 0.5982046723365784\n",
      "Ep 70: Batch #146 - Loss: 0.6977735757827759\n",
      "Ep 70: Batch #147 - Loss: 0.6620169281959534\n",
      "Ep 70: Batch #148 - Loss: 0.7528911232948303\n",
      "Ep 70: Batch #149 - Loss: 0.6141648292541504\n",
      "Ep 70: Batch #150 - Loss: 0.7199155688285828\n",
      "Ep 70: Batch #151 - Loss: 0.6262640357017517\n",
      "Ep 70: Batch #152 - Loss: 0.6070773005485535\n",
      "Ep 70: Batch #153 - Loss: 0.8264299631118774\n",
      "Ep 70: Batch #154 - Loss: 0.6326001882553101\n",
      "Ep 70: Batch #155 - Loss: 0.6905014514923096\n",
      "Ep 70: Batch #156 - Loss: 0.7785000205039978\n",
      "Ep 70: Batch #157 - Loss: 0.6125048995018005\n",
      "Ep 70: Batch #158 - Loss: 0.7177896499633789\n",
      "Ep 70: Batch #159 - Loss: 0.5969316363334656\n",
      "Ep 70: Batch #160 - Loss: 0.6920925378799438\n",
      "Ep 70: Batch #161 - Loss: 0.6692288517951965\n",
      "Ep 70: Batch #162 - Loss: 0.7189204096794128\n",
      "Ep 70: Batch #163 - Loss: 0.7595574259757996\n",
      "Ep 70: Batch #164 - Loss: 0.6477009654045105\n",
      "Ep 70: Batch #165 - Loss: 1.339640736579895\n",
      "Ep 70: Batch #166 - Loss: 0.5343663692474365\n",
      "Ep 70: Batch #167 - Loss: 0.7077035307884216\n",
      "Ep 70: Batch #168 - Loss: 0.6928985714912415\n",
      "Ep 70: Batch #169 - Loss: 0.6664295792579651\n",
      "Ep 70: Batch #170 - Loss: 0.627768874168396\n",
      "Ep 70: Batch #171 - Loss: 0.6414068937301636\n",
      "Ep 70: Batch #172 - Loss: 0.5339077115058899\n",
      "Ep 70: Batch #173 - Loss: 0.9298732280731201\n",
      "Ep 70: Batch #174 - Loss: 0.49449560046195984\n",
      "Ep 70: Batch #175 - Loss: 0.6349132061004639\n",
      "Ep 70: Batch #176 - Loss: 0.8969153165817261\n",
      "Ep 70: Batch #177 - Loss: 0.64863121509552\n",
      "Ep 70: Batch #178 - Loss: 0.622136652469635\n",
      "Ep 70: Batch #179 - Loss: 0.7453160285949707\n",
      "Ep 70: Batch #180 - Loss: 0.649080753326416\n",
      "Ep 70: Batch #181 - Loss: 0.8017534613609314\n",
      "Ep 70: Batch #182 - Loss: 0.6291166543960571\n",
      "Ep 70: Batch #183 - Loss: 0.6056578159332275\n",
      "Ep 70: Batch #184 - Loss: 0.9200225472450256\n",
      "Ep 70: Batch #185 - Loss: 0.6340678930282593\n",
      "Ep 70: Batch #186 - Loss: 0.7522239685058594\n",
      "Ep 70: Batch #187 - Loss: 0.8681020140647888\n",
      "Ep 70: Batch #188 - Loss: 0.939677357673645\n",
      "Ep 70: Batch #189 - Loss: 0.5871348977088928\n",
      "Ep 70: Batch #190 - Loss: 0.6224612593650818\n",
      "Ep 70: Batch #191 - Loss: 0.802405834197998\n",
      "Ep 70: Batch #192 - Loss: 0.571618378162384\n",
      "Ep 70: Batch #193 - Loss: 0.6311588883399963\n",
      "Ep 70: Batch #194 - Loss: 0.5426591038703918\n",
      "Ep 70: Batch #195 - Loss: 0.7842674851417542\n",
      "Ep 70: Batch #196 - Loss: 0.6933609247207642\n",
      "Ep 70: Batch #197 - Loss: 0.700023889541626\n",
      "Ep 70: Batch #198 - Loss: 0.5337130427360535\n",
      "Ep 70: Batch #199 - Loss: 0.6432790160179138\n",
      "Ep 71: Batch #0 - Loss: 0.6517953872680664\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 71: Batch #1 - Loss: 0.7168765664100647\n",
      "Ep 71: Batch #2 - Loss: 0.8614293932914734\n",
      "Ep 71: Batch #3 - Loss: 0.7212657332420349\n",
      "Ep 71: Batch #4 - Loss: 0.657636821269989\n",
      "Ep 71: Batch #5 - Loss: 0.5536815524101257\n",
      "Ep 71: Batch #6 - Loss: 0.7347943186759949\n",
      "Ep 71: Batch #7 - Loss: 0.5760323405265808\n",
      "Ep 71: Batch #8 - Loss: 0.584867000579834\n",
      "Ep 71: Batch #9 - Loss: 1.093390703201294\n",
      "Ep 71: Batch #10 - Loss: 0.7961859703063965\n",
      "Ep 71: Batch #11 - Loss: 0.5443521738052368\n",
      "Ep 71: Batch #12 - Loss: 1.1972321271896362\n",
      "Ep 71: Batch #13 - Loss: 0.5716593861579895\n",
      "Ep 71: Batch #14 - Loss: 0.5985817909240723\n",
      "Ep 71: Batch #15 - Loss: 0.8442696928977966\n",
      "Ep 71: Batch #16 - Loss: 0.9548437595367432\n",
      "Ep 71: Batch #17 - Loss: 0.731589138507843\n",
      "Ep 71: Batch #18 - Loss: 0.8091582655906677\n",
      "Ep 71: Batch #19 - Loss: 0.5638594627380371\n",
      "Ep 71: Batch #20 - Loss: 0.5462175011634827\n",
      "Ep 71: Batch #21 - Loss: 0.8019288182258606\n",
      "Ep 71: Batch #22 - Loss: 0.6072748303413391\n",
      "Ep 71: Batch #23 - Loss: 0.6001107096672058\n",
      "Ep 71: Batch #24 - Loss: 0.6396650075912476\n",
      "Ep 71: Batch #25 - Loss: 0.6062363386154175\n",
      "Ep 71: Batch #26 - Loss: 0.5559565424919128\n",
      "Ep 71: Batch #27 - Loss: 1.1398690938949585\n",
      "Ep 71: Batch #28 - Loss: 0.6930559277534485\n",
      "Ep 71: Batch #29 - Loss: 0.7536273002624512\n",
      "Ep 71: Batch #30 - Loss: 0.8228384852409363\n",
      "Ep 71: Batch #31 - Loss: 0.5619926452636719\n",
      "Ep 71: Batch #32 - Loss: 0.5809820294380188\n",
      "Ep 71: Batch #33 - Loss: 0.6664573550224304\n",
      "Ep 71: Batch #34 - Loss: 0.636446475982666\n",
      "Ep 71: Batch #35 - Loss: 0.7241491079330444\n",
      "Ep 71: Batch #36 - Loss: 0.5850476622581482\n",
      "Ep 71: Batch #37 - Loss: 0.9210323095321655\n",
      "Ep 71: Batch #38 - Loss: 0.5684159994125366\n",
      "Ep 71: Batch #39 - Loss: 0.6867202520370483\n",
      "Ep 71: Batch #40 - Loss: 0.6045103669166565\n",
      "Ep 71: Batch #41 - Loss: 0.6199501752853394\n",
      "Ep 71: Batch #42 - Loss: 0.5702266097068787\n",
      "Ep 71: Batch #43 - Loss: 0.6331764459609985\n",
      "Ep 71: Batch #44 - Loss: 0.6129531860351562\n",
      "Ep 71: Batch #45 - Loss: 0.5243631601333618\n",
      "Ep 71: Batch #46 - Loss: 0.6974095106124878\n",
      "Ep 71: Batch #47 - Loss: 0.8037469983100891\n",
      "Ep 71: Batch #48 - Loss: 1.043768286705017\n",
      "Ep 71: Batch #49 - Loss: 0.8095808625221252\n",
      "Ep 71: Batch #50 - Loss: 0.5737693905830383\n",
      "Ep 71: Batch #51 - Loss: 0.8170406818389893\n",
      "Ep 71: Batch #52 - Loss: 0.6759400963783264\n",
      "Ep 71: Batch #53 - Loss: 0.7149394154548645\n",
      "Ep 71: Batch #54 - Loss: 0.577955424785614\n",
      "Ep 71: Batch #55 - Loss: 0.6113867163658142\n",
      "Ep 71: Batch #56 - Loss: 0.8588706254959106\n",
      "Ep 71: Batch #57 - Loss: 0.6821545958518982\n",
      "Ep 71: Batch #58 - Loss: 0.8263635635375977\n",
      "Ep 71: Batch #59 - Loss: 0.5571694374084473\n",
      "Ep 71: Batch #60 - Loss: 1.0078901052474976\n",
      "Ep 71: Batch #61 - Loss: 0.5353165864944458\n",
      "Ep 71: Batch #62 - Loss: 0.5744690299034119\n",
      "Ep 71: Batch #63 - Loss: 0.7796919345855713\n",
      "Ep 71: Batch #64 - Loss: 8.155181884765625\n",
      "Ep 71: Batch #65 - Loss: 0.5238271951675415\n",
      "Ep 71: Batch #66 - Loss: 0.6646156907081604\n",
      "Ep 71: Batch #67 - Loss: 0.7760130763053894\n",
      "Ep 71: Batch #68 - Loss: 0.7128733992576599\n",
      "Ep 71: Batch #69 - Loss: 0.5866473913192749\n",
      "Ep 71: Batch #70 - Loss: 0.6151865720748901\n",
      "Ep 71: Batch #71 - Loss: 0.5356497168540955\n",
      "Ep 71: Batch #72 - Loss: 0.6623658537864685\n",
      "Ep 71: Batch #73 - Loss: 0.7200074791908264\n",
      "Ep 71: Batch #74 - Loss: 0.5764462947845459\n",
      "Ep 71: Batch #75 - Loss: 0.6666527390480042\n",
      "Ep 71: Batch #76 - Loss: 0.9236894249916077\n",
      "Ep 71: Batch #77 - Loss: 0.5758453607559204\n",
      "Ep 71: Batch #78 - Loss: 0.9176524877548218\n",
      "Ep 71: Batch #79 - Loss: 0.5252365469932556\n",
      "Ep 71: Batch #80 - Loss: 0.6911770105361938\n",
      "Ep 71: Batch #81 - Loss: 1.527937889099121\n",
      "Ep 71: Batch #82 - Loss: 0.7532300353050232\n",
      "Ep 71: Batch #83 - Loss: 1.222808837890625\n",
      "Ep 71: Batch #84 - Loss: 0.5778934359550476\n",
      "Ep 71: Batch #85 - Loss: 0.7848047018051147\n",
      "Ep 71: Batch #86 - Loss: 0.5474632382392883\n",
      "Ep 71: Batch #87 - Loss: 0.5716407895088196\n",
      "Ep 71: Batch #88 - Loss: 0.6565372347831726\n",
      "Ep 71: Batch #89 - Loss: 0.726796567440033\n",
      "Ep 71: Batch #90 - Loss: 0.9011225700378418\n",
      "Ep 71: Batch #91 - Loss: 0.6499214172363281\n",
      "Ep 71: Batch #92 - Loss: 0.7304844856262207\n",
      "Ep 71: Batch #93 - Loss: 0.7828778624534607\n",
      "Ep 71: Batch #94 - Loss: 0.7450084090232849\n",
      "Ep 71: Batch #95 - Loss: 0.7608283162117004\n",
      "Ep 71: Batch #96 - Loss: 0.7573117613792419\n",
      "Ep 71: Batch #97 - Loss: 0.5879722833633423\n",
      "Ep 71: Batch #98 - Loss: 0.5779736042022705\n",
      "Ep 71: Batch #99 - Loss: 0.7931103706359863\n",
      "Ep 71: Batch #100 - Loss: 0.5577914714813232\n",
      "Ep 71: Batch #101 - Loss: 0.8688649535179138\n",
      "Ep 71: Batch #102 - Loss: 0.6121060848236084\n",
      "Ep 71: Batch #103 - Loss: 0.635259747505188\n",
      "Ep 71: Batch #104 - Loss: 0.6605900526046753\n",
      "Ep 71: Batch #105 - Loss: 0.8177648782730103\n",
      "Ep 71: Batch #106 - Loss: 0.6259910464286804\n",
      "Ep 71: Batch #107 - Loss: 0.6151320338249207\n",
      "Ep 71: Batch #108 - Loss: 0.901130735874176\n",
      "Ep 71: Batch #109 - Loss: 0.626214325428009\n",
      "Ep 71: Batch #110 - Loss: 0.7237597107887268\n",
      "Ep 71: Batch #111 - Loss: 1.0394128561019897\n",
      "Ep 71: Batch #112 - Loss: 0.7918590307235718\n",
      "Ep 71: Batch #113 - Loss: 0.6572311520576477\n",
      "Ep 71: Batch #114 - Loss: 0.7254367470741272\n",
      "Ep 71: Batch #115 - Loss: 0.9099640846252441\n",
      "Ep 71: Batch #116 - Loss: 0.5216056108474731\n",
      "Ep 71: Batch #117 - Loss: 0.6780958771705627\n",
      "Ep 71: Batch #118 - Loss: 0.4543420076370239\n",
      "Ep 71: Batch #119 - Loss: 0.8089156150817871\n",
      "Ep 71: Batch #120 - Loss: 0.6589475274085999\n",
      "Ep 71: Batch #121 - Loss: 0.5604296922683716\n",
      "Ep 71: Batch #122 - Loss: 0.7094241380691528\n",
      "Ep 71: Batch #123 - Loss: 0.7152732610702515\n",
      "Ep 71: Batch #124 - Loss: 0.5565271973609924\n",
      "Ep 71: Batch #125 - Loss: 2.4748523235321045\n",
      "Ep 71: Batch #126 - Loss: 1.005426049232483\n",
      "Ep 71: Batch #127 - Loss: 0.5823232531547546\n",
      "Ep 71: Batch #128 - Loss: 0.8862950205802917\n",
      "Ep 71: Batch #129 - Loss: 0.6772958040237427\n",
      "Ep 71: Batch #130 - Loss: 0.5953055620193481\n",
      "Ep 71: Batch #131 - Loss: 0.8016016483306885\n",
      "Ep 71: Batch #132 - Loss: 0.6832366585731506\n",
      "Ep 71: Batch #133 - Loss: 0.6666180491447449\n",
      "Ep 71: Batch #134 - Loss: 0.6371076107025146\n",
      "Ep 71: Batch #135 - Loss: 0.821832001209259\n",
      "Ep 71: Batch #136 - Loss: 1.0429015159606934\n",
      "Ep 71: Batch #137 - Loss: 0.7550041079521179\n",
      "Ep 71: Batch #138 - Loss: 0.9018885493278503\n",
      "Ep 71: Batch #139 - Loss: 0.6767712235450745\n",
      "Ep 71: Batch #140 - Loss: 0.8417116403579712\n",
      "Ep 71: Batch #141 - Loss: 1.1178648471832275\n",
      "Ep 71: Batch #142 - Loss: 0.6712231636047363\n",
      "Ep 71: Batch #143 - Loss: 0.770696759223938\n",
      "Ep 71: Batch #144 - Loss: 0.6117933392524719\n",
      "Ep 71: Batch #145 - Loss: 0.5980125069618225\n",
      "Ep 71: Batch #146 - Loss: 0.6974757313728333\n",
      "Ep 71: Batch #147 - Loss: 0.6619540452957153\n",
      "Ep 71: Batch #148 - Loss: 0.7523921728134155\n",
      "Ep 71: Batch #149 - Loss: 0.6140692830085754\n",
      "Ep 71: Batch #150 - Loss: 0.7199374437332153\n",
      "Ep 71: Batch #151 - Loss: 0.6261249780654907\n",
      "Ep 71: Batch #152 - Loss: 0.6071911454200745\n",
      "Ep 71: Batch #153 - Loss: 0.8257579207420349\n",
      "Ep 71: Batch #154 - Loss: 0.6319875121116638\n",
      "Ep 71: Batch #155 - Loss: 0.6899467706680298\n",
      "Ep 71: Batch #156 - Loss: 0.778374433517456\n",
      "Ep 71: Batch #157 - Loss: 0.6126253604888916\n",
      "Ep 71: Batch #158 - Loss: 0.7176438570022583\n",
      "Ep 71: Batch #159 - Loss: 0.5968721508979797\n",
      "Ep 71: Batch #160 - Loss: 0.6918342113494873\n",
      "Ep 71: Batch #161 - Loss: 0.6690014600753784\n",
      "Ep 71: Batch #162 - Loss: 0.7186204195022583\n",
      "Ep 71: Batch #163 - Loss: 0.759736955165863\n",
      "Ep 71: Batch #164 - Loss: 0.6476263403892517\n",
      "Ep 71: Batch #165 - Loss: 1.3377126455307007\n",
      "Ep 71: Batch #166 - Loss: 0.5345086455345154\n",
      "Ep 71: Batch #167 - Loss: 0.70737224817276\n",
      "Ep 71: Batch #168 - Loss: 0.6926157474517822\n",
      "Ep 71: Batch #169 - Loss: 0.666700005531311\n",
      "Ep 71: Batch #170 - Loss: 0.6274681091308594\n",
      "Ep 71: Batch #171 - Loss: 0.6410983800888062\n",
      "Ep 71: Batch #172 - Loss: 0.534064531326294\n",
      "Ep 71: Batch #173 - Loss: 0.9285608530044556\n",
      "Ep 71: Batch #174 - Loss: 0.4950234293937683\n",
      "Ep 71: Batch #175 - Loss: 0.6351751685142517\n",
      "Ep 71: Batch #176 - Loss: 0.896228551864624\n",
      "Ep 71: Batch #177 - Loss: 0.648327648639679\n",
      "Ep 71: Batch #178 - Loss: 0.6220982074737549\n",
      "Ep 71: Batch #179 - Loss: 0.7451571226119995\n",
      "Ep 71: Batch #180 - Loss: 0.6490879058837891\n",
      "Ep 71: Batch #181 - Loss: 0.8010736703872681\n",
      "Ep 71: Batch #182 - Loss: 0.6289170384407043\n",
      "Ep 71: Batch #183 - Loss: 0.6054452657699585\n",
      "Ep 71: Batch #184 - Loss: 0.9194502830505371\n",
      "Ep 71: Batch #185 - Loss: 0.6331601738929749\n",
      "Ep 71: Batch #186 - Loss: 0.7512941956520081\n",
      "Ep 71: Batch #187 - Loss: 0.8661785125732422\n",
      "Ep 71: Batch #188 - Loss: 0.9391709566116333\n",
      "Ep 71: Batch #189 - Loss: 0.5865423679351807\n",
      "Ep 71: Batch #190 - Loss: 0.621717631816864\n",
      "Ep 71: Batch #191 - Loss: 0.8019603490829468\n",
      "Ep 71: Batch #192 - Loss: 0.5716164708137512\n",
      "Ep 71: Batch #193 - Loss: 0.6309394836425781\n",
      "Ep 71: Batch #194 - Loss: 0.5423548817634583\n",
      "Ep 71: Batch #195 - Loss: 0.783479630947113\n",
      "Ep 71: Batch #196 - Loss: 0.6933150887489319\n",
      "Ep 71: Batch #197 - Loss: 0.6997649073600769\n",
      "Ep 71: Batch #198 - Loss: 0.5336140394210815\n",
      "Ep 71: Batch #199 - Loss: 0.6432046890258789\n",
      "Ep 72: Batch #0 - Loss: 0.6512430906295776\n",
      "Ep 72: Batch #1 - Loss: 0.7168968915939331\n",
      "Ep 72: Batch #2 - Loss: 0.8606776595115662\n",
      "Ep 72: Batch #3 - Loss: 0.7208026051521301\n",
      "Ep 72: Batch #4 - Loss: 0.6574792265892029\n",
      "Ep 72: Batch #5 - Loss: 0.553112804889679\n",
      "Ep 72: Batch #6 - Loss: 0.7341510057449341\n",
      "Ep 72: Batch #7 - Loss: 0.5760036706924438\n",
      "Ep 72: Batch #8 - Loss: 0.5848230719566345\n",
      "Ep 72: Batch #9 - Loss: 1.0928311347961426\n",
      "Ep 72: Batch #10 - Loss: 0.7962942719459534\n",
      "Ep 72: Batch #11 - Loss: 0.5441388487815857\n",
      "Ep 72: Batch #12 - Loss: 1.1966569423675537\n",
      "Ep 72: Batch #13 - Loss: 0.5714762806892395\n",
      "Ep 72: Batch #14 - Loss: 0.5984830856323242\n",
      "Ep 72: Batch #15 - Loss: 0.8432825207710266\n",
      "Ep 72: Batch #16 - Loss: 0.955636203289032\n",
      "Ep 72: Batch #17 - Loss: 0.7313451170921326\n",
      "Ep 72: Batch #18 - Loss: 0.809300422668457\n",
      "Ep 72: Batch #19 - Loss: 0.563652515411377\n",
      "Ep 72: Batch #20 - Loss: 0.5462457537651062\n",
      "Ep 72: Batch #21 - Loss: 0.8007507920265198\n",
      "Ep 72: Batch #22 - Loss: 0.6077607870101929\n",
      "Ep 72: Batch #23 - Loss: 0.5999974608421326\n",
      "Ep 72: Batch #24 - Loss: 0.6398828029632568\n",
      "Ep 72: Batch #25 - Loss: 0.6059568524360657\n",
      "Ep 72: Batch #26 - Loss: 0.5557881593704224\n",
      "Ep 72: Batch #27 - Loss: 1.1392203569412231\n",
      "Ep 72: Batch #28 - Loss: 0.6927388906478882\n",
      "Ep 72: Batch #29 - Loss: 0.7534075975418091\n",
      "Ep 72: Batch #30 - Loss: 0.8229143023490906\n",
      "Ep 72: Batch #31 - Loss: 0.5619035959243774\n",
      "Ep 72: Batch #32 - Loss: 0.5809245705604553\n",
      "Ep 72: Batch #33 - Loss: 0.6669906973838806\n",
      "Ep 72: Batch #34 - Loss: 0.6363353729248047\n",
      "Ep 72: Batch #35 - Loss: 0.7241928577423096\n",
      "Ep 72: Batch #36 - Loss: 0.5851854681968689\n",
      "Ep 72: Batch #37 - Loss: 0.9208351373672485\n",
      "Ep 72: Batch #38 - Loss: 0.5682708024978638\n",
      "Ep 72: Batch #39 - Loss: 0.6866462826728821\n",
      "Ep 72: Batch #40 - Loss: 0.604457437992096\n",
      "Ep 72: Batch #41 - Loss: 0.6195718050003052\n",
      "Ep 72: Batch #42 - Loss: 0.5701054334640503\n",
      "Ep 72: Batch #43 - Loss: 0.6332233548164368\n",
      "Ep 72: Batch #44 - Loss: 0.613024115562439\n",
      "Ep 72: Batch #45 - Loss: 0.5243197083473206\n",
      "Ep 72: Batch #46 - Loss: 0.6974332928657532\n",
      "Ep 72: Batch #47 - Loss: 0.8035339117050171\n",
      "Ep 72: Batch #48 - Loss: 1.04457688331604\n",
      "Ep 72: Batch #49 - Loss: 0.8092758655548096\n",
      "Ep 72: Batch #50 - Loss: 0.5737048983573914\n",
      "Ep 72: Batch #51 - Loss: 0.8170021176338196\n",
      "Ep 72: Batch #52 - Loss: 0.6760150194168091\n",
      "Ep 72: Batch #53 - Loss: 0.7148118615150452\n",
      "Ep 72: Batch #54 - Loss: 0.5780590176582336\n",
      "Ep 72: Batch #55 - Loss: 0.6114528179168701\n",
      "Ep 72: Batch #56 - Loss: 0.8585506081581116\n",
      "Ep 72: Batch #57 - Loss: 0.6819392442703247\n",
      "Ep 72: Batch #58 - Loss: 0.8265113234519958\n",
      "Ep 72: Batch #59 - Loss: 0.5569819211959839\n",
      "Ep 72: Batch #60 - Loss: 1.00785493850708\n",
      "Ep 72: Batch #61 - Loss: 0.5354411602020264\n",
      "Ep 72: Batch #62 - Loss: 0.5744730830192566\n",
      "Ep 72: Batch #63 - Loss: 0.7795812487602234\n",
      "Ep 72: Batch #64 - Loss: 8.142718315124512\n",
      "Ep 72: Batch #65 - Loss: 0.5239987969398499\n",
      "Ep 72: Batch #66 - Loss: 0.6640902757644653\n",
      "Ep 72: Batch #67 - Loss: 0.7760778665542603\n",
      "Ep 72: Batch #68 - Loss: 0.7128666639328003\n",
      "Ep 72: Batch #69 - Loss: 0.5870071649551392\n",
      "Ep 72: Batch #70 - Loss: 0.6156508922576904\n",
      "Ep 72: Batch #71 - Loss: 0.5357472896575928\n",
      "Ep 72: Batch #72 - Loss: 0.6627903580665588\n",
      "Ep 72: Batch #73 - Loss: 0.7200832366943359\n",
      "Ep 72: Batch #74 - Loss: 0.5765506029129028\n",
      "Ep 72: Batch #75 - Loss: 0.6664632558822632\n",
      "Ep 72: Batch #76 - Loss: 0.9236368536949158\n",
      "Ep 72: Batch #77 - Loss: 0.5753543972969055\n",
      "Ep 72: Batch #78 - Loss: 0.9175031781196594\n",
      "Ep 72: Batch #79 - Loss: 0.5252149105072021\n",
      "Ep 72: Batch #80 - Loss: 0.6910960078239441\n",
      "Ep 72: Batch #81 - Loss: 1.522508144378662\n",
      "Ep 72: Batch #82 - Loss: 0.7531186938285828\n",
      "Ep 72: Batch #83 - Loss: 1.2210363149642944\n",
      "Ep 72: Batch #84 - Loss: 0.5779871940612793\n",
      "Ep 72: Batch #85 - Loss: 0.784908652305603\n",
      "Ep 72: Batch #86 - Loss: 0.5472486019134521\n",
      "Ep 72: Batch #87 - Loss: 0.5716887712478638\n",
      "Ep 72: Batch #88 - Loss: 0.6563214063644409\n",
      "Ep 72: Batch #89 - Loss: 0.7265812158584595\n",
      "Ep 72: Batch #90 - Loss: 0.9012863636016846\n",
      "Ep 72: Batch #91 - Loss: 0.6498124599456787\n",
      "Ep 72: Batch #92 - Loss: 0.7306638360023499\n",
      "Ep 72: Batch #93 - Loss: 0.7825623154640198\n",
      "Ep 72: Batch #94 - Loss: 0.7448543310165405\n",
      "Ep 72: Batch #95 - Loss: 0.7607990503311157\n",
      "Ep 72: Batch #96 - Loss: 0.7568564414978027\n",
      "Ep 72: Batch #97 - Loss: 0.5874665975570679\n",
      "Ep 72: Batch #98 - Loss: 0.5774484276771545\n",
      "Ep 72: Batch #99 - Loss: 0.7920263409614563\n",
      "Ep 72: Batch #100 - Loss: 0.5575488805770874\n",
      "Ep 72: Batch #101 - Loss: 0.8688541054725647\n",
      "Ep 72: Batch #102 - Loss: 0.6118752956390381\n",
      "Ep 72: Batch #103 - Loss: 0.6350899338722229\n",
      "Ep 72: Batch #104 - Loss: 0.6606882214546204\n",
      "Ep 72: Batch #105 - Loss: 0.8183508515357971\n",
      "Ep 72: Batch #106 - Loss: 0.6258449554443359\n",
      "Ep 72: Batch #107 - Loss: 0.6150113940238953\n",
      "Ep 72: Batch #108 - Loss: 0.9011858701705933\n",
      "Ep 72: Batch #109 - Loss: 0.6261880397796631\n",
      "Ep 72: Batch #110 - Loss: 0.7240031361579895\n",
      "Ep 72: Batch #111 - Loss: 1.0402679443359375\n",
      "Ep 72: Batch #112 - Loss: 0.7908515930175781\n",
      "Ep 72: Batch #113 - Loss: 0.6573383808135986\n",
      "Ep 72: Batch #114 - Loss: 0.725128710269928\n",
      "Ep 72: Batch #115 - Loss: 0.9098789691925049\n",
      "Ep 72: Batch #116 - Loss: 0.5215098261833191\n",
      "Ep 72: Batch #117 - Loss: 0.6783419847488403\n",
      "Ep 72: Batch #118 - Loss: 0.4542812705039978\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved in file: ./weights_autoencoder_sigmoid/model_e72b118_1516648801.156577.ckpt\n",
      "Ep 72: Batch #119 - Loss: 0.8086523413658142\n",
      "Ep 72: Batch #120 - Loss: 0.6587139964103699\n",
      "Ep 72: Batch #121 - Loss: 0.5605198740959167\n",
      "Ep 72: Batch #122 - Loss: 0.709331214427948\n",
      "Ep 72: Batch #123 - Loss: 0.7151845097541809\n",
      "Ep 72: Batch #124 - Loss: 0.5566027164459229\n",
      "Ep 72: Batch #125 - Loss: 2.4744231700897217\n",
      "Ep 72: Batch #126 - Loss: 1.0059031248092651\n",
      "Ep 72: Batch #127 - Loss: 0.5821789503097534\n",
      "Ep 72: Batch #128 - Loss: 0.886433482170105\n",
      "Ep 72: Batch #129 - Loss: 0.678074061870575\n",
      "Ep 72: Batch #130 - Loss: 0.5952833294868469\n",
      "Ep 72: Batch #131 - Loss: 0.8019326329231262\n",
      "Ep 72: Batch #132 - Loss: 0.683366596698761\n",
      "Ep 72: Batch #133 - Loss: 0.6665468215942383\n",
      "Ep 72: Batch #134 - Loss: 0.6370114684104919\n",
      "Ep 72: Batch #135 - Loss: 0.8217653632164001\n",
      "Ep 72: Batch #136 - Loss: 1.0430526733398438\n",
      "Ep 72: Batch #137 - Loss: 0.7550963759422302\n",
      "Ep 72: Batch #138 - Loss: 0.9016115069389343\n",
      "Ep 72: Batch #139 - Loss: 0.6744478344917297\n",
      "Ep 72: Batch #140 - Loss: 0.8414137959480286\n",
      "Ep 72: Batch #141 - Loss: 1.1180293560028076\n",
      "Ep 72: Batch #142 - Loss: 0.6715700626373291\n",
      "Ep 72: Batch #143 - Loss: 0.7708590626716614\n",
      "Ep 72: Batch #144 - Loss: 0.611838161945343\n",
      "Ep 72: Batch #145 - Loss: 0.5980356335639954\n",
      "Ep 72: Batch #146 - Loss: 0.6975939273834229\n",
      "Ep 72: Batch #147 - Loss: 0.6617609858512878\n",
      "Ep 72: Batch #148 - Loss: 0.7525125741958618\n",
      "Ep 72: Batch #149 - Loss: 0.6132798194885254\n",
      "Ep 72: Batch #150 - Loss: 0.7197046875953674\n",
      "Ep 72: Batch #151 - Loss: 0.6259545683860779\n",
      "Ep 72: Batch #152 - Loss: 0.6069637537002563\n",
      "Ep 72: Batch #153 - Loss: 0.8260085582733154\n",
      "Ep 72: Batch #154 - Loss: 0.6320595145225525\n",
      "Ep 72: Batch #155 - Loss: 0.6899901032447815\n",
      "Ep 72: Batch #156 - Loss: 0.7780648469924927\n",
      "Ep 72: Batch #157 - Loss: 0.6126117706298828\n",
      "Ep 72: Batch #158 - Loss: 0.7175916433334351\n",
      "Ep 72: Batch #159 - Loss: 0.5967976450920105\n",
      "Ep 72: Batch #160 - Loss: 0.6917163729667664\n",
      "Ep 72: Batch #161 - Loss: 0.668859601020813\n",
      "Ep 72: Batch #162 - Loss: 0.7189300060272217\n",
      "Ep 72: Batch #163 - Loss: 0.7599738240242004\n",
      "Ep 72: Batch #164 - Loss: 0.6475170254707336\n",
      "Ep 72: Batch #165 - Loss: 1.3375005722045898\n",
      "Ep 72: Batch #166 - Loss: 0.5342400074005127\n",
      "Ep 72: Batch #167 - Loss: 0.7063431143760681\n",
      "Ep 72: Batch #168 - Loss: 0.6926161050796509\n",
      "Ep 72: Batch #169 - Loss: 0.6664785742759705\n",
      "Ep 72: Batch #170 - Loss: 0.6272996664047241\n",
      "Ep 72: Batch #171 - Loss: 0.641282856464386\n",
      "Ep 72: Batch #172 - Loss: 0.5338329076766968\n",
      "Ep 72: Batch #173 - Loss: 0.9286324977874756\n",
      "Ep 72: Batch #174 - Loss: 0.494655579328537\n",
      "Ep 72: Batch #175 - Loss: 0.6345911026000977\n",
      "Ep 72: Batch #176 - Loss: 0.8965684771537781\n",
      "Ep 72: Batch #177 - Loss: 0.6481888890266418\n",
      "Ep 72: Batch #178 - Loss: 0.6217474937438965\n",
      "Ep 72: Batch #179 - Loss: 0.7448115944862366\n",
      "Ep 72: Batch #180 - Loss: 0.6488572359085083\n",
      "Ep 72: Batch #181 - Loss: 0.8012180328369141\n",
      "Ep 72: Batch #182 - Loss: 0.6290078163146973\n",
      "Ep 72: Batch #183 - Loss: 0.6052669286727905\n",
      "Ep 72: Batch #184 - Loss: 0.9192705750465393\n",
      "Ep 72: Batch #185 - Loss: 0.6331757307052612\n",
      "Ep 72: Batch #186 - Loss: 0.7509210109710693\n",
      "Ep 72: Batch #187 - Loss: 0.866828203201294\n",
      "Ep 72: Batch #188 - Loss: 0.9385277628898621\n",
      "Ep 72: Batch #189 - Loss: 0.5865735411643982\n",
      "Ep 72: Batch #190 - Loss: 0.621562659740448\n",
      "Ep 72: Batch #191 - Loss: 0.8018588423728943\n",
      "Ep 72: Batch #192 - Loss: 0.5717476606369019\n",
      "Ep 72: Batch #193 - Loss: 0.6308466792106628\n",
      "Ep 72: Batch #194 - Loss: 0.5422250032424927\n",
      "Ep 72: Batch #195 - Loss: 0.7834567427635193\n",
      "Ep 72: Batch #196 - Loss: 0.6933664679527283\n",
      "Ep 72: Batch #197 - Loss: 0.699667751789093\n",
      "Ep 72: Batch #198 - Loss: 0.533713698387146\n",
      "Ep 72: Batch #199 - Loss: 0.6431905627250671\n",
      "Ep 73: Batch #0 - Loss: 0.6514391303062439\n",
      "Ep 73: Batch #1 - Loss: 0.7169608473777771\n",
      "Ep 73: Batch #2 - Loss: 0.8609581589698792\n",
      "Ep 73: Batch #3 - Loss: 0.7209349870681763\n",
      "Ep 73: Batch #4 - Loss: 0.6575451493263245\n",
      "Ep 73: Batch #5 - Loss: 0.5529571771621704\n",
      "Ep 73: Batch #6 - Loss: 0.7338266372680664\n",
      "Ep 73: Batch #7 - Loss: 0.5758208632469177\n",
      "Ep 73: Batch #8 - Loss: 0.5845944285392761\n",
      "Ep 73: Batch #9 - Loss: 1.0929250717163086\n",
      "Ep 73: Batch #10 - Loss: 0.7959423661231995\n",
      "Ep 73: Batch #11 - Loss: 0.5442270636558533\n",
      "Ep 73: Batch #12 - Loss: 1.1959394216537476\n",
      "Ep 73: Batch #13 - Loss: 0.5715609788894653\n",
      "Ep 73: Batch #14 - Loss: 0.5982434749603271\n",
      "Ep 73: Batch #15 - Loss: 0.8429449796676636\n",
      "Ep 73: Batch #16 - Loss: 0.9553117752075195\n",
      "Ep 73: Batch #17 - Loss: 0.7317086458206177\n",
      "Ep 73: Batch #18 - Loss: 0.8094147443771362\n",
      "Ep 73: Batch #19 - Loss: 0.5637523531913757\n",
      "Ep 73: Batch #20 - Loss: 0.5461868643760681\n",
      "Ep 73: Batch #21 - Loss: 0.8001324534416199\n",
      "Ep 73: Batch #22 - Loss: 0.6073970794677734\n",
      "Ep 73: Batch #23 - Loss: 0.6000920534133911\n",
      "Ep 73: Batch #24 - Loss: 0.6399670243263245\n",
      "Ep 73: Batch #25 - Loss: 0.6059191226959229\n",
      "Ep 73: Batch #26 - Loss: 0.5557907223701477\n",
      "Ep 73: Batch #27 - Loss: 1.1392533779144287\n",
      "Ep 73: Batch #28 - Loss: 0.6932574510574341\n",
      "Ep 73: Batch #29 - Loss: 0.7536185383796692\n",
      "Ep 73: Batch #30 - Loss: 0.8220359683036804\n",
      "Ep 73: Batch #31 - Loss: 0.5619443655014038\n",
      "Ep 73: Batch #32 - Loss: 0.5808725357055664\n",
      "Ep 73: Batch #33 - Loss: 0.6667653918266296\n",
      "Ep 73: Batch #34 - Loss: 0.6361198425292969\n",
      "Ep 73: Batch #35 - Loss: 0.7242377996444702\n",
      "Ep 73: Batch #36 - Loss: 0.5851678848266602\n",
      "Ep 73: Batch #37 - Loss: 0.9209896922111511\n",
      "Ep 73: Batch #38 - Loss: 0.568202555179596\n",
      "Ep 73: Batch #39 - Loss: 0.6868112087249756\n",
      "Ep 73: Batch #40 - Loss: 0.6043475866317749\n",
      "Ep 73: Batch #41 - Loss: 0.6196004152297974\n",
      "Ep 73: Batch #42 - Loss: 0.5699969530105591\n",
      "Ep 73: Batch #43 - Loss: 0.6332218647003174\n",
      "Ep 73: Batch #44 - Loss: 0.612902045249939\n",
      "Ep 73: Batch #45 - Loss: 0.5242201089859009\n",
      "Ep 73: Batch #46 - Loss: 0.6973869800567627\n",
      "Ep 73: Batch #47 - Loss: 0.8035885691642761\n",
      "Ep 73: Batch #48 - Loss: 1.0446256399154663\n",
      "Ep 73: Batch #49 - Loss: 0.8089830279350281\n",
      "Ep 73: Batch #50 - Loss: 0.5737280249595642\n",
      "Ep 73: Batch #51 - Loss: 0.8169592618942261\n",
      "Ep 73: Batch #52 - Loss: 0.6759692430496216\n",
      "Ep 73: Batch #53 - Loss: 0.714697003364563\n",
      "Ep 73: Batch #54 - Loss: 0.5779146552085876\n",
      "Ep 73: Batch #55 - Loss: 0.6113008260726929\n",
      "Ep 73: Batch #56 - Loss: 0.8587374687194824\n",
      "Ep 73: Batch #57 - Loss: 0.6819060444831848\n",
      "Ep 73: Batch #58 - Loss: 0.8264096975326538\n",
      "Ep 73: Batch #59 - Loss: 0.5569807887077332\n",
      "Ep 73: Batch #60 - Loss: 1.007660984992981\n",
      "Ep 73: Batch #61 - Loss: 0.535444974899292\n",
      "Ep 73: Batch #62 - Loss: 0.5744135975837708\n",
      "Ep 73: Batch #63 - Loss: 0.7796270847320557\n",
      "Ep 73: Batch #64 - Loss: 8.128536224365234\n",
      "Ep 73: Batch #65 - Loss: 0.5239543914794922\n",
      "Ep 73: Batch #66 - Loss: 0.664079487323761\n",
      "Ep 73: Batch #67 - Loss: 0.7759566307067871\n",
      "Ep 73: Batch #68 - Loss: 0.7129563689231873\n",
      "Ep 73: Batch #69 - Loss: 0.5867778658866882\n",
      "Ep 73: Batch #70 - Loss: 0.6155430674552917\n",
      "Ep 73: Batch #71 - Loss: 0.5354974865913391\n",
      "Ep 73: Batch #72 - Loss: 0.6627775430679321\n",
      "Ep 73: Batch #73 - Loss: 0.7200142741203308\n",
      "Ep 73: Batch #74 - Loss: 0.5764654874801636\n",
      "Ep 73: Batch #75 - Loss: 0.6664251685142517\n",
      "Ep 73: Batch #76 - Loss: 0.9234718084335327\n",
      "Ep 73: Batch #77 - Loss: 0.575230598449707\n",
      "Ep 73: Batch #78 - Loss: 0.9173180460929871\n",
      "Ep 73: Batch #79 - Loss: 0.5252241492271423\n",
      "Ep 73: Batch #80 - Loss: 0.6909162402153015\n",
      "Ep 73: Batch #81 - Loss: 1.5251178741455078\n",
      "Ep 73: Batch #82 - Loss: 0.7532996535301208\n",
      "Ep 73: Batch #83 - Loss: 1.2182538509368896\n",
      "Ep 73: Batch #84 - Loss: 0.5781232118606567\n",
      "Ep 73: Batch #85 - Loss: 0.7840976119041443\n",
      "Ep 73: Batch #86 - Loss: 0.547311544418335\n",
      "Ep 73: Batch #87 - Loss: 0.5716909766197205\n",
      "Ep 73: Batch #88 - Loss: 0.6566981673240662\n",
      "Ep 73: Batch #89 - Loss: 0.7267630100250244\n",
      "Ep 73: Batch #90 - Loss: 0.901731014251709\n",
      "Ep 73: Batch #91 - Loss: 0.6499758362770081\n",
      "Ep 73: Batch #92 - Loss: 0.7307383418083191\n",
      "Ep 73: Batch #93 - Loss: 0.7828582525253296\n",
      "Ep 73: Batch #94 - Loss: 0.7452318668365479\n",
      "Ep 73: Batch #95 - Loss: 0.7608097791671753\n",
      "Ep 73: Batch #96 - Loss: 0.7584936022758484\n",
      "Ep 73: Batch #97 - Loss: 0.5874937176704407\n",
      "Ep 73: Batch #98 - Loss: 0.5780017971992493\n",
      "Ep 73: Batch #99 - Loss: 0.7939375042915344\n",
      "Ep 73: Batch #100 - Loss: 0.5576004385948181\n",
      "Ep 73: Batch #101 - Loss: 0.869044840335846\n",
      "Ep 73: Batch #102 - Loss: 0.6121434569358826\n",
      "Ep 73: Batch #103 - Loss: 0.6353612542152405\n",
      "Ep 73: Batch #104 - Loss: 0.661041796207428\n",
      "Ep 73: Batch #105 - Loss: 0.8185292482376099\n",
      "Ep 73: Batch #106 - Loss: 0.6260996460914612\n",
      "Ep 73: Batch #107 - Loss: 0.6152195334434509\n",
      "Ep 73: Batch #108 - Loss: 0.9010969996452332\n",
      "Ep 73: Batch #109 - Loss: 0.6263590455055237\n",
      "Ep 73: Batch #110 - Loss: 0.7252611517906189\n",
      "Ep 73: Batch #111 - Loss: 1.040554404258728\n",
      "Ep 73: Batch #112 - Loss: 0.7905290722846985\n",
      "Ep 73: Batch #113 - Loss: 0.6577885746955872\n",
      "Ep 73: Batch #114 - Loss: 0.7257280349731445\n",
      "Ep 73: Batch #115 - Loss: 0.9100812673568726\n",
      "Ep 73: Batch #116 - Loss: 0.5217682123184204\n",
      "Ep 73: Batch #117 - Loss: 0.6785858869552612\n",
      "Ep 73: Batch #118 - Loss: 0.4543333649635315\n",
      "Ep 73: Batch #119 - Loss: 0.8076419830322266\n",
      "Ep 73: Batch #120 - Loss: 0.6585964560508728\n",
      "Ep 73: Batch #121 - Loss: 0.5609762072563171\n",
      "Ep 73: Batch #122 - Loss: 0.7095260620117188\n",
      "Ep 73: Batch #123 - Loss: 0.7149168252944946\n",
      "Ep 73: Batch #124 - Loss: 0.5566360354423523\n",
      "Ep 73: Batch #125 - Loss: 2.4755635261535645\n",
      "Ep 73: Batch #126 - Loss: 1.0063360929489136\n",
      "Ep 73: Batch #127 - Loss: 0.5824251770973206\n",
      "Ep 73: Batch #128 - Loss: 0.8867117166519165\n",
      "Ep 73: Batch #129 - Loss: 0.6779479384422302\n",
      "Ep 73: Batch #130 - Loss: 0.5955739617347717\n",
      "Ep 73: Batch #131 - Loss: 0.8025921583175659\n",
      "Ep 73: Batch #132 - Loss: 0.6836652755737305\n",
      "Ep 73: Batch #133 - Loss: 0.666530430316925\n",
      "Ep 73: Batch #134 - Loss: 0.6374093294143677\n",
      "Ep 73: Batch #135 - Loss: 0.8219329118728638\n",
      "Ep 73: Batch #136 - Loss: 1.0431885719299316\n",
      "Ep 73: Batch #137 - Loss: 0.756187915802002\n",
      "Ep 73: Batch #138 - Loss: 0.9017522931098938\n",
      "Ep 73: Batch #139 - Loss: 0.6745696067810059\n",
      "Ep 73: Batch #140 - Loss: 0.841533362865448\n",
      "Ep 73: Batch #141 - Loss: 1.1179991960525513\n",
      "Ep 73: Batch #142 - Loss: 0.6718566417694092\n",
      "Ep 73: Batch #143 - Loss: 0.7712056040763855\n",
      "Ep 73: Batch #144 - Loss: 0.6118434071540833\n",
      "Ep 73: Batch #145 - Loss: 0.5979636311531067\n",
      "Ep 73: Batch #146 - Loss: 0.6978184580802917\n",
      "Ep 73: Batch #147 - Loss: 0.6619726419448853\n",
      "Ep 73: Batch #148 - Loss: 0.7528526782989502\n",
      "Ep 73: Batch #149 - Loss: 0.6136593222618103\n",
      "Ep 73: Batch #150 - Loss: 0.7197496891021729\n",
      "Ep 73: Batch #151 - Loss: 0.6260174512863159\n",
      "Ep 73: Batch #152 - Loss: 0.6069723963737488\n",
      "Ep 73: Batch #153 - Loss: 0.8262209892272949\n",
      "Ep 73: Batch #154 - Loss: 0.6327417492866516\n",
      "Ep 73: Batch #155 - Loss: 0.6899771690368652\n",
      "Ep 73: Batch #156 - Loss: 0.7775905728340149\n",
      "Ep 73: Batch #157 - Loss: 0.6124318838119507\n",
      "Ep 73: Batch #158 - Loss: 0.7176546454429626\n",
      "Ep 73: Batch #159 - Loss: 0.5968053936958313\n",
      "Ep 73: Batch #160 - Loss: 0.6914125680923462\n",
      "Ep 73: Batch #161 - Loss: 0.6690602898597717\n",
      "Ep 73: Batch #162 - Loss: 0.7190952897071838\n",
      "Ep 73: Batch #163 - Loss: 0.7597547769546509\n",
      "Ep 73: Batch #164 - Loss: 0.6477117538452148\n",
      "Ep 73: Batch #165 - Loss: 1.3394732475280762\n",
      "Ep 73: Batch #166 - Loss: 0.5343571901321411\n",
      "Ep 73: Batch #167 - Loss: 0.7060412764549255\n",
      "Ep 73: Batch #168 - Loss: 0.6929843425750732\n",
      "Ep 73: Batch #169 - Loss: 0.666240394115448\n",
      "Ep 73: Batch #170 - Loss: 0.6278117895126343\n",
      "Ep 73: Batch #171 - Loss: 0.641480565071106\n",
      "Ep 73: Batch #172 - Loss: 0.5338152050971985\n",
      "Ep 73: Batch #173 - Loss: 0.9296273589134216\n",
      "Ep 73: Batch #174 - Loss: 0.49462568759918213\n",
      "Ep 73: Batch #175 - Loss: 0.6345783472061157\n",
      "Ep 73: Batch #176 - Loss: 0.896859347820282\n",
      "Ep 73: Batch #177 - Loss: 0.648272693157196\n",
      "Ep 73: Batch #178 - Loss: 0.6219189167022705\n",
      "Ep 73: Batch #179 - Loss: 0.7449055910110474\n",
      "Ep 73: Batch #180 - Loss: 0.6485214233398438\n",
      "Ep 73: Batch #181 - Loss: 0.8015505075454712\n",
      "Ep 73: Batch #182 - Loss: 0.6293356418609619\n",
      "Ep 73: Batch #183 - Loss: 0.6053271293640137\n",
      "Ep 73: Batch #184 - Loss: 0.9195378422737122\n",
      "Ep 73: Batch #185 - Loss: 0.6340070366859436\n",
      "Ep 73: Batch #186 - Loss: 0.7513218522071838\n",
      "Ep 73: Batch #187 - Loss: 0.8672316074371338\n",
      "Ep 73: Batch #188 - Loss: 0.9373852014541626\n",
      "Ep 73: Batch #189 - Loss: 0.586799681186676\n",
      "Ep 73: Batch #190 - Loss: 0.6219354867935181\n",
      "Ep 73: Batch #191 - Loss: 0.8013014197349548\n",
      "Ep 73: Batch #192 - Loss: 0.5715827345848083\n",
      "Ep 73: Batch #193 - Loss: 0.6310278177261353\n",
      "Ep 73: Batch #194 - Loss: 0.5422384738922119\n",
      "Ep 73: Batch #195 - Loss: 0.7829844355583191\n",
      "Ep 73: Batch #196 - Loss: 0.6933236718177795\n",
      "Ep 73: Batch #197 - Loss: 0.699278712272644\n",
      "Ep 73: Batch #198 - Loss: 0.5337939858436584\n",
      "Ep 73: Batch #199 - Loss: 0.6431569457054138\n",
      "Ep 74: Batch #0 - Loss: 0.6517165303230286\n",
      "Ep 74: Batch #1 - Loss: 0.7169613242149353\n",
      "Ep 74: Batch #2 - Loss: 0.861243724822998\n",
      "Ep 74: Batch #3 - Loss: 0.7210299372673035\n",
      "Ep 74: Batch #4 - Loss: 0.6576499342918396\n",
      "Ep 74: Batch #5 - Loss: 0.5527896881103516\n",
      "Ep 74: Batch #6 - Loss: 0.7340292930603027\n",
      "Ep 74: Batch #7 - Loss: 0.5761326551437378\n",
      "Ep 74: Batch #8 - Loss: 0.5846706628799438\n",
      "Ep 74: Batch #9 - Loss: 1.0930224657058716\n",
      "Ep 74: Batch #10 - Loss: 0.7953236699104309\n",
      "Ep 74: Batch #11 - Loss: 0.544292688369751\n",
      "Ep 74: Batch #12 - Loss: 1.1956732273101807\n",
      "Ep 74: Batch #13 - Loss: 0.5716268420219421\n",
      "Ep 74: Batch #14 - Loss: 0.5982192158699036\n",
      "Ep 74: Batch #15 - Loss: 0.8428419828414917\n",
      "Ep 74: Batch #16 - Loss: 0.9552465081214905\n",
      "Ep 74: Batch #17 - Loss: 0.7316116690635681\n",
      "Ep 74: Batch #18 - Loss: 0.8092415928840637\n",
      "Ep 74: Batch #19 - Loss: 0.5636746883392334\n",
      "Ep 74: Batch #20 - Loss: 0.5462505221366882\n",
      "Ep 74: Batch #21 - Loss: 0.7991715669631958\n",
      "Ep 74: Batch #22 - Loss: 0.6072748899459839\n",
      "Ep 74: Batch #23 - Loss: 0.599997341632843\n",
      "Ep 74: Batch #24 - Loss: 0.63993901014328\n",
      "Ep 74: Batch #25 - Loss: 0.6058314442634583\n",
      "Ep 74: Batch #26 - Loss: 0.5558342337608337\n",
      "Ep 74: Batch #27 - Loss: 1.1390173435211182\n",
      "Ep 74: Batch #28 - Loss: 0.6928951144218445\n",
      "Ep 74: Batch #29 - Loss: 0.7534662485122681\n",
      "Ep 74: Batch #30 - Loss: 0.8214210271835327\n",
      "Ep 74: Batch #31 - Loss: 0.561858594417572\n",
      "Ep 74: Batch #32 - Loss: 0.5806624889373779\n",
      "Ep 74: Batch #33 - Loss: 0.6666541695594788\n",
      "Ep 74: Batch #34 - Loss: 0.6359775066375732\n",
      "Ep 74: Batch #35 - Loss: 0.7243725061416626\n",
      "Ep 74: Batch #36 - Loss: 0.5851122736930847\n",
      "Ep 74: Batch #37 - Loss: 0.9210075736045837\n",
      "Ep 74: Batch #38 - Loss: 0.5681704878807068\n",
      "Ep 74: Batch #39 - Loss: 0.6868234872817993\n",
      "Ep 74: Batch #40 - Loss: 0.6041907668113708\n",
      "Ep 74: Batch #41 - Loss: 0.6197097301483154\n",
      "Ep 74: Batch #42 - Loss: 0.5698625445365906\n",
      "Ep 74: Batch #43 - Loss: 0.6331871747970581\n",
      "Ep 74: Batch #44 - Loss: 0.6129031181335449\n",
      "Ep 74: Batch #45 - Loss: 0.5241908431053162\n",
      "Ep 74: Batch #46 - Loss: 0.6973087787628174\n",
      "Ep 74: Batch #47 - Loss: 0.8033783435821533\n",
      "Ep 74: Batch #48 - Loss: 1.0448904037475586\n",
      "Ep 74: Batch #49 - Loss: 0.8086562156677246\n",
      "Ep 74: Batch #50 - Loss: 0.5737156867980957\n",
      "Ep 74: Batch #51 - Loss: 0.8170833587646484\n",
      "Ep 74: Batch #52 - Loss: 0.6759553551673889\n",
      "Ep 74: Batch #53 - Loss: 0.7145116925239563\n",
      "Ep 74: Batch #54 - Loss: 0.5777621865272522\n",
      "Ep 74: Batch #55 - Loss: 0.6113334894180298\n",
      "Ep 74: Batch #56 - Loss: 0.8590548038482666\n",
      "Ep 74: Batch #57 - Loss: 0.681837260723114\n",
      "Ep 74: Batch #58 - Loss: 0.8256637454032898\n",
      "Ep 74: Batch #59 - Loss: 0.5570198893547058\n",
      "Ep 74: Batch #60 - Loss: 1.0070827007293701\n",
      "Ep 74: Batch #61 - Loss: 0.535301685333252\n",
      "Ep 74: Batch #62 - Loss: 0.5743955969810486\n",
      "Ep 74: Batch #63 - Loss: 0.7795411944389343\n",
      "Ep 74: Batch #64 - Loss: 8.114460945129395\n",
      "Ep 74: Batch #65 - Loss: 0.5237336754798889\n",
      "Ep 74: Batch #66 - Loss: 0.6647034287452698\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 74: Batch #67 - Loss: 0.7758762240409851\n",
      "Ep 74: Batch #68 - Loss: 0.7128459215164185\n",
      "Ep 74: Batch #69 - Loss: 0.5865566730499268\n",
      "Ep 74: Batch #70 - Loss: 0.6151321530342102\n",
      "Ep 74: Batch #71 - Loss: 0.5354731678962708\n",
      "Ep 74: Batch #72 - Loss: 0.662797212600708\n",
      "Ep 74: Batch #73 - Loss: 0.7198062539100647\n",
      "Ep 74: Batch #74 - Loss: 0.5765033960342407\n",
      "Ep 74: Batch #75 - Loss: 0.6665588617324829\n",
      "Ep 74: Batch #76 - Loss: 0.923231303691864\n",
      "Ep 74: Batch #77 - Loss: 0.5759931206703186\n",
      "Ep 74: Batch #78 - Loss: 0.9170385599136353\n",
      "Ep 74: Batch #79 - Loss: 0.5250585675239563\n",
      "Ep 74: Batch #80 - Loss: 0.6906861066818237\n",
      "Ep 74: Batch #81 - Loss: 1.5261151790618896\n",
      "Ep 74: Batch #82 - Loss: 0.7537839412689209\n",
      "Ep 74: Batch #83 - Loss: 1.2159137725830078\n",
      "Ep 74: Batch #84 - Loss: 0.5777168273925781\n",
      "Ep 74: Batch #85 - Loss: 0.7843382954597473\n",
      "Ep 74: Batch #86 - Loss: 0.5473785400390625\n",
      "Ep 74: Batch #87 - Loss: 0.5714457631111145\n",
      "Ep 74: Batch #88 - Loss: 0.6558427214622498\n",
      "Ep 74: Batch #89 - Loss: 0.7262954711914062\n",
      "Ep 74: Batch #90 - Loss: 0.9015098214149475\n",
      "Ep 74: Batch #91 - Loss: 0.6500205993652344\n",
      "Ep 74: Batch #92 - Loss: 0.7304035425186157\n",
      "Ep 74: Batch #93 - Loss: 0.7827165126800537\n",
      "Ep 74: Batch #94 - Loss: 0.7445724606513977\n",
      "Ep 74: Batch #95 - Loss: 0.7607713937759399\n",
      "Ep 74: Batch #96 - Loss: 0.7566787600517273\n",
      "Ep 74: Batch #97 - Loss: 0.5878363847732544\n",
      "Ep 74: Batch #98 - Loss: 0.5776936411857605\n",
      "Ep 74: Batch #99 - Loss: 0.7922651767730713\n",
      "Ep 74: Batch #100 - Loss: 0.5576592683792114\n",
      "Ep 74: Batch #101 - Loss: 0.8690976500511169\n",
      "Ep 74: Batch #102 - Loss: 0.6118895411491394\n",
      "Ep 74: Batch #103 - Loss: 0.6348735690116882\n",
      "Ep 74: Batch #104 - Loss: 0.6604952216148376\n",
      "Ep 74: Batch #105 - Loss: 0.8184517621994019\n",
      "Ep 74: Batch #106 - Loss: 0.6259648203849792\n",
      "Ep 74: Batch #107 - Loss: 0.6151357889175415\n",
      "Ep 74: Batch #108 - Loss: 0.9014467597007751\n",
      "Ep 74: Batch #109 - Loss: 0.6259258985519409\n",
      "Ep 74: Batch #110 - Loss: 0.7237463593482971\n",
      "Ep 74: Batch #111 - Loss: 1.0392274856567383\n",
      "Ep 74: Batch #112 - Loss: 0.7903227210044861\n",
      "Ep 74: Batch #113 - Loss: 0.6571962237358093\n",
      "Ep 74: Batch #114 - Loss: 0.7252076268196106\n",
      "Ep 74: Batch #115 - Loss: 0.9100538492202759\n",
      "Ep 74: Batch #116 - Loss: 0.5213835835456848\n",
      "Ep 74: Batch #117 - Loss: 0.6780811548233032\n",
      "Ep 74: Batch #118 - Loss: 0.45425671339035034\n",
      "Model saved in file: ./weights_autoencoder_sigmoid/model_e74b118_1516648801.4076843.ckpt\n",
      "Ep 74: Batch #119 - Loss: 0.8084617853164673\n",
      "Ep 74: Batch #120 - Loss: 0.6586613655090332\n",
      "Ep 74: Batch #121 - Loss: 0.5604921579360962\n",
      "Ep 74: Batch #122 - Loss: 0.7093814015388489\n",
      "Ep 74: Batch #123 - Loss: 0.7153640985488892\n",
      "Ep 74: Batch #124 - Loss: 0.5563988089561462\n",
      "Ep 74: Batch #125 - Loss: 2.4745311737060547\n",
      "Ep 74: Batch #126 - Loss: 1.0058715343475342\n",
      "Ep 74: Batch #127 - Loss: 0.5818650126457214\n",
      "Ep 74: Batch #128 - Loss: 0.8865503668785095\n",
      "Ep 74: Batch #129 - Loss: 0.6774346232414246\n",
      "Ep 74: Batch #130 - Loss: 0.5950091481208801\n",
      "Ep 74: Batch #131 - Loss: 0.8010686039924622\n",
      "Ep 74: Batch #132 - Loss: 0.683059811592102\n",
      "Ep 74: Batch #133 - Loss: 0.6664689183235168\n",
      "Ep 74: Batch #134 - Loss: 0.6369375586509705\n",
      "Ep 74: Batch #135 - Loss: 0.8215280175209045\n",
      "Ep 74: Batch #136 - Loss: 1.0428986549377441\n",
      "Ep 74: Batch #137 - Loss: 0.7549269795417786\n",
      "Ep 74: Batch #138 - Loss: 0.9016532301902771\n",
      "Ep 74: Batch #139 - Loss: 0.6748590469360352\n",
      "Ep 74: Batch #140 - Loss: 0.8412157297134399\n",
      "Ep 74: Batch #141 - Loss: 1.1171542406082153\n",
      "Ep 74: Batch #142 - Loss: 0.6711480021476746\n",
      "Ep 74: Batch #143 - Loss: 0.7704640030860901\n",
      "Ep 74: Batch #144 - Loss: 0.611754298210144\n",
      "Ep 74: Batch #145 - Loss: 0.597813069820404\n",
      "Ep 74: Batch #146 - Loss: 0.6974712610244751\n",
      "Ep 74: Batch #147 - Loss: 0.6620107889175415\n",
      "Ep 74: Batch #148 - Loss: 0.752386748790741\n",
      "Ep 74: Batch #149 - Loss: 0.6131252646446228\n",
      "Ep 74: Batch #150 - Loss: 0.7195533514022827\n",
      "Ep 74: Batch #151 - Loss: 0.6254920363426208\n",
      "Ep 74: Batch #152 - Loss: 0.6070342659950256\n",
      "Ep 74: Batch #153 - Loss: 0.8256803154945374\n",
      "Ep 74: Batch #154 - Loss: 0.6321807503700256\n",
      "Ep 74: Batch #155 - Loss: 0.6896896958351135\n",
      "Ep 74: Batch #156 - Loss: 0.7775017619132996\n",
      "Ep 74: Batch #157 - Loss: 0.6123085618019104\n",
      "Ep 74: Batch #158 - Loss: 0.71762615442276\n",
      "Ep 74: Batch #159 - Loss: 0.5965563654899597\n",
      "Ep 74: Batch #160 - Loss: 0.6912121772766113\n",
      "Ep 74: Batch #161 - Loss: 0.6687844395637512\n",
      "Ep 74: Batch #162 - Loss: 0.718707263469696\n",
      "Ep 74: Batch #163 - Loss: 0.7598068714141846\n",
      "Ep 74: Batch #164 - Loss: 0.647406280040741\n",
      "Ep 74: Batch #165 - Loss: 1.3379473686218262\n",
      "Ep 74: Batch #166 - Loss: 0.5342835783958435\n",
      "Ep 74: Batch #167 - Loss: 0.7053983211517334\n",
      "Ep 74: Batch #168 - Loss: 0.6926627159118652\n",
      "Ep 74: Batch #169 - Loss: 0.6664908528327942\n",
      "Ep 74: Batch #170 - Loss: 0.6275257468223572\n",
      "Ep 74: Batch #171 - Loss: 0.6413938403129578\n",
      "Ep 74: Batch #172 - Loss: 0.5340417623519897\n",
      "Ep 74: Batch #173 - Loss: 0.9278615117073059\n",
      "Ep 74: Batch #174 - Loss: 0.49481669068336487\n",
      "Ep 74: Batch #175 - Loss: 0.6352627873420715\n",
      "Ep 74: Batch #176 - Loss: 0.8961474895477295\n",
      "Ep 74: Batch #177 - Loss: 0.6476625800132751\n",
      "Ep 74: Batch #178 - Loss: 0.6216629147529602\n",
      "Ep 74: Batch #179 - Loss: 0.7447296977043152\n",
      "Ep 74: Batch #180 - Loss: 0.6487593054771423\n",
      "Ep 74: Batch #181 - Loss: 0.8009551167488098\n",
      "Ep 74: Batch #182 - Loss: 0.6292519569396973\n",
      "Ep 74: Batch #183 - Loss: 0.6052654981613159\n",
      "Ep 74: Batch #184 - Loss: 0.9192935824394226\n",
      "Ep 74: Batch #185 - Loss: 0.6333271265029907\n",
      "Ep 74: Batch #186 - Loss: 0.7504439949989319\n",
      "Ep 74: Batch #187 - Loss: 0.8663030862808228\n",
      "Ep 74: Batch #188 - Loss: 0.9370048642158508\n",
      "Ep 74: Batch #189 - Loss: 0.5864127278327942\n",
      "Ep 74: Batch #190 - Loss: 0.621504545211792\n",
      "Ep 74: Batch #191 - Loss: 0.8016703128814697\n",
      "Ep 74: Batch #192 - Loss: 0.5716640949249268\n",
      "Ep 74: Batch #193 - Loss: 0.6308053731918335\n",
      "Ep 74: Batch #194 - Loss: 0.5422122478485107\n",
      "Ep 74: Batch #195 - Loss: 0.7832803130149841\n",
      "Ep 74: Batch #196 - Loss: 0.6934986114501953\n",
      "Ep 74: Batch #197 - Loss: 0.6992817521095276\n",
      "Ep 74: Batch #198 - Loss: 0.5337543487548828\n",
      "Ep 74: Batch #199 - Loss: 0.6429048776626587\n",
      "Ep 75: Batch #0 - Loss: 0.651340901851654\n",
      "Ep 75: Batch #1 - Loss: 0.7173565626144409\n",
      "Ep 75: Batch #2 - Loss: 0.8607174754142761\n",
      "Ep 75: Batch #3 - Loss: 0.7208479046821594\n",
      "Ep 75: Batch #4 - Loss: 0.6575899720191956\n",
      "Ep 75: Batch #5 - Loss: 0.5526443719863892\n",
      "Ep 75: Batch #6 - Loss: 0.7336487174034119\n",
      "Ep 75: Batch #7 - Loss: 0.5761140584945679\n",
      "Ep 75: Batch #8 - Loss: 0.584588348865509\n",
      "Ep 75: Batch #9 - Loss: 1.0927742719650269\n",
      "Ep 75: Batch #10 - Loss: 0.79511559009552\n",
      "Ep 75: Batch #11 - Loss: 0.5441998243331909\n",
      "Ep 75: Batch #12 - Loss: 1.1953402757644653\n",
      "Ep 75: Batch #13 - Loss: 0.5716618299484253\n",
      "Ep 75: Batch #14 - Loss: 0.598055362701416\n",
      "Ep 75: Batch #15 - Loss: 0.8420491814613342\n",
      "Ep 75: Batch #16 - Loss: 0.9558500647544861\n",
      "Ep 75: Batch #17 - Loss: 0.7316451668739319\n",
      "Ep 75: Batch #18 - Loss: 0.8096632361412048\n",
      "Ep 75: Batch #19 - Loss: 0.5635553002357483\n",
      "Ep 75: Batch #20 - Loss: 0.546140193939209\n",
      "Ep 75: Batch #21 - Loss: 0.798310399055481\n",
      "Ep 75: Batch #22 - Loss: 0.607482373714447\n",
      "Ep 75: Batch #23 - Loss: 0.5999366641044617\n",
      "Ep 75: Batch #24 - Loss: 0.6402928233146667\n",
      "Ep 75: Batch #25 - Loss: 0.6057366728782654\n",
      "Ep 75: Batch #26 - Loss: 0.5557773113250732\n",
      "Ep 75: Batch #27 - Loss: 1.1389175653457642\n",
      "Ep 75: Batch #28 - Loss: 0.692574679851532\n",
      "Ep 75: Batch #29 - Loss: 0.7533203363418579\n",
      "Ep 75: Batch #30 - Loss: 0.8215498924255371\n",
      "Ep 75: Batch #31 - Loss: 0.5618928074836731\n",
      "Ep 75: Batch #32 - Loss: 0.5805752873420715\n",
      "Ep 75: Batch #33 - Loss: 0.6668961048126221\n",
      "Ep 75: Batch #34 - Loss: 0.6358102560043335\n",
      "Ep 75: Batch #35 - Loss: 0.7241880297660828\n",
      "Ep 75: Batch #36 - Loss: 0.5852487087249756\n",
      "Ep 75: Batch #37 - Loss: 0.9206476807594299\n",
      "Ep 75: Batch #38 - Loss: 0.5679351091384888\n",
      "Ep 75: Batch #39 - Loss: 0.6868537068367004\n",
      "Ep 75: Batch #40 - Loss: 0.6041967868804932\n",
      "Ep 75: Batch #41 - Loss: 0.6194902062416077\n",
      "Ep 75: Batch #42 - Loss: 0.5697695016860962\n",
      "Ep 75: Batch #43 - Loss: 0.6330759525299072\n",
      "Ep 75: Batch #44 - Loss: 0.6129069328308105\n",
      "Ep 75: Batch #45 - Loss: 0.5242425203323364\n",
      "Ep 75: Batch #46 - Loss: 0.6973639130592346\n",
      "Ep 75: Batch #47 - Loss: 0.8033581972122192\n",
      "Ep 75: Batch #48 - Loss: 1.0451104640960693\n",
      "Ep 75: Batch #49 - Loss: 0.8084615468978882\n",
      "Ep 75: Batch #50 - Loss: 0.5737141370773315\n",
      "Ep 75: Batch #51 - Loss: 0.817038357257843\n",
      "Ep 75: Batch #52 - Loss: 0.6759310364723206\n",
      "Ep 75: Batch #53 - Loss: 0.7145257592201233\n",
      "Ep 75: Batch #54 - Loss: 0.5777906179428101\n",
      "Ep 75: Batch #55 - Loss: 0.6110662221908569\n",
      "Ep 75: Batch #56 - Loss: 0.8589516878128052\n",
      "Ep 75: Batch #57 - Loss: 0.6817018985748291\n",
      "Ep 75: Batch #58 - Loss: 0.824903666973114\n",
      "Ep 75: Batch #59 - Loss: 0.5568399429321289\n",
      "Ep 75: Batch #60 - Loss: 1.007159948348999\n",
      "Ep 75: Batch #61 - Loss: 0.5352190136909485\n",
      "Ep 75: Batch #62 - Loss: 0.5744025111198425\n",
      "Ep 75: Batch #63 - Loss: 0.7793392539024353\n",
      "Ep 75: Batch #64 - Loss: 8.100762367248535\n",
      "Ep 75: Batch #65 - Loss: 0.5236274003982544\n",
      "Ep 75: Batch #66 - Loss: 0.6645422577857971\n",
      "Ep 75: Batch #67 - Loss: 0.7757543325424194\n",
      "Ep 75: Batch #68 - Loss: 0.7129150629043579\n",
      "Ep 75: Batch #69 - Loss: 0.5866259336471558\n",
      "Ep 75: Batch #70 - Loss: 0.6152974963188171\n",
      "Ep 75: Batch #71 - Loss: 0.5353555679321289\n",
      "Ep 75: Batch #72 - Loss: 0.6628506779670715\n",
      "Ep 75: Batch #73 - Loss: 0.7198522686958313\n",
      "Ep 75: Batch #74 - Loss: 0.5763754844665527\n",
      "Ep 75: Batch #75 - Loss: 0.6664183139801025\n",
      "Ep 75: Batch #76 - Loss: 0.9232218861579895\n",
      "Ep 75: Batch #77 - Loss: 0.5754826068878174\n",
      "Ep 75: Batch #78 - Loss: 0.9170292019844055\n",
      "Ep 75: Batch #79 - Loss: 0.5251305103302002\n",
      "Ep 75: Batch #80 - Loss: 0.6905242800712585\n",
      "Ep 75: Batch #81 - Loss: 1.521714687347412\n",
      "Ep 75: Batch #82 - Loss: 0.753568708896637\n",
      "Ep 75: Batch #83 - Loss: 1.2139673233032227\n",
      "Ep 75: Batch #84 - Loss: 0.5778233408927917\n",
      "Ep 75: Batch #85 - Loss: 0.7842090725898743\n",
      "Ep 75: Batch #86 - Loss: 0.546843409538269\n",
      "Ep 75: Batch #87 - Loss: 0.5715482234954834\n",
      "Ep 75: Batch #88 - Loss: 0.6560347676277161\n",
      "Ep 75: Batch #89 - Loss: 0.7262886762619019\n",
      "Ep 75: Batch #90 - Loss: 0.9018468260765076\n",
      "Ep 75: Batch #91 - Loss: 0.6500514149665833\n",
      "Ep 75: Batch #92 - Loss: 0.7308899164199829\n",
      "Ep 75: Batch #93 - Loss: 0.7824996709823608\n",
      "Ep 75: Batch #94 - Loss: 0.7449215650558472\n",
      "Ep 75: Batch #95 - Loss: 0.7610225677490234\n",
      "Ep 75: Batch #96 - Loss: 0.7565022706985474\n",
      "Ep 75: Batch #97 - Loss: 0.5874680876731873\n",
      "Ep 75: Batch #98 - Loss: 0.5774620771408081\n",
      "Ep 75: Batch #99 - Loss: 0.791867733001709\n",
      "Ep 75: Batch #100 - Loss: 0.5574663877487183\n",
      "Ep 75: Batch #101 - Loss: 0.869015634059906\n",
      "Ep 75: Batch #102 - Loss: 0.6121010780334473\n",
      "Ep 75: Batch #103 - Loss: 0.6350206732749939\n",
      "Ep 75: Batch #104 - Loss: 0.6608417630195618\n",
      "Ep 75: Batch #105 - Loss: 0.8182172179222107\n",
      "Ep 75: Batch #106 - Loss: 0.6259825229644775\n",
      "Ep 75: Batch #107 - Loss: 0.6152656674385071\n",
      "Ep 75: Batch #108 - Loss: 0.9008414149284363\n",
      "Ep 75: Batch #109 - Loss: 0.6262295246124268\n",
      "Ep 75: Batch #110 - Loss: 0.7244479060173035\n",
      "Ep 75: Batch #111 - Loss: 1.039397120475769\n",
      "Ep 75: Batch #112 - Loss: 0.7898785471916199\n",
      "Ep 75: Batch #113 - Loss: 0.6574388742446899\n",
      "Ep 75: Batch #114 - Loss: 0.7252126336097717\n",
      "Ep 75: Batch #115 - Loss: 0.9101810455322266\n",
      "Ep 75: Batch #116 - Loss: 0.521716833114624\n",
      "Ep 75: Batch #117 - Loss: 0.6782920956611633\n",
      "Ep 75: Batch #118 - Loss: 0.45422181487083435\n",
      "Model saved in file: ./weights_autoencoder_sigmoid/model_e75b118_1516648801.5436227.ckpt\n",
      "Ep 75: Batch #119 - Loss: 0.8072982430458069\n",
      "Ep 75: Batch #120 - Loss: 0.6583757400512695\n",
      "Ep 75: Batch #121 - Loss: 0.5607215166091919\n",
      "Ep 75: Batch #122 - Loss: 0.7091113924980164\n",
      "Ep 75: Batch #123 - Loss: 0.7150493860244751\n",
      "Ep 75: Batch #124 - Loss: 0.5565234422683716\n",
      "Ep 75: Batch #125 - Loss: 2.475910186767578\n",
      "Ep 75: Batch #126 - Loss: 1.0063377618789673\n",
      "Ep 75: Batch #127 - Loss: 0.5821380019187927\n",
      "Ep 75: Batch #128 - Loss: 0.8869825005531311\n",
      "Ep 75: Batch #129 - Loss: 0.6775804758071899\n",
      "Ep 75: Batch #130 - Loss: 0.5951879024505615\n",
      "Ep 75: Batch #131 - Loss: 0.8013673424720764\n",
      "Ep 75: Batch #132 - Loss: 0.682906985282898\n",
      "Ep 75: Batch #133 - Loss: 0.666578471660614\n",
      "Ep 75: Batch #134 - Loss: 0.6369744539260864\n",
      "Ep 75: Batch #135 - Loss: 0.8217338919639587\n",
      "Ep 75: Batch #136 - Loss: 1.0430152416229248\n",
      "Ep 75: Batch #137 - Loss: 0.7556079626083374\n",
      "Ep 75: Batch #138 - Loss: 0.9018344283103943\n",
      "Ep 75: Batch #139 - Loss: 0.67464679479599\n",
      "Ep 75: Batch #140 - Loss: 0.8414769768714905\n",
      "Ep 75: Batch #141 - Loss: 1.1169631481170654\n",
      "Ep 75: Batch #142 - Loss: 0.67159503698349\n",
      "Ep 75: Batch #143 - Loss: 0.7708228230476379\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 75: Batch #144 - Loss: 0.6116806864738464\n",
      "Ep 75: Batch #145 - Loss: 0.5980878472328186\n",
      "Ep 75: Batch #146 - Loss: 0.697289228439331\n",
      "Ep 75: Batch #147 - Loss: 0.6620267033576965\n",
      "Ep 75: Batch #148 - Loss: 0.7526773810386658\n",
      "Ep 75: Batch #149 - Loss: 0.6127976775169373\n",
      "Ep 75: Batch #150 - Loss: 0.7195929884910583\n",
      "Ep 75: Batch #151 - Loss: 0.6256231069564819\n",
      "Ep 75: Batch #152 - Loss: 0.6072667837142944\n",
      "Ep 75: Batch #153 - Loss: 0.8261359333992004\n",
      "Ep 75: Batch #154 - Loss: 0.6330744624137878\n",
      "Ep 75: Batch #155 - Loss: 0.6896725296974182\n",
      "Ep 75: Batch #156 - Loss: 0.7771883010864258\n",
      "Ep 75: Batch #157 - Loss: 0.6124426126480103\n",
      "Ep 75: Batch #158 - Loss: 0.7176150679588318\n",
      "Ep 75: Batch #159 - Loss: 0.5966256856918335\n",
      "Ep 75: Batch #160 - Loss: 0.6911314725875854\n",
      "Ep 75: Batch #161 - Loss: 0.6688845157623291\n",
      "Ep 75: Batch #162 - Loss: 0.7187227606773376\n",
      "Ep 75: Batch #163 - Loss: 0.760100781917572\n",
      "Ep 75: Batch #164 - Loss: 0.6474427580833435\n",
      "Ep 75: Batch #165 - Loss: 1.3391363620758057\n",
      "Ep 75: Batch #166 - Loss: 0.5341689586639404\n",
      "Ep 75: Batch #167 - Loss: 0.705390214920044\n",
      "Ep 75: Batch #168 - Loss: 0.6928890347480774\n",
      "Ep 75: Batch #169 - Loss: 0.6664595007896423\n",
      "Ep 75: Batch #170 - Loss: 0.627805233001709\n",
      "Ep 75: Batch #171 - Loss: 0.6421423554420471\n",
      "Ep 75: Batch #172 - Loss: 0.5340610146522522\n",
      "Ep 75: Batch #173 - Loss: 0.9289366602897644\n",
      "Ep 75: Batch #174 - Loss: 0.49448809027671814\n",
      "Ep 75: Batch #175 - Loss: 0.6352694034576416\n",
      "Ep 75: Batch #176 - Loss: 0.896728515625\n",
      "Ep 75: Batch #177 - Loss: 0.6478511095046997\n",
      "Ep 75: Batch #178 - Loss: 0.621608316898346\n",
      "Ep 75: Batch #179 - Loss: 0.7445882558822632\n",
      "Ep 75: Batch #180 - Loss: 0.6484331488609314\n",
      "Ep 75: Batch #181 - Loss: 0.8014982342720032\n",
      "Ep 75: Batch #182 - Loss: 0.6295458078384399\n",
      "Ep 75: Batch #183 - Loss: 0.6052480340003967\n",
      "Ep 75: Batch #184 - Loss: 0.9193723797798157\n",
      "Ep 75: Batch #185 - Loss: 0.6340063214302063\n",
      "Ep 75: Batch #186 - Loss: 0.7513075470924377\n",
      "Ep 75: Batch #187 - Loss: 0.8674238324165344\n",
      "Ep 75: Batch #188 - Loss: 0.9358343482017517\n",
      "Ep 75: Batch #189 - Loss: 0.5865569710731506\n",
      "Ep 75: Batch #190 - Loss: 0.6219285130500793\n",
      "Ep 75: Batch #191 - Loss: 0.8009155988693237\n",
      "Ep 75: Batch #192 - Loss: 0.5716343522071838\n",
      "Ep 75: Batch #193 - Loss: 0.6311455368995667\n",
      "Ep 75: Batch #194 - Loss: 0.5421954393386841\n",
      "Ep 75: Batch #195 - Loss: 0.7831205725669861\n",
      "Ep 75: Batch #196 - Loss: 0.6935611367225647\n",
      "Ep 75: Batch #197 - Loss: 0.6992666125297546\n",
      "Ep 75: Batch #198 - Loss: 0.5337887406349182\n",
      "Ep 75: Batch #199 - Loss: 0.6428235769271851\n",
      "Ep 76: Batch #0 - Loss: 0.6514777541160583\n",
      "Ep 76: Batch #1 - Loss: 0.717205822467804\n",
      "Ep 76: Batch #2 - Loss: 0.8611955046653748\n",
      "Ep 76: Batch #3 - Loss: 0.720980167388916\n",
      "Ep 76: Batch #4 - Loss: 0.6576504707336426\n",
      "Ep 76: Batch #5 - Loss: 0.552562952041626\n",
      "Ep 76: Batch #6 - Loss: 0.7340639233589172\n",
      "Ep 76: Batch #7 - Loss: 0.5759976506233215\n",
      "Ep 76: Batch #8 - Loss: 0.5846319198608398\n",
      "Ep 76: Batch #9 - Loss: 1.092829704284668\n",
      "Ep 76: Batch #10 - Loss: 0.7941568493843079\n",
      "Ep 76: Batch #11 - Loss: 0.5442233085632324\n",
      "Ep 76: Batch #12 - Loss: 1.194664478302002\n",
      "Ep 76: Batch #13 - Loss: 0.571793258190155\n",
      "Ep 76: Batch #14 - Loss: 0.5980678796768188\n",
      "Ep 76: Batch #15 - Loss: 0.8425796031951904\n",
      "Ep 76: Batch #16 - Loss: 0.9550803303718567\n",
      "Ep 76: Batch #17 - Loss: 0.7317769527435303\n",
      "Ep 76: Batch #18 - Loss: 0.8094920516014099\n",
      "Ep 76: Batch #19 - Loss: 0.5637864470481873\n",
      "Ep 76: Batch #20 - Loss: 0.5462327599525452\n",
      "Ep 76: Batch #21 - Loss: 0.79803067445755\n",
      "Ep 76: Batch #22 - Loss: 0.6070219278335571\n",
      "Ep 76: Batch #23 - Loss: 0.5999184846878052\n",
      "Ep 76: Batch #24 - Loss: 0.6404309272766113\n",
      "Ep 76: Batch #25 - Loss: 0.605679452419281\n",
      "Ep 76: Batch #26 - Loss: 0.5557927489280701\n",
      "Ep 76: Batch #27 - Loss: 1.1390448808670044\n",
      "Ep 76: Batch #28 - Loss: 0.6926395297050476\n",
      "Ep 76: Batch #29 - Loss: 0.7530255913734436\n",
      "Ep 76: Batch #30 - Loss: 0.8208414316177368\n",
      "Ep 76: Batch #31 - Loss: 0.5619877576828003\n",
      "Ep 76: Batch #32 - Loss: 0.5806551575660706\n",
      "Ep 76: Batch #33 - Loss: 0.6664199829101562\n",
      "Ep 76: Batch #34 - Loss: 0.6359378099441528\n",
      "Ep 76: Batch #35 - Loss: 0.7242470979690552\n",
      "Ep 76: Batch #36 - Loss: 0.5852462649345398\n",
      "Ep 76: Batch #37 - Loss: 0.9206444025039673\n",
      "Ep 76: Batch #38 - Loss: 0.5678650140762329\n",
      "Ep 76: Batch #39 - Loss: 0.6869405508041382\n",
      "Ep 76: Batch #40 - Loss: 0.6042353510856628\n",
      "Ep 76: Batch #41 - Loss: 0.619552493095398\n",
      "Ep 76: Batch #42 - Loss: 0.5697796940803528\n",
      "Ep 76: Batch #43 - Loss: 0.633201539516449\n",
      "Ep 76: Batch #44 - Loss: 0.6128247380256653\n",
      "Ep 76: Batch #45 - Loss: 0.5241358876228333\n",
      "Ep 76: Batch #46 - Loss: 0.6973837614059448\n",
      "Ep 76: Batch #47 - Loss: 0.8033696413040161\n",
      "Ep 76: Batch #48 - Loss: 1.0458950996398926\n",
      "Ep 76: Batch #49 - Loss: 0.8082623481750488\n",
      "Ep 76: Batch #50 - Loss: 0.573645293712616\n",
      "Ep 76: Batch #51 - Loss: 0.8172800540924072\n",
      "Ep 76: Batch #52 - Loss: 0.6760934591293335\n",
      "Ep 76: Batch #53 - Loss: 0.7146511673927307\n",
      "Ep 76: Batch #54 - Loss: 0.5776692628860474\n",
      "Ep 76: Batch #55 - Loss: 0.6070029139518738\n",
      "Ep 76: Batch #56 - Loss: 0.8593346476554871\n",
      "Ep 76: Batch #57 - Loss: 0.6816889643669128\n",
      "Ep 76: Batch #58 - Loss: 0.8245866894721985\n",
      "Ep 76: Batch #59 - Loss: 0.5567950010299683\n",
      "Ep 76: Batch #60 - Loss: 1.0071250200271606\n",
      "Ep 76: Batch #61 - Loss: 0.5350691676139832\n",
      "Ep 76: Batch #62 - Loss: 0.5743808150291443\n",
      "Ep 76: Batch #63 - Loss: 0.7794201374053955\n",
      "Ep 76: Batch #64 - Loss: 8.087846755981445\n",
      "Ep 76: Batch #65 - Loss: 0.5236680507659912\n",
      "Ep 76: Batch #66 - Loss: 0.6646047234535217\n",
      "Ep 76: Batch #67 - Loss: 0.7757880091667175\n",
      "Ep 76: Batch #68 - Loss: 0.7128950357437134\n",
      "Ep 76: Batch #69 - Loss: 0.5867519974708557\n",
      "Ep 76: Batch #70 - Loss: 0.6153045296669006\n",
      "Ep 76: Batch #71 - Loss: 0.5351240038871765\n",
      "Ep 76: Batch #72 - Loss: 0.6627587676048279\n",
      "Ep 76: Batch #73 - Loss: 0.719826877117157\n",
      "Ep 76: Batch #74 - Loss: 0.57645583152771\n",
      "Ep 76: Batch #75 - Loss: 0.6664987206459045\n",
      "Ep 76: Batch #76 - Loss: 0.9231037497520447\n",
      "Ep 76: Batch #77 - Loss: 0.5757799744606018\n",
      "Ep 76: Batch #78 - Loss: 0.9166471362113953\n",
      "Ep 76: Batch #79 - Loss: 0.5250002145767212\n",
      "Ep 76: Batch #80 - Loss: 0.690424382686615\n",
      "Ep 76: Batch #81 - Loss: 1.5269216299057007\n",
      "Ep 76: Batch #82 - Loss: 0.7549141049385071\n",
      "Ep 76: Batch #83 - Loss: 1.2117984294891357\n",
      "Ep 76: Batch #84 - Loss: 0.5777410864830017\n",
      "Ep 76: Batch #85 - Loss: 0.7842086553573608\n",
      "Ep 76: Batch #86 - Loss: 0.5471418499946594\n",
      "Ep 76: Batch #87 - Loss: 0.5711141228675842\n",
      "Ep 76: Batch #88 - Loss: 0.6556115746498108\n",
      "Ep 76: Batch #89 - Loss: 0.7261050343513489\n",
      "Ep 76: Batch #90 - Loss: 0.9018825888633728\n",
      "Ep 76: Batch #91 - Loss: 0.6500434875488281\n",
      "Ep 76: Batch #92 - Loss: 0.7306901812553406\n",
      "Ep 76: Batch #93 - Loss: 0.7827433347702026\n",
      "Ep 76: Batch #94 - Loss: 0.7439423203468323\n",
      "Ep 76: Batch #95 - Loss: 0.7608311772346497\n",
      "Ep 76: Batch #96 - Loss: 0.7562112808227539\n",
      "Ep 76: Batch #97 - Loss: 0.5882911682128906\n",
      "Ep 76: Batch #98 - Loss: 0.577811062335968\n",
      "Ep 76: Batch #99 - Loss: 0.7923954129219055\n",
      "Ep 76: Batch #100 - Loss: 0.5575975775718689\n",
      "Ep 76: Batch #101 - Loss: 0.8694905042648315\n",
      "Ep 76: Batch #102 - Loss: 0.6120827794075012\n",
      "Ep 76: Batch #103 - Loss: 0.6347267031669617\n",
      "Ep 76: Batch #104 - Loss: 0.6602860689163208\n",
      "Ep 76: Batch #105 - Loss: 0.8183213472366333\n",
      "Ep 76: Batch #106 - Loss: 0.6263045072555542\n",
      "Ep 76: Batch #107 - Loss: 0.6153144836425781\n",
      "Ep 76: Batch #108 - Loss: 0.901772141456604\n",
      "Ep 76: Batch #109 - Loss: 0.6259511113166809\n",
      "Ep 76: Batch #110 - Loss: 0.7235119342803955\n",
      "Ep 76: Batch #111 - Loss: 1.0388062000274658\n",
      "Ep 76: Batch #112 - Loss: 0.7899096012115479\n",
      "Ep 76: Batch #113 - Loss: 0.6573548316955566\n",
      "Ep 76: Batch #114 - Loss: 0.7254420518875122\n",
      "Ep 76: Batch #115 - Loss: 0.9105323553085327\n",
      "Ep 76: Batch #116 - Loss: 0.5213791728019714\n",
      "Ep 76: Batch #117 - Loss: 0.6782651543617249\n",
      "Ep 76: Batch #118 - Loss: 0.4543413817882538\n",
      "Ep 76: Batch #119 - Loss: 0.8086066842079163\n",
      "Ep 76: Batch #120 - Loss: 0.6589829921722412\n",
      "Ep 76: Batch #121 - Loss: 0.560467004776001\n",
      "Ep 76: Batch #122 - Loss: 0.7092733979225159\n",
      "Ep 76: Batch #123 - Loss: 0.7157829999923706\n",
      "Ep 76: Batch #124 - Loss: 0.5563995242118835\n",
      "Ep 76: Batch #125 - Loss: 2.4749178886413574\n",
      "Ep 76: Batch #126 - Loss: 1.0064371824264526\n",
      "Ep 76: Batch #127 - Loss: 0.5817741751670837\n",
      "Ep 76: Batch #128 - Loss: 0.8873692154884338\n",
      "Ep 76: Batch #129 - Loss: 0.6774851679801941\n",
      "Ep 76: Batch #130 - Loss: 0.5950506925582886\n",
      "Ep 76: Batch #131 - Loss: 0.8003735542297363\n",
      "Ep 76: Batch #132 - Loss: 0.6829245090484619\n",
      "Ep 76: Batch #133 - Loss: 0.6667506694793701\n",
      "Ep 76: Batch #134 - Loss: 0.6366410851478577\n",
      "Ep 76: Batch #135 - Loss: 0.8211544156074524\n",
      "Ep 76: Batch #136 - Loss: 1.0431476831436157\n",
      "Ep 76: Batch #137 - Loss: 0.7547948360443115\n",
      "Ep 76: Batch #138 - Loss: 0.9017832279205322\n",
      "Ep 76: Batch #139 - Loss: 0.6739688515663147\n",
      "Ep 76: Batch #140 - Loss: 0.8411548733711243\n",
      "Ep 76: Batch #141 - Loss: 1.1169137954711914\n",
      "Ep 76: Batch #142 - Loss: 0.671161413192749\n",
      "Ep 76: Batch #143 - Loss: 0.7702237963676453\n",
      "Ep 76: Batch #144 - Loss: 0.6121546626091003\n",
      "Ep 76: Batch #145 - Loss: 0.5982185006141663\n",
      "Ep 76: Batch #146 - Loss: 0.697745144367218\n",
      "Ep 76: Batch #147 - Loss: 0.6622542142868042\n",
      "Ep 76: Batch #148 - Loss: 0.7523676753044128\n",
      "Ep 76: Batch #149 - Loss: 0.6124861240386963\n",
      "Ep 76: Batch #150 - Loss: 0.7196211814880371\n",
      "Ep 76: Batch #151 - Loss: 0.6252663135528564\n",
      "Ep 76: Batch #152 - Loss: 0.6070723533630371\n",
      "Ep 76: Batch #153 - Loss: 0.8261904120445251\n",
      "Ep 76: Batch #154 - Loss: 0.6332873702049255\n",
      "Ep 76: Batch #155 - Loss: 0.6897180676460266\n",
      "Ep 76: Batch #156 - Loss: 0.7771196365356445\n",
      "Ep 76: Batch #157 - Loss: 0.6121862530708313\n",
      "Ep 76: Batch #158 - Loss: 0.7176608443260193\n",
      "Ep 76: Batch #159 - Loss: 0.5963013768196106\n",
      "Ep 76: Batch #160 - Loss: 0.6910935640335083\n",
      "Ep 76: Batch #161 - Loss: 0.6686629056930542\n",
      "Ep 76: Batch #162 - Loss: 0.7185556292533875\n",
      "Ep 76: Batch #163 - Loss: 0.7600751519203186\n",
      "Ep 76: Batch #164 - Loss: 0.6472896933555603\n",
      "Ep 76: Batch #165 - Loss: 1.3384970426559448\n",
      "Ep 76: Batch #166 - Loss: 0.5341243743896484\n",
      "Ep 76: Batch #167 - Loss: 0.7045381665229797\n",
      "Ep 76: Batch #168 - Loss: 0.6926956176757812\n",
      "Ep 76: Batch #169 - Loss: 0.66628497838974\n",
      "Ep 76: Batch #170 - Loss: 0.6272691488265991\n",
      "Ep 76: Batch #171 - Loss: 0.6416263580322266\n",
      "Ep 76: Batch #172 - Loss: 0.5339321494102478\n",
      "Ep 76: Batch #173 - Loss: 0.9275144934654236\n",
      "Ep 76: Batch #174 - Loss: 0.49467360973358154\n",
      "Ep 76: Batch #175 - Loss: 0.6357125639915466\n",
      "Ep 76: Batch #176 - Loss: 0.8961472511291504\n",
      "Ep 76: Batch #177 - Loss: 0.6472535729408264\n",
      "Ep 76: Batch #178 - Loss: 0.6215322613716125\n",
      "Ep 76: Batch #179 - Loss: 0.7443914413452148\n",
      "Ep 76: Batch #180 - Loss: 0.6484983563423157\n",
      "Ep 76: Batch #181 - Loss: 0.8006556630134583\n",
      "Ep 76: Batch #182 - Loss: 0.6293741464614868\n",
      "Ep 76: Batch #183 - Loss: 0.605118453502655\n",
      "Ep 76: Batch #184 - Loss: 0.9193559288978577\n",
      "Ep 76: Batch #185 - Loss: 0.6334518790245056\n",
      "Ep 76: Batch #186 - Loss: 0.7500821948051453\n",
      "Ep 76: Batch #187 - Loss: 0.8660410046577454\n",
      "Ep 76: Batch #188 - Loss: 0.9353269934654236\n",
      "Ep 76: Batch #189 - Loss: 0.5858922600746155\n",
      "Ep 76: Batch #190 - Loss: 0.6213082671165466\n",
      "Ep 76: Batch #191 - Loss: 0.8017497658729553\n",
      "Ep 76: Batch #192 - Loss: 0.5717763304710388\n",
      "Ep 76: Batch #193 - Loss: 0.6307915449142456\n",
      "Ep 76: Batch #194 - Loss: 0.5420334935188293\n",
      "Ep 76: Batch #195 - Loss: 0.7831053137779236\n",
      "Ep 76: Batch #196 - Loss: 0.693639874458313\n",
      "Ep 76: Batch #197 - Loss: 0.6990365386009216\n",
      "Ep 76: Batch #198 - Loss: 0.5338760018348694\n",
      "Ep 76: Batch #199 - Loss: 0.6428656578063965\n",
      "Ep 77: Batch #0 - Loss: 0.6512314081192017\n",
      "Ep 77: Batch #1 - Loss: 0.7177160978317261\n",
      "Ep 77: Batch #2 - Loss: 0.8605896234512329\n",
      "Ep 77: Batch #3 - Loss: 0.720946729183197\n",
      "Ep 77: Batch #4 - Loss: 0.6574947834014893\n",
      "Ep 77: Batch #5 - Loss: 0.5526458024978638\n",
      "Ep 77: Batch #6 - Loss: 0.7333855032920837\n",
      "Ep 77: Batch #7 - Loss: 0.5761185884475708\n",
      "Ep 77: Batch #8 - Loss: 0.5846054553985596\n",
      "Ep 77: Batch #9 - Loss: 1.0925909280776978\n",
      "Ep 77: Batch #10 - Loss: 0.7944326400756836\n",
      "Ep 77: Batch #11 - Loss: 0.5441046357154846\n",
      "Ep 77: Batch #12 - Loss: 1.1948987245559692\n",
      "Ep 77: Batch #13 - Loss: 0.5717836618423462\n",
      "Ep 77: Batch #14 - Loss: 0.5978386402130127\n",
      "Ep 77: Batch #15 - Loss: 0.8412465453147888\n",
      "Ep 77: Batch #16 - Loss: 0.9558144807815552\n",
      "Ep 77: Batch #17 - Loss: 0.731777012348175\n",
      "Ep 77: Batch #18 - Loss: 0.8096723556518555\n",
      "Ep 77: Batch #19 - Loss: 0.5635961294174194\n",
      "Ep 77: Batch #20 - Loss: 0.5461316108703613\n",
      "Ep 77: Batch #21 - Loss: 0.7966463565826416\n",
      "Ep 77: Batch #22 - Loss: 0.607391893863678\n",
      "Ep 77: Batch #23 - Loss: 0.5999346971511841\n",
      "Ep 77: Batch #24 - Loss: 0.6405863165855408\n",
      "Ep 77: Batch #25 - Loss: 0.6055572032928467\n",
      "Ep 77: Batch #26 - Loss: 0.5555866360664368\n",
      "Ep 77: Batch #27 - Loss: 1.138609528541565\n",
      "Ep 77: Batch #28 - Loss: 0.6924391984939575\n",
      "Ep 77: Batch #29 - Loss: 0.7540180683135986\n",
      "Ep 77: Batch #30 - Loss: 0.8206326961517334\n",
      "Ep 77: Batch #31 - Loss: 0.5617977976799011\n",
      "Ep 77: Batch #32 - Loss: 0.5805200338363647\n",
      "Ep 77: Batch #33 - Loss: 0.6668619513511658\n",
      "Ep 77: Batch #34 - Loss: 0.6356200575828552\n",
      "Ep 77: Batch #35 - Loss: 0.7242428660392761\n",
      "Ep 77: Batch #36 - Loss: 0.5852317810058594\n",
      "Ep 77: Batch #37 - Loss: 0.920487105846405\n",
      "Ep 77: Batch #38 - Loss: 0.5676817893981934\n",
      "Ep 77: Batch #39 - Loss: 0.6868834495544434\n",
      "Ep 77: Batch #40 - Loss: 0.6041898727416992\n",
      "Ep 77: Batch #41 - Loss: 0.619440495967865\n",
      "Ep 77: Batch #42 - Loss: 0.5697034001350403\n",
      "Ep 77: Batch #43 - Loss: 0.633259117603302\n",
      "Ep 77: Batch #44 - Loss: 0.6126759052276611\n",
      "Ep 77: Batch #45 - Loss: 0.5238787531852722\n",
      "Ep 77: Batch #46 - Loss: 0.6973825693130493\n",
      "Ep 77: Batch #47 - Loss: 0.803136944770813\n",
      "Ep 77: Batch #48 - Loss: 1.0456883907318115\n",
      "Ep 77: Batch #49 - Loss: 0.8079444766044617\n",
      "Ep 77: Batch #50 - Loss: 0.573639988899231\n",
      "Ep 77: Batch #51 - Loss: 0.8171952366828918\n",
      "Ep 77: Batch #52 - Loss: 0.675957977771759\n",
      "Ep 77: Batch #53 - Loss: 0.7143772840499878\n",
      "Ep 77: Batch #54 - Loss: 0.5777197480201721\n",
      "Ep 77: Batch #55 - Loss: 0.6050634384155273\n",
      "Ep 77: Batch #56 - Loss: 0.8590108156204224\n",
      "Ep 77: Batch #57 - Loss: 0.6815319657325745\n",
      "Ep 77: Batch #58 - Loss: 0.8240013718605042\n",
      "Ep 77: Batch #59 - Loss: 0.5564652681350708\n",
      "Ep 77: Batch #60 - Loss: 1.0072894096374512\n",
      "Ep 77: Batch #61 - Loss: 0.5350856781005859\n",
      "Ep 77: Batch #62 - Loss: 0.5745784044265747\n",
      "Ep 77: Batch #63 - Loss: 0.7791370153427124\n",
      "Ep 77: Batch #64 - Loss: 8.073919296264648\n",
      "Ep 77: Batch #65 - Loss: 0.5237296223640442\n",
      "Ep 77: Batch #66 - Loss: 0.6643761992454529\n",
      "Ep 77: Batch #67 - Loss: 0.775627076625824\n",
      "Ep 77: Batch #68 - Loss: 0.7130361795425415\n",
      "Ep 77: Batch #69 - Loss: 0.5868028402328491\n",
      "Ep 77: Batch #70 - Loss: 0.6154981255531311\n",
      "Ep 77: Batch #71 - Loss: 0.5354124903678894\n",
      "Ep 77: Batch #72 - Loss: 0.6629106402397156\n",
      "Ep 77: Batch #73 - Loss: 0.7198854684829712\n",
      "Ep 77: Batch #74 - Loss: 0.576373815536499\n",
      "Ep 77: Batch #75 - Loss: 0.6664304137229919\n",
      "Ep 77: Batch #76 - Loss: 0.9229925274848938\n",
      "Ep 77: Batch #77 - Loss: 0.5757815837860107\n",
      "Ep 77: Batch #78 - Loss: 0.9168122410774231\n",
      "Ep 77: Batch #79 - Loss: 0.52506023645401\n",
      "Ep 77: Batch #80 - Loss: 0.6903157234191895\n",
      "Ep 77: Batch #81 - Loss: 1.5222978591918945\n",
      "Ep 77: Batch #82 - Loss: 0.7537262439727783\n",
      "Ep 77: Batch #83 - Loss: 1.2100374698638916\n",
      "Ep 77: Batch #84 - Loss: 0.5778430700302124\n",
      "Ep 77: Batch #85 - Loss: 0.7843077182769775\n",
      "Ep 77: Batch #86 - Loss: 0.5466261506080627\n",
      "Ep 77: Batch #87 - Loss: 0.5713660717010498\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 77: Batch #88 - Loss: 0.6559743285179138\n",
      "Ep 77: Batch #89 - Loss: 0.7257393598556519\n",
      "Ep 77: Batch #90 - Loss: 0.9022300839424133\n",
      "Ep 77: Batch #91 - Loss: 0.6501144170761108\n",
      "Ep 77: Batch #92 - Loss: 0.7303135991096497\n",
      "Ep 77: Batch #93 - Loss: 0.7822226285934448\n",
      "Ep 77: Batch #94 - Loss: 0.7444422841072083\n",
      "Ep 77: Batch #95 - Loss: 0.760707676410675\n",
      "Ep 77: Batch #96 - Loss: 0.7560887336730957\n",
      "Ep 77: Batch #97 - Loss: 0.5875864624977112\n",
      "Ep 77: Batch #98 - Loss: 0.5774869918823242\n",
      "Ep 77: Batch #99 - Loss: 0.7924013137817383\n",
      "Ep 77: Batch #100 - Loss: 0.557632565498352\n",
      "Ep 77: Batch #101 - Loss: 0.8692895770072937\n",
      "Ep 77: Batch #102 - Loss: 0.6122335195541382\n",
      "Ep 77: Batch #103 - Loss: 0.6349196434020996\n",
      "Ep 77: Batch #104 - Loss: 0.660769522190094\n",
      "Ep 77: Batch #105 - Loss: 0.8185584545135498\n",
      "Ep 77: Batch #106 - Loss: 0.6261375546455383\n",
      "Ep 77: Batch #107 - Loss: 0.6152331233024597\n",
      "Ep 77: Batch #108 - Loss: 0.900907576084137\n",
      "Ep 77: Batch #109 - Loss: 0.6262138485908508\n",
      "Ep 77: Batch #110 - Loss: 0.7244966626167297\n",
      "Ep 77: Batch #111 - Loss: 1.0394573211669922\n",
      "Ep 77: Batch #112 - Loss: 0.7899366617202759\n",
      "Ep 77: Batch #113 - Loss: 0.6575086712837219\n",
      "Ep 77: Batch #114 - Loss: 0.7256242036819458\n",
      "Ep 77: Batch #115 - Loss: 0.9104048609733582\n",
      "Ep 77: Batch #116 - Loss: 0.521545946598053\n",
      "Ep 77: Batch #117 - Loss: 0.6783623695373535\n",
      "Ep 77: Batch #118 - Loss: 0.45416638255119324\n",
      "Model saved in file: ./weights_autoencoder_sigmoid/model_e77b118_1516648801.7966459.ckpt\n",
      "Ep 77: Batch #119 - Loss: 0.8071497678756714\n",
      "Ep 77: Batch #120 - Loss: 0.6584436297416687\n",
      "Ep 77: Batch #121 - Loss: 0.5604807138442993\n",
      "Ep 77: Batch #122 - Loss: 0.7091678977012634\n",
      "Ep 77: Batch #123 - Loss: 0.7146630883216858\n",
      "Ep 77: Batch #124 - Loss: 0.5564167499542236\n",
      "Ep 77: Batch #125 - Loss: 2.475365161895752\n",
      "Ep 77: Batch #126 - Loss: 1.0067845582962036\n",
      "Ep 77: Batch #127 - Loss: 0.5818792581558228\n",
      "Ep 77: Batch #128 - Loss: 0.8869550228118896\n",
      "Ep 77: Batch #129 - Loss: 0.6776825785636902\n",
      "Ep 77: Batch #130 - Loss: 0.5951352119445801\n",
      "Ep 77: Batch #131 - Loss: 0.8011717796325684\n",
      "Ep 77: Batch #132 - Loss: 0.683256208896637\n",
      "Ep 77: Batch #133 - Loss: 0.666355550289154\n",
      "Ep 77: Batch #134 - Loss: 0.6370509266853333\n",
      "Ep 77: Batch #135 - Loss: 0.8214839100837708\n",
      "Ep 77: Batch #136 - Loss: 1.0427801609039307\n",
      "Ep 77: Batch #137 - Loss: 0.7555792927742004\n",
      "Ep 77: Batch #138 - Loss: 0.901909351348877\n",
      "Ep 77: Batch #139 - Loss: 0.6744815707206726\n",
      "Ep 77: Batch #140 - Loss: 0.8414011597633362\n",
      "Ep 77: Batch #141 - Loss: 1.1164500713348389\n",
      "Ep 77: Batch #142 - Loss: 0.6715891361236572\n",
      "Ep 77: Batch #143 - Loss: 0.7706577777862549\n",
      "Ep 77: Batch #144 - Loss: 0.6118939518928528\n",
      "Ep 77: Batch #145 - Loss: 0.5979871153831482\n",
      "Ep 77: Batch #146 - Loss: 0.6970648765563965\n",
      "Ep 77: Batch #147 - Loss: 0.6621000170707703\n",
      "Ep 77: Batch #148 - Loss: 0.7529096603393555\n",
      "Ep 77: Batch #149 - Loss: 0.6122927069664001\n",
      "Ep 77: Batch #150 - Loss: 0.7196791768074036\n",
      "Ep 77: Batch #151 - Loss: 0.6253588795661926\n",
      "Ep 77: Batch #152 - Loss: 0.6070558428764343\n",
      "Ep 77: Batch #153 - Loss: 0.8260949850082397\n",
      "Ep 77: Batch #154 - Loss: 0.6324964761734009\n",
      "Ep 77: Batch #155 - Loss: 0.6895962357521057\n",
      "Ep 77: Batch #156 - Loss: 0.7775871157646179\n",
      "Ep 77: Batch #157 - Loss: 0.6123500466346741\n",
      "Ep 77: Batch #158 - Loss: 0.7174808382987976\n",
      "Ep 77: Batch #159 - Loss: 0.5964072942733765\n",
      "Ep 77: Batch #160 - Loss: 0.69098299741745\n",
      "Ep 77: Batch #161 - Loss: 0.6687417030334473\n",
      "Ep 77: Batch #162 - Loss: 0.7185608148574829\n",
      "Ep 77: Batch #163 - Loss: 0.7602629065513611\n",
      "Ep 77: Batch #164 - Loss: 0.6473342776298523\n",
      "Ep 77: Batch #165 - Loss: 1.339331865310669\n",
      "Ep 77: Batch #166 - Loss: 0.5339351892471313\n",
      "Ep 77: Batch #167 - Loss: 0.7047136425971985\n",
      "Ep 77: Batch #168 - Loss: 0.6929010152816772\n",
      "Ep 77: Batch #169 - Loss: 0.6662114262580872\n",
      "Ep 77: Batch #170 - Loss: 0.6275913715362549\n",
      "Ep 77: Batch #171 - Loss: 0.642310619354248\n",
      "Ep 77: Batch #172 - Loss: 0.5339319109916687\n",
      "Ep 77: Batch #173 - Loss: 0.9288569688796997\n",
      "Ep 77: Batch #174 - Loss: 0.49450045824050903\n",
      "Ep 77: Batch #175 - Loss: 0.6348942518234253\n",
      "Ep 77: Batch #176 - Loss: 0.8966907262802124\n",
      "Ep 77: Batch #177 - Loss: 0.647543728351593\n",
      "Ep 77: Batch #178 - Loss: 0.6212714314460754\n",
      "Ep 77: Batch #179 - Loss: 0.7444321513175964\n",
      "Ep 77: Batch #180 - Loss: 0.6484156847000122\n",
      "Ep 77: Batch #181 - Loss: 0.8014543056488037\n",
      "Ep 77: Batch #182 - Loss: 0.6297131180763245\n",
      "Ep 77: Batch #183 - Loss: 0.6052045822143555\n",
      "Ep 77: Batch #184 - Loss: 0.919180154800415\n",
      "Ep 77: Batch #185 - Loss: 0.6340944766998291\n",
      "Ep 77: Batch #186 - Loss: 0.7509947419166565\n",
      "Ep 77: Batch #187 - Loss: 0.8675058484077454\n",
      "Ep 77: Batch #188 - Loss: 0.9339638352394104\n",
      "Ep 77: Batch #189 - Loss: 0.5864299535751343\n",
      "Ep 77: Batch #190 - Loss: 0.6214873790740967\n",
      "Ep 77: Batch #191 - Loss: 0.8005582094192505\n",
      "Ep 77: Batch #192 - Loss: 0.5714974999427795\n",
      "Ep 77: Batch #193 - Loss: 0.6311902403831482\n",
      "Ep 77: Batch #194 - Loss: 0.5418901443481445\n",
      "Ep 77: Batch #195 - Loss: 0.7829614877700806\n",
      "Ep 77: Batch #196 - Loss: 0.6935571432113647\n",
      "Ep 77: Batch #197 - Loss: 0.699032723903656\n",
      "Ep 77: Batch #198 - Loss: 0.5338147282600403\n",
      "Ep 77: Batch #199 - Loss: 0.6425467729568481\n",
      "Ep 78: Batch #0 - Loss: 0.6511907577514648\n",
      "Ep 78: Batch #1 - Loss: 0.7173495888710022\n",
      "Ep 78: Batch #2 - Loss: 0.8610137104988098\n",
      "Ep 78: Batch #3 - Loss: 0.7209963202476501\n",
      "Ep 78: Batch #4 - Loss: 0.6575602293014526\n",
      "Ep 78: Batch #5 - Loss: 0.5522936582565308\n",
      "Ep 78: Batch #6 - Loss: 0.7333135604858398\n",
      "Ep 78: Batch #7 - Loss: 0.5758777260780334\n",
      "Ep 78: Batch #8 - Loss: 0.5844116806983948\n",
      "Ep 78: Batch #9 - Loss: 1.09322988986969\n",
      "Ep 78: Batch #10 - Loss: 0.7936749458312988\n",
      "Ep 78: Batch #11 - Loss: 0.5441579222679138\n",
      "Ep 78: Batch #12 - Loss: 1.1945326328277588\n",
      "Ep 78: Batch #13 - Loss: 0.5717586874961853\n",
      "Ep 78: Batch #14 - Loss: 0.5977191925048828\n",
      "Ep 78: Batch #15 - Loss: 0.841484546661377\n",
      "Ep 78: Batch #16 - Loss: 0.9551888704299927\n",
      "Ep 78: Batch #17 - Loss: 0.7319071888923645\n",
      "Ep 78: Batch #18 - Loss: 0.8097991943359375\n",
      "Ep 78: Batch #19 - Loss: 0.5637653470039368\n",
      "Ep 78: Batch #20 - Loss: 0.5462191104888916\n",
      "Ep 78: Batch #21 - Loss: 0.7968825101852417\n",
      "Ep 78: Batch #22 - Loss: 0.6069872379302979\n",
      "Ep 78: Batch #23 - Loss: 0.5999137759208679\n",
      "Ep 78: Batch #24 - Loss: 0.6408074498176575\n",
      "Ep 78: Batch #25 - Loss: 0.6054832935333252\n",
      "Ep 78: Batch #26 - Loss: 0.5557162761688232\n",
      "Ep 78: Batch #27 - Loss: 1.138705849647522\n",
      "Ep 78: Batch #28 - Loss: 0.6927517652511597\n",
      "Ep 78: Batch #29 - Loss: 0.7540736794471741\n",
      "Ep 78: Batch #30 - Loss: 0.8197577595710754\n",
      "Ep 78: Batch #31 - Loss: 0.5619620680809021\n",
      "Ep 78: Batch #32 - Loss: 0.5806061029434204\n",
      "Ep 78: Batch #33 - Loss: 0.6667886972427368\n",
      "Ep 78: Batch #34 - Loss: 0.6354215145111084\n",
      "Ep 78: Batch #35 - Loss: 0.7242348194122314\n",
      "Ep 78: Batch #36 - Loss: 0.5849394202232361\n",
      "Ep 78: Batch #37 - Loss: 0.9204927086830139\n",
      "Ep 78: Batch #38 - Loss: 0.567672073841095\n",
      "Ep 78: Batch #39 - Loss: 0.6867162585258484\n",
      "Ep 78: Batch #40 - Loss: 0.6042431592941284\n",
      "Ep 78: Batch #41 - Loss: 0.6194207668304443\n",
      "Ep 78: Batch #42 - Loss: 0.5698772072792053\n",
      "Ep 78: Batch #43 - Loss: 0.6333878040313721\n",
      "Ep 78: Batch #44 - Loss: 0.6125990152359009\n",
      "Ep 78: Batch #45 - Loss: 0.5238239765167236\n",
      "Ep 78: Batch #46 - Loss: 0.6974183917045593\n",
      "Ep 78: Batch #47 - Loss: 0.8029980659484863\n",
      "Ep 78: Batch #48 - Loss: 1.045473575592041\n",
      "Ep 78: Batch #49 - Loss: 0.807550847530365\n",
      "Ep 78: Batch #50 - Loss: 0.5736581087112427\n",
      "Ep 78: Batch #51 - Loss: 0.8172175884246826\n",
      "Ep 78: Batch #52 - Loss: 0.6759418845176697\n",
      "Ep 78: Batch #53 - Loss: 0.7142897844314575\n",
      "Ep 78: Batch #54 - Loss: 0.5776073932647705\n",
      "Ep 78: Batch #55 - Loss: 0.6049469709396362\n",
      "Ep 78: Batch #56 - Loss: 0.8593698740005493\n",
      "Ep 78: Batch #57 - Loss: 0.6815385818481445\n",
      "Ep 78: Batch #58 - Loss: 0.8238677978515625\n",
      "Ep 78: Batch #59 - Loss: 0.5564634203910828\n",
      "Ep 78: Batch #60 - Loss: 1.006940245628357\n",
      "Ep 78: Batch #61 - Loss: 0.5351799726486206\n",
      "Ep 78: Batch #62 - Loss: 0.574506938457489\n",
      "Ep 78: Batch #63 - Loss: 0.7790490388870239\n",
      "Ep 78: Batch #64 - Loss: 8.059245109558105\n",
      "Ep 78: Batch #65 - Loss: 0.523577868938446\n",
      "Ep 78: Batch #66 - Loss: 0.6642456650733948\n",
      "Ep 78: Batch #67 - Loss: 0.7754725217819214\n",
      "Ep 78: Batch #68 - Loss: 0.7126153707504272\n",
      "Ep 78: Batch #69 - Loss: 0.5863787531852722\n",
      "Ep 78: Batch #70 - Loss: 0.6151617765426636\n",
      "Ep 78: Batch #71 - Loss: 0.5350022315979004\n",
      "Ep 78: Batch #72 - Loss: 0.6624506711959839\n",
      "Ep 78: Batch #73 - Loss: 0.719530463218689\n",
      "Ep 78: Batch #74 - Loss: 0.5760998725891113\n",
      "Ep 78: Batch #75 - Loss: 0.6662495136260986\n",
      "Ep 78: Batch #76 - Loss: 0.9226812720298767\n",
      "Ep 78: Batch #77 - Loss: 0.5756009817123413\n",
      "Ep 78: Batch #78 - Loss: 0.9165149927139282\n",
      "Ep 78: Batch #79 - Loss: 0.524899959564209\n",
      "Ep 78: Batch #80 - Loss: 0.6899152398109436\n",
      "Ep 78: Batch #81 - Loss: 1.5226316452026367\n",
      "Ep 78: Batch #82 - Loss: 0.7533199787139893\n",
      "Ep 78: Batch #83 - Loss: 1.2075332403182983\n",
      "Ep 78: Batch #84 - Loss: 0.5773906707763672\n",
      "Ep 78: Batch #85 - Loss: 0.7836357951164246\n",
      "Ep 78: Batch #86 - Loss: 0.5467671751976013\n",
      "Ep 78: Batch #87 - Loss: 0.5709222555160522\n",
      "Ep 78: Batch #88 - Loss: 0.655738890171051\n",
      "Ep 78: Batch #89 - Loss: 0.7257201075553894\n",
      "Ep 78: Batch #90 - Loss: 0.9018459916114807\n",
      "Ep 78: Batch #91 - Loss: 0.6501016616821289\n",
      "Ep 78: Batch #92 - Loss: 0.7298967242240906\n",
      "Ep 78: Batch #93 - Loss: 0.7819892168045044\n",
      "Ep 78: Batch #94 - Loss: 0.7435346841812134\n",
      "Ep 78: Batch #95 - Loss: 0.7605293989181519\n",
      "Ep 78: Batch #96 - Loss: 0.7558466196060181\n",
      "Ep 78: Batch #97 - Loss: 0.5879700779914856\n",
      "Ep 78: Batch #98 - Loss: 0.5773078799247742\n",
      "Ep 78: Batch #99 - Loss: 0.7914049029350281\n",
      "Ep 78: Batch #100 - Loss: 0.5573510527610779\n",
      "Ep 78: Batch #101 - Loss: 0.8694282174110413\n",
      "Ep 78: Batch #102 - Loss: 0.612041175365448\n",
      "Ep 78: Batch #103 - Loss: 0.6344727277755737\n",
      "Ep 78: Batch #104 - Loss: 0.6599196195602417\n",
      "Ep 78: Batch #105 - Loss: 0.8181207180023193\n",
      "Ep 78: Batch #106 - Loss: 0.6262807250022888\n",
      "Ep 78: Batch #107 - Loss: 0.6152423024177551\n",
      "Ep 78: Batch #108 - Loss: 0.9010798931121826\n",
      "Ep 78: Batch #109 - Loss: 0.6255532503128052\n",
      "Ep 78: Batch #110 - Loss: 0.7235323786735535\n",
      "Ep 78: Batch #111 - Loss: 1.038110613822937\n",
      "Ep 78: Batch #112 - Loss: 0.7894570827484131\n",
      "Ep 78: Batch #113 - Loss: 0.6572085022926331\n",
      "Ep 78: Batch #114 - Loss: 0.7249056696891785\n",
      "Ep 78: Batch #115 - Loss: 0.910625159740448\n",
      "Ep 78: Batch #116 - Loss: 0.5212249755859375\n",
      "Ep 78: Batch #117 - Loss: 0.6782864332199097\n",
      "Ep 78: Batch #118 - Loss: 0.45411863923072815\n",
      "Model saved in file: ./weights_autoencoder_sigmoid/model_e78b118_1516648801.9356694.ckpt\n",
      "Ep 78: Batch #119 - Loss: 0.8078917860984802\n",
      "Ep 78: Batch #120 - Loss: 0.6587522029876709\n",
      "Ep 78: Batch #121 - Loss: 0.5602331757545471\n",
      "Ep 78: Batch #122 - Loss: 0.7093636393547058\n",
      "Ep 78: Batch #123 - Loss: 0.7150660753250122\n",
      "Ep 78: Batch #124 - Loss: 0.556272029876709\n",
      "Ep 78: Batch #125 - Loss: 2.4751811027526855\n",
      "Ep 78: Batch #126 - Loss: 1.0067728757858276\n",
      "Ep 78: Batch #127 - Loss: 0.5817630290985107\n",
      "Ep 78: Batch #128 - Loss: 0.8873258829116821\n",
      "Ep 78: Batch #129 - Loss: 0.6774417757987976\n",
      "Ep 78: Batch #130 - Loss: 0.5950532555580139\n",
      "Ep 78: Batch #131 - Loss: 0.8003032207489014\n",
      "Ep 78: Batch #132 - Loss: 0.6829702258110046\n",
      "Ep 78: Batch #133 - Loss: 0.6665114760398865\n",
      "Ep 78: Batch #134 - Loss: 0.6367018818855286\n",
      "Ep 78: Batch #135 - Loss: 0.8211381435394287\n",
      "Ep 78: Batch #136 - Loss: 1.0429428815841675\n",
      "Ep 78: Batch #137 - Loss: 0.7549908757209778\n",
      "Ep 78: Batch #138 - Loss: 0.9019074440002441\n",
      "Ep 78: Batch #139 - Loss: 0.6757050156593323\n",
      "Ep 78: Batch #140 - Loss: 0.8412593007087708\n",
      "Ep 78: Batch #141 - Loss: 1.1153074502944946\n",
      "Ep 78: Batch #142 - Loss: 0.6712511777877808\n",
      "Ep 78: Batch #143 - Loss: 0.7705023288726807\n",
      "Ep 78: Batch #144 - Loss: 0.6118999719619751\n",
      "Ep 78: Batch #145 - Loss: 0.5978389382362366\n",
      "Ep 78: Batch #146 - Loss: 0.6969189643859863\n",
      "Ep 78: Batch #147 - Loss: 0.6620805263519287\n",
      "Ep 78: Batch #148 - Loss: 0.7523007392883301\n",
      "Ep 78: Batch #149 - Loss: 0.6120964884757996\n",
      "Ep 78: Batch #150 - Loss: 0.7196512818336487\n",
      "Ep 78: Batch #151 - Loss: 0.6250444054603577\n",
      "Ep 78: Batch #152 - Loss: 0.606847882270813\n",
      "Ep 78: Batch #153 - Loss: 0.825975775718689\n",
      "Ep 78: Batch #154 - Loss: 0.6326631307601929\n",
      "Ep 78: Batch #155 - Loss: 0.6893693208694458\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 78: Batch #156 - Loss: 0.7774171233177185\n",
      "Ep 78: Batch #157 - Loss: 0.6122127771377563\n",
      "Ep 78: Batch #158 - Loss: 0.7171593308448792\n",
      "Ep 78: Batch #159 - Loss: 0.5964359641075134\n",
      "Ep 78: Batch #160 - Loss: 0.6908218860626221\n",
      "Ep 78: Batch #161 - Loss: 0.668792188167572\n",
      "Ep 78: Batch #162 - Loss: 0.718920886516571\n",
      "Ep 78: Batch #163 - Loss: 0.7604377269744873\n",
      "Ep 78: Batch #164 - Loss: 0.6473770141601562\n",
      "Ep 78: Batch #165 - Loss: 1.3380285501480103\n",
      "Ep 78: Batch #166 - Loss: 0.5339736938476562\n",
      "Ep 78: Batch #167 - Loss: 0.7040165066719055\n",
      "Ep 78: Batch #168 - Loss: 0.6926080584526062\n",
      "Ep 78: Batch #169 - Loss: 0.6661168932914734\n",
      "Ep 78: Batch #170 - Loss: 0.6271688342094421\n",
      "Ep 78: Batch #171 - Loss: 0.6422313451766968\n",
      "Ep 78: Batch #172 - Loss: 0.5337701439857483\n",
      "Ep 78: Batch #173 - Loss: 0.9277825951576233\n",
      "Ep 78: Batch #174 - Loss: 0.4943961799144745\n",
      "Ep 78: Batch #175 - Loss: 0.6348809003829956\n",
      "Ep 78: Batch #176 - Loss: 0.8961485028266907\n",
      "Ep 78: Batch #177 - Loss: 0.6470856666564941\n",
      "Ep 78: Batch #178 - Loss: 0.6208677887916565\n",
      "Ep 78: Batch #179 - Loss: 0.744346022605896\n",
      "Ep 78: Batch #180 - Loss: 0.6479841470718384\n",
      "Ep 78: Batch #181 - Loss: 0.8006002902984619\n",
      "Ep 78: Batch #182 - Loss: 0.6298710107803345\n",
      "Ep 78: Batch #183 - Loss: 0.6050560474395752\n",
      "Ep 78: Batch #184 - Loss: 0.9189305305480957\n",
      "Ep 78: Batch #185 - Loss: 0.6332629919052124\n",
      "Ep 78: Batch #186 - Loss: 0.7502939701080322\n",
      "Ep 78: Batch #187 - Loss: 0.8670414090156555\n",
      "Ep 78: Batch #188 - Loss: 0.9335495829582214\n",
      "Ep 78: Batch #189 - Loss: 0.5858529806137085\n",
      "Ep 78: Batch #190 - Loss: 0.6210528612136841\n",
      "Ep 78: Batch #191 - Loss: 0.8001846671104431\n",
      "Ep 78: Batch #192 - Loss: 0.5713955760002136\n",
      "Ep 78: Batch #193 - Loss: 0.6310309171676636\n",
      "Ep 78: Batch #194 - Loss: 0.5418630242347717\n",
      "Ep 78: Batch #195 - Loss: 0.7826897501945496\n",
      "Ep 78: Batch #196 - Loss: 0.693577229976654\n",
      "Ep 78: Batch #197 - Loss: 0.6989092230796814\n",
      "Ep 78: Batch #198 - Loss: 0.5338411927223206\n",
      "Ep 78: Batch #199 - Loss: 0.6422749161720276\n",
      "Ep 79: Batch #0 - Loss: 0.6510013341903687\n",
      "Ep 79: Batch #1 - Loss: 0.7176192402839661\n",
      "Ep 79: Batch #2 - Loss: 0.8605971336364746\n",
      "Ep 79: Batch #3 - Loss: 0.7209003567695618\n",
      "Ep 79: Batch #4 - Loss: 0.657380998134613\n",
      "Ep 79: Batch #5 - Loss: 0.5523024201393127\n",
      "Ep 79: Batch #6 - Loss: 0.7330455183982849\n",
      "Ep 79: Batch #7 - Loss: 0.575908899307251\n",
      "Ep 79: Batch #8 - Loss: 0.5845039486885071\n",
      "Ep 79: Batch #9 - Loss: 1.092325210571289\n",
      "Ep 79: Batch #10 - Loss: 0.7930774092674255\n",
      "Ep 79: Batch #11 - Loss: 0.5440549254417419\n",
      "Ep 79: Batch #12 - Loss: 1.1941680908203125\n",
      "Ep 79: Batch #13 - Loss: 0.5718112587928772\n",
      "Ep 79: Batch #14 - Loss: 0.5977122187614441\n",
      "Ep 79: Batch #15 - Loss: 0.8408617377281189\n",
      "Ep 79: Batch #16 - Loss: 0.9552394151687622\n",
      "Ep 79: Batch #17 - Loss: 0.73183673620224\n",
      "Ep 79: Batch #18 - Loss: 0.8099541664123535\n",
      "Ep 79: Batch #19 - Loss: 0.5636124610900879\n",
      "Ep 79: Batch #20 - Loss: 0.546143114566803\n",
      "Ep 79: Batch #21 - Loss: 0.7955463528633118\n",
      "Ep 79: Batch #22 - Loss: 0.6068679094314575\n",
      "Ep 79: Batch #23 - Loss: 0.5997869372367859\n",
      "Ep 79: Batch #24 - Loss: 0.6409721970558167\n",
      "Ep 79: Batch #25 - Loss: 0.6053252220153809\n",
      "Ep 79: Batch #26 - Loss: 0.5557124018669128\n",
      "Ep 79: Batch #27 - Loss: 1.1383204460144043\n",
      "Ep 79: Batch #28 - Loss: 0.6928413510322571\n",
      "Ep 79: Batch #29 - Loss: 0.7535437941551208\n",
      "Ep 79: Batch #30 - Loss: 0.8198930621147156\n",
      "Ep 79: Batch #31 - Loss: 0.5618171691894531\n",
      "Ep 79: Batch #32 - Loss: 0.5805591940879822\n",
      "Ep 79: Batch #33 - Loss: 0.6669808626174927\n",
      "Ep 79: Batch #34 - Loss: 0.6352929472923279\n",
      "Ep 79: Batch #35 - Loss: 0.7240877747535706\n",
      "Ep 79: Batch #36 - Loss: 0.584805965423584\n",
      "Ep 79: Batch #37 - Loss: 0.9203068017959595\n",
      "Ep 79: Batch #38 - Loss: 0.5676027536392212\n",
      "Ep 79: Batch #39 - Loss: 0.6866902112960815\n",
      "Ep 79: Batch #40 - Loss: 0.6041401624679565\n",
      "Ep 79: Batch #41 - Loss: 0.6194032430648804\n",
      "Ep 79: Batch #42 - Loss: 0.5697233080863953\n",
      "Ep 79: Batch #43 - Loss: 0.633429765701294\n",
      "Ep 79: Batch #44 - Loss: 0.6126030683517456\n",
      "Ep 79: Batch #45 - Loss: 0.5237162113189697\n",
      "Ep 79: Batch #46 - Loss: 0.6974207758903503\n",
      "Ep 79: Batch #47 - Loss: 0.8028126358985901\n",
      "Ep 79: Batch #48 - Loss: 1.0456851720809937\n",
      "Ep 79: Batch #49 - Loss: 0.8073588609695435\n",
      "Ep 79: Batch #50 - Loss: 0.5735469460487366\n",
      "Ep 79: Batch #51 - Loss: 0.8171019554138184\n",
      "Ep 79: Batch #52 - Loss: 0.6759474277496338\n",
      "Ep 79: Batch #53 - Loss: 0.7145355939865112\n",
      "Ep 79: Batch #54 - Loss: 0.5776209831237793\n",
      "Ep 79: Batch #55 - Loss: 0.6050227880477905\n",
      "Ep 79: Batch #56 - Loss: 0.8596128225326538\n",
      "Ep 79: Batch #57 - Loss: 0.6814495921134949\n",
      "Ep 79: Batch #58 - Loss: 0.8234358429908752\n",
      "Ep 79: Batch #59 - Loss: 0.5563052296638489\n",
      "Ep 79: Batch #60 - Loss: 1.0069037675857544\n",
      "Ep 79: Batch #61 - Loss: 0.5350284576416016\n",
      "Ep 79: Batch #62 - Loss: 0.574542760848999\n",
      "Ep 79: Batch #63 - Loss: 0.7788378000259399\n",
      "Ep 79: Batch #64 - Loss: 8.046725273132324\n",
      "Ep 79: Batch #65 - Loss: 0.5235582590103149\n",
      "Ep 79: Batch #66 - Loss: 0.6642681956291199\n",
      "Ep 79: Batch #67 - Loss: 0.7755489349365234\n",
      "Ep 79: Batch #68 - Loss: 0.7128546833992004\n",
      "Ep 79: Batch #69 - Loss: 0.5865252614021301\n",
      "Ep 79: Batch #70 - Loss: 0.6153877973556519\n",
      "Ep 79: Batch #71 - Loss: 0.5350072383880615\n",
      "Ep 79: Batch #72 - Loss: 0.6631553173065186\n",
      "Ep 79: Batch #73 - Loss: 0.719714343547821\n",
      "Ep 79: Batch #74 - Loss: 0.5761072635650635\n",
      "Ep 79: Batch #75 - Loss: 0.6662776470184326\n",
      "Ep 79: Batch #76 - Loss: 0.9227373600006104\n",
      "Ep 79: Batch #77 - Loss: 0.5755828619003296\n",
      "Ep 79: Batch #78 - Loss: 0.9167570471763611\n",
      "Ep 79: Batch #79 - Loss: 0.5249906778335571\n",
      "Ep 79: Batch #80 - Loss: 0.6898527145385742\n",
      "Ep 79: Batch #81 - Loss: 1.5242812633514404\n",
      "Ep 79: Batch #82 - Loss: 0.7541903853416443\n",
      "Ep 79: Batch #83 - Loss: 1.2057461738586426\n",
      "Ep 79: Batch #84 - Loss: 0.5776734352111816\n",
      "Ep 79: Batch #85 - Loss: 0.783855676651001\n",
      "Ep 79: Batch #86 - Loss: 0.5463686585426331\n",
      "Ep 79: Batch #87 - Loss: 0.5713165998458862\n",
      "Ep 79: Batch #88 - Loss: 0.6562988758087158\n",
      "Ep 79: Batch #89 - Loss: 0.7256782650947571\n",
      "Ep 79: Batch #90 - Loss: 0.9021714329719543\n",
      "Ep 79: Batch #91 - Loss: 0.6503022909164429\n",
      "Ep 79: Batch #92 - Loss: 0.7303574085235596\n",
      "Ep 79: Batch #93 - Loss: 0.7815728783607483\n",
      "Ep 79: Batch #94 - Loss: 0.744516134262085\n",
      "Ep 79: Batch #95 - Loss: 0.7607818841934204\n",
      "Ep 79: Batch #96 - Loss: 0.756167471408844\n",
      "Ep 79: Batch #97 - Loss: 0.5876975655555725\n",
      "Ep 79: Batch #98 - Loss: 0.5776892900466919\n",
      "Ep 79: Batch #99 - Loss: 0.7924885749816895\n",
      "Ep 79: Batch #100 - Loss: 0.5574085712432861\n",
      "Ep 79: Batch #101 - Loss: 0.8694154024124146\n",
      "Ep 79: Batch #102 - Loss: 0.6124206781387329\n",
      "Ep 79: Batch #103 - Loss: 0.6349002122879028\n",
      "Ep 79: Batch #104 - Loss: 0.6607106924057007\n",
      "Ep 79: Batch #105 - Loss: 0.8187397718429565\n",
      "Ep 79: Batch #106 - Loss: 0.6262848377227783\n",
      "Ep 79: Batch #107 - Loss: 0.6153974533081055\n",
      "Ep 79: Batch #108 - Loss: 0.9008897542953491\n",
      "Ep 79: Batch #109 - Loss: 0.626453161239624\n",
      "Ep 79: Batch #110 - Loss: 0.7243921160697937\n",
      "Ep 79: Batch #111 - Loss: 1.0388894081115723\n",
      "Ep 79: Batch #112 - Loss: 0.7897218465805054\n",
      "Ep 79: Batch #113 - Loss: 0.6576287746429443\n",
      "Ep 79: Batch #114 - Loss: 0.7253528237342834\n",
      "Ep 79: Batch #115 - Loss: 0.9106824994087219\n",
      "Ep 79: Batch #116 - Loss: 0.5214802622795105\n",
      "Ep 79: Batch #117 - Loss: 0.6787871718406677\n",
      "Ep 79: Batch #118 - Loss: 0.4541340172290802\n",
      "Ep 79: Batch #119 - Loss: 0.8071783781051636\n",
      "Ep 79: Batch #120 - Loss: 0.6586117744445801\n",
      "Ep 79: Batch #121 - Loss: 0.5603983402252197\n",
      "Ep 79: Batch #122 - Loss: 0.7090562582015991\n",
      "Ep 79: Batch #123 - Loss: 0.7148281335830688\n",
      "Ep 79: Batch #124 - Loss: 0.5565040707588196\n",
      "Ep 79: Batch #125 - Loss: 2.476769208908081\n",
      "Ep 79: Batch #126 - Loss: 1.0074015855789185\n",
      "Ep 79: Batch #127 - Loss: 0.5820171236991882\n",
      "Ep 79: Batch #128 - Loss: 0.8874470591545105\n",
      "Ep 79: Batch #129 - Loss: 0.6781321167945862\n",
      "Ep 79: Batch #130 - Loss: 0.5953078269958496\n",
      "Ep 79: Batch #131 - Loss: 0.8008373975753784\n",
      "Ep 79: Batch #132 - Loss: 0.6830780506134033\n",
      "Ep 79: Batch #133 - Loss: 0.6665164828300476\n",
      "Ep 79: Batch #134 - Loss: 0.6366763114929199\n",
      "Ep 79: Batch #135 - Loss: 0.8216035962104797\n",
      "Ep 79: Batch #136 - Loss: 1.0426706075668335\n",
      "Ep 79: Batch #137 - Loss: 0.7557600140571594\n",
      "Ep 79: Batch #138 - Loss: 0.9017172455787659\n",
      "Ep 79: Batch #139 - Loss: 0.6750437021255493\n",
      "Ep 79: Batch #140 - Loss: 0.8414487838745117\n",
      "Ep 79: Batch #141 - Loss: 1.1154799461364746\n",
      "Ep 79: Batch #142 - Loss: 0.6716516613960266\n",
      "Ep 79: Batch #143 - Loss: 0.7707738280296326\n",
      "Ep 79: Batch #144 - Loss: 0.6118231415748596\n",
      "Ep 79: Batch #145 - Loss: 0.5980085134506226\n",
      "Ep 79: Batch #146 - Loss: 0.6969608664512634\n",
      "Ep 79: Batch #147 - Loss: 0.6622321009635925\n",
      "Ep 79: Batch #148 - Loss: 0.7529823184013367\n",
      "Ep 79: Batch #149 - Loss: 0.6123226881027222\n",
      "Ep 79: Batch #150 - Loss: 0.7197831273078918\n",
      "Ep 79: Batch #151 - Loss: 0.6253520250320435\n",
      "Ep 79: Batch #152 - Loss: 0.606907069683075\n",
      "Ep 79: Batch #153 - Loss: 0.826406717300415\n",
      "Ep 79: Batch #154 - Loss: 0.6327377557754517\n",
      "Ep 79: Batch #155 - Loss: 0.689458966255188\n",
      "Ep 79: Batch #156 - Loss: 0.7771626114845276\n",
      "Ep 79: Batch #157 - Loss: 0.6122976541519165\n",
      "Ep 79: Batch #158 - Loss: 0.7172930240631104\n",
      "Ep 79: Batch #159 - Loss: 0.5964333415031433\n",
      "Ep 79: Batch #160 - Loss: 0.6905946731567383\n",
      "Ep 79: Batch #161 - Loss: 0.6687555909156799\n",
      "Ep 79: Batch #162 - Loss: 0.719269335269928\n",
      "Ep 79: Batch #163 - Loss: 0.7604230642318726\n",
      "Ep 79: Batch #164 - Loss: 0.6474950909614563\n",
      "Ep 79: Batch #165 - Loss: 1.3394078016281128\n",
      "Ep 79: Batch #166 - Loss: 0.5340911746025085\n",
      "Ep 79: Batch #167 - Loss: 0.7040766477584839\n",
      "Ep 79: Batch #168 - Loss: 0.6928498148918152\n",
      "Ep 79: Batch #169 - Loss: 0.6660095453262329\n",
      "Ep 79: Batch #170 - Loss: 0.627641499042511\n",
      "Ep 79: Batch #171 - Loss: 0.642254650592804\n",
      "Ep 79: Batch #172 - Loss: 0.5339208841323853\n",
      "Ep 79: Batch #173 - Loss: 0.9284359216690063\n",
      "Ep 79: Batch #174 - Loss: 0.49432986974716187\n",
      "Ep 79: Batch #175 - Loss: 0.634997546672821\n",
      "Ep 79: Batch #176 - Loss: 0.8962588310241699\n",
      "Ep 79: Batch #177 - Loss: 0.6471693515777588\n",
      "Ep 79: Batch #178 - Loss: 0.6210419535636902\n",
      "Ep 79: Batch #179 - Loss: 0.744577169418335\n",
      "Ep 79: Batch #180 - Loss: 0.6478726863861084\n",
      "Ep 79: Batch #181 - Loss: 0.8012036681175232\n",
      "Ep 79: Batch #182 - Loss: 0.6298577189445496\n",
      "Ep 79: Batch #183 - Loss: 0.6052889227867126\n",
      "Ep 79: Batch #184 - Loss: 0.9190501570701599\n",
      "Ep 79: Batch #185 - Loss: 0.6340733766555786\n",
      "Ep 79: Batch #186 - Loss: 0.7505156993865967\n",
      "Ep 79: Batch #187 - Loss: 0.8677318692207336\n",
      "Ep 79: Batch #188 - Loss: 0.9326748251914978\n",
      "Ep 79: Batch #189 - Loss: 0.586115300655365\n",
      "Ep 79: Batch #190 - Loss: 0.6215329766273499\n",
      "Ep 79: Batch #191 - Loss: 0.8004493713378906\n",
      "Ep 79: Batch #192 - Loss: 0.5716105699539185\n",
      "Ep 79: Batch #193 - Loss: 0.6313486099243164\n",
      "Ep 79: Batch #194 - Loss: 0.5417994856834412\n",
      "Ep 79: Batch #195 - Loss: 0.7827612161636353\n",
      "Ep 79: Batch #196 - Loss: 0.6937564611434937\n",
      "Ep 79: Batch #197 - Loss: 0.6988522410392761\n",
      "Ep 79: Batch #198 - Loss: 0.5338538289070129\n",
      "Ep 79: Batch #199 - Loss: 0.642332911491394\n",
      "Ep 80: Batch #0 - Loss: 0.6512631773948669\n",
      "Ep 80: Batch #1 - Loss: 0.7177145481109619\n",
      "Ep 80: Batch #2 - Loss: 0.8606937527656555\n",
      "Ep 80: Batch #3 - Loss: 0.721041202545166\n",
      "Ep 80: Batch #4 - Loss: 0.6574500799179077\n",
      "Ep 80: Batch #5 - Loss: 0.5521864891052246\n",
      "Ep 80: Batch #6 - Loss: 0.7329049706459045\n",
      "Ep 80: Batch #7 - Loss: 0.5758194327354431\n",
      "Ep 80: Batch #8 - Loss: 0.5845003128051758\n",
      "Ep 80: Batch #9 - Loss: 1.0928696393966675\n",
      "Ep 80: Batch #10 - Loss: 0.7928197383880615\n",
      "Ep 80: Batch #11 - Loss: 0.5441498160362244\n",
      "Ep 80: Batch #12 - Loss: 1.194151759147644\n",
      "Ep 80: Batch #13 - Loss: 0.5718801021575928\n",
      "Ep 80: Batch #14 - Loss: 0.5976658463478088\n",
      "Ep 80: Batch #15 - Loss: 0.8408737182617188\n",
      "Ep 80: Batch #16 - Loss: 0.9550215005874634\n",
      "Ep 80: Batch #17 - Loss: 0.7318518757820129\n",
      "Ep 80: Batch #18 - Loss: 0.8100384473800659\n",
      "Ep 80: Batch #19 - Loss: 0.5636236667633057\n",
      "Ep 80: Batch #20 - Loss: 0.5461959838867188\n",
      "Ep 80: Batch #21 - Loss: 0.7947338819503784\n",
      "Ep 80: Batch #22 - Loss: 0.6066858768463135\n",
      "Ep 80: Batch #23 - Loss: 0.5997439026832581\n",
      "Ep 80: Batch #24 - Loss: 0.6411089301109314\n",
      "Ep 80: Batch #25 - Loss: 0.605266809463501\n",
      "Ep 80: Batch #26 - Loss: 0.5557219982147217\n",
      "Ep 80: Batch #27 - Loss: 1.138436198234558\n",
      "Ep 80: Batch #28 - Loss: 0.6928211450576782\n",
      "Ep 80: Batch #29 - Loss: 0.7535785436630249\n",
      "Ep 80: Batch #30 - Loss: 0.8193138837814331\n",
      "Ep 80: Batch #31 - Loss: 0.5617631077766418\n",
      "Ep 80: Batch #32 - Loss: 0.5805431604385376\n",
      "Ep 80: Batch #33 - Loss: 0.6669002175331116\n",
      "Ep 80: Batch #34 - Loss: 0.6350833177566528\n",
      "Ep 80: Batch #35 - Loss: 0.7240990400314331\n",
      "Ep 80: Batch #36 - Loss: 0.58493572473526\n",
      "Ep 80: Batch #37 - Loss: 0.9202702641487122\n",
      "Ep 80: Batch #38 - Loss: 0.5674688220024109\n",
      "Ep 80: Batch #39 - Loss: 0.686579167842865\n",
      "Ep 80: Batch #40 - Loss: 0.6041597127914429\n",
      "Ep 80: Batch #41 - Loss: 0.6193755269050598\n",
      "Ep 80: Batch #42 - Loss: 0.5698453783988953\n",
      "Ep 80: Batch #43 - Loss: 0.6334802508354187\n",
      "Ep 80: Batch #44 - Loss: 0.6125103831291199\n",
      "Ep 80: Batch #45 - Loss: 0.5236826539039612\n",
      "Ep 80: Batch #46 - Loss: 0.6975195407867432\n",
      "Ep 80: Batch #47 - Loss: 0.8027795553207397\n",
      "Ep 80: Batch #48 - Loss: 1.0459970235824585\n",
      "Ep 80: Batch #49 - Loss: 0.807186484336853\n",
      "Ep 80: Batch #50 - Loss: 0.5735043883323669\n",
      "Ep 80: Batch #51 - Loss: 0.8172261118888855\n",
      "Ep 80: Batch #52 - Loss: 0.6759483814239502\n",
      "Ep 80: Batch #53 - Loss: 0.714799165725708\n",
      "Ep 80: Batch #54 - Loss: 0.5775551199913025\n",
      "Ep 80: Batch #55 - Loss: 0.6049790382385254\n",
      "Ep 80: Batch #56 - Loss: 0.8598126173019409\n",
      "Ep 80: Batch #57 - Loss: 0.6814221739768982\n",
      "Ep 80: Batch #58 - Loss: 0.8234987854957581\n",
      "Ep 80: Batch #59 - Loss: 0.5563055872917175\n",
      "Ep 80: Batch #60 - Loss: 1.0068762302398682\n",
      "Ep 80: Batch #61 - Loss: 0.5349626541137695\n",
      "Ep 80: Batch #62 - Loss: 0.5744826793670654\n",
      "Ep 80: Batch #63 - Loss: 0.7788446545600891\n",
      "Ep 80: Batch #64 - Loss: 8.032386779785156\n",
      "Ep 80: Batch #65 - Loss: 0.5236031413078308\n",
      "Ep 80: Batch #66 - Loss: 0.6640737056732178\n",
      "Ep 80: Batch #67 - Loss: 0.7753307819366455\n",
      "Ep 80: Batch #68 - Loss: 0.7126592397689819\n",
      "Ep 80: Batch #69 - Loss: 0.5864136219024658\n",
      "Ep 80: Batch #70 - Loss: 0.6152034401893616\n",
      "Ep 80: Batch #71 - Loss: 0.5348230004310608\n",
      "Ep 80: Batch #72 - Loss: 0.6626035571098328\n",
      "Ep 80: Batch #73 - Loss: 0.7196399569511414\n",
      "Ep 80: Batch #74 - Loss: 0.5761207938194275\n",
      "Ep 80: Batch #75 - Loss: 0.6661035418510437\n",
      "Ep 80: Batch #76 - Loss: 0.9225220680236816\n",
      "Ep 80: Batch #77 - Loss: 0.5754384398460388\n",
      "Ep 80: Batch #78 - Loss: 0.9165066480636597\n",
      "Ep 80: Batch #79 - Loss: 0.5248047113418579\n",
      "Ep 80: Batch #80 - Loss: 0.6897296905517578\n",
      "Ep 80: Batch #81 - Loss: 1.5224202871322632\n",
      "Ep 80: Batch #82 - Loss: 0.7537548542022705\n",
      "Ep 80: Batch #83 - Loss: 1.2033990621566772\n",
      "Ep 80: Batch #84 - Loss: 0.577214241027832\n",
      "Ep 80: Batch #85 - Loss: 0.78337562084198\n",
      "Ep 80: Batch #86 - Loss: 0.5464732646942139\n",
      "Ep 80: Batch #87 - Loss: 0.5708745121955872\n",
      "Ep 80: Batch #88 - Loss: 0.6558859944343567\n",
      "Ep 80: Batch #89 - Loss: 0.7253866791725159\n",
      "Ep 80: Batch #90 - Loss: 0.9018793106079102\n",
      "Ep 80: Batch #91 - Loss: 0.650183916091919\n",
      "Ep 80: Batch #92 - Loss: 0.7296760082244873\n",
      "Ep 80: Batch #93 - Loss: 0.7813702821731567\n",
      "Ep 80: Batch #94 - Loss: 0.743539571762085\n",
      "Ep 80: Batch #95 - Loss: 0.7602808475494385\n",
      "Ep 80: Batch #96 - Loss: 0.7557426691055298\n",
      "Ep 80: Batch #97 - Loss: 0.588027834892273\n",
      "Ep 80: Batch #98 - Loss: 0.5773313641548157\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 80: Batch #99 - Loss: 0.7910102009773254\n",
      "Ep 80: Batch #100 - Loss: 0.5572054386138916\n",
      "Ep 80: Batch #101 - Loss: 0.8696902394294739\n",
      "Ep 80: Batch #102 - Loss: 0.6119587421417236\n",
      "Ep 80: Batch #103 - Loss: 0.6343428492546082\n",
      "Ep 80: Batch #104 - Loss: 0.6598770618438721\n",
      "Ep 80: Batch #105 - Loss: 0.8187320232391357\n",
      "Ep 80: Batch #106 - Loss: 0.6263963580131531\n",
      "Ep 80: Batch #107 - Loss: 0.6153260469436646\n",
      "Ep 80: Batch #108 - Loss: 0.9008820056915283\n",
      "Ep 80: Batch #109 - Loss: 0.6254921555519104\n",
      "Ep 80: Batch #110 - Loss: 0.7233891487121582\n",
      "Ep 80: Batch #111 - Loss: 1.037959337234497\n",
      "Ep 80: Batch #112 - Loss: 0.7891883254051208\n",
      "Ep 80: Batch #113 - Loss: 0.6572765111923218\n",
      "Ep 80: Batch #114 - Loss: 0.724638819694519\n",
      "Ep 80: Batch #115 - Loss: 0.9107046127319336\n",
      "Ep 80: Batch #116 - Loss: 0.5211021304130554\n",
      "Ep 80: Batch #117 - Loss: 0.678544282913208\n",
      "Ep 80: Batch #118 - Loss: 0.4540253281593323\n",
      "Model saved in file: ./weights_autoencoder_sigmoid/model_e80b118_1516648802.1922784.ckpt\n",
      "Ep 80: Batch #119 - Loss: 0.8076797127723694\n",
      "Ep 80: Batch #120 - Loss: 0.6588391661643982\n",
      "Ep 80: Batch #121 - Loss: 0.5600487589836121\n",
      "Ep 80: Batch #122 - Loss: 0.7091361880302429\n",
      "Ep 80: Batch #123 - Loss: 0.7147906422615051\n",
      "Ep 80: Batch #124 - Loss: 0.5561617016792297\n",
      "Ep 80: Batch #125 - Loss: 2.4751229286193848\n",
      "Ep 80: Batch #126 - Loss: 1.0069537162780762\n",
      "Ep 80: Batch #127 - Loss: 0.5817165374755859\n",
      "Ep 80: Batch #128 - Loss: 0.8874675631523132\n",
      "Ep 80: Batch #129 - Loss: 0.6772853136062622\n",
      "Ep 80: Batch #130 - Loss: 0.5949517488479614\n",
      "Ep 80: Batch #131 - Loss: 0.799856960773468\n",
      "Ep 80: Batch #132 - Loss: 0.6829280853271484\n",
      "Ep 80: Batch #133 - Loss: 0.6665814518928528\n",
      "Ep 80: Batch #134 - Loss: 0.636415958404541\n",
      "Ep 80: Batch #135 - Loss: 0.8209606409072876\n",
      "Ep 80: Batch #136 - Loss: 1.0426055192947388\n",
      "Ep 80: Batch #137 - Loss: 0.7545509338378906\n",
      "Ep 80: Batch #138 - Loss: 0.9019767642021179\n",
      "Ep 80: Batch #139 - Loss: 0.6743620038032532\n",
      "Ep 80: Batch #140 - Loss: 0.8412573337554932\n",
      "Ep 80: Batch #141 - Loss: 1.1140799522399902\n",
      "Ep 80: Batch #142 - Loss: 0.6711159348487854\n",
      "Ep 80: Batch #143 - Loss: 0.7702760100364685\n",
      "Ep 80: Batch #144 - Loss: 0.6117306351661682\n",
      "Ep 80: Batch #145 - Loss: 0.5979000329971313\n",
      "Ep 80: Batch #146 - Loss: 0.6966155767440796\n",
      "Ep 80: Batch #147 - Loss: 0.6619956493377686\n",
      "Ep 80: Batch #148 - Loss: 0.752099871635437\n",
      "Ep 80: Batch #149 - Loss: 0.6120510697364807\n",
      "Ep 80: Batch #150 - Loss: 0.7194463610649109\n",
      "Ep 80: Batch #151 - Loss: 0.6249480843544006\n",
      "Ep 80: Batch #152 - Loss: 0.606847882270813\n",
      "Ep 80: Batch #153 - Loss: 0.8260313868522644\n",
      "Ep 80: Batch #154 - Loss: 0.6324252486228943\n",
      "Ep 80: Batch #155 - Loss: 0.6890400648117065\n",
      "Ep 80: Batch #156 - Loss: 0.777056872844696\n",
      "Ep 80: Batch #157 - Loss: 0.6122437119483948\n",
      "Ep 80: Batch #158 - Loss: 0.7170074582099915\n",
      "Ep 80: Batch #159 - Loss: 0.5964840650558472\n",
      "Ep 80: Batch #160 - Loss: 0.690471887588501\n",
      "Ep 80: Batch #161 - Loss: 0.6688375473022461\n",
      "Ep 80: Batch #162 - Loss: 0.7190214395523071\n",
      "Ep 80: Batch #163 - Loss: 0.7604912519454956\n",
      "Ep 80: Batch #164 - Loss: 0.6475805044174194\n",
      "Ep 80: Batch #165 - Loss: 1.3379689455032349\n",
      "Ep 80: Batch #166 - Loss: 0.534022867679596\n",
      "Ep 80: Batch #167 - Loss: 0.7036640644073486\n",
      "Ep 80: Batch #168 - Loss: 0.6926237940788269\n",
      "Ep 80: Batch #169 - Loss: 0.6658334136009216\n",
      "Ep 80: Batch #170 - Loss: 0.6272519826889038\n",
      "Ep 80: Batch #171 - Loss: 0.6421996355056763\n",
      "Ep 80: Batch #172 - Loss: 0.53378826379776\n",
      "Ep 80: Batch #173 - Loss: 0.9276951551437378\n",
      "Ep 80: Batch #174 - Loss: 0.4944113790988922\n",
      "Ep 80: Batch #175 - Loss: 0.6346136331558228\n",
      "Ep 80: Batch #176 - Loss: 0.8957343101501465\n",
      "Ep 80: Batch #177 - Loss: 0.646668553352356\n",
      "Ep 80: Batch #178 - Loss: 0.6206201314926147\n",
      "Ep 80: Batch #179 - Loss: 0.7440357208251953\n",
      "Ep 80: Batch #180 - Loss: 0.6479276418685913\n",
      "Ep 80: Batch #181 - Loss: 0.800478994846344\n",
      "Ep 80: Batch #182 - Loss: 0.629820704460144\n",
      "Ep 80: Batch #183 - Loss: 0.6049954891204834\n",
      "Ep 80: Batch #184 - Loss: 0.9189347624778748\n",
      "Ep 80: Batch #185 - Loss: 0.6333077549934387\n",
      "Ep 80: Batch #186 - Loss: 0.7501696348190308\n",
      "Ep 80: Batch #187 - Loss: 0.8671465516090393\n",
      "Ep 80: Batch #188 - Loss: 0.9316354393959045\n",
      "Ep 80: Batch #189 - Loss: 0.5857909917831421\n",
      "Ep 80: Batch #190 - Loss: 0.6210777759552002\n",
      "Ep 80: Batch #191 - Loss: 0.7999024391174316\n",
      "Ep 80: Batch #192 - Loss: 0.5716712474822998\n",
      "Ep 80: Batch #193 - Loss: 0.6311944127082825\n",
      "Ep 80: Batch #194 - Loss: 0.5416676998138428\n",
      "Ep 80: Batch #195 - Loss: 0.7826123237609863\n",
      "Ep 80: Batch #196 - Loss: 0.6937008500099182\n",
      "Ep 80: Batch #197 - Loss: 0.6988341808319092\n",
      "Ep 80: Batch #198 - Loss: 0.5339242219924927\n",
      "Ep 80: Batch #199 - Loss: 0.6419206857681274\n",
      "Ep 81: Batch #0 - Loss: 0.6510363221168518\n",
      "Ep 81: Batch #1 - Loss: 0.7179000973701477\n",
      "Ep 81: Batch #2 - Loss: 0.8603792190551758\n",
      "Ep 81: Batch #3 - Loss: 0.721085786819458\n",
      "Ep 81: Batch #4 - Loss: 0.6572726964950562\n",
      "Ep 81: Batch #5 - Loss: 0.5522222518920898\n",
      "Ep 81: Batch #6 - Loss: 0.732654333114624\n",
      "Ep 81: Batch #7 - Loss: 0.5756597518920898\n",
      "Ep 81: Batch #8 - Loss: 0.5844279527664185\n",
      "Ep 81: Batch #9 - Loss: 1.0922276973724365\n",
      "Ep 81: Batch #10 - Loss: 0.7923996448516846\n",
      "Ep 81: Batch #11 - Loss: 0.5440806150436401\n",
      "Ep 81: Batch #12 - Loss: 1.19403874874115\n",
      "Ep 81: Batch #13 - Loss: 0.5718961954116821\n",
      "Ep 81: Batch #14 - Loss: 0.5977553129196167\n",
      "Ep 81: Batch #15 - Loss: 0.8404159545898438\n",
      "Ep 81: Batch #16 - Loss: 0.9549852609634399\n",
      "Ep 81: Batch #17 - Loss: 0.7316485047340393\n",
      "Ep 81: Batch #18 - Loss: 0.8100534677505493\n",
      "Ep 81: Batch #19 - Loss: 0.5635762214660645\n",
      "Ep 81: Batch #20 - Loss: 0.5462262630462646\n",
      "Ep 81: Batch #21 - Loss: 0.7941171526908875\n",
      "Ep 81: Batch #22 - Loss: 0.6065549254417419\n",
      "Ep 81: Batch #23 - Loss: 0.5997900366783142\n",
      "Ep 81: Batch #24 - Loss: 0.6414238810539246\n",
      "Ep 81: Batch #25 - Loss: 0.6053021550178528\n",
      "Ep 81: Batch #26 - Loss: 0.555492639541626\n",
      "Ep 81: Batch #27 - Loss: 1.138342022895813\n",
      "Ep 81: Batch #28 - Loss: 0.6930044889450073\n",
      "Ep 81: Batch #29 - Loss: 0.7536038160324097\n",
      "Ep 81: Batch #30 - Loss: 0.8192213773727417\n",
      "Ep 81: Batch #31 - Loss: 0.5619230270385742\n",
      "Ep 81: Batch #32 - Loss: 0.5806230306625366\n",
      "Ep 81: Batch #33 - Loss: 0.666862428188324\n",
      "Ep 81: Batch #34 - Loss: 0.6349596381187439\n",
      "Ep 81: Batch #35 - Loss: 0.7239394783973694\n",
      "Ep 81: Batch #36 - Loss: 0.5849406123161316\n",
      "Ep 81: Batch #37 - Loss: 0.9203510880470276\n",
      "Ep 81: Batch #38 - Loss: 0.5673404932022095\n",
      "Ep 81: Batch #39 - Loss: 0.686922550201416\n",
      "Ep 81: Batch #40 - Loss: 0.6041514277458191\n",
      "Ep 81: Batch #41 - Loss: 0.6193376779556274\n",
      "Ep 81: Batch #42 - Loss: 0.5698716044425964\n",
      "Ep 81: Batch #43 - Loss: 0.6334866881370544\n",
      "Ep 81: Batch #44 - Loss: 0.6123490333557129\n",
      "Ep 81: Batch #45 - Loss: 0.5235767960548401\n",
      "Ep 81: Batch #46 - Loss: 0.6976478099822998\n",
      "Ep 81: Batch #47 - Loss: 0.8027327060699463\n",
      "Ep 81: Batch #48 - Loss: 1.0465984344482422\n",
      "Ep 81: Batch #49 - Loss: 0.8071008920669556\n",
      "Ep 81: Batch #50 - Loss: 0.5735127925872803\n",
      "Ep 81: Batch #51 - Loss: 0.8171525597572327\n",
      "Ep 81: Batch #52 - Loss: 0.6759962439537048\n",
      "Ep 81: Batch #53 - Loss: 0.7140814065933228\n",
      "Ep 81: Batch #54 - Loss: 0.5775406956672668\n",
      "Ep 81: Batch #55 - Loss: 0.6051374077796936\n",
      "Ep 81: Batch #56 - Loss: 0.8596541881561279\n",
      "Ep 81: Batch #57 - Loss: 0.6814243793487549\n",
      "Ep 81: Batch #58 - Loss: 0.8232481479644775\n",
      "Ep 81: Batch #59 - Loss: 0.5561614036560059\n",
      "Ep 81: Batch #60 - Loss: 1.0072777271270752\n",
      "Ep 81: Batch #61 - Loss: 0.5349528193473816\n",
      "Ep 81: Batch #62 - Loss: 0.574489176273346\n",
      "Ep 81: Batch #63 - Loss: 0.7789834141731262\n",
      "Ep 81: Batch #64 - Loss: 8.018302917480469\n",
      "Ep 81: Batch #65 - Loss: 0.5237019062042236\n",
      "Ep 81: Batch #66 - Loss: 0.6639645099639893\n",
      "Ep 81: Batch #67 - Loss: 0.7754851579666138\n",
      "Ep 81: Batch #68 - Loss: 0.7129320502281189\n",
      "Ep 81: Batch #69 - Loss: 0.5866273045539856\n",
      "Ep 81: Batch #70 - Loss: 0.6153247356414795\n",
      "Ep 81: Batch #71 - Loss: 0.5348012447357178\n",
      "Ep 81: Batch #72 - Loss: 0.6631248593330383\n",
      "Ep 81: Batch #73 - Loss: 0.7198743224143982\n",
      "Ep 81: Batch #74 - Loss: 0.5761772394180298\n",
      "Ep 81: Batch #75 - Loss: 0.66614830493927\n",
      "Ep 81: Batch #76 - Loss: 0.9226762652397156\n",
      "Ep 81: Batch #77 - Loss: 0.575624942779541\n",
      "Ep 81: Batch #78 - Loss: 0.9164317846298218\n",
      "Ep 81: Batch #79 - Loss: 0.5249207615852356\n",
      "Ep 81: Batch #80 - Loss: 0.6897801160812378\n",
      "Ep 81: Batch #81 - Loss: 1.5244802236557007\n",
      "Ep 81: Batch #82 - Loss: 0.7552450895309448\n",
      "Ep 81: Batch #83 - Loss: 1.201357126235962\n",
      "Ep 81: Batch #84 - Loss: 0.5774558782577515\n",
      "Ep 81: Batch #85 - Loss: 0.7834782004356384\n",
      "Ep 81: Batch #86 - Loss: 0.5462399125099182\n",
      "Ep 81: Batch #87 - Loss: 0.570893406867981\n",
      "Ep 81: Batch #88 - Loss: 0.6562420725822449\n",
      "Ep 81: Batch #89 - Loss: 0.7252540588378906\n",
      "Ep 81: Batch #90 - Loss: 0.9025667309761047\n",
      "Ep 81: Batch #91 - Loss: 0.6501753926277161\n",
      "Ep 81: Batch #92 - Loss: 0.7299760580062866\n",
      "Ep 81: Batch #93 - Loss: 0.7811543345451355\n",
      "Ep 81: Batch #94 - Loss: 0.744201123714447\n",
      "Ep 81: Batch #95 - Loss: 0.7607583999633789\n",
      "Ep 81: Batch #96 - Loss: 0.7560520172119141\n",
      "Ep 81: Batch #97 - Loss: 0.5877828001976013\n",
      "Ep 81: Batch #98 - Loss: 0.5774469971656799\n",
      "Ep 81: Batch #99 - Loss: 0.7920979261398315\n",
      "Ep 81: Batch #100 - Loss: 0.5572055578231812\n",
      "Ep 81: Batch #101 - Loss: 0.8694069981575012\n",
      "Ep 81: Batch #102 - Loss: 0.6121295094490051\n",
      "Ep 81: Batch #103 - Loss: 0.6346533298492432\n",
      "Ep 81: Batch #104 - Loss: 0.6603238582611084\n",
      "Ep 81: Batch #105 - Loss: 0.8188875913619995\n",
      "Ep 81: Batch #106 - Loss: 0.6264480948448181\n",
      "Ep 81: Batch #107 - Loss: 0.6155123114585876\n",
      "Ep 81: Batch #108 - Loss: 0.9008041620254517\n",
      "Ep 81: Batch #109 - Loss: 0.626291036605835\n",
      "Ep 81: Batch #110 - Loss: 0.724223792552948\n",
      "Ep 81: Batch #111 - Loss: 1.03825843334198\n",
      "Ep 81: Batch #112 - Loss: 0.7891992330551147\n",
      "Ep 81: Batch #113 - Loss: 0.6575269103050232\n",
      "Ep 81: Batch #114 - Loss: 0.7250369191169739\n",
      "Ep 81: Batch #115 - Loss: 0.9106719493865967\n",
      "Ep 81: Batch #116 - Loss: 0.521299421787262\n",
      "Ep 81: Batch #117 - Loss: 0.6786807775497437\n",
      "Ep 81: Batch #118 - Loss: 0.45406728982925415\n",
      "Ep 81: Batch #119 - Loss: 0.8069702982902527\n",
      "Ep 81: Batch #120 - Loss: 0.658545732498169\n",
      "Ep 81: Batch #121 - Loss: 0.5602213740348816\n",
      "Ep 81: Batch #122 - Loss: 0.7089052796363831\n",
      "Ep 81: Batch #123 - Loss: 0.7141606211662292\n",
      "Ep 81: Batch #124 - Loss: 0.5562818050384521\n",
      "Ep 81: Batch #125 - Loss: 2.476767063140869\n",
      "Ep 81: Batch #126 - Loss: 1.0074766874313354\n",
      "Ep 81: Batch #127 - Loss: 0.582030713558197\n",
      "Ep 81: Batch #128 - Loss: 0.887622058391571\n",
      "Ep 81: Batch #129 - Loss: 0.6783011555671692\n",
      "Ep 81: Batch #130 - Loss: 0.5952576398849487\n",
      "Ep 81: Batch #131 - Loss: 0.8003247976303101\n",
      "Ep 81: Batch #132 - Loss: 0.6829490065574646\n",
      "Ep 81: Batch #133 - Loss: 0.6664940714836121\n",
      "Ep 81: Batch #134 - Loss: 0.6370606422424316\n",
      "Ep 81: Batch #135 - Loss: 0.8212701678276062\n",
      "Ep 81: Batch #136 - Loss: 1.0425564050674438\n",
      "Ep 81: Batch #137 - Loss: 0.7556919455528259\n",
      "Ep 81: Batch #138 - Loss: 0.9017959833145142\n",
      "Ep 81: Batch #139 - Loss: 0.6747405529022217\n",
      "Ep 81: Batch #140 - Loss: 0.8414682149887085\n",
      "Ep 81: Batch #141 - Loss: 1.1143481731414795\n",
      "Ep 81: Batch #142 - Loss: 0.6715735197067261\n",
      "Ep 81: Batch #143 - Loss: 0.7704408168792725\n",
      "Ep 81: Batch #144 - Loss: 0.6115427613258362\n",
      "Ep 81: Batch #145 - Loss: 0.597839891910553\n",
      "Ep 81: Batch #146 - Loss: 0.6966913342475891\n",
      "Ep 81: Batch #147 - Loss: 0.662135660648346\n",
      "Ep 81: Batch #148 - Loss: 0.7525089979171753\n",
      "Ep 81: Batch #149 - Loss: 0.6125327944755554\n",
      "Ep 81: Batch #150 - Loss: 0.7196274995803833\n",
      "Ep 81: Batch #151 - Loss: 0.6251857876777649\n",
      "Ep 81: Batch #152 - Loss: 0.6069515347480774\n",
      "Ep 81: Batch #153 - Loss: 0.8263126015663147\n",
      "Ep 81: Batch #154 - Loss: 0.6324996948242188\n",
      "Ep 81: Batch #155 - Loss: 0.6888967156410217\n",
      "Ep 81: Batch #156 - Loss: 0.7771630883216858\n",
      "Ep 81: Batch #157 - Loss: 0.6121658682823181\n",
      "Ep 81: Batch #158 - Loss: 0.7171364426612854\n",
      "Ep 81: Batch #159 - Loss: 0.5963141322135925\n",
      "Ep 81: Batch #160 - Loss: 0.6903640031814575\n",
      "Ep 81: Batch #161 - Loss: 0.6687808632850647\n",
      "Ep 81: Batch #162 - Loss: 0.7190967798233032\n",
      "Ep 81: Batch #163 - Loss: 0.7605342864990234\n",
      "Ep 81: Batch #164 - Loss: 0.6475535035133362\n",
      "Ep 81: Batch #165 - Loss: 1.3394124507904053\n",
      "Ep 81: Batch #166 - Loss: 0.5340887308120728\n",
      "Ep 81: Batch #167 - Loss: 0.7031475305557251\n",
      "Ep 81: Batch #168 - Loss: 0.6929921507835388\n",
      "Ep 81: Batch #169 - Loss: 0.6659076809883118\n",
      "Ep 81: Batch #170 - Loss: 0.6275964975357056\n",
      "Ep 81: Batch #171 - Loss: 0.6422635912895203\n",
      "Ep 81: Batch #172 - Loss: 0.533823549747467\n",
      "Ep 81: Batch #173 - Loss: 0.9279730319976807\n",
      "Ep 81: Batch #174 - Loss: 0.4943483769893646\n",
      "Ep 81: Batch #175 - Loss: 0.6346631646156311\n",
      "Ep 81: Batch #176 - Loss: 0.8958659768104553\n",
      "Ep 81: Batch #177 - Loss: 0.6465730667114258\n",
      "Ep 81: Batch #178 - Loss: 0.6207417249679565\n",
      "Ep 81: Batch #179 - Loss: 0.7442244291305542\n",
      "Ep 81: Batch #180 - Loss: 0.6478212475776672\n",
      "Ep 81: Batch #181 - Loss: 0.8009699583053589\n",
      "Ep 81: Batch #182 - Loss: 0.6300236582756042\n",
      "Ep 81: Batch #183 - Loss: 0.6051023602485657\n",
      "Ep 81: Batch #184 - Loss: 0.9187546372413635\n",
      "Ep 81: Batch #185 - Loss: 0.6339206099510193\n",
      "Ep 81: Batch #186 - Loss: 0.7505109906196594\n",
      "Ep 81: Batch #187 - Loss: 0.8680540919303894\n",
      "Ep 81: Batch #188 - Loss: 0.9311474561691284\n",
      "Ep 81: Batch #189 - Loss: 0.5860080122947693\n",
      "Ep 81: Batch #190 - Loss: 0.6213815808296204\n",
      "Ep 81: Batch #191 - Loss: 0.8000527024269104\n",
      "Ep 81: Batch #192 - Loss: 0.571967363357544\n",
      "Ep 81: Batch #193 - Loss: 0.631521463394165\n",
      "Ep 81: Batch #194 - Loss: 0.5417224764823914\n",
      "Ep 81: Batch #195 - Loss: 0.782751202583313\n",
      "Ep 81: Batch #196 - Loss: 0.6937775611877441\n",
      "Ep 81: Batch #197 - Loss: 0.6987158060073853\n",
      "Ep 81: Batch #198 - Loss: 0.5339897274971008\n",
      "Ep 81: Batch #199 - Loss: 0.642104983329773\n",
      "Ep 82: Batch #0 - Loss: 0.65120929479599\n",
      "Ep 82: Batch #1 - Loss: 0.7180588245391846\n",
      "Ep 82: Batch #2 - Loss: 0.8604742884635925\n",
      "Ep 82: Batch #3 - Loss: 0.7212681174278259\n",
      "Ep 82: Batch #4 - Loss: 0.6573615670204163\n",
      "Ep 82: Batch #5 - Loss: 0.5521849989891052\n",
      "Ep 82: Batch #6 - Loss: 0.7326419353485107\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 82: Batch #7 - Loss: 0.5755812525749207\n",
      "Ep 82: Batch #8 - Loss: 0.5844935774803162\n",
      "Ep 82: Batch #9 - Loss: 1.0923861265182495\n",
      "Ep 82: Batch #10 - Loss: 0.792021632194519\n",
      "Ep 82: Batch #11 - Loss: 0.544124186038971\n",
      "Ep 82: Batch #12 - Loss: 1.1936125755310059\n",
      "Ep 82: Batch #13 - Loss: 0.571896493434906\n",
      "Ep 82: Batch #14 - Loss: 0.5976256728172302\n",
      "Ep 82: Batch #15 - Loss: 0.8403388261795044\n",
      "Ep 82: Batch #16 - Loss: 0.9550864696502686\n",
      "Ep 82: Batch #17 - Loss: 0.7318586111068726\n",
      "Ep 82: Batch #18 - Loss: 0.8102244734764099\n",
      "Ep 82: Batch #19 - Loss: 0.5636463761329651\n",
      "Ep 82: Batch #20 - Loss: 0.5462478995323181\n",
      "Ep 82: Batch #21 - Loss: 0.7932521104812622\n",
      "Ep 82: Batch #22 - Loss: 0.6064513921737671\n",
      "Ep 82: Batch #23 - Loss: 0.5997187495231628\n",
      "Ep 82: Batch #24 - Loss: 0.6415682435035706\n",
      "Ep 82: Batch #25 - Loss: 0.6052474975585938\n",
      "Ep 82: Batch #26 - Loss: 0.5554935336112976\n",
      "Ep 82: Batch #27 - Loss: 1.1381487846374512\n",
      "Ep 82: Batch #28 - Loss: 0.6929531693458557\n",
      "Ep 82: Batch #29 - Loss: 0.7534056305885315\n",
      "Ep 82: Batch #30 - Loss: 0.818871021270752\n",
      "Ep 82: Batch #31 - Loss: 0.5619405508041382\n",
      "Ep 82: Batch #32 - Loss: 0.5806435942649841\n",
      "Ep 82: Batch #33 - Loss: 0.6669465899467468\n",
      "Ep 82: Batch #34 - Loss: 0.6348327398300171\n",
      "Ep 82: Batch #35 - Loss: 0.7240598201751709\n",
      "Ep 82: Batch #36 - Loss: 0.5850245356559753\n",
      "Ep 82: Batch #37 - Loss: 0.9203699827194214\n",
      "Ep 82: Batch #38 - Loss: 0.567295253276825\n",
      "Ep 82: Batch #39 - Loss: 0.686898410320282\n",
      "Ep 82: Batch #40 - Loss: 0.6040987968444824\n",
      "Ep 82: Batch #41 - Loss: 0.619357168674469\n",
      "Ep 82: Batch #42 - Loss: 0.5698740482330322\n",
      "Ep 82: Batch #43 - Loss: 0.6336767673492432\n",
      "Ep 82: Batch #44 - Loss: 0.6123960018157959\n",
      "Ep 82: Batch #45 - Loss: 0.5234634876251221\n",
      "Ep 82: Batch #46 - Loss: 0.6976425647735596\n",
      "Ep 82: Batch #47 - Loss: 0.8026718497276306\n",
      "Ep 82: Batch #48 - Loss: 1.0463558435440063\n",
      "Ep 82: Batch #49 - Loss: 0.806776225566864\n",
      "Ep 82: Batch #50 - Loss: 0.5734938383102417\n",
      "Ep 82: Batch #51 - Loss: 0.8170448541641235\n",
      "Ep 82: Batch #52 - Loss: 0.6760045886039734\n",
      "Ep 82: Batch #53 - Loss: 0.7142341732978821\n",
      "Ep 82: Batch #54 - Loss: 0.5773640275001526\n",
      "Ep 82: Batch #55 - Loss: 0.6058816909790039\n",
      "Ep 82: Batch #56 - Loss: 0.8598218560218811\n",
      "Ep 82: Batch #57 - Loss: 0.6812698245048523\n",
      "Ep 82: Batch #58 - Loss: 0.8230016827583313\n",
      "Ep 82: Batch #59 - Loss: 0.5561742186546326\n",
      "Ep 82: Batch #60 - Loss: 1.0069557428359985\n",
      "Ep 82: Batch #61 - Loss: 0.5348500609397888\n",
      "Ep 82: Batch #62 - Loss: 0.5744815468788147\n",
      "Ep 82: Batch #63 - Loss: 0.7787500023841858\n",
      "Ep 82: Batch #64 - Loss: 8.003756523132324\n",
      "Ep 82: Batch #65 - Loss: 0.523658812046051\n",
      "Ep 82: Batch #66 - Loss: 0.6640017032623291\n",
      "Ep 82: Batch #67 - Loss: 0.7753859758377075\n",
      "Ep 82: Batch #68 - Loss: 0.7127553224563599\n",
      "Ep 82: Batch #69 - Loss: 0.5863741040229797\n",
      "Ep 82: Batch #70 - Loss: 0.6151019334793091\n",
      "Ep 82: Batch #71 - Loss: 0.5347772240638733\n",
      "Ep 82: Batch #72 - Loss: 0.6627817749977112\n",
      "Ep 82: Batch #73 - Loss: 0.7195308804512024\n",
      "Ep 82: Batch #74 - Loss: 0.5760679841041565\n",
      "Ep 82: Batch #75 - Loss: 0.6660131216049194\n",
      "Ep 82: Batch #76 - Loss: 0.9226193428039551\n",
      "Ep 82: Batch #77 - Loss: 0.5754076242446899\n",
      "Ep 82: Batch #78 - Loss: 0.9162769317626953\n",
      "Ep 82: Batch #79 - Loss: 0.5249760150909424\n",
      "Ep 82: Batch #80 - Loss: 0.6896167993545532\n",
      "Ep 82: Batch #81 - Loss: 1.5226222276687622\n",
      "Ep 82: Batch #82 - Loss: 0.754481852054596\n",
      "Ep 82: Batch #83 - Loss: 1.1993566751480103\n",
      "Ep 82: Batch #84 - Loss: 0.5771852731704712\n",
      "Ep 82: Batch #85 - Loss: 0.7834433317184448\n",
      "Ep 82: Batch #86 - Loss: 0.5464352965354919\n",
      "Ep 82: Batch #87 - Loss: 0.57062166929245\n",
      "Ep 82: Batch #88 - Loss: 0.6558710932731628\n",
      "Ep 82: Batch #89 - Loss: 0.724882960319519\n",
      "Ep 82: Batch #90 - Loss: 0.9024692177772522\n",
      "Ep 82: Batch #91 - Loss: 0.650230348110199\n",
      "Ep 82: Batch #92 - Loss: 0.7294195890426636\n",
      "Ep 82: Batch #93 - Loss: 0.7811568975448608\n",
      "Ep 82: Batch #94 - Loss: 0.7433626651763916\n",
      "Ep 82: Batch #95 - Loss: 0.7603798508644104\n",
      "Ep 82: Batch #96 - Loss: 0.7555407285690308\n",
      "Ep 82: Batch #97 - Loss: 0.5883772373199463\n",
      "Ep 82: Batch #98 - Loss: 0.5774360299110413\n",
      "Ep 82: Batch #99 - Loss: 0.7910211086273193\n",
      "Ep 82: Batch #100 - Loss: 0.5572010278701782\n",
      "Ep 82: Batch #101 - Loss: 0.8699086308479309\n",
      "Ep 82: Batch #102 - Loss: 0.6118969917297363\n",
      "Ep 82: Batch #103 - Loss: 0.6342957019805908\n",
      "Ep 82: Batch #104 - Loss: 0.659716010093689\n",
      "Ep 82: Batch #105 - Loss: 0.8190593719482422\n",
      "Ep 82: Batch #106 - Loss: 0.6267112493515015\n",
      "Ep 82: Batch #107 - Loss: 0.61541348695755\n",
      "Ep 82: Batch #108 - Loss: 0.9008699059486389\n",
      "Ep 82: Batch #109 - Loss: 0.6256887912750244\n",
      "Ep 82: Batch #110 - Loss: 0.723365306854248\n",
      "Ep 82: Batch #111 - Loss: 1.0381945371627808\n",
      "Ep 82: Batch #112 - Loss: 0.7889410853385925\n",
      "Ep 82: Batch #113 - Loss: 0.6573218703269958\n",
      "Ep 82: Batch #114 - Loss: 0.7247552871704102\n",
      "Ep 82: Batch #115 - Loss: 0.911145806312561\n",
      "Ep 82: Batch #116 - Loss: 0.5211360454559326\n",
      "Ep 82: Batch #117 - Loss: 0.6787349581718445\n",
      "Ep 82: Batch #118 - Loss: 0.45405668020248413\n",
      "Ep 82: Batch #119 - Loss: 0.8079448342323303\n",
      "Ep 82: Batch #120 - Loss: 0.6589096188545227\n",
      "Ep 82: Batch #121 - Loss: 0.5598989725112915\n",
      "Ep 82: Batch #122 - Loss: 0.7091711163520813\n",
      "Ep 82: Batch #123 - Loss: 0.7145683169364929\n",
      "Ep 82: Batch #124 - Loss: 0.5561816692352295\n",
      "Ep 82: Batch #125 - Loss: 2.475752592086792\n",
      "Ep 82: Batch #126 - Loss: 1.0077543258666992\n",
      "Ep 82: Batch #127 - Loss: 0.5818215012550354\n",
      "Ep 82: Batch #128 - Loss: 0.8881569504737854\n",
      "Ep 82: Batch #129 - Loss: 0.6779763698577881\n",
      "Ep 82: Batch #130 - Loss: 0.5950923562049866\n",
      "Ep 82: Batch #131 - Loss: 0.7997472882270813\n",
      "Ep 82: Batch #132 - Loss: 0.6828323602676392\n",
      "Ep 82: Batch #133 - Loss: 0.6666267514228821\n",
      "Ep 82: Batch #134 - Loss: 0.6366049647331238\n",
      "Ep 82: Batch #135 - Loss: 0.8206121921539307\n",
      "Ep 82: Batch #136 - Loss: 1.0429691076278687\n",
      "Ep 82: Batch #137 - Loss: 0.7550620436668396\n",
      "Ep 82: Batch #138 - Loss: 0.9021137952804565\n",
      "Ep 82: Batch #139 - Loss: 0.674453616142273\n",
      "Ep 82: Batch #140 - Loss: 0.841365396976471\n",
      "Ep 82: Batch #141 - Loss: 1.113430380821228\n",
      "Ep 82: Batch #142 - Loss: 0.6714528799057007\n",
      "Ep 82: Batch #143 - Loss: 0.7702298164367676\n",
      "Ep 82: Batch #144 - Loss: 0.6117134690284729\n",
      "Ep 82: Batch #145 - Loss: 0.5978910326957703\n",
      "Ep 82: Batch #146 - Loss: 0.6963667869567871\n",
      "Ep 82: Batch #147 - Loss: 0.6622101664543152\n",
      "Ep 82: Batch #148 - Loss: 0.7521656155586243\n",
      "Ep 82: Batch #149 - Loss: 0.6120908856391907\n",
      "Ep 82: Batch #150 - Loss: 0.7195133566856384\n",
      "Ep 82: Batch #151 - Loss: 0.6248365640640259\n",
      "Ep 82: Batch #152 - Loss: 0.606850266456604\n",
      "Ep 82: Batch #153 - Loss: 0.826164722442627\n",
      "Ep 82: Batch #154 - Loss: 0.6325139999389648\n",
      "Ep 82: Batch #155 - Loss: 0.6886153817176819\n",
      "Ep 82: Batch #156 - Loss: 0.7772994041442871\n",
      "Ep 82: Batch #157 - Loss: 0.6121963262557983\n",
      "Ep 82: Batch #158 - Loss: 0.7170143723487854\n",
      "Ep 82: Batch #159 - Loss: 0.5964277386665344\n",
      "Ep 82: Batch #160 - Loss: 0.6903759241104126\n",
      "Ep 82: Batch #161 - Loss: 0.6687615513801575\n",
      "Ep 82: Batch #162 - Loss: 0.7189238667488098\n",
      "Ep 82: Batch #163 - Loss: 0.7605418562889099\n",
      "Ep 82: Batch #164 - Loss: 0.647558331489563\n",
      "Ep 82: Batch #165 - Loss: 1.3380522727966309\n",
      "Ep 82: Batch #166 - Loss: 0.5341019034385681\n",
      "Ep 82: Batch #167 - Loss: 0.7028052806854248\n",
      "Ep 82: Batch #168 - Loss: 0.6925615668296814\n",
      "Ep 82: Batch #169 - Loss: 0.6658437252044678\n",
      "Ep 82: Batch #170 - Loss: 0.6271165609359741\n",
      "Ep 82: Batch #171 - Loss: 0.6419797539710999\n",
      "Ep 82: Batch #172 - Loss: 0.533842921257019\n",
      "Ep 82: Batch #173 - Loss: 0.9271841049194336\n",
      "Ep 82: Batch #174 - Loss: 0.49465230107307434\n",
      "Ep 82: Batch #175 - Loss: 0.6347274780273438\n",
      "Ep 82: Batch #176 - Loss: 0.8953229784965515\n",
      "Ep 82: Batch #177 - Loss: 0.6461921334266663\n",
      "Ep 82: Batch #178 - Loss: 0.6206993460655212\n",
      "Ep 82: Batch #179 - Loss: 0.7440301179885864\n",
      "Ep 82: Batch #180 - Loss: 0.647685170173645\n",
      "Ep 82: Batch #181 - Loss: 0.8002684712409973\n",
      "Ep 82: Batch #182 - Loss: 0.6298837661743164\n",
      "Ep 82: Batch #183 - Loss: 0.6048536896705627\n",
      "Ep 82: Batch #184 - Loss: 0.9186932444572449\n",
      "Ep 82: Batch #185 - Loss: 0.6333774924278259\n",
      "Ep 82: Batch #186 - Loss: 0.7495224475860596\n",
      "Ep 82: Batch #187 - Loss: 0.8668801188468933\n",
      "Ep 82: Batch #188 - Loss: 0.9304777383804321\n",
      "Ep 82: Batch #189 - Loss: 0.5853536128997803\n",
      "Ep 82: Batch #190 - Loss: 0.6209126114845276\n",
      "Ep 82: Batch #191 - Loss: 0.8003827333450317\n",
      "Ep 82: Batch #192 - Loss: 0.5718192458152771\n",
      "Ep 82: Batch #193 - Loss: 0.631227970123291\n",
      "Ep 82: Batch #194 - Loss: 0.5417606234550476\n",
      "Ep 82: Batch #195 - Loss: 0.7829577326774597\n",
      "Ep 82: Batch #196 - Loss: 0.6936635375022888\n",
      "Ep 82: Batch #197 - Loss: 0.6985058784484863\n",
      "Ep 82: Batch #198 - Loss: 0.533985435962677\n",
      "Ep 82: Batch #199 - Loss: 0.6416780352592468\n",
      "Ep 83: Batch #0 - Loss: 0.6510194540023804\n",
      "Ep 83: Batch #1 - Loss: 0.7182155847549438\n",
      "Ep 83: Batch #2 - Loss: 0.860010027885437\n",
      "Ep 83: Batch #3 - Loss: 0.7211923599243164\n",
      "Ep 83: Batch #4 - Loss: 0.6570928692817688\n",
      "Ep 83: Batch #5 - Loss: 0.5520136952400208\n",
      "Ep 83: Batch #6 - Loss: 0.7321500778198242\n",
      "Ep 83: Batch #7 - Loss: 0.5754891037940979\n",
      "Ep 83: Batch #8 - Loss: 0.5842164754867554\n",
      "Ep 83: Batch #9 - Loss: 1.0916768312454224\n",
      "Ep 83: Batch #10 - Loss: 0.7917742133140564\n",
      "Ep 83: Batch #11 - Loss: 0.5441334247589111\n",
      "Ep 83: Batch #12 - Loss: 1.19303297996521\n",
      "Ep 83: Batch #13 - Loss: 0.5718194246292114\n",
      "Ep 83: Batch #14 - Loss: 0.5977182984352112\n",
      "Ep 83: Batch #15 - Loss: 0.8399960398674011\n",
      "Ep 83: Batch #16 - Loss: 0.9552176594734192\n",
      "Ep 83: Batch #17 - Loss: 0.7318193912506104\n",
      "Ep 83: Batch #18 - Loss: 0.8101945519447327\n",
      "Ep 83: Batch #19 - Loss: 0.563524067401886\n",
      "Ep 83: Batch #20 - Loss: 0.5461815595626831\n",
      "Ep 83: Batch #21 - Loss: 0.7926079630851746\n",
      "Ep 83: Batch #22 - Loss: 0.6064552068710327\n",
      "Ep 83: Batch #23 - Loss: 0.5997902154922485\n",
      "Ep 83: Batch #24 - Loss: 0.6420240998268127\n",
      "Ep 83: Batch #25 - Loss: 0.605288565158844\n",
      "Ep 83: Batch #26 - Loss: 0.5553646683692932\n",
      "Ep 83: Batch #27 - Loss: 1.1380712985992432\n",
      "Ep 83: Batch #28 - Loss: 0.6927444338798523\n",
      "Ep 83: Batch #29 - Loss: 0.753180205821991\n",
      "Ep 83: Batch #30 - Loss: 0.818747341632843\n",
      "Ep 83: Batch #31 - Loss: 0.5621163249015808\n",
      "Ep 83: Batch #32 - Loss: 0.5806682705879211\n",
      "Ep 83: Batch #33 - Loss: 0.6668726205825806\n",
      "Ep 83: Batch #34 - Loss: 0.6348127722740173\n",
      "Ep 83: Batch #35 - Loss: 0.7240288853645325\n",
      "Ep 83: Batch #36 - Loss: 0.5850540399551392\n",
      "Ep 83: Batch #37 - Loss: 0.9202059507369995\n",
      "Ep 83: Batch #38 - Loss: 0.5671723484992981\n",
      "Ep 83: Batch #39 - Loss: 0.686975359916687\n",
      "Ep 83: Batch #40 - Loss: 0.6041467785835266\n",
      "Ep 83: Batch #41 - Loss: 0.6192684173583984\n",
      "Ep 83: Batch #42 - Loss: 0.5699047446250916\n",
      "Ep 83: Batch #43 - Loss: 0.6336856484413147\n",
      "Ep 83: Batch #44 - Loss: 0.6122859716415405\n",
      "Ep 83: Batch #45 - Loss: 0.5233436226844788\n",
      "Ep 83: Batch #46 - Loss: 0.6976768970489502\n",
      "Ep 83: Batch #47 - Loss: 0.8025073409080505\n",
      "Ep 83: Batch #48 - Loss: 1.0470657348632812\n",
      "Ep 83: Batch #49 - Loss: 0.8066027164459229\n",
      "Ep 83: Batch #50 - Loss: 0.5734267234802246\n",
      "Ep 83: Batch #51 - Loss: 0.8170472979545593\n",
      "Ep 83: Batch #52 - Loss: 0.6759842038154602\n",
      "Ep 83: Batch #53 - Loss: 0.7138965129852295\n",
      "Ep 83: Batch #54 - Loss: 0.5773276686668396\n",
      "Ep 83: Batch #55 - Loss: 0.6052490472793579\n",
      "Ep 83: Batch #56 - Loss: 0.8598299622535706\n",
      "Ep 83: Batch #57 - Loss: 0.6813337802886963\n",
      "Ep 83: Batch #58 - Loss: 0.8229650259017944\n",
      "Ep 83: Batch #59 - Loss: 0.5560176968574524\n",
      "Ep 83: Batch #60 - Loss: 1.0073573589324951\n",
      "Ep 83: Batch #61 - Loss: 0.5349314212799072\n",
      "Ep 83: Batch #62 - Loss: 0.5747038722038269\n",
      "Ep 83: Batch #63 - Loss: 0.7786811590194702\n",
      "Ep 83: Batch #64 - Loss: 7.989328861236572\n",
      "Ep 83: Batch #65 - Loss: 0.5237810611724854\n",
      "Ep 83: Batch #66 - Loss: 0.6637396216392517\n",
      "Ep 83: Batch #67 - Loss: 0.7754359245300293\n",
      "Ep 83: Batch #68 - Loss: 0.7129753828048706\n",
      "Ep 83: Batch #69 - Loss: 0.58656907081604\n",
      "Ep 83: Batch #70 - Loss: 0.6151478290557861\n",
      "Ep 83: Batch #71 - Loss: 0.5347199440002441\n",
      "Ep 83: Batch #72 - Loss: 0.6630082726478577\n",
      "Ep 83: Batch #73 - Loss: 0.7197464108467102\n",
      "Ep 83: Batch #74 - Loss: 0.5761562585830688\n",
      "Ep 83: Batch #75 - Loss: 0.6659582853317261\n",
      "Ep 83: Batch #76 - Loss: 0.9226524829864502\n",
      "Ep 83: Batch #77 - Loss: 0.5754304528236389\n",
      "Ep 83: Batch #78 - Loss: 0.9163318872451782\n",
      "Ep 83: Batch #79 - Loss: 0.5248910188674927\n",
      "Ep 83: Batch #80 - Loss: 0.6896942853927612\n",
      "Ep 83: Batch #81 - Loss: 1.522001028060913\n",
      "Ep 83: Batch #82 - Loss: 0.7541472315788269\n",
      "Ep 83: Batch #83 - Loss: 1.1973282098770142\n",
      "Ep 83: Batch #84 - Loss: 0.5774197578430176\n",
      "Ep 83: Batch #85 - Loss: 0.783206582069397\n",
      "Ep 83: Batch #86 - Loss: 0.5461170077323914\n",
      "Ep 83: Batch #87 - Loss: 0.5705547332763672\n",
      "Ep 83: Batch #88 - Loss: 0.6560813188552856\n",
      "Ep 83: Batch #89 - Loss: 0.724944531917572\n",
      "Ep 83: Batch #90 - Loss: 0.9025968909263611\n",
      "Ep 83: Batch #91 - Loss: 0.6500734090805054\n",
      "Ep 83: Batch #92 - Loss: 0.7289887070655823\n",
      "Ep 83: Batch #93 - Loss: 0.7808988094329834\n",
      "Ep 83: Batch #94 - Loss: 0.7437254190444946\n",
      "Ep 83: Batch #95 - Loss: 0.760479748249054\n",
      "Ep 83: Batch #96 - Loss: 0.7559289932250977\n",
      "Ep 83: Batch #97 - Loss: 0.5876806378364563\n",
      "Ep 83: Batch #98 - Loss: 0.5770810842514038\n",
      "Ep 83: Batch #99 - Loss: 0.7911109328269958\n",
      "Ep 83: Batch #100 - Loss: 0.5569123029708862\n",
      "Ep 83: Batch #101 - Loss: 0.86944979429245\n",
      "Ep 83: Batch #102 - Loss: 0.6119425892829895\n",
      "Ep 83: Batch #103 - Loss: 0.6345251202583313\n",
      "Ep 83: Batch #104 - Loss: 0.6600169539451599\n",
      "Ep 83: Batch #105 - Loss: 0.8187673091888428\n",
      "Ep 83: Batch #106 - Loss: 0.6264994740486145\n",
      "Ep 83: Batch #107 - Loss: 0.6155338287353516\n",
      "Ep 83: Batch #108 - Loss: 0.9005484580993652\n",
      "Ep 83: Batch #109 - Loss: 0.6259844899177551\n",
      "Ep 83: Batch #110 - Loss: 0.723710298538208\n",
      "Ep 83: Batch #111 - Loss: 1.037933588027954\n",
      "Ep 83: Batch #112 - Loss: 0.7888383865356445\n",
      "Ep 83: Batch #113 - Loss: 0.6574533581733704\n",
      "Ep 83: Batch #114 - Loss: 0.7245690226554871\n",
      "Ep 83: Batch #115 - Loss: 0.9107707142829895\n",
      "Ep 83: Batch #116 - Loss: 0.5212497115135193\n",
      "Ep 83: Batch #117 - Loss: 0.6787883043289185\n",
      "Ep 83: Batch #118 - Loss: 0.4540303647518158\n",
      "Ep 83: Batch #119 - Loss: 0.8071559071540833\n",
      "Ep 83: Batch #120 - Loss: 0.6584740281105042\n",
      "Ep 83: Batch #121 - Loss: 0.5599841475486755\n",
      "Ep 83: Batch #122 - Loss: 0.7087201476097107\n",
      "Ep 83: Batch #123 - Loss: 0.7140546441078186\n",
      "Ep 83: Batch #124 - Loss: 0.5561250448226929\n",
      "Ep 83: Batch #125 - Loss: 2.4762299060821533\n",
      "Ep 83: Batch #126 - Loss: 1.0077580213546753\n",
      "Ep 83: Batch #127 - Loss: 0.58194899559021\n",
      "Ep 83: Batch #128 - Loss: 0.8877562880516052\n",
      "Ep 83: Batch #129 - Loss: 0.6782851219177246\n",
      "Ep 83: Batch #130 - Loss: 0.5951403379440308\n",
      "Ep 83: Batch #131 - Loss: 0.7998644113540649\n",
      "Ep 83: Batch #132 - Loss: 0.6828024387359619\n",
      "Ep 83: Batch #133 - Loss: 0.6664563417434692\n",
      "Ep 83: Batch #134 - Loss: 0.6366204619407654\n",
      "Ep 83: Batch #135 - Loss: 0.8209534287452698\n",
      "Ep 83: Batch #136 - Loss: 1.0425264835357666\n",
      "Ep 83: Batch #137 - Loss: 0.7554964423179626\n",
      "Ep 83: Batch #138 - Loss: 0.9017378091812134\n",
      "Ep 83: Batch #139 - Loss: 0.6745142340660095\n",
      "Ep 83: Batch #140 - Loss: 0.8413745164871216\n",
      "Ep 83: Batch #141 - Loss: 1.1133499145507812\n",
      "Ep 83: Batch #142 - Loss: 0.6715213656425476\n",
      "Ep 83: Batch #143 - Loss: 0.7701666355133057\n",
      "Ep 83: Batch #144 - Loss: 0.6114636063575745\n",
      "Ep 83: Batch #145 - Loss: 0.5976839065551758\n",
      "Ep 83: Batch #146 - Loss: 0.6964712738990784\n",
      "Ep 83: Batch #147 - Loss: 0.6621596217155457\n",
      "Ep 83: Batch #148 - Loss: 0.7524948120117188\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 83: Batch #149 - Loss: 0.6120685338973999\n",
      "Ep 83: Batch #150 - Loss: 0.7195024490356445\n",
      "Ep 83: Batch #151 - Loss: 0.6250436305999756\n",
      "Ep 83: Batch #152 - Loss: 0.6067665815353394\n",
      "Ep 83: Batch #153 - Loss: 0.8262532949447632\n",
      "Ep 83: Batch #154 - Loss: 0.632530927658081\n",
      "Ep 83: Batch #155 - Loss: 0.6884121298789978\n",
      "Ep 83: Batch #156 - Loss: 0.7769944667816162\n",
      "Ep 83: Batch #157 - Loss: 0.6122115254402161\n",
      "Ep 83: Batch #158 - Loss: 0.7171770930290222\n",
      "Ep 83: Batch #159 - Loss: 0.5963349938392639\n",
      "Ep 83: Batch #160 - Loss: 0.6902360916137695\n",
      "Ep 83: Batch #161 - Loss: 0.6687825918197632\n",
      "Ep 83: Batch #162 - Loss: 0.7191329002380371\n",
      "Ep 83: Batch #163 - Loss: 0.7606377601623535\n",
      "Ep 83: Batch #164 - Loss: 0.6475793123245239\n",
      "Ep 83: Batch #165 - Loss: 1.339648723602295\n",
      "Ep 83: Batch #166 - Loss: 0.5339871644973755\n",
      "Ep 83: Batch #167 - Loss: 0.7022591829299927\n",
      "Ep 83: Batch #168 - Loss: 0.693168580532074\n",
      "Ep 83: Batch #169 - Loss: 0.6660288572311401\n",
      "Ep 83: Batch #170 - Loss: 0.6276023983955383\n",
      "Ep 83: Batch #171 - Loss: 0.642257809638977\n",
      "Ep 83: Batch #172 - Loss: 0.5338621735572815\n",
      "Ep 83: Batch #173 - Loss: 0.9279181957244873\n",
      "Ep 83: Batch #174 - Loss: 0.49441611766815186\n",
      "Ep 83: Batch #175 - Loss: 0.6346253156661987\n",
      "Ep 83: Batch #176 - Loss: 0.8955027461051941\n",
      "Ep 83: Batch #177 - Loss: 0.6463868021965027\n",
      "Ep 83: Batch #178 - Loss: 0.6206498146057129\n",
      "Ep 83: Batch #179 - Loss: 0.7440764307975769\n",
      "Ep 83: Batch #180 - Loss: 0.6476849317550659\n",
      "Ep 83: Batch #181 - Loss: 0.8006604313850403\n",
      "Ep 83: Batch #182 - Loss: 0.6302632093429565\n",
      "Ep 83: Batch #183 - Loss: 0.6049209833145142\n",
      "Ep 83: Batch #184 - Loss: 0.918597936630249\n",
      "Ep 83: Batch #185 - Loss: 0.6340895295143127\n",
      "Ep 83: Batch #186 - Loss: 0.7503325939178467\n",
      "Ep 83: Batch #187 - Loss: 0.8683682084083557\n",
      "Ep 83: Batch #188 - Loss: 0.9295893907546997\n",
      "Ep 83: Batch #189 - Loss: 0.5858632922172546\n",
      "Ep 83: Batch #190 - Loss: 0.621062695980072\n",
      "Ep 83: Batch #191 - Loss: 0.7996841669082642\n",
      "Ep 83: Batch #192 - Loss: 0.5720058679580688\n",
      "Ep 83: Batch #193 - Loss: 0.6314815282821655\n",
      "Ep 83: Batch #194 - Loss: 0.5416391491889954\n",
      "Ep 83: Batch #195 - Loss: 0.7825202345848083\n",
      "Ep 83: Batch #196 - Loss: 0.6938098669052124\n",
      "Ep 83: Batch #197 - Loss: 0.6985211968421936\n",
      "Ep 83: Batch #198 - Loss: 0.534130334854126\n",
      "Ep 83: Batch #199 - Loss: 0.6417866349220276\n",
      "Ep 84: Batch #0 - Loss: 0.6511675119400024\n",
      "Ep 84: Batch #1 - Loss: 0.7183018922805786\n",
      "Ep 84: Batch #2 - Loss: 0.860109806060791\n",
      "Ep 84: Batch #3 - Loss: 0.7213917374610901\n",
      "Ep 84: Batch #4 - Loss: 0.6571957468986511\n",
      "Ep 84: Batch #5 - Loss: 0.5520396828651428\n",
      "Ep 84: Batch #6 - Loss: 0.7322183847427368\n",
      "Ep 84: Batch #7 - Loss: 0.5755725502967834\n",
      "Ep 84: Batch #8 - Loss: 0.5843915939331055\n",
      "Ep 84: Batch #9 - Loss: 1.092016339302063\n",
      "Ep 84: Batch #10 - Loss: 0.7913032174110413\n",
      "Ep 84: Batch #11 - Loss: 0.5440641641616821\n",
      "Ep 84: Batch #12 - Loss: 1.1927367448806763\n",
      "Ep 84: Batch #13 - Loss: 0.5718981027603149\n",
      "Ep 84: Batch #14 - Loss: 0.5976009964942932\n",
      "Ep 84: Batch #15 - Loss: 0.8400083184242249\n",
      "Ep 84: Batch #16 - Loss: 0.9552537202835083\n",
      "Ep 84: Batch #17 - Loss: 0.7320531606674194\n",
      "Ep 84: Batch #18 - Loss: 0.8103125095367432\n",
      "Ep 84: Batch #19 - Loss: 0.563589334487915\n",
      "Ep 84: Batch #20 - Loss: 0.5462050437927246\n",
      "Ep 84: Batch #21 - Loss: 0.7920681834220886\n",
      "Ep 84: Batch #22 - Loss: 0.6062314510345459\n",
      "Ep 84: Batch #23 - Loss: 0.5997329950332642\n",
      "Ep 84: Batch #24 - Loss: 0.6420829892158508\n",
      "Ep 84: Batch #25 - Loss: 0.6052064895629883\n",
      "Ep 84: Batch #26 - Loss: 0.5554234385490417\n",
      "Ep 84: Batch #27 - Loss: 1.1377005577087402\n",
      "Ep 84: Batch #28 - Loss: 0.6928743720054626\n",
      "Ep 84: Batch #29 - Loss: 0.7532595992088318\n",
      "Ep 84: Batch #30 - Loss: 0.8183525204658508\n",
      "Ep 84: Batch #31 - Loss: 0.5621293783187866\n",
      "Ep 84: Batch #32 - Loss: 0.5806518197059631\n",
      "Ep 84: Batch #33 - Loss: 0.6669504642486572\n",
      "Ep 84: Batch #34 - Loss: 0.6347606778144836\n",
      "Ep 84: Batch #35 - Loss: 0.7241684794425964\n",
      "Ep 84: Batch #36 - Loss: 0.5850549340248108\n",
      "Ep 84: Batch #37 - Loss: 0.9202672243118286\n",
      "Ep 84: Batch #38 - Loss: 0.5670747756958008\n",
      "Ep 84: Batch #39 - Loss: 0.6868261694908142\n",
      "Ep 84: Batch #40 - Loss: 0.6041266322135925\n",
      "Ep 84: Batch #41 - Loss: 0.6193780899047852\n",
      "Ep 84: Batch #42 - Loss: 0.5699282288551331\n",
      "Ep 84: Batch #43 - Loss: 0.6337587237358093\n",
      "Ep 84: Batch #44 - Loss: 0.6123055815696716\n",
      "Ep 84: Batch #45 - Loss: 0.5233383178710938\n",
      "Ep 84: Batch #46 - Loss: 0.6977783441543579\n",
      "Ep 84: Batch #47 - Loss: 0.8025122880935669\n",
      "Ep 84: Batch #48 - Loss: 1.0466197729110718\n",
      "Ep 84: Batch #49 - Loss: 0.806399941444397\n",
      "Ep 84: Batch #50 - Loss: 0.5734561085700989\n",
      "Ep 84: Batch #51 - Loss: 0.8170830011367798\n",
      "Ep 84: Batch #52 - Loss: 0.6759394407272339\n",
      "Ep 84: Batch #53 - Loss: 0.7138679623603821\n",
      "Ep 84: Batch #54 - Loss: 0.5772501826286316\n",
      "Ep 84: Batch #55 - Loss: 0.6052603125572205\n",
      "Ep 84: Batch #56 - Loss: 0.8599036931991577\n",
      "Ep 84: Batch #57 - Loss: 0.681199848651886\n",
      "Ep 84: Batch #58 - Loss: 0.822662889957428\n",
      "Ep 84: Batch #59 - Loss: 0.555952250957489\n",
      "Ep 84: Batch #60 - Loss: 1.007084846496582\n",
      "Ep 84: Batch #61 - Loss: 0.53486168384552\n",
      "Ep 84: Batch #62 - Loss: 0.5746303200721741\n",
      "Ep 84: Batch #63 - Loss: 0.7783911824226379\n",
      "Ep 84: Batch #64 - Loss: 7.974056243896484\n",
      "Ep 84: Batch #65 - Loss: 0.523682177066803\n",
      "Ep 84: Batch #66 - Loss: 0.6638317704200745\n",
      "Ep 84: Batch #67 - Loss: 0.7753069996833801\n",
      "Ep 84: Batch #68 - Loss: 0.7126854062080383\n",
      "Ep 84: Batch #69 - Loss: 0.5862132906913757\n",
      "Ep 84: Batch #70 - Loss: 0.61497962474823\n",
      "Ep 84: Batch #71 - Loss: 0.5346860289573669\n",
      "Ep 84: Batch #72 - Loss: 0.6627557873725891\n",
      "Ep 84: Batch #73 - Loss: 0.719404399394989\n",
      "Ep 84: Batch #74 - Loss: 0.5759926438331604\n",
      "Ep 84: Batch #75 - Loss: 0.6658568382263184\n",
      "Ep 84: Batch #76 - Loss: 0.9224245548248291\n",
      "Ep 84: Batch #77 - Loss: 0.5752183198928833\n",
      "Ep 84: Batch #78 - Loss: 0.9159959554672241\n",
      "Ep 84: Batch #79 - Loss: 0.5248470306396484\n",
      "Ep 84: Batch #80 - Loss: 0.689446210861206\n",
      "Ep 84: Batch #81 - Loss: 1.5227419137954712\n",
      "Ep 84: Batch #82 - Loss: 0.7542384266853333\n",
      "Ep 84: Batch #83 - Loss: 1.1952404975891113\n",
      "Ep 84: Batch #84 - Loss: 0.5771217346191406\n",
      "Ep 84: Batch #85 - Loss: 0.7830374240875244\n",
      "Ep 84: Batch #86 - Loss: 0.5461214780807495\n",
      "Ep 84: Batch #87 - Loss: 0.570421040058136\n",
      "Ep 84: Batch #88 - Loss: 0.6560132503509521\n",
      "Ep 84: Batch #89 - Loss: 0.7247630953788757\n",
      "Ep 84: Batch #90 - Loss: 0.9024394154548645\n",
      "Ep 84: Batch #91 - Loss: 0.6503228545188904\n",
      "Ep 84: Batch #92 - Loss: 0.7291678786277771\n",
      "Ep 84: Batch #93 - Loss: 0.7809239625930786\n",
      "Ep 84: Batch #94 - Loss: 0.7431954145431519\n",
      "Ep 84: Batch #95 - Loss: 0.7603350281715393\n",
      "Ep 84: Batch #96 - Loss: 0.7555723786354065\n",
      "Ep 84: Batch #97 - Loss: 0.5885890126228333\n",
      "Ep 84: Batch #98 - Loss: 0.5774924159049988\n",
      "Ep 84: Batch #99 - Loss: 0.7908514738082886\n",
      "Ep 84: Batch #100 - Loss: 0.5569518208503723\n",
      "Ep 84: Batch #101 - Loss: 0.870028018951416\n",
      "Ep 84: Batch #102 - Loss: 0.6117590069770813\n",
      "Ep 84: Batch #103 - Loss: 0.634148895740509\n",
      "Ep 84: Batch #104 - Loss: 0.6595795154571533\n",
      "Ep 84: Batch #105 - Loss: 0.8190602660179138\n",
      "Ep 84: Batch #106 - Loss: 0.6266114711761475\n",
      "Ep 84: Batch #107 - Loss: 0.6153985261917114\n",
      "Ep 84: Batch #108 - Loss: 0.900793194770813\n",
      "Ep 84: Batch #109 - Loss: 0.6257190108299255\n",
      "Ep 84: Batch #110 - Loss: 0.7230960130691528\n",
      "Ep 84: Batch #111 - Loss: 1.0377395153045654\n",
      "Ep 84: Batch #112 - Loss: 0.7886748909950256\n",
      "Ep 84: Batch #113 - Loss: 0.6573092341423035\n",
      "Ep 84: Batch #114 - Loss: 0.7244058847427368\n",
      "Ep 84: Batch #115 - Loss: 0.9112032055854797\n",
      "Ep 84: Batch #116 - Loss: 0.5210444331169128\n",
      "Ep 84: Batch #117 - Loss: 0.6787582635879517\n",
      "Ep 84: Batch #118 - Loss: 0.45392030477523804\n",
      "Model saved in file: ./weights_autoencoder_sigmoid/model_e84b118_1516648802.6842997.ckpt\n",
      "Ep 84: Batch #119 - Loss: 0.8078997731208801\n",
      "Ep 84: Batch #120 - Loss: 0.6586875319480896\n",
      "Ep 84: Batch #121 - Loss: 0.5597248077392578\n",
      "Ep 84: Batch #122 - Loss: 0.7088777422904968\n",
      "Ep 84: Batch #123 - Loss: 0.714175283908844\n",
      "Ep 84: Batch #124 - Loss: 0.5560858845710754\n",
      "Ep 84: Batch #125 - Loss: 2.475754737854004\n",
      "Ep 84: Batch #126 - Loss: 1.0080065727233887\n",
      "Ep 84: Batch #127 - Loss: 0.5818132758140564\n",
      "Ep 84: Batch #128 - Loss: 0.8881263136863708\n",
      "Ep 84: Batch #129 - Loss: 0.6779930591583252\n",
      "Ep 84: Batch #130 - Loss: 0.5950437188148499\n",
      "Ep 84: Batch #131 - Loss: 0.7993931770324707\n",
      "Ep 84: Batch #132 - Loss: 0.682611346244812\n",
      "Ep 84: Batch #133 - Loss: 0.6665870547294617\n",
      "Ep 84: Batch #134 - Loss: 0.6363991498947144\n",
      "Ep 84: Batch #135 - Loss: 0.8205273151397705\n",
      "Ep 84: Batch #136 - Loss: 1.042776107788086\n",
      "Ep 84: Batch #137 - Loss: 0.7550230622291565\n",
      "Ep 84: Batch #138 - Loss: 0.9019473791122437\n",
      "Ep 84: Batch #139 - Loss: 0.6742678880691528\n",
      "Ep 84: Batch #140 - Loss: 0.8411740660667419\n",
      "Ep 84: Batch #141 - Loss: 1.1125017404556274\n",
      "Ep 84: Batch #142 - Loss: 0.6713495254516602\n",
      "Ep 84: Batch #143 - Loss: 0.7699885964393616\n",
      "Ep 84: Batch #144 - Loss: 0.6115337610244751\n",
      "Ep 84: Batch #145 - Loss: 0.5976387858390808\n",
      "Ep 84: Batch #146 - Loss: 0.6961637735366821\n",
      "Ep 84: Batch #147 - Loss: 0.6620346307754517\n",
      "Ep 84: Batch #148 - Loss: 0.7520896792411804\n",
      "Ep 84: Batch #149 - Loss: 0.6119548082351685\n",
      "Ep 84: Batch #150 - Loss: 0.719439685344696\n",
      "Ep 84: Batch #151 - Loss: 0.6246947646141052\n",
      "Ep 84: Batch #152 - Loss: 0.6067541241645813\n",
      "Ep 84: Batch #153 - Loss: 0.8260667324066162\n",
      "Ep 84: Batch #154 - Loss: 0.6324928402900696\n",
      "Ep 84: Batch #155 - Loss: 0.6880537867546082\n",
      "Ep 84: Batch #156 - Loss: 0.7770241498947144\n",
      "Ep 84: Batch #157 - Loss: 0.6120644211769104\n",
      "Ep 84: Batch #158 - Loss: 0.7168920040130615\n",
      "Ep 84: Batch #159 - Loss: 0.59639972448349\n",
      "Ep 84: Batch #160 - Loss: 0.6902605891227722\n",
      "Ep 84: Batch #161 - Loss: 0.668746829032898\n",
      "Ep 84: Batch #162 - Loss: 0.7189850211143494\n",
      "Ep 84: Batch #163 - Loss: 0.7607030272483826\n",
      "Ep 84: Batch #164 - Loss: 0.6474592685699463\n",
      "Ep 84: Batch #165 - Loss: 1.3380478620529175\n",
      "Ep 84: Batch #166 - Loss: 0.53396075963974\n",
      "Ep 84: Batch #167 - Loss: 0.7018260359764099\n",
      "Ep 84: Batch #168 - Loss: 0.6926817893981934\n",
      "Ep 84: Batch #169 - Loss: 0.6659083366394043\n",
      "Ep 84: Batch #170 - Loss: 0.6270429491996765\n",
      "Ep 84: Batch #171 - Loss: 0.6418391466140747\n",
      "Ep 84: Batch #172 - Loss: 0.5338680744171143\n",
      "Ep 84: Batch #173 - Loss: 0.9268501996994019\n",
      "Ep 84: Batch #174 - Loss: 0.4945727586746216\n",
      "Ep 84: Batch #175 - Loss: 0.6347220540046692\n",
      "Ep 84: Batch #176 - Loss: 0.8949474096298218\n",
      "Ep 84: Batch #177 - Loss: 0.646124541759491\n",
      "Ep 84: Batch #178 - Loss: 0.6205185651779175\n",
      "Ep 84: Batch #179 - Loss: 0.7438106536865234\n",
      "Ep 84: Batch #180 - Loss: 0.6475651264190674\n",
      "Ep 84: Batch #181 - Loss: 0.8000513315200806\n",
      "Ep 84: Batch #182 - Loss: 0.6301150321960449\n",
      "Ep 84: Batch #183 - Loss: 0.604865550994873\n",
      "Ep 84: Batch #184 - Loss: 0.9185192584991455\n",
      "Ep 84: Batch #185 - Loss: 0.6334785223007202\n",
      "Ep 84: Batch #186 - Loss: 0.7491006255149841\n",
      "Ep 84: Batch #187 - Loss: 0.8671517372131348\n",
      "Ep 84: Batch #188 - Loss: 0.929205060005188\n",
      "Ep 84: Batch #189 - Loss: 0.5852319002151489\n",
      "Ep 84: Batch #190 - Loss: 0.6207046508789062\n",
      "Ep 84: Batch #191 - Loss: 0.800231397151947\n",
      "Ep 84: Batch #192 - Loss: 0.571864664554596\n",
      "Ep 84: Batch #193 - Loss: 0.6311042308807373\n",
      "Ep 84: Batch #194 - Loss: 0.5416964888572693\n",
      "Ep 84: Batch #195 - Loss: 0.7823855876922607\n",
      "Ep 84: Batch #196 - Loss: 0.6936861276626587\n",
      "Ep 84: Batch #197 - Loss: 0.6984071135520935\n",
      "Ep 84: Batch #198 - Loss: 0.5342719554901123\n",
      "Ep 84: Batch #199 - Loss: 0.6415876150131226\n",
      "Ep 85: Batch #0 - Loss: 0.6509442329406738\n",
      "Ep 85: Batch #1 - Loss: 0.7189359664916992\n",
      "Ep 85: Batch #2 - Loss: 0.8597667217254639\n",
      "Ep 85: Batch #3 - Loss: 0.7214367985725403\n",
      "Ep 85: Batch #4 - Loss: 0.6571594476699829\n",
      "Ep 85: Batch #5 - Loss: 0.5518898367881775\n",
      "Ep 85: Batch #6 - Loss: 0.7317425608634949\n",
      "Ep 85: Batch #7 - Loss: 0.5755564570426941\n",
      "Ep 85: Batch #8 - Loss: 0.5843052268028259\n",
      "Ep 85: Batch #9 - Loss: 1.0917303562164307\n",
      "Ep 85: Batch #10 - Loss: 0.7908433675765991\n",
      "Ep 85: Batch #11 - Loss: 0.5442017912864685\n",
      "Ep 85: Batch #12 - Loss: 1.1926491260528564\n",
      "Ep 85: Batch #13 - Loss: 0.5718610882759094\n",
      "Ep 85: Batch #14 - Loss: 0.5974829792976379\n",
      "Ep 85: Batch #15 - Loss: 0.839470624923706\n",
      "Ep 85: Batch #16 - Loss: 0.9552899599075317\n",
      "Ep 85: Batch #17 - Loss: 0.7318170070648193\n",
      "Ep 85: Batch #18 - Loss: 0.8103811740875244\n",
      "Ep 85: Batch #19 - Loss: 0.5634009838104248\n",
      "Ep 85: Batch #20 - Loss: 0.546064555644989\n",
      "Ep 85: Batch #21 - Loss: 0.7908222079277039\n",
      "Ep 85: Batch #22 - Loss: 0.6063091158866882\n",
      "Ep 85: Batch #23 - Loss: 0.5997532606124878\n",
      "Ep 85: Batch #24 - Loss: 0.6425065398216248\n",
      "Ep 85: Batch #25 - Loss: 0.6052660942077637\n",
      "Ep 85: Batch #26 - Loss: 0.5554839372634888\n",
      "Ep 85: Batch #27 - Loss: 1.1375558376312256\n",
      "Ep 85: Batch #28 - Loss: 0.6925191879272461\n",
      "Ep 85: Batch #29 - Loss: 0.752953052520752\n",
      "Ep 85: Batch #30 - Loss: 0.8183691501617432\n",
      "Ep 85: Batch #31 - Loss: 0.562136173248291\n",
      "Ep 85: Batch #32 - Loss: 0.5806379318237305\n",
      "Ep 85: Batch #33 - Loss: 0.6668686866760254\n",
      "Ep 85: Batch #34 - Loss: 0.6346121430397034\n",
      "Ep 85: Batch #35 - Loss: 0.7241734862327576\n",
      "Ep 85: Batch #36 - Loss: 0.585165798664093\n",
      "Ep 85: Batch #37 - Loss: 0.920046329498291\n",
      "Ep 85: Batch #38 - Loss: 0.5669828653335571\n",
      "Ep 85: Batch #39 - Loss: 0.6867943406105042\n",
      "Ep 85: Batch #40 - Loss: 0.6039297580718994\n",
      "Ep 85: Batch #41 - Loss: 0.6190959215164185\n",
      "Ep 85: Batch #42 - Loss: 0.569918155670166\n",
      "Ep 85: Batch #43 - Loss: 0.6334667801856995\n",
      "Ep 85: Batch #44 - Loss: 0.6121810674667358\n",
      "Ep 85: Batch #45 - Loss: 0.523177444934845\n",
      "Ep 85: Batch #46 - Loss: 0.6976886987686157\n",
      "Ep 85: Batch #47 - Loss: 0.8023762106895447\n",
      "Ep 85: Batch #48 - Loss: 1.0472687482833862\n",
      "Ep 85: Batch #49 - Loss: 0.8062390685081482\n",
      "Ep 85: Batch #50 - Loss: 0.5735722780227661\n",
      "Ep 85: Batch #51 - Loss: 0.8171379566192627\n",
      "Ep 85: Batch #52 - Loss: 0.6758826971054077\n",
      "Ep 85: Batch #53 - Loss: 0.7136754989624023\n",
      "Ep 85: Batch #54 - Loss: 0.5772014260292053\n",
      "Ep 85: Batch #55 - Loss: 0.6053245067596436\n",
      "Ep 85: Batch #56 - Loss: 0.8600144982337952\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 85: Batch #57 - Loss: 0.6811717748641968\n",
      "Ep 85: Batch #58 - Loss: 0.8224232792854309\n",
      "Ep 85: Batch #59 - Loss: 0.5560157895088196\n",
      "Ep 85: Batch #60 - Loss: 1.0069280862808228\n",
      "Ep 85: Batch #61 - Loss: 0.5347813963890076\n",
      "Ep 85: Batch #62 - Loss: 0.574615478515625\n",
      "Ep 85: Batch #63 - Loss: 0.7783847451210022\n",
      "Ep 85: Batch #64 - Loss: 7.9598212242126465\n",
      "Ep 85: Batch #65 - Loss: 0.523635983467102\n",
      "Ep 85: Batch #66 - Loss: 0.6638849973678589\n",
      "Ep 85: Batch #67 - Loss: 0.7752683758735657\n",
      "Ep 85: Batch #68 - Loss: 0.7127082347869873\n",
      "Ep 85: Batch #69 - Loss: 0.5862231254577637\n",
      "Ep 85: Batch #70 - Loss: 0.6150704622268677\n",
      "Ep 85: Batch #71 - Loss: 0.5344455242156982\n",
      "Ep 85: Batch #72 - Loss: 0.6628769040107727\n",
      "Ep 85: Batch #73 - Loss: 0.7195929884910583\n",
      "Ep 85: Batch #74 - Loss: 0.5759912133216858\n",
      "Ep 85: Batch #75 - Loss: 0.6657964587211609\n",
      "Ep 85: Batch #76 - Loss: 0.9221974015235901\n",
      "Ep 85: Batch #77 - Loss: 0.5749984979629517\n",
      "Ep 85: Batch #78 - Loss: 0.9160019159317017\n",
      "Ep 85: Batch #79 - Loss: 0.5249698162078857\n",
      "Ep 85: Batch #80 - Loss: 0.6893513798713684\n",
      "Ep 85: Batch #81 - Loss: 1.5218778848648071\n",
      "Ep 85: Batch #82 - Loss: 0.7541185617446899\n",
      "Ep 85: Batch #83 - Loss: 1.1933093070983887\n",
      "Ep 85: Batch #84 - Loss: 0.5770632028579712\n",
      "Ep 85: Batch #85 - Loss: 0.7829421162605286\n",
      "Ep 85: Batch #86 - Loss: 0.5461381673812866\n",
      "Ep 85: Batch #87 - Loss: 0.5703592300415039\n",
      "Ep 85: Batch #88 - Loss: 0.6559691429138184\n",
      "Ep 85: Batch #89 - Loss: 0.7247679829597473\n",
      "Ep 85: Batch #90 - Loss: 0.902591347694397\n",
      "Ep 85: Batch #91 - Loss: 0.6500275135040283\n",
      "Ep 85: Batch #92 - Loss: 0.7286494970321655\n",
      "Ep 85: Batch #93 - Loss: 0.7809159755706787\n",
      "Ep 85: Batch #94 - Loss: 0.7442957758903503\n",
      "Ep 85: Batch #95 - Loss: 0.7603976130485535\n",
      "Ep 85: Batch #96 - Loss: 0.755816638469696\n",
      "Ep 85: Batch #97 - Loss: 0.5878194570541382\n",
      "Ep 85: Batch #98 - Loss: 0.5770760178565979\n",
      "Ep 85: Batch #99 - Loss: 0.7911180853843689\n",
      "Ep 85: Batch #100 - Loss: 0.5568361282348633\n",
      "Ep 85: Batch #101 - Loss: 0.8694332838058472\n",
      "Ep 85: Batch #102 - Loss: 0.6120054721832275\n",
      "Ep 85: Batch #103 - Loss: 0.634460985660553\n",
      "Ep 85: Batch #104 - Loss: 0.6600146889686584\n",
      "Ep 85: Batch #105 - Loss: 0.8188015222549438\n",
      "Ep 85: Batch #106 - Loss: 0.6264790892601013\n",
      "Ep 85: Batch #107 - Loss: 0.6155573725700378\n",
      "Ep 85: Batch #108 - Loss: 0.9004358053207397\n",
      "Ep 85: Batch #109 - Loss: 0.6260981559753418\n",
      "Ep 85: Batch #110 - Loss: 0.7238516211509705\n",
      "Ep 85: Batch #111 - Loss: 1.0374648571014404\n",
      "Ep 85: Batch #112 - Loss: 0.788615345954895\n",
      "Ep 85: Batch #113 - Loss: 0.6574851274490356\n",
      "Ep 85: Batch #114 - Loss: 0.7244701385498047\n",
      "Ep 85: Batch #115 - Loss: 0.9109207987785339\n",
      "Ep 85: Batch #116 - Loss: 0.5211829543113708\n",
      "Ep 85: Batch #117 - Loss: 0.6787353754043579\n",
      "Ep 85: Batch #118 - Loss: 0.45391443371772766\n",
      "Model saved in file: ./weights_autoencoder_sigmoid/model_e85b118_1516648802.821706.ckpt\n",
      "Ep 85: Batch #119 - Loss: 0.8070095181465149\n",
      "Ep 85: Batch #120 - Loss: 0.6584088206291199\n",
      "Ep 85: Batch #121 - Loss: 0.55986487865448\n",
      "Ep 85: Batch #122 - Loss: 0.7085274457931519\n",
      "Ep 85: Batch #123 - Loss: 0.7137176990509033\n",
      "Ep 85: Batch #124 - Loss: 0.5561538934707642\n",
      "Ep 85: Batch #125 - Loss: 2.4764888286590576\n",
      "Ep 85: Batch #126 - Loss: 1.0082300901412964\n",
      "Ep 85: Batch #127 - Loss: 0.5820109844207764\n",
      "Ep 85: Batch #128 - Loss: 0.8880739808082581\n",
      "Ep 85: Batch #129 - Loss: 0.6786465048789978\n",
      "Ep 85: Batch #130 - Loss: 0.5951889157295227\n",
      "Ep 85: Batch #131 - Loss: 0.7997382283210754\n",
      "Ep 85: Batch #132 - Loss: 0.6826581358909607\n",
      "Ep 85: Batch #133 - Loss: 0.6664438843727112\n",
      "Ep 85: Batch #134 - Loss: 0.6365178227424622\n",
      "Ep 85: Batch #135 - Loss: 0.820707380771637\n",
      "Ep 85: Batch #136 - Loss: 1.0424704551696777\n",
      "Ep 85: Batch #137 - Loss: 0.7561331987380981\n",
      "Ep 85: Batch #138 - Loss: 0.901719868183136\n",
      "Ep 85: Batch #139 - Loss: 0.6743149161338806\n",
      "Ep 85: Batch #140 - Loss: 0.8412622809410095\n",
      "Ep 85: Batch #141 - Loss: 1.1126102209091187\n",
      "Ep 85: Batch #142 - Loss: 0.6717690229415894\n",
      "Ep 85: Batch #143 - Loss: 0.7702322602272034\n",
      "Ep 85: Batch #144 - Loss: 0.6116538047790527\n",
      "Ep 85: Batch #145 - Loss: 0.5976030826568604\n",
      "Ep 85: Batch #146 - Loss: 0.6962112784385681\n",
      "Ep 85: Batch #147 - Loss: 0.6620566248893738\n",
      "Ep 85: Batch #148 - Loss: 0.752427875995636\n",
      "Ep 85: Batch #149 - Loss: 0.61308753490448\n",
      "Ep 85: Batch #150 - Loss: 0.7195299863815308\n",
      "Ep 85: Batch #151 - Loss: 0.6249516606330872\n",
      "Ep 85: Batch #152 - Loss: 0.606647253036499\n",
      "Ep 85: Batch #153 - Loss: 0.8262224197387695\n",
      "Ep 85: Batch #154 - Loss: 0.6326434016227722\n",
      "Ep 85: Batch #155 - Loss: 0.6881280541419983\n",
      "Ep 85: Batch #156 - Loss: 0.7770262360572815\n",
      "Ep 85: Batch #157 - Loss: 0.61208575963974\n",
      "Ep 85: Batch #158 - Loss: 0.7169403433799744\n",
      "Ep 85: Batch #159 - Loss: 0.596217155456543\n",
      "Ep 85: Batch #160 - Loss: 0.6900865435600281\n",
      "Ep 85: Batch #161 - Loss: 0.6688627600669861\n",
      "Ep 85: Batch #162 - Loss: 0.7192777991294861\n",
      "Ep 85: Batch #163 - Loss: 0.7608534097671509\n",
      "Ep 85: Batch #164 - Loss: 0.6474882960319519\n",
      "Ep 85: Batch #165 - Loss: 1.3396985530853271\n",
      "Ep 85: Batch #166 - Loss: 0.5340673923492432\n",
      "Ep 85: Batch #167 - Loss: 0.7002855539321899\n",
      "Ep 85: Batch #168 - Loss: 0.6932255029678345\n",
      "Ep 85: Batch #169 - Loss: 0.6661460399627686\n",
      "Ep 85: Batch #170 - Loss: 0.6273683309555054\n",
      "Ep 85: Batch #171 - Loss: 0.6420037746429443\n",
      "Ep 85: Batch #172 - Loss: 0.5337547063827515\n",
      "Ep 85: Batch #173 - Loss: 0.9271561503410339\n",
      "Ep 85: Batch #174 - Loss: 0.49428561329841614\n",
      "Ep 85: Batch #175 - Loss: 0.6344453692436218\n",
      "Ep 85: Batch #176 - Loss: 0.8943827152252197\n",
      "Ep 85: Batch #177 - Loss: 0.6459732055664062\n",
      "Ep 85: Batch #178 - Loss: 0.6206743121147156\n",
      "Ep 85: Batch #179 - Loss: 0.7438353896141052\n",
      "Ep 85: Batch #180 - Loss: 0.6472983360290527\n",
      "Ep 85: Batch #181 - Loss: 0.8004380464553833\n",
      "Ep 85: Batch #182 - Loss: 0.6302605867385864\n",
      "Ep 85: Batch #183 - Loss: 0.6048078536987305\n",
      "Ep 85: Batch #184 - Loss: 0.9184474349021912\n",
      "Ep 85: Batch #185 - Loss: 0.6342064738273621\n",
      "Ep 85: Batch #186 - Loss: 0.7505329847335815\n",
      "Ep 85: Batch #187 - Loss: 0.867847204208374\n",
      "Ep 85: Batch #188 - Loss: 0.928611159324646\n",
      "Ep 85: Batch #189 - Loss: 0.5857540369033813\n",
      "Ep 85: Batch #190 - Loss: 0.6209635138511658\n",
      "Ep 85: Batch #191 - Loss: 0.7991470694541931\n",
      "Ep 85: Batch #192 - Loss: 0.5720365047454834\n",
      "Ep 85: Batch #193 - Loss: 0.6313040256500244\n",
      "Ep 85: Batch #194 - Loss: 0.5415568947792053\n",
      "Ep 85: Batch #195 - Loss: 0.7823265194892883\n",
      "Ep 85: Batch #196 - Loss: 0.6938368082046509\n",
      "Ep 85: Batch #197 - Loss: 0.6983391642570496\n",
      "Ep 85: Batch #198 - Loss: 0.5341929793357849\n",
      "Ep 85: Batch #199 - Loss: 0.6417790055274963\n",
      "Ep 86: Batch #0 - Loss: 0.6511154770851135\n",
      "Ep 86: Batch #1 - Loss: 0.7187634110450745\n",
      "Ep 86: Batch #2 - Loss: 0.8600308895111084\n",
      "Ep 86: Batch #3 - Loss: 0.7213870286941528\n",
      "Ep 86: Batch #4 - Loss: 0.6572983264923096\n",
      "Ep 86: Batch #5 - Loss: 0.5518794059753418\n",
      "Ep 86: Batch #6 - Loss: 0.7319573760032654\n",
      "Ep 86: Batch #7 - Loss: 0.5756471753120422\n",
      "Ep 86: Batch #8 - Loss: 0.584282398223877\n",
      "Ep 86: Batch #9 - Loss: 1.091860055923462\n",
      "Ep 86: Batch #10 - Loss: 0.7905537486076355\n",
      "Ep 86: Batch #11 - Loss: 0.5441255569458008\n",
      "Ep 86: Batch #12 - Loss: 1.1923890113830566\n",
      "Ep 86: Batch #13 - Loss: 0.5719712376594543\n",
      "Ep 86: Batch #14 - Loss: 0.5974650382995605\n",
      "Ep 86: Batch #15 - Loss: 0.8396055698394775\n",
      "Ep 86: Batch #16 - Loss: 0.9552575349807739\n",
      "Ep 86: Batch #17 - Loss: 0.7319707870483398\n",
      "Ep 86: Batch #18 - Loss: 0.8104120492935181\n",
      "Ep 86: Batch #19 - Loss: 0.5635302662849426\n",
      "Ep 86: Batch #20 - Loss: 0.546184241771698\n",
      "Ep 86: Batch #21 - Loss: 0.7902331352233887\n",
      "Ep 86: Batch #22 - Loss: 0.6061241626739502\n",
      "Ep 86: Batch #23 - Loss: 0.5997461080551147\n",
      "Ep 86: Batch #24 - Loss: 0.6426045894622803\n",
      "Ep 86: Batch #25 - Loss: 0.6053045988082886\n",
      "Ep 86: Batch #26 - Loss: 0.5554727911949158\n",
      "Ep 86: Batch #27 - Loss: 1.1377133131027222\n",
      "Ep 86: Batch #28 - Loss: 0.6927696466445923\n",
      "Ep 86: Batch #29 - Loss: 0.7529934644699097\n",
      "Ep 86: Batch #30 - Loss: 0.8181882500648499\n",
      "Ep 86: Batch #31 - Loss: 0.5622109770774841\n",
      "Ep 86: Batch #32 - Loss: 0.5806871652603149\n",
      "Ep 86: Batch #33 - Loss: 0.6668943762779236\n",
      "Ep 86: Batch #34 - Loss: 0.6345533132553101\n",
      "Ep 86: Batch #35 - Loss: 0.7242451906204224\n",
      "Ep 86: Batch #36 - Loss: 0.5851763486862183\n",
      "Ep 86: Batch #37 - Loss: 0.9201547503471375\n",
      "Ep 86: Batch #38 - Loss: 0.5669068694114685\n",
      "Ep 86: Batch #39 - Loss: 0.6868138909339905\n",
      "Ep 86: Batch #40 - Loss: 0.6039266586303711\n",
      "Ep 86: Batch #41 - Loss: 0.6193206906318665\n",
      "Ep 86: Batch #42 - Loss: 0.5698518753051758\n",
      "Ep 86: Batch #43 - Loss: 0.6335147023200989\n",
      "Ep 86: Batch #44 - Loss: 0.6121858954429626\n",
      "Ep 86: Batch #45 - Loss: 0.5232336521148682\n",
      "Ep 86: Batch #46 - Loss: 0.6977543830871582\n",
      "Ep 86: Batch #47 - Loss: 0.8022703528404236\n",
      "Ep 86: Batch #48 - Loss: 1.047534465789795\n",
      "Ep 86: Batch #49 - Loss: 0.8060501217842102\n",
      "Ep 86: Batch #50 - Loss: 0.5734511017799377\n",
      "Ep 86: Batch #51 - Loss: 0.817392885684967\n",
      "Ep 86: Batch #52 - Loss: 0.6758484840393066\n",
      "Ep 86: Batch #53 - Loss: 0.7136157751083374\n",
      "Ep 86: Batch #54 - Loss: 0.577174723148346\n",
      "Ep 86: Batch #55 - Loss: 0.6052300333976746\n",
      "Ep 86: Batch #56 - Loss: 0.8601255416870117\n",
      "Ep 86: Batch #57 - Loss: 0.6811304688453674\n",
      "Ep 86: Batch #58 - Loss: 0.8224424123764038\n",
      "Ep 86: Batch #59 - Loss: 0.5559669137001038\n",
      "Ep 86: Batch #60 - Loss: 1.0071207284927368\n",
      "Ep 86: Batch #61 - Loss: 0.5347832441329956\n",
      "Ep 86: Batch #62 - Loss: 0.5746186971664429\n",
      "Ep 86: Batch #63 - Loss: 0.7782124876976013\n",
      "Ep 86: Batch #64 - Loss: 7.944949626922607\n",
      "Ep 86: Batch #65 - Loss: 0.5237721800804138\n",
      "Ep 86: Batch #66 - Loss: 0.6638514399528503\n",
      "Ep 86: Batch #67 - Loss: 0.7752687931060791\n",
      "Ep 86: Batch #68 - Loss: 0.7126080393791199\n",
      "Ep 86: Batch #69 - Loss: 0.586146354675293\n",
      "Ep 86: Batch #70 - Loss: 0.6150856614112854\n",
      "Ep 86: Batch #71 - Loss: 0.5346224308013916\n",
      "Ep 86: Batch #72 - Loss: 0.6628578901290894\n",
      "Ep 86: Batch #73 - Loss: 0.7195399403572083\n",
      "Ep 86: Batch #74 - Loss: 0.5761226415634155\n",
      "Ep 86: Batch #75 - Loss: 0.6657981276512146\n",
      "Ep 86: Batch #76 - Loss: 0.9221279621124268\n",
      "Ep 86: Batch #77 - Loss: 0.5749215483665466\n",
      "Ep 86: Batch #78 - Loss: 0.9155744314193726\n",
      "Ep 86: Batch #79 - Loss: 0.5248578190803528\n",
      "Ep 86: Batch #80 - Loss: 0.6892974376678467\n",
      "Ep 86: Batch #81 - Loss: 1.5226103067398071\n",
      "Ep 86: Batch #82 - Loss: 0.7537641525268555\n",
      "Ep 86: Batch #83 - Loss: 1.191562294960022\n",
      "Ep 86: Batch #84 - Loss: 0.5768667459487915\n",
      "Ep 86: Batch #85 - Loss: 0.7829768061637878\n",
      "Ep 86: Batch #86 - Loss: 0.5461713075637817\n",
      "Ep 86: Batch #87 - Loss: 0.5702102184295654\n",
      "Ep 86: Batch #88 - Loss: 0.655924916267395\n",
      "Ep 86: Batch #89 - Loss: 0.72427898645401\n",
      "Ep 86: Batch #90 - Loss: 0.9027146697044373\n",
      "Ep 86: Batch #91 - Loss: 0.6503733992576599\n",
      "Ep 86: Batch #92 - Loss: 0.7288413643836975\n",
      "Ep 86: Batch #93 - Loss: 0.7808007001876831\n",
      "Ep 86: Batch #94 - Loss: 0.7434594035148621\n",
      "Ep 86: Batch #95 - Loss: 0.7604389190673828\n",
      "Ep 86: Batch #96 - Loss: 0.7551386952400208\n",
      "Ep 86: Batch #97 - Loss: 0.5889037251472473\n",
      "Ep 86: Batch #98 - Loss: 0.5776082277297974\n",
      "Ep 86: Batch #99 - Loss: 0.7907527685165405\n",
      "Ep 86: Batch #100 - Loss: 0.5568509697914124\n",
      "Ep 86: Batch #101 - Loss: 0.8703800439834595\n",
      "Ep 86: Batch #102 - Loss: 0.6118541955947876\n",
      "Ep 86: Batch #103 - Loss: 0.6340383887290955\n",
      "Ep 86: Batch #104 - Loss: 0.6595875024795532\n",
      "Ep 86: Batch #105 - Loss: 0.8192883729934692\n",
      "Ep 86: Batch #106 - Loss: 0.6265715956687927\n",
      "Ep 86: Batch #107 - Loss: 0.6153111457824707\n",
      "Ep 86: Batch #108 - Loss: 0.9008901715278625\n",
      "Ep 86: Batch #109 - Loss: 0.625617265701294\n",
      "Ep 86: Batch #110 - Loss: 0.7230758666992188\n",
      "Ep 86: Batch #111 - Loss: 1.0382272005081177\n",
      "Ep 86: Batch #112 - Loss: 0.7882373929023743\n",
      "Ep 86: Batch #113 - Loss: 0.6572609543800354\n",
      "Ep 86: Batch #114 - Loss: 0.7241162061691284\n",
      "Ep 86: Batch #115 - Loss: 0.9112323522567749\n",
      "Ep 86: Batch #116 - Loss: 0.5210499167442322\n",
      "Ep 86: Batch #117 - Loss: 0.6786724925041199\n",
      "Ep 86: Batch #118 - Loss: 0.45390623807907104\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved in file: ./weights_autoencoder_sigmoid/model_e86b118_1516648802.9588203.ckpt\n",
      "Ep 86: Batch #119 - Loss: 0.8079721331596375\n",
      "Ep 86: Batch #120 - Loss: 0.6587483882904053\n",
      "Ep 86: Batch #121 - Loss: 0.5598012804985046\n",
      "Ep 86: Batch #122 - Loss: 0.7088098526000977\n",
      "Ep 86: Batch #123 - Loss: 0.7139591574668884\n",
      "Ep 86: Batch #124 - Loss: 0.5560089349746704\n",
      "Ep 86: Batch #125 - Loss: 2.475240468978882\n",
      "Ep 86: Batch #126 - Loss: 1.008216142654419\n",
      "Ep 86: Batch #127 - Loss: 0.5818316340446472\n",
      "Ep 86: Batch #128 - Loss: 0.8883169293403625\n",
      "Ep 86: Batch #129 - Loss: 0.6782952547073364\n",
      "Ep 86: Batch #130 - Loss: 0.5949627757072449\n",
      "Ep 86: Batch #131 - Loss: 0.7991759777069092\n",
      "Ep 86: Batch #132 - Loss: 0.6826753616333008\n",
      "Ep 86: Batch #133 - Loss: 0.6666261553764343\n",
      "Ep 86: Batch #134 - Loss: 0.6365296244621277\n",
      "Ep 86: Batch #135 - Loss: 0.8200034499168396\n",
      "Ep 86: Batch #136 - Loss: 1.0424485206604004\n",
      "Ep 86: Batch #137 - Loss: 0.7550798654556274\n",
      "Ep 86: Batch #138 - Loss: 0.9019215703010559\n",
      "Ep 86: Batch #139 - Loss: 0.6744335889816284\n",
      "Ep 86: Batch #140 - Loss: 0.8409518599510193\n",
      "Ep 86: Batch #141 - Loss: 1.111802101135254\n",
      "Ep 86: Batch #142 - Loss: 0.6714720726013184\n",
      "Ep 86: Batch #143 - Loss: 0.769920289516449\n",
      "Ep 86: Batch #144 - Loss: 0.6118525266647339\n",
      "Ep 86: Batch #145 - Loss: 0.5976545214653015\n",
      "Ep 86: Batch #146 - Loss: 0.6958323121070862\n",
      "Ep 86: Batch #147 - Loss: 0.6619685888290405\n",
      "Ep 86: Batch #148 - Loss: 0.7520588040351868\n",
      "Ep 86: Batch #149 - Loss: 0.6128215789794922\n",
      "Ep 86: Batch #150 - Loss: 0.7194573879241943\n",
      "Ep 86: Batch #151 - Loss: 0.6245708465576172\n",
      "Ep 86: Batch #152 - Loss: 0.6067007780075073\n",
      "Ep 86: Batch #153 - Loss: 0.8260422945022583\n",
      "Ep 86: Batch #154 - Loss: 0.6325840950012207\n",
      "Ep 86: Batch #155 - Loss: 0.6880156993865967\n",
      "Ep 86: Batch #156 - Loss: 0.7766625881195068\n",
      "Ep 86: Batch #157 - Loss: 0.6120076775550842\n",
      "Ep 86: Batch #158 - Loss: 0.7169235944747925\n",
      "Ep 86: Batch #159 - Loss: 0.5964483022689819\n",
      "Ep 86: Batch #160 - Loss: 0.6899803280830383\n",
      "Ep 86: Batch #161 - Loss: 0.6688472032546997\n",
      "Ep 86: Batch #162 - Loss: 0.7192664742469788\n",
      "Ep 86: Batch #163 - Loss: 0.7607139945030212\n",
      "Ep 86: Batch #164 - Loss: 0.647311806678772\n",
      "Ep 86: Batch #165 - Loss: 1.3380135297775269\n",
      "Ep 86: Batch #166 - Loss: 0.5338899493217468\n",
      "Ep 86: Batch #167 - Loss: 0.7002712488174438\n",
      "Ep 86: Batch #168 - Loss: 0.6929723620414734\n",
      "Ep 86: Batch #169 - Loss: 0.6661384701728821\n",
      "Ep 86: Batch #170 - Loss: 0.6271254420280457\n",
      "Ep 86: Batch #171 - Loss: 0.6418253183364868\n",
      "Ep 86: Batch #172 - Loss: 0.5335311889648438\n",
      "Ep 86: Batch #173 - Loss: 0.9266253709793091\n",
      "Ep 86: Batch #174 - Loss: 0.4942440390586853\n",
      "Ep 86: Batch #175 - Loss: 0.6341537237167358\n",
      "Ep 86: Batch #176 - Loss: 0.8944175839424133\n",
      "Ep 86: Batch #177 - Loss: 0.6458859443664551\n",
      "Ep 86: Batch #178 - Loss: 0.620208740234375\n",
      "Ep 86: Batch #179 - Loss: 0.7436609864234924\n",
      "Ep 86: Batch #180 - Loss: 0.6470343470573425\n",
      "Ep 86: Batch #181 - Loss: 0.7999122738838196\n",
      "Ep 86: Batch #182 - Loss: 0.6304922699928284\n",
      "Ep 86: Batch #183 - Loss: 0.6046796441078186\n",
      "Ep 86: Batch #184 - Loss: 0.9184298515319824\n",
      "Ep 86: Batch #185 - Loss: 0.6335133910179138\n",
      "Ep 86: Batch #186 - Loss: 0.7494043111801147\n",
      "Ep 86: Batch #187 - Loss: 0.8675289750099182\n",
      "Ep 86: Batch #188 - Loss: 0.9276394248008728\n",
      "Ep 86: Batch #189 - Loss: 0.5854800343513489\n",
      "Ep 86: Batch #190 - Loss: 0.6203864216804504\n",
      "Ep 86: Batch #191 - Loss: 0.7991005182266235\n",
      "Ep 86: Batch #192 - Loss: 0.5718465447425842\n",
      "Ep 86: Batch #193 - Loss: 0.6311154961585999\n",
      "Ep 86: Batch #194 - Loss: 0.541577935218811\n",
      "Ep 86: Batch #195 - Loss: 0.7820145487785339\n",
      "Ep 86: Batch #196 - Loss: 0.6936202645301819\n",
      "Ep 86: Batch #197 - Loss: 0.6981528997421265\n",
      "Ep 86: Batch #198 - Loss: 0.5343539118766785\n",
      "Ep 86: Batch #199 - Loss: 0.641506016254425\n",
      "Ep 87: Batch #0 - Loss: 0.6508685946464539\n",
      "Ep 87: Batch #1 - Loss: 0.7187801003456116\n",
      "Ep 87: Batch #2 - Loss: 0.8598480224609375\n",
      "Ep 87: Batch #3 - Loss: 0.7213172316551208\n",
      "Ep 87: Batch #4 - Loss: 0.6571611762046814\n",
      "Ep 87: Batch #5 - Loss: 0.551841139793396\n",
      "Ep 87: Batch #6 - Loss: 0.7314757108688354\n",
      "Ep 87: Batch #7 - Loss: 0.5754461288452148\n",
      "Ep 87: Batch #8 - Loss: 0.5842201709747314\n",
      "Ep 87: Batch #9 - Loss: 1.0916316509246826\n",
      "Ep 87: Batch #10 - Loss: 0.7904112339019775\n",
      "Ep 87: Batch #11 - Loss: 0.5440865755081177\n",
      "Ep 87: Batch #12 - Loss: 1.1920292377471924\n",
      "Ep 87: Batch #13 - Loss: 0.5718291401863098\n",
      "Ep 87: Batch #14 - Loss: 0.5974150896072388\n",
      "Ep 87: Batch #15 - Loss: 0.8391594290733337\n",
      "Ep 87: Batch #16 - Loss: 0.9553108215332031\n",
      "Ep 87: Batch #17 - Loss: 0.7319431900978088\n",
      "Ep 87: Batch #18 - Loss: 0.8105848431587219\n",
      "Ep 87: Batch #19 - Loss: 0.5635543465614319\n",
      "Ep 87: Batch #20 - Loss: 0.5462532043457031\n",
      "Ep 87: Batch #21 - Loss: 0.7903684377670288\n",
      "Ep 87: Batch #22 - Loss: 0.6062009930610657\n",
      "Ep 87: Batch #23 - Loss: 0.5998385548591614\n",
      "Ep 87: Batch #24 - Loss: 0.6429793238639832\n",
      "Ep 87: Batch #25 - Loss: 0.6053773760795593\n",
      "Ep 87: Batch #26 - Loss: 0.5554001927375793\n",
      "Ep 87: Batch #27 - Loss: 1.1373623609542847\n",
      "Ep 87: Batch #28 - Loss: 0.6930310726165771\n",
      "Ep 87: Batch #29 - Loss: 0.7530250549316406\n",
      "Ep 87: Batch #30 - Loss: 0.8182376027107239\n",
      "Ep 87: Batch #31 - Loss: 0.5623672008514404\n",
      "Ep 87: Batch #32 - Loss: 0.5807857513427734\n",
      "Ep 87: Batch #33 - Loss: 0.6670053601264954\n",
      "Ep 87: Batch #34 - Loss: 0.6345620155334473\n",
      "Ep 87: Batch #35 - Loss: 0.7240935564041138\n",
      "Ep 87: Batch #36 - Loss: 0.5850570797920227\n",
      "Ep 87: Batch #37 - Loss: 0.9201023578643799\n",
      "Ep 87: Batch #38 - Loss: 0.566886842250824\n",
      "Ep 87: Batch #39 - Loss: 0.6867359280586243\n",
      "Ep 87: Batch #40 - Loss: 0.6038371324539185\n",
      "Ep 87: Batch #41 - Loss: 0.6190704107284546\n",
      "Ep 87: Batch #42 - Loss: 0.569868266582489\n",
      "Ep 87: Batch #43 - Loss: 0.6333621144294739\n",
      "Ep 87: Batch #44 - Loss: 0.6121628880500793\n",
      "Ep 87: Batch #45 - Loss: 0.5231297016143799\n",
      "Ep 87: Batch #46 - Loss: 0.6977980136871338\n",
      "Ep 87: Batch #47 - Loss: 0.8022071719169617\n",
      "Ep 87: Batch #48 - Loss: 1.0475242137908936\n",
      "Ep 87: Batch #49 - Loss: 0.806047260761261\n",
      "Ep 87: Batch #50 - Loss: 0.5736042261123657\n",
      "Ep 87: Batch #51 - Loss: 0.8174076080322266\n",
      "Ep 87: Batch #52 - Loss: 0.6758161187171936\n",
      "Ep 87: Batch #53 - Loss: 0.7135310769081116\n",
      "Ep 87: Batch #54 - Loss: 0.5771435499191284\n",
      "Ep 87: Batch #55 - Loss: 0.605445921421051\n",
      "Ep 87: Batch #56 - Loss: 0.8603704571723938\n",
      "Ep 87: Batch #57 - Loss: 0.6811227202415466\n",
      "Ep 87: Batch #58 - Loss: 0.8221932649612427\n",
      "Ep 87: Batch #59 - Loss: 0.5558888912200928\n",
      "Ep 87: Batch #60 - Loss: 1.0068726539611816\n",
      "Ep 87: Batch #61 - Loss: 0.5346882343292236\n",
      "Ep 87: Batch #62 - Loss: 0.5746476054191589\n",
      "Ep 87: Batch #63 - Loss: 0.7781854867935181\n",
      "Ep 87: Batch #64 - Loss: 7.930866718292236\n",
      "Ep 87: Batch #65 - Loss: 0.5237364768981934\n",
      "Ep 87: Batch #66 - Loss: 0.6639524698257446\n",
      "Ep 87: Batch #67 - Loss: 0.775335967540741\n",
      "Ep 87: Batch #68 - Loss: 0.7128031849861145\n",
      "Ep 87: Batch #69 - Loss: 0.5861613154411316\n",
      "Ep 87: Batch #70 - Loss: 0.6153122782707214\n",
      "Ep 87: Batch #71 - Loss: 0.5345858931541443\n",
      "Ep 87: Batch #72 - Loss: 0.6629981994628906\n",
      "Ep 87: Batch #73 - Loss: 0.7195852994918823\n",
      "Ep 87: Batch #74 - Loss: 0.5761598944664001\n",
      "Ep 87: Batch #75 - Loss: 0.6658179759979248\n",
      "Ep 87: Batch #76 - Loss: 0.9220022559165955\n",
      "Ep 87: Batch #77 - Loss: 0.5748843550682068\n",
      "Ep 87: Batch #78 - Loss: 0.915596067905426\n",
      "Ep 87: Batch #79 - Loss: 0.5248894691467285\n",
      "Ep 87: Batch #80 - Loss: 0.6892344355583191\n",
      "Ep 87: Batch #81 - Loss: 1.5250270366668701\n",
      "Ep 87: Batch #82 - Loss: 0.7543038129806519\n",
      "Ep 87: Batch #83 - Loss: 1.1895314455032349\n",
      "Ep 87: Batch #84 - Loss: 0.5769428610801697\n",
      "Ep 87: Batch #85 - Loss: 0.7826349139213562\n",
      "Ep 87: Batch #86 - Loss: 0.5461087822914124\n",
      "Ep 87: Batch #87 - Loss: 0.5702301859855652\n",
      "Ep 87: Batch #88 - Loss: 0.6562796235084534\n",
      "Ep 87: Batch #89 - Loss: 0.7247283458709717\n",
      "Ep 87: Batch #90 - Loss: 0.9028457999229431\n",
      "Ep 87: Batch #91 - Loss: 0.6503766775131226\n",
      "Ep 87: Batch #92 - Loss: 0.7288937568664551\n",
      "Ep 87: Batch #93 - Loss: 0.7810080647468567\n",
      "Ep 87: Batch #94 - Loss: 0.7441543340682983\n",
      "Ep 87: Batch #95 - Loss: 0.760587751865387\n",
      "Ep 87: Batch #96 - Loss: 0.7558740377426147\n",
      "Ep 87: Batch #97 - Loss: 0.5882169604301453\n",
      "Ep 87: Batch #98 - Loss: 0.5774860978126526\n",
      "Ep 87: Batch #99 - Loss: 0.7920368909835815\n",
      "Ep 87: Batch #100 - Loss: 0.5568596124649048\n",
      "Ep 87: Batch #101 - Loss: 0.8696644902229309\n",
      "Ep 87: Batch #102 - Loss: 0.6121343970298767\n",
      "Ep 87: Batch #103 - Loss: 0.6345256567001343\n",
      "Ep 87: Batch #104 - Loss: 0.6600492000579834\n",
      "Ep 87: Batch #105 - Loss: 0.8190478682518005\n",
      "Ep 87: Batch #106 - Loss: 0.6264905333518982\n",
      "Ep 87: Batch #107 - Loss: 0.6156911253929138\n",
      "Ep 87: Batch #108 - Loss: 0.900612473487854\n",
      "Ep 87: Batch #109 - Loss: 0.6261028051376343\n",
      "Ep 87: Batch #110 - Loss: 0.7240692973136902\n",
      "Ep 87: Batch #111 - Loss: 1.0372354984283447\n",
      "Ep 87: Batch #112 - Loss: 0.7882146239280701\n",
      "Ep 87: Batch #113 - Loss: 0.6575461626052856\n",
      "Ep 87: Batch #114 - Loss: 0.7246369123458862\n",
      "Ep 87: Batch #115 - Loss: 0.9109815955162048\n",
      "Ep 87: Batch #116 - Loss: 0.5212653279304504\n",
      "Ep 87: Batch #117 - Loss: 0.6788938045501709\n",
      "Ep 87: Batch #118 - Loss: 0.45399150252342224\n",
      "Ep 87: Batch #119 - Loss: 0.8070528507232666\n",
      "Ep 87: Batch #120 - Loss: 0.6582860350608826\n",
      "Ep 87: Batch #121 - Loss: 0.5598882436752319\n",
      "Ep 87: Batch #122 - Loss: 0.7084313035011292\n",
      "Ep 87: Batch #123 - Loss: 0.7134576439857483\n",
      "Ep 87: Batch #124 - Loss: 0.5562386512756348\n",
      "Ep 87: Batch #125 - Loss: 2.4782555103302\n",
      "Ep 87: Batch #126 - Loss: 1.0087400674819946\n",
      "Ep 87: Batch #127 - Loss: 0.5820682644844055\n",
      "Ep 87: Batch #128 - Loss: 0.8888466358184814\n",
      "Ep 87: Batch #129 - Loss: 0.6788904070854187\n",
      "Ep 87: Batch #130 - Loss: 0.595333993434906\n",
      "Ep 87: Batch #131 - Loss: 0.7997948527336121\n",
      "Ep 87: Batch #132 - Loss: 0.6826172471046448\n",
      "Ep 87: Batch #133 - Loss: 0.6667313575744629\n",
      "Ep 87: Batch #134 - Loss: 0.6368809938430786\n",
      "Ep 87: Batch #135 - Loss: 0.820789098739624\n",
      "Ep 87: Batch #136 - Loss: 1.0424423217773438\n",
      "Ep 87: Batch #137 - Loss: 0.756828784942627\n",
      "Ep 87: Batch #138 - Loss: 0.9017351269721985\n",
      "Ep 87: Batch #139 - Loss: 0.6748007535934448\n",
      "Ep 87: Batch #140 - Loss: 0.8413115739822388\n",
      "Ep 87: Batch #141 - Loss: 1.1123062372207642\n",
      "Ep 87: Batch #142 - Loss: 0.6720718741416931\n",
      "Ep 87: Batch #143 - Loss: 0.7704426646232605\n",
      "Ep 87: Batch #144 - Loss: 0.6118346452713013\n",
      "Ep 87: Batch #145 - Loss: 0.5975791215896606\n",
      "Ep 87: Batch #146 - Loss: 0.6963950395584106\n",
      "Ep 87: Batch #147 - Loss: 0.6619397401809692\n",
      "Ep 87: Batch #148 - Loss: 0.7526330947875977\n",
      "Ep 87: Batch #149 - Loss: 0.6129980683326721\n",
      "Ep 87: Batch #150 - Loss: 0.719518780708313\n",
      "Ep 87: Batch #151 - Loss: 0.6250576376914978\n",
      "Ep 87: Batch #152 - Loss: 0.6067031621932983\n",
      "Ep 87: Batch #153 - Loss: 0.826579749584198\n",
      "Ep 87: Batch #154 - Loss: 0.6327306032180786\n",
      "Ep 87: Batch #155 - Loss: 0.6878868341445923\n",
      "Ep 87: Batch #156 - Loss: 0.7768738865852356\n",
      "Ep 87: Batch #157 - Loss: 0.6121310591697693\n",
      "Ep 87: Batch #158 - Loss: 0.717045247554779\n",
      "Ep 87: Batch #159 - Loss: 0.5963919162750244\n",
      "Ep 87: Batch #160 - Loss: 0.6898989677429199\n",
      "Ep 87: Batch #161 - Loss: 0.6689478158950806\n",
      "Ep 87: Batch #162 - Loss: 0.7195309400558472\n",
      "Ep 87: Batch #163 - Loss: 0.7608645558357239\n",
      "Ep 87: Batch #164 - Loss: 0.6476010084152222\n",
      "Ep 87: Batch #165 - Loss: 1.339652419090271\n",
      "Ep 87: Batch #166 - Loss: 0.5339707732200623\n",
      "Ep 87: Batch #167 - Loss: 0.699836254119873\n",
      "Ep 87: Batch #168 - Loss: 0.6933877468109131\n",
      "Ep 87: Batch #169 - Loss: 0.666269838809967\n",
      "Ep 87: Batch #170 - Loss: 0.6275933384895325\n",
      "Ep 87: Batch #171 - Loss: 0.6418747901916504\n",
      "Ep 87: Batch #172 - Loss: 0.5336311459541321\n",
      "Ep 87: Batch #173 - Loss: 0.9268974661827087\n",
      "Ep 87: Batch #174 - Loss: 0.4943271577358246\n",
      "Ep 87: Batch #175 - Loss: 0.6343769431114197\n",
      "Ep 87: Batch #176 - Loss: 0.8942736983299255\n",
      "Ep 87: Batch #177 - Loss: 0.6457117199897766\n",
      "Ep 87: Batch #178 - Loss: 0.6205966472625732\n",
      "Ep 87: Batch #179 - Loss: 0.7437024116516113\n",
      "Ep 87: Batch #180 - Loss: 0.6471353769302368\n",
      "Ep 87: Batch #181 - Loss: 0.8003571629524231\n",
      "Ep 87: Batch #182 - Loss: 0.6305291056632996\n",
      "Ep 87: Batch #183 - Loss: 0.6048153042793274\n",
      "Ep 87: Batch #184 - Loss: 0.9183351993560791\n",
      "Ep 87: Batch #185 - Loss: 0.6342253088951111\n",
      "Ep 87: Batch #186 - Loss: 0.7501866221427917\n",
      "Ep 87: Batch #187 - Loss: 0.867742657661438\n",
      "Ep 87: Batch #188 - Loss: 0.927329957485199\n",
      "Ep 87: Batch #189 - Loss: 0.5856603980064392\n",
      "Ep 87: Batch #190 - Loss: 0.6207966208457947\n",
      "Ep 87: Batch #191 - Loss: 0.7990550398826599\n",
      "Ep 87: Batch #192 - Loss: 0.572139322757721\n",
      "Ep 87: Batch #193 - Loss: 0.6312975883483887\n",
      "Ep 87: Batch #194 - Loss: 0.5414937734603882\n",
      "Ep 87: Batch #195 - Loss: 0.7820537686347961\n",
      "Ep 87: Batch #196 - Loss: 0.6939069032669067\n",
      "Ep 87: Batch #197 - Loss: 0.698127806186676\n",
      "Ep 87: Batch #198 - Loss: 0.5343345403671265\n",
      "Ep 87: Batch #199 - Loss: 0.6415841579437256\n",
      "Ep 88: Batch #0 - Loss: 0.651081919670105\n",
      "Ep 88: Batch #1 - Loss: 0.718869686126709\n",
      "Ep 88: Batch #2 - Loss: 0.8599629998207092\n",
      "Ep 88: Batch #3 - Loss: 0.7214530110359192\n",
      "Ep 88: Batch #4 - Loss: 0.657191276550293\n",
      "Ep 88: Batch #5 - Loss: 0.5518199801445007\n",
      "Ep 88: Batch #6 - Loss: 0.7314009070396423\n",
      "Ep 88: Batch #7 - Loss: 0.5756523609161377\n",
      "Ep 88: Batch #8 - Loss: 0.5841554403305054\n",
      "Ep 88: Batch #9 - Loss: 1.0918196439743042\n",
      "Ep 88: Batch #10 - Loss: 0.7900009155273438\n",
      "Ep 88: Batch #11 - Loss: 0.5440945625305176\n",
      "Ep 88: Batch #12 - Loss: 1.1921669244766235\n",
      "Ep 88: Batch #13 - Loss: 0.5719504356384277\n",
      "Ep 88: Batch #14 - Loss: 0.597383975982666\n",
      "Ep 88: Batch #15 - Loss: 0.8393042683601379\n",
      "Ep 88: Batch #16 - Loss: 0.9552050828933716\n",
      "Ep 88: Batch #17 - Loss: 0.7319085597991943\n",
      "Ep 88: Batch #18 - Loss: 0.8106558918952942\n",
      "Ep 88: Batch #19 - Loss: 0.5636422038078308\n",
      "Ep 88: Batch #20 - Loss: 0.5463172793388367\n",
      "Ep 88: Batch #21 - Loss: 0.7893964052200317\n",
      "Ep 88: Batch #22 - Loss: 0.6060678362846375\n",
      "Ep 88: Batch #23 - Loss: 0.5997644662857056\n",
      "Ep 88: Batch #24 - Loss: 0.6430554389953613\n",
      "Ep 88: Batch #25 - Loss: 0.605294406414032\n",
      "Ep 88: Batch #26 - Loss: 0.5553708076477051\n",
      "Ep 88: Batch #27 - Loss: 1.1373487710952759\n",
      "Ep 88: Batch #28 - Loss: 0.692674994468689\n",
      "Ep 88: Batch #29 - Loss: 0.7528929710388184\n",
      "Ep 88: Batch #30 - Loss: 0.8180956840515137\n",
      "Ep 88: Batch #31 - Loss: 0.5622928738594055\n",
      "Ep 88: Batch #32 - Loss: 0.5808359980583191\n",
      "Ep 88: Batch #33 - Loss: 0.6670458316802979\n",
      "Ep 88: Batch #34 - Loss: 0.6343857645988464\n",
      "Ep 88: Batch #35 - Loss: 0.7242123484611511\n",
      "Ep 88: Batch #36 - Loss: 0.5850488543510437\n",
      "Ep 88: Batch #37 - Loss: 0.9201657176017761\n",
      "Ep 88: Batch #38 - Loss: 0.5669012665748596\n",
      "Ep 88: Batch #39 - Loss: 0.6868321299552917\n",
      "Ep 88: Batch #40 - Loss: 0.6037482023239136\n",
      "Ep 88: Batch #41 - Loss: 0.6190818548202515\n",
      "Ep 88: Batch #42 - Loss: 0.5698681473731995\n",
      "Ep 88: Batch #43 - Loss: 0.6335557699203491\n",
      "Ep 88: Batch #44 - Loss: 0.6122480034828186\n",
      "Ep 88: Batch #45 - Loss: 0.5232601165771484\n",
      "Ep 88: Batch #46 - Loss: 0.6978418827056885\n",
      "Ep 88: Batch #47 - Loss: 0.8021219968795776\n",
      "Ep 88: Batch #48 - Loss: 1.047879934310913\n",
      "Ep 88: Batch #49 - Loss: 0.8059021234512329\n",
      "Ep 88: Batch #50 - Loss: 0.5734516978263855\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 88: Batch #51 - Loss: 0.8175011873245239\n",
      "Ep 88: Batch #52 - Loss: 0.6758511662483215\n",
      "Ep 88: Batch #53 - Loss: 0.7134866714477539\n",
      "Ep 88: Batch #54 - Loss: 0.5770338177680969\n",
      "Ep 88: Batch #55 - Loss: 0.6051634550094604\n",
      "Ep 88: Batch #56 - Loss: 0.8604150414466858\n",
      "Ep 88: Batch #57 - Loss: 0.6810950636863708\n",
      "Ep 88: Batch #58 - Loss: 0.8222585320472717\n",
      "Ep 88: Batch #59 - Loss: 0.5559765696525574\n",
      "Ep 88: Batch #60 - Loss: 1.0066325664520264\n",
      "Ep 88: Batch #61 - Loss: 0.5347118377685547\n",
      "Ep 88: Batch #62 - Loss: 0.5747416019439697\n",
      "Ep 88: Batch #63 - Loss: 0.7780371308326721\n",
      "Ep 88: Batch #64 - Loss: 7.915521621704102\n",
      "Ep 88: Batch #65 - Loss: 0.5237439870834351\n",
      "Ep 88: Batch #66 - Loss: 0.6638965010643005\n",
      "Ep 88: Batch #67 - Loss: 0.7752965688705444\n",
      "Ep 88: Batch #68 - Loss: 0.7127997279167175\n",
      "Ep 88: Batch #69 - Loss: 0.5861578583717346\n",
      "Ep 88: Batch #70 - Loss: 0.615257740020752\n",
      "Ep 88: Batch #71 - Loss: 0.5343670845031738\n",
      "Ep 88: Batch #72 - Loss: 0.6629914045333862\n",
      "Ep 88: Batch #73 - Loss: 0.7196499109268188\n",
      "Ep 88: Batch #74 - Loss: 0.5761584043502808\n",
      "Ep 88: Batch #75 - Loss: 0.6657281517982483\n",
      "Ep 88: Batch #76 - Loss: 0.9219581484794617\n",
      "Ep 88: Batch #77 - Loss: 0.574733316898346\n",
      "Ep 88: Batch #78 - Loss: 0.9155774116516113\n",
      "Ep 88: Batch #79 - Loss: 0.5249289870262146\n",
      "Ep 88: Batch #80 - Loss: 0.6891433596611023\n",
      "Ep 88: Batch #81 - Loss: 1.5226213932037354\n",
      "Ep 88: Batch #82 - Loss: 0.7539711594581604\n",
      "Ep 88: Batch #83 - Loss: 1.1880327463150024\n",
      "Ep 88: Batch #84 - Loss: 0.576713502407074\n",
      "Ep 88: Batch #85 - Loss: 0.7830854654312134\n",
      "Ep 88: Batch #86 - Loss: 0.5461382269859314\n",
      "Ep 88: Batch #87 - Loss: 0.5700090527534485\n",
      "Ep 88: Batch #88 - Loss: 0.6559446454048157\n",
      "Ep 88: Batch #89 - Loss: 0.7241725921630859\n",
      "Ep 88: Batch #90 - Loss: 0.9031363129615784\n",
      "Ep 88: Batch #91 - Loss: 0.6502776145935059\n",
      "Ep 88: Batch #92 - Loss: 0.7288551926612854\n",
      "Ep 88: Batch #93 - Loss: 0.7806265950202942\n",
      "Ep 88: Batch #94 - Loss: 0.743508517742157\n",
      "Ep 88: Batch #95 - Loss: 0.7605580687522888\n",
      "Ep 88: Batch #96 - Loss: 0.755058765411377\n",
      "Ep 88: Batch #97 - Loss: 0.5891554951667786\n",
      "Ep 88: Batch #98 - Loss: 0.5777086019515991\n",
      "Ep 88: Batch #99 - Loss: 0.7908075451850891\n",
      "Ep 88: Batch #100 - Loss: 0.5567383766174316\n",
      "Ep 88: Batch #101 - Loss: 0.8705537915229797\n",
      "Ep 88: Batch #102 - Loss: 0.6117624044418335\n",
      "Ep 88: Batch #103 - Loss: 0.6339802145957947\n",
      "Ep 88: Batch #104 - Loss: 0.6595491170883179\n",
      "Ep 88: Batch #105 - Loss: 0.8194553256034851\n",
      "Ep 88: Batch #106 - Loss: 0.6264979243278503\n",
      "Ep 88: Batch #107 - Loss: 0.6153643727302551\n",
      "Ep 88: Batch #108 - Loss: 0.9008591175079346\n",
      "Ep 88: Batch #109 - Loss: 0.6253800988197327\n",
      "Ep 88: Batch #110 - Loss: 0.7227702736854553\n",
      "Ep 88: Batch #111 - Loss: 1.0380629301071167\n",
      "Ep 88: Batch #112 - Loss: 0.7878903150558472\n",
      "Ep 88: Batch #113 - Loss: 0.6571630239486694\n",
      "Ep 88: Batch #114 - Loss: 0.7239425778388977\n",
      "Ep 88: Batch #115 - Loss: 0.9114252924919128\n",
      "Ep 88: Batch #116 - Loss: 0.521066427230835\n",
      "Ep 88: Batch #117 - Loss: 0.6787129640579224\n",
      "Ep 88: Batch #118 - Loss: 0.45383620262145996\n",
      "Model saved in file: ./weights_autoencoder_sigmoid/model_e88b118_1516648803.227445.ckpt\n",
      "Ep 88: Batch #119 - Loss: 0.8080108761787415\n",
      "Ep 88: Batch #120 - Loss: 0.6586693525314331\n",
      "Ep 88: Batch #121 - Loss: 0.5597396492958069\n",
      "Ep 88: Batch #122 - Loss: 0.7086539268493652\n",
      "Ep 88: Batch #123 - Loss: 0.7135287523269653\n",
      "Ep 88: Batch #124 - Loss: 0.5559130907058716\n",
      "Ep 88: Batch #125 - Loss: 2.475341558456421\n",
      "Ep 88: Batch #126 - Loss: 1.0084283351898193\n",
      "Ep 88: Batch #127 - Loss: 0.5818422436714172\n",
      "Ep 88: Batch #128 - Loss: 0.8884252905845642\n",
      "Ep 88: Batch #129 - Loss: 0.6784040927886963\n",
      "Ep 88: Batch #130 - Loss: 0.5948623418807983\n",
      "Ep 88: Batch #131 - Loss: 0.799262523651123\n",
      "Ep 88: Batch #132 - Loss: 0.6826417446136475\n",
      "Ep 88: Batch #133 - Loss: 0.666624903678894\n",
      "Ep 88: Batch #134 - Loss: 0.6365787386894226\n",
      "Ep 88: Batch #135 - Loss: 0.8198928833007812\n",
      "Ep 88: Batch #136 - Loss: 1.0422756671905518\n",
      "Ep 88: Batch #137 - Loss: 0.7550513744354248\n",
      "Ep 88: Batch #138 - Loss: 0.9020792245864868\n",
      "Ep 88: Batch #139 - Loss: 0.6741374731063843\n",
      "Ep 88: Batch #140 - Loss: 0.8406854867935181\n",
      "Ep 88: Batch #141 - Loss: 1.1111196279525757\n",
      "Ep 88: Batch #142 - Loss: 0.671337902545929\n",
      "Ep 88: Batch #143 - Loss: 0.7699726819992065\n",
      "Ep 88: Batch #144 - Loss: 0.6118993759155273\n",
      "Ep 88: Batch #145 - Loss: 0.5974568128585815\n",
      "Ep 88: Batch #146 - Loss: 0.6956260800361633\n",
      "Ep 88: Batch #147 - Loss: 0.6615130305290222\n",
      "Ep 88: Batch #148 - Loss: 0.7518344521522522\n",
      "Ep 88: Batch #149 - Loss: 0.6127264499664307\n",
      "Ep 88: Batch #150 - Loss: 0.7194578647613525\n",
      "Ep 88: Batch #151 - Loss: 0.6245484352111816\n",
      "Ep 88: Batch #152 - Loss: 0.6067405343055725\n",
      "Ep 88: Batch #153 - Loss: 0.8261959552764893\n",
      "Ep 88: Batch #154 - Loss: 0.632594108581543\n",
      "Ep 88: Batch #155 - Loss: 0.687561571598053\n",
      "Ep 88: Batch #156 - Loss: 0.7765828967094421\n",
      "Ep 88: Batch #157 - Loss: 0.6120656132698059\n",
      "Ep 88: Batch #158 - Loss: 0.7169947624206543\n",
      "Ep 88: Batch #159 - Loss: 0.5963663458824158\n",
      "Ep 88: Batch #160 - Loss: 0.6899545788764954\n",
      "Ep 88: Batch #161 - Loss: 0.6688676476478577\n",
      "Ep 88: Batch #162 - Loss: 0.719603419303894\n",
      "Ep 88: Batch #163 - Loss: 0.7604784965515137\n",
      "Ep 88: Batch #164 - Loss: 0.6473403573036194\n",
      "Ep 88: Batch #165 - Loss: 1.3381863832473755\n",
      "Ep 88: Batch #166 - Loss: 0.5338742136955261\n",
      "Ep 88: Batch #167 - Loss: 0.6998015642166138\n",
      "Ep 88: Batch #168 - Loss: 0.6928916573524475\n",
      "Ep 88: Batch #169 - Loss: 0.6664108037948608\n",
      "Ep 88: Batch #170 - Loss: 0.6272283792495728\n",
      "Ep 88: Batch #171 - Loss: 0.641703724861145\n",
      "Ep 88: Batch #172 - Loss: 0.5336121916770935\n",
      "Ep 88: Batch #173 - Loss: 0.9262999892234802\n",
      "Ep 88: Batch #174 - Loss: 0.4944702982902527\n",
      "Ep 88: Batch #175 - Loss: 0.6345298886299133\n",
      "Ep 88: Batch #176 - Loss: 0.8941716551780701\n",
      "Ep 88: Batch #177 - Loss: 0.6456429958343506\n",
      "Ep 88: Batch #178 - Loss: 0.6202370524406433\n",
      "Ep 88: Batch #179 - Loss: 0.743373692035675\n",
      "Ep 88: Batch #180 - Loss: 0.6468061804771423\n",
      "Ep 88: Batch #181 - Loss: 0.7997583746910095\n",
      "Ep 88: Batch #182 - Loss: 0.6305906772613525\n",
      "Ep 88: Batch #183 - Loss: 0.6046359539031982\n",
      "Ep 88: Batch #184 - Loss: 0.918244481086731\n",
      "Ep 88: Batch #185 - Loss: 0.6335370540618896\n",
      "Ep 88: Batch #186 - Loss: 0.7488812804222107\n",
      "Ep 88: Batch #187 - Loss: 0.8670895099639893\n",
      "Ep 88: Batch #188 - Loss: 0.9264435172080994\n",
      "Ep 88: Batch #189 - Loss: 0.5850625038146973\n",
      "Ep 88: Batch #190 - Loss: 0.6203293800354004\n",
      "Ep 88: Batch #191 - Loss: 0.7994796633720398\n",
      "Ep 88: Batch #192 - Loss: 0.5719514489173889\n",
      "Ep 88: Batch #193 - Loss: 0.6310778856277466\n",
      "Ep 88: Batch #194 - Loss: 0.5416618585586548\n",
      "Ep 88: Batch #195 - Loss: 0.782042920589447\n",
      "Ep 88: Batch #196 - Loss: 0.6936866641044617\n",
      "Ep 88: Batch #197 - Loss: 0.6978917121887207\n",
      "Ep 88: Batch #198 - Loss: 0.5345624089241028\n",
      "Ep 88: Batch #199 - Loss: 0.6413379907608032\n",
      "Ep 89: Batch #0 - Loss: 0.6507733464241028\n",
      "Ep 89: Batch #1 - Loss: 0.7189602851867676\n",
      "Ep 89: Batch #2 - Loss: 0.8596317172050476\n",
      "Ep 89: Batch #3 - Loss: 0.7214382290840149\n",
      "Ep 89: Batch #4 - Loss: 0.6570654511451721\n",
      "Ep 89: Batch #5 - Loss: 0.5517206192016602\n",
      "Ep 89: Batch #6 - Loss: 0.7310013175010681\n",
      "Ep 89: Batch #7 - Loss: 0.5754728317260742\n",
      "Ep 89: Batch #8 - Loss: 0.5840253829956055\n",
      "Ep 89: Batch #9 - Loss: 1.091333270072937\n",
      "Ep 89: Batch #10 - Loss: 0.7900277972221375\n",
      "Ep 89: Batch #11 - Loss: 0.5440376400947571\n",
      "Ep 89: Batch #12 - Loss: 1.1914355754852295\n",
      "Ep 89: Batch #13 - Loss: 0.5717914700508118\n",
      "Ep 89: Batch #14 - Loss: 0.5973296165466309\n",
      "Ep 89: Batch #15 - Loss: 0.8388194441795349\n",
      "Ep 89: Batch #16 - Loss: 0.9555703401565552\n",
      "Ep 89: Batch #17 - Loss: 0.7318747043609619\n",
      "Ep 89: Batch #18 - Loss: 0.810492992401123\n",
      "Ep 89: Batch #19 - Loss: 0.5634190440177917\n",
      "Ep 89: Batch #20 - Loss: 0.5462759137153625\n",
      "Ep 89: Batch #21 - Loss: 0.7892075777053833\n",
      "Ep 89: Batch #22 - Loss: 0.6060084700584412\n",
      "Ep 89: Batch #23 - Loss: 0.5998097062110901\n",
      "Ep 89: Batch #24 - Loss: 0.6431207656860352\n",
      "Ep 89: Batch #25 - Loss: 0.6052350997924805\n",
      "Ep 89: Batch #26 - Loss: 0.5551769733428955\n",
      "Ep 89: Batch #27 - Loss: 1.1367276906967163\n",
      "Ep 89: Batch #28 - Loss: 0.6926718354225159\n",
      "Ep 89: Batch #29 - Loss: 0.7526156902313232\n",
      "Ep 89: Batch #30 - Loss: 0.8183029294013977\n",
      "Ep 89: Batch #31 - Loss: 0.5623507499694824\n",
      "Ep 89: Batch #32 - Loss: 0.5809713006019592\n",
      "Ep 89: Batch #33 - Loss: 0.666725218296051\n",
      "Ep 89: Batch #34 - Loss: 0.6342803239822388\n",
      "Ep 89: Batch #35 - Loss: 0.7243421077728271\n",
      "Ep 89: Batch #36 - Loss: 0.5847486853599548\n",
      "Ep 89: Batch #37 - Loss: 0.9199463129043579\n",
      "Ep 89: Batch #38 - Loss: 0.5667832493782043\n",
      "Ep 89: Batch #39 - Loss: 0.6869239807128906\n",
      "Ep 89: Batch #40 - Loss: 0.6038212180137634\n",
      "Ep 89: Batch #41 - Loss: 0.6188204884529114\n",
      "Ep 89: Batch #42 - Loss: 0.5699262619018555\n",
      "Ep 89: Batch #43 - Loss: 0.6337484121322632\n",
      "Ep 89: Batch #44 - Loss: 0.6122784614562988\n",
      "Ep 89: Batch #45 - Loss: 0.5231422185897827\n",
      "Ep 89: Batch #46 - Loss: 0.697874903678894\n",
      "Ep 89: Batch #47 - Loss: 0.8022646903991699\n",
      "Ep 89: Batch #48 - Loss: 1.047410249710083\n",
      "Ep 89: Batch #49 - Loss: 0.8058072924613953\n",
      "Ep 89: Batch #50 - Loss: 0.5735235810279846\n",
      "Ep 89: Batch #51 - Loss: 0.8174884915351868\n",
      "Ep 89: Batch #52 - Loss: 0.6757116317749023\n",
      "Ep 89: Batch #53 - Loss: 0.7137309908866882\n",
      "Ep 89: Batch #54 - Loss: 0.5770592093467712\n",
      "Ep 89: Batch #55 - Loss: 0.6053416132926941\n",
      "Ep 89: Batch #56 - Loss: 0.8605889081954956\n",
      "Ep 89: Batch #57 - Loss: 0.681196928024292\n",
      "Ep 89: Batch #58 - Loss: 0.8219417333602905\n",
      "Ep 89: Batch #59 - Loss: 0.5557897686958313\n",
      "Ep 89: Batch #60 - Loss: 1.006382942199707\n",
      "Ep 89: Batch #61 - Loss: 0.5346429944038391\n",
      "Ep 89: Batch #62 - Loss: 0.5748096108436584\n",
      "Ep 89: Batch #63 - Loss: 0.7780072093009949\n",
      "Ep 89: Batch #64 - Loss: 7.900214195251465\n",
      "Ep 89: Batch #65 - Loss: 0.5237218737602234\n",
      "Ep 89: Batch #66 - Loss: 0.6639193892478943\n",
      "Ep 89: Batch #67 - Loss: 0.7752780318260193\n",
      "Ep 89: Batch #68 - Loss: 0.7128679156303406\n",
      "Ep 89: Batch #69 - Loss: 0.5859487056732178\n",
      "Ep 89: Batch #70 - Loss: 0.6151577830314636\n",
      "Ep 89: Batch #71 - Loss: 0.5343005061149597\n",
      "Ep 89: Batch #72 - Loss: 0.6627779006958008\n",
      "Ep 89: Batch #73 - Loss: 0.7194836139678955\n",
      "Ep 89: Batch #74 - Loss: 0.5761699676513672\n",
      "Ep 89: Batch #75 - Loss: 0.6657190322875977\n",
      "Ep 89: Batch #76 - Loss: 0.9219083786010742\n",
      "Ep 89: Batch #77 - Loss: 0.5746362209320068\n",
      "Ep 89: Batch #78 - Loss: 0.9155043363571167\n",
      "Ep 89: Batch #79 - Loss: 0.5248628854751587\n",
      "Ep 89: Batch #80 - Loss: 0.6888972520828247\n",
      "Ep 89: Batch #81 - Loss: 1.5220868587493896\n",
      "Ep 89: Batch #82 - Loss: 0.7542559504508972\n",
      "Ep 89: Batch #83 - Loss: 1.1861671209335327\n",
      "Ep 89: Batch #84 - Loss: 0.5766647458076477\n",
      "Ep 89: Batch #85 - Loss: 0.7827044725418091\n",
      "Ep 89: Batch #86 - Loss: 0.546035647392273\n",
      "Ep 89: Batch #87 - Loss: 0.5701389312744141\n",
      "Ep 89: Batch #88 - Loss: 0.656271755695343\n",
      "Ep 89: Batch #89 - Loss: 0.724824845790863\n",
      "Ep 89: Batch #90 - Loss: 0.9032623767852783\n",
      "Ep 89: Batch #91 - Loss: 0.6503612995147705\n",
      "Ep 89: Batch #92 - Loss: 0.7286732792854309\n",
      "Ep 89: Batch #93 - Loss: 0.7810021638870239\n",
      "Ep 89: Batch #94 - Loss: 0.7439389824867249\n",
      "Ep 89: Batch #95 - Loss: 0.7603890299797058\n",
      "Ep 89: Batch #96 - Loss: 0.7557467818260193\n",
      "Ep 89: Batch #97 - Loss: 0.5879013538360596\n",
      "Ep 89: Batch #98 - Loss: 0.576897144317627\n",
      "Ep 89: Batch #99 - Loss: 0.7910537719726562\n",
      "Ep 89: Batch #100 - Loss: 0.5567516684532166\n",
      "Ep 89: Batch #101 - Loss: 0.8697553873062134\n",
      "Ep 89: Batch #102 - Loss: 0.6120016574859619\n",
      "Ep 89: Batch #103 - Loss: 0.6342544555664062\n",
      "Ep 89: Batch #104 - Loss: 0.6598069071769714\n",
      "Ep 89: Batch #105 - Loss: 0.8188048005104065\n",
      "Ep 89: Batch #106 - Loss: 0.6266347765922546\n",
      "Ep 89: Batch #107 - Loss: 0.6156349182128906\n",
      "Ep 89: Batch #108 - Loss: 0.9002410769462585\n",
      "Ep 89: Batch #109 - Loss: 0.6255159974098206\n",
      "Ep 89: Batch #110 - Loss: 0.7233209609985352\n",
      "Ep 89: Batch #111 - Loss: 1.0365830659866333\n",
      "Ep 89: Batch #112 - Loss: 0.7884148955345154\n",
      "Ep 89: Batch #113 - Loss: 0.6573452353477478\n",
      "Ep 89: Batch #114 - Loss: 0.7239070534706116\n",
      "Ep 89: Batch #115 - Loss: 0.9111582636833191\n",
      "Ep 89: Batch #116 - Loss: 0.5210624933242798\n",
      "Ep 89: Batch #117 - Loss: 0.678583562374115\n",
      "Ep 89: Batch #118 - Loss: 0.4539056718349457\n",
      "Ep 89: Batch #119 - Loss: 0.8071680665016174\n",
      "Ep 89: Batch #120 - Loss: 0.6581791043281555\n",
      "Ep 89: Batch #121 - Loss: 0.5599408149719238\n",
      "Ep 89: Batch #122 - Loss: 0.7082346081733704\n",
      "Ep 89: Batch #123 - Loss: 0.7132861614227295\n",
      "Ep 89: Batch #124 - Loss: 0.5562775135040283\n",
      "Ep 89: Batch #125 - Loss: 2.4778685569763184\n",
      "Ep 89: Batch #126 - Loss: 1.0086411237716675\n",
      "Ep 89: Batch #127 - Loss: 0.5820398330688477\n",
      "Ep 89: Batch #128 - Loss: 0.8892780542373657\n",
      "Ep 89: Batch #129 - Loss: 0.6782932877540588\n",
      "Ep 89: Batch #130 - Loss: 0.5950207114219666\n",
      "Ep 89: Batch #131 - Loss: 0.799340009689331\n",
      "Ep 89: Batch #132 - Loss: 0.6826305985450745\n",
      "Ep 89: Batch #133 - Loss: 0.6666936874389648\n",
      "Ep 89: Batch #134 - Loss: 0.6367815136909485\n",
      "Ep 89: Batch #135 - Loss: 0.8203381896018982\n",
      "Ep 89: Batch #136 - Loss: 1.041965365409851\n",
      "Ep 89: Batch #137 - Loss: 0.7558324337005615\n",
      "Ep 89: Batch #138 - Loss: 0.9014989733695984\n",
      "Ep 89: Batch #139 - Loss: 0.674548864364624\n",
      "Ep 89: Batch #140 - Loss: 0.8410935997962952\n",
      "Ep 89: Batch #141 - Loss: 1.1112004518508911\n",
      "Ep 89: Batch #142 - Loss: 0.671435534954071\n",
      "Ep 89: Batch #143 - Loss: 0.7700376510620117\n",
      "Ep 89: Batch #144 - Loss: 0.6117438077926636\n",
      "Ep 89: Batch #145 - Loss: 0.5972159504890442\n",
      "Ep 89: Batch #146 - Loss: 0.6957098245620728\n",
      "Ep 89: Batch #147 - Loss: 0.6617186069488525\n",
      "Ep 89: Batch #148 - Loss: 0.7520744800567627\n",
      "Ep 89: Batch #149 - Loss: 0.6129916310310364\n",
      "Ep 89: Batch #150 - Loss: 0.7194064855575562\n",
      "Ep 89: Batch #151 - Loss: 0.6249004602432251\n",
      "Ep 89: Batch #152 - Loss: 0.6065692901611328\n",
      "Ep 89: Batch #153 - Loss: 0.8265324234962463\n",
      "Ep 89: Batch #154 - Loss: 0.632819652557373\n",
      "Ep 89: Batch #155 - Loss: 0.6874465942382812\n",
      "Ep 89: Batch #156 - Loss: 0.7766838073730469\n",
      "Ep 89: Batch #157 - Loss: 0.6120222806930542\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 89: Batch #158 - Loss: 0.7169728875160217\n",
      "Ep 89: Batch #159 - Loss: 0.5962620973587036\n",
      "Ep 89: Batch #160 - Loss: 0.6898860931396484\n",
      "Ep 89: Batch #161 - Loss: 0.6688879728317261\n",
      "Ep 89: Batch #162 - Loss: 0.7199422121047974\n",
      "Ep 89: Batch #163 - Loss: 0.7604816555976868\n",
      "Ep 89: Batch #164 - Loss: 0.6475263833999634\n",
      "Ep 89: Batch #165 - Loss: 1.3401817083358765\n",
      "Ep 89: Batch #166 - Loss: 0.5339450240135193\n",
      "Ep 89: Batch #167 - Loss: 0.699286162853241\n",
      "Ep 89: Batch #168 - Loss: 0.6934608221054077\n",
      "Ep 89: Batch #169 - Loss: 0.6662709712982178\n",
      "Ep 89: Batch #170 - Loss: 0.6276755332946777\n",
      "Ep 89: Batch #171 - Loss: 0.6422712206840515\n",
      "Ep 89: Batch #172 - Loss: 0.5336101055145264\n",
      "Ep 89: Batch #173 - Loss: 0.9270671010017395\n",
      "Ep 89: Batch #174 - Loss: 0.4944072961807251\n",
      "Ep 89: Batch #175 - Loss: 0.63454270362854\n",
      "Ep 89: Batch #176 - Loss: 0.894231915473938\n",
      "Ep 89: Batch #177 - Loss: 0.6456775665283203\n",
      "Ep 89: Batch #178 - Loss: 0.6206017136573792\n",
      "Ep 89: Batch #179 - Loss: 0.7438347935676575\n",
      "Ep 89: Batch #180 - Loss: 0.6469225883483887\n",
      "Ep 89: Batch #181 - Loss: 0.8006037473678589\n",
      "Ep 89: Batch #182 - Loss: 0.6309390068054199\n",
      "Ep 89: Batch #183 - Loss: 0.604665994644165\n",
      "Ep 89: Batch #184 - Loss: 0.9183184504508972\n",
      "Ep 89: Batch #185 - Loss: 0.6345676183700562\n",
      "Ep 89: Batch #186 - Loss: 0.7503051161766052\n",
      "Ep 89: Batch #187 - Loss: 0.8681854605674744\n",
      "Ep 89: Batch #188 - Loss: 0.9253333210945129\n",
      "Ep 89: Batch #189 - Loss: 0.5856432914733887\n",
      "Ep 89: Batch #190 - Loss: 0.6206713318824768\n",
      "Ep 89: Batch #191 - Loss: 0.7987203598022461\n",
      "Ep 89: Batch #192 - Loss: 0.572152316570282\n",
      "Ep 89: Batch #193 - Loss: 0.6311246752738953\n",
      "Ep 89: Batch #194 - Loss: 0.5414218306541443\n",
      "Ep 89: Batch #195 - Loss: 0.7818677425384521\n",
      "Ep 89: Batch #196 - Loss: 0.6939018368721008\n",
      "Ep 89: Batch #197 - Loss: 0.6979215741157532\n",
      "Ep 89: Batch #198 - Loss: 0.5344190001487732\n",
      "Ep 89: Batch #199 - Loss: 0.6414322853088379\n",
      "Ep 90: Batch #0 - Loss: 0.6510182023048401\n",
      "Ep 90: Batch #1 - Loss: 0.7191118001937866\n",
      "Ep 90: Batch #2 - Loss: 0.859818696975708\n",
      "Ep 90: Batch #3 - Loss: 0.721444845199585\n",
      "Ep 90: Batch #4 - Loss: 0.6571733355522156\n",
      "Ep 90: Batch #5 - Loss: 0.551788866519928\n",
      "Ep 90: Batch #6 - Loss: 0.7312533259391785\n",
      "Ep 90: Batch #7 - Loss: 0.5756812691688538\n",
      "Ep 90: Batch #8 - Loss: 0.5841269493103027\n",
      "Ep 90: Batch #9 - Loss: 1.091803789138794\n",
      "Ep 90: Batch #10 - Loss: 0.7895487546920776\n",
      "Ep 90: Batch #11 - Loss: 0.5440524220466614\n",
      "Ep 90: Batch #12 - Loss: 1.191575288772583\n",
      "Ep 90: Batch #13 - Loss: 0.5720615983009338\n",
      "Ep 90: Batch #14 - Loss: 0.5973473191261292\n",
      "Ep 90: Batch #15 - Loss: 0.8388864994049072\n",
      "Ep 90: Batch #16 - Loss: 0.9552244544029236\n",
      "Ep 90: Batch #17 - Loss: 0.7319291830062866\n",
      "Ep 90: Batch #18 - Loss: 0.8107700943946838\n",
      "Ep 90: Batch #19 - Loss: 0.5636498332023621\n",
      "Ep 90: Batch #20 - Loss: 0.5463207364082336\n",
      "Ep 90: Batch #21 - Loss: 0.7884641289710999\n",
      "Ep 90: Batch #22 - Loss: 0.6059296131134033\n",
      "Ep 90: Batch #23 - Loss: 0.5997151136398315\n",
      "Ep 90: Batch #24 - Loss: 0.6431859135627747\n",
      "Ep 90: Batch #25 - Loss: 0.6052069664001465\n",
      "Ep 90: Batch #26 - Loss: 0.5552275776863098\n",
      "Ep 90: Batch #27 - Loss: 1.1367689371109009\n",
      "Ep 90: Batch #28 - Loss: 0.6927431225776672\n",
      "Ep 90: Batch #29 - Loss: 0.7524962425231934\n",
      "Ep 90: Batch #30 - Loss: 0.8178225159645081\n",
      "Ep 90: Batch #31 - Loss: 0.5623366832733154\n",
      "Ep 90: Batch #32 - Loss: 0.5810786485671997\n",
      "Ep 90: Batch #33 - Loss: 0.6669265031814575\n",
      "Ep 90: Batch #34 - Loss: 0.6342393755912781\n",
      "Ep 90: Batch #35 - Loss: 0.7244698405265808\n",
      "Ep 90: Batch #36 - Loss: 0.584795355796814\n",
      "Ep 90: Batch #37 - Loss: 0.9200378060340881\n",
      "Ep 90: Batch #38 - Loss: 0.5667277574539185\n",
      "Ep 90: Batch #39 - Loss: 0.6868721842765808\n",
      "Ep 90: Batch #40 - Loss: 0.6037419438362122\n",
      "Ep 90: Batch #41 - Loss: 0.6188156604766846\n",
      "Ep 90: Batch #42 - Loss: 0.5698714852333069\n",
      "Ep 90: Batch #43 - Loss: 0.6337453722953796\n",
      "Ep 90: Batch #44 - Loss: 0.6123416423797607\n",
      "Ep 90: Batch #45 - Loss: 0.5232040882110596\n",
      "Ep 90: Batch #46 - Loss: 0.6978948712348938\n",
      "Ep 90: Batch #47 - Loss: 0.8021257519721985\n",
      "Ep 90: Batch #48 - Loss: 1.0478867292404175\n",
      "Ep 90: Batch #49 - Loss: 0.8057103157043457\n",
      "Ep 90: Batch #50 - Loss: 0.5736492872238159\n",
      "Ep 90: Batch #51 - Loss: 0.817436695098877\n",
      "Ep 90: Batch #52 - Loss: 0.6757891774177551\n",
      "Ep 90: Batch #53 - Loss: 0.713418185710907\n",
      "Ep 90: Batch #54 - Loss: 0.5770618915557861\n",
      "Ep 90: Batch #55 - Loss: 0.6052666902542114\n",
      "Ep 90: Batch #56 - Loss: 0.8608237504959106\n",
      "Ep 90: Batch #57 - Loss: 0.6811135411262512\n",
      "Ep 90: Batch #58 - Loss: 0.8219701647758484\n",
      "Ep 90: Batch #59 - Loss: 0.555764377117157\n",
      "Ep 90: Batch #60 - Loss: 1.0065867900848389\n",
      "Ep 90: Batch #61 - Loss: 0.5345773100852966\n",
      "Ep 90: Batch #62 - Loss: 0.5748846530914307\n",
      "Ep 90: Batch #63 - Loss: 0.7779480218887329\n",
      "Ep 90: Batch #64 - Loss: 7.885016441345215\n",
      "Ep 90: Batch #65 - Loss: 0.5236308574676514\n",
      "Ep 90: Batch #66 - Loss: 0.6637825965881348\n",
      "Ep 90: Batch #67 - Loss: 0.775303065776825\n",
      "Ep 90: Batch #68 - Loss: 0.7128671407699585\n",
      "Ep 90: Batch #69 - Loss: 0.5859843492507935\n",
      "Ep 90: Batch #70 - Loss: 0.6152724623680115\n",
      "Ep 90: Batch #71 - Loss: 0.5343090295791626\n",
      "Ep 90: Batch #72 - Loss: 0.6629160642623901\n",
      "Ep 90: Batch #73 - Loss: 0.7194122672080994\n",
      "Ep 90: Batch #74 - Loss: 0.5761743187904358\n",
      "Ep 90: Batch #75 - Loss: 0.6654947400093079\n",
      "Ep 90: Batch #76 - Loss: 0.9217110276222229\n",
      "Ep 90: Batch #77 - Loss: 0.574510395526886\n",
      "Ep 90: Batch #78 - Loss: 0.9153947234153748\n",
      "Ep 90: Batch #79 - Loss: 0.5248240828514099\n",
      "Ep 90: Batch #80 - Loss: 0.6888646483421326\n",
      "Ep 90: Batch #81 - Loss: 1.522711992263794\n",
      "Ep 90: Batch #82 - Loss: 0.7540972828865051\n",
      "Ep 90: Batch #83 - Loss: 1.1849364042282104\n",
      "Ep 90: Batch #84 - Loss: 0.576645016670227\n",
      "Ep 90: Batch #85 - Loss: 0.783566951751709\n",
      "Ep 90: Batch #86 - Loss: 0.5461104512214661\n",
      "Ep 90: Batch #87 - Loss: 0.5703541040420532\n",
      "Ep 90: Batch #88 - Loss: 0.6563196778297424\n",
      "Ep 90: Batch #89 - Loss: 0.724046528339386\n",
      "Ep 90: Batch #90 - Loss: 0.903868556022644\n",
      "Ep 90: Batch #91 - Loss: 0.6504939198493958\n",
      "Ep 90: Batch #92 - Loss: 0.729293942451477\n",
      "Ep 90: Batch #93 - Loss: 0.7806264162063599\n",
      "Ep 90: Batch #94 - Loss: 0.7441880106925964\n",
      "Ep 90: Batch #95 - Loss: 0.7609757781028748\n",
      "Ep 90: Batch #96 - Loss: 0.7549688220024109\n",
      "Ep 90: Batch #97 - Loss: 0.5896084308624268\n",
      "Ep 90: Batch #98 - Loss: 0.5780923366546631\n",
      "Ep 90: Batch #99 - Loss: 0.7911408543586731\n",
      "Ep 90: Batch #100 - Loss: 0.5568904280662537\n",
      "Ep 90: Batch #101 - Loss: 0.8709104061126709\n",
      "Ep 90: Batch #102 - Loss: 0.6116021275520325\n",
      "Ep 90: Batch #103 - Loss: 0.6339157819747925\n",
      "Ep 90: Batch #104 - Loss: 0.6597836017608643\n",
      "Ep 90: Batch #105 - Loss: 0.8202708959579468\n",
      "Ep 90: Batch #106 - Loss: 0.626975953578949\n",
      "Ep 90: Batch #107 - Loss: 0.6154033541679382\n",
      "Ep 90: Batch #108 - Loss: 0.9010821580886841\n",
      "Ep 90: Batch #109 - Loss: 0.6253994703292847\n",
      "Ep 90: Batch #110 - Loss: 0.7228702902793884\n",
      "Ep 90: Batch #111 - Loss: 1.0390057563781738\n",
      "Ep 90: Batch #112 - Loss: 0.7878937721252441\n",
      "Ep 90: Batch #113 - Loss: 0.6572425961494446\n",
      "Ep 90: Batch #114 - Loss: 0.7238930463790894\n",
      "Ep 90: Batch #115 - Loss: 0.9115475416183472\n",
      "Ep 90: Batch #116 - Loss: 0.5212137699127197\n",
      "Ep 90: Batch #117 - Loss: 0.678868293762207\n",
      "Ep 90: Batch #118 - Loss: 0.4537036418914795\n",
      "Model saved in file: ./weights_autoencoder_sigmoid/model_e90b118_1516648803.4817216.ckpt\n",
      "Ep 90: Batch #119 - Loss: 0.8080958724021912\n",
      "Ep 90: Batch #120 - Loss: 0.65884929895401\n",
      "Ep 90: Batch #121 - Loss: 0.5599116086959839\n",
      "Ep 90: Batch #122 - Loss: 0.7084578275680542\n",
      "Ep 90: Batch #123 - Loss: 0.713505208492279\n",
      "Ep 90: Batch #124 - Loss: 0.5559566617012024\n",
      "Ep 90: Batch #125 - Loss: 2.4747426509857178\n",
      "Ep 90: Batch #126 - Loss: 1.0083630084991455\n",
      "Ep 90: Batch #127 - Loss: 0.5817419290542603\n",
      "Ep 90: Batch #128 - Loss: 0.8885804414749146\n",
      "Ep 90: Batch #129 - Loss: 0.6779378652572632\n",
      "Ep 90: Batch #130 - Loss: 0.594901978969574\n",
      "Ep 90: Batch #131 - Loss: 0.7987568378448486\n",
      "Ep 90: Batch #132 - Loss: 0.682157039642334\n",
      "Ep 90: Batch #133 - Loss: 0.6668491959571838\n",
      "Ep 90: Batch #134 - Loss: 0.6362719535827637\n",
      "Ep 90: Batch #135 - Loss: 0.8199212551116943\n",
      "Ep 90: Batch #136 - Loss: 1.042131781578064\n",
      "Ep 90: Batch #137 - Loss: 0.7542435526847839\n",
      "Ep 90: Batch #138 - Loss: 0.901925802230835\n",
      "Ep 90: Batch #139 - Loss: 0.6741160750389099\n",
      "Ep 90: Batch #140 - Loss: 0.8407058119773865\n",
      "Ep 90: Batch #141 - Loss: 1.1100589036941528\n",
      "Ep 90: Batch #142 - Loss: 0.6709085702896118\n",
      "Ep 90: Batch #143 - Loss: 0.7697161436080933\n",
      "Ep 90: Batch #144 - Loss: 0.6119288802146912\n",
      "Ep 90: Batch #145 - Loss: 0.5972785353660583\n",
      "Ep 90: Batch #146 - Loss: 0.6953707933425903\n",
      "Ep 90: Batch #147 - Loss: 0.6612017750740051\n",
      "Ep 90: Batch #148 - Loss: 0.7512352466583252\n",
      "Ep 90: Batch #149 - Loss: 0.6126599311828613\n",
      "Ep 90: Batch #150 - Loss: 0.719283938407898\n",
      "Ep 90: Batch #151 - Loss: 0.6243274211883545\n",
      "Ep 90: Batch #152 - Loss: 0.606440007686615\n",
      "Ep 90: Batch #153 - Loss: 0.8262231349945068\n",
      "Ep 90: Batch #154 - Loss: 0.6322233080863953\n",
      "Ep 90: Batch #155 - Loss: 0.6869131326675415\n",
      "Ep 90: Batch #156 - Loss: 0.7763370871543884\n",
      "Ep 90: Batch #157 - Loss: 0.6119275093078613\n",
      "Ep 90: Batch #158 - Loss: 0.7168088555335999\n",
      "Ep 90: Batch #159 - Loss: 0.5964564681053162\n",
      "Ep 90: Batch #160 - Loss: 0.6900671124458313\n",
      "Ep 90: Batch #161 - Loss: 0.6686981916427612\n",
      "Ep 90: Batch #162 - Loss: 0.7196546792984009\n",
      "Ep 90: Batch #163 - Loss: 0.7606973648071289\n",
      "Ep 90: Batch #164 - Loss: 0.6471262574195862\n",
      "Ep 90: Batch #165 - Loss: 1.3372132778167725\n",
      "Ep 90: Batch #166 - Loss: 0.5335127711296082\n",
      "Ep 90: Batch #167 - Loss: 0.6992548108100891\n",
      "Ep 90: Batch #168 - Loss: 0.6930640935897827\n",
      "Ep 90: Batch #169 - Loss: 0.6663177013397217\n",
      "Ep 90: Batch #170 - Loss: 0.6275126934051514\n",
      "Ep 90: Batch #171 - Loss: 0.6431185603141785\n",
      "Ep 90: Batch #172 - Loss: 0.5333519577980042\n",
      "Ep 90: Batch #173 - Loss: 0.9269617795944214\n",
      "Ep 90: Batch #174 - Loss: 0.49431994557380676\n",
      "Ep 90: Batch #175 - Loss: 0.6342998147010803\n",
      "Ep 90: Batch #176 - Loss: 0.8942608833312988\n",
      "Ep 90: Batch #177 - Loss: 0.6462889909744263\n",
      "Ep 90: Batch #178 - Loss: 0.6199140548706055\n",
      "Ep 90: Batch #179 - Loss: 0.7434236407279968\n",
      "Ep 90: Batch #180 - Loss: 0.6455273628234863\n",
      "Ep 90: Batch #181 - Loss: 0.7991663217544556\n",
      "Ep 90: Batch #182 - Loss: 0.6306621432304382\n",
      "Ep 90: Batch #183 - Loss: 0.6042986512184143\n",
      "Ep 90: Batch #184 - Loss: 0.9173041582107544\n",
      "Ep 90: Batch #185 - Loss: 0.6333330273628235\n",
      "Ep 90: Batch #186 - Loss: 0.7468113899230957\n",
      "Ep 90: Batch #187 - Loss: 0.8637874126434326\n",
      "Ep 90: Batch #188 - Loss: 0.9209241271018982\n",
      "Ep 90: Batch #189 - Loss: 0.5855216383934021\n",
      "Ep 90: Batch #190 - Loss: 0.6202481389045715\n",
      "Ep 90: Batch #191 - Loss: 0.7964828014373779\n",
      "Ep 90: Batch #192 - Loss: 0.5717176198959351\n",
      "Ep 90: Batch #193 - Loss: 0.6286810636520386\n",
      "Ep 90: Batch #194 - Loss: 0.5423285365104675\n",
      "Ep 90: Batch #195 - Loss: 0.780451238155365\n",
      "Ep 90: Batch #196 - Loss: 0.6912277936935425\n",
      "Ep 90: Batch #197 - Loss: 0.6959063410758972\n",
      "Ep 90: Batch #198 - Loss: 0.5348337292671204\n",
      "Ep 90: Batch #199 - Loss: 0.6406680941581726\n",
      "Ep 91: Batch #0 - Loss: 0.6506410241127014\n",
      "Ep 91: Batch #1 - Loss: 0.7194125056266785\n",
      "Ep 91: Batch #2 - Loss: 0.8592742085456848\n",
      "Ep 91: Batch #3 - Loss: 0.7201462984085083\n",
      "Ep 91: Batch #4 - Loss: 0.6560544967651367\n",
      "Ep 91: Batch #5 - Loss: 0.5501675009727478\n",
      "Ep 91: Batch #6 - Loss: 0.7300784587860107\n",
      "Ep 91: Batch #7 - Loss: 0.5751891136169434\n",
      "Ep 91: Batch #8 - Loss: 0.5831744074821472\n",
      "Ep 91: Batch #9 - Loss: 1.0888285636901855\n",
      "Ep 91: Batch #10 - Loss: 0.7850547432899475\n",
      "Ep 91: Batch #11 - Loss: 0.5435817241668701\n",
      "Ep 91: Batch #12 - Loss: 1.1827987432479858\n",
      "Ep 91: Batch #13 - Loss: 0.5707284808158875\n",
      "Ep 91: Batch #14 - Loss: 0.5984185338020325\n",
      "Ep 91: Batch #15 - Loss: 0.8369512557983398\n",
      "Ep 91: Batch #16 - Loss: 0.9522955417633057\n",
      "Ep 91: Batch #17 - Loss: 0.7295476198196411\n",
      "Ep 91: Batch #18 - Loss: 0.8092505931854248\n",
      "Ep 91: Batch #19 - Loss: 0.5632358193397522\n",
      "Ep 91: Batch #20 - Loss: 0.5457749366760254\n",
      "Ep 91: Batch #21 - Loss: 0.7884998917579651\n",
      "Ep 91: Batch #22 - Loss: 0.6043142676353455\n",
      "Ep 91: Batch #23 - Loss: 0.598686158657074\n",
      "Ep 91: Batch #24 - Loss: 0.6398026347160339\n",
      "Ep 91: Batch #25 - Loss: 0.6045212745666504\n",
      "Ep 91: Batch #26 - Loss: 0.5538585186004639\n",
      "Ep 91: Batch #27 - Loss: 1.1286649703979492\n",
      "Ep 91: Batch #28 - Loss: 0.6909245848655701\n",
      "Ep 91: Batch #29 - Loss: 0.7491158246994019\n",
      "Ep 91: Batch #30 - Loss: 0.8119343519210815\n",
      "Ep 91: Batch #31 - Loss: 0.5603563785552979\n",
      "Ep 91: Batch #32 - Loss: 0.5776957273483276\n",
      "Ep 91: Batch #33 - Loss: 0.663557231426239\n",
      "Ep 91: Batch #34 - Loss: 0.6329247951507568\n",
      "Ep 91: Batch #35 - Loss: 0.7229707837104797\n",
      "Ep 91: Batch #36 - Loss: 0.5802239775657654\n",
      "Ep 91: Batch #37 - Loss: 0.9193094968795776\n",
      "Ep 91: Batch #38 - Loss: 0.5647384524345398\n",
      "Ep 91: Batch #39 - Loss: 0.6839736700057983\n",
      "Ep 91: Batch #40 - Loss: 0.6042917966842651\n",
      "Ep 91: Batch #41 - Loss: 0.6157062649726868\n",
      "Ep 91: Batch #42 - Loss: 0.5684022307395935\n",
      "Ep 91: Batch #43 - Loss: 0.6300359964370728\n",
      "Ep 91: Batch #44 - Loss: 0.6088025569915771\n",
      "Ep 91: Batch #45 - Loss: 0.5235402584075928\n",
      "Ep 91: Batch #46 - Loss: 0.694342851638794\n",
      "Ep 91: Batch #47 - Loss: 0.7927069664001465\n",
      "Ep 91: Batch #48 - Loss: 1.035689115524292\n",
      "Ep 91: Batch #49 - Loss: 0.8038991689682007\n",
      "Ep 91: Batch #50 - Loss: 0.5700130462646484\n",
      "Ep 91: Batch #51 - Loss: 0.8062655925750732\n",
      "Ep 91: Batch #52 - Loss: 0.6663963198661804\n",
      "Ep 91: Batch #53 - Loss: 0.7067983150482178\n",
      "Ep 91: Batch #54 - Loss: 0.5743939876556396\n",
      "Ep 91: Batch #55 - Loss: 0.6032496690750122\n",
      "Ep 91: Batch #56 - Loss: 0.8495172262191772\n",
      "Ep 91: Batch #57 - Loss: 0.6774951219558716\n",
      "Ep 91: Batch #58 - Loss: 0.8184992671012878\n",
      "Ep 91: Batch #59 - Loss: 0.5565209984779358\n",
      "Ep 91: Batch #60 - Loss: 0.9888581037521362\n",
      "Ep 91: Batch #61 - Loss: 0.5347809195518494\n",
      "Ep 91: Batch #62 - Loss: 0.5739330649375916\n",
      "Ep 91: Batch #63 - Loss: 0.7739112973213196\n",
      "Ep 91: Batch #64 - Loss: 7.865708827972412\n",
      "Ep 91: Batch #65 - Loss: 0.5204759836196899\n",
      "Ep 91: Batch #66 - Loss: 0.6597782373428345\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 91: Batch #67 - Loss: 0.7740683555603027\n",
      "Ep 91: Batch #68 - Loss: 0.7063924074172974\n",
      "Ep 91: Batch #69 - Loss: 0.5876941084861755\n",
      "Ep 91: Batch #70 - Loss: 0.611487865447998\n",
      "Ep 91: Batch #71 - Loss: 0.5357227921485901\n",
      "Ep 91: Batch #72 - Loss: 0.6618976593017578\n",
      "Ep 91: Batch #73 - Loss: 0.7129188179969788\n",
      "Ep 91: Batch #74 - Loss: 0.5732174515724182\n",
      "Ep 91: Batch #75 - Loss: 0.664100170135498\n",
      "Ep 91: Batch #76 - Loss: 0.917277455329895\n",
      "Ep 91: Batch #77 - Loss: 0.5691618919372559\n",
      "Ep 91: Batch #78 - Loss: 0.8980700373649597\n",
      "Ep 91: Batch #79 - Loss: 0.521496593952179\n",
      "Ep 91: Batch #80 - Loss: 0.6819893717765808\n",
      "Ep 91: Batch #81 - Loss: 1.5228830575942993\n",
      "Ep 91: Batch #82 - Loss: 0.7454736828804016\n",
      "Ep 91: Batch #83 - Loss: 1.1819552183151245\n",
      "Ep 91: Batch #84 - Loss: 0.5753928422927856\n",
      "Ep 91: Batch #85 - Loss: 0.7782695293426514\n",
      "Ep 91: Batch #86 - Loss: 0.5441330075263977\n",
      "Ep 91: Batch #87 - Loss: 0.5698665380477905\n",
      "Ep 91: Batch #88 - Loss: 0.6525363922119141\n",
      "Ep 91: Batch #89 - Loss: 0.7249828577041626\n",
      "Ep 91: Batch #90 - Loss: 0.9037905335426331\n",
      "Ep 91: Batch #91 - Loss: 0.6425221562385559\n",
      "Ep 91: Batch #92 - Loss: 0.7303417921066284\n",
      "Ep 91: Batch #93 - Loss: 0.7672443389892578\n",
      "Ep 91: Batch #94 - Loss: 0.7416675090789795\n",
      "Ep 91: Batch #95 - Loss: 0.7581522464752197\n",
      "Ep 91: Batch #96 - Loss: 0.7506911754608154\n",
      "Ep 91: Batch #97 - Loss: 0.587772786617279\n",
      "Ep 91: Batch #98 - Loss: 0.5756099820137024\n",
      "Ep 91: Batch #99 - Loss: 0.7904918193817139\n",
      "Ep 91: Batch #100 - Loss: 0.5558609962463379\n",
      "Ep 91: Batch #101 - Loss: 0.870469868183136\n",
      "Ep 91: Batch #102 - Loss: 0.6078054308891296\n",
      "Ep 91: Batch #103 - Loss: 0.629772961139679\n",
      "Ep 91: Batch #104 - Loss: 0.6565086245536804\n",
      "Ep 91: Batch #105 - Loss: 0.8214197754859924\n",
      "Ep 91: Batch #106 - Loss: 0.6251034736633301\n",
      "Ep 91: Batch #107 - Loss: 0.6131253242492676\n",
      "Ep 91: Batch #108 - Loss: 0.89940345287323\n",
      "Ep 91: Batch #109 - Loss: 0.6206648349761963\n",
      "Ep 91: Batch #110 - Loss: 0.7204465270042419\n",
      "Ep 91: Batch #111 - Loss: 1.0303587913513184\n",
      "Ep 91: Batch #112 - Loss: 0.7903194427490234\n",
      "Ep 91: Batch #113 - Loss: 0.6566897034645081\n",
      "Ep 91: Batch #114 - Loss: 0.7177104353904724\n",
      "Ep 91: Batch #115 - Loss: 0.9066722989082336\n",
      "Ep 91: Batch #116 - Loss: 0.5207614898681641\n",
      "Ep 91: Batch #117 - Loss: 0.6770104765892029\n",
      "Ep 91: Batch #118 - Loss: 0.4529103934764862\n",
      "Model saved in file: ./weights_autoencoder_sigmoid/model_e91b118_1516648803.6198604.ckpt\n",
      "Ep 91: Batch #119 - Loss: 0.8005139827728271\n",
      "Ep 91: Batch #120 - Loss: 0.6533492803573608\n",
      "Ep 91: Batch #121 - Loss: 0.5606364607810974\n",
      "Ep 91: Batch #122 - Loss: 0.6984151601791382\n",
      "Ep 91: Batch #123 - Loss: 0.7070906162261963\n",
      "Ep 91: Batch #124 - Loss: 0.5532229542732239\n",
      "Ep 91: Batch #125 - Loss: 2.4737417697906494\n",
      "Ep 91: Batch #126 - Loss: 1.0069286823272705\n",
      "Ep 91: Batch #127 - Loss: 0.5789499878883362\n",
      "Ep 91: Batch #128 - Loss: 0.8783042430877686\n",
      "Ep 91: Batch #129 - Loss: 0.6742761731147766\n",
      "Ep 91: Batch #130 - Loss: 0.5965229868888855\n",
      "Ep 91: Batch #131 - Loss: 0.7903783321380615\n",
      "Ep 91: Batch #132 - Loss: 0.6817429065704346\n",
      "Ep 91: Batch #133 - Loss: 0.661514937877655\n",
      "Ep 91: Batch #134 - Loss: 0.6352118253707886\n",
      "Ep 91: Batch #135 - Loss: 0.8178534507751465\n",
      "Ep 91: Batch #136 - Loss: 1.0386253595352173\n",
      "Ep 91: Batch #137 - Loss: 0.7501170039176941\n",
      "Ep 91: Batch #138 - Loss: 0.8954375386238098\n",
      "Ep 91: Batch #139 - Loss: 0.6698076725006104\n",
      "Ep 91: Batch #140 - Loss: 0.8392540216445923\n",
      "Ep 91: Batch #141 - Loss: 1.1037577390670776\n",
      "Ep 91: Batch #142 - Loss: 0.6665218472480774\n",
      "Ep 91: Batch #143 - Loss: 0.7623066306114197\n",
      "Ep 91: Batch #144 - Loss: 0.6070539951324463\n",
      "Ep 91: Batch #145 - Loss: 0.5964035987854004\n",
      "Ep 91: Batch #146 - Loss: 0.6937208771705627\n",
      "Ep 91: Batch #147 - Loss: 0.6596900224685669\n",
      "Ep 91: Batch #148 - Loss: 0.7510766386985779\n",
      "Ep 91: Batch #149 - Loss: 0.6101474761962891\n",
      "Ep 91: Batch #150 - Loss: 0.7200437784194946\n",
      "Ep 91: Batch #151 - Loss: 0.6225021481513977\n",
      "Ep 91: Batch #152 - Loss: 0.6076793074607849\n",
      "Ep 91: Batch #153 - Loss: 0.8183807730674744\n",
      "Ep 91: Batch #154 - Loss: 0.6312841176986694\n",
      "Ep 91: Batch #155 - Loss: 0.6837490797042847\n",
      "Ep 91: Batch #156 - Loss: 0.767262876033783\n",
      "Ep 91: Batch #157 - Loss: 0.6087673902511597\n",
      "Ep 91: Batch #158 - Loss: 0.7172744274139404\n",
      "Ep 91: Batch #159 - Loss: 0.5935438871383667\n",
      "Ep 91: Batch #160 - Loss: 0.6891356110572815\n",
      "Ep 91: Batch #161 - Loss: 0.6675667762756348\n",
      "Ep 91: Batch #162 - Loss: 0.7204742431640625\n",
      "Ep 91: Batch #163 - Loss: 0.7555052638053894\n",
      "Ep 91: Batch #164 - Loss: 0.6412704586982727\n",
      "Ep 91: Batch #165 - Loss: 1.3346526622772217\n",
      "Ep 91: Batch #166 - Loss: 0.5293750166893005\n",
      "Ep 91: Batch #167 - Loss: 0.6964130997657776\n",
      "Ep 91: Batch #168 - Loss: 0.6890944838523865\n",
      "Ep 91: Batch #169 - Loss: 0.6659715175628662\n",
      "Ep 91: Batch #170 - Loss: 0.6292009353637695\n",
      "Ep 91: Batch #171 - Loss: 0.6390518546104431\n",
      "Ep 91: Batch #172 - Loss: 0.5333861112594604\n",
      "Ep 91: Batch #173 - Loss: 0.9221610426902771\n",
      "Ep 91: Batch #174 - Loss: 0.49341315031051636\n",
      "Ep 91: Batch #175 - Loss: 0.6351368427276611\n",
      "Ep 91: Batch #176 - Loss: 0.8926234841346741\n",
      "Ep 91: Batch #177 - Loss: 0.6451935172080994\n",
      "Ep 91: Batch #178 - Loss: 0.6175214648246765\n",
      "Ep 91: Batch #179 - Loss: 0.7469815015792847\n",
      "Ep 91: Batch #180 - Loss: 0.644518256187439\n",
      "Ep 91: Batch #181 - Loss: 0.7876773476600647\n",
      "Ep 91: Batch #182 - Loss: 0.6278361082077026\n",
      "Ep 91: Batch #183 - Loss: 0.6020612716674805\n",
      "Ep 91: Batch #184 - Loss: 0.9037527441978455\n",
      "Ep 91: Batch #185 - Loss: 0.6319441199302673\n",
      "Ep 91: Batch #186 - Loss: 0.7406145930290222\n",
      "Ep 91: Batch #187 - Loss: 0.8557409048080444\n",
      "Ep 91: Batch #188 - Loss: 0.9181312918663025\n",
      "Ep 91: Batch #189 - Loss: 0.5865924954414368\n",
      "Ep 91: Batch #190 - Loss: 0.6180632710456848\n",
      "Ep 91: Batch #191 - Loss: 0.7898265719413757\n",
      "Ep 91: Batch #192 - Loss: 0.5722967982292175\n",
      "Ep 91: Batch #193 - Loss: 0.6260576844215393\n",
      "Ep 91: Batch #194 - Loss: 0.5404028296470642\n",
      "Ep 91: Batch #195 - Loss: 0.7767645716667175\n",
      "Ep 91: Batch #196 - Loss: 0.6883811950683594\n",
      "Ep 91: Batch #197 - Loss: 0.6925296783447266\n",
      "Ep 91: Batch #198 - Loss: 0.5345062613487244\n",
      "Ep 91: Batch #199 - Loss: 0.6409164667129517\n",
      "Ep 92: Batch #0 - Loss: 0.6498721241950989\n",
      "Ep 92: Batch #1 - Loss: 0.718646228313446\n",
      "Ep 92: Batch #2 - Loss: 0.85933917760849\n",
      "Ep 92: Batch #3 - Loss: 0.7191839218139648\n",
      "Ep 92: Batch #4 - Loss: 0.6549777388572693\n",
      "Ep 92: Batch #5 - Loss: 0.5486172437667847\n",
      "Ep 92: Batch #6 - Loss: 0.7272639870643616\n",
      "Ep 92: Batch #7 - Loss: 0.5753148794174194\n",
      "Ep 92: Batch #8 - Loss: 0.5802666544914246\n",
      "Ep 92: Batch #9 - Loss: 1.084220290184021\n",
      "Ep 92: Batch #10 - Loss: 0.7815114855766296\n",
      "Ep 92: Batch #11 - Loss: 0.5416538715362549\n",
      "Ep 92: Batch #12 - Loss: 1.1709522008895874\n",
      "Ep 92: Batch #13 - Loss: 0.5690833926200867\n",
      "Ep 92: Batch #14 - Loss: 0.5985072255134583\n",
      "Ep 92: Batch #15 - Loss: 0.8385902643203735\n",
      "Ep 92: Batch #16 - Loss: 0.9490334987640381\n",
      "Ep 92: Batch #17 - Loss: 0.7270377278327942\n",
      "Ep 92: Batch #18 - Loss: 0.8077905774116516\n",
      "Ep 92: Batch #19 - Loss: 0.5632262825965881\n",
      "Ep 92: Batch #20 - Loss: 0.545121431350708\n",
      "Ep 92: Batch #21 - Loss: 0.7856348156929016\n",
      "Ep 92: Batch #22 - Loss: 0.6028227210044861\n",
      "Ep 92: Batch #23 - Loss: 0.5984758734703064\n",
      "Ep 92: Batch #24 - Loss: 0.6400737762451172\n",
      "Ep 92: Batch #25 - Loss: 0.6023991107940674\n",
      "Ep 92: Batch #26 - Loss: 0.5535920858383179\n",
      "Ep 92: Batch #27 - Loss: 1.121862530708313\n",
      "Ep 92: Batch #28 - Loss: 0.6916111707687378\n",
      "Ep 92: Batch #29 - Loss: 0.746868371963501\n",
      "Ep 92: Batch #30 - Loss: 0.8112680315971375\n",
      "Ep 92: Batch #31 - Loss: 0.5593550205230713\n",
      "Ep 92: Batch #32 - Loss: 0.5753607153892517\n",
      "Ep 92: Batch #33 - Loss: 0.6607259511947632\n",
      "Ep 92: Batch #34 - Loss: 0.6312584280967712\n",
      "Ep 92: Batch #35 - Loss: 0.7226635217666626\n",
      "Ep 92: Batch #36 - Loss: 0.5779410004615784\n",
      "Ep 92: Batch #37 - Loss: 0.919865071773529\n",
      "Ep 92: Batch #38 - Loss: 0.5642064809799194\n",
      "Ep 92: Batch #39 - Loss: 0.6827183365821838\n",
      "Ep 92: Batch #40 - Loss: 0.6050225496292114\n",
      "Ep 92: Batch #41 - Loss: 0.6150873303413391\n",
      "Ep 92: Batch #42 - Loss: 0.5677390098571777\n",
      "Ep 92: Batch #43 - Loss: 0.6290674805641174\n",
      "Ep 92: Batch #44 - Loss: 0.6079434156417847\n",
      "Ep 92: Batch #45 - Loss: 0.5233710408210754\n",
      "Ep 92: Batch #46 - Loss: 0.6933842897415161\n",
      "Ep 92: Batch #47 - Loss: 0.7881685495376587\n",
      "Ep 92: Batch #48 - Loss: 1.0321784019470215\n",
      "Ep 92: Batch #49 - Loss: 0.803916335105896\n",
      "Ep 92: Batch #50 - Loss: 0.5686365365982056\n",
      "Ep 92: Batch #51 - Loss: 0.8043212890625\n",
      "Ep 92: Batch #52 - Loss: 0.6638681292533875\n",
      "Ep 92: Batch #53 - Loss: 0.7044810056686401\n",
      "Ep 92: Batch #54 - Loss: 0.5726985335350037\n",
      "Ep 92: Batch #55 - Loss: 0.6020304560661316\n",
      "Ep 92: Batch #56 - Loss: 0.8471219539642334\n",
      "Ep 92: Batch #57 - Loss: 0.676793098449707\n",
      "Ep 92: Batch #58 - Loss: 0.8176767826080322\n",
      "Ep 92: Batch #59 - Loss: 0.5566367506980896\n",
      "Ep 92: Batch #60 - Loss: 0.9846953749656677\n",
      "Ep 92: Batch #61 - Loss: 0.5346002578735352\n",
      "Ep 92: Batch #62 - Loss: 0.5743734836578369\n",
      "Ep 92: Batch #63 - Loss: 0.7726584672927856\n",
      "Ep 92: Batch #64 - Loss: 7.850438594818115\n",
      "Ep 92: Batch #65 - Loss: 0.519603967666626\n",
      "Ep 92: Batch #66 - Loss: 0.6586782932281494\n",
      "Ep 92: Batch #67 - Loss: 0.7740064263343811\n",
      "Ep 92: Batch #68 - Loss: 0.7041348218917847\n",
      "Ep 92: Batch #69 - Loss: 0.5879805684089661\n",
      "Ep 92: Batch #70 - Loss: 0.6115667223930359\n",
      "Ep 92: Batch #71 - Loss: 0.5365386605262756\n",
      "Ep 92: Batch #72 - Loss: 0.6621108055114746\n",
      "Ep 92: Batch #73 - Loss: 0.7114944458007812\n",
      "Ep 92: Batch #74 - Loss: 0.572766125202179\n",
      "Ep 92: Batch #75 - Loss: 0.66373211145401\n",
      "Ep 92: Batch #76 - Loss: 0.916308581829071\n",
      "Ep 92: Batch #77 - Loss: 0.56688392162323\n",
      "Ep 92: Batch #78 - Loss: 0.8928386569023132\n",
      "Ep 92: Batch #79 - Loss: 0.5213237404823303\n",
      "Ep 92: Batch #80 - Loss: 0.680665135383606\n",
      "Ep 92: Batch #81 - Loss: 1.527404546737671\n",
      "Ep 92: Batch #82 - Loss: 0.7427440881729126\n",
      "Ep 92: Batch #83 - Loss: 1.1800950765609741\n",
      "Ep 92: Batch #84 - Loss: 0.5751816034317017\n",
      "Ep 92: Batch #85 - Loss: 0.7777103781700134\n",
      "Ep 92: Batch #86 - Loss: 0.5437831282615662\n",
      "Ep 92: Batch #87 - Loss: 0.569166362285614\n",
      "Ep 92: Batch #88 - Loss: 0.651938259601593\n",
      "Ep 92: Batch #89 - Loss: 0.7236546874046326\n",
      "Ep 92: Batch #90 - Loss: 0.9049795866012573\n",
      "Ep 92: Batch #91 - Loss: 0.6412087082862854\n",
      "Ep 92: Batch #92 - Loss: 0.7316327691078186\n",
      "Ep 92: Batch #93 - Loss: 0.7646592855453491\n",
      "Ep 92: Batch #94 - Loss: 0.7395627498626709\n",
      "Ep 92: Batch #95 - Loss: 0.7585370540618896\n",
      "Ep 92: Batch #96 - Loss: 0.7478841543197632\n",
      "Ep 92: Batch #97 - Loss: 0.589605450630188\n",
      "Ep 92: Batch #98 - Loss: 0.5780254602432251\n",
      "Ep 92: Batch #99 - Loss: 0.791204571723938\n",
      "Ep 92: Batch #100 - Loss: 0.5555868148803711\n",
      "Ep 92: Batch #101 - Loss: 0.8718747496604919\n",
      "Ep 92: Batch #102 - Loss: 0.6068980693817139\n",
      "Ep 92: Batch #103 - Loss: 0.6289798021316528\n",
      "Ep 92: Batch #104 - Loss: 0.6560523509979248\n",
      "Ep 92: Batch #105 - Loss: 0.8233080506324768\n",
      "Ep 92: Batch #106 - Loss: 0.625426173210144\n",
      "Ep 92: Batch #107 - Loss: 0.6128513813018799\n",
      "Ep 92: Batch #108 - Loss: 0.9014003276824951\n",
      "Ep 92: Batch #109 - Loss: 0.6190140843391418\n",
      "Ep 92: Batch #110 - Loss: 0.7189476490020752\n",
      "Ep 92: Batch #111 - Loss: 1.0327390432357788\n",
      "Ep 92: Batch #112 - Loss: 0.7911617755889893\n",
      "Ep 92: Batch #113 - Loss: 0.6561862826347351\n",
      "Ep 92: Batch #114 - Loss: 0.716382622718811\n",
      "Ep 92: Batch #115 - Loss: 0.9064161777496338\n",
      "Ep 92: Batch #116 - Loss: 0.5207849740982056\n",
      "Ep 92: Batch #117 - Loss: 0.6771925687789917\n",
      "Ep 92: Batch #118 - Loss: 0.4525696635246277\n",
      "Model saved in file: ./weights_autoencoder_sigmoid/model_e92b118_1516648803.7634988.ckpt\n",
      "Ep 92: Batch #119 - Loss: 0.8010070323944092\n",
      "Ep 92: Batch #120 - Loss: 0.6533504128456116\n",
      "Ep 92: Batch #121 - Loss: 0.5610336661338806\n",
      "Ep 92: Batch #122 - Loss: 0.6958014965057373\n",
      "Ep 92: Batch #123 - Loss: 0.7053722143173218\n",
      "Ep 92: Batch #124 - Loss: 0.5522933006286621\n",
      "Ep 92: Batch #125 - Loss: 2.4702188968658447\n",
      "Ep 92: Batch #126 - Loss: 1.0073707103729248\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 92: Batch #127 - Loss: 0.5785493850708008\n",
      "Ep 92: Batch #128 - Loss: 0.876731276512146\n",
      "Ep 92: Batch #129 - Loss: 0.6740007400512695\n",
      "Ep 92: Batch #130 - Loss: 0.597183108329773\n",
      "Ep 92: Batch #131 - Loss: 0.7889220714569092\n",
      "Ep 92: Batch #132 - Loss: 0.6826298832893372\n",
      "Ep 92: Batch #133 - Loss: 0.6604695320129395\n",
      "Ep 92: Batch #134 - Loss: 0.6349952816963196\n",
      "Ep 92: Batch #135 - Loss: 0.8167684674263\n",
      "Ep 92: Batch #136 - Loss: 1.0387158393859863\n",
      "Ep 92: Batch #137 - Loss: 0.7485441565513611\n",
      "Ep 92: Batch #138 - Loss: 0.8954039216041565\n",
      "Ep 92: Batch #139 - Loss: 0.6692869663238525\n",
      "Ep 92: Batch #140 - Loss: 0.8387841582298279\n",
      "Ep 92: Batch #141 - Loss: 1.1016261577606201\n",
      "Ep 92: Batch #142 - Loss: 0.6661067605018616\n",
      "Ep 92: Batch #143 - Loss: 0.7612321972846985\n",
      "Ep 92: Batch #144 - Loss: 0.6065880656242371\n",
      "Ep 92: Batch #145 - Loss: 0.5969620943069458\n",
      "Ep 92: Batch #146 - Loss: 0.6932672262191772\n",
      "Ep 92: Batch #147 - Loss: 0.659075915813446\n",
      "Ep 92: Batch #148 - Loss: 0.7513156533241272\n",
      "Ep 92: Batch #149 - Loss: 0.6073523163795471\n",
      "Ep 92: Batch #150 - Loss: 0.7206913828849792\n",
      "Ep 92: Batch #151 - Loss: 0.6217343807220459\n",
      "Ep 92: Batch #152 - Loss: 0.608158528804779\n",
      "Ep 92: Batch #153 - Loss: 0.8164754509925842\n",
      "Ep 92: Batch #154 - Loss: 0.6309540867805481\n",
      "Ep 92: Batch #155 - Loss: 0.6830769777297974\n",
      "Ep 92: Batch #156 - Loss: 0.7651962637901306\n",
      "Ep 92: Batch #157 - Loss: 0.6083166599273682\n",
      "Ep 92: Batch #158 - Loss: 0.7168728113174438\n",
      "Ep 92: Batch #159 - Loss: 0.5933184027671814\n",
      "Ep 92: Batch #160 - Loss: 0.6894266605377197\n",
      "Ep 92: Batch #161 - Loss: 0.6675084233283997\n",
      "Ep 92: Batch #162 - Loss: 0.7212701439857483\n",
      "Ep 92: Batch #163 - Loss: 0.7538447976112366\n",
      "Ep 92: Batch #164 - Loss: 0.6406371593475342\n",
      "Ep 92: Batch #165 - Loss: 1.334110975265503\n",
      "Ep 92: Batch #166 - Loss: 0.5288681387901306\n",
      "Ep 92: Batch #167 - Loss: 0.6958039999008179\n",
      "Ep 92: Batch #168 - Loss: 0.6881570816040039\n",
      "Ep 92: Batch #169 - Loss: 0.6666299104690552\n",
      "Ep 92: Batch #170 - Loss: 0.6283189058303833\n",
      "Ep 92: Batch #171 - Loss: 0.6380159258842468\n",
      "Ep 92: Batch #172 - Loss: 0.5330625176429749\n",
      "Ep 92: Batch #173 - Loss: 0.9210317134857178\n",
      "Ep 92: Batch #174 - Loss: 0.49320414662361145\n",
      "Ep 92: Batch #175 - Loss: 0.6353100538253784\n",
      "Ep 92: Batch #176 - Loss: 0.8932209014892578\n",
      "Ep 92: Batch #177 - Loss: 0.6449857354164124\n",
      "Ep 92: Batch #178 - Loss: 0.6161869764328003\n",
      "Ep 92: Batch #179 - Loss: 0.7469344735145569\n",
      "Ep 92: Batch #180 - Loss: 0.6441125273704529\n",
      "Ep 92: Batch #181 - Loss: 0.7845743894577026\n",
      "Ep 92: Batch #182 - Loss: 0.6273747086524963\n",
      "Ep 92: Batch #183 - Loss: 0.6016857624053955\n",
      "Ep 92: Batch #184 - Loss: 0.9009876847267151\n",
      "Ep 92: Batch #185 - Loss: 0.6309607625007629\n",
      "Ep 92: Batch #186 - Loss: 0.7378741502761841\n",
      "Ep 92: Batch #187 - Loss: 0.853858232498169\n",
      "Ep 92: Batch #188 - Loss: 0.9175480604171753\n",
      "Ep 92: Batch #189 - Loss: 0.5861314535140991\n",
      "Ep 92: Batch #190 - Loss: 0.6163318157196045\n",
      "Ep 92: Batch #191 - Loss: 0.7891525030136108\n",
      "Ep 92: Batch #192 - Loss: 0.5717942118644714\n",
      "Ep 92: Batch #193 - Loss: 0.6256408095359802\n",
      "Ep 92: Batch #194 - Loss: 0.5398800373077393\n",
      "Ep 92: Batch #195 - Loss: 0.7762615084648132\n",
      "Ep 92: Batch #196 - Loss: 0.6878389120101929\n",
      "Ep 92: Batch #197 - Loss: 0.6919986605644226\n",
      "Ep 92: Batch #198 - Loss: 0.5351237058639526\n",
      "Ep 92: Batch #199 - Loss: 0.6410074234008789\n",
      "Ep 93: Batch #0 - Loss: 0.6492400169372559\n",
      "Ep 93: Batch #1 - Loss: 0.719028651714325\n",
      "Ep 93: Batch #2 - Loss: 0.8595766425132751\n",
      "Ep 93: Batch #3 - Loss: 0.7193759679794312\n",
      "Ep 93: Batch #4 - Loss: 0.6547272801399231\n",
      "Ep 93: Batch #5 - Loss: 0.5481104254722595\n",
      "Ep 93: Batch #6 - Loss: 0.7256982922554016\n",
      "Ep 93: Batch #7 - Loss: 0.5757099986076355\n",
      "Ep 93: Batch #8 - Loss: 0.5794199705123901\n",
      "Ep 93: Batch #9 - Loss: 1.0830594301223755\n",
      "Ep 93: Batch #10 - Loss: 0.7814688682556152\n",
      "Ep 93: Batch #11 - Loss: 0.541207492351532\n",
      "Ep 93: Batch #12 - Loss: 1.1664360761642456\n",
      "Ep 93: Batch #13 - Loss: 0.5680516958236694\n",
      "Ep 93: Batch #14 - Loss: 0.5986403822898865\n",
      "Ep 93: Batch #15 - Loss: 0.838428258895874\n",
      "Ep 93: Batch #16 - Loss: 0.9487736821174622\n",
      "Ep 93: Batch #17 - Loss: 0.7266828417778015\n",
      "Ep 93: Batch #18 - Loss: 0.8073090314865112\n",
      "Ep 93: Batch #19 - Loss: 0.5630649328231812\n",
      "Ep 93: Batch #20 - Loss: 0.5449433922767639\n",
      "Ep 93: Batch #21 - Loss: 0.7851283550262451\n",
      "Ep 93: Batch #22 - Loss: 0.6024249196052551\n",
      "Ep 93: Batch #23 - Loss: 0.5984115600585938\n",
      "Ep 93: Batch #24 - Loss: 0.6407546997070312\n",
      "Ep 93: Batch #25 - Loss: 0.6018406748771667\n",
      "Ep 93: Batch #26 - Loss: 0.5536717176437378\n",
      "Ep 93: Batch #27 - Loss: 1.1187397241592407\n",
      "Ep 93: Batch #28 - Loss: 0.6911807656288147\n",
      "Ep 93: Batch #29 - Loss: 0.7460167407989502\n",
      "Ep 93: Batch #30 - Loss: 0.8126198053359985\n",
      "Ep 93: Batch #31 - Loss: 0.5589606165885925\n",
      "Ep 93: Batch #32 - Loss: 0.5744271874427795\n",
      "Ep 93: Batch #33 - Loss: 0.6598386168479919\n",
      "Ep 93: Batch #34 - Loss: 0.6308063268661499\n",
      "Ep 93: Batch #35 - Loss: 0.7231817245483398\n",
      "Ep 93: Batch #36 - Loss: 0.5768962502479553\n",
      "Ep 93: Batch #37 - Loss: 0.9194918870925903\n",
      "Ep 93: Batch #38 - Loss: 0.5640072822570801\n",
      "Ep 93: Batch #39 - Loss: 0.6825747489929199\n",
      "Ep 93: Batch #40 - Loss: 0.6053979992866516\n",
      "Ep 93: Batch #41 - Loss: 0.614885687828064\n",
      "Ep 93: Batch #42 - Loss: 0.5676764249801636\n",
      "Ep 93: Batch #43 - Loss: 0.6290209293365479\n",
      "Ep 93: Batch #44 - Loss: 0.6077817678451538\n",
      "Ep 93: Batch #45 - Loss: 0.5232589840888977\n",
      "Ep 93: Batch #46 - Loss: 0.6931917071342468\n",
      "Ep 93: Batch #47 - Loss: 0.7866265177726746\n",
      "Ep 93: Batch #48 - Loss: 1.0314271450042725\n",
      "Ep 93: Batch #49 - Loss: 0.804218590259552\n",
      "Ep 93: Batch #50 - Loss: 0.5685643553733826\n",
      "Ep 93: Batch #51 - Loss: 0.803856611251831\n",
      "Ep 93: Batch #52 - Loss: 0.6628143787384033\n",
      "Ep 93: Batch #53 - Loss: 0.7040824890136719\n",
      "Ep 93: Batch #54 - Loss: 0.5723398923873901\n",
      "Ep 93: Batch #55 - Loss: 0.6020277142524719\n",
      "Ep 93: Batch #56 - Loss: 0.8467291593551636\n",
      "Ep 93: Batch #57 - Loss: 0.67670738697052\n",
      "Ep 93: Batch #58 - Loss: 0.8175582885742188\n",
      "Ep 93: Batch #59 - Loss: 0.5570203065872192\n",
      "Ep 93: Batch #60 - Loss: 0.98264080286026\n",
      "Ep 93: Batch #61 - Loss: 0.5349034667015076\n",
      "Ep 93: Batch #62 - Loss: 0.5749044418334961\n",
      "Ep 93: Batch #63 - Loss: 0.7722266912460327\n",
      "Ep 93: Batch #64 - Loss: 7.835037708282471\n",
      "Ep 93: Batch #65 - Loss: 0.5192022919654846\n",
      "Ep 93: Batch #66 - Loss: 0.658598005771637\n",
      "Ep 93: Batch #67 - Loss: 0.7743606567382812\n",
      "Ep 93: Batch #68 - Loss: 0.7043113708496094\n",
      "Ep 93: Batch #69 - Loss: 0.5880461931228638\n",
      "Ep 93: Batch #70 - Loss: 0.6122222542762756\n",
      "Ep 93: Batch #71 - Loss: 0.5368525385856628\n",
      "Ep 93: Batch #72 - Loss: 0.6626282334327698\n",
      "Ep 93: Batch #73 - Loss: 0.7112742066383362\n",
      "Ep 93: Batch #74 - Loss: 0.5728957056999207\n",
      "Ep 93: Batch #75 - Loss: 0.6636815667152405\n",
      "Ep 93: Batch #76 - Loss: 0.9156596660614014\n",
      "Ep 93: Batch #77 - Loss: 0.5662944316864014\n",
      "Ep 93: Batch #78 - Loss: 0.8904941082000732\n",
      "Ep 93: Batch #79 - Loss: 0.5215139985084534\n",
      "Ep 93: Batch #80 - Loss: 0.6796435713768005\n",
      "Ep 93: Batch #81 - Loss: 1.520930290222168\n",
      "Ep 93: Batch #82 - Loss: 0.7418586015701294\n",
      "Ep 93: Batch #83 - Loss: 1.179404854774475\n",
      "Ep 93: Batch #84 - Loss: 0.5748186707496643\n",
      "Ep 93: Batch #85 - Loss: 0.7757565379142761\n",
      "Ep 93: Batch #86 - Loss: 0.5437020659446716\n",
      "Ep 93: Batch #87 - Loss: 0.5686619281768799\n",
      "Ep 93: Batch #88 - Loss: 0.6515862345695496\n",
      "Ep 93: Batch #89 - Loss: 0.7247509956359863\n",
      "Ep 93: Batch #90 - Loss: 0.9048631191253662\n",
      "Ep 93: Batch #91 - Loss: 0.6398295164108276\n",
      "Ep 93: Batch #92 - Loss: 0.7314728498458862\n",
      "Ep 93: Batch #93 - Loss: 0.7637876272201538\n",
      "Ep 93: Batch #94 - Loss: 0.7397909760475159\n",
      "Ep 93: Batch #95 - Loss: 0.758560061454773\n",
      "Ep 93: Batch #96 - Loss: 0.7480111122131348\n",
      "Ep 93: Batch #97 - Loss: 0.5869826078414917\n",
      "Ep 93: Batch #98 - Loss: 0.5759323835372925\n",
      "Ep 93: Batch #99 - Loss: 0.79058837890625\n",
      "Ep 93: Batch #100 - Loss: 0.555068850517273\n",
      "Ep 93: Batch #101 - Loss: 0.8714759349822998\n",
      "Ep 93: Batch #102 - Loss: 0.606406033039093\n",
      "Ep 93: Batch #103 - Loss: 0.6295292973518372\n",
      "Ep 93: Batch #104 - Loss: 0.6560083627700806\n",
      "Ep 93: Batch #105 - Loss: 0.8222291469573975\n",
      "Ep 93: Batch #106 - Loss: 0.6255359649658203\n",
      "Ep 93: Batch #107 - Loss: 0.6130625605583191\n",
      "Ep 93: Batch #108 - Loss: 0.8997376561164856\n",
      "Ep 93: Batch #109 - Loss: 0.6183618307113647\n",
      "Ep 93: Batch #110 - Loss: 0.7194047570228577\n",
      "Ep 93: Batch #111 - Loss: 1.027930498123169\n",
      "Ep 93: Batch #112 - Loss: 0.7912804484367371\n",
      "Ep 93: Batch #113 - Loss: 0.6563770771026611\n",
      "Ep 93: Batch #114 - Loss: 0.7162638902664185\n",
      "Ep 93: Batch #115 - Loss: 0.9059160947799683\n",
      "Ep 93: Batch #116 - Loss: 0.5204806923866272\n",
      "Ep 93: Batch #117 - Loss: 0.6767382621765137\n",
      "Ep 93: Batch #118 - Loss: 0.4525347650051117\n",
      "Model saved in file: ./weights_autoencoder_sigmoid/model_e93b118_1516648803.9023302.ckpt\n",
      "Ep 93: Batch #119 - Loss: 0.798869252204895\n",
      "Ep 93: Batch #120 - Loss: 0.6519962549209595\n",
      "Ep 93: Batch #121 - Loss: 0.5613219141960144\n",
      "Ep 93: Batch #122 - Loss: 0.694612979888916\n",
      "Ep 93: Batch #123 - Loss: 0.7040302157402039\n",
      "Ep 93: Batch #124 - Loss: 0.5521830320358276\n",
      "Ep 93: Batch #125 - Loss: 2.4722630977630615\n",
      "Ep 93: Batch #126 - Loss: 1.0066062211990356\n",
      "Ep 93: Batch #127 - Loss: 0.5785708427429199\n",
      "Ep 93: Batch #128 - Loss: 0.8764508366584778\n",
      "Ep 93: Batch #129 - Loss: 0.6733381152153015\n",
      "Ep 93: Batch #130 - Loss: 0.5973220467567444\n",
      "Ep 93: Batch #131 - Loss: 0.7885055541992188\n",
      "Ep 93: Batch #132 - Loss: 0.6826689839363098\n",
      "Ep 93: Batch #133 - Loss: 0.659705638885498\n",
      "Ep 93: Batch #134 - Loss: 0.6351028084754944\n",
      "Ep 93: Batch #135 - Loss: 0.81699138879776\n",
      "Ep 93: Batch #136 - Loss: 1.037960410118103\n",
      "Ep 93: Batch #137 - Loss: 0.7490435242652893\n",
      "Ep 93: Batch #138 - Loss: 0.8947405219078064\n",
      "Ep 93: Batch #139 - Loss: 0.6694512367248535\n",
      "Ep 93: Batch #140 - Loss: 0.8392981886863708\n",
      "Ep 93: Batch #141 - Loss: 1.1012763977050781\n",
      "Ep 93: Batch #142 - Loss: 0.6662300229072571\n",
      "Ep 93: Batch #143 - Loss: 0.7611293196678162\n",
      "Ep 93: Batch #144 - Loss: 0.6060932874679565\n",
      "Ep 93: Batch #145 - Loss: 0.5965871810913086\n",
      "Ep 93: Batch #146 - Loss: 0.6930617094039917\n",
      "Ep 93: Batch #147 - Loss: 0.6585533618927002\n",
      "Ep 93: Batch #148 - Loss: 0.7519476413726807\n",
      "Ep 93: Batch #149 - Loss: 0.6088734865188599\n",
      "Ep 93: Batch #150 - Loss: 0.7208558320999146\n",
      "Ep 93: Batch #151 - Loss: 0.6218758821487427\n",
      "Ep 93: Batch #152 - Loss: 0.6083123683929443\n",
      "Ep 93: Batch #153 - Loss: 0.8167058229446411\n",
      "Ep 93: Batch #154 - Loss: 0.6327589750289917\n",
      "Ep 93: Batch #155 - Loss: 0.6828280687332153\n",
      "Ep 93: Batch #156 - Loss: 0.7646303176879883\n",
      "Ep 93: Batch #157 - Loss: 0.6085003614425659\n",
      "Ep 93: Batch #158 - Loss: 0.7169954180717468\n",
      "Ep 93: Batch #159 - Loss: 0.5932214260101318\n",
      "Ep 93: Batch #160 - Loss: 0.6892800331115723\n",
      "Ep 93: Batch #161 - Loss: 0.6677119135856628\n",
      "Ep 93: Batch #162 - Loss: 0.7218899130821228\n",
      "Ep 93: Batch #163 - Loss: 0.7532141804695129\n",
      "Ep 93: Batch #164 - Loss: 0.6406692862510681\n",
      "Ep 93: Batch #165 - Loss: 1.3345961570739746\n",
      "Ep 93: Batch #166 - Loss: 0.5288339257240295\n",
      "Ep 93: Batch #167 - Loss: 0.6960616111755371\n",
      "Ep 93: Batch #168 - Loss: 0.6886513829231262\n",
      "Ep 93: Batch #169 - Loss: 0.6665158271789551\n",
      "Ep 93: Batch #170 - Loss: 0.6286377906799316\n",
      "Ep 93: Batch #171 - Loss: 0.637964129447937\n",
      "Ep 93: Batch #172 - Loss: 0.5333026647567749\n",
      "Ep 93: Batch #173 - Loss: 0.9212536215782166\n",
      "Ep 93: Batch #174 - Loss: 0.4931449890136719\n",
      "Ep 93: Batch #175 - Loss: 0.6350255608558655\n",
      "Ep 93: Batch #176 - Loss: 0.8927700519561768\n",
      "Ep 93: Batch #177 - Loss: 0.6453274488449097\n",
      "Ep 93: Batch #178 - Loss: 0.6162652969360352\n",
      "Ep 93: Batch #179 - Loss: 0.7483144998550415\n",
      "Ep 93: Batch #180 - Loss: 0.6444186568260193\n",
      "Ep 93: Batch #181 - Loss: 0.7834767699241638\n",
      "Ep 93: Batch #182 - Loss: 0.6276064515113831\n",
      "Ep 93: Batch #183 - Loss: 0.601695716381073\n",
      "Ep 93: Batch #184 - Loss: 0.8993099331855774\n",
      "Ep 93: Batch #185 - Loss: 0.6318114995956421\n",
      "Ep 93: Batch #186 - Loss: 0.7389105558395386\n",
      "Ep 93: Batch #187 - Loss: 0.8540070652961731\n",
      "Ep 93: Batch #188 - Loss: 0.9174094200134277\n",
      "Ep 93: Batch #189 - Loss: 0.5866941809654236\n",
      "Ep 93: Batch #190 - Loss: 0.6159973740577698\n",
      "Ep 93: Batch #191 - Loss: 0.7869510650634766\n",
      "Ep 93: Batch #192 - Loss: 0.5720920562744141\n",
      "Ep 93: Batch #193 - Loss: 0.6255260705947876\n",
      "Ep 93: Batch #194 - Loss: 0.5394598841667175\n",
      "Ep 93: Batch #195 - Loss: 0.775646448135376\n",
      "Ep 93: Batch #196 - Loss: 0.6874971389770508\n",
      "Ep 93: Batch #197 - Loss: 0.691669762134552\n",
      "Ep 93: Batch #198 - Loss: 0.5348609089851379\n",
      "Ep 93: Batch #199 - Loss: 0.6415416598320007\n",
      "Ep 94: Batch #0 - Loss: 0.6495559811592102\n",
      "Ep 94: Batch #1 - Loss: 0.7192442417144775\n",
      "Ep 94: Batch #2 - Loss: 0.8599762320518494\n",
      "Ep 94: Batch #3 - Loss: 0.7194507718086243\n",
      "Ep 94: Batch #4 - Loss: 0.6545966267585754\n",
      "Ep 94: Batch #5 - Loss: 0.5482254028320312\n",
      "Ep 94: Batch #6 - Loss: 0.7255376577377319\n",
      "Ep 94: Batch #7 - Loss: 0.5758310556411743\n",
      "Ep 94: Batch #8 - Loss: 0.5792351365089417\n",
      "Ep 94: Batch #9 - Loss: 1.0829977989196777\n",
      "Ep 94: Batch #10 - Loss: 0.7807201147079468\n",
      "Ep 94: Batch #11 - Loss: 0.5409837961196899\n",
      "Ep 94: Batch #12 - Loss: 1.164872169494629\n",
      "Ep 94: Batch #13 - Loss: 0.5672024488449097\n",
      "Ep 94: Batch #14 - Loss: 0.5986213684082031\n",
      "Ep 94: Batch #15 - Loss: 0.8388336300849915\n",
      "Ep 94: Batch #16 - Loss: 0.9478210210800171\n",
      "Ep 94: Batch #17 - Loss: 0.7265194058418274\n",
      "Ep 94: Batch #18 - Loss: 0.8074464201927185\n",
      "Ep 94: Batch #19 - Loss: 0.5631022453308105\n",
      "Ep 94: Batch #20 - Loss: 0.544895589351654\n",
      "Ep 94: Batch #21 - Loss: 0.7843704223632812\n",
      "Ep 94: Batch #22 - Loss: 0.6021867990493774\n",
      "Ep 94: Batch #23 - Loss: 0.5982346534729004\n",
      "Ep 94: Batch #24 - Loss: 0.6409274935722351\n",
      "Ep 94: Batch #25 - Loss: 0.6014995574951172\n",
      "Ep 94: Batch #26 - Loss: 0.5541816353797913\n",
      "Ep 94: Batch #27 - Loss: 1.1174980401992798\n",
      "Ep 94: Batch #28 - Loss: 0.6918193101882935\n",
      "Ep 94: Batch #29 - Loss: 0.7460057735443115\n",
      "Ep 94: Batch #30 - Loss: 0.8122232556343079\n",
      "Ep 94: Batch #31 - Loss: 0.5589092373847961\n",
      "Ep 94: Batch #32 - Loss: 0.5743508338928223\n",
      "Ep 94: Batch #33 - Loss: 0.659623384475708\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 94: Batch #34 - Loss: 0.6303978562355042\n",
      "Ep 94: Batch #35 - Loss: 0.723205029964447\n",
      "Ep 94: Batch #36 - Loss: 0.5767064690589905\n",
      "Ep 94: Batch #37 - Loss: 0.9197816848754883\n",
      "Ep 94: Batch #38 - Loss: 0.5637546181678772\n",
      "Ep 94: Batch #39 - Loss: 0.6821078658103943\n",
      "Ep 94: Batch #40 - Loss: 0.6053066849708557\n",
      "Ep 94: Batch #41 - Loss: 0.6148622035980225\n",
      "Ep 94: Batch #42 - Loss: 0.5675817131996155\n",
      "Ep 94: Batch #43 - Loss: 0.6288548111915588\n",
      "Ep 94: Batch #44 - Loss: 0.6076104044914246\n",
      "Ep 94: Batch #45 - Loss: 0.5234460234642029\n",
      "Ep 94: Batch #46 - Loss: 0.6930427551269531\n",
      "Ep 94: Batch #47 - Loss: 0.7857487797737122\n",
      "Ep 94: Batch #48 - Loss: 1.0303832292556763\n",
      "Ep 94: Batch #49 - Loss: 0.8043316602706909\n",
      "Ep 94: Batch #50 - Loss: 0.5684027075767517\n",
      "Ep 94: Batch #51 - Loss: 0.8035457730293274\n",
      "Ep 94: Batch #52 - Loss: 0.6622979640960693\n",
      "Ep 94: Batch #53 - Loss: 0.7032777070999146\n",
      "Ep 94: Batch #54 - Loss: 0.5719099640846252\n",
      "Ep 94: Batch #55 - Loss: 0.601883053779602\n",
      "Ep 94: Batch #56 - Loss: 0.8464915156364441\n",
      "Ep 94: Batch #57 - Loss: 0.6765878796577454\n",
      "Ep 94: Batch #58 - Loss: 0.8173300623893738\n",
      "Ep 94: Batch #59 - Loss: 0.5568932890892029\n",
      "Ep 94: Batch #60 - Loss: 0.981995165348053\n",
      "Ep 94: Batch #61 - Loss: 0.5349346995353699\n",
      "Ep 94: Batch #62 - Loss: 0.5750960111618042\n",
      "Ep 94: Batch #63 - Loss: 0.7720084190368652\n",
      "Ep 94: Batch #64 - Loss: 7.819519996643066\n",
      "Ep 94: Batch #65 - Loss: 0.5189719200134277\n",
      "Ep 94: Batch #66 - Loss: 0.6583518385887146\n",
      "Ep 94: Batch #67 - Loss: 0.7741502523422241\n",
      "Ep 94: Batch #68 - Loss: 0.7036755084991455\n",
      "Ep 94: Batch #69 - Loss: 0.5877241492271423\n",
      "Ep 94: Batch #70 - Loss: 0.6122409105300903\n",
      "Ep 94: Batch #71 - Loss: 0.5369709134101868\n",
      "Ep 94: Batch #72 - Loss: 0.6624132394790649\n",
      "Ep 94: Batch #73 - Loss: 0.7107788920402527\n",
      "Ep 94: Batch #74 - Loss: 0.5727781057357788\n",
      "Ep 94: Batch #75 - Loss: 0.66363924741745\n",
      "Ep 94: Batch #76 - Loss: 0.9151228070259094\n",
      "Ep 94: Batch #77 - Loss: 0.56583172082901\n",
      "Ep 94: Batch #78 - Loss: 0.8890476822853088\n",
      "Ep 94: Batch #79 - Loss: 0.521532416343689\n",
      "Ep 94: Batch #80 - Loss: 0.679323673248291\n",
      "Ep 94: Batch #81 - Loss: 1.5193791389465332\n",
      "Ep 94: Batch #82 - Loss: 0.7410973906517029\n",
      "Ep 94: Batch #83 - Loss: 1.1765841245651245\n",
      "Ep 94: Batch #84 - Loss: 0.574863612651825\n",
      "Ep 94: Batch #85 - Loss: 0.7762205600738525\n",
      "Ep 94: Batch #86 - Loss: 0.5435646772384644\n",
      "Ep 94: Batch #87 - Loss: 0.5685664415359497\n",
      "Ep 94: Batch #88 - Loss: 0.6513890027999878\n",
      "Ep 94: Batch #89 - Loss: 0.7236105799674988\n",
      "Ep 94: Batch #90 - Loss: 0.905439555644989\n",
      "Ep 94: Batch #91 - Loss: 0.6398629546165466\n",
      "Ep 94: Batch #92 - Loss: 0.7314475178718567\n",
      "Ep 94: Batch #93 - Loss: 0.763171911239624\n",
      "Ep 94: Batch #94 - Loss: 0.7383846044540405\n",
      "Ep 94: Batch #95 - Loss: 0.7583305239677429\n",
      "Ep 94: Batch #96 - Loss: 0.7465606927871704\n",
      "Ep 94: Batch #97 - Loss: 0.5880979299545288\n",
      "Ep 94: Batch #98 - Loss: 0.5766925811767578\n",
      "Ep 94: Batch #99 - Loss: 0.7899314761161804\n",
      "Ep 94: Batch #100 - Loss: 0.5547658801078796\n",
      "Ep 94: Batch #101 - Loss: 0.8719024062156677\n",
      "Ep 94: Batch #102 - Loss: 0.6059421300888062\n",
      "Ep 94: Batch #103 - Loss: 0.6291604042053223\n",
      "Ep 94: Batch #104 - Loss: 0.6561700701713562\n",
      "Ep 94: Batch #105 - Loss: 0.8237143754959106\n",
      "Ep 94: Batch #106 - Loss: 0.6252232193946838\n",
      "Ep 94: Batch #107 - Loss: 0.6126571297645569\n",
      "Ep 94: Batch #108 - Loss: 0.9005879759788513\n",
      "Ep 94: Batch #109 - Loss: 0.617917001247406\n",
      "Ep 94: Batch #110 - Loss: 0.7188193202018738\n",
      "Ep 94: Batch #111 - Loss: 1.0306100845336914\n",
      "Ep 94: Batch #112 - Loss: 0.7910261750221252\n",
      "Ep 94: Batch #113 - Loss: 0.6561307311058044\n",
      "Ep 94: Batch #114 - Loss: 0.7156009078025818\n",
      "Ep 94: Batch #115 - Loss: 0.9063051342964172\n",
      "Ep 94: Batch #116 - Loss: 0.5205843448638916\n",
      "Ep 94: Batch #117 - Loss: 0.6769184470176697\n",
      "Ep 94: Batch #118 - Loss: 0.452492356300354\n",
      "Model saved in file: ./weights_autoencoder_sigmoid/model_e94b118_1516648804.0388043.ckpt\n",
      "Ep 94: Batch #119 - Loss: 0.7988742589950562\n",
      "Ep 94: Batch #120 - Loss: 0.6530190706253052\n",
      "Ep 94: Batch #121 - Loss: 0.5612368583679199\n",
      "Ep 94: Batch #122 - Loss: 0.6943844556808472\n",
      "Ep 94: Batch #123 - Loss: 0.703544557094574\n",
      "Ep 94: Batch #124 - Loss: 0.5517732501029968\n",
      "Ep 94: Batch #125 - Loss: 2.469871997833252\n",
      "Ep 94: Batch #126 - Loss: 1.0070984363555908\n",
      "Ep 94: Batch #127 - Loss: 0.5783942341804504\n",
      "Ep 94: Batch #128 - Loss: 0.875732421875\n",
      "Ep 94: Batch #129 - Loss: 0.6733406186103821\n",
      "Ep 94: Batch #130 - Loss: 0.5971235036849976\n",
      "Ep 94: Batch #131 - Loss: 0.7880430221557617\n",
      "Ep 94: Batch #132 - Loss: 0.6829584240913391\n",
      "Ep 94: Batch #133 - Loss: 0.6590403318405151\n",
      "Ep 94: Batch #134 - Loss: 0.6348011493682861\n",
      "Ep 94: Batch #135 - Loss: 0.8164390325546265\n",
      "Ep 94: Batch #136 - Loss: 1.0375947952270508\n",
      "Ep 94: Batch #137 - Loss: 0.7477676272392273\n",
      "Ep 94: Batch #138 - Loss: 0.8947158455848694\n",
      "Ep 94: Batch #139 - Loss: 0.6695774793624878\n",
      "Ep 94: Batch #140 - Loss: 0.8389821648597717\n",
      "Ep 94: Batch #141 - Loss: 1.1000789403915405\n",
      "Ep 94: Batch #142 - Loss: 0.6659408211708069\n",
      "Ep 94: Batch #143 - Loss: 0.7604767680168152\n",
      "Ep 94: Batch #144 - Loss: 0.6062861084938049\n",
      "Ep 94: Batch #145 - Loss: 0.5967588424682617\n",
      "Ep 94: Batch #146 - Loss: 0.6924517750740051\n",
      "Ep 94: Batch #147 - Loss: 0.6586770415306091\n",
      "Ep 94: Batch #148 - Loss: 0.7519963383674622\n",
      "Ep 94: Batch #149 - Loss: 0.6082040667533875\n",
      "Ep 94: Batch #150 - Loss: 0.7209697961807251\n",
      "Ep 94: Batch #151 - Loss: 0.6214503645896912\n",
      "Ep 94: Batch #152 - Loss: 0.6084322333335876\n",
      "Ep 94: Batch #153 - Loss: 0.8156941533088684\n",
      "Ep 94: Batch #154 - Loss: 0.6313687562942505\n",
      "Ep 94: Batch #155 - Loss: 0.6823785305023193\n",
      "Ep 94: Batch #156 - Loss: 0.7643025517463684\n",
      "Ep 94: Batch #157 - Loss: 0.6086717844009399\n",
      "Ep 94: Batch #158 - Loss: 0.7166250348091125\n",
      "Ep 94: Batch #159 - Loss: 0.5936320424079895\n",
      "Ep 94: Batch #160 - Loss: 0.689569354057312\n",
      "Ep 94: Batch #161 - Loss: 0.6677736639976501\n",
      "Ep 94: Batch #162 - Loss: 0.7221081852912903\n",
      "Ep 94: Batch #163 - Loss: 0.7528914213180542\n",
      "Ep 94: Batch #164 - Loss: 0.6403984427452087\n",
      "Ep 94: Batch #165 - Loss: 1.333045482635498\n",
      "Ep 94: Batch #166 - Loss: 0.5287472605705261\n",
      "Ep 94: Batch #167 - Loss: 0.6960080862045288\n",
      "Ep 94: Batch #168 - Loss: 0.6879927515983582\n",
      "Ep 94: Batch #169 - Loss: 0.6666535139083862\n",
      "Ep 94: Batch #170 - Loss: 0.6285279393196106\n",
      "Ep 94: Batch #171 - Loss: 0.6379966735839844\n",
      "Ep 94: Batch #172 - Loss: 0.5330308079719543\n",
      "Ep 94: Batch #173 - Loss: 0.9210112690925598\n",
      "Ep 94: Batch #174 - Loss: 0.4929388761520386\n",
      "Ep 94: Batch #175 - Loss: 0.6344260573387146\n",
      "Ep 94: Batch #176 - Loss: 0.8928107619285583\n",
      "Ep 94: Batch #177 - Loss: 0.6452255249023438\n",
      "Ep 94: Batch #178 - Loss: 0.6157957911491394\n",
      "Ep 94: Batch #179 - Loss: 0.7476614713668823\n",
      "Ep 94: Batch #180 - Loss: 0.6441687345504761\n",
      "Ep 94: Batch #181 - Loss: 0.7818778157234192\n",
      "Ep 94: Batch #182 - Loss: 0.6279352903366089\n",
      "Ep 94: Batch #183 - Loss: 0.6016623973846436\n",
      "Ep 94: Batch #184 - Loss: 0.8985757827758789\n",
      "Ep 94: Batch #185 - Loss: 0.6311420202255249\n",
      "Ep 94: Batch #186 - Loss: 0.7375500202178955\n",
      "Ep 94: Batch #187 - Loss: 0.8534442186355591\n",
      "Ep 94: Batch #188 - Loss: 0.9168173670768738\n",
      "Ep 94: Batch #189 - Loss: 0.5862478017807007\n",
      "Ep 94: Batch #190 - Loss: 0.615283727645874\n",
      "Ep 94: Batch #191 - Loss: 0.7868390679359436\n",
      "Ep 94: Batch #192 - Loss: 0.5717814564704895\n",
      "Ep 94: Batch #193 - Loss: 0.625325620174408\n",
      "Ep 94: Batch #194 - Loss: 0.5393205881118774\n",
      "Ep 94: Batch #195 - Loss: 0.7752736210823059\n",
      "Ep 94: Batch #196 - Loss: 0.6873173117637634\n",
      "Ep 94: Batch #197 - Loss: 0.6915679574012756\n",
      "Ep 94: Batch #198 - Loss: 0.5352043509483337\n",
      "Ep 94: Batch #199 - Loss: 0.6413915157318115\n",
      "Ep 95: Batch #0 - Loss: 0.6492511034011841\n",
      "Ep 95: Batch #1 - Loss: 0.7190552353858948\n",
      "Ep 95: Batch #2 - Loss: 0.859920859336853\n",
      "Ep 95: Batch #3 - Loss: 0.7194898128509521\n",
      "Ep 95: Batch #4 - Loss: 0.6545332074165344\n",
      "Ep 95: Batch #5 - Loss: 0.5480859875679016\n",
      "Ep 95: Batch #6 - Loss: 0.7249833941459656\n",
      "Ep 95: Batch #7 - Loss: 0.5759258270263672\n",
      "Ep 95: Batch #8 - Loss: 0.5789559483528137\n",
      "Ep 95: Batch #9 - Loss: 1.0825940370559692\n",
      "Ep 95: Batch #10 - Loss: 0.7805742621421814\n",
      "Ep 95: Batch #11 - Loss: 0.5406920909881592\n",
      "Ep 95: Batch #12 - Loss: 1.1629761457443237\n",
      "Ep 95: Batch #13 - Loss: 0.5664812922477722\n",
      "Ep 95: Batch #14 - Loss: 0.5987105965614319\n",
      "Ep 95: Batch #15 - Loss: 0.8391338586807251\n",
      "Ep 95: Batch #16 - Loss: 0.9479073286056519\n",
      "Ep 95: Batch #17 - Loss: 0.7263134717941284\n",
      "Ep 95: Batch #18 - Loss: 0.8073516488075256\n",
      "Ep 95: Batch #19 - Loss: 0.5630714297294617\n",
      "Ep 95: Batch #20 - Loss: 0.5447708368301392\n",
      "Ep 95: Batch #21 - Loss: 0.7839418649673462\n",
      "Ep 95: Batch #22 - Loss: 0.6021423935890198\n",
      "Ep 95: Batch #23 - Loss: 0.5982546806335449\n",
      "Ep 95: Batch #24 - Loss: 0.6413338780403137\n",
      "Ep 95: Batch #25 - Loss: 0.6014195680618286\n",
      "Ep 95: Batch #26 - Loss: 0.5540462732315063\n",
      "Ep 95: Batch #27 - Loss: 1.1163289546966553\n",
      "Ep 95: Batch #28 - Loss: 0.6919634938240051\n",
      "Ep 95: Batch #29 - Loss: 0.7459007501602173\n",
      "Ep 95: Batch #30 - Loss: 0.8131914734840393\n",
      "Ep 95: Batch #31 - Loss: 0.5588335990905762\n",
      "Ep 95: Batch #32 - Loss: 0.5741537809371948\n",
      "Ep 95: Batch #33 - Loss: 0.6596425175666809\n",
      "Ep 95: Batch #34 - Loss: 0.6302039623260498\n",
      "Ep 95: Batch #35 - Loss: 0.7232325077056885\n",
      "Ep 95: Batch #36 - Loss: 0.5763405561447144\n",
      "Ep 95: Batch #37 - Loss: 0.9197176694869995\n",
      "Ep 95: Batch #38 - Loss: 0.5637499690055847\n",
      "Ep 95: Batch #39 - Loss: 0.6822276711463928\n",
      "Ep 95: Batch #40 - Loss: 0.6053596138954163\n",
      "Ep 95: Batch #41 - Loss: 0.6149004697799683\n",
      "Ep 95: Batch #42 - Loss: 0.5677490830421448\n",
      "Ep 95: Batch #43 - Loss: 0.6289793848991394\n",
      "Ep 95: Batch #44 - Loss: 0.6076039671897888\n",
      "Ep 95: Batch #45 - Loss: 0.5233067870140076\n",
      "Ep 95: Batch #46 - Loss: 0.6930559873580933\n",
      "Ep 95: Batch #47 - Loss: 0.7851282358169556\n",
      "Ep 95: Batch #48 - Loss: 1.0304399728775024\n",
      "Ep 95: Batch #49 - Loss: 0.8045126795768738\n",
      "Ep 95: Batch #50 - Loss: 0.5683029890060425\n",
      "Ep 95: Batch #51 - Loss: 0.8034173250198364\n",
      "Ep 95: Batch #52 - Loss: 0.6618108749389648\n",
      "Ep 95: Batch #53 - Loss: 0.7030519843101501\n",
      "Ep 95: Batch #54 - Loss: 0.571813702583313\n",
      "Ep 95: Batch #55 - Loss: 0.6019155979156494\n",
      "Ep 95: Batch #56 - Loss: 0.846506655216217\n",
      "Ep 95: Batch #57 - Loss: 0.6767053604125977\n",
      "Ep 95: Batch #58 - Loss: 0.8172531127929688\n",
      "Ep 95: Batch #59 - Loss: 0.5570369958877563\n",
      "Ep 95: Batch #60 - Loss: 0.9814281463623047\n",
      "Ep 95: Batch #61 - Loss: 0.5350146889686584\n",
      "Ep 95: Batch #62 - Loss: 0.575242817401886\n",
      "Ep 95: Batch #63 - Loss: 0.7720180749893188\n",
      "Ep 95: Batch #64 - Loss: 7.804609298706055\n",
      "Ep 95: Batch #65 - Loss: 0.5188124775886536\n",
      "Ep 95: Batch #66 - Loss: 0.6584864258766174\n",
      "Ep 95: Batch #67 - Loss: 0.774228036403656\n",
      "Ep 95: Batch #68 - Loss: 0.7036046385765076\n",
      "Ep 95: Batch #69 - Loss: 0.5876341462135315\n",
      "Ep 95: Batch #70 - Loss: 0.6125655770301819\n",
      "Ep 95: Batch #71 - Loss: 0.537040650844574\n",
      "Ep 95: Batch #72 - Loss: 0.6625207662582397\n",
      "Ep 95: Batch #73 - Loss: 0.7106919288635254\n",
      "Ep 95: Batch #74 - Loss: 0.5727862119674683\n",
      "Ep 95: Batch #75 - Loss: 0.6635387539863586\n",
      "Ep 95: Batch #76 - Loss: 0.9149342179298401\n",
      "Ep 95: Batch #77 - Loss: 0.5657565593719482\n",
      "Ep 95: Batch #78 - Loss: 0.888655960559845\n",
      "Ep 95: Batch #79 - Loss: 0.5215955972671509\n",
      "Ep 95: Batch #80 - Loss: 0.6788955926895142\n",
      "Ep 95: Batch #81 - Loss: 1.5239050388336182\n",
      "Ep 95: Batch #82 - Loss: 0.7410439252853394\n",
      "Ep 95: Batch #83 - Loss: 1.1755964756011963\n",
      "Ep 95: Batch #84 - Loss: 0.5748740434646606\n",
      "Ep 95: Batch #85 - Loss: 0.7753716707229614\n",
      "Ep 95: Batch #86 - Loss: 0.5436018109321594\n",
      "Ep 95: Batch #87 - Loss: 0.5684850811958313\n",
      "Ep 95: Batch #88 - Loss: 0.651953935623169\n",
      "Ep 95: Batch #89 - Loss: 0.7249167561531067\n",
      "Ep 95: Batch #90 - Loss: 0.9056010842323303\n",
      "Ep 95: Batch #91 - Loss: 0.639509379863739\n",
      "Ep 95: Batch #92 - Loss: 0.7318311929702759\n",
      "Ep 95: Batch #93 - Loss: 0.7631440758705139\n",
      "Ep 95: Batch #94 - Loss: 0.739589512348175\n",
      "Ep 95: Batch #95 - Loss: 0.7586413025856018\n",
      "Ep 95: Batch #96 - Loss: 0.7478460669517517\n",
      "Ep 95: Batch #97 - Loss: 0.58758944272995\n",
      "Ep 95: Batch #98 - Loss: 0.5763385891914368\n",
      "Ep 95: Batch #99 - Loss: 0.7913711071014404\n",
      "Ep 95: Batch #100 - Loss: 0.5550826787948608\n",
      "Ep 95: Batch #101 - Loss: 0.8723585605621338\n",
      "Ep 95: Batch #102 - Loss: 0.6064360737800598\n",
      "Ep 95: Batch #103 - Loss: 0.6296809315681458\n",
      "Ep 95: Batch #104 - Loss: 0.6562679409980774\n",
      "Ep 95: Batch #105 - Loss: 0.8228825926780701\n",
      "Ep 95: Batch #106 - Loss: 0.6256029605865479\n",
      "Ep 95: Batch #107 - Loss: 0.6131493449211121\n",
      "Ep 95: Batch #108 - Loss: 0.900177538394928\n",
      "Ep 95: Batch #109 - Loss: 0.618126630783081\n",
      "Ep 95: Batch #110 - Loss: 0.7195871472358704\n",
      "Ep 95: Batch #111 - Loss: 1.0272995233535767\n",
      "Ep 95: Batch #112 - Loss: 0.7918745279312134\n",
      "Ep 95: Batch #113 - Loss: 0.6566342711448669\n",
      "Ep 95: Batch #114 - Loss: 0.7162504196166992\n",
      "Ep 95: Batch #115 - Loss: 0.9061484336853027\n",
      "Ep 95: Batch #116 - Loss: 0.5204406976699829\n",
      "Ep 95: Batch #117 - Loss: 0.6765018701553345\n",
      "Ep 95: Batch #118 - Loss: 0.45266738533973694\n",
      "Ep 95: Batch #119 - Loss: 0.7980934977531433\n",
      "Ep 95: Batch #120 - Loss: 0.6520208716392517\n",
      "Ep 95: Batch #121 - Loss: 0.5615475177764893\n",
      "Ep 95: Batch #122 - Loss: 0.6939911246299744\n",
      "Ep 95: Batch #123 - Loss: 0.7030267715454102\n",
      "Ep 95: Batch #124 - Loss: 0.5521003007888794\n",
      "Ep 95: Batch #125 - Loss: 2.4733662605285645\n",
      "Ep 95: Batch #126 - Loss: 1.0067988634109497\n",
      "Ep 95: Batch #127 - Loss: 0.578552782535553\n",
      "Ep 95: Batch #128 - Loss: 0.8764604330062866\n",
      "Ep 95: Batch #129 - Loss: 0.6737377047538757\n",
      "Ep 95: Batch #130 - Loss: 0.5973144769668579\n",
      "Ep 95: Batch #131 - Loss: 0.7880521416664124\n",
      "Ep 95: Batch #132 - Loss: 0.682767927646637\n",
      "Ep 95: Batch #133 - Loss: 0.6592702269554138\n",
      "Ep 95: Batch #134 - Loss: 0.6352669596672058\n",
      "Ep 95: Batch #135 - Loss: 0.8170756697654724\n",
      "Ep 95: Batch #136 - Loss: 1.037492275238037\n",
      "Ep 95: Batch #137 - Loss: 0.7489674687385559\n",
      "Ep 95: Batch #138 - Loss: 0.8944159746170044\n",
      "Ep 95: Batch #139 - Loss: 0.6697096824645996\n",
      "Ep 95: Batch #140 - Loss: 0.8393915891647339\n",
      "Ep 95: Batch #141 - Loss: 1.100479006767273\n",
      "Ep 95: Batch #142 - Loss: 0.666292667388916\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 95: Batch #143 - Loss: 0.7608352899551392\n",
      "Ep 95: Batch #144 - Loss: 0.606107234954834\n",
      "Ep 95: Batch #145 - Loss: 0.5966131687164307\n",
      "Ep 95: Batch #146 - Loss: 0.6926653981208801\n",
      "Ep 95: Batch #147 - Loss: 0.658409833908081\n",
      "Ep 95: Batch #148 - Loss: 0.7524592876434326\n",
      "Ep 95: Batch #149 - Loss: 0.6095789670944214\n",
      "Ep 95: Batch #150 - Loss: 0.7209845781326294\n",
      "Ep 95: Batch #151 - Loss: 0.6216659545898438\n",
      "Ep 95: Batch #152 - Loss: 0.6085344552993774\n",
      "Ep 95: Batch #153 - Loss: 0.816580057144165\n",
      "Ep 95: Batch #154 - Loss: 0.6332210302352905\n",
      "Ep 95: Batch #155 - Loss: 0.6824812293052673\n",
      "Ep 95: Batch #156 - Loss: 0.7641040682792664\n",
      "Ep 95: Batch #157 - Loss: 0.6087526679039001\n",
      "Ep 95: Batch #158 - Loss: 0.7167922258377075\n",
      "Ep 95: Batch #159 - Loss: 0.5937694311141968\n",
      "Ep 95: Batch #160 - Loss: 0.6893185973167419\n",
      "Ep 95: Batch #161 - Loss: 0.6679549813270569\n",
      "Ep 95: Batch #162 - Loss: 0.7227392792701721\n",
      "Ep 95: Batch #163 - Loss: 0.7529958486557007\n",
      "Ep 95: Batch #164 - Loss: 0.6407318115234375\n",
      "Ep 95: Batch #165 - Loss: 1.334904432296753\n",
      "Ep 95: Batch #166 - Loss: 0.5288416147232056\n",
      "Ep 95: Batch #167 - Loss: 0.6970131397247314\n",
      "Ep 95: Batch #168 - Loss: 0.6885468363761902\n",
      "Ep 95: Batch #169 - Loss: 0.6667723059654236\n",
      "Ep 95: Batch #170 - Loss: 0.6292911767959595\n",
      "Ep 95: Batch #171 - Loss: 0.6382032632827759\n",
      "Ep 95: Batch #172 - Loss: 0.5334893465042114\n",
      "Ep 95: Batch #173 - Loss: 0.9215413928031921\n",
      "Ep 95: Batch #174 - Loss: 0.4931494891643524\n",
      "Ep 95: Batch #175 - Loss: 0.6356132626533508\n",
      "Ep 95: Batch #176 - Loss: 0.8929399847984314\n",
      "Ep 95: Batch #177 - Loss: 0.6453335285186768\n",
      "Ep 95: Batch #178 - Loss: 0.6163409352302551\n",
      "Ep 95: Batch #179 - Loss: 0.7489351630210876\n",
      "Ep 95: Batch #180 - Loss: 0.6447117328643799\n",
      "Ep 95: Batch #181 - Loss: 0.782383918762207\n",
      "Ep 95: Batch #182 - Loss: 0.6279586553573608\n",
      "Ep 95: Batch #183 - Loss: 0.6017516851425171\n",
      "Ep 95: Batch #184 - Loss: 0.8983075022697449\n",
      "Ep 95: Batch #185 - Loss: 0.6321937441825867\n",
      "Ep 95: Batch #186 - Loss: 0.7389975786209106\n",
      "Ep 95: Batch #187 - Loss: 0.8531624674797058\n",
      "Ep 95: Batch #188 - Loss: 0.9165568351745605\n",
      "Ep 95: Batch #189 - Loss: 0.5870366096496582\n",
      "Ep 95: Batch #190 - Loss: 0.6156401634216309\n",
      "Ep 95: Batch #191 - Loss: 0.7860119938850403\n",
      "Ep 95: Batch #192 - Loss: 0.5721835494041443\n",
      "Ep 95: Batch #193 - Loss: 0.625385046005249\n",
      "Ep 95: Batch #194 - Loss: 0.5394279956817627\n",
      "Ep 95: Batch #195 - Loss: 0.7752962112426758\n",
      "Ep 95: Batch #196 - Loss: 0.6873433589935303\n",
      "Ep 95: Batch #197 - Loss: 0.6912657618522644\n",
      "Ep 95: Batch #198 - Loss: 0.5350160002708435\n",
      "Ep 95: Batch #199 - Loss: 0.6415486931800842\n",
      "Ep 96: Batch #0 - Loss: 0.6494510173797607\n",
      "Ep 96: Batch #1 - Loss: 0.719106137752533\n",
      "Ep 96: Batch #2 - Loss: 0.8599290251731873\n",
      "Ep 96: Batch #3 - Loss: 0.7195443511009216\n",
      "Ep 96: Batch #4 - Loss: 0.6545386910438538\n",
      "Ep 96: Batch #5 - Loss: 0.548297107219696\n",
      "Ep 96: Batch #6 - Loss: 0.7250400185585022\n",
      "Ep 96: Batch #7 - Loss: 0.5758312344551086\n",
      "Ep 96: Batch #8 - Loss: 0.5789493322372437\n",
      "Ep 96: Batch #9 - Loss: 1.082203984260559\n",
      "Ep 96: Batch #10 - Loss: 0.7801805138587952\n",
      "Ep 96: Batch #11 - Loss: 0.5407763719558716\n",
      "Ep 96: Batch #12 - Loss: 1.162265419960022\n",
      "Ep 96: Batch #13 - Loss: 0.5664620995521545\n",
      "Ep 96: Batch #14 - Loss: 0.5986620187759399\n",
      "Ep 96: Batch #15 - Loss: 0.8396739363670349\n",
      "Ep 96: Batch #16 - Loss: 0.9473589658737183\n",
      "Ep 96: Batch #17 - Loss: 0.7263830900192261\n",
      "Ep 96: Batch #18 - Loss: 0.807506799697876\n",
      "Ep 96: Batch #19 - Loss: 0.5631103515625\n",
      "Ep 96: Batch #20 - Loss: 0.5448274612426758\n",
      "Ep 96: Batch #21 - Loss: 0.7834053635597229\n",
      "Ep 96: Batch #22 - Loss: 0.6019212007522583\n",
      "Ep 96: Batch #23 - Loss: 0.5980626940727234\n",
      "Ep 96: Batch #24 - Loss: 0.6416773200035095\n",
      "Ep 96: Batch #25 - Loss: 0.6009555459022522\n",
      "Ep 96: Batch #26 - Loss: 0.5545164346694946\n",
      "Ep 96: Batch #27 - Loss: 1.115460753440857\n",
      "Ep 96: Batch #28 - Loss: 0.6920489072799683\n",
      "Ep 96: Batch #29 - Loss: 0.7457464337348938\n",
      "Ep 96: Batch #30 - Loss: 0.8128998279571533\n",
      "Ep 96: Batch #31 - Loss: 0.5588982701301575\n",
      "Ep 96: Batch #32 - Loss: 0.5743328928947449\n",
      "Ep 96: Batch #33 - Loss: 0.6595503687858582\n",
      "Ep 96: Batch #34 - Loss: 0.6299435496330261\n",
      "Ep 96: Batch #35 - Loss: 0.7230527997016907\n",
      "Ep 96: Batch #36 - Loss: 0.5764302015304565\n",
      "Ep 96: Batch #37 - Loss: 0.9199895858764648\n",
      "Ep 96: Batch #38 - Loss: 0.5635180473327637\n",
      "Ep 96: Batch #39 - Loss: 0.6819853186607361\n",
      "Ep 96: Batch #40 - Loss: 0.6055422425270081\n",
      "Ep 96: Batch #41 - Loss: 0.614899754524231\n",
      "Ep 96: Batch #42 - Loss: 0.5676155090332031\n",
      "Ep 96: Batch #43 - Loss: 0.6289462447166443\n",
      "Ep 96: Batch #44 - Loss: 0.607539713382721\n",
      "Ep 96: Batch #45 - Loss: 0.5234469175338745\n",
      "Ep 96: Batch #46 - Loss: 0.692957878112793\n",
      "Ep 96: Batch #47 - Loss: 0.7845069766044617\n",
      "Ep 96: Batch #48 - Loss: 1.029893159866333\n",
      "Ep 96: Batch #49 - Loss: 0.8044115304946899\n",
      "Ep 96: Batch #50 - Loss: 0.5681621432304382\n",
      "Ep 96: Batch #51 - Loss: 0.8030550479888916\n",
      "Ep 96: Batch #52 - Loss: 0.6615757942199707\n",
      "Ep 96: Batch #53 - Loss: 0.7024078369140625\n",
      "Ep 96: Batch #54 - Loss: 0.5716440677642822\n",
      "Ep 96: Batch #55 - Loss: 0.6018561124801636\n",
      "Ep 96: Batch #56 - Loss: 0.8461333513259888\n",
      "Ep 96: Batch #57 - Loss: 0.6766376495361328\n",
      "Ep 96: Batch #58 - Loss: 0.8169987797737122\n",
      "Ep 96: Batch #59 - Loss: 0.5567712187767029\n",
      "Ep 96: Batch #60 - Loss: 0.9811643362045288\n",
      "Ep 96: Batch #61 - Loss: 0.5348923206329346\n",
      "Ep 96: Batch #62 - Loss: 0.5753536820411682\n",
      "Ep 96: Batch #63 - Loss: 0.7718239426612854\n",
      "Ep 96: Batch #64 - Loss: 7.7887187004089355\n",
      "Ep 96: Batch #65 - Loss: 0.5187621116638184\n",
      "Ep 96: Batch #66 - Loss: 0.6581218242645264\n",
      "Ep 96: Batch #67 - Loss: 0.7740998864173889\n",
      "Ep 96: Batch #68 - Loss: 0.7034049034118652\n",
      "Ep 96: Batch #69 - Loss: 0.5878116488456726\n",
      "Ep 96: Batch #70 - Loss: 0.6127122640609741\n",
      "Ep 96: Batch #71 - Loss: 0.5371074080467224\n",
      "Ep 96: Batch #72 - Loss: 0.6624844074249268\n",
      "Ep 96: Batch #73 - Loss: 0.7104539275169373\n",
      "Ep 96: Batch #74 - Loss: 0.5729184746742249\n",
      "Ep 96: Batch #75 - Loss: 0.6635622382164001\n",
      "Ep 96: Batch #76 - Loss: 0.9147433638572693\n",
      "Ep 96: Batch #77 - Loss: 0.5652047395706177\n",
      "Ep 96: Batch #78 - Loss: 0.8879733681678772\n",
      "Ep 96: Batch #79 - Loss: 0.5215486884117126\n",
      "Ep 96: Batch #80 - Loss: 0.6789317727088928\n",
      "Ep 96: Batch #81 - Loss: 1.5194169282913208\n",
      "Ep 96: Batch #82 - Loss: 0.7407527565956116\n",
      "Ep 96: Batch #83 - Loss: 1.1740574836730957\n",
      "Ep 96: Batch #84 - Loss: 0.5749133825302124\n",
      "Ep 96: Batch #85 - Loss: 0.7761449217796326\n",
      "Ep 96: Batch #86 - Loss: 0.5435456037521362\n",
      "Ep 96: Batch #87 - Loss: 0.5689023733139038\n",
      "Ep 96: Batch #88 - Loss: 0.6522001028060913\n",
      "Ep 96: Batch #89 - Loss: 0.7240445613861084\n",
      "Ep 96: Batch #90 - Loss: 0.9061825275421143\n",
      "Ep 96: Batch #91 - Loss: 0.6395381689071655\n",
      "Ep 96: Batch #92 - Loss: 0.7310672998428345\n",
      "Ep 96: Batch #93 - Loss: 0.7627735733985901\n",
      "Ep 96: Batch #94 - Loss: 0.738034725189209\n",
      "Ep 96: Batch #95 - Loss: 0.7588659524917603\n",
      "Ep 96: Batch #96 - Loss: 0.7462676167488098\n",
      "Ep 96: Batch #97 - Loss: 0.5877514481544495\n",
      "Ep 96: Batch #98 - Loss: 0.5767816305160522\n",
      "Ep 96: Batch #99 - Loss: 0.7908629775047302\n",
      "Ep 96: Batch #100 - Loss: 0.5546694397926331\n",
      "Ep 96: Batch #101 - Loss: 0.8716047406196594\n",
      "Ep 96: Batch #102 - Loss: 0.6057376861572266\n",
      "Ep 96: Batch #103 - Loss: 0.629509687423706\n",
      "Ep 96: Batch #104 - Loss: 0.6568811535835266\n",
      "Ep 96: Batch #105 - Loss: 0.8240652680397034\n",
      "Ep 96: Batch #106 - Loss: 0.6251299977302551\n",
      "Ep 96: Batch #107 - Loss: 0.612970769405365\n",
      "Ep 96: Batch #108 - Loss: 0.9002537727355957\n",
      "Ep 96: Batch #109 - Loss: 0.6179799437522888\n",
      "Ep 96: Batch #110 - Loss: 0.719469428062439\n",
      "Ep 96: Batch #111 - Loss: 1.0315003395080566\n",
      "Ep 96: Batch #112 - Loss: 0.7917112112045288\n",
      "Ep 96: Batch #113 - Loss: 0.6564995646476746\n",
      "Ep 96: Batch #114 - Loss: 0.7159149646759033\n",
      "Ep 96: Batch #115 - Loss: 0.9070578813552856\n",
      "Ep 96: Batch #116 - Loss: 0.5206888914108276\n",
      "Ep 96: Batch #117 - Loss: 0.6768946647644043\n",
      "Ep 96: Batch #118 - Loss: 0.452526330947876\n",
      "Ep 96: Batch #119 - Loss: 0.7978454232215881\n",
      "Ep 96: Batch #120 - Loss: 0.652708888053894\n",
      "Ep 96: Batch #121 - Loss: 0.5615913271903992\n",
      "Ep 96: Batch #122 - Loss: 0.6938464641571045\n",
      "Ep 96: Batch #123 - Loss: 0.7026063203811646\n",
      "Ep 96: Batch #124 - Loss: 0.5519759058952332\n",
      "Ep 96: Batch #125 - Loss: 2.4708399772644043\n",
      "Ep 96: Batch #126 - Loss: 1.0079129934310913\n",
      "Ep 96: Batch #127 - Loss: 0.5786663889884949\n",
      "Ep 96: Batch #128 - Loss: 0.8758683800697327\n",
      "Ep 96: Batch #129 - Loss: 0.6736623644828796\n",
      "Ep 96: Batch #130 - Loss: 0.5972892045974731\n",
      "Ep 96: Batch #131 - Loss: 0.7883504033088684\n",
      "Ep 96: Batch #132 - Loss: 0.6831578612327576\n",
      "Ep 96: Batch #133 - Loss: 0.658639132976532\n",
      "Ep 96: Batch #134 - Loss: 0.6353042125701904\n",
      "Ep 96: Batch #135 - Loss: 0.8163246512413025\n",
      "Ep 96: Batch #136 - Loss: 1.0370209217071533\n",
      "Ep 96: Batch #137 - Loss: 0.7487200498580933\n",
      "Ep 96: Batch #138 - Loss: 0.8947342038154602\n",
      "Ep 96: Batch #139 - Loss: 0.6694765090942383\n",
      "Ep 96: Batch #140 - Loss: 0.8388070464134216\n",
      "Ep 96: Batch #141 - Loss: 1.0994864702224731\n",
      "Ep 96: Batch #142 - Loss: 0.666182279586792\n",
      "Ep 96: Batch #143 - Loss: 0.7607594132423401\n",
      "Ep 96: Batch #144 - Loss: 0.6063017249107361\n",
      "Ep 96: Batch #145 - Loss: 0.596973717212677\n",
      "Ep 96: Batch #146 - Loss: 0.692135214805603\n",
      "Ep 96: Batch #147 - Loss: 0.6581432223320007\n",
      "Ep 96: Batch #148 - Loss: 0.7523619532585144\n",
      "Ep 96: Batch #149 - Loss: 0.6074810028076172\n",
      "Ep 96: Batch #150 - Loss: 0.7210080623626709\n",
      "Ep 96: Batch #151 - Loss: 0.6216424107551575\n",
      "Ep 96: Batch #152 - Loss: 0.6084046959877014\n",
      "Ep 96: Batch #153 - Loss: 0.8153913617134094\n",
      "Ep 96: Batch #154 - Loss: 0.6326842904090881\n",
      "Ep 96: Batch #155 - Loss: 0.6818354725837708\n",
      "Ep 96: Batch #156 - Loss: 0.7636205554008484\n",
      "Ep 96: Batch #157 - Loss: 0.6089943051338196\n",
      "Ep 96: Batch #158 - Loss: 0.7169143557548523\n",
      "Ep 96: Batch #159 - Loss: 0.5938602685928345\n",
      "Ep 96: Batch #160 - Loss: 0.6894381642341614\n",
      "Ep 96: Batch #161 - Loss: 0.6679530143737793\n",
      "Ep 96: Batch #162 - Loss: 0.7229344248771667\n",
      "Ep 96: Batch #163 - Loss: 0.7525114417076111\n",
      "Ep 96: Batch #164 - Loss: 0.6404215693473816\n",
      "Ep 96: Batch #165 - Loss: 1.3350882530212402\n",
      "Ep 96: Batch #166 - Loss: 0.5287479758262634\n",
      "Ep 96: Batch #167 - Loss: 0.6961642503738403\n",
      "Ep 96: Batch #168 - Loss: 0.6883719563484192\n",
      "Ep 96: Batch #169 - Loss: 0.6669696569442749\n",
      "Ep 96: Batch #170 - Loss: 0.629294753074646\n",
      "Ep 96: Batch #171 - Loss: 0.638128399848938\n",
      "Ep 96: Batch #172 - Loss: 0.5332930088043213\n",
      "Ep 96: Batch #173 - Loss: 0.922107458114624\n",
      "Ep 96: Batch #174 - Loss: 0.4929095208644867\n",
      "Ep 96: Batch #175 - Loss: 0.634917676448822\n",
      "Ep 96: Batch #176 - Loss: 0.8933505415916443\n",
      "Ep 96: Batch #177 - Loss: 0.6452690958976746\n",
      "Ep 96: Batch #178 - Loss: 0.6156966686248779\n",
      "Ep 96: Batch #179 - Loss: 0.7486011385917664\n",
      "Ep 96: Batch #180 - Loss: 0.6443474888801575\n",
      "Ep 96: Batch #181 - Loss: 0.7815402150154114\n",
      "Ep 96: Batch #182 - Loss: 0.6283514499664307\n",
      "Ep 96: Batch #183 - Loss: 0.6018974184989929\n",
      "Ep 96: Batch #184 - Loss: 0.8977484107017517\n",
      "Ep 96: Batch #185 - Loss: 0.6321671009063721\n",
      "Ep 96: Batch #186 - Loss: 0.7378765940666199\n",
      "Ep 96: Batch #187 - Loss: 0.8542202711105347\n",
      "Ep 96: Batch #188 - Loss: 0.9157081842422485\n",
      "Ep 96: Batch #189 - Loss: 0.5864319205284119\n",
      "Ep 96: Batch #190 - Loss: 0.6154653429985046\n",
      "Ep 96: Batch #191 - Loss: 0.7864166498184204\n",
      "Ep 96: Batch #192 - Loss: 0.5721036791801453\n",
      "Ep 96: Batch #193 - Loss: 0.625424325466156\n",
      "Ep 96: Batch #194 - Loss: 0.5391899943351746\n",
      "Ep 96: Batch #195 - Loss: 0.775065541267395\n",
      "Ep 96: Batch #196 - Loss: 0.6870498657226562\n",
      "Ep 96: Batch #197 - Loss: 0.6913039684295654\n",
      "Ep 96: Batch #198 - Loss: 0.5354206562042236\n",
      "Ep 96: Batch #199 - Loss: 0.6416927576065063\n",
      "Ep 97: Batch #0 - Loss: 0.6494672298431396\n",
      "Ep 97: Batch #1 - Loss: 0.719011127948761\n",
      "Ep 97: Batch #2 - Loss: 0.8599611520767212\n",
      "Ep 97: Batch #3 - Loss: 0.7196263670921326\n",
      "Ep 97: Batch #4 - Loss: 0.6546571254730225\n",
      "Ep 97: Batch #5 - Loss: 0.5481638312339783\n",
      "Ep 97: Batch #6 - Loss: 0.7244753241539001\n",
      "Ep 97: Batch #7 - Loss: 0.5761188864707947\n",
      "Ep 97: Batch #8 - Loss: 0.5788745284080505\n",
      "Ep 97: Batch #9 - Loss: 1.0824178457260132\n",
      "Ep 97: Batch #10 - Loss: 0.7800756692886353\n",
      "Ep 97: Batch #11 - Loss: 0.5406763553619385\n",
      "Ep 97: Batch #12 - Loss: 1.161232829093933\n",
      "Ep 97: Batch #13 - Loss: 0.5662678480148315\n",
      "Ep 97: Batch #14 - Loss: 0.5986925959587097\n",
      "Ep 97: Batch #15 - Loss: 0.8398342728614807\n",
      "Ep 97: Batch #16 - Loss: 0.9472323656082153\n",
      "Ep 97: Batch #17 - Loss: 0.7261835932731628\n",
      "Ep 97: Batch #18 - Loss: 0.8076573610305786\n",
      "Ep 97: Batch #19 - Loss: 0.5629406571388245\n",
      "Ep 97: Batch #20 - Loss: 0.5448940992355347\n",
      "Ep 97: Batch #21 - Loss: 0.7826336622238159\n",
      "Ep 97: Batch #22 - Loss: 0.6018798351287842\n",
      "Ep 97: Batch #23 - Loss: 0.5980542898178101\n",
      "Ep 97: Batch #24 - Loss: 0.642029345035553\n",
      "Ep 97: Batch #25 - Loss: 0.6011353731155396\n",
      "Ep 97: Batch #26 - Loss: 0.5544996857643127\n",
      "Ep 97: Batch #27 - Loss: 1.1150624752044678\n",
      "Ep 97: Batch #28 - Loss: 0.6919196248054504\n",
      "Ep 97: Batch #29 - Loss: 0.7458576560020447\n",
      "Ep 97: Batch #30 - Loss: 0.8135425448417664\n",
      "Ep 97: Batch #31 - Loss: 0.558829128742218\n",
      "Ep 97: Batch #32 - Loss: 0.5740014314651489\n",
      "Ep 97: Batch #33 - Loss: 0.6594821214675903\n",
      "Ep 97: Batch #34 - Loss: 0.6298837065696716\n",
      "Ep 97: Batch #35 - Loss: 0.7232013940811157\n",
      "Ep 97: Batch #36 - Loss: 0.5762679576873779\n",
      "Ep 97: Batch #37 - Loss: 0.9198242425918579\n",
      "Ep 97: Batch #38 - Loss: 0.5636120438575745\n",
      "Ep 97: Batch #39 - Loss: 0.6819864511489868\n",
      "Ep 97: Batch #40 - Loss: 0.6055262684822083\n",
      "Ep 97: Batch #41 - Loss: 0.6149075031280518\n",
      "Ep 97: Batch #42 - Loss: 0.5677675604820251\n",
      "Ep 97: Batch #43 - Loss: 0.6291417479515076\n",
      "Ep 97: Batch #44 - Loss: 0.6076956391334534\n",
      "Ep 97: Batch #45 - Loss: 0.5234629511833191\n",
      "Ep 97: Batch #46 - Loss: 0.6930248737335205\n",
      "Ep 97: Batch #47 - Loss: 0.7842597961425781\n",
      "Ep 97: Batch #48 - Loss: 1.0300092697143555\n",
      "Ep 97: Batch #49 - Loss: 0.8042472004890442\n",
      "Ep 97: Batch #50 - Loss: 0.5682037472724915\n",
      "Ep 97: Batch #51 - Loss: 0.803337037563324\n",
      "Ep 97: Batch #52 - Loss: 0.6612882614135742\n",
      "Ep 97: Batch #53 - Loss: 0.7025511860847473\n",
      "Ep 97: Batch #54 - Loss: 0.5715494155883789\n",
      "Ep 97: Batch #55 - Loss: 0.6019328236579895\n",
      "Ep 97: Batch #56 - Loss: 0.8466208577156067\n",
      "Ep 97: Batch #57 - Loss: 0.6766719818115234\n",
      "Ep 97: Batch #58 - Loss: 0.8169720768928528\n",
      "Ep 97: Batch #59 - Loss: 0.5569882392883301\n",
      "Ep 97: Batch #60 - Loss: 0.9807005524635315\n",
      "Ep 97: Batch #61 - Loss: 0.534940242767334\n",
      "Ep 97: Batch #62 - Loss: 0.5752851963043213\n",
      "Ep 97: Batch #63 - Loss: 0.7716871500015259\n",
      "Ep 97: Batch #64 - Loss: 7.772415637969971\n",
      "Ep 97: Batch #65 - Loss: 0.5186711549758911\n",
      "Ep 97: Batch #66 - Loss: 0.6582128405570984\n",
      "Ep 97: Batch #67 - Loss: 0.773934543132782\n",
      "Ep 97: Batch #68 - Loss: 0.7032524347305298\n",
      "Ep 97: Batch #69 - Loss: 0.5876992344856262\n",
      "Ep 97: Batch #70 - Loss: 0.6130160689353943\n",
      "Ep 97: Batch #71 - Loss: 0.5371628999710083\n",
      "Ep 97: Batch #72 - Loss: 0.6624212265014648\n",
      "Ep 97: Batch #73 - Loss: 0.7102736830711365\n",
      "Ep 97: Batch #74 - Loss: 0.5728314518928528\n",
      "Ep 97: Batch #75 - Loss: 0.6634927988052368\n",
      "Ep 97: Batch #76 - Loss: 0.914564311504364\n",
      "Ep 97: Batch #77 - Loss: 0.565138041973114\n",
      "Ep 97: Batch #78 - Loss: 0.8875373005867004\n",
      "Ep 97: Batch #79 - Loss: 0.5213651657104492\n",
      "Ep 97: Batch #80 - Loss: 0.6786673069000244\n",
      "Ep 97: Batch #81 - Loss: 1.5197269916534424\n",
      "Ep 97: Batch #82 - Loss: 0.7407805919647217\n",
      "Ep 97: Batch #83 - Loss: 1.1723130941390991\n",
      "Ep 97: Batch #84 - Loss: 0.5748896598815918\n",
      "Ep 97: Batch #85 - Loss: 0.7754411697387695\n",
      "Ep 97: Batch #86 - Loss: 0.5437362790107727\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 97: Batch #87 - Loss: 0.5679410696029663\n",
      "Ep 97: Batch #88 - Loss: 0.6517542004585266\n",
      "Ep 97: Batch #89 - Loss: 0.7252123951911926\n",
      "Ep 97: Batch #90 - Loss: 0.9057740569114685\n",
      "Ep 97: Batch #91 - Loss: 0.6388932466506958\n",
      "Ep 97: Batch #92 - Loss: 0.731569766998291\n",
      "Ep 97: Batch #93 - Loss: 0.7627144455909729\n",
      "Ep 97: Batch #94 - Loss: 0.7377614378929138\n",
      "Ep 97: Batch #95 - Loss: 0.7587424516677856\n",
      "Ep 97: Batch #96 - Loss: 0.7462425231933594\n",
      "Ep 97: Batch #97 - Loss: 0.5880259871482849\n",
      "Ep 97: Batch #98 - Loss: 0.5761169791221619\n",
      "Ep 97: Batch #99 - Loss: 0.7911549210548401\n",
      "Ep 97: Batch #100 - Loss: 0.5548287630081177\n",
      "Ep 97: Batch #101 - Loss: 0.8733897805213928\n",
      "Ep 97: Batch #102 - Loss: 0.6060896515846252\n",
      "Ep 97: Batch #103 - Loss: 0.629645824432373\n",
      "Ep 97: Batch #104 - Loss: 0.6560214161872864\n",
      "Ep 97: Batch #105 - Loss: 0.8235594034194946\n",
      "Ep 97: Batch #106 - Loss: 0.6259849071502686\n",
      "Ep 97: Batch #107 - Loss: 0.6132686734199524\n",
      "Ep 97: Batch #108 - Loss: 0.9001383781433105\n",
      "Ep 97: Batch #109 - Loss: 0.6170670390129089\n",
      "Ep 97: Batch #110 - Loss: 0.7189255952835083\n",
      "Ep 97: Batch #111 - Loss: 1.0259209871292114\n",
      "Ep 97: Batch #112 - Loss: 0.7924287915229797\n",
      "Ep 97: Batch #113 - Loss: 0.6563178896903992\n",
      "Ep 97: Batch #114 - Loss: 0.7150695323944092\n",
      "Ep 97: Batch #115 - Loss: 0.9067820906639099\n",
      "Ep 97: Batch #116 - Loss: 0.5202963352203369\n",
      "Ep 97: Batch #117 - Loss: 0.6759732365608215\n",
      "Ep 97: Batch #118 - Loss: 0.45241668820381165\n",
      "Model saved in file: ./weights_autoencoder_sigmoid/model_e97b118_1516648804.4088936.ckpt\n",
      "Ep 97: Batch #119 - Loss: 0.7981947660446167\n",
      "Ep 97: Batch #120 - Loss: 0.6517057418823242\n",
      "Ep 97: Batch #121 - Loss: 0.5615059733390808\n",
      "Ep 97: Batch #122 - Loss: 0.6939131617546082\n",
      "Ep 97: Batch #123 - Loss: 0.7025021910667419\n",
      "Ep 97: Batch #124 - Loss: 0.5516654849052429\n",
      "Ep 97: Batch #125 - Loss: 2.4721922874450684\n",
      "Ep 97: Batch #126 - Loss: 1.0067026615142822\n",
      "Ep 97: Batch #127 - Loss: 0.5782579183578491\n",
      "Ep 97: Batch #128 - Loss: 0.8764586448669434\n",
      "Ep 97: Batch #129 - Loss: 0.6731557250022888\n",
      "Ep 97: Batch #130 - Loss: 0.5971922874450684\n",
      "Ep 97: Batch #131 - Loss: 0.7873528599739075\n",
      "Ep 97: Batch #132 - Loss: 0.6828364133834839\n",
      "Ep 97: Batch #133 - Loss: 0.6591545939445496\n",
      "Ep 97: Batch #134 - Loss: 0.6346830129623413\n",
      "Ep 97: Batch #135 - Loss: 0.816972017288208\n",
      "Ep 97: Batch #136 - Loss: 1.038273572921753\n",
      "Ep 97: Batch #137 - Loss: 0.7480040192604065\n",
      "Ep 97: Batch #138 - Loss: 0.8948200941085815\n",
      "Ep 97: Batch #139 - Loss: 0.6697238683700562\n",
      "Ep 97: Batch #140 - Loss: 0.8389306664466858\n",
      "Ep 97: Batch #141 - Loss: 1.0994062423706055\n",
      "Ep 97: Batch #142 - Loss: 0.6660327911376953\n",
      "Ep 97: Batch #143 - Loss: 0.7604164481163025\n",
      "Ep 97: Batch #144 - Loss: 0.6061195135116577\n",
      "Ep 97: Batch #145 - Loss: 0.5968149900436401\n",
      "Ep 97: Batch #146 - Loss: 0.6921901702880859\n",
      "Ep 97: Batch #147 - Loss: 0.6587880849838257\n",
      "Ep 97: Batch #148 - Loss: 0.7531943321228027\n",
      "Ep 97: Batch #149 - Loss: 0.6087658405303955\n",
      "Ep 97: Batch #150 - Loss: 0.7209727764129639\n",
      "Ep 97: Batch #151 - Loss: 0.6211650371551514\n",
      "Ep 97: Batch #152 - Loss: 0.6085445880889893\n",
      "Ep 97: Batch #153 - Loss: 0.8159981369972229\n",
      "Ep 97: Batch #154 - Loss: 0.6323007345199585\n",
      "Ep 97: Batch #155 - Loss: 0.681625485420227\n",
      "Ep 97: Batch #156 - Loss: 0.7637646198272705\n",
      "Ep 97: Batch #157 - Loss: 0.6087754368782043\n",
      "Ep 97: Batch #158 - Loss: 0.7165838479995728\n",
      "Ep 97: Batch #159 - Loss: 0.5939163565635681\n",
      "Ep 97: Batch #160 - Loss: 0.6893416047096252\n",
      "Ep 97: Batch #161 - Loss: 0.6679158210754395\n",
      "Ep 97: Batch #162 - Loss: 0.723129391670227\n",
      "Ep 97: Batch #163 - Loss: 0.7522656321525574\n",
      "Ep 97: Batch #164 - Loss: 0.6403899192810059\n",
      "Ep 97: Batch #165 - Loss: 1.3330949544906616\n",
      "Ep 97: Batch #166 - Loss: 0.5287554264068604\n",
      "Ep 97: Batch #167 - Loss: 0.6959008574485779\n",
      "Ep 97: Batch #168 - Loss: 0.6876239776611328\n",
      "Ep 97: Batch #169 - Loss: 0.6669518351554871\n",
      "Ep 97: Batch #170 - Loss: 0.6288309097290039\n",
      "Ep 97: Batch #171 - Loss: 0.6374492049217224\n",
      "Ep 97: Batch #172 - Loss: 0.5333484411239624\n",
      "Ep 97: Batch #173 - Loss: 0.9202136397361755\n",
      "Ep 97: Batch #174 - Loss: 0.4930589497089386\n",
      "Ep 97: Batch #175 - Loss: 0.6353206634521484\n",
      "Ep 97: Batch #176 - Loss: 0.8926627039909363\n",
      "Ep 97: Batch #177 - Loss: 0.6446771621704102\n",
      "Ep 97: Batch #178 - Loss: 0.6152012348175049\n",
      "Ep 97: Batch #179 - Loss: 0.7481875419616699\n",
      "Ep 97: Batch #180 - Loss: 0.644451379776001\n",
      "Ep 97: Batch #181 - Loss: 0.7805281281471252\n",
      "Ep 97: Batch #182 - Loss: 0.628139317035675\n",
      "Ep 97: Batch #183 - Loss: 0.601678729057312\n",
      "Ep 97: Batch #184 - Loss: 0.8972207307815552\n",
      "Ep 97: Batch #185 - Loss: 0.6311736106872559\n",
      "Ep 97: Batch #186 - Loss: 0.7363987565040588\n",
      "Ep 97: Batch #187 - Loss: 0.8527039885520935\n",
      "Ep 97: Batch #188 - Loss: 0.9163541793823242\n",
      "Ep 97: Batch #189 - Loss: 0.5863840579986572\n",
      "Ep 97: Batch #190 - Loss: 0.6153333783149719\n",
      "Ep 97: Batch #191 - Loss: 0.7863298654556274\n",
      "Ep 97: Batch #192 - Loss: 0.572197675704956\n",
      "Ep 97: Batch #193 - Loss: 0.6251324415206909\n",
      "Ep 97: Batch #194 - Loss: 0.5392823219299316\n",
      "Ep 97: Batch #195 - Loss: 0.7751085162162781\n",
      "Ep 97: Batch #196 - Loss: 0.6871716976165771\n",
      "Ep 97: Batch #197 - Loss: 0.6912352442741394\n",
      "Ep 97: Batch #198 - Loss: 0.5352926254272461\n",
      "Ep 97: Batch #199 - Loss: 0.6415591239929199\n",
      "Ep 98: Batch #0 - Loss: 0.649285614490509\n",
      "Ep 98: Batch #1 - Loss: 0.7192617654800415\n",
      "Ep 98: Batch #2 - Loss: 0.8596449494361877\n",
      "Ep 98: Batch #3 - Loss: 0.719969630241394\n",
      "Ep 98: Batch #4 - Loss: 0.6546400785446167\n",
      "Ep 98: Batch #5 - Loss: 0.5483832955360413\n",
      "Ep 98: Batch #6 - Loss: 0.7239558696746826\n",
      "Ep 98: Batch #7 - Loss: 0.576150119304657\n",
      "Ep 98: Batch #8 - Loss: 0.578876256942749\n",
      "Ep 98: Batch #9 - Loss: 1.0817718505859375\n",
      "Ep 98: Batch #10 - Loss: 0.7804906368255615\n",
      "Ep 98: Batch #11 - Loss: 0.5405633449554443\n",
      "Ep 98: Batch #12 - Loss: 1.1602517366409302\n",
      "Ep 98: Batch #13 - Loss: 0.566089928150177\n",
      "Ep 98: Batch #14 - Loss: 0.5984542369842529\n",
      "Ep 98: Batch #15 - Loss: 0.8401097655296326\n",
      "Ep 98: Batch #16 - Loss: 0.9480250477790833\n",
      "Ep 98: Batch #17 - Loss: 0.7261187434196472\n",
      "Ep 98: Batch #18 - Loss: 0.8074482083320618\n",
      "Ep 98: Batch #19 - Loss: 0.5629467964172363\n",
      "Ep 98: Batch #20 - Loss: 0.5448576807975769\n",
      "Ep 98: Batch #21 - Loss: 0.7821722030639648\n",
      "Ep 98: Batch #22 - Loss: 0.601882815361023\n",
      "Ep 98: Batch #23 - Loss: 0.5979277491569519\n",
      "Ep 98: Batch #24 - Loss: 0.6421393752098083\n",
      "Ep 98: Batch #25 - Loss: 0.600883424282074\n",
      "Ep 98: Batch #26 - Loss: 0.5544514060020447\n",
      "Ep 98: Batch #27 - Loss: 1.1140186786651611\n",
      "Ep 98: Batch #28 - Loss: 0.691997766494751\n",
      "Ep 98: Batch #29 - Loss: 0.7455887198448181\n",
      "Ep 98: Batch #30 - Loss: 0.8134579658508301\n",
      "Ep 98: Batch #31 - Loss: 0.5589532256126404\n",
      "Ep 98: Batch #32 - Loss: 0.5739314556121826\n",
      "Ep 98: Batch #33 - Loss: 0.6595401763916016\n",
      "Ep 98: Batch #34 - Loss: 0.6297701597213745\n",
      "Ep 98: Batch #35 - Loss: 0.7232851982116699\n",
      "Ep 98: Batch #36 - Loss: 0.5764294266700745\n",
      "Ep 98: Batch #37 - Loss: 0.9200373291969299\n",
      "Ep 98: Batch #38 - Loss: 0.5634395480155945\n",
      "Ep 98: Batch #39 - Loss: 0.6818239688873291\n",
      "Ep 98: Batch #40 - Loss: 0.6054577827453613\n",
      "Ep 98: Batch #41 - Loss: 0.6147500872612\n",
      "Ep 98: Batch #42 - Loss: 0.5678371787071228\n",
      "Ep 98: Batch #43 - Loss: 0.6287195682525635\n",
      "Ep 98: Batch #44 - Loss: 0.6075969338417053\n",
      "Ep 98: Batch #45 - Loss: 0.5234537124633789\n",
      "Ep 98: Batch #46 - Loss: 0.6928197741508484\n",
      "Ep 98: Batch #47 - Loss: 0.7839466333389282\n",
      "Ep 98: Batch #48 - Loss: 1.0299447774887085\n",
      "Ep 98: Batch #49 - Loss: 0.8043015003204346\n",
      "Ep 98: Batch #50 - Loss: 0.5681775212287903\n",
      "Ep 98: Batch #51 - Loss: 0.8030989170074463\n",
      "Ep 98: Batch #52 - Loss: 0.6610798835754395\n",
      "Ep 98: Batch #53 - Loss: 0.702277421951294\n",
      "Ep 98: Batch #54 - Loss: 0.5714449286460876\n",
      "Ep 98: Batch #55 - Loss: 0.6024042367935181\n",
      "Ep 98: Batch #56 - Loss: 0.8462674617767334\n",
      "Ep 98: Batch #57 - Loss: 0.676648736000061\n",
      "Ep 98: Batch #58 - Loss: 0.8167168498039246\n",
      "Ep 98: Batch #59 - Loss: 0.5567803978919983\n",
      "Ep 98: Batch #60 - Loss: 0.9807563424110413\n",
      "Ep 98: Batch #61 - Loss: 0.5348689556121826\n",
      "Ep 98: Batch #62 - Loss: 0.5752285718917847\n",
      "Ep 98: Batch #63 - Loss: 0.7717307209968567\n",
      "Ep 98: Batch #64 - Loss: 7.756206035614014\n",
      "Ep 98: Batch #65 - Loss: 0.5185855031013489\n",
      "Ep 98: Batch #66 - Loss: 0.6579375267028809\n",
      "Ep 98: Batch #67 - Loss: 0.7738576531410217\n",
      "Ep 98: Batch #68 - Loss: 0.7031170725822449\n",
      "Ep 98: Batch #69 - Loss: 0.587722897529602\n",
      "Ep 98: Batch #70 - Loss: 0.6131675839424133\n",
      "Ep 98: Batch #71 - Loss: 0.5371614098548889\n",
      "Ep 98: Batch #72 - Loss: 0.6623795032501221\n",
      "Ep 98: Batch #73 - Loss: 0.7103860378265381\n",
      "Ep 98: Batch #74 - Loss: 0.5730308294296265\n",
      "Ep 98: Batch #75 - Loss: 0.6634470820426941\n",
      "Ep 98: Batch #76 - Loss: 0.9143863916397095\n",
      "Ep 98: Batch #77 - Loss: 0.564723014831543\n",
      "Ep 98: Batch #78 - Loss: 0.8869579434394836\n",
      "Ep 98: Batch #79 - Loss: 0.5212970972061157\n",
      "Ep 98: Batch #80 - Loss: 0.6786597371101379\n",
      "Ep 98: Batch #81 - Loss: 1.5208643674850464\n",
      "Ep 98: Batch #82 - Loss: 0.7407988905906677\n",
      "Ep 98: Batch #83 - Loss: 1.1718565225601196\n",
      "Ep 98: Batch #84 - Loss: 0.5748935341835022\n",
      "Ep 98: Batch #85 - Loss: 0.7781851887702942\n",
      "Ep 98: Batch #86 - Loss: 0.5442031025886536\n",
      "Ep 98: Batch #87 - Loss: 0.5706139802932739\n",
      "Ep 98: Batch #88 - Loss: 0.6546704173088074\n",
      "Ep 98: Batch #89 - Loss: 0.726635217666626\n",
      "Ep 98: Batch #90 - Loss: 0.9088448286056519\n",
      "Ep 98: Batch #91 - Loss: 0.6407275199890137\n",
      "Ep 98: Batch #92 - Loss: 0.7330645322799683\n",
      "Ep 98: Batch #93 - Loss: 0.7638159990310669\n",
      "Ep 98: Batch #94 - Loss: 0.7421686053276062\n",
      "Ep 98: Batch #95 - Loss: 0.7601745128631592\n",
      "Ep 98: Batch #96 - Loss: 0.7465648651123047\n",
      "Ep 98: Batch #97 - Loss: 0.588520884513855\n",
      "Ep 98: Batch #98 - Loss: 0.5781794786453247\n",
      "Ep 98: Batch #99 - Loss: 0.793364942073822\n",
      "Ep 98: Batch #100 - Loss: 0.5556433796882629\n",
      "Ep 98: Batch #101 - Loss: 0.8719063401222229\n",
      "Ep 98: Batch #102 - Loss: 0.6064431667327881\n",
      "Ep 98: Batch #103 - Loss: 0.630079448223114\n",
      "Ep 98: Batch #104 - Loss: 0.6583682894706726\n",
      "Ep 98: Batch #105 - Loss: 0.8261738419532776\n",
      "Ep 98: Batch #106 - Loss: 0.6261122822761536\n",
      "Ep 98: Batch #107 - Loss: 0.613425612449646\n",
      "Ep 98: Batch #108 - Loss: 0.9013853073120117\n",
      "Ep 98: Batch #109 - Loss: 0.6185967326164246\n",
      "Ep 98: Batch #110 - Loss: 0.7204023003578186\n",
      "Ep 98: Batch #111 - Loss: 1.0359671115875244\n",
      "Ep 98: Batch #112 - Loss: 0.7927420735359192\n",
      "Ep 98: Batch #113 - Loss: 0.6566900610923767\n",
      "Ep 98: Batch #114 - Loss: 0.7166633009910583\n",
      "Ep 98: Batch #115 - Loss: 0.908545732498169\n",
      "Ep 98: Batch #116 - Loss: 0.5210146903991699\n",
      "Ep 98: Batch #117 - Loss: 0.6773228049278259\n",
      "Ep 98: Batch #118 - Loss: 0.45269641280174255\n",
      "Ep 98: Batch #119 - Loss: 0.7980715036392212\n",
      "Ep 98: Batch #120 - Loss: 0.6531707644462585\n",
      "Ep 98: Batch #121 - Loss: 0.5620982050895691\n",
      "Ep 98: Batch #122 - Loss: 0.6937322020530701\n",
      "Ep 98: Batch #123 - Loss: 0.7018932104110718\n",
      "Ep 98: Batch #124 - Loss: 0.5521975755691528\n",
      "Ep 98: Batch #125 - Loss: 2.471691608428955\n",
      "Ep 98: Batch #126 - Loss: 1.0085585117340088\n",
      "Ep 98: Batch #127 - Loss: 0.5789108872413635\n",
      "Ep 98: Batch #128 - Loss: 0.876897394657135\n",
      "Ep 98: Batch #129 - Loss: 0.6742706298828125\n",
      "Ep 98: Batch #130 - Loss: 0.5973212122917175\n",
      "Ep 98: Batch #131 - Loss: 0.7889569401741028\n",
      "Ep 98: Batch #132 - Loss: 0.6835052371025085\n",
      "Ep 98: Batch #133 - Loss: 0.6588603854179382\n",
      "Ep 98: Batch #134 - Loss: 0.6355023980140686\n",
      "Ep 98: Batch #135 - Loss: 0.816155195236206\n",
      "Ep 98: Batch #136 - Loss: 1.0371975898742676\n",
      "Ep 98: Batch #137 - Loss: 0.7495588064193726\n",
      "Ep 98: Batch #138 - Loss: 0.8948935270309448\n",
      "Ep 98: Batch #139 - Loss: 0.6703474521636963\n",
      "Ep 98: Batch #140 - Loss: 0.8388583660125732\n",
      "Ep 98: Batch #141 - Loss: 1.0986113548278809\n",
      "Ep 98: Batch #142 - Loss: 0.6664736866950989\n",
      "Ep 98: Batch #143 - Loss: 0.7612409591674805\n",
      "Ep 98: Batch #144 - Loss: 0.6064919233322144\n",
      "Ep 98: Batch #145 - Loss: 0.5973405838012695\n",
      "Ep 98: Batch #146 - Loss: 0.6919736266136169\n",
      "Ep 98: Batch #147 - Loss: 0.6580570936203003\n",
      "Ep 98: Batch #148 - Loss: 0.7527887225151062\n",
      "Ep 98: Batch #149 - Loss: 0.6079608201980591\n",
      "Ep 98: Batch #150 - Loss: 0.7210730910301208\n",
      "Ep 98: Batch #151 - Loss: 0.6218354105949402\n",
      "Ep 98: Batch #152 - Loss: 0.6088874936103821\n",
      "Ep 98: Batch #153 - Loss: 0.815439760684967\n",
      "Ep 98: Batch #154 - Loss: 0.632194459438324\n",
      "Ep 98: Batch #155 - Loss: 0.6816256046295166\n",
      "Ep 98: Batch #156 - Loss: 0.7635021805763245\n",
      "Ep 98: Batch #157 - Loss: 0.6091939210891724\n",
      "Ep 98: Batch #158 - Loss: 0.7169493436813354\n",
      "Ep 98: Batch #159 - Loss: 0.5945149064064026\n",
      "Ep 98: Batch #160 - Loss: 0.6895865201950073\n",
      "Ep 98: Batch #161 - Loss: 0.6684423089027405\n",
      "Ep 98: Batch #162 - Loss: 0.723568856716156\n",
      "Ep 98: Batch #163 - Loss: 0.7523714900016785\n",
      "Ep 98: Batch #164 - Loss: 0.6404550671577454\n",
      "Ep 98: Batch #165 - Loss: 1.3352736234664917\n",
      "Ep 98: Batch #166 - Loss: 0.5289596319198608\n",
      "Ep 98: Batch #167 - Loss: 0.6960546970367432\n",
      "Ep 98: Batch #168 - Loss: 0.6884121298789978\n",
      "Ep 98: Batch #169 - Loss: 0.667651891708374\n",
      "Ep 98: Batch #170 - Loss: 0.6293478012084961\n",
      "Ep 98: Batch #171 - Loss: 0.6380575895309448\n",
      "Ep 98: Batch #172 - Loss: 0.5332793593406677\n",
      "Ep 98: Batch #173 - Loss: 0.9224502444267273\n",
      "Ep 98: Batch #174 - Loss: 0.49331390857696533\n",
      "Ep 98: Batch #175 - Loss: 0.6354329586029053\n",
      "Ep 98: Batch #176 - Loss: 0.8929506540298462\n",
      "Ep 98: Batch #177 - Loss: 0.6452199816703796\n",
      "Ep 98: Batch #178 - Loss: 0.6154746413230896\n",
      "Ep 98: Batch #179 - Loss: 0.7486398816108704\n",
      "Ep 98: Batch #180 - Loss: 0.644610583782196\n",
      "Ep 98: Batch #181 - Loss: 0.7809433341026306\n",
      "Ep 98: Batch #182 - Loss: 0.6285618543624878\n",
      "Ep 98: Batch #183 - Loss: 0.6019213199615479\n",
      "Ep 98: Batch #184 - Loss: 0.8972027897834778\n",
      "Ep 98: Batch #185 - Loss: 0.6325822472572327\n",
      "Ep 98: Batch #186 - Loss: 0.7376924753189087\n",
      "Ep 98: Batch #187 - Loss: 0.8541355133056641\n",
      "Ep 98: Batch #188 - Loss: 0.9174221158027649\n",
      "Ep 98: Batch #189 - Loss: 0.5865864157676697\n",
      "Ep 98: Batch #190 - Loss: 0.6153610348701477\n",
      "Ep 98: Batch #191 - Loss: 0.7861246466636658\n",
      "Ep 98: Batch #192 - Loss: 0.5724308490753174\n",
      "Ep 98: Batch #193 - Loss: 0.6257579922676086\n",
      "Ep 98: Batch #194 - Loss: 0.5390981435775757\n",
      "Ep 98: Batch #195 - Loss: 0.7752082347869873\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 98: Batch #196 - Loss: 0.6867721676826477\n",
      "Ep 98: Batch #197 - Loss: 0.6911689043045044\n",
      "Ep 98: Batch #198 - Loss: 0.53559410572052\n",
      "Ep 98: Batch #199 - Loss: 0.641803503036499\n",
      "Ep 99: Batch #0 - Loss: 0.6493303775787354\n",
      "Ep 99: Batch #1 - Loss: 0.7191312313079834\n",
      "Ep 99: Batch #2 - Loss: 0.8603429794311523\n",
      "Ep 99: Batch #3 - Loss: 0.7196184992790222\n",
      "Ep 99: Batch #4 - Loss: 0.654534101486206\n",
      "Ep 99: Batch #5 - Loss: 0.5482643842697144\n",
      "Ep 99: Batch #6 - Loss: 0.7238555550575256\n",
      "Ep 99: Batch #7 - Loss: 0.5762156844139099\n",
      "Ep 99: Batch #8 - Loss: 0.5787703394889832\n",
      "Ep 99: Batch #9 - Loss: 1.0819153785705566\n",
      "Ep 99: Batch #10 - Loss: 0.7796292304992676\n",
      "Ep 99: Batch #11 - Loss: 0.5406064391136169\n",
      "Ep 99: Batch #12 - Loss: 1.1593180894851685\n",
      "Ep 99: Batch #13 - Loss: 0.5660807490348816\n",
      "Ep 99: Batch #14 - Loss: 0.5987597107887268\n",
      "Ep 99: Batch #15 - Loss: 0.8406843543052673\n",
      "Ep 99: Batch #16 - Loss: 0.947182297706604\n",
      "Ep 99: Batch #17 - Loss: 0.7260356545448303\n",
      "Ep 99: Batch #18 - Loss: 0.8078051209449768\n",
      "Ep 99: Batch #19 - Loss: 0.5627996921539307\n",
      "Ep 99: Batch #20 - Loss: 0.5448823571205139\n",
      "Ep 99: Batch #21 - Loss: 0.7817807197570801\n",
      "Ep 99: Batch #22 - Loss: 0.6016669273376465\n",
      "Ep 99: Batch #23 - Loss: 0.5980366468429565\n",
      "Ep 99: Batch #24 - Loss: 0.642482340335846\n",
      "Ep 99: Batch #25 - Loss: 0.6011040806770325\n",
      "Ep 99: Batch #26 - Loss: 0.554837703704834\n",
      "Ep 99: Batch #27 - Loss: 1.1135092973709106\n",
      "Ep 99: Batch #28 - Loss: 0.6918524503707886\n",
      "Ep 99: Batch #29 - Loss: 0.745641827583313\n",
      "Ep 99: Batch #30 - Loss: 0.8143705725669861\n",
      "Ep 99: Batch #31 - Loss: 0.559076726436615\n",
      "Ep 99: Batch #32 - Loss: 0.5739690661430359\n",
      "Ep 99: Batch #33 - Loss: 0.6595519185066223\n",
      "Ep 99: Batch #34 - Loss: 0.6296749114990234\n",
      "Ep 99: Batch #35 - Loss: 0.7232965230941772\n",
      "Ep 99: Batch #36 - Loss: 0.5760383605957031\n",
      "Ep 99: Batch #37 - Loss: 0.9198539853096008\n",
      "Ep 99: Batch #38 - Loss: 0.5637043118476868\n",
      "Ep 99: Batch #39 - Loss: 0.6818058490753174\n",
      "Ep 99: Batch #40 - Loss: 0.6055216789245605\n",
      "Ep 99: Batch #41 - Loss: 0.6149011850357056\n",
      "Ep 99: Batch #42 - Loss: 0.5679512023925781\n",
      "Ep 99: Batch #43 - Loss: 0.6290283799171448\n",
      "Ep 99: Batch #44 - Loss: 0.6077482104301453\n",
      "Ep 99: Batch #45 - Loss: 0.5236998200416565\n",
      "Ep 99: Batch #46 - Loss: 0.6930453181266785\n",
      "Ep 99: Batch #47 - Loss: 0.7837903499603271\n",
      "Ep 99: Batch #48 - Loss: 1.0307488441467285\n",
      "Ep 99: Batch #49 - Loss: 0.8041212558746338\n",
      "Ep 99: Batch #50 - Loss: 0.5685058832168579\n",
      "Ep 99: Batch #51 - Loss: 0.8033661246299744\n",
      "Ep 99: Batch #52 - Loss: 0.6610469818115234\n",
      "Ep 99: Batch #53 - Loss: 0.7016986608505249\n",
      "Ep 99: Batch #54 - Loss: 0.5714989900588989\n",
      "Ep 99: Batch #55 - Loss: 0.6021965146064758\n",
      "Ep 99: Batch #56 - Loss: 0.8467010855674744\n",
      "Ep 99: Batch #57 - Loss: 0.6766697764396667\n",
      "Ep 99: Batch #58 - Loss: 0.8169275522232056\n",
      "Ep 99: Batch #59 - Loss: 0.5571388006210327\n",
      "Ep 99: Batch #60 - Loss: 0.980557918548584\n",
      "Ep 99: Batch #61 - Loss: 0.5348460078239441\n",
      "Ep 99: Batch #62 - Loss: 0.5753340125083923\n",
      "Ep 99: Batch #63 - Loss: 0.7718245983123779\n",
      "Ep 99: Batch #64 - Loss: 7.740277290344238\n",
      "Ep 99: Batch #65 - Loss: 0.5183801054954529\n",
      "Ep 99: Batch #66 - Loss: 0.6584681868553162\n",
      "Ep 99: Batch #67 - Loss: 0.773922324180603\n",
      "Ep 99: Batch #68 - Loss: 0.7032219767570496\n",
      "Ep 99: Batch #69 - Loss: 0.5878665447235107\n",
      "Ep 99: Batch #70 - Loss: 0.6135345101356506\n",
      "Ep 99: Batch #71 - Loss: 0.5371219515800476\n",
      "Ep 99: Batch #72 - Loss: 0.6623296737670898\n",
      "Ep 99: Batch #73 - Loss: 0.7103442549705505\n",
      "Ep 99: Batch #74 - Loss: 0.5730488300323486\n",
      "Ep 99: Batch #75 - Loss: 0.6633332371711731\n",
      "Ep 99: Batch #76 - Loss: 0.9142161011695862\n",
      "Ep 99: Batch #77 - Loss: 0.5646904110908508\n",
      "Ep 99: Batch #78 - Loss: 0.8867457509040833\n",
      "Ep 99: Batch #79 - Loss: 0.5213717222213745\n",
      "Ep 99: Batch #80 - Loss: 0.6784581542015076\n",
      "Ep 99: Batch #81 - Loss: 1.519494652748108\n",
      "Ep 99: Batch #82 - Loss: 0.7404279708862305\n",
      "Ep 99: Batch #83 - Loss: 1.1744643449783325\n",
      "Ep 99: Batch #84 - Loss: 0.5750085115432739\n",
      "Ep 99: Batch #85 - Loss: 0.7759016156196594\n",
      "Ep 99: Batch #86 - Loss: 0.5439695119857788\n",
      "Ep 99: Batch #87 - Loss: 0.5679351091384888\n",
      "Ep 99: Batch #88 - Loss: 0.6524503827095032\n",
      "Ep 99: Batch #89 - Loss: 0.7258210778236389\n",
      "Ep 99: Batch #90 - Loss: 0.9066236019134521\n",
      "Ep 99: Batch #91 - Loss: 0.6387205719947815\n",
      "Ep 99: Batch #92 - Loss: 0.7323546409606934\n",
      "Ep 99: Batch #93 - Loss: 0.763152003288269\n",
      "Ep 99: Batch #94 - Loss: 0.738496720790863\n",
      "Ep 99: Batch #95 - Loss: 0.7590548396110535\n",
      "Ep 99: Batch #96 - Loss: 0.7461655735969543\n",
      "Ep 99: Batch #97 - Loss: 0.5883875489234924\n",
      "Ep 99: Batch #98 - Loss: 0.5759585499763489\n",
      "Ep 99: Batch #99 - Loss: 0.7911426424980164\n",
      "Ep 99: Batch #100 - Loss: 0.5550135374069214\n",
      "Ep 99: Batch #101 - Loss: 0.8739248514175415\n",
      "Ep 99: Batch #102 - Loss: 0.6056885719299316\n",
      "Ep 99: Batch #103 - Loss: 0.6299222707748413\n",
      "Ep 99: Batch #104 - Loss: 0.6562416553497314\n",
      "Ep 99: Batch #105 - Loss: 0.8235161900520325\n",
      "Ep 99: Batch #106 - Loss: 0.6260648965835571\n",
      "Ep 99: Batch #107 - Loss: 0.6134372353553772\n",
      "Ep 99: Batch #108 - Loss: 0.9002641439437866\n",
      "Ep 99: Batch #109 - Loss: 0.6168377995491028\n",
      "Ep 99: Batch #110 - Loss: 0.7190863490104675\n",
      "Ep 99: Batch #111 - Loss: 1.025524377822876\n",
      "Ep 99: Batch #112 - Loss: 0.7924505472183228\n",
      "Ep 99: Batch #113 - Loss: 0.6561756730079651\n",
      "Ep 99: Batch #114 - Loss: 0.7146833539009094\n",
      "Ep 99: Batch #115 - Loss: 0.9073119163513184\n",
      "Ep 99: Batch #116 - Loss: 0.5201565027236938\n",
      "Ep 99: Batch #117 - Loss: 0.6756770014762878\n",
      "Ep 99: Batch #118 - Loss: 0.45237022638320923\n",
      "Model saved in file: ./weights_autoencoder_sigmoid/model_e99b118_1516648804.661837.ckpt\n",
      "Ep 99: Batch #119 - Loss: 0.7975451946258545\n",
      "Ep 99: Batch #120 - Loss: 0.6515163779258728\n",
      "Ep 99: Batch #121 - Loss: 0.5616068243980408\n",
      "Ep 99: Batch #122 - Loss: 0.6936502456665039\n",
      "Ep 99: Batch #123 - Loss: 0.7017914652824402\n",
      "Ep 99: Batch #124 - Loss: 0.5514721870422363\n",
      "Ep 99: Batch #125 - Loss: 2.47198486328125\n",
      "Ep 99: Batch #126 - Loss: 1.0064932107925415\n",
      "Ep 99: Batch #127 - Loss: 0.5781867504119873\n",
      "Ep 99: Batch #128 - Loss: 0.8765523433685303\n",
      "Ep 99: Batch #129 - Loss: 0.6732851266860962\n",
      "Ep 99: Batch #130 - Loss: 0.5970083475112915\n",
      "Ep 99: Batch #131 - Loss: 0.7869566679000854\n",
      "Ep 99: Batch #132 - Loss: 0.6830873489379883\n",
      "Ep 99: Batch #133 - Loss: 0.6589933037757874\n",
      "Ep 99: Batch #134 - Loss: 0.6345739364624023\n",
      "Ep 99: Batch #135 - Loss: 0.8169648051261902\n",
      "Ep 99: Batch #136 - Loss: 1.037840723991394\n",
      "Ep 99: Batch #137 - Loss: 0.747452437877655\n",
      "Ep 99: Batch #138 - Loss: 0.8944711685180664\n",
      "Ep 99: Batch #139 - Loss: 0.669158399105072\n",
      "Ep 99: Batch #140 - Loss: 0.8389270305633545\n",
      "Ep 99: Batch #141 - Loss: 1.0982269048690796\n",
      "Ep 99: Batch #142 - Loss: 0.665794312953949\n",
      "Ep 99: Batch #143 - Loss: 0.7604171633720398\n",
      "Ep 99: Batch #144 - Loss: 0.606183648109436\n",
      "Ep 99: Batch #145 - Loss: 0.5966168642044067\n",
      "Ep 99: Batch #146 - Loss: 0.6918672323226929\n",
      "Ep 99: Batch #147 - Loss: 0.6581246852874756\n",
      "Ep 99: Batch #148 - Loss: 0.7531784176826477\n",
      "Ep 99: Batch #149 - Loss: 0.6097739934921265\n",
      "Ep 99: Batch #150 - Loss: 0.7208859324455261\n",
      "Ep 99: Batch #151 - Loss: 0.6212171316146851\n",
      "Ep 99: Batch #152 - Loss: 0.6087472438812256\n",
      "Ep 99: Batch #153 - Loss: 0.8162209987640381\n",
      "Ep 99: Batch #154 - Loss: 0.6326256394386292\n",
      "Ep 99: Batch #155 - Loss: 0.6809613108634949\n",
      "Ep 99: Batch #156 - Loss: 0.7636030316352844\n",
      "Ep 99: Batch #157 - Loss: 0.6087621450424194\n",
      "Ep 99: Batch #158 - Loss: 0.7164697051048279\n",
      "Ep 99: Batch #159 - Loss: 0.5941689610481262\n",
      "Ep 99: Batch #160 - Loss: 0.6893754005432129\n",
      "Ep 99: Batch #161 - Loss: 0.6683592200279236\n",
      "Ep 99: Batch #162 - Loss: 0.7235492467880249\n",
      "Ep 99: Batch #163 - Loss: 0.7520495057106018\n",
      "Ep 99: Batch #164 - Loss: 0.6404783725738525\n",
      "Ep 99: Batch #165 - Loss: 1.333224892616272\n",
      "Ep 99: Batch #166 - Loss: 0.5288804769515991\n",
      "Ep 99: Batch #167 - Loss: 0.6953950524330139\n",
      "Ep 99: Batch #168 - Loss: 0.6878647208213806\n",
      "Ep 99: Batch #169 - Loss: 0.667219340801239\n",
      "Ep 99: Batch #170 - Loss: 0.6291062831878662\n",
      "Ep 99: Batch #171 - Loss: 0.6373991370201111\n",
      "Ep 99: Batch #172 - Loss: 0.5332910418510437\n",
      "Ep 99: Batch #173 - Loss: 0.9202606081962585\n",
      "Ep 99: Batch #174 - Loss: 0.4931498169898987\n",
      "Ep 99: Batch #175 - Loss: 0.6349806785583496\n",
      "Ep 99: Batch #176 - Loss: 0.8926920890808105\n",
      "Ep 99: Batch #177 - Loss: 0.6447495222091675\n",
      "Ep 99: Batch #178 - Loss: 0.6151264309883118\n",
      "Ep 99: Batch #179 - Loss: 0.7483110427856445\n",
      "Ep 99: Batch #180 - Loss: 0.6445409059524536\n",
      "Ep 99: Batch #181 - Loss: 0.7797866463661194\n",
      "Ep 99: Batch #182 - Loss: 0.6283926367759705\n",
      "Ep 99: Batch #183 - Loss: 0.6015549302101135\n",
      "Ep 99: Batch #184 - Loss: 0.8966765403747559\n",
      "Ep 99: Batch #185 - Loss: 0.6313170194625854\n",
      "Ep 99: Batch #186 - Loss: 0.7360705733299255\n",
      "Ep 99: Batch #187 - Loss: 0.8528569340705872\n",
      "Ep 99: Batch #188 - Loss: 0.9159333109855652\n",
      "Ep 99: Batch #189 - Loss: 0.5862833857536316\n",
      "Ep 99: Batch #190 - Loss: 0.6149163842201233\n",
      "Ep 99: Batch #191 - Loss: 0.7858814001083374\n",
      "Ep 99: Batch #192 - Loss: 0.5725069642066956\n",
      "Ep 99: Batch #193 - Loss: 0.6250429749488831\n",
      "Ep 99: Batch #194 - Loss: 0.5388786196708679\n",
      "Ep 99: Batch #195 - Loss: 0.7747510671615601\n",
      "Ep 99: Batch #196 - Loss: 0.6868844628334045\n",
      "Ep 99: Batch #197 - Loss: 0.6910009980201721\n",
      "Ep 99: Batch #198 - Loss: 0.535437285900116\n",
      "Ep 99: Batch #199 - Loss: 0.6417500376701355\n"
     ]
    }
   ],
   "source": [
    "losses = []\n",
    "min_loss = float(\"inf\")\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for epoch in range(100):\n",
    "        for i in range(200):\n",
    "            batch = next_batch(100, i)\n",
    "    #         print(batch[0].shape, batch[1].shape)\n",
    "#             train_step.run(feed_dict={x: batch})\n",
    "            _, current_loss = sess.run([train_step, loss], feed_dict={x:batch})\n",
    "            losses.append(current_loss)\n",
    "            print(\"Ep {}: Batch #{} - Loss: {}\".format(epoch, i, losses[-1]))\n",
    "            if losses[-1] < min_loss:\n",
    "                min_loss = losses[-1]\n",
    "                save_path = saver.save(sess, \"./weights_autoencoder_sigmoid/model_e{}b{}_{}.ckpt\".format(epoch, i, time.time()))\n",
    "                print(\"Model saved in file: %s\" % save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW4AAAD8CAYAAABXe05zAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYDsAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fe479a8c748>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Sigmoid\n",
    "plt.plot(losses)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW4AAAD8CAYAAABXe05zAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f09c80f6f28>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#ReLU\n",
    "plt.plot(losses)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlYAAAJOCAYAAAB1IEnpAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fe476f92588>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_points_31D = {\"s005\":[], \"s010\":[], \"s011\":[], \"s016\":[]}\n",
    "plot_points_2D = {\"s005\":[], \"s010\":[], \"s011\":[], \"s016\":[]}\n",
    "for i, point in enumerate(norm_keystrokes):\n",
    "    if recordings[i][0] in vis_users:\n",
    "        plot_points_31D[recordings[i][0]].append(point)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for user in plot_points_31D:\n",
    "        points_31D = np.array(plot_points_31D[user])\n",
    "        points_2D = sess.run(embedding_2D, feed_dict={x:points_31D})\n",
    "        plot_points_2D[user] = points_2D\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "for user in plot_points_2D:\n",
    "    plt.scatter(plot_points_2D[user][:,0], plot_points_2D[user][:,1], c=colors[user])\n",
    "plt.title(\"Dados de digitação dos usuários {}\".format(\", \".join(vis_users)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlYAAAJOCAYAAAB1IEnpAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fe476f92588>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Sigmoid\n",
    "plot_points_31D = {\"s005\":[], \"s010\":[], \"s011\":[], \"s016\":[]}\n",
    "plot_points_2D = {\"s005\":[], \"s010\":[], \"s011\":[], \"s016\":[]}\n",
    "for i, point in enumerate(norm_keystrokes):\n",
    "    if recordings[i][0] in vis_users:\n",
    "        plot_points_31D[recordings[i][0]].append(point)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for user in plot_points_31D:\n",
    "        points_31D = np.array(plot_points_31D[user])\n",
    "        points_2D = sess.run(embedding_2D, feed_dict={x:points_31D})\n",
    "        plot_points_2D[user] = points_2D\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "for user in plot_points_2D:\n",
    "    plt.scatter(plot_points_2D[user][:,0], plot_points_2D[user][:,1], c=colors[user])\n",
    "plt.title(\"Dados de digitação dos usuários {}\".format(\", \".join(vis_users)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classificação\n",
    "Agora que temos um melhor entendimento dos dados do dataset, passemos à parte de classificação de dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.5  1.5  1.5]\n",
      "[[-1. -1. -1.]\n",
      " [ 1.  1.  1.]]\n"
     ]
    }
   ],
   "source": [
    "s = np.std(a, axis=0)\n",
    "n = (a - m) / s\n",
    "print(s)\n",
    "print(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 0 0 0]\n",
      " [0 2 0 0]\n",
      " [0 0 0 0]\n",
      " [0 0 0 0]] \n",
      "\n",
      " [[ 1  2  3  4]\n",
      " [ 5  6  7  8]\n",
      " [ 9 10 11 12]\n",
      " [13 14 15 16]]\n",
      "\n",
      " [[ 1  2  3  4]\n",
      " [10 12 14 16]\n",
      " [ 0  0  0  0]\n",
      " [ 0  0  0  0]]\n"
     ]
    }
   ],
   "source": [
    "a = np.diag([1,2,0,0])\n",
    "b = np.array([[1,2,3,4],[5,6,7,8],[9,10,11,12],[13,14,15,16]])\n",
    "c = a @ b\n",
    "print(a,\"\\n\\n\", b)\n",
    "print(\"\\n\",c)\n",
    "print(b )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 0 0 0]\n",
      " [2 0 0 0]\n",
      " [0 1 0 0]\n",
      " [0 2 0 0]\n",
      " [0 1 1 0]\n",
      " [1 0 0 1]]\n",
      "\n",
      "[[  0.00000000e+00  -3.94599292e-01  -2.10455217e-01   0.00000000e+00\n",
      "    0.00000000e+00  -8.94427191e-01]\n",
      " [  0.00000000e+00  -7.89198585e-01  -4.20910435e-01   0.00000000e+00\n",
      "    0.00000000e+00   4.47213595e-01]\n",
      " [ -3.94599292e-01   0.00000000e+00   0.00000000e+00  -2.10455217e-01\n",
      "   -8.94427191e-01   0.00000000e+00]\n",
      " [ -7.89198585e-01   0.00000000e+00   0.00000000e+00  -4.20910435e-01\n",
      "    4.47213595e-01   0.00000000e+00]\n",
      " [ -4.70592172e-01   0.00000000e+00   0.00000000e+00   8.82350841e-01\n",
      "    0.00000000e+00   0.00000000e+00]\n",
      " [  0.00000000e+00  -4.70592172e-01   8.82350841e-01   0.00000000e+00\n",
      "    0.00000000e+00   1.11022302e-16]]\n",
      "\n",
      "[ 2.48848998  2.48848998  0.89856419  0.89856419]\n",
      "\n",
      "[[-0.         -0.98195639 -0.18910752  0.        ]\n",
      " [-0.98195639  0.         -0.         -0.18910752]\n",
      " [-0.18910752  0.          0.          0.98195639]\n",
      " [-0.         -0.18910752  0.98195639  0.        ]]\n",
      "\n",
      "[[ 2.48848998  0.          0.          0.        ]\n",
      " [ 0.          2.48848998  0.          0.        ]\n",
      " [ 0.          0.          0.89856419  0.        ]\n",
      " [ 0.          0.          0.          0.89856419]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]]\n",
      "================================================== \n",
      "\n",
      "\n",
      "[[  1.00000000e+00   0.00000000e+00   0.00000000e+00   1.66533454e-16]\n",
      " [  2.00000000e+00   0.00000000e+00   0.00000000e+00  -5.55111512e-17]\n",
      " [  0.00000000e+00   1.00000000e+00   5.55111512e-17   0.00000000e+00]\n",
      " [  0.00000000e+00   2.00000000e+00   0.00000000e+00   0.00000000e+00]\n",
      " [  0.00000000e+00   1.00000000e+00   1.00000000e+00   0.00000000e+00]\n",
      " [  1.00000000e+00   0.00000000e+00   0.00000000e+00   1.00000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "t = np.array([[1,0,0,0],[2,0,0,0],[0,1,0,0],[0,2,0,0],[0,1,1,0],[1,0,0,1]])\n",
    "# t = t.T\n",
    "d = np.linalg.svd(t)\n",
    "print(t, end=\"\\n\\n\")\n",
    "print(d[0], d[1], d[2], sep=\"\\n\\n\", end=\"\\n\\n\")\n",
    "ss = np.zeros((6,4))\n",
    "# d[1][2] = 0\n",
    "# d[1][3] = 0\n",
    "for i, e in enumerate(d[1]):\n",
    "    ss[i,i] = e\n",
    "print(ss)\n",
    "print(\"=\"*50, \"\\n\\n\")\n",
    "print(d[0]@ss@d[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "partial = keystrokes[:2000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.1227,  0.3441,  0.2214, ...,  0.2655,  0.1832,  0.1084],\n",
       "       [ 0.0377,  0.5097,  0.472 , ...,  0.4406,  0.4013,  0.0364],\n",
       "       [ 0.0853,  0.1757,  0.0904, ...,  0.1929,  0.1121,  0.0829],\n",
       "       ..., \n",
       "       [ 0.0776,  0.3103,  0.2327, ...,  0.2907,  0.1917,  0.0945],\n",
       "       [ 0.0591,  0.265 ,  0.2059, ...,  0.5553,  0.4746,  0.0886],\n",
       "       [ 0.0657,  0.409 ,  0.3433, ...,  0.3733,  0.2881,  0.072 ]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "decomp = np.linalg.svd(partial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000, 2000)\n",
      "(31,)\n",
      "(31, 31)\n"
     ]
    }
   ],
   "source": [
    "U, sigma, Vt = decomp\n",
    "print(U.shape)\n",
    "print(sigma.shape)\n",
    "print(Vt.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  5.37860351e+01   1.45971181e+01   1.39542872e+01   1.13840973e+01\n",
      "   9.56374289e+00   9.20264712e+00   7.71927016e+00   7.52113688e+00\n",
      "   6.41529380e+00   5.77067003e+00   5.50869931e+00   1.58892232e+00\n",
      "   1.37413431e+00   1.25452098e+00   1.12088379e+00   1.08756954e+00\n",
      "   9.80826384e-01   8.76163838e-01   8.50212712e-01   8.28806611e-01\n",
      "   7.73274781e-01   3.51964339e-14   1.44156497e-14   1.19870887e-14\n",
      "   7.79112368e-15   7.74209255e-15   5.80840869e-15   4.44215664e-15\n",
      "   4.44215664e-15   3.54364698e-15   2.97049823e-15]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7ff91d897320>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(sigma)\n",
    "plt.plot(sigma)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 53.7860351    0.           0.         ...,   0.           0.           0.        ]\n",
      " [  0.          14.59711807   0.         ...,   0.           0.           0.        ]\n",
      " [  0.           0.           0.         ...,   0.           0.           0.        ]\n",
      " ..., \n",
      " [  0.           0.           0.         ...,   0.           0.           0.        ]\n",
      " [  0.           0.           0.         ...,   0.           0.           0.        ]\n",
      " [  0.           0.           0.         ...,   0.           0.           0.        ]]\n",
      "[[ -6.75936637e-02  -2.49557191e-01]\n",
      " [ -1.83758381e-02   4.50418569e-01]\n",
      " [  1.78634943e-02   1.04421094e-01]\n",
      " [ -6.48506372e-02   4.12272012e-01]\n",
      " [  1.63725324e-01   2.09097054e-01]\n",
      " [ -1.31253972e-01   2.51447174e-02]\n",
      " [  7.42528957e-02   8.41307492e-02]\n",
      " [ -3.02612331e-02  -1.04679674e-01]\n",
      " [  5.76043880e-02   2.65105431e-02]\n",
      " [ -6.14543112e-02  -2.18016951e-02]\n",
      " [  5.57318797e-02   4.99800247e-02]\n",
      " [ -2.57013496e-01  -1.26424121e-01]\n",
      " [  3.85613053e-01   1.98459893e-01]\n",
      " [  7.74264202e-02   4.40429441e-02]\n",
      " [  3.85448027e-01   1.96395380e-01]\n",
      " [  9.79429630e-02   5.08728620e-02]\n",
      " [ -4.20698848e-01  -2.14278003e-01]\n",
      " [ -1.84091623e-01  -9.11536096e-02]\n",
      " [ -7.16081119e-02  -3.72812831e-02]\n",
      " [ -2.48134977e-02  -1.25010711e-02]\n",
      " [ -3.22447406e-02  -1.82936452e-02]\n",
      " [ -1.69083877e-01   1.69083877e-01]\n",
      " [ -5.52036209e-01   5.52036209e-01]\n",
      " [ -0.00000000e+00  -9.29213601e-15]\n",
      " [  0.00000000e+00   2.26755533e-15]\n",
      " [  0.00000000e+00   2.07052325e-15]\n",
      " [  0.00000000e+00  -7.88690537e-16]\n",
      " [  0.00000000e+00   1.32282085e-16]\n",
      " [  0.00000000e+00  -2.35208761e-16]\n",
      " [  0.00000000e+00  -8.93876480e-16]\n",
      " [  0.00000000e+00   1.47847935e-15]]\n",
      "[[ 0.10593932  0.28981998]\n",
      " [ 0.10540816  0.59793701]\n",
      " [ 0.04637591  0.17384805]\n",
      " ..., \n",
      " [ 0.07725431  0.3062696 ]\n",
      " [ 0.06016892  0.36243945]\n",
      " [ 0.08317183  0.42905028]]\n"
     ]
    }
   ],
   "source": [
    "Sigma = np.zeros((2000, 31))\n",
    "Sigma[0][0] = sigma[0]\n",
    "Sigma[1][1] = sigma[1]\n",
    "print(Sigma)\n",
    "\n",
    "Vt_2D = np.zeros((Vt.shape[0],2))\n",
    "Vt_2D[:,:2] = Vt[:,:2]\n",
    "print(Vt_2D)\n",
    "\n",
    "partial_2D = U.dot(Sigma.dot(Vt_2D))\n",
    "print(partial_2D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 53.7860351    0.           0.         ...,   0.           0.           0.        ]\n",
      " [  0.          14.59711807   0.         ...,   0.           0.           0.        ]\n",
      " [  0.           0.           0.         ...,   0.           0.           0.        ]\n",
      " ..., \n",
      " [  0.           0.           0.         ...,   0.           0.           0.        ]\n",
      " [  0.           0.           0.         ...,   0.           0.           0.        ]\n",
      " [  0.           0.           0.         ...,   0.           0.           0.        ]]\n",
      "[[-1.51415386 -0.19548041]\n",
      " [-1.66894887  0.40282269]\n",
      " [-0.68747665  0.0050693 ]\n",
      " ..., \n",
      " [-1.15396163  0.04060706]\n",
      " [-0.96374844  0.27070175]\n",
      " [-1.29445221  0.2353598 ]]\n",
      "(2000, 2)\n"
     ]
    }
   ],
   "source": [
    "print(Sigma)\n",
    "pp_2D = U@Sigma[:,:2]\n",
    "print(pp_2D)\n",
    "print(pp_2D.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = {\n",
    "    \"s002\": \"#0048BA\",\n",
    "    \"s003\": \"#B0BF1A\",\n",
    "    \"s004\": \"#7CB9E8\",\n",
    "    \"s005\": \"#C9FFE5\",\n",
    "    \"s007\": \"#B284BE\",\n",
    "    \"s008\": \"#00308F\",\n",
    "    \"s010\": \"#72A0C1\",\n",
    "    \"s011\": \"#AF002A\",\n",
    "    \"s012\": \"#84DE02\",\n",
    "    \"s013\": \"#E32636\",\n",
    "    \"s015\": \"#C46210\",\n",
    "    \"s016\": \"#EFDECD\",\n",
    "    \"s017\": \"#E52B50\",\n",
    "    \"s018\": \"#9F2B68\",\n",
    "    \"s019\": \"#F19CBB\",\n",
    "    \"s020\": \"#AB274F\",\n",
    "    \"s021\": \"#D3212D\",\n",
    "    \"s022\": \"#3B7A57\",\n",
    "    \"s024\": \"#FFBF00\",\n",
    "    \"s025\": \"#FF7E00\",\n",
    "    \"s026\": \"#3B3B6D\",\n",
    "    \"s027\": \"#391802\",\n",
    "    \"s028\": \"#804040\",\n",
    "    \"s029\": \"#D3AF37\",\n",
    "    \"s030\": \"#34B334\",\n",
    "    \"s031\": \"#FF8B00\",\n",
    "    \"s032\": \"#FF9899\",\n",
    "    \"s033\": \"#431C53\",\n",
    "    \"s034\": \"#B32134\",\n",
    "    \"s035\": \"#FF033E\",\n",
    "    \"s036\": \"#CFCFCF\",\n",
    "    \"s037\": \"#551B8C\",\n",
    "    \"s038\": \"#F2B400\",\n",
    "    \"s039\": \"#9966CC\",\n",
    "    \"s040\": \"#A4C639\",\n",
    "    \"s041\": \"#F2F3F4\",\n",
    "    \"s042\": \"#CD9575\",\n",
    "    \"s043\": \"#665D1E\",\n",
    "    \"s044\": \"#915C83\",\n",
    "    \"s046\": \"#841B2D\",\n",
    "    \"s047\": \"#FAEBD7\",\n",
    "    \"s048\": \"#008000\",\n",
    "    \"s049\": \"#66B447\",\n",
    "    \"s050\": \"#8DB600\",\n",
    "    \"s051\": \"#FBCEB1\",\n",
    "    \"s052\": \"#00FFFF\",\n",
    "    \"s053\": \"#7FFFD4\",\n",
    "    \"s054\": \"#D0FF14\",\n",
    "    \"s055\": \"#C0C0C0\",\n",
    "    \"s056\": \"#4B5320\",\n",
    "    \"s057\": \"#3B444B\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7ff919bf0f28>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(20,20))\n",
    "for i, point in enumerate(partial_2D):\n",
    "    if recordings[i][0] == \"s002\" or recordings[i][0] == \"s004\":\n",
    "        plt.scatter(point[0], point[1], c=colors[recordings[i][0]])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7ff91b5ff860>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(20,20))\n",
    "for i, point in enumerate(pp_2D):\n",
    "    if recordings[i][0] == \"s002\" or recordings[i][0] == \"s013\" or recordings[i][0] == \"s011\" or recordings[i][0] == \"s015\":\n",
    "        plt.scatter(point[0], point[1], c=colors[recordings[i][0]])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.10593932,  0.28981998],\n",
       "       [ 0.10540816,  0.59793701],\n",
       "       [ 0.04637591,  0.17384805],\n",
       "       ..., \n",
       "       [ 0.07725431,  0.3062696 ],\n",
       "       [ 0.06016892,  0.36243945],\n",
       "       [ 0.08317183,  0.42905028]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "partial_2D"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
